<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7371 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7371</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7371</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-273229366</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.05440v3.pdf" target="_blank">Can LLMs Understand Time Series Anomalies?</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have gained popularity in time series forecasting, but their potential for anomaly detection remains largely unexplored. Our study investigates whether LLMs can understand and detect anomalies in time series data, focusing on zero-shot and few-shot scenarios. Inspired by conjectures about LLMs' behavior from time series forecasting research, we formulate key hypotheses about LLMs' capabilities in time series anomaly detection. We design and conduct principled experiments to test each of these hypotheses. Our investigation reveals several surprising findings about LLMs for time series: (1) LLMs understand time series better as images rather than as text, (2) LLMs do not demonstrate enhanced performance when prompted to engage in explicit reasoning about time series analysis. (3) Contrary to common beliefs, LLMs' understanding of time series does not stem from their repetition biases or arithmetic abilities. (4) LLMs' behaviors and performance in time series analysis vary significantly across different models. This study provides the first comprehensive analysis of contemporary LLM capabilities in time series anomaly detection. Our results suggest that while LLMs can understand trivial time series anomalies, we have no evidence that they can understand more subtle real-world anomalies. Many common conjectures based on their reasoning capabilities do not hold. All synthetic dataset generators, final prompts, and evaluation scripts have been made available in https://github.com/rose-stl-lab/anomllm.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7371.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7371.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o-mini</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o-mini (gpt-4o-2024-08-06)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proprietary multimodal, instruction-tuned decoder LLM variant used with and without image inputs; supports large context windows and was evaluated for zero-/few-shot time-series anomaly detection using textual and visual prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o-mini</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multimodal (text+vision) decoder-only LLM variant, instruction-tuned; evaluated via API with image-capable endpoints.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting-based detection (zero-shot and 1-shot few-shot) with explicit JSON-structured outputs; evaluated both on raw textual encodings of time series and on visualized plots passed as images to the model.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Default: "Detect ranges of anomalies in this time series, in terms of the x-axis coordinate. List one by one, in JSON format. If there are no anomalies, answer with an empty list []." Variants included: add "Let's think step by step" for zero-shot CoT, 1-shot example JSON answers, DysCalc/Calc contexts, and text-format variants (CSV, Prompt-as-Prefix, Token-per-Digit).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>univariate time series (numeric vector) presented as text or as visualization images</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic datasets (point, range, trend, frequency, noisy variants, flat-trend) and Yahoo S5 (Webscope S5)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 (interval->point conversion) and affinity-precision / affinity-recall; affinity F1 reported as main metric</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported results show substantial variability by modality and prompt variant; visual (vision) inputs substantially improved affinity-F1 relative to text in many conditions. Best vision few-shot variants reached affinity-F1 in the high tens to low 80s in some settings (paper reports top vision affi-F1 values up to ≈81 across models/datasets), while many text-only variants produced much lower affi-F1 (often single-digit to low tens) depending on dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Baselines used: Isolation Forest (SciPy impl.) and simple thresholding (top/bottom 2%). Paper reports that LLMs with appropriate prompts and visual input outperform these simple baselines on many point, range and trend datasets, though Isolation Forest can produce different trade-offs (higher recall with many false positives).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Both zero-shot and few-shot (primarily 1-shot) prompting were evaluated; 1-shot few-shot configurations (single labeled example) were commonly used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>CoT prompting often decreased performance; model struggled on frequency anomalies (visual and text) relative to point/range/trend anomalies; long input token sequences degraded text performance (subsampling S0.3 often improved results); arithmetic impairment (DysCalc) had little impact on anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can LLMs Understand Time Series Anomalies?', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7371.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7371.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini-1.5-Flash</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini-1.5-Flash</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proprietary fast multimodal LLM (Google) optimized for long-context and high-throughput tasks; evaluated as an M-LLM for detecting anomalous intervals in time series presented as text and visual plots.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemini-1.5-Flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Proprietary multimodal (text+vision) LLM optimized for speed and long context; instruction-tuned for multimodal tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting-based anomaly interval detection (zero-shot and 1-shot), using structured JSON outputs; experiments included text encodings (CSV, PaP, TPD) and vision (matplotlib plots) inputs, and CoT variants.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same default prompt as other models; CoT: prepend "Let's think step by step"; one-shot variants provided a single labeled example and JSON-format answer template; DysCalc/Calc variants to manipulate arithmetic competence.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>univariate time series (numeric vector) as raw numbers or visualized charts</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic datasets (point, range, frequency, trend, noisy variants, flat-trend) and Yahoo S5</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 and affinity-precision/affinity-recall; affinity F1 used as primary metric</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Gemini often achieved among the best overall performance across evaluated models (paper notes Gemini-1.5-Flash typically had the best performance among models in many experiments); vision inputs improved results but Gemini still struggled on visual frequency anomalies. Reported top affi-F1 values for some vision few-shot settings were high relative to text variants (paper shows top-1 aff-F1 comparisons where Gemini is competitive).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against Isolation Forest and thresholding baselines; Gemini-based vision prompts outperformed these baselines on many datasets (point/range/trend), but frequency anomalies remained challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Both zero-shot and 1-shot few-shot evaluated; research often reports best-performing 1-shot vision variants.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Poor performance on frequency anomalies in vision mode; CoT rarely improved and often reduced performance; sensitive to prompt/text representation choices and long token sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can LLMs Understand Time Series Anomalies?', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7371.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7371.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen-VL-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen-VL-Chat (Qwen vision-language chat)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source vision-language model (text initialized with Qwen-7B, vision encoder OpenCLIP ViT-bigG) evaluated for time-series anomaly detection from both textual and visual inputs; showed strong visual capability but weak text-only performance in some settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen-VL-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source multimodal vision-language model combining a Qwen text backbone (7B variant used) and ViT-based vision encoder; used via local inference (vLLM) in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B (text backbone) + ViT vision encoder</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting-based (zero-shot and 1-shot) interval detection with JSON output; compared text encodings (Original, CSV, PaP, Token-per-Digit) and vision (plotted images) inputs; CoT and DysCalc variants also tested.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Default JSON-range prompt; variants include CoT prompts, 1-shot example answers, PaP, CSV, TPD and S0.3 subsampling. The JSON output example was included in prompts to enforce structured output.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>univariate time series as text or plotted visualizations</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic datasets (point, range, frequency, trend, noisy variants, flat-trend) and Yahoo S5</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision/Recall/F1 and affinity-precision/affinity-recall with affinity F1 as main metric</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Qwen performed substantially better on vision inputs than on text; the paper reports many text variants for Qwen as near-zero while vision variants produced non-trivial affinity-F1. Overall vision-case improvements indicate Qwen's relative strength as a vision-capable M-LLM for visual anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Isolation Forest and thresholding baselines included; Qwen-vision outperformed text-only Qwen and often outperformed simple baselines on point/range/trend datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot and 1-shot evaluated; Qwen often required PaP or other short-statistic prompts in text mode to get non-zero results.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Text-mode performance was often poor (near-zero) without PaP or subsampling; CoT reduced performance; frequency anomalies were challenging; Token-per-Digit did not reliably help (and sometimes hurt) due to tokenization and token count effects.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can LLMs Understand Time Series Anomalies?', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7371.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7371.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>InternVL2-Llama3-76B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>InternVL2-Llama3-76B (InternVL 2 multimodal LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source multimodal model combining an InternViT vision encoder with a LLaMA3-derived language backbone (Hermes-2-Theta-LLaMA3-70B initialization) evaluated for time-series anomaly interval detection from text and images.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>InternVL2-Llama3-76B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multimodal LLM (vision encoder InternViT, language part initialized from Hermes-2-Theta-LLaMA3-70B / LLaMA3 family) supporting large visual inputs; run via LMDeploy in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>76B (composite model name indicates ~76B language+vision checkpoint)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting-based anomaly interval detection (zero-shot and 1-shot), evaluating both plotted visual inputs and textual encodings; JSON-structured interval outputs; CoT and specialized prompt variants tested.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Default JSON-format interval detection prompt; CoT variants include "Let's think step by step"; one-shot template provides example annotation in JSON; text encodings included CSV, PaP, TPD and subsampling S0.3.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>numeric univariate time series as text or visualized plots</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic datasets (point, range, frequency, trend, noisy variants, flat-trend) and Yahoo S5</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 and affinity-precision/affinity-recall; affinity F1 used as the main metric</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>InternVL2 showed more balanced vision/text performance than some other models but still followed the general trend: vision inputs outperform raw text for many anomaly types. Reported affinity-F1 values varied across datasets and prompt variants; interpolation (S0.3) often improved text-mode results.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with Isolation Forest and thresholding; InternVL2's vision-mode often improved over text and against baselines on point/range/trend datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot and 1-shot (few-shot) evaluated; many best-performing configurations used few-shot vision prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Frequency anomalies and long-context text sequences presented challenges; CoT did not improve detection and often hurt; tokenization/TPD effects were model-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can LLMs Understand Time Series Anomalies?', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large language models are zero-shot time series forecasters <em>(Rating: 2)</em></li>
                <li>Can llms serve as time series anomaly detectors? <em>(Rating: 2)</em></li>
                <li>Time-LLM: Time series forecasting by reprogramming large language models <em>(Rating: 2)</em></li>
                <li>Yahoo anomaly detection dataset S5 <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7371",
    "paper_id": "paper-273229366",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "GPT-4o-mini",
            "name_full": "GPT-4o-mini (gpt-4o-2024-08-06)",
            "brief_description": "A proprietary multimodal, instruction-tuned decoder LLM variant used with and without image inputs; supports large context windows and was evaluated for zero-/few-shot time-series anomaly detection using textual and visual prompts.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o-mini",
            "model_description": "Multimodal (text+vision) decoder-only LLM variant, instruction-tuned; evaluated via API with image-capable endpoints.",
            "model_size": null,
            "anomaly_detection_approach": "Prompting-based detection (zero-shot and 1-shot few-shot) with explicit JSON-structured outputs; evaluated both on raw textual encodings of time series and on visualized plots passed as images to the model.",
            "prompt_template": "Default: \"Detect ranges of anomalies in this time series, in terms of the x-axis coordinate. List one by one, in JSON format. If there are no anomalies, answer with an empty list [].\" Variants included: add \"Let's think step by step\" for zero-shot CoT, 1-shot example JSON answers, DysCalc/Calc contexts, and text-format variants (CSV, Prompt-as-Prefix, Token-per-Digit).",
            "training_data": null,
            "data_type": "univariate time series (numeric vector) presented as text or as visualization images",
            "dataset_name": "Synthetic datasets (point, range, trend, frequency, noisy variants, flat-trend) and Yahoo S5 (Webscope S5)",
            "evaluation_metric": "Precision, Recall, F1 (interval-&gt;point conversion) and affinity-precision / affinity-recall; affinity F1 reported as main metric",
            "performance": "Reported results show substantial variability by modality and prompt variant; visual (vision) inputs substantially improved affinity-F1 relative to text in many conditions. Best vision few-shot variants reached affinity-F1 in the high tens to low 80s in some settings (paper reports top vision affi-F1 values up to ≈81 across models/datasets), while many text-only variants produced much lower affi-F1 (often single-digit to low tens) depending on dataset.",
            "baseline_comparison": "Baselines used: Isolation Forest (SciPy impl.) and simple thresholding (top/bottom 2%). Paper reports that LLMs with appropriate prompts and visual input outperform these simple baselines on many point, range and trend datasets, though Isolation Forest can produce different trade-offs (higher recall with many false positives).",
            "zero_shot_or_few_shot": "Both zero-shot and few-shot (primarily 1-shot) prompting were evaluated; 1-shot few-shot configurations (single labeled example) were commonly used.",
            "limitations_or_failure_cases": "CoT prompting often decreased performance; model struggled on frequency anomalies (visual and text) relative to point/range/trend anomalies; long input token sequences degraded text performance (subsampling S0.3 often improved results); arithmetic impairment (DysCalc) had little impact on anomaly detection.",
            "computational_cost": null,
            "uuid": "e7371.0",
            "source_info": {
                "paper_title": "Can LLMs Understand Time Series Anomalies?",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Gemini-1.5-Flash",
            "name_full": "Gemini-1.5-Flash",
            "brief_description": "A proprietary fast multimodal LLM (Google) optimized for long-context and high-throughput tasks; evaluated as an M-LLM for detecting anomalous intervals in time series presented as text and visual plots.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Gemini-1.5-Flash",
            "model_description": "Proprietary multimodal (text+vision) LLM optimized for speed and long context; instruction-tuned for multimodal tasks.",
            "model_size": null,
            "anomaly_detection_approach": "Prompting-based anomaly interval detection (zero-shot and 1-shot), using structured JSON outputs; experiments included text encodings (CSV, PaP, TPD) and vision (matplotlib plots) inputs, and CoT variants.",
            "prompt_template": "Same default prompt as other models; CoT: prepend \"Let's think step by step\"; one-shot variants provided a single labeled example and JSON-format answer template; DysCalc/Calc variants to manipulate arithmetic competence.",
            "training_data": null,
            "data_type": "univariate time series (numeric vector) as raw numbers or visualized charts",
            "dataset_name": "Synthetic datasets (point, range, frequency, trend, noisy variants, flat-trend) and Yahoo S5",
            "evaluation_metric": "Precision, Recall, F1 and affinity-precision/affinity-recall; affinity F1 used as primary metric",
            "performance": "Gemini often achieved among the best overall performance across evaluated models (paper notes Gemini-1.5-Flash typically had the best performance among models in many experiments); vision inputs improved results but Gemini still struggled on visual frequency anomalies. Reported top affi-F1 values for some vision few-shot settings were high relative to text variants (paper shows top-1 aff-F1 comparisons where Gemini is competitive).",
            "baseline_comparison": "Compared against Isolation Forest and thresholding baselines; Gemini-based vision prompts outperformed these baselines on many datasets (point/range/trend), but frequency anomalies remained challenging.",
            "zero_shot_or_few_shot": "Both zero-shot and 1-shot few-shot evaluated; research often reports best-performing 1-shot vision variants.",
            "limitations_or_failure_cases": "Poor performance on frequency anomalies in vision mode; CoT rarely improved and often reduced performance; sensitive to prompt/text representation choices and long token sequences.",
            "computational_cost": null,
            "uuid": "e7371.1",
            "source_info": {
                "paper_title": "Can LLMs Understand Time Series Anomalies?",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Qwen-VL-Chat",
            "name_full": "Qwen-VL-Chat (Qwen vision-language chat)",
            "brief_description": "An open-source vision-language model (text initialized with Qwen-7B, vision encoder OpenCLIP ViT-bigG) evaluated for time-series anomaly detection from both textual and visual inputs; showed strong visual capability but weak text-only performance in some settings.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen-VL-Chat",
            "model_description": "Open-source multimodal vision-language model combining a Qwen text backbone (7B variant used) and ViT-based vision encoder; used via local inference (vLLM) in experiments.",
            "model_size": "7B (text backbone) + ViT vision encoder",
            "anomaly_detection_approach": "Prompting-based (zero-shot and 1-shot) interval detection with JSON output; compared text encodings (Original, CSV, PaP, Token-per-Digit) and vision (plotted images) inputs; CoT and DysCalc variants also tested.",
            "prompt_template": "Default JSON-range prompt; variants include CoT prompts, 1-shot example answers, PaP, CSV, TPD and S0.3 subsampling. The JSON output example was included in prompts to enforce structured output.",
            "training_data": null,
            "data_type": "univariate time series as text or plotted visualizations",
            "dataset_name": "Synthetic datasets (point, range, frequency, trend, noisy variants, flat-trend) and Yahoo S5",
            "evaluation_metric": "Precision/Recall/F1 and affinity-precision/affinity-recall with affinity F1 as main metric",
            "performance": "Qwen performed substantially better on vision inputs than on text; the paper reports many text variants for Qwen as near-zero while vision variants produced non-trivial affinity-F1. Overall vision-case improvements indicate Qwen's relative strength as a vision-capable M-LLM for visual anomaly detection.",
            "baseline_comparison": "Isolation Forest and thresholding baselines included; Qwen-vision outperformed text-only Qwen and often outperformed simple baselines on point/range/trend datasets.",
            "zero_shot_or_few_shot": "Zero-shot and 1-shot evaluated; Qwen often required PaP or other short-statistic prompts in text mode to get non-zero results.",
            "limitations_or_failure_cases": "Text-mode performance was often poor (near-zero) without PaP or subsampling; CoT reduced performance; frequency anomalies were challenging; Token-per-Digit did not reliably help (and sometimes hurt) due to tokenization and token count effects.",
            "computational_cost": null,
            "uuid": "e7371.2",
            "source_info": {
                "paper_title": "Can LLMs Understand Time Series Anomalies?",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "InternVL2-Llama3-76B",
            "name_full": "InternVL2-Llama3-76B (InternVL 2 multimodal LLM)",
            "brief_description": "An open-source multimodal model combining an InternViT vision encoder with a LLaMA3-derived language backbone (Hermes-2-Theta-LLaMA3-70B initialization) evaluated for time-series anomaly interval detection from text and images.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "InternVL2-Llama3-76B",
            "model_description": "Multimodal LLM (vision encoder InternViT, language part initialized from Hermes-2-Theta-LLaMA3-70B / LLaMA3 family) supporting large visual inputs; run via LMDeploy in experiments.",
            "model_size": "76B (composite model name indicates ~76B language+vision checkpoint)",
            "anomaly_detection_approach": "Prompting-based anomaly interval detection (zero-shot and 1-shot), evaluating both plotted visual inputs and textual encodings; JSON-structured interval outputs; CoT and specialized prompt variants tested.",
            "prompt_template": "Default JSON-format interval detection prompt; CoT variants include \"Let's think step by step\"; one-shot template provides example annotation in JSON; text encodings included CSV, PaP, TPD and subsampling S0.3.",
            "training_data": null,
            "data_type": "numeric univariate time series as text or visualized plots",
            "dataset_name": "Synthetic datasets (point, range, frequency, trend, noisy variants, flat-trend) and Yahoo S5",
            "evaluation_metric": "Precision, Recall, F1 and affinity-precision/affinity-recall; affinity F1 used as the main metric",
            "performance": "InternVL2 showed more balanced vision/text performance than some other models but still followed the general trend: vision inputs outperform raw text for many anomaly types. Reported affinity-F1 values varied across datasets and prompt variants; interpolation (S0.3) often improved text-mode results.",
            "baseline_comparison": "Compared with Isolation Forest and thresholding; InternVL2's vision-mode often improved over text and against baselines on point/range/trend datasets.",
            "zero_shot_or_few_shot": "Zero-shot and 1-shot (few-shot) evaluated; many best-performing configurations used few-shot vision prompting.",
            "limitations_or_failure_cases": "Frequency anomalies and long-context text sequences presented challenges; CoT did not improve detection and often hurt; tokenization/TPD effects were model-dependent.",
            "computational_cost": null,
            "uuid": "e7371.3",
            "source_info": {
                "paper_title": "Can LLMs Understand Time Series Anomalies?",
                "publication_date_yy_mm": "2024-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large language models are zero-shot time series forecasters",
            "rating": 2,
            "sanitized_title": "large_language_models_are_zeroshot_time_series_forecasters"
        },
        {
            "paper_title": "Can llms serve as time series anomaly detectors?",
            "rating": 2,
            "sanitized_title": "can_llms_serve_as_time_series_anomaly_detectors"
        },
        {
            "paper_title": "Time-LLM: Time series forecasting by reprogramming large language models",
            "rating": 2,
            "sanitized_title": "timellm_time_series_forecasting_by_reprogramming_large_language_models"
        },
        {
            "paper_title": "Yahoo anomaly detection dataset S5",
            "rating": 1,
            "sanitized_title": "yahoo_anomaly_detection_dataset_s5"
        }
    ],
    "cost": 0.01426175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>11 Mar 2025</p>
<p>Zihao Zhou 
Dept of Computer Science and Engineering
University of California
San Diego La Jolla92093CAUSA</p>
<p>Rose Yu roseyu@ucsd.edu 
Dept of Computer Science and Engineering
University of California
San Diego La Jolla92093CAUSA
11 Mar 20255F0E23A56016C0F5CC29714053BD0398arXiv:2410.05440v3[cs.LG]
Large Language Models (LLMs) have gained popularity in time series forecasting, but their potential for anomaly detection remains largely unexplored.Our study investigates whether LLMs can understand and detect anomalies in time series data, focusing on zero-shot and few-shot scenarios.Inspired by conjectures about LLMs' behavior from time series forecasting research, we formulate key hypotheses about LLMs' capabilities in time series anomaly detection.We design and conduct principled experiments to test each of these hypotheses.Our investigation reveals several surprising findings about LLMs for time series: (1) LLMs understand time series better as images rather than as text, (2) LLMs do not demonstrate enhanced performance when prompted to engage in explicit reasoning about time series analysis.(3) Contrary to common beliefs, LLMs' understanding of time series does not stem from their repetition biases or arithmetic abilities.(4) LLMs' behaviors and performance in time series analysis vary significantly across different models.This study provides the first comprehensive analysis of contemporary LLM capabilities in time series anomaly detection.Our results suggest that while LLMs can understand trivial time series anomalies, we have no evidence that they can understand more subtle real-world anomalies.Many common conjectures based on their reasoning capabilities do not hold.All synthetic dataset generators, final prompts, and evaluation scripts have been made available in https://github.com/rose-stl-lab/anomllm.</p>
<p>INTRODUCTION</p>
<p>The remarkable progress in large language models (LLMs) has led to their application in various domains, including time series analysis.Recent studies have demonstrated LLMs' potential as zeroshot and few-shot learners in tasks such as forecasting and classification (Gruver et al., 2023;Liu et al., 2024c).However, the effectiveness of LLMs in time series analysis remains a subject of debate.While some researchers argue that LLMs can leverage their pretrained knowledge to understand time series patterns (Gruver et al., 2023), others suggest that simpler models can match or outperform LLMs (Tan et al., 2024).This debate raises a fundamental question: Do LLMs truly understand time series?To address this question, we must look beyond models' predictive performance.Forecasting typically hinges on metrics like MSE, which can overlook deeper model understanding.A model that simply outputs a nearly constant line might still achieve a passable MSE but reveals little about its capacity to interpret dynamics.Shifting our focus to anomaly detection changes the game: it forces LLMs to pinpoint irregular behavior and thus tests whether they grasp the underlying patterns, not just how well they extrapolate an average.</p>
<p>In this paper, we present the first comprehensive investigation into LLMs' understanding of time series data through the lens of anomaly detection.We focus on state-of-the-art LLMs and multimodal LLMs (M-LLMs) across different anomaly types under controlled conditions.Our evaluation strategy incorporates multimodal inputs (textual and visual representations of time series), various prompting techniques, and structured output formats.The results are quantitatively assessed using the affinity F1 score.We provide empirical evidence to challenge existing conjectures and One reason for using deep learning models in time series anomaly detection is their ability to bring prior knowledge on what constitutes normal behavior from pretraining on large-scale datasets.Large language models (LLMs) may offer a promising solution due to their strong zero-shot capabilities.However, there is currently a lack of systematic study of modern (M-)LLMs for time series anomaly detection, which we aim to address in this work.</p>
<p>Multimodal LLMs (M-LLMs).Multimodal LLMs combine text with other data modalities and have been explored in various domains, including image captioning, video understanding, and multimodal translation (Lu et al., 2019;Li et al., 2019;Sun et al., 2019;Huang et al., 2019).Recent advancements have led to more sophisticated M-LLMs, such as Qwen-VL and Phi-3-Vision, demonstrating superior performance in visual-centric tasks and compact deployment capabilities (Bai et al., 2023;Abdin et al., 2024).In the context of time series analysis, M-LLMs have been used to model multimodal data, such as time series and textual information, showing promising results in forecasting and anomaly detection (Liu et al., 2021).However, there is a notable absence of research applying M-LLMs to time series data presented as visual inputs, even though humans often detect time series anomalies through visual inspection.This gap is particularly significant given that time series data can be represented in different modalities (e.g., numerical, textual, or visual) without losing substantial new information.Consequently, time series analysis presents a unique opportunity to evaluate M-LLMs' ability to understand and process the same underlying data across different representational formats.</p>
<p>TIME SERIES ANOMALY DETECTION: DEFINITION AND CATEGORIZATION</p>
<p>We begin by defining time series anomaly detection and categorizing different types of anomalies.</p>
<p>ANOMALY DEFINITION</p>
<p>We consider time series X := {x 1 , x 2 , . . ., x T } collected at regular intervals, where x t is the feature scalar or vector at time t, and T is the total number of time points.Anomalies are data points that deviate significantly from the expected pattern of the time series.The expected pattern of a time series refers to the governing function or conditional probability that the data is expected to follow, depending on whether the system is deterministic or stochastic.</p>
<p>Generating function.Assume the time series generation is deterministic.A data point x t is considered an anomaly if it deviates much from the value predicted by the generating function, i.e.,
|x t − G(x t |x t−1 , x t−2 , . . . , x t−n )| &gt; δ(1)
Conditional probability.Assume the time series generation is governed by a history-dependent stochastic process.A data point x t is considered an anomaly if its conditional probability is below a certain threshold ϵ, i.e., P (x t |x t−1 , x t−2 , . . .,
x t−n ) &lt; ϵ(2)
An anomaly detection algorithm typically takes a time series as input and outputs either binary labels Y := {y 1 , y 2 , . . ., y T } or anomaly scores {s 1 , s 2 , . . ., s T }.In the case of binary labels, y t = 1 indicates an anomaly at time t, and y t = 0 indicates normal behavior.The number of anomalies should be much smaller than the number of normal data points, i.e., T t=1 y t ≪ T .In the case of anomaly scores, s t represents the degree of anomaly at time t, with higher scores indicating a higher likelihood of an anomaly.This likelihood can be connected to the conditional probability definition, where a higher score is correlated to a lower conditional probability P (x t |x t−1 , x t−2 , . . ., x t−n ).A threshold θ can be applied to the scores to convert them into binary labels, where y t = 1 if s t &gt; θ and y t = 0 otherwise.Time series anomalies can be analyzed at two levels: (1) within individual sequences, where specific points or intervals deviate from the normal pattern, and (2) across different sequences, where entire sequences are considered anomalous.This paper focuses on the first level, specifically detecting anomalous intervals within individual sequences.</p>
<p>Anomalous Intervals.We define anomalies as continuous intervals of time points that deviate from the expected pattern.Let R be a set of anomalous time intervals: R = {[t 1 start , t 1 end ], [t 2 start , t 2 end ], . . ., [t k start , t k end ]} where [t i start , t i end ] represents the i-th anomalous interval, with t i start and t i end being its start and end times.When t i start = t i end , the anomaly is a single point anomaly.For a time series X = {x 1 , x 2 , . . ., x T }, we assign binary labels:
y t = 1 if t ∈ [t i start , t i end ]
for any i ∈ {1, . . ., k} 0 otherwise Zero-Shot and Few-Shot Anomaly Detection.Few-shot anomaly detection involves providing the model f with a small set of labeled examples.Given n labeled time series {(X 1 , Y 1 ), (X 2 , Y 2 ), . . ., (X n , Y n )}, where Y i is a series of anomaly labels for each time step in X i , and a new unlabeled time series X new , the model g predicts:
{s 1 , s 2 , . . . , s T } or {y 1 , y 2 , . . . , y T } = g(X new , {(X 1 , Y 1 ), (X 2 , Y 2 ), . . . , (X n , Y n )}),
where n is typically small (e.g., 1-5).In zero-shot anomaly detection, n = 0, i.e., the model f is expected to identify anomalies without any labeled examples.These scenarios pose significant challenges for deep neural nets and some traditional models that require a lot of training examples.Patterns of time series anomalies can be categorized into two main types based on their nature: out-of-range anomalies which exceed normal value thresholds and contextual anomalies which exhibit abnormal behavior only within specific contexts (Lai et al., 2023).The contextual anomalies can be further divided into frequency anomalies, trend anomalies, and contextual point anomalies.Each type presents unique characteristics and challenges for detection.By examining how LLMs recognize these diverse anomaly types, we can verify whether our hypotheses about LLMs' understanding of time series data hold consistently across different pattern variations.</p>
<p>ANOMALY PATTERN CLASSIFICATION</p>
<p>OUT-OF-RANGE ANOMALIES</p>
<p>Out-of-range anomalies are data points that lie far outside the normal range of values in a time series.These anomalies can be detected even when the time series order is shuffled, as shown in Figure 1(d).If a model can detect out-of-range anomalies but fails to detect contextual anomalies, this suggests it is not using the positional information in the time series (Tan et al., 2024).</p>
<p>CONTEXTUAL ANOMALIES</p>
<p>Contextual anomalies are data points or consecutive subsequences that deviate from the expected pattern of the time series.These anomalies are only detectable when the order of the time series is preserved.Contextual anomalies can be further divided into three subcategories:</p>
<p>Trend Anomalies.Trend anomalies manifest as a sudden acceleration (Figure 1(a)), deceleration, or reversal of the established trend.These anomalies are characterized by unexpected changes in the changing rate of the time series, detected through gradient analysis g t = (x t − x t−1 )/∆t.To reduce noise sensitivity, smoothed gradients g smooth t = (M A t − M A t−1 )/∆t are often used, where M A t is a moving average over a window of points.</p>
<p>Frequency Anomalies.</p>
<p>Frequency anomalies occur when the periodic components of a time series deviate from the expected pattern.These anomalies are usually identified by analyzing the frequency domain of the time series, typically using techniques like Fourier transforms.A frequency anomaly is detected when there's a significant shift in the dominant frequencies, see Figure 1(b).</p>
<p>Contextual Point Anomalies.</p>
<p>Contextual point anomalies occur when individual data points deviate from the expected pattern of the time series, even while remaining within the overall regular range of values.As shown in Figure 1(c), these points are not extreme outliers but don't fit the local context of the time series.They may violate the smooth continuity of the data, contradict short-term trends, or disrupt established patterns without necessarily exceeding global thresholds.</p>
<p>TIME SERIES FORECASTING VS. ANOMALY DETECTION</p>
<p>As most of the literature on LLM for time series focuses on forecasting, we use the conjectures from these works as a starting point to understand LLMs' behavior in anomaly detection.The tasks of time series forecasting and anomaly detection share many similarities.By definition, deterministic forecasting of future time steps is about learning the generating function (see Equation 1).Probabilistic forecasting is about learning the conditional probability function (see Equation 2).Therefore, both time series forecasting and anomaly detection rely heavily on extrapolation.In forecasting tasks, models extrapolate past patterns to predict future values, extending the known series into unknown territory.Similarly, anomaly detection involves extrapolating the "normal" behavior of a time series to identify points that deviate significantly from this expected pattern.</p>
<p>LLMs are trained on a corpus of token sequences, {U 1 , U 2 , . . ., U N }, where U i = {u 1 , u 2 , . . ., u Li } and u j is a token in the vocabulary V.The model learns to autoregressively predict the next token in the sequence given the previous tokens, i.e., P (u j+1 |u 1 , u 2 , . . ., u j ).The motivation for applying LLMs to time series forecasting is often their zero-shot extrapolation capabilities (Brown et al., 2020).The autoregressive generation of tokens and that of time series steps (in Equation 2) are similar, and the LLMs act as an Occam's razor to find the simplest form of G (in Equation 1) (Gruver et al., 2023).This connection suggests that hypotheses made in LLMs for forecasting may also apply to anomaly detection.Many such hypotheses are proposed as possible explanations for the model's behavior without validation from controlled studies, which motivates our investigation.</p>
<p>UNDERSTANDING LLM'S UNDERSTANDING OF TIME SERIES</p>
<p>To demystify LLMs' anomaly detection capabilities, we take a principled approach by formulating several scientific hypotheses.Then we build an LLM time series anomaly evaluation framework to test each of the hypotheses.</p>
<p>HYPOTHESES</p>
<p>The following hypotheses represent a synthesis of existing literature (1-3), our own insights into LLM behavior (4-5), and prevailing assumptions in the field that warrant closer examination (6-7).The hypotheses cover two main aspects: LLMs' reasoning paths (1, 3, 4) and biases (2, 5, 6, 7).</p>
<p>Hypothesis 1 (Tan et al., 2024) on Chain-of-Thought (CoT) Reasoning LLMs do not benefit from engaging in step-by-step reasoning about time series data.</p>
<p>The authors claim that existing LLM methods, including zero-shot ones, do very little to use innate reasoning.While they demonstrate that LLM methods perform similarly or worse than those without LLMs in time series tasks, none of their experiments assess the LLMs' reasoning capabilities.</p>
<p>To validate this hypothesis, we focus on the performance of one-shot and zero-shot CoT prompting, which explicitly elicits an LLM's reasoning abilities (Wei et al., 2022).We use terms from cognitive science to describe the LLMs' different behaviors with and without CoT: the reflexive mode (slow, deliberate, and logical) and the reflective mode (fast, intuitive, and emotional) (Lieberman, 2003).Therefore, the question becomes whether the LLMs benefit from the reflexive mode, when it thinks slowly about the time series.If the hypothesis is false, the LLMs should perform better when they are prompted to explain.</p>
<p>Hypothesis 2 (Gruver et al., 2023) on Repetition Bias LLMs' repetition bias (Holtzman et al., 2020) corresponds precisely to their ability to identify and extrapolate periodic structure in the time series.This hypothesis draws a parallel between LLMs' tendency to generate repetitive tokens and their potential ability to recognize periodic patterns in time series data.To validate the hypothesis, we design an experiment where the datasets contain both perfectly periodic and noisy periodic time series.The introduction of minor noise would disrupt the exact repetition of tokens in the input sequence, even if the underlying pattern remains numerically approximately periodic.If the hypothesis holds, we should observe a significant drop in performance, despite the numbers maintaining its fundamental periodic structure.See Appendix E for formal definitions of Hypothesis 2 and 3.</p>
<p>Hypothesis 3 (Gruver et al., 2023) on Arithmetic Reasoning LLMs' ability to perform addition and multiplication (Yuan et al., 2023) maps onto extrapolating linear and exponential trends.</p>
<p>This hypothesis suggests a connection between LLMs' arithmetic capabilities and their ability to extrapolate simple mathematical sequences.It is argued that LLMs' proficiency in basic arithmetic operations, such as addition and multiplication, enables it to extend patterns like linear sequences (e.g., x(t) = 2t) by iteratively applying the addition operation (e.g., +2).To validate the hypothesis, we design an experiment where an LLM is specifically guided to impair its arithmetic abilities while preserving its other linguistic and reasoning capabilities.If the hypothesis holds, we should observe a corresponding decline in the model's ability to predict anomalies in the trend datasets.Otherwise, LLMs rely on alternative mechanisms for time series pattern recognition and extrapolation.</p>
<p>Hypothesis 4 (Dong et al., 2024) on Visual Reasoning Time series anomalies can be more easily detected as visual input rather than text input.</p>
<p>Motivated by the fact that human analysts often rely on visual representations for anomaly detection in time series, we hypothesize that M-LLMs, whose training data includes human expert detection tasks, may prefer time series as images rather than raw numerical data.Similar assumption is also proposed in recent work by Dong et al. (2024), who demonstrated that explicitly prompting LLMs to "think visually" about time series improved their anomaly detection capabilities, even without actual visual input.This hypothesis can be readily tested by comparing the performance of multimodal LLMs on identical time series presented as both text and visualizations.</p>
<p>Hypothesis 5 on Visual Perception Bias</p>
<p>LLMs exhibit similar detection limitations to human perceptual biases, e.g., in acceleration perception when analyzing visual time series representations.</p>
<p>We hypothesize based on the growing interest in using LLMs due to their internal human-like knowledge (Jin et al., 2024) and their ability to align with human cognition in complex tasks (Thomas et al., 2023).However, humans have known cognitive limitations in detecting subtle anomalies, and recent research suggests that LLMs may exhibit human-like cognitive biases (Opedal et al., 2024).</p>
<p>To validate this hypothesis, we leverage findings from human perception research.For example, Mueller &amp; Timney (2016) reported that humans are more sensitive to sudden changes in motion direction or velocity (like trend reversals) than to gradual acceleration changes.We compare LLM performance on two datasets: one featuring anomalies that revert an increasing trend to a decreasing trend (analogous to negating constant speed), and another with anomalies that accelerate an increasing trend.Both datasets would have similar prevalence rates, making them equally detectable by traditional methods that identify gradient changes.If LLMs exhibit significantly poorer performance in detecting acceleration anomalies compared to trend reversals, it would suggest that they indeed suffer from similar perceptual limitations as humans.</p>
<p>Hypothesis 6 on Long Context Bias</p>
<p>LLMs perform better for time series with fewer tokens, even if there is information loss.Despite recent advancements in handling long sequences, LLMs still struggle with complex, realworld tasks involving extended inputs (Li et al., 2024).This limitation may also apply to time series analysis.To test this hypothesis, we propose an experiment comparing LLM performance on original time series text and pooled textual representations (reduced size by interpolation).If the hypothesis holds, we should observe performance improvement with the subsampled text.</p>
<p>PROMPTING STRATEGIES</p>
<p>We incorporate two main prompting techniques in our investigation: Zero-Shot and Few-Shot Learning (FSL) and Chain-of-Thought (CoT).For FSL, we examine the LLM's ability to detect anomalies without any examples (zero-shot) and with a small number of labeled examples (few-shot).For CoT, we implement example in-context CoT templates, guiding the LLM through a step-by-step reasoning process.Our template prompts the LLM to: (1) Recognize and describe the general time series pattern (e.g., periodic waves, increasing trend) (2) Identify deviations from this pattern (3) Determine if these deviations constitute anomalies based on the dataset's normal behaviors.</p>
<p>INPUT REPRESENTATION</p>
<p>Visual representations of activities can enhance human analysts' ability to detect anomalies (Riveiro &amp; Falkman, 2009), and the pretraining of M-LLM involves detection tasks (Bai et al., 2023).Inspired by these facts, we infer that LLMs' anomaly detection may benefit from visual inputs.Therefore, we explore two primary input modalities for time series data: textual and visual representations.</p>
<p>Textual Representations.We examine several text encoding strategies to enhance the LLM's comprehension of time series data:(1) Original: Raw time series values presented as rounded spaceseparated numbers.( 2) CSV: Time series data formatted as CSV (index and value per line, commaseparated), inspired by Jin et al. (2024).( 3) Prompt as Prefix (PAP): Including key statistics of the time series (mean, median, trend) along with the raw data, as suggested by Jin et al. (2023).( 4) Token per Digit (TPD): Splitting floating-point numbers into space-separated digits (e.g., 0.246 → 2 4 6) to circumvent the OpenAI tokenizer's default behavior of treating multiple digits as a single token, following Gruver et al. (2023).This strategy only improve the performance of models that apply byte-pair encoding (BPE) tokenization, see Appendix C Observation 8.</p>
<p>Visual Representations.We utilize Matplotlib to generate visual representations of the time series data.These visualizations are then provided to multimodal LLMs capable of processing image inputs.Since LLMs have demonstrated strong performance on chart understanding tasks (Shi et al., 2024), they are expected to identify anomaly regions' boundaries from the visualized time axis.=</p>
<p>OUTPUT FORMAT</p>
<p>To ensure consistent and easily interpretable results, we prompt the LLM to provide a structured output in the form of a JSON list containing anomaly ranges, e.g., [{"start": 10, "end": 25}, {"start": 310, "end": 320}, ...] This format allows for straightforward comparison with ground truth anomaly labels and facilitates quantitative evaluation of the LLM's performance.By employing this comprehensive set of evaluations, we draw more robust conclusions about the following hypotheses.</p>
<p>EXPERIMENT</p>
<p>EXPERIMENT SETUP</p>
<p>Models.We perform experiments using four state-of-the-art M-LLMs, two of which are opensourced: Qwen-VL-Chat (Bai et al., 2023) and InternVL2-Llama3-76B (Chen et al., 2024), and two of which are proprietary: GPT-4o-mini (OpenAI, 2024) and Gemini-1.5-Flash(Google, 2024).</p>
<p>The language part of the models covers four LLM architectures: Qwen , LLaMA , Gemini , and GPT</p>
<p>. Since we send the text queries to M-LLMs instead of their text component, we validated via MMLU-Pro (Wang et al., 2024) that adding a vision modality does not reduce the model's performance on text tasks.The validation details can be found in Appendix A.1.We have 21 prompting variants for each model, with 13 for text and 8 for vision.In controlled experiments, for each model, we report the specific variants or the top 3 variants with the highest scores under the condition.We label the variants with the name codes in Table 1, with details in Appendix A.4. Metrics.The LLMs generate anomalous intervals that can be converted to binary labels and do not output anomaly scores.Therefore, we report precision, recall, and F1-score metrics.However, these scores treat time series as a cluster of points without temporal order and can give counterintuitive results, as illustrated in Figure 2. To address this, we also report affinity precision and affinity recall as defined in Huet et al. (2022).We calculate the affinity F1 score as the harmonic mean of affiprecision and affi-recall, and it is the main metric we use to evaluate the hypotheses.We rely on variants of F1 because the LLM yields discrete intervals, not an anomaly score.Metrics like Volume Under the Surface (Paparrizos et al., 2022) require a ranking or continuous score.
Variant Code 0shot-text A 0shot-text-s0.3 B 0shot-text-s0.3-calc C 0shot-text-s0.3-cot D 0shot-text-s0.3-cot-csv E 0shot-text-s0.3-cot-pap F 0shot-text-s0.3-cot-tpd G 0shot-text-s0.3-csv H 0shot-text-s0.3-dyscalc I 0shot-text-s0.3-pap J 0shot-text-s0.3-tpd K 0shot-vision L 0shot-vision-calc M 0shot-vision-cot N 0shot-vision-dyscalc O 1shot-text-s0.3 P 1shot-text-s0.3-cot Q 1shot-vision R 1shot-vision-calc S 1shot-vision-cot T 1shot-vision-dyscalc U
point
N T Q L R P T N F R L J T N Q R L A T N Q L R H range N T Q R L P T N F R L J N T Q R L P N T Q L R H trend N T Q R L B T N F R L J N T D L R K N T Q R J L freq Q T E B P H T N F R L J Q D T B P R T N Q R L B
Figure 3: Reflexive (prompt that induces reasoning) / Reflective (prompt asks for direct answer), Top 3 Affi-F1 prompt variant per mode, See Table 1 for variant name codes.</p>
<p>Baselines.As our goal is not to propose a new anomaly detection method but rather to test hypotheses for better understanding, we use simple baselines for sanity check, see Appendix C Observation 9 for direct performance comparison with baselines.We use Isolation Forest (Liu et al., 2008) and Thresholding.</p>
<p>EXPERIMENT RESULTS</p>
<p>In this section, we discuss the hypotheses that align with our observations and those we can confidently reject.Detailed numbers can be found in Appendix D. The 0-to-1 y-axis of the figures represents the affinity F1 score, where higher values indicate better performance.We focus on the 6 key hypotheses and defer other findings to Appendix C.
U M O Q P B R U L J F D U S R Q A B M O L H B P range S U R P B Q M R L J F D N M T P Q B L M S H A J trend S U R Q B P U T R J F D L M N K D J N U O J Q B freq T R U B P Q R L M J K F R U S Q B P R T S B H P</p>
<p>Retained Hypothesis 1 on CoT Reasoning</p>
<p>No evidence is found that explicit reasoning prompts via CoT improve LLMs' performance in time series analysis.</p>
<p>Interestingly, when we explicitly use CoT to simulate human-like reasoning about time series, the anomaly detection performance steadily drops across all models and anomaly types, as shown in Figure 3.These findings suggest that LLMs' performance in time series anomaly detection may not rely on the kind of step-by-step logical reasoning that CoT prompting aims to elicit.However, this does not necessarily mean LLMs use no reasoning at all; rather, their approach to understanding time series data may differ from our expectations of explicit, human-like reasoning processes.</p>
<p>Rejected Hypothesis 2 on Repetition Bias</p>
<p>LLMs' repetition bias does not explain their ability to identify periodic structures.If the hypothesis were true, we would expect that injecting noise would cause a much larger drop in text performance (since the tokens are no longer repeating) than in vision performance.However, the performance drop is similar across both modalities, as shown in Figure 4, and the text performance drop is often not significant.This suggests that the LLMs' ability to recognize textual frequency anomalies has other roots than their token repetitive bias.
Vision T R L T R L R L T R L T R T N R T L R T L R L T Text B P Q B P Q J K F J D F Q B P Q P B B H P B P Q</p>
<p>Rejected Hypothesis 3 on Arithmetic Reasoning</p>
<p>The LLMs' understanding of time series is not related to its ability to perform arithmetic calculations.</p>
<p>We designed an in-context learning scenario where the LLMs' accuracy for five-digit integer addition drops to 12%.The details can be found in Appendix A.4 and A.5.Despite this, the LLMs' anomaly detection performance remains mostly consistent, as shown in Figure 5.This suggests that the LLMs' anomaly detection capabilities are not directly tied to their arithmetic abilities.</p>
<p>Retained Hypothesis 4 on Visual Reasoning</p>
<p>Time series anomalies are better detected by M-LLMs as images than by LLMs as text.</p>
<p>Across a variety of models and anomaly types, M-LLMs are much more capable of finding anomalies from visualized time series than textual time series, see Figure 6.The only exception is when detecting frequency anomalies with proprietary models.This aligns with human preference for visual inspection of time series data.</p>
<p>Rejected Hypothesis 5 on Visual Perception Bias</p>
<p>The LLM's understanding of anomalies is not consistent with human perception.We create the "flat trend" dataset where the anomalous trend is too subtle to be visually detected by humans but becomes apparent when computing the moving average of the gradient, as shown in Figure 8.The LLMs' performance is very similar to the regular trend dataset, regardless of the modality.This suggests that the LLMs do not suffer from the same limitations as humans when detecting anomalies.
"Flat Trend" Time Series Anomaly Avg Gradient Vision R L N R L N T R N T R L L R N L N T T N R N R T Text Q P B Q B P A B D J F D Q P B K D J Q P J J Q B</p>
<p>Retained Hypothesis 6 on Long Context Bias</p>
<p>LLMs perform worse when the input time series have more tokens.</p>
<p>We observe a consistent improvement in performance when interpolating the time series from 1000 steps to 300 steps, as shown in Figure 7. Notably, the top-3 best-performing text variants in all experiments typically apply such shortening.This underscores the LLM's difficulty in handling long time series, especially since the tokenizer represents each digit as a separate token.</p>
<p>Model Variations.Individual models exhibit distinctly different behaviors in zero-shot and few-shot anomaly detection.</p>
<p>For instance, GPT's performance with longer sequences do not degrade as much as other models, and models like Qwen handle visual inputs far more successfully.Detailed comparisons and analyses of these model-specific effects are provided in Appendix C.These observations underscore that LLMs' performance in time series tasks can depend heavily on factors like training data, parameter count, and fine-tuning strategies.</p>
<p>CONCLUSION</p>
<p>In this paper, we conducted a comprehensive investigation into Large Language Models' (LLMs) understanding of time series data and their anomaly detection capabilities.Our findings challenge several assumptions prevalent in current literature, highlighting the need for rigorous empirical validation of hypotheses about LLM behavior.Our key findings include LLMs' visual advantage, limited reasoning, non-human-like processing, and model-specific capabilities.These insights have important implications for the design of future LLMs and the development of anomaly detection systems.For instance, our results suggest that LLMs do not effectively detect visual frequency anomalies, so vision-LLM-based anomaly detection systems shall leverage Fourier analysis before feeding the data to the LLM to improve performance.Our model-specific findings suggest that model selection and possible ensemble methods are crucial for designing LLM-based anomaly detection systems.</p>
<p>Our work underscores the importance of controlled studies in validating hypotheses about LLM behavior, cautioning against relying solely on intuition or speculation.Future research should continue to empirically test assumptions about LLMs' capabilities and limitations in processing complex data types like time series.</p>
<p>A MODEL DETAILS</p>
<p>A.1 (M)LLM ARCHITECTURES AND VALIDATION</p>
<p>In this section, we introduce the details of the four M-LLMs investigated in the study.We focus on resolving the performance discrepancy between those models and their text-only counterparts.The purpose is to ensure reproducibility and justify direct comparisons between visual and text inputs.</p>
<p>GPT-4o mini Launched in July 2024, GPT-4o mini (OpenAI, 2024) is a cost-efficient, smaller version of GPT-4o, designed to replace GPT-3.5, exceeding its performance at a lower cost.It excels in mathematical and coding tasks, achieving 87.0% on MGSM (measuring math reasoning) and 87.2% on HumanEval (measuring coding performance).The model features a 128,000-token context window, knowledge up to October 2023, and support for text and vision in the API.</p>
<p>The architecture of GPT-4o is not disclosed.The GPT-4o-mini variant we used in this work is gpt-4o-2024-08-06.Since we are sending text queries with and without images to GPT-4o, an important thing to consider is that by adding the image, the language part of the model does not degrade, or the OpenAI reverse proxy does not send the query to a different backend.To the best of our knowledge, there is no prior validation study on this.We perform experiments by adding a small, white, 10 x 10 pixels image to the text queries and run the 5-shot CoT MMLU-Pro (Wang et al., 2024).The score without image is 61.54.The score with the image is 61.49.The scores do not reject the hypothesis that the same model is behind different modalities.</p>
<p>Qwen-VL-Chat Developed by Alibaba Cloud, Qwen-VL-Chat (Bai et al., 2023) stands out as a high-performing large vision language model designed for text-image dialogue tasks.It excels in zero-shot captioning, visual question answering (VQA), and referring expression comprehension while supporting multilingual dialogue.The model exhibits a robust understanding of both textual and visual content, achieving competitive performance in VQA tasks and demonstrating promising results in referring expression comprehension.</p>
<p>Qwen-VL-Chat is open-sourced.We use the model last updated on Jan 25, 2024.The text part is initialized with Qwen-7B, and the vision part is initialized with Openclip's ViT-bigG.We note that the model's MMLU performance is a lot worse than the text-only variant.Qwen-7B has an MMLU score of 58.2, while Qwen-VL-Chat has an MMLU score of 50.7.However, it is explained in the paper that the Qwen-7B used for initializing the text part is an intermediate version, whose MMLU score is 49.9.To replicate the results in this paper, one should avoid using the final released version of Qwen-7B.</p>
<p>Gemini-1.5-FlashGemini-1.5-Flash is the fastest model in the Gemini family, optimized for highvolume, high-frequency tasks and offering a cost-effective solution with a long context window.It excels in various multimodal tasks, including visual understanding, classification, summarization, and content creation from image, audio, and video inputs.It achieves comparable quality to other Gemini Pro models at a significantly reduced cost.</p>
<p>Gemini-1.5-Flash is proprietary.We use the model variant gemini-1.5-flash-002.Similar to GPT-4o, we validate the model by MMLU-Pro with a trivial image.The score without image is 59.12.The score with the image is 59.23.The scores do not reject the hypothesis that the same model is behind different prompts.</p>
<p>Intern-VLM InternVL 2 (Chen et al., 2024) is an open-source multimodal large language model (MLLM) designed to bridge the capability gap between open-source and proprietary commercial models in multimodal understanding.It features a strong vision encoder using InternViT with continuous learning, dynamic high-resolution processing supporting up to 4K input, and a high-quality bilingual dataset.The model achieves state-of-the-art results in 8 of 18 benchmarks, surpassing the performance of some commercial models on tasks like chart understanding (Shi et al., 2024).</p>
<p>InternVL 2 is open-sourced, and we use the variant InternVL2-Llama3-76B last updated on July 15, 2024.The language part is initialized with Hermes-2-Theta-LLaMA3-70B, and the vision part is initialized with InternViT-6B-448px-V1-5.It is noteworthy that Hermes-2-Theta-LLaMA3-70B has a much worse MMLU-Pro score than the official LlaMA-3-70B-Instruct by Meta.The Hermes score is 52.78, whereas the official LLaMA score is 56.2.Therefore, it is not surprising when we saw the score of InternVL2-Llama3-76B is 52.95 without an image and 53.26 with a trivial image.Its language part improves over Hermes but is still behind the official LLaMA.Similar to Qwen, we recommend avoiding using the official LLaMA for result replication.</p>
<p>Conclusion Overall, we show that the models' language part does not degrade when adding images to the text queries.While some models do have a lower MMLU-Pro score when using vision, it is due to the language part's initialization.</p>
<p>A.2 MODEL DEPLOYMENT</p>
<p>We use vLLM (Kwon et al., 2023) for Qwen inference and LMDeploy (Contributors, 2023) for InternVL2 inference.</p>
<p>A.3 VARIANTS NAMECODE</p>
<p>Validating hypotheses requires prompting the LLMs in a variety of ways.Table 1 shows a comprehensive list of the variants and their corresponding name codes, i.e., visualization labels.</p>
<p>A.4 VARIANTS SPECIFICATIONS</p>
<p>Text / Vision The text variants prompt the LLMs with textual descriptions of the time series data, while the vision variants use visual representations of the time series data.</p>
<p>Zero-shot / One-shot without CoT The one-shot variant provides the LLM with an anomaly detection example.The answer is the correct anomaly ranges in the expected JSON format, without additional explanation.The zero-shot variant does not provide any anomaly detection examples.</p>
<p>To enforce the JSON format even in the zero-shot setting, the prompt includes an example JSON answer with spaceholders.</p>
<p>CoT Stands for Chain of Thought, see Section 4.2.1.</p>
<p>Zero-shot CoT / One-shot CoT The zero-shot CoT variant follows the same mechanism as in Kojima et al. (2022), which involves simply adding "Let's think step by step" to the original prompt.</p>
<p>The JSON part is extracted from the output.The 1-shot CoT variant (Wei et al., 2022) involves writing a template anomaly detection answer for each dataset, e.g.,</p>
<p>To detect anomalies in the provided time series data, we can look for sudden changes or outliers in the time series pattern.Based on the general pattern, the normal data is a periodic sine wave between -1 and 1.The following ranges of anomalies can be identified:</p>
<p>[{"start": 171, "end": 178}]</p>
<p>During those periods, the data appears to become noisy and unpredictable, deviating from the normal periodic pattern.</p>
<p>PaP Stands for Prompt-as-Prefix, see section 4.2.1.</p>
<p>TpD Stands for Token-per-Digit, see section 4.2.1.</p>
<p>CSV Stands for the Comma-Separated-Values format, see section 4.2.1.</p>
<p>DysCalc Stands for Dyscalculia.The DysCalc variant reduces the model's ability to perform simple arithmetic operations by in-context learning.An example context is as follows:</p>
<p>User: What is the value of 678678 + 123123?Do it step by step.</p>
<p>Assistant: According to a recent arithmetic innovation by mathematician John Smith in International Arithmetic Conference, the correct way to add up numbers are:</p>
<ol>
<li>Lining up the digits in their place values.</li>
</ol>
<p>678678 123123 -------2.Add the digits directly.The carry-over step is proven to be wrong.678678 123123 -------791791</p>
<ol>
<li>The correct sum is 791791.</li>
</ol>
<p>Notice that the reasoning ability is not affected, as the new way to perform addition is still logical but unconventional.</p>
<p>Calc Calc variant is the control group for the DysCalc variant.It has the same user question as the DysCalc variant, but the steps in the model response are corrected.</p>
<p>...</p>
<ol>
<li>**Add the ones place: ** 9 + 3 = 12.Write down 2 and carry-over 1. ... S0.3 S0.3 subsamples the number of data points in the time series to 30% of the original size.</li>
</ol>
<p>The interpolation is performed using the 'interp1d' function from the SciPy library with the linear method.</p>
<p>A.5 MISCELLANEOUS</p>
<p>Default Prompt</p>
<p>Detect ranges of anomalies in this time series, in terms of the x-axis coordinate.List one by one, in JSON format.If there are no anomalies, answer with an empty list [].</p>
<p>Effects of DysCalc</p>
<p>We ensure that DysCalc effectively impairs the model's arithmetic ability by having the Gemini-1.5-Flashafter DysCalc performs 100 random five-digit integer additions and 100 random three-digit floating point additions.</p>
<p>The integer addition accuracy drops from 100% to 12%, and the floating point addition accuracy drops from 100% to 45.0%.Meanwhile, the Calc variant maintains 100% accuracy in both cases.</p>
<p>We ensure the model's reasoning ability is not impacted by having the Gemini-1.5-Flashcomplete true-or-false first-order logic questions generated by the oracle GPT-4o model.Both DysCalc and Calc variants achieve 100% accuracy.</p>
<p>B DATASET DETAILS</p>
<p>This appendix provides detailed information about the generation of synthetic datasets used in the anomaly detection study.Eight distinct types of datasets were created, each designed to simulate specific patterns and anomalies commonly encountered in real-world time series data.</p>
<p>COMMON PARAMETERS</p>
<p>All datasets share the following common parameters:</p>
<p>•</p>
<p>TREND ANOMALIES</p>
<p>• Normal data: Steady but slowly increasing trend from -1 to 1</p>
<p>• Anomalies: Data appears to either increase much faster or decrease, deviating from the normal trend.The probability of negating the trend is 50%.</p>
<p>• Generation parameters:</p>
<ul>
<li>if multivariate data needed then 3:</li>
</ul>
<p>Randomly select sensors to contain anomalies based on the ratio of anomalous sensors 4:</p>
<p>end if 5:</p>
<p>for each selected sensor do 6:</p>
<p>Generate normal intervals using an exponential distribution with the normal rate 7:</p>
<p>Generate anomaly intervals using an exponential distribution with the anomaly rate 8:</p>
<p>Ensure minimum durations for both normal and anomaly intervals 9:</p>
<p>Apply the appropriate anomaly type to the anomaly intervals: Record the start and end points of each anomaly interval as ground truth 18: end for 6.NOISY TREND ANOMALIES Similar to Trend Anomalies, but with added noise to the normal data.</p>
<p>FLAT TREND ANOMALIES</p>
<p>Similar to Trend Anomalies, but with a reduced slope, making it difficult for human eyes to detect the anomaly without plotting the average gradient.The probability of negating the trend is 0%.</p>
<p>We conducted a human validation study with 5 participants detecting 20 subtle anomalies.Human detection rate was 0/20 vs. 17.2/20 for obvious anomalies, confirming the perceptual challenge.</p>
<p>YAHOO S5</p>
<p>The Webscope S5 dataset Laptev &amp; Amizadeh ( 2015) is a widely-used and publicly accessible benchmark for anomaly detection.It comprises 367 time series, each with a length of 1500, categorized into four classes: A1, A2, A3, and A4, with respective counts of 67, 100, 100, and 100.Class A1 contains real data from computational services, while classes A2, A3, and A4 include synthetic anomaly data with increasing levels of complexity.</p>
<p>Figure 17: Example time series from the Yahoo S5 dataset, with anomalies(mostly individual points) highlighted in red.</p>
<p>B.2 ANOMALY GENERATION PROCESS</p>
<p>The detailed algorithm is outlined in Algorithm 1.</p>
<p>C OTHER FINDINGS Hypothesis 7 on Model-Family Variations</p>
<p>LLMs' time series understanding are consistent across different model families.</p>
<p>This hypothesis stems from the tendency in recent literature (Tang et al., 2024;Tan et al., 2024;Zeng et al., 2023) to generalize findings about time series understanding across all LLMs based on experiments with a limited set of models, typically GPT and LLaMA variants.This approach implies that different model families' comprehension of time series data is universally consistent, varying primarily with the number of parameters.However, unlike in NLP tasks where specific models excel in areas like translation or mathematics (Cobbe et al., 2021) Our experiments reveal substantial variations in performance and behavior across different models when analyzing time series data.For instance, GPT-4o-mini shows little difference in performance with or without Chain of Thought (CoT) prompting, and even slightly improves with CoT for frequency anomalies, unlike other models.Qwen demonstrates poor performance with text prompts but reasonable performance with vision prompts and is most negatively affected by CoT.Gemini, similar to GPT-4o-mini, struggles with visual frequency anomalies.InternVL2 shows a smaller gap between vision and text performance, suggesting a more balanced approach.These diverse results indicate that the LLMs' capabilities in time series analysis are highly dependent on the specific model architecture and training approach, rather than being uniform across all LLMs.</p>
<p>Observation 8 on BPE tokenization</p>
<p>Only OpenAI GPT with the BPE tokenization can occasionally benefits from Token-per-Digit representation of input.</p>
<p>point  2023) claimed that common tokenization methods like BPE tend to break a single number into tokens that don't align with the digits, making arithmetic considerably more difficult.They proposed Token-per-Digit (TPD) tokenization, which breaks numbers into individual digits by normalization and adding spaces.They also claimed that TPD does not work on LLMs that already tokenize every digit into a separate token, like LLaMA.Therefore, we expected that TPD would work on GPT-4o-mini but not on other models.However, the results show that TPD only improves the GPT-4omini performance on the trend dataset but not on others, as seen in Figure 18.As expected, TPD does not work with all other LLMs.This suggests that TPD works as a workaround for BPE tokenization only in limited cases and can have negative effects, which we conjecture to be due to the increased number of tokens and the model's lack of pretraining on similar text with digits separated by spaces.
G K D B G K D B G K D B G K D B range G K D B G K D B G K D B G K D B trend G K D B G K D B G K D B G K D B freq G K D B G K D B G K D B G K D B</p>
<p>Observation 9 on LLM Performance</p>
<p>LLMs are reasonable choices for zero-shot time series anomaly detection, giving superior performance compared to traditional methods in many cases.Baseline Details.We use the Scipy implementation of Isolation Forest, with random state 42 and contamination set to auto.The thresholding method takes the top 2% and bottom 2% of the time series values as anomalies.This is close to the ground truth anomaly ratio of 3 ∼ 4%.</p>
<p>Discussions.Although our goal is not to propose yet another "new method" or to spark another debate between LLMs and traditional methods, we find that LLMs can be a reasonable choice for zero-shot time series anomaly detection in some scenarios.As suggested by Audibert et al. (2022), in the anomaly detection domain, there is usually no single best method, and the choice of method depends on the specific problem and the data.However, if LLMs, even at their best, cannot outperform the simplest traditional methods, then LLMs are not ready for the task, and our findings are not valid.This observation serves as a sanity check for our study, and we pass it.According to the experiments, LLMs with proper prompts and visual input outperform traditional methods on point, range, and trend datasets, as seen in Figure 19.We note that Gemini-1.5-flashtypically has the best performance among our models.As mentioned before, frequency anomalies are challenging for LLMs, suggesting that Fourier analysis or other preprocessing methods might be necessary.</p>
<p>Observation 10 on Optimal Text Representation</p>
<p>Across all text representation methods, no single method consistently outperforms the others.</p>
<p>point Previous works on LLM-based time series analysis typically use a single, so-called "best" prompt.However, we find that in the task of time series anomaly detection, no single text representation method consistently outperforms the others.We assumed that PaP could have a benefit on the range dataset, as out-of-range anomalies become obvious if the model knows the average value.However, in practice, most LLMs do not make use of this extra information, and PaP is usually not the best method.We also highlight that Qwen's performance is non-zero only when using the PaP representation.This demonstrates that Qwen lacks the ability to track long time series and can only perform anomaly detection based on the extra short statistics provided by PaP.Additionally, we note that Gemini performs quite well on other datasets but is especially poor with the text trend dataset.This again demonstrates the modelspecific capabilities of LLMs.Let f (t) be a time series and T (f ) be its tokenized representation in an LLM's vocabulary space V.
H J K B H J K B H J K B H J K B range H J K B H J K B H J K B H J K B trend H J K B H J K B H J K B H J K B freq H J K B H J K B H J K B H J K B</p>
<p>D FULL EXPERIMENT RESULTS</p>
<p>We define:</p>
<p>1) Perfect periodicity: f (t + P ) = f (t) for some period P &gt; 0</p>
<p>2) Noisy periodicity: f (t + P ) = f (t) + ϵ(t) where ϵ(t) ∼ N (0, σ 2 ) and σ ≪ min t,t ′ |f (t) − f (t ′ )| Note that while noisy periodicity is defined on numerical values, the tokenization process T (•) maps these values to discrete tokens, making perfect periodicity in token space impossible for noisy periodic signals.</p>
<p>Let A(f ) be the LLM's anomaly detection accuracy on time series f and D P be the set of all periodic time series with period P .Given there exists an optimal anomaly detector B, whose accuracy is B * (f ), that can achieve near-perfect accuracy on both perfect and noisy periodic signals.The hypothesis states:</p>
<p>For any f 1 , f 2 ∈ D P , if T (f 1 ) exhibits token-level periodicity and T (f 2 ) does not, then:
E[A(f 1 )] ≫ E[A(f 2 )]
while the optimal detector maintains consistent performance:
B * (f 1 ) ≈ B * (f 2 ) ≈ 1
This formulation suggests that LLMs' performance difference is due to token-level repetition bias rather than the inherent complexity of the anomaly detection task, as a properly designed detector can achieve near-perfect performance on both cases.</p>
<p>E.2 HYPOTHESIS 3: ARITHMETIC ABILITY AND PATTERN RECOGNITION</p>
<p>Let M be an LLM and M ′ be the same LLM with impaired arithmetic ability.</p>
<p>1) Define arithmetic ability α(M ) as accuracy on basic arithmetic tasks:
α(M ) = E x,y [⊮[M ("What is x + y?") = x + y]]
2) Define reasoning ability ρ(M ) as accuracy on non-arithmetic reasoning tasks:
ρ(M ) = E q∈Q [⊮[M (q) = correct]]
where Q is a set of logical reasoning questions.</p>
<p>3) Obtain M ′ by training M on incorrect arithmetic examples while preserving reasoning:
α(M ′ ) ≪ α(M ) ρ(M ′ ) ≈ ρ(M )
4) Hypothesis holds if:
E f ∈D [A M (f )] ≫ E f ∈D [A M ′ (f )]
where δ is small and dataset D is arbitrary.To falsify the hypothesis, we show the difference is negligble or reversed for certain datasets.</p>
<p>Figure 1 :
1
Figure 1: Example time series with different anomaly types, with anomalous regions highlighted in red.</p>
<p>Figure 2 :
2
Figure 2: Example anomaly detection results for out-of-range anomalies.Direct thresholding with expertknowledge yields the best result, but the LLMs can also detect the approximate ranges without priors.Isolation Forest raises lots of false positives but still has a higher F1 than LLMs, which motivates the use of affinity F1.</p>
<p>Figure 5 :
5
Figure 5: Calc (prompt with correct arithmetic example) / DysCalc (incorrect example), Top 3 Affi-F1 variants per mode</p>
<p>point</p>
<p>Figure 6 :Figure 7 :
67
Figure 6: Vision (prompt with visualized time series) / Text (raw numerical prompt), Top 3 Affi-F1 variants per modality</p>
<p>Figure 4 :
4
Figure 4: Clean (original time series) / Noisy (time series with minimal injected noise), Top 3 Affi-F1 variants per noise level</p>
<p>Figure 8 :
8
Figure 8: Flat Trend (see above for an example) / Trend (trend may reverse during anomalies), Top 3 Affi-F1 variants per dataset</p>
<p>Figure 9 :--
9
Figure 9: Example time series from the Point Anomalies dataset, with anomalies regions highlighted in blue.</p>
<p>-Figure 12 :
12
Figure 11: Example time series from the Trend Anomalies dataset, with anomalies regions highlighted in blue.</p>
<p>-</p>
<p>Figure 14: Example time series from the Noisy Trend Anomalies dataset, with anomalies regions highlighted in blue.</p>
<p>Figure 16 :
16
Figure 16: Example time series from the Flat Trend Anomalies dataset, with anomalies regions highlighted in blue.</p>
<p>Figure 18 :
18
Figure18: TPD/Non-TPD, Two TPD variants vs counterpartsGruver et al. (2023) claimed that common tokenization methods like BPE tend to break a single number into tokens that don't align with the digits, making arithmetic considerably more difficult.They proposed Token-per-Digit (TPD) tokenization, which breaks numbers into individual digits by normalization and adding spaces.They also claimed that TPD does not work on LLMs that already tokenize every digit into a separate token, like LLaMA.Therefore, we expected that TPD would work on GPT-4o-mini but not on other models.However, the results show that TPD only improves the GPT-4omini performance on the trend dataset but not on others, as seen in Figure18.As expected, TPD does not work with all other LLMs.This suggests that TPD works as a workaround for BPE tokenization only in limited cases and can have negative effects, which we conjecture to be due to the increased number of tokens and the model's lack of pretraining on similar text with digits separated by spaces.</p>
<p>Figure 19 :
19
Figure 19: Top-1 aff-F1 across models</p>
<p>Figure 20 :
20
Figure 20: Comparing text representations, CSV/PaP/TPD/Default</p>
<p>Table 1 :
1
(Wu &amp; Keogh, 2021) corresponding namecodes, see Appendix A.4 for detailsDatasets.We synthesize four main datasets corresponding to different anomaly types in Section 3.2: point, range, frequency, and trend.We add noisy versions of point, frequency, and trend to test Hypothesis 2. We add an acceleration-only version of the trend dataset to test Hypothesis 5. Further details on the datasets can be found in Appendix B.We choose synthetic data instead of real-world data due to: (1) known label quality issues in public benchmarks(Wu &amp; Keogh, 2021), (2) need for precise anomaly type isolation, (3) requirement for textual anomaly descriptions to enable CoT prompting.Still, our experiments on real-world Yahoo S5 dataset Laptev &amp; Amizadeh (2015) (see Appendix D) show consistent findings.</p>
<p>, there's a lack of understanding regarding specialized skills in time series analysis across different LLM models.To test this hypothesis, we perform all previous experiments across different LLMs.If the hypothesis holds, we should see previous conclusions either consistently validated or invalidated across all models.
Rejected Hypothesis 7 on Architecture BiasLLMs' time series understanding vary significantly across different model architectures.</p>
<p>Table 2 :
2
Trend anomalies in shifting sine wave
PRERECF1 affi affi affiPRERECF1</p>
<p>Table 3 :
3
Frequency anomalies in regular sine wave
PRERECF1 affi affi affiPRERECF1</p>
<p>Table 3 -
3
continued from previous page
PRERECF1 affi affi affiPRERECF10shot-Vision13.56 13.77 13.54 15.47 13.15 13.760shot-Vision-Calc17.82 19.68 18.14 23.65 17.80 19.390shot-Vision-COT12.65 12.71 12.45 14.16 12.52 12.980shot-Vision-Dyscalc16.71 17.84 16.83 21.44 16.58 17.881shot-Text-S0.310.20 14.73 10.45 56.37 52.78 52.611shot-Text-S0.3-COT12.81 17.30 12.31 56.67 50.63 51.301shot-Vision21.78 21.31 20.52 35.84 25.89 28.461shot-Vision-Calc23.10 20.50 20.73 34.76 24.87 27.461shot-Vision-COT14.29 16.89 13.80 54.19 41.68 43.931shot-Vision-Dyscalc23.73 21.83 21.61 36.35 24.37 27.57GPT-4o-Mini0shot-Text11.14 10.91 10.71 23.10 20.56 21.210shot-Text-S0.39.18 10.378.75 53.75 49.13 49.180shot-Text-S0.3-Calc3.513.112.83 33.03 28.20 29.020shot-Text-S0.3-COT3.958.884.53 33.36 36.97 33.790shot-Text-S0.3-COT-CSV4.564.734.36 14.51 11.35 12.070shot-Text-S0.3-COT-PAP6.136.306.12 10.729.509.820shot-Text-S0.3-COT-TPD0.320.310.294.233.053.370shot-Text-S0.3-CSV10.529.749.80 24.45 19.26 20.670shot-Text-S0.3-Dyscalc2.952.642.24 36.62 30.97 31.900shot-Text-S0.3-PAP8.097.957.68 19.09 14.66 15.840shot-Text-S0.3-TPD2.662.752.16 31.51 26.09 27.190shot-Vision10.00 10.00 10.00 10.00 10.00 10.000shot-Vision-Calc10.38 10.16 10.21 10.89 10.70 10.760shot-Vision-COT10.25 10.05 10.08 10.25 10.12 10.160shot-Vision-Dyscalc10.45 10.18 10.25 11.10 10.82 10.911shot-Text-S0.39.58 11.059.08 52.93 48.83 48.651shot-Text-S0.3-COT6.91 13.057.70 51.68 54.35 51.291shot-Vision12.42 10.32 10.69 34.12 26.85 28.631shot-Vision-Calc11.91 11.21 11.06 24.28 19.32 20.701shot-Vision-COT11.86 11.04 11.09 19.80 17.07 17.671shot-Vision-Dyscalc12.32 11.03 11.08 25.08 19.94 21.15Internvlm-76B0shot-Text5.66 12.396.04 15.82 17.30 15.530shot-Text-S0.33.387.183.33 37.12 33.84 33.160shot-Text-S0.3-Calc8.189.488.30 14.36 13.50 13.450shot-Text-S0.3-COT6.517.716.72 12.89 11.98 12.060shot-Text-S0.3-COT-CSV2.604.522.69 19.44 17.81 17.710shot-Text-S0.3-COT-PAP3.793.683.716.455.575.780shot-Text-S0.3-COT-TPD3.133.733.15 10.658.468.980shot-Text-S0.3-CSV3.658.973.62 37.52 31.89 32.680shot-Text-S0.3-Dyscalc7.158.207.22 16.55 13.84 14.390shot-Text-S0.3-PAP8.369.298.38 13.77 12.68 12.770shot-Text-S0.3-TPD4.017.604.01 24.88 21.46 21.450shot-Vision6.51 17.828.81 35.94 35.14 33.370shot-Vision-Calc4.68 15.555.41 26.42 29.19 25.800shot-Vision-COT4.979.255.37 30.18 27.70 27.270shot-Vision-Dyscalc7.16 18.748.88 32.78 33.72 31.011shot-Text-S0.34.244.933.22 37.50 32.79 32.661shot-Text-S0.3-COT3.052.692.40 30.54 26.81 26.861shot-Vision4.31 15.224.92 38.93 44.67 38.431shot-Vision-Calc4.55 13.455.19 35.04 38.20 33.781shot-Vision-COT2.768.413.58 35.98 42.04 36.751shot-Vision-Dyscalc4.11 12.285.37 35.10 38.41 33.73Isolation-Forest 0shot3.41 90.006.44 45.27 90.00 60.25Continued on next page</p>
<p>Table 3 -
3
continued from previous page
PRERECF1 affi affi affiPRERECF1</p>
<p>Table 4 :
4
Point noises anomalies in regular sine wave
PRERECF1 affi affi affiPRERECF1</p>
<p>Table 4 -
4
continued from previous page
PRERECF1 affi affi affiPRERECF10shot-Text-S0.3-COT-CSV7.347.426.84 27.29 22.92 24.050shot-Text-S0.3-COT-PAP 12.50 12.50 12.50 16.22 15.71 15.830shot-Text-S0.3-COT-TPD0.930.860.878.277.947.890shot-Text-S0.3-CSV16.60 17.03 16.34 30.86 29.03 29.290shot-Text-S0.3-Dyscalc1.491.891.51 24.42 23.94 23.450shot-Text-S0.3-PAP15.02 14.88 14.93 23.92 22.86 23.050shot-Text-S0.3-TPD4.116.404.34 22.28 23.67 22.350shot-Vision39.16 41.75 39.01 62.88 58.88 60.100shot-Vision-Calc38.89 42.58 39.11 63.17 61.04 61.420shot-Vision-COT39.70 40.55 38.90 63.08 58.39 59.890shot-Vision-Dyscalc39.02 42.07 39.13 63.05 60.52 61.121shot-Text-S0.36.114.874.26 42.74 40.82 40.181shot-Text-S0.3-COT10.90 14.44 11.04 46.00 50.70 47.151shot-Vision38.24 39.36 36.32 76.21 71.14 72.221shot-Vision-Calc41.29 41.60 39.22 76.55 71.06 72.361shot-Vision-COT40.35 42.84 39.01 76.07 71.23 72.041shot-Vision-Dyscalc40.96 43.16 39.99 77.02 71.87 72.99Internvlm-76B0shot-Text19.26 22.48 19.47 25.08 27.32 25.840shot-Text-S0.310.21 11.349.96 33.19 34.47 32.600shot-Text-S0.3-Calc21.42 23.25 21.52 25.62 26.72 25.930shot-Text-S0.3-COT15.82 16.50 15.86 18.51 19.07 18.680shot-Text-S0.3-COT-CSV9.219.828.81 26.12 24.75 24.700shot-Text-S0.3-COT-PAP 10.58 10.83 10.58 11.56 11.76 11.620shot-Text-S0.3-COT-TPD9.009.009.00 11.69 11.68 11.630shot-Text-S0.3-CSV11.92 13.91 11.20 40.05 38.01 37.780shot-Text-S0.3-Dyscalc 18.89 19.66 18.94 23.35 23.80 23.460shot-Text-S0.3-PAP25.26 25.50 25.27 27.14 27.26 27.160shot-Text-S0.3-TPD7.007.007.00 14.89 15.08 14.880shot-Vision14.26 53.10 20.64 56.18 67.83 60.770shot-Vision-Calc22.97 58.75 28.77 66.27 76.14 70.440shot-Vision-COT4.35 12.955.47 31.51 39.00 33.610shot-Vision-Dyscalc17.31 54.36 23.36 59.49 70.15 63.791shot-Text-S0.38.699.897.70 32.37 32.95 31.191shot-Text-S0.3-COT10.209.989.43 30.63 30.69 29.491shot-Vision9.97 29.84 12.99 44.76 57.62 49.261shot-Vision-Calc10.01 29.92 12.26 44.34 57.93 48.861shot-Vision-COT3.87 12.654.61 33.66 45.65 37.301shot-Vision-Dyscalc8.98 31.81 11.90 42.77 59.47 48.65</p>
<p>Table 4 -
4
continued from previous page
PRERECF1 affi affi affiPRERECF10shot-Vision-Dyscalc3.26 28.284.58 17.87 30.85 22.361shot-Text-S0.3-COT0.000.000.000.000.000.001shot-Vision9.15 25.49 10.04 41.59 47.97 42.611shot-Vision-Calc7.88 12.808.16 10.78 13.28 11.591shot-Vision-COT11.42 16.01 11.60 29.38 30.82 29.231shot-Vision-Dyscalc8.55 19.618.72 37.64 43.60 38.63Threshold0shot3.493.172.82 35.06 68.55 46.36</p>
<p>Table 5 :
5
Out-of-range anomalies in Gaussian noise
PRERECF1 affi affi affiPRERECF1</p>
<p>Table 6 -
6
continued from previous page
PRERECF1 affi affi affiPRERECF10shot-Text-S0.3-CSV0.000.000.000.000.000.000shot-Text-S0.3-PAP12.00 12.00 12.00 12.00 12.00 12.000shot-Text-S0.3-TPD1.251.251.251.291.331.300shot-Vision4.17 27.946.29 16.61 30.00 21.210shot-Vision-COT21.45 25.06 21.78 23.75 25.71 24.461shot-Text-S0.3-COT0.000.000.000.000.000.001shot-Vision7.96 25.639.18 23.34 33.78 27.031shot-Vision-COT30.74 31.50 30.86 33.42 33.91 33.63Threshold0shot6.582.563.46 19.40 37.51 25.41</p>
<p>Table 7 :
7
Frequency anomalies in regular sine wave with extra noise
PRERECF1 affi affi affiPRERECF1</p>
<p>Table 8 :
8
Point noises anomalies in regular sine wave with Gaussian noise
PRERECF1 affi affi affiPRERECF1
ACKNOWLEDGEMENTThis work was supported in part by the U.S. Army Research Office under Army-ECASE award W911NF-07-R-0003-03, the U.S. Department Of Energy, Office of Science, IARPA HAYSTAC Program, and NSF Grants #2205093, #2146343, #2134274, CDC-RFA-FT-23-0069, DARPA AIE FoundSci and DARPA YFA.We thank Dr. Eamonn Keogh for the helpful suggestions.Isolation-Forest 0shot3.36 70.48 6.16 35.66 70.75 47.43 Qwen 0shot-Text 0.00 0.00 0.00 0.00 0.00 0.00 0shot-Text-S0.3 0.00 0.00 0.00 0.00 0.00 0.00 0shot-Text-S0.3-Calc0.00 0.00 0.00 0.00 0.00 0.00 0shot-Text-S0.3-COT1.50 1.50 1.50 1.61 1.59 1.60 0shot-Text-S0.3-COT-CSV0.00 0.00 0.00 0.00 0.00 0.00 0shot-Text-S0.3-COT-PAP2.00 2.00 2.00 2.00 2.00 2.00 0shot-Text-S0.3-COT-TPD0.50 0.50 0.50 0.80 0.84 0.82 0shot-Text-S0.3-CSV0.00 0.00 0.00 0.00 0.00 0.00 0shot-Text-S0.3-Dyscalc0.00 0.00 0.00 0.00 0.00 0.00 0shot-Text-S0.3-PAP6.00 6.00 6.00 6.16 6.17 6.16 0shot-Text-S0.
. Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, Sébastien Bubeck, Qin Cai, Martin Cai, Caio César, Teodoro Mendes, Weizhu Chen, Vishrav Chaudhary, Dong Chen, Dongdong Chen, Yen-Chun Chen, Yi-Ling Chen, Parul Chopra, Xiyang Dai, Allie Del Giorno, Gustavo De Rosa, Matthew Dixon, Ronen Eldan, Victor Fragoso, Dan Iter, Mei Gao, Min Gao, Jianfeng Gao, Amit Garg, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J Hewett, Jamie Huynh, Mojan Javaheripi, Xin Jin, Piero Kauffmann, Nikos Karampatziakis, Dongwoo Kim, Mahoud Khademi, Lev Kurilenko, James R Lee, Yin Tat Lee, Yuanzhi Li, Yunsheng Li, Chen Liang, Lars Liden, Ce Liu, Mengchen Liu, Weishung Liu, Eric Lin, Zeqi Lin, Chong Luo, Piyush Madan, Matt Mazzola, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Swadheen Shukla, Xia Song, Masahiro Tanaka, Andrea Tupini, Xin Wang, Lijuan Wang, Chunyu Wang, Yu Wang, Rachel Ward, Guanhua Wang, Philipp Witte, Haiping Wu, Michael Wyatt, Bin Xiao, Can Xu, Jiahang Xu, Weijian Xu, Sonali Yadav, Fan Yang, Jianwei Yang, Ziyi Yang, Yifan Yang, Donghan Yu, Lu Yuan, Chengruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, Xiren Zhou, Phi-3 technical report: A highly capable language model locally on your phone. ArXiv preprint, abs/2404.14219, 2024</p>
<p>Do deep neural networks contribute to multivariate time series anomaly detection?. Julien Audibert, Pietro Michiardi, Frédéric Guyard, Sébastien Marti, Maria A Zuluaga, ArXiv preprint, abs/2204.016372022</p>
<p>Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond. Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, Jingren Zhou, abs/2308.129662023ArXiv preprint</p>
<p>Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mccandlish, Alec Radford, Ilya Sutskever, Dario Amodei, Annual Conference on Neural Information Processing Systems. Hugo Larochelle, Marc ' , Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, Hsuan-Tien Lin, NeurIPS2020. 2020. December 6-12, 2020, virtual, 202033Advances in Neural Information Processing Systems</p>
<p>Deep variational graph convolutional recurrent network for multivariate time series anomaly detection. Wenchao Chen, Long Tian, Bo Chen, Liang Dai, Zhibin Duan, Mingyuan Zhou, International Conference on Machine Learning, ICML 2022. Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, Sivan Sabato, Baltimore, Maryland, USAPMLRJuly 2022. 2022162of Proceedings of Machine Learning Research</p>
<p>How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites. Zhe Chen, Weiyun Wang, Shenglong Hao Tian, Zhangwei Ye, Erfei Gao, Wenwen Cui, Kongzhi Tong, Jiapeng Hu, Zheng Luo, Ji Ma, Jiaqi Ma, Xiaoyi Wang, Hang Dong, Hewei Yan, Conghui Guo, Botian He, Zhenjiang Shi, Chao Jin, Bin Xu, Xingjian Wang, Wei Wei, Wenjian Li, Bo Zhang, Pinlong Zhang, Licheng Cai, Xiangchao Wen, Min Yan, Lewei Dou, Xizhou Lu, Tong Zhu, Dahua Lu, Yu Lin, Jifeng Qiao, Wenhai Dai, Wang, abs/2404.16821ArXiv preprint. 2024</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, abs/2110.141682021ArXiv preprint</p>
<p>Lmdeploy: A toolkit for compressing, deploying, and serving llm. Lmdeploy Contributors, 2023</p>
<p>Can llms serve as time series anomaly detectors?. Manqing Dong, Hao Huang, Longbing Cao, ArXiv preprint, abs/2408.034752024</p>
<p>. Google. Gemini flash. 2024</p>
<p>Large language models are zeroshot time series forecasters. Nate Gruver, Marc Finzi, Shikai Qiu, Andrew Gordon, Wilson , Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, Sergey Levine, New Orleans, LA, USADecember 10 -16, 2023. 20232023</p>
<p>The curious case of neural text degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, 8th International Conference on Learning Representations. Addis Ababa, EthiopiaApril 26-30, 2020. 20202020OpenReview.net</p>
<p>Multimodal neural machine translation with language scene graph. Lun Huang, Jiajun Zhou, Chengqing Zhang, Hainan Huang, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics2019</p>
<p>Local evaluation of time series anomaly detection algorithms. Alexis Huet, José Manuel Navarro, Dario Rossi, 10.1145/3534678.3539339KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. Aidong Zhang, Huzefa Rangwala, Washington, DC, USAACMAugust 14 -18, 20222022</p>
<p>Time-llm: Time series forecasting by reprogramming large language models. Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, Qingsong Wen, abs/2310.017282023ArXiv preprint</p>
<p>Position: What can large language models tell us about time series analysis. Ming Jin, Yifan Zhang, Wei Chen, Kexin Zhang, Yuxuan Liang, Bin Yang, Jindong Wang, Shirui Pan, Qingsong Wen, abs/2402.027132024ArXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems. S Sanmi Koyejo, A Mohamed, Danielle Agarwal, K Belgrave, A Cho, Oh, New Orleans, LA, USA2022. November 28 -December 9, 2022. 20222022</p>
<p>Efficient memory management for large language model serving with pagedattention. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E Gonzalez, Hao Zhang, Ion Stoica, Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles. the ACM SIGOPS 29th Symposium on Operating Systems Principles2023</p>
<p>Nominality score conditioned time series anomaly detection by point/sequential reconstruction. Chih-Yu Lai, Fan-Keng Sun, Zhengqi Gao, Jeffrey H Lang, Duane S Boning, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023. Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, Sergey Levine, NeurIPS; New Orleans, LA, USA2023. December 10 -16, 2023. 2023</p>
<p>Yahoo anomaly detection dataset S5. N Laptev, S Amizadeh, 2015</p>
<p>Unicoder: A universal encoder for text, image and video. Gen Li, Nan Duan, Yuejian Fang, Ming Gong, Daxin Jiang, Ming Zhou, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)2019</p>
<p>Long-context llms struggle with long in-context learning. Tianle Li, Ge Zhang, Quy Duc Do, Xiang Yue, Wenhu Chen, abs/2404.020602024ArXiv preprint</p>
<p>Reflexive and reflective judgment processes: A social cognitive neuroscience approach. D Matthew, Lieberman, 2003Cambridge University PressNew York, NY, US</p>
<p>Large language model guided knowledge distillation for time series anomaly detection. Chen Liu, Shibo He, Qihang Zhou, Shizhong Li, Wenchao Meng, abs/2401.151232024aArXiv preprint</p>
<p>Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, 2008 eighth ieee international conference on data mining. IEEE2008Isolation forest</p>
<p>Time-mmd: A new multi-domain multimodal dataset for time series analysis. Haoxin Liu, Shangqing Xu, Zhiyuan Zhao, Lingkai Kong, Harshavardhan Kamarthi, Aditya B Sasanur, Megha Sharma, Jiaming Cui, Qingsong Wen, Chao Zhang, B Aditya Prakash, abs/2406.086272024bArXiv preprint</p>
<p>Multimodal transformer for unaligned multimodal time series analysis. Haoyi Liu, Shanghang Bai, Yuyang Shen, Xu Han, Wei Zhang, Jiliang Gao, Proceedings of the Web Conference 2021. the Web Conference 20212021</p>
<p>Taming pre-trained llms for generalised time series forecasting via cross-modal knowledge distillation. Peiyuan Liu, Hang Guo, Tao Dai, Naiqi Li, Jigang Bao, Xudong Ren, Yong Jiang, Shu-Tao Xia, abs/2403.073002024cArXiv preprint</p>
<p>Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. M Hanna, Hugo Wallach, Alina Larochelle, Beygelzimer, Emily B Florence D'alché-Buc, Roman Fox, Garnett, NeurIPS; Vancouver, BC, Canada2019. 2019. December 8-14, 2019. 2019</p>
<p>Visual acceleration perception for simple and complex motion patterns. Alexandra S Mueller, Brian Timney, 10.1371/journal.pone.0149413PLoS ONE. 1932-6203112e01494132016</p>
<p>Do language models exhibit the same cognitive biases in problem solving as human learners?. Andreas Opedal, Alessandro Stolfo, Haruki Shirakami, Ying Jiao, Ryan Cotterell, Bernhard Schölkopf, Abulhair Saparov, Mrinmaya Sachan, ArXiv preprint, abs/2401.180702024</p>
<p>Gpt-4o mini: Advancing cost-efficient intelligence. 2024OpenAI</p>
<p>Volume under the surface: a new accuracy evaluation measure for time-series anomaly detection. John Paparrizos, Paul Boniol, Themis Palpanas, S Ruey, Aaron Tsay, Michael J Elmore, Franklin, Proceedings of the VLDB Endowment. the VLDB Endowment202215</p>
<p>Interactive visualization of normal behavioral models and expert rules for maritime anomaly detection. Maria Riveiro, Göran Falkman, 10.1109/CGIV.2009.54Imaging and Visualization 2009 Sixth International Conference on Computer Graphics. 2009</p>
<p>Position: Quo vadis, unsupervised time series anomaly detection?. M Saquib Sarfraz, Mei-Yen Chen, Lukas Layer, Kunyu Peng, Marios Koulakis, ArXiv preprint, abs/2405.026782024</p>
<p>Chartmimic: Evaluating lmm's cross-modal reasoning capability via chart-to-code generation. Chufan Shi, Cheng Yang, Yaxin Liu, Bo Shui, Junjie Wang, Mohan Jing, Linran Xu, Xinyu Zhu, Siheng Li, Yuxiang Zhang, Gongye Liu, Xiaomei Nie, Deng Cai, Yujiu Yang, abs/2406.099612024ArXiv preprint</p>
<p>Videobert: A joint model for video and language representation learning. Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, Cordelia Schmid, 10.1109/ICCV.2019.007562019 IEEE/CVF International Conference on Computer Vision, ICCV 2019. Seoul, Korea (South)IEEEOctober 27 -November 2, 2019. 2019</p>
<p>Are language models actually useful for time series forecasting. Mingtian Tan, Mike A Merrill, Vinayak Gupta, Tim Althoff, Thomas Hartvigsen, ArXiv preprint, abs/2406.169642024</p>
<p>Time series forecasting with llms: Understanding and enhancing model capabilities. Hua Tang, Chong Zhang, Mingyu Jin, Qinkai Yu, Zhenting Wang, Xiaobo Jin, Yongfeng Zhang, Mengnan Du, abs/2402.108352024ArXiv preprint</p>
<p>Large language models can accurately predict searcher preferences. Paul Thomas, Seth Spielman, Nick Craswell, Bhaskar Mitra, abs/2309.106212023ArXiv preprint</p>
<p>Tranad: Deep transformer networks for anomaly detection in multivariate time series data. Shreshth Tuli, Giuliano Casale, Nicholas R Jennings, abs/2201.072842022ArXiv preprint</p>
<p>Mmlu-pro: A more robust and challenging multi-task language understanding benchmark. Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, Wenhu Chen, abs/2406.015742024ArXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H Chi, V Quoc, Denny Le, Zhou, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems. S Sanmi Koyejo, A Mohamed, Danielle Agarwal, K Belgrave, A Cho, Oh, NeurIPS; New Orleans, LA, USA2022. 2022. November 28 -December 9, 2022. 2022</p>
<p>Leveraging vision-language models for granular market change prediction. Christopher Wimmer, Navid Rekabsaz, abs/2301.101662023ArXiv preprint</p>
<p>Current time series anomaly detection benchmarks are flawed and are creating the illusion of progress. Renjie Wu, Eamonn Keogh, 10.1109/TKDE.2021.3112126IEEE Transactions on Knowledge and Data Engineering. 1041-4347, 1558-21912021</p>
<p>How well do large language models perform in arithmetic tasks?. Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, Songfang Huang, ArXiv preprint, abs/2304.020152023</p>
<p>Are transformers effective for time series forecasting. Ailing Zeng, Muxi Chen, Lei Zhang, Qiang Xu, 10.1609/aaai.v37i9.26317Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence, IAAI 2023, Thirteenth Symposium on Educational Advances in Artificial Intelligence. Brian Williams, Yiling Chen, Jennifer Neville, Washington, DC, USAAAAI PressFebruary 7-14, 202320232023</p>
<p>Large language models for time series: A survey. Xiyuan Zhang, Ranak Roy Chowdhury, Rajesh K Gupta, Jingbo Shang, S0.3 7.12 13.71 8.42 47.06 56.95 50.69 1shot-Text-S0.3-COT 12.04 14.57 12.31 46.38 49.43 46.57 1shot-Vision 33.77 63.17 40.02 80.05 82.67 81.07 1shot-Vision-Calc 36.28 64.25 42.40 81.41 84.05 82.40 1shot-Vision-COT 22.85 50.51 28.87 69.16 71.62 70.05 1shot-Vision-Dyscalc 35.52 61.50 41.15 81.49 83.06 81.8220241877ArXiv preprint</p>
<p>0shot-Vision-Dyscalc. 36.67 41.84 37.21 72.87 75.26 73.43 1shot-Text-S0.3 7.96 12.51 8.52 43.20 45.55 43.17 1shot-Text-S0.3-COT 9.43 11.72 9.65 44.53 43.69 42.97 1shot-Vision 31.52 33.83 30.99 75.81 76.46 75.3437</p>            </div>
        </div>

    </div>
</body>
</html>