<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9161 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9161</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9161</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-266998884</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.08089v1.pdf" target="_blank">A Study on Training and Developing Large Language Models for Behavior Tree Generation</a></p>
                <p><strong>Paper Abstract:</strong> This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks. The conventional manual BT generation method is inefficient and heavily reliant on domain expertise. On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability. In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs. The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification. Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance. In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy. Additionally, we explore a range of agent design and development schemes with LLM as the central element. We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9161.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9161.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LMulator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language-Model-Augmented Code Emulator (LMulator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach that uses an LLM to simulate program execution when real execution fails, updating program state from the LLM outputs to continue execution; proposed as a mechanism to enable LLMs to act as executors/emulators for code and program-state transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described as an LLM used together with a code emulator: if code execution fails, the LLM simulates the execution and provides outputs that update program state; no model size or training-data details are provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Software engineering / program synthesis / code generation</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Emulate program execution and update program state when generated code cannot be run (i.e., simulate runtime behavior of code to continue program-level reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Functional correctness via unit tests / execution pass rate (paper references use of unit tests and pass@k as evaluation metrics for code generation/emulation tasks), but LMulator-specific metrics are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported in this paper; no numerical performance values provided.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Quality and reasoning ability of the underlying LLM; completeness and coverage of unit tests; fidelity of the mapping from LLM textual output to program state; prompt design and the emulator integration; availability of diverse example executions during training/fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Actual execution on real interpreters/runtimes and unit-test-driven verification; LMulator is framed as a fallback when real execution fails (i.e., compared conceptually to native execution rather than quantitatively compared to other LLMs).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes that LLM-based simulation is an approximation — when code cannot run, LLM outputs may be incorrect or hallucinated; emulation fidelity is lower than real execution and correctness is not guaranteed; no empirical robustness numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors recommend using LMulator-like ideas as inspiration for BT validation: interleave real execution and LLM-based simulation in a feedback loop, and use unit tests and iterative inspection to improve correctness; integrate LLM emulation with verification to guide refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Study on Training and Developing Large Language Models for Behavior Tree Generation', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9161.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9161.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 Inspector</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 used as a compilation/runtime inspector</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of GPT-4 as an automated inspector that detects compilation/runtime errors in generated code and suggests fixes in an iterative loop until tests pass or a limit is reached.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>High-capacity OpenAI conversational model (described earlier in the paper as GPT-4; no parameter count provided in this paper), used here as a textual inspector for code correctness and runtime issues.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Software engineering / program debugging and verification</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Inspect code for compilation and runtime errors and generate corrective suggestions; effectively simulates an expert debugger/reviewer in text form to guide code repair.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Implicitly: number of inspection iterations until the code compiles/runs or unit tests pass; specific numeric metrics not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported in this paper; no quantitative accuracy or success-rate numbers are given.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Quality of prompts and instruction design for the inspector; availability and coverage of unit tests; LLM reasoning quality and up-to-date knowledge; complexity of the code and the runtime environment; potential hallucination of fixes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Implicit baseline is human debugging or traditional static/dynamic analyzers; no quantitative comparison reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Potential for hallucinated or incorrect fixes; iterative process may not converge to a correct solution; reliance on tests/unit coverage for verification.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Integrate LLM-based inspection with unit tests and iterative loops; use the inspector as part of a refinement/validation pipeline rather than as a sole correctness oracle.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Study on Training and Developing Large Language Models for Behavior Tree Generation', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9161.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9161.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM State-Transition Simulator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based Environment State Transition Simulator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using LLMs as textual world models that take a representation of the current environment state and an action, and output the predicted next environment state — effectively replacing or augmenting traditional simulators for state-transition prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM(s) (as used in cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>General large language models employed to interpret textual/state descriptions and predict subsequent states given actions; the paper references external work that applies LLMs to simulate environment dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Robotics / embodied agents / planning and simulation</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Predict the next environment state given the current state and an action (text-based simulation of state transitions for embodied agents or planners).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Not specified in this paper for the cited work; natural possibilities discussed include state-prediction accuracy, task success rates in downstream planning, and qualitative agreement with ground-truth simulator behavior, but no empirical numbers are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported in this paper; authors state effectiveness and accuracy require further research.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Representation granularity of environment state; model reasoning and planning ability; prompt design and instruction format; domain complexity and partial observability; training / fine-tuning on domain-specific transition examples; retrieval-augmented knowledge access.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Classical/high-fidelity simulators (physics-based or domain-specific simulators); authors discuss LLMs as either augmenting or replacing simulators but no quantitative baseline comparison is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fidelity and generalization of purely LLM-based state simulators are uncertain; LLMs can hallucinate transitions or miss low-level physical constraints; building accurate textual state encodings is nontrivial; more validation is needed.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Recommend interweaving LLM-based state prediction with existing simulators in a feedback loop to leverage strengths of both: use simulators for precise low-level dynamics and LLMs for high-level generalization, environment setup, and feedback design.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Study on Training and Developing Large Language Models for Behavior Tree Generation', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9161.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9161.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BT Simulator (proposed)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Behavior-Tree Simulator (LLM + Simulator feedback loop) — proposed in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed simulator specifically for V&V of generated behavior trees that interleaves a traditional simulator with an LLM in a feedback loop; the LLM helps set environments, simulate state transitions and actions generation, and design feedback functions to improve generalization and reduce manual simulator design work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM (to be integrated)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An LLM integrated into a BT simulation loop: the existing simulator provides structural state transitions while the LLM augments simulation by supplying world knowledge, action semantics, and higher-level state reasoning; no concrete model or size is specified.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Robotics / behavior-tree validation and verification (robot task execution)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Simulate execution of generated Behavior Trees (BTs) by (1) setting simulated environments, (2) predicting state transitions and action outcomes textually, and (3) providing feedback signals to iteratively update the BTGen model.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Proposed evaluation includes: executability (compilation), unit-test pass rate, simulator-derived task-success rate, and higher-level BT benchmarks (accuracy, F1, ROUGE-L for some sub-tasks); precise BT-simulator metrics are proposed but not empirically reported.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported — the paper proposes the BT simulator design and suggests it should improve generalization, but provides no quantitative results or accuracy figures.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Simulator fidelity; quality and coverage of the BT node library; LLM planning and reasoning abilities; prompt design and retrieval-augmented generation (RAG) quality; quality of synthetic training data; validation/verification feedback loop design; domain complexity and out-of-domain knowledge gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Existing standalone simulators and unit-test-driven V&V; the authors position the BT simulator as a hybrid expected to generalize better than pure simulator-only approaches but provide no empirical comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Challenges include labor-intensive simulator construction, potential for LLM-introduced incorrect or low-quality feedback, hallucinations, and unclear fidelity for physical dynamics; the method is proposed conceptually and not validated empirically in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors recommend a mixed loop: combine existing simulators with LLMs so the LLM can set environments and provide high-level state reasoning while simulators provide precise dynamics; employ multi-level refinement (fast/cheap feedback then full validation) and rigorous V&V (unit tests, benchmarks) to mitigate hallucination and improve BT quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Study on Training and Developing Large Language Models for Behavior Tree Generation', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of code: Reasoning with a language model-augmented code emulator <em>(Rating: 2)</em></li>
                <li>Large language models empowered agent-based modeling and simulation: A survey and perspectives <em>(Rating: 2)</em></li>
                <li>Real-time prompting of interactive worlds using large language models <em>(Rating: 1)</em></li>
                <li>Emergent gaming interaction <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9161",
    "paper_id": "paper-266998884",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "LMulator",
            "name_full": "Language-Model-Augmented Code Emulator (LMulator)",
            "brief_description": "A hybrid approach that uses an LLM to simulate program execution when real execution fails, updating program state from the LLM outputs to continue execution; proposed as a mechanism to enable LLMs to act as executors/emulators for code and program-state transitions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM (generic)",
            "model_description": "Described as an LLM used together with a code emulator: if code execution fails, the LLM simulates the execution and provides outputs that update program state; no model size or training-data details are provided in the paper.",
            "scientific_subdomain": "Software engineering / program synthesis / code generation",
            "simulation_task": "Emulate program execution and update program state when generated code cannot be run (i.e., simulate runtime behavior of code to continue program-level reasoning).",
            "evaluation_metric": "Functional correctness via unit tests / execution pass rate (paper references use of unit tests and pass@k as evaluation metrics for code generation/emulation tasks), but LMulator-specific metrics are not reported.",
            "simulation_accuracy": "Not reported in this paper; no numerical performance values provided.",
            "factors_affecting_accuracy": "Quality and reasoning ability of the underlying LLM; completeness and coverage of unit tests; fidelity of the mapping from LLM textual output to program state; prompt design and the emulator integration; availability of diverse example executions during training/fine-tuning.",
            "comparison_baseline": "Actual execution on real interpreters/runtimes and unit-test-driven verification; LMulator is framed as a fallback when real execution fails (i.e., compared conceptually to native execution rather than quantitatively compared to other LLMs).",
            "limitations_or_failure_cases": "Paper notes that LLM-based simulation is an approximation — when code cannot run, LLM outputs may be incorrect or hallucinated; emulation fidelity is lower than real execution and correctness is not guaranteed; no empirical robustness numbers provided.",
            "author_recommendations_or_insights": "Authors recommend using LMulator-like ideas as inspiration for BT validation: interleave real execution and LLM-based simulation in a feedback loop, and use unit tests and iterative inspection to improve correctness; integrate LLM emulation with verification to guide refinement.",
            "uuid": "e9161.0",
            "source_info": {
                "paper_title": "A Study on Training and Developing Large Language Models for Behavior Tree Generation",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "GPT-4 Inspector",
            "name_full": "GPT-4 used as a compilation/runtime inspector",
            "brief_description": "Use of GPT-4 as an automated inspector that detects compilation/runtime errors in generated code and suggests fixes in an iterative loop until tests pass or a limit is reached.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_description": "High-capacity OpenAI conversational model (described earlier in the paper as GPT-4; no parameter count provided in this paper), used here as a textual inspector for code correctness and runtime issues.",
            "scientific_subdomain": "Software engineering / program debugging and verification",
            "simulation_task": "Inspect code for compilation and runtime errors and generate corrective suggestions; effectively simulates an expert debugger/reviewer in text form to guide code repair.",
            "evaluation_metric": "Implicitly: number of inspection iterations until the code compiles/runs or unit tests pass; specific numeric metrics not provided in the paper.",
            "simulation_accuracy": "Not reported in this paper; no quantitative accuracy or success-rate numbers are given.",
            "factors_affecting_accuracy": "Quality of prompts and instruction design for the inspector; availability and coverage of unit tests; LLM reasoning quality and up-to-date knowledge; complexity of the code and the runtime environment; potential hallucination of fixes.",
            "comparison_baseline": "Implicit baseline is human debugging or traditional static/dynamic analyzers; no quantitative comparison reported in the paper.",
            "limitations_or_failure_cases": "Potential for hallucinated or incorrect fixes; iterative process may not converge to a correct solution; reliance on tests/unit coverage for verification.",
            "author_recommendations_or_insights": "Integrate LLM-based inspection with unit tests and iterative loops; use the inspector as part of a refinement/validation pipeline rather than as a sole correctness oracle.",
            "uuid": "e9161.1",
            "source_info": {
                "paper_title": "A Study on Training and Developing Large Language Models for Behavior Tree Generation",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "LLM State-Transition Simulator",
            "name_full": "LLM-based Environment State Transition Simulator",
            "brief_description": "Using LLMs as textual world models that take a representation of the current environment state and an action, and output the predicted next environment state — effectively replacing or augmenting traditional simulators for state-transition prediction.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM(s) (as used in cited work)",
            "model_description": "General large language models employed to interpret textual/state descriptions and predict subsequent states given actions; the paper references external work that applies LLMs to simulate environment dynamics.",
            "scientific_subdomain": "Robotics / embodied agents / planning and simulation",
            "simulation_task": "Predict the next environment state given the current state and an action (text-based simulation of state transitions for embodied agents or planners).",
            "evaluation_metric": "Not specified in this paper for the cited work; natural possibilities discussed include state-prediction accuracy, task success rates in downstream planning, and qualitative agreement with ground-truth simulator behavior, but no empirical numbers are provided here.",
            "simulation_accuracy": "Not reported in this paper; authors state effectiveness and accuracy require further research.",
            "factors_affecting_accuracy": "Representation granularity of environment state; model reasoning and planning ability; prompt design and instruction format; domain complexity and partial observability; training / fine-tuning on domain-specific transition examples; retrieval-augmented knowledge access.",
            "comparison_baseline": "Classical/high-fidelity simulators (physics-based or domain-specific simulators); authors discuss LLMs as either augmenting or replacing simulators but no quantitative baseline comparison is provided.",
            "limitations_or_failure_cases": "Fidelity and generalization of purely LLM-based state simulators are uncertain; LLMs can hallucinate transitions or miss low-level physical constraints; building accurate textual state encodings is nontrivial; more validation is needed.",
            "author_recommendations_or_insights": "Recommend interweaving LLM-based state prediction with existing simulators in a feedback loop to leverage strengths of both: use simulators for precise low-level dynamics and LLMs for high-level generalization, environment setup, and feedback design.",
            "uuid": "e9161.2",
            "source_info": {
                "paper_title": "A Study on Training and Developing Large Language Models for Behavior Tree Generation",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "BT Simulator (proposed)",
            "name_full": "Behavior-Tree Simulator (LLM + Simulator feedback loop) — proposed in this paper",
            "brief_description": "A proposed simulator specifically for V&V of generated behavior trees that interleaves a traditional simulator with an LLM in a feedback loop; the LLM helps set environments, simulate state transitions and actions generation, and design feedback functions to improve generalization and reduce manual simulator design work.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM (to be integrated)",
            "model_description": "An LLM integrated into a BT simulation loop: the existing simulator provides structural state transitions while the LLM augments simulation by supplying world knowledge, action semantics, and higher-level state reasoning; no concrete model or size is specified.",
            "scientific_subdomain": "Robotics / behavior-tree validation and verification (robot task execution)",
            "simulation_task": "Simulate execution of generated Behavior Trees (BTs) by (1) setting simulated environments, (2) predicting state transitions and action outcomes textually, and (3) providing feedback signals to iteratively update the BTGen model.",
            "evaluation_metric": "Proposed evaluation includes: executability (compilation), unit-test pass rate, simulator-derived task-success rate, and higher-level BT benchmarks (accuracy, F1, ROUGE-L for some sub-tasks); precise BT-simulator metrics are proposed but not empirically reported.",
            "simulation_accuracy": "Not reported — the paper proposes the BT simulator design and suggests it should improve generalization, but provides no quantitative results or accuracy figures.",
            "factors_affecting_accuracy": "Simulator fidelity; quality and coverage of the BT node library; LLM planning and reasoning abilities; prompt design and retrieval-augmented generation (RAG) quality; quality of synthetic training data; validation/verification feedback loop design; domain complexity and out-of-domain knowledge gaps.",
            "comparison_baseline": "Existing standalone simulators and unit-test-driven V&V; the authors position the BT simulator as a hybrid expected to generalize better than pure simulator-only approaches but provide no empirical comparisons.",
            "limitations_or_failure_cases": "Challenges include labor-intensive simulator construction, potential for LLM-introduced incorrect or low-quality feedback, hallucinations, and unclear fidelity for physical dynamics; the method is proposed conceptually and not validated empirically in this paper.",
            "author_recommendations_or_insights": "Authors recommend a mixed loop: combine existing simulators with LLMs so the LLM can set environments and provide high-level state reasoning while simulators provide precise dynamics; employ multi-level refinement (fast/cheap feedback then full validation) and rigorous V&V (unit tests, benchmarks) to mitigate hallucination and improve BT quality.",
            "uuid": "e9161.3",
            "source_info": {
                "paper_title": "A Study on Training and Developing Large Language Models for Behavior Tree Generation",
                "publication_date_yy_mm": "2024-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of code: Reasoning with a language model-augmented code emulator",
            "rating": 2,
            "sanitized_title": "chain_of_code_reasoning_with_a_language_modelaugmented_code_emulator"
        },
        {
            "paper_title": "Large language models empowered agent-based modeling and simulation: A survey and perspectives",
            "rating": 2,
            "sanitized_title": "large_language_models_empowered_agentbased_modeling_and_simulation_a_survey_and_perspectives"
        },
        {
            "paper_title": "Real-time prompting of interactive worlds using large language models",
            "rating": 1,
            "sanitized_title": "realtime_prompting_of_interactive_worlds_using_large_language_models"
        },
        {
            "paper_title": "Emergent gaming interaction",
            "rating": 1,
            "sanitized_title": "emergent_gaming_interaction"
        }
    ],
    "cost": 0.01861425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Study on Training and Developing Large Language Models for Behavior Tree Generation
16 Jan 2024</p>
<p>Fu Li 
Intelligent Game and Decision Lab (IGDL)
100091BeijingChina</p>
<p>Tianjin Artificial Intelligence Innovation Center (TAIIC)
300457TianjinChina</p>
<p>Xueying Wang 
Intelligent Game and Decision Lab (IGDL)
100091BeijingChina</p>
<p>Tianjin Artificial Intelligence Innovation Center (TAIIC)
300457TianjinChina</p>
<p>Bin Li 
Intelligent Game and Decision Lab (IGDL)
100091BeijingChina</p>
<p>Yunlong Wu yunlong.wu@vip.163.com 
Intelligent Game and Decision Lab (IGDL)
100091BeijingChina</p>
<p>Tianjin Artificial Intelligence Innovation Center (TAIIC)
300457TianjinChina</p>
<p>Yanzhen Wang 
Intelligent Game and Decision Lab (IGDL)
100091BeijingChina</p>
<p>Tianjin Artificial Intelligence Innovation Center (TAIIC)
300457TianjinChina</p>
<p>Xiaodong Yi 
Intelligent Game and Decision Lab (IGDL)
100091BeijingChina</p>
<p>Tianjin Artificial Intelligence Innovation Center (TAIIC)
300457TianjinChina</p>
<p>A Study on Training and Developing Large Language Models for Behavior Tree Generation
16 Jan 2024E28B07C0C399F5E84E829DD42E3B488EarXiv:2401.08089v1[cs.CL]
This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks.The conventional manual BT generation method is inefficient and heavily reliant on domain expertise.On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability.In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs.The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification.Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance.In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy.Additionally, we explore a range of agent design and development schemes with LLM as the central element.We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs.</p>
<p>Introduction</p>
<p>Behavior tree is a typical control architecture (CA) that is widely used in computer games and robotics to describe the behaviors of AI and robots [1].It can flexibly control task switching between different autonomic agents, such as robots or virtual entities in computer games, and has explicit support for task hierarchy, action sequencing, and reactivity [2].BT provides a structured and systematic approach to model the behaviors of agents and bridges the gap between abstract goals and concrete implementation of those goals.One of the key advantages of BT is its flexibility in controlling the actions of agents.It offers a modular and hierarchical representation, where each task or behavior can be encapsulated as a separate node in the tree.This allows for feasible modification and extension of the behaviors of agents without disrupting the overall architecture of the system.Compared with other control architectures, BT has the advantages of modularity, hierarchy, reactivity, readability, and reusability [3].</p>
<p>The researches on BT have been rapidly growing due to its potential in improving complex decision-making processes and enabling more efficient planning and execution of tasks [4].Existing research can be categorized into several areas.One area focuses on enhancing the implementation of BT itself, such as improving node efficiency [5] and robustness [6].Another area explores methods for efficient BT generation, including learning-based approaches [7,8,9,10] and planning-based approaches [11,12,13,14].Additionally, there are studies aiming to expand the application scope of BT in various fields [15,16,17,18,19].</p>
<p>In this paper, we mainly focus on the problem of BT generation.Currently, the vast majority of BTs applied to the real world are manually designed by human experts, which requires rich experience and domain knowledge.However, with the increasing complexity and variety of tasks, designing BTs by hand will be a very complex and timeconsuming task, which has led to research on automatic BT generation [7,20,3].Typical automatic BT generation methods include planning-based methods [21,22,23,13] and learning-based methods [24,25,26,27,28].However, the above methods still have limitations in understanding tasks, especially the ability to generate BTs according to complex task descriptions is still insufficient.</p>
<p>To meet the challenges faced by traditional BT generation methods, we need a method with strong adaptability, generality, and interpretability.LLMs represented by ChatGPT [29] and LLaMA [30] are developing explosively, showing strong complex reasoning ability, intelligent emergence ability, and interpretability.The advancement of LLMs presents a promising avenue for streamlining the generation of practical BTs.By harnessing the abilities of these models, it becomes possible to minimize the knowledge requirements associated with this process.Leveraging the power of LLMs can potentially alleviate the burden of extensive task knowledge and intricate sensor coding details that have traditionally been mandatory in the generation of practical BTs.Research on BT generation based on LLM is still in the early stages.In [31], a BT embedded approach was proposed to solve the task-level knowledge representation problem.Based on this, a BT generation method based on LLM was proposed, which realizes BT generation according to target task descriptions and few-shot examples through phase-step prompt design [28].In [32], 8.5k selfinstruct BT instructor-following data was generated by textdavinchi-003 and used to fine-tune another LLM (Stanford Alpaca 7B) for BT generation.</p>
<p>In general, training and developing LLMs for BT generation is very important.However, it is still in its infancy.Therefore, in this paper, we aim to examine the key technologies involved in various steps.The main contributions are summarized as follows:</p>
<p>• To the best of our knowledge, limited works focus on training and developing LLMs for BT generation.This paper delves into this area to efficiently obtain highquality BTs.</p>
<p>• We introduce a new BT data generation method using Monte Carlo tree search (MCTS) with state representation and operator libraries, improved with a knowledge base and node library constraints, and optimized with verification feedback for reliable the BT generation.</p>
<p>• We propose a training pipeline based on the foundation LLM and collected BT data set, including pretraining and supervised fine-tuning training, to enhance the abilities of BTGen model in the specialized BT applications.</p>
<p>• We propose a BT generation framework, named BT-Gen Agent, to deploy the trained BTGen model in realworld scenarios, which aims to mitigate common issues such as hallucination, data bias, limited out-ofdomain knowledge, and issues with less explainability and transparency.It comprises four main modules: memory module, action module, planning module, and profile module.In addition to these modules, it also incorporates a refinement mechanism to ensure usability.</p>
<p>• We propose a verification and validation (V&amp;V) driven pipeline to generate high-quality BTs, which runs through all steps in training and developing the BT-Gen model.It ensures that the functions correctly and meets the specified requirements, as well as provides feedback to improve the quality of the BT generation further.</p>
<p>The rest of the paper is organized as follows.First, Section 2 summarizes the methodology of this paper.Then, Section 3 introduces existing foundation models and the required abilities for LLMs.Section 4 shows the basic information of collected BTs for training.Section 5 and Section 6 show the pipelines for training BTGen model and developing it, respectively.Section 7 analyzes the V&amp;V on BT-Gen model and the generated BTs.Last, Section 8 summarizes the open questions.Section 9 makes conclusions.</p>
<p>Methodology</p>
<p>Generating BTs from task descriptions is a fundamental objective in the domain of automated planning and execution for robotics applications.The primary goal is to transform a given task description into an executable action plan structured as BTs.This enables robots to perform complex tasks autonomously by following the logical flow dictated by the BTs.
BT = G(task)(1)
As shown in Eq 1, the BT generation task is defined as a function G that maps a task description task onto a corresponding BT.The BT generation task requires the following abilities: task understanding, task planning, specific behavior generation, as well as verification and validation of the generated BTs.</p>
<p>Task Understanding is significant for the BT generation since it is the first step in structuring the task into a BT.Without a clear understanding, it is impossible to create BTs to successfully complete the specified tasks and meet the requirements of users.Extracting relevant information for generation, such as task objectives, robot hardware capabilities, and environmental constraints, is particularly challenging when the task description is provided in unconstrained natural language form.</p>
<p>Task Planning decomposes the complex task into multiple subtasks and organizes them in BT generation.Task planning requires converting abstract semantic instructions into detailed actionable sub-tasks and organizing them in the correct order.Specifically, it decomposes high-level goals into simpler manageable sub-tasks and organizes their control and information flows into the structure of a BT.</p>
<p>Specific Behavior Generation lays the groundwork for creating a BT by defining the actions and decision rules that the system will use to interact with its environment.It is a critical step that influences the functionality, reliability, and effectiveness of the resulting BT.Without properly gener-ated behaviors, a BT would lack the necessary elements to operate or achieve its intended goals.</p>
<p>V&amp;V in the BT generation is critical for creating systems that are dependable, safe, and effective.It prevents the implementation of flawed behaviors and guarantees that the designed behaviors are within the system's capability to carry out, ultimately contributing to the successful application of BTs in complex, real-world tasks.</p>
<p>LLMs have shown promise in the BT generation.The advent of LLMs represents a recent milestone in machine learning, showcasing immense capabilities in natural language processing tasks and textual generation [33].For Task Understanding, LLMs demonstrate an exceptional ability in understanding natural languages as well as in the creation of new content that is coherent, contextually relevant, and appropriate.For Task Planning, LLMs are equipped with intricate mechanisms for strategic planning, dynamically generating multi-step action sequences and adapting them to evolving scenarios.For Behavior Generation, although LLMs do not directly create BTs, they can play a supportive role in the behavior generation process and bridge the gap between human communication and machine-executable behavior sequences.For Verification and validation, recent scientific reports indicate that LLMs have the potential to function as comprehensive world models, simulating complex environments and scenarios with a high degree of fidelity, which could provide robust frameworks for testing the reliability and performance of AIdriven systems before they are developed in real-world applications.</p>
<p>Applying LLMs to the BT generation tasks still faces multiple challenges.Obtaining an effective BTGen model based on LLMs can be divided into three steps: training, developing and V&amp;V.We summarize these challenges from these three steps as follows.</p>
<p>First, in terms of training the BTGen model, the ability of BT generation involves key considerations about the interaction between model performance and its constituent elements.We simply encapsulate this ability, denoted as A BTGen , in Eq 2.
A BTGen = M ⊕ D(2)
According to Eq 2, three items are included: the foundation LLM M, the datasets used to train D, and the training pipeline ⊕.Thus, three challenges remain to be addressed in training LLMs for the BT generation.Challenge 1: How to select a proper foundation LLM for the BT generation?Many foundation LLMs with billions of parameters have been proposed, such as GPT [29], LLaMA [30], and GLM [34].The BTGen model can be trained on these foundation LLMs incrementally rather than being trained from scratch when computing resources are limited.However, how to choose an appropriate foundation LLM based on the abili-ties required for the BT generation needs to be addressed.</p>
<p>To the best of our knowledge, there is limited research in this area.Challenge 2: How to generate a high-quality BT dataset?A growing body of work emphasizes the impact of data quality on the performance of LLMs [35,36].Data quality significantly impacts the performance of LLMs in terms of their abilities to understand language and provide reliable outputs.A high-quality dataset is integral to enhancing both the efficiency and the performance of the BT generation process.However, how to prepare a high-quality BT dataset for training a BTGen model has received limited attention.Challenge 3: How to develop a training pipeline for the BT generation?Moreover, optimizing the interaction between foundation LLMs and data quality is important for enhancing the ability of AI systems [37,38].This balance between model complexity and data quality acts as a guiding principle to maximize the learning effects of the model on collected BT datasets.A good training pipeline that effectively aligns the BT generation with LLM original abilities is needed.</p>
<p>Second, the BTGen model needs to be employed in realworld scenarios and address practical challenges.The BT-Gen model still struggles with a series of problems, such as hallucination, data bias, lack of domain knowledge, and explanation after the training process.The next challenge is Challenge 4: How to develop the BTGen model in realworld scenarios?A good development pipeline tailored to BT generation integrates advanced strategies, such as prompts and agents, to address and attenuate these prevalent challenges inherent in LLMs, paving the way to generate BTs with a higher degree of sophistication and operational reliability.</p>
<p>Lastly, measuring the effectiveness of the BTGen model after training and developing is crucial.Thus, the last challenge is Challenge 5: How to verify and validate the BT-Gen model?Many researches have reported that LLMs cannot generate correct outcomes when faced with complex tasks.Thus, an effective V&amp;V pipeline is imperative for the BT generation.By instituting rigorous evaluation protocols and testing methodologies, the V&amp;V pipeline can guarantee that the BTs not only operate effectively within their intended operational parameters but also conform to stringent quality standards.Consequently, the incorporation of a comprehensive V&amp;V pipeline thus serves as a cornerstone for the utilization of BTGen model in producing dependable BTs.</p>
<p>In this paper, we explore the use of LLMs to enhance the BT generation and offer insights and perspectives on overcoming the aforementioned challenges.The main structure of our paper is shown in Figure 1, including the training phase, developing phase, and verification and validation phase.Specifically, the training phase is further divided into foundation LLM selection, BT dataset collection, and the training pipeline.We introduce each component that addresses the above-summarized challenges in each section in detail.</p>
<p>Foundation Model</p>
<p>Foundation Models</p>
<p>A foundation model is a model that is trained on broad data (generally using self-supervision at scale) and can be adapted (e.g., fine-tuned) to a wide range of downstream tasks [39].These models are based on deep neural networks and self-supervised learning, both of which have existed for decades.However, the recent scale and scope of foundation models have pushed the boundaries of what is possible.Foundation models are typically huge, with billions or even trillions of parameters, which allows them to learn complex language patterns and perform tasks that would be difficult or impossible for smaller models.In recent years, several foundation LLMs have been proposed by different organizations, each with its own characteristics.We briefly summarize and introduce three representative foundation LLMs: GPT-series, LLaMA-series, and GLM-series.</p>
<p>GPT-Series: The GPT (Generative Pre-trained Transformer) series of LLMs developed by OpenAI 1 has undergone significant development over the years.The family of GPT-series models is briefly shown in Figure 3.The first two initial models are GPT-1 [40] and GPT-2 [41], which can be considered as the foundation for more powerful models subsequently, such as GPT-3 [42] and GPT-4 [29].GPT-1 was introduced in June 2018 and developed based on a generative, decoder-only Transformer architecture with 117 million parameters.It adopts a hybrid approach of unsupervised pretraining and supervised fine-tuning.GPT-1 [40] set up the core architecture for the GPT-series models and established the underlying principle of modeling natural language text, i.e., predicting the next word.GPT-2 was introduced in February 2019 and increased the parameter scale to 1.5B, trained with a large webpage dataset.As claimed in the paper of GPT-2 [41], it seeks to perform tasks via unsupervised language modeling, without explicit fine-tuning using labeled data.Based on GPT-2, GPT-3 [42] released 1 https://openai.com/in 2020 demonstrated a significant capacity leap by scaling the generative pre-training architecture to an even larger size of 175B parameters.GPT-3 can be viewed as a remarkable landmark in the journey from PLMs to LLMs.It empirically proved that scaling the neural networks to a significant size can lead to a huge increase in model capacity.The conversation model ChatGPT2 was released by Ope-nAI in November 2022, based on the GPT models (GPT-3.5 and GPT-4).ChatGPT exhibits superior capacities in communicating with humans, possessing a vast store of knowledge, skill at reasoning on mathematical problems, accurately tracing the context in multi-turn dialogues, and aligning well with human values for safe use.GPT-4 [29], released in March 2023, extends the text input to multimodal signals with more parameters.Overall, GPT-4 has stronger capacities in solving complex tasks than all former GPTseries models, showing a large performance improvement on many evaluation tasks.</p>
<p>LLaMA-Series: LLaMA (LLM Meta AI) [30] is a family of LLMs released by Meta AI starting in February 2023.LLaMA foundational models are trained on a dataset with 1.4 trillion tokens, drawn from publicly available data sources.Four model sizes were trained: 7, 13, 33, and 65 billion parameters.LLaMA uses the transformer architecture with minor architectural differences.Compared to GPT-3, LLaMA uses the SwiGLU [43] activation function instead of ReLU, rotary positional embeddings [44] instead of absolute positional embedding, and root-mean-squared layer-normalization instead of standard layer-normalization.LLaMA 2 [45] is trained on a dataset with 2 trillion tokens and increases the context length from 2K tokens to 4K tokens.Three model sizes, 7, 13, and 70 billion parameters, are released.LLaMA 2-Chat is additionally fine-tuned on 27,540 prompt-response pairs created for this project, which performs better than larger but lowerquality third-party datasets.For AI alignment, reinforcement learning with human feedback (RLHF) is used with a combination of 1,418,091 Meta examples and seven smaller datasets.</p>
<p>GLM-Series: GLM (General Language Model) [34] Figure 2. A brief illustration for the evolution of GPT-series models [33].</p>
<p>is pretrained with an autoregressive blank-filling objective.</p>
<p>It randomly blanks out continuous spans of tokens from the input text, following the idea of auto-encoding, and is trained to sequentially reconstruct the spans, following the idea of autoregressive pertaining.ChatGLM-6B is a conversational language model that supports bilingual questionanswering in Chinese and English.ChatGLM-6B adopts the same model architecture as GLM-130B.As of July 2022, GLM-130B [46] has only been trained on 400 billion tokens with a 1:1 ratio of Chinese to English.In contrast, ChatGLM-6B utilizes a larger training dataset with up to 1 trillion tokens, consisting solely of Chinese and English text in a 1:1 ratio.These foundation models exhibit strong capacities in the area of natural language after being trained on large unlabeled corpus datasets.However, the BT generation tasks are more complex compared to text generation.As foundation LLMs, certain basic abilities are needed for BT generation tasks.We categorize the basic abilities of foundation LLMs for BT generation into four principal domains: natural language-related abilities, reasoning-related abilities, tool-related abilities, and code-related abilities, as shown in Table 3.</p>
<p>Natural-Language-Related Abilities</p>
<p>Natural language-related abilities are the core abilities of human linguistic competence.These abilities include natural language understanding, natural language generation, in-context learning, and instruction following.Natural language understanding refers to the ability to understand natural language text and extract useful information for downstream tasks.Common tasks in natural language understanding include sentiment analysis, text classification, natural language inference, and semantic understanding.Natural language generation evaluates the capabilities of LLMs in generating specific texts, including tasks such as summarization, dialogue generation, machine translation, question answering, and other open-ended generation tasks.In-context learning (ICL) is a paradigm that al-lows language models to learn tasks given only a few examples in the form of demonstrations [42].With ICL, the pre-training and utilization of LLMs converge to the same language modeling paradigm: pre-training predicts the following text sequence conditioned on the context, while ICL predicts the correct task solution, which can also be formatted as a text sequence, given the task description and demonstrations.Instruction following enables LLMs to understand and carry out instructions or commands accurately and effectively.With instruction following, LLMs can align with the intentions of humans, follow task instructions for new tasks without using explicit examples, and improve their generalization ability.</p>
<p>Related to BT Generation: These natural languagerelated abilities play a crucial role in the BT generation as they enable LLMs to understand the task description, environmental information, and the desired objective states.Under prompts involving a few examples in similar scenarios and specific instructions, the models can effectively comprehend and interpret the provided instructions, ensuring a clear understanding of the task requirements.Moreover, these abilities empower the models to generate humanreadable and explainable actions, allowing for transparent and interpretable decision-making processes.This not only enhances the model's overall performance but also promotes trust and understanding between the model and its users.</p>
<p>Reasoning-Related Abilities</p>
<p>Complex reasoning encompasses the capacity to comprehend and effectively employ supporting evidence and logical frameworks to deduce conclusions or facilitate decision-making.By analyzing the reasoning abilities required for BT generation, we believe that the three most crucial reasoning abilities currently needed for BT generation are commonsense reasoning, logical reasoning, and planning.Commonsense reasoning is a fundamental ingredient of human cognition, encompassing the capacity to comprehend the world and make decisions.This cognitive Understand the meaning of actions, entities, and intentions of the BT generation tasks.</p>
<p>Natural language generation Generate human-readable texts.Achieve better human-computer interaction and return natural language texts to explain the process in the BT generation for humans.</p>
<p>In-context learning Learn and perform new tasks by observing a few examples.</p>
<p>Learn novel knowledge from fewshots demonstrations, especially in unseen scenarios of the BT generation tasks.</p>
<p>Instruction following Understand and carry out instructions or commands accurately and effectively.</p>
<p>Align with the human intentions in the BT generation.</p>
<p>Reasoning-Related</p>
<p>Commonsense reasoning Understand and use general knowledge that is common to the most people in their daily lives.</p>
<p>Make reasonable assumptions and inferences in the absence of specific information.</p>
<p>Logical reasoning</p>
<p>Using logical principles and rules to arrive at valid conclusions or make sound judgment.</p>
<p>Understand and make the transition of actions and states in BTs.</p>
<p>Planning</p>
<p>Decompose a potentially complex task into subtasks.</p>
<p>Decompose the complex BT generation tasks into several simple subtasks that are easy for LLMs to implement.</p>
<p>Tool-Related</p>
<p>Retrieval Enable AI to find the proper knowledge from database based on the given query conditions.</p>
<p>Find corresponding tools or knowledge for BT generation tasks.</p>
<p>Tool manipulation</p>
<p>Enable AI to manipulate the existing tools to get the desired outputs.</p>
<p>Use specialized tools, such as the node libraries and visual detectors for BT generation tasks.</p>
<p>Code-Related</p>
<p>Code generation Generating program codes.Generate the BT codes that are executable and meet the requirements of users.</p>
<p>Code explanation</p>
<p>Return the concrete meanings of the code program.</p>
<p>Explain the BT codes in natural languages for humans.</p>
<p>Code translation</p>
<p>Translate the codes from one language to other language.</p>
<p>Translate BT codes between different code languages for different goals.</p>
<p>ability plays a pivotal role in developing natural language processing systems capable of making situational presumptions and generating human-like language.Logical reasoning is the ability to examine, analyze, and critically evaluate arguments as they occur, holding significant importance in understanding.The chain of thoughts (CoT) [47] is a well-known logical reasoning technique that solves problems or accomplishes tasks through a series of intermediate steps and logical operations.With the CoT prompting strategy, LLMs can solve many tasks by utilizing the prompting mechanism that involves intermediate reasoning steps for deriving the final answer.Planning decomposes a potentially complex task into simpler subtasks that the LLM can solve more easily by itself or using tools according to [48].</p>
<p>Planning involves developing a course of actions (policy) to execute tasks, which takes the agent to a desired state of the world.</p>
<p>Related to BT Generation: These three capabilities synergistically combine and collaborate in the intricate process of the BT generation based on LLMs.Commonsense reasoning serves as the foundation, allowing the model to grasp the task context and apply contextual knowledge to its decision-making.Logical reasoning ensures the coherence and rationality of the reasoning process, enabling the model to make sound judgments and logical connections between different components of BTs.Planning facilitates the effective execution of the task by devising efficient strategies to accomplish the desired objectives.Therefore, LLMs equipped with these capabilities possess a profound understanding of the task at hand, ensuring the generation of complex BTs.</p>
<p>Tool-Related Abilities</p>
<p>Tool-related abilities refer to the capabilities of foundation models to manipulate tools, leading to more potent and streamlined solutions for real-world tasks.These abilities enable LLMs to interact with the real world, such as manipulating search engines [49], shopping on e-commerce websites [50], planning in robotic tasks [51,52].We summarize the tool-related abilities into retrieval and tool manipulation.Retrieval refers to the model's ability to efficiently and accurately retrieve query-related information from a knowledge library.This includes retrieving relevant tools, domain knowledge, and other pertinent information based on the given query conditions.The model should be capable of effectively searching and retrieving the most relevant and useful information to assist in addressing the query or task at hand.Tool manipulation refers to the ability of LLMs to utilize various tools or software to perform specific tasks.It enhances and expands the performance of models, leading to more potent and streamlined solutions for real-world tasks, bridging the gap between its language generation capabilities and practical scenarios.</p>
<p>Related to BT Generation: The tool-related abilities are crucial for complex BT generation tasks as they allow leveraging the functionalities and expertise of existing tools and knowledge.Given the complexity and domain-specific nature of the BT generation tasks, utilizing domain-specific tools simplifies the process and significantly enhances the quality of BTs.These tools offer specialized functionalities like visual editors, code analysis, and debugging, greatly assisting in creating and validating the BT generation.By integrating with these tools, LLMs can generate effective BTs while leveraging domain-specific knowledge.</p>
<p>Code-Related Abilities</p>
<p>Code-related abilities play a key role in ensuring the correctness and executability of BTs.We summarize three main abilities: code generation ability, code explanation ability, and code translation ability.Code generation ability is the core ability in the code-related category and aims to make LLMs automatically generate a program that satisfies a given natural language requirement.It requires LLMs to generate code snippets, complete functions, or even entire programs based on given prompts or specifications.To enable LLMs to acquire code generation ability, mainstream LLMs are trained on large code repositories from GitHub, competitive programming websites, and public benchmarks.They can be trained from scratch or based on existing LLMs.CodeGen [53], StarCoder [35], and CodeGeeX [36] are representative works that are trained from scratch based on a decoder-only transformer architecture.They are pre-trained in an autoregressive manner on a large corpus of code, resulting in significant training costs.In contrast, some works perform incremental training based on existing LLMs to obtain code generation capabilities.Codex [54] is incrementally trained based on GPT-3, and Code LLaMA [55] is incrementally trained on LLaMA-2.</p>
<p>Code explanation ability refers to describing and clarifying</p>
<p>what a piece of code does, how it works, its purpose, and its logic in a human-understandable way.The goal of code explanation is to make the code maintainable and understandable for anyone who might read it in the future, including the original author.Code translation ability refers to converting code written in one programming language into another programming language while preserving the original program's functionality and logic under different requirements.Translating code often requires significant refinement and testing to ensure it behaves as intended and follows the conventions of the target language.</p>
<p>Related to BT Generation: Since BTs are represented in the form of code, the code-related abilities play a pivotal role in the BT generation tasks, ensuring the generation of executable and human-desired codes.These abilities facilitate the translation of abstract instructions into actionable code that can be readily executed by agents or systems, explain the codes for developers in natural language, and enhance the transparency and interpretability of the generated BTs.</p>
<p>BT Dataset Collection</p>
<p>As highlighted in Section 2, the role of data is pivotal in the development of proficient LLMs.In the context of generating BTs, a high-quality dataset is integral to enhancing both the efficiency and performance of the BT generation process.</p>
<p>Dataset Composition</p>
<p>We commence by outlining the structure and format of the dataset required for training our LLM-based BT generation.Given that our approach leverages the capabilities of LLMs, it is essential to incorporate both structured and natural language elements within each data entry.We propose a novel dataset schema tailored for BT generation, encompassing five key components: Name, Description, XML Representation, Nodes Metadata, and Implementations.</p>
<p>• Name: This field specifies the identifier of the BT, which is meaningful in both a domain-specific and a natural language context.For instance, the name could reflect the type of robotic platform or the intended objective of the BT.</p>
<p>• Description: A comprehensive description of the BT's purpose is provided here, detailing aspects such as the robotic platform it is designed for, the task it aims to achieve, and any relevant environmental considerations.</p>
<p>• XML Representation: An XML-formatted representation encapsulates the structural and node-specific details of the BT, facilitating both human readability and machine parsability.</p>
<p>• Nodes Metadata: This part elucidates the functionality and operational logic of individual nodes within the tree, encompassing their respective names and roles.</p>
<p>• Implementations: This section delineates the concrete code implementations for the behavior encapsulated by each node, promoting an understanding of the practical application of the tree's logic.</p>
<p>To elucidate the proposed data format, we present an illustrative example in Table 2.</p>
<p>Synthetic Data Generation</p>
<p>The utilization of LLMs typically necessitates the availability of vast amounts of data.In many cases, such datasets are derived from human-generated sources, which present several challenges: they can be costly to gather [56], are often difficult to obtain [57], may suffer from limitations in scope and diversity [58], or, in some instances, are simply not available [59,60].Within the domain of BT generation, these issues are exacerbated due to the dearth of BT-specific datasets, which tend to be scattered across various platforms such as paper-based prototypes, gaming environments, and robotic applications.The scarcity of BT data hinders the effective training or fine-tuning of LLMs.</p>
<p>Yet, recent advancements have shown that synthetic data, generated by models themselves, can yield performance on par with, if not superior to, that of human-generated counterparts [61].Synthetic data provides a viable solution to circumvent the limitations posed by human-generated datasets, enhancing sample efficiency [56], mitigating the shortage of training data, and reducing the cost associated with data collection.Therefore, the automatic construction of high-quality synthetic datasets emerges as an effective strategy to quickly expand the volume of available training data.Our focus will be on delineating the methodologies for generating synthetic data pertinent to BTs.</p>
<p>Approaches to data synthesis can generally be classified into two categories: those based on domain information and those leveraging LLMs.Domain-based methods may utilize features inherent to the data, exploit domainspecific knowledge [62], or employ domain-centric tools [63].On the other hand, LLM-based synthesis capitalizes on the ability of LLMs to generate contextually relevant content through specific instructions [64].</p>
<p>Learning-Based Methods</p>
<p>Learning-based methods for BT generation demonstrate superior adaptability by effectively representing strategic behaviors within BT structures [24].These methods leverage large amounts of data to learn behavior patterns and strategies, enabling agents to adapt more effectively across diverse tasks and environments.By automatically discovering and capturing strategic behaviors, learning methods empower agents to make adaptive decisions in complex environments.Furthermore, through iterative training, these methods can refine the generated BTs based on its actual effectiveness, ensuring better alignment with desired goals and requirements.Notable examples of these methods include RL-based approaches [24,25], evolution-based techniques [65,66], and demonstration-based methods [8,67].</p>
<p>RL-Based BT Generation.Reinforcement learning (RL) has proven effective in the generation of BTs.The process entails defining state and action spaces, creating reward functions [25], establishing RL models [27], and determining appropriate representations for BTs [24].Notably, RL has demonstrated its capability to learn both the structure and parameters of BTs, making them applicable in dynamic settings [68].Moreover, hierarchical RL techniques have been employed to decompose tasks into subtasks, each with its localized strategy [69].</p>
<p>Evolution-based BT Generation.Evolution-based methods, centered around the genetic algorithm, play a crucial role in BT generation.These methods emulate biological evolution by employing selection, crossover, and mutation processes to optimize BTs based on fitness evaluation outcomes [70].In practical implementation, populations are initialized, renewed, and termination criteria are established [65].Genetic programming is one approach used for BT generation, which involves defining encoding methods [66].Another approach is grammar evolution, where grammatical rules are specified to constrain the search space of evolutionary algorithms, simplifying problem-solving [71]. .Genetic programming has proven effective in handling highly uncertain environments during BT generation [72], while grammar evolution aids in constraining the search space and streamlining the evolutionary process [73].</p>
<p>Demonstration-Based BT Generation.Learning from demonstrations allows the acquisition of complex, multistep tasks through observation of expert-provided examples [8].Such a method captures the decision-making pathways and rule sets within these demonstrations, extracting the underlying structures and regulations to form BTs. This approach has enabled the generation of BTs by observing human behaviors [74] and has led to the development of semi-automatic optimization methods for adjusting expertconstructed BTs [67].</p>
<p>Planning-Based Methods</p>
<p>Planning-based methods offer an intuitive and interpretable framework for BT generation.These methods are grounded in the principles of automated planning and have been explored extensively in the literature [21,22,23,13].</p>
<p>Colledanchise et al. introduced a novel reactive planning</p>
<p>Name</p>
<p>UAV Patrol Campsite Desc.</p>
<p>The tree describes the UAV patrolling based on a predetermined route.If a suspicious target is detected, the UAV will warn the target, otherwise, the UAV will move to the next location in the route.algorithm that facilitates the automatic generation and dynamic updating of BTs, effectively integrating the modular and reactive nature of BTs with the systematic synthesis process of automated planning [13].We categorize planning-based methods into three distinct types: logicbased, hierarchical, and active planning methods.</p>
<p>Logic-Based Method Approaches such as linear temporal logic (LTL) have been utilized to synthesize BTs [21,22], providing a formal mechanism to define complex behaviors.For instance, [75] employs decision tree learning combined with logical decomposition techniques to generate BTs from execution traces of previously manually designed plans.Additionally, a top-down divide-and-conquer strategy is proposed in [76], which simplifies complex F-LTL formulas into manageable sub-formulas that facilitate the automatic BT generation.</p>
<p>Hierarchical Method Hierarchical methods utilize task networks to structure BTs.A state space representation can be incorporated to ensure the soundness and completeness of BTs, enabling robots to handle all solvable external disturbances [77].[78] integrates hierarchical planning to construct BTs systematically.Coordination among intelligent vehicles is achieved using a hierarchical auction algorithm in [79], while state-aware hierarchical BTs are developed to support post-action decision-making, preferences, and local priorities within robotic applications [80].Francesco et al. advocated for the use of hierarchical task networks optimized for execution time efficacy in BT creation [23].</p>
<p>Active Planning Methods Active planning methods merge environmental perception with planning capabilities to address the dynamics of action execution contexts.A method incorporating both environmental awareness and planning to infer context and automatically generate BTs is presented in [81].Hybrid active planning, which allows BTs to dynamically adjust in response to environmental changes, is discussed in [82].Further, active reasoning is leveraged in [83] through the introduction of new leaf node types that specify desired states and determine actions online to achieve those states.Finally, strategies for generating BTs in partially observable environments, aimed at mitigating uncertainty within conditional nodes, are explored in [84].</p>
<p>Nevertheless, it is imperative to acknowledge the inherent limitations of planning-based methods.Their dependency on pre-defined knowledge constrains their ability to adapt to unforeseen circumstances or environments where explicit rules may not exist.This reliance on existing domain knowledge poses challenges when encountering novel scenarios, necessitating further research to enhance the robustness and generality of BT generation in dynamic and unpredictable settings.</p>
<p>LLM-Based Methods</p>
<p>The advent of large language models has catalyzed innovative approaches in BT generation by harnessing the generative and semantic comprehension capabilities of such models.The advanced linguistic processing prowess of LLMs facilitates the crafting of detailed descriptions and definitions, thereby enabling the generation of high-quality BTs from task narratives or constraints.This method encompasses various stages including task description completion, task decomposition, node selection, BT structuring, preliminary BT validation, and iterative BT refinement.</p>
<p>Among the notable applications, [85] encodes a BT into a numerical vector while preserving both the semantic content of task descriptions and the structural intricacies of hierarchical task arrangements through pre-trained language embeddings and node aggregation mechanisms.In another study, [31] introduces an embedding methodology for BTs that accepts as input a BT associated with individual tasks and outputs the corresponding numerical representation.</p>
<p>Alternative Methods</p>
<p>In the paper by Gonzalo Florez-Puga [86], Case-based Reasoning (CBR) is employed to facilitate the retrieval and adaptation of existing BTs, allowing for the reuse of previously developed BTs.This approach enhances efficiency and promotes knowledge transfer.El-Ariss [87] proposes a novel extension to traditional BTs that enables them to recall and utilize information from previously executed subtrees, leveraging historical context to make informed decisions.This enhancement improves the sophistication and reusability of BTs, enabling them to adapt and improve based on past experiences.Umeyama [88] constructs an action node graph using geospatial data, which is then automatically converted into a nuanced BT, enhancing its capabilities and effectiveness for context-aware decision making.Scheide [89] formalizes the search space for BTs as a grammar, allowing the BT structure to be derived through exploration using the Monte Carlo tree search algorithm.This formalization provides a systematic and efficient approach to generating BTs, improving the overall effectiveness of the generation process.Lastly, Gao [90] introduces a three-phase BT generation algorithm that includes construction, simulation, and online re-planning, enabling the generation of adaptive BTs that can dynamically adjust their behavior based on the current situation, enhancing their flexibility and robustness.</p>
<p>Node Library</p>
<p>The Node Library is pivotal for assuring that the execution of BTs fulfills its purpose effectively and translates abstract task directives into operational code.This library is a cornerstone in refining task descriptions and furnishing leaf nodes that are both adaptable to various software and hardware environments and designed with scalability in mind.</p>
<p>To bolster data synthesis, it is essential to curate a Node Library that offers a repository of reusable node types crucial for the assembly of BT data.The library's design emphasizes ease of use and modularity, enabling straightforward adoption and extension of nodes to suit a variety of developmental needs.Moreover, by modularizing the development workflow, the Node Library streamlines the design process, leading to improved productivity.</p>
<p>Within the context of BTs, nodes are generally partitioned into control nodes, which govern the BT's execution flow, and leaf nodes, which enact precise condition assessments and action implementation.Specifically: Control Nodes dictate the logical structure and sequencing within the BT.Leaf Nodes include Condition Nodes and Action Nodes.Condition Nodes that appraise logical states and navigate the BT along different branches based on those evaluations.Action Nodes that initiate distinct operations capable of altering environmental states.</p>
<p>The symbiosis of condition nodes and action nodes under the auspices of control nodes allows BTs to adapt to and make informed decisions in response to environmental contingencies, thus achieving sophisticated behavioral patterns.Our Node Library's primary aim is to facilitate robust implementations of these leaf nodes.</p>
<p>For each node, the following attributes are meticulously curated:</p>
<p>• Type: A dichotomy encompassing condition nodes and action nodes typifies node classification.</p>
<p>• Name: Descriptive naming conventions enhance the readability and accessibility of the node library, fostering user-friendly interaction.</p>
<p>• Description(Desc.):An elaborate exposition of the node's function delineates its objectives, behaviors, parameters (both input and output), and its contextual role within the BT framework.Clarity in function description is instrumental for developers and LLMs alike, ensuring appropriate node deployment in BT generation.</p>
<p>• Implementation (Impl.):This constitutes the node's operational codebase, which includes simulation verification scripts and real-world operational code.Rigorous testing in simulated environments precedes deployment, validating the node's efficacy in fulfilling intended tasks and confirming its practical problemsolving capabilities in authentic settings.</p>
<p>Our Method for Data Generation</p>
<p>Despite LLMs demonstrating significant promise in BT generation, their application to domain adaptation is still an emerging field.The integration of BTs with natural language directives to guide agents in learning and executing complex tasks is explored in [91], with potential extensions to novel contexts.</p>
<p>Hierarchical Generation with LLM Method Investigating automatic task generation based on BTs, [28] delineates a stage-step prompting technique tailored for hierarchically structured robot tasks.Sequentially Ordered Tasks (SOT) [92] pioneer a strategy whereby LLMs draft a skeletal framework for responses before conducting parallel API queries or collective decoding to flesh out each element of the skeleton simultaneously.</p>
<p>Reasoning with LLM Method Chain-of-Thought (COT) [47] empowers LLMs by articulating reasoning processes step-by-step, thereby augmenting the models' infer-ential capabilities.Expansion of Thoughts (XOT) [93] employs reinforcement learning coupled with Monte Carlo tree search methodologies to navigate thought processes, enriching LLMs with external domain expertise during problemsolving phases.</p>
<p>Constrained Selection with LLM Method [32] presents an autonomous robotic control approach predicated on an LLM fine-tuned from the Stanford Alpaca 7B architecture, specializing in generating robot BTs from textual descriptions using a predefined node library.</p>
<p>Retrieval with LLM Method In realms demanding specialized knowledge, database integration can elevate the expertise of LLMs.Introducing programmatic mapping layers bridges the gap between general-purpose and domainspecific vernaculars.</p>
<p>The emergence of LLMs has sparked new and innovative approaches in generating BTs by leveraging the generative and semantic comprehension capabilities of these models.The advanced linguistic processing capabilities of LLMs enable the creation of detailed descriptions and definitions, facilitating the generation of high-quality BTs from task narratives or constraints.This method involves several stages that collectively contribute to the generation process, such as task description completion, task decomposition, node selected, structure design, verification and verification, reflection, etc.</p>
<p>The proposed methodology involves synthesizing synthetic data through interaction with Large Language Models (LLMs), guided by carefully structured prompts.We prioritize the fine-tuning phase in this work but also acknowledge the potential of investigating pre-training strategies in future research.The crux of effective fine-tuning lies in the construction of question and answer pairs; however, existing datasets often present challenges such as being incomplete or having an imbalance between questions and answers.LLMs excel in filling these gaps by producing the missing elements-whether that involves generating questions from given answers or vice versa.Contemporary tactics for LLM-based synthetic data generation are predominantly categorized into two streams: example imitation and data-driven information extraction.</p>
<p>To generate synthetic BTs, we leverage methods such as self-instruct [94] and evol-instruct [95], which draw upon an extensive problem seed pool.These methodologies integrate the seed pool data with foundational prompts to create new problem instances.The quality and diversity of the seed pool substantially affect the caliber of the resulting queries.Our focus is on formulating robust inputs for tasksolving data, considering that solutions to certain problems are already accessible within established knowledge bases.Utilizing an LLM enables us to infer the corresponding problems grounded in these known solutions.A comprehensive seed data repository is constructed by analyzing the vast array of information from internet resources and literature.For complex problems, the decompositional ability of LLMs is employed to construct associated questions.Further, incorporating multi-input/multi-output schemas and meta-hint techniques facilitates the LLM in autonomously creating suggestive prompts that steer the synthetic data generation process.</p>
<p>Building upon these insights and identified enhancement opportunities, we propose a revised framework for BT generation tasks, formalized in the following updated Equation 3:
S 0 = f init (root), S t+1 = f M CT S (S t , f RAG (S t )),(3)
where f init signifies the initial setup function that creates the root of the tree, f M CT S denotes the enhanced planning function integrating Monte Carlo Tree Search, and f RAG represents the Retrieval-Augmented Generation mechanism.</p>
<p>Expanding on our analysis, we introduce the BT generation method and an agent-based framework for its implementation.As portrayed in Figure 3, the BT generation approach adopts a strategy patterned after the Monte Carlo Tree Search (MCTS), elucidating the progression of states throughout the process of BT generation.</p>
<p>In this schema, each BT is depicted as a state S t .Initiated with only a root node at S 0 , the BT generation algorithm iteratively develops S t into intermediate BTs that function yet may not entirely align with predefined objectives.The ultimate aim is to converge upon a final state S f inal , reflecting a BT proficient in executing the intended task accurately.</p>
<p>The transition between states is choreographed using an MCTS-like strategy, composed of four cardinal stages: Selection, Expansion, Validation, and Iterative Refinement, all tailored to accommodate the nuances of BT generation.</p>
<p>During the Selection phase, LLM-based strategies are utilized, especially those involving Retrieval-Augmented Generation (RAG) as previously mentioned.The 'Ops Library' contains a suite of actions that facilitate the transition from parent nodes to child nodes, including various decomposition operations like sequential and parallel constructs.Simultaneously, the Knowledge Base retains a catalog of actionable leaf nodes applicable in simulation or real-world environments.The result of the Selection phase encompasses custom operations and task-specific nodes, laying the groundwork for subsequent expansion prompts.</p>
<p>Following this, the Expansion phase engages LLMs to use the generated prompts to extend the structure of BT.This leads to the development of multiple sub-nodes, delineating the succeeding state.</p>
<p>Next, the Validation phase rigorously evaluates the newly formed BT S t+1 , determining the viability of this progression.Should the expansion adhere to the pre-set benchmarks, the state transformation proceeds; if not, feedback is harnessed to guide additional Selection and Expansion cycles-this recursive process embodies Iterative Refinement.</p>
<p>The process culminates when further decomposition of leaf nodes becomes untenable, signaling the creation of the final BT, denoted as S f inal .The performance of the BT generation methodology hinges on these methodical transformations, collectively ensuring the systematic assembly of a capable and efficient BT.</p>
<p>Training</p>
<p>LLMs exhibit substantial improvements when trained on extensive datasets rich in domain-specific language and terminologies.Such targeted training enhances their capabilities in specialized applications that necessitate robust natural language understanding, including interaction with computing systems through tasks like program synthesis, code completion, debugging, and documentation generation.</p>
<p>In our BT generation method, as we analyzed, require various LLM abilities which are the most advanced usage of LLM, such as planning, reasoning, tool manipulation abili-ties, etc.Some maybe meet our task requirements after being pretrained but it is various on the different LLM model.And Some abilities can not meet our requirements.So to make LLM model more useble, the training is necessary.The quality of data is paramount for effective training and ethical development of LLMs, a principle equally relevant to the context of BT generation.Typically, these models leverage diverse and publicly accessible open-source data during their initial training phase.</p>
<p>In this section, we will delineate the pretraining and Supervised Fine-Tuning (SFT) stages within the LLM training pipeline.</p>
<p>Pretraining</p>
<p>The pretraining of LLMs is conventionally initiated using a broad dataset.However, to refine and elevate the linguistic capabilities of an existing model, additional pretraining is employed, targeting domain-specific data that may have been underrepresented during the initial training corpus compilation.</p>
<p>This pretraining phase is designed to bolster the model's comprehension by introducing it to more focused data sets that encapsulate the idiosyncrasies and jargon intrinsic to the tasks for which the model is being primed.The construction of this domain-oriented data for our BT generation task has been elaborated in the preceding section.Similar to the original pretraining, this phase engages unsupervised or self-supervised learning strategies but narrows down the data spectrum to align with specific domains.For example, Masked Language Modeling (MLM) techniques are reutilized, prompting the model to infer masked segments of text, thus honing its grasp on the subtleties of specialized lexicons.</p>
<p>Although a substantial portion of the model's parameters was established during primary pretraining, the additional pretraining introduces refinements through the assimilation of novel datasets.The quintessential goal remains consistent: to reduce predictive inaccuracies and enable the model to adjust its extensive knowledge base to resonate more precisely with targeted fields of application.This augmented pretraining stage is particularly vital when the intended applications possess linguistic features that are markedly different from those prevalent in the original pretraining data.By ensuring that the model enters the finetuning phase already attuned to the nuances of the tasks, this step substantially augments the efficiency of Supervised Fine-Tuning (SFT) and the overall performance of the LLM within domain-specific contexts.</p>
<p>The execution of this pretraining segment presents significant challenges, rooted not only in the arduous task of acquiring pertinent BT-related data but also in the intricate details of the training process that are critical for optimal performance.While some foundational work [55] has il-luminated aspects of these complexities, extensive empirical practice remains indispensable.Despite its inherent difficulties, this preparatory phase is essential, setting the groundwork for effective task-specific LLM applications.</p>
<p>Supervised Fine-Tuning (SFT)</p>
<p>In scrutinizing the training dynamics of foundation models such as Code LLaMa [55], the predominant emphasis has been placed on refining the underlying base model.This focus underscores a belief that foundational enhancements are instrumental for long-term performance gains, relegating changes in inference mechanisms to a secondary role.However, the examination of intricate inference methodologies constitutes a compelling frontier in the research landscape.Initiatives in this domain have introduced the integration of structural programming insights into training objectives.For instance, bespoke objectives dedicated to code deobfuscation have been formulated [96], along with the application of contrastive learning using semantically invariant transformations of code [97], and the adoption of Abstract Syntax Trees to impart tree-aware positional encodings [98].</p>
<p>An expanding area of research contemplates the utility of program execution or unit tests for enhancing the evaluation and reinforcement of program correctness, particularly when the pool of solutions is limited [99,100,101,102].In parallel, other studies have woven unit tests into the tapestry of reinforcement learning, thereby magnifying the training signal [102,103].</p>
<p>Fine-tuning represents the process by which a model's broad capabilities, honed during pretraining, are tailored to meet the specific demands of a target task or domain, leading to substantial gains in targeted application efficacy.As its name implies, supervised fine-tuning leverages supervised learning techniques, relying on labeled datasets that map inputs to their respective target outputs.This correlation enables the model to adjust its parameters with precision, optimizing it for the task at hand.For SFT in our BT generation task, the data corpus exclusively comprises taskspecific input-output pairs.Data collection spans multiple formats, each designed to engage different required abilities.The aim of this fine-tuning phase is to train the LLM to interpret user prompts and generate appropriate outputs across various formats such as Code, XML, or constrained languages.</p>
<p>Recent advancements in fine-tuning techniques have yielded methodologies like P-tuning, LoRA, and QLoRA, each offering unique contributions to the customization of models for particular tasks.P-tuning [104] introduces prompt tuning as a method of soft prompt engineering, where continuous vectors (prompts) are optimized to guide the model's predictions without altering the model's parameters.LoRA [105], which stands for low-rank adaptation, modifies the attention mechanism by introducing low-rank matrices to adapt the model's behavior while maintaining most of the pre-trained parameters intact.QLoRA [106] takes this concept further by quantizing the low-rank matrices, reducing memory footprint and computational overhead even more significantly.In practice, LoRA and QLoRA are the methods that can easy to train and deploy, yet keep the good performance of the LLM model.In practice, training packages such as Deepspeed3 provide useful and easy-to-setup tools to support the achievement of SFT.These packages utilize optimizations to make the training process fast, reliable and distributed.</p>
<p>These fine-tuning approaches enhance model specificity, outperforming their corresponding generic pretrained variants on specialized tasks.While the computational resources required for fine-tuning are considerable, they are generally less intense than those needed for comprehensive pretraining, given the head start provided by an existing pretrained model foundation.</p>
<p>Developing</p>
<p>After thorough training and extensive testing to confirm that the BTGen Model satisfies our stringent capability criteria, we are now poised to outline the proposed approaches for generating BTs.These strategies capitalize on the LLM's robust features for effective deployment and real-world application.</p>
<p>We propose a BT generation application method based on LLMs.This method requires carefully crafted prompts to ensure that the LLM's responses align with specified criteria.To tackle the issues of hallucination and out-ofdomain knowledge, we employ an agent-based framework that incorporates elements of memory, planning, action, and multi-agent interactions.This framework is specifically designed to manage the complexities involved in creating BTs and harnesses the strengths of LLMs to simulate real-world scenarios that robots might encounter.</p>
<p>Prompting</p>
<p>LLMs have evolved as instrumental assets across a plethora of Natural Language Processing applications, markedly when guided through judiciously crafted prompts. 4The art of prompt engineering-meticulous and strategic development of prompts-is paramount, as it involves a nuanced selection of language that steers the LLM toward producing relevant and articulate outputs.This aspect becomes even more critical within the realm of BT generation for robotics, where proficient prompting directly influences the creation of effective BTs.</p>
<p>There exists an array of methodologies for devising prompts, with notable approaches being Zero-shot Prompting, Few-shot Prompting, Chain-of-Thought Prompting, and Prompts Optimization.</p>
<p>Zero-shot Prompting: Zero-shot prompting introduces a novel task to the language model without furnishing any preceding examples.Within the domain of BT Generation, zero-shot prompts must be succinct yet comprehensive, capturing an explicit representation of the required behavior, which includes delineating the problem at hand, the operative regulations, and the envisioned final state.An exemplary zero-shot prompt may declare, Design a BT for an autonomous robot tasked with prioritizing kitchen cleanliness whilst optimizing energy consumption.In this scenario, the model leverages its preexisting knowledge to compose a viable BT without reliance on extraneous exemplars.</p>
<p>Few-shot Prompting: Advancing from zero-shot techniques, few-shot prompting equips LLMs with a handful of instances.These precedents, proven effective in the domain of coding tasks [55], embody the target output structure or schema prior to soliciting the generation of novel content.For BT Generation, providing the system with rudimentary examples of BTs or schematics of antecedent tasks can bolster its adeptness in fabricating precise and contextually suitable BTs.Moreover, few-shot prompting can alleviate uncertainties inherent in the initial prompt and construct a sturdier scaffolding for the model to replicate, culminating in outcomes that are more uniform and reliable.</p>
<p>Chain-of-Thought related Prompting: Advancements in LLMs have seen the emergence of novel prompting techniques that enhance their reasoning capabilities.A pivotal development is the Chain-of-Thought (CoT) prompting method introduced by Wei et al. [47].This technique encourages LLMs to articulate intermediate reasoning steps, which increases transparency and performance on complex tasks.Extending CoT's linear approach, Yao et al. proposed the Tree-of-Thoughts (ToT) framework [107], enabling LLMs to perform multi-trajectory decision-making, a boon for tasks requiring substantial exploration or intricate planning.The ToT's branching structure better reflects the nonlinear nature of such problem-solving scenarios.Complementing this, Besta et al. introduced the Graph-of-Thoughts (GoT) strategy [108], which organizes knowledge into a graph where nodes symbolize discrete information units interconnected by edges representing their relationships.This graph-based method encapsulates human cognitive complexity, offering an approach for its emulation within LLMs.To facilitate rapid decisionmaking, Ning et al. developed the Skeleton-of-Thought (SoT) technique [92], priming the generative process with broad strokes before detailing specifics.This hierarchical technique not only accelerates the response time of LLMs but also yields more diverse and pertinent outcomes.In coding, Li et al. introduced the Structured-CoT (SCoT) [109] and the Chain-of-Code (CoC) [110] methodologies.SCoT uses structured patterns inherent in source code to guide LLMs, enhancing code generation accuracy.CoC integrates natural language, pseudocode, and executable code, featuring an LMulator, a dual-mode execution system combining traditional interpreters with a language model-based emulator, to maintain program state continuity even when code is non-executable.These Chain-of-Thought methods aim to enable LLMs to comprehend complex tasks not directly solvable from inputs and stored knowledge, and to decompose them into manageable sub-steps.They employ specialized designs prompt LLMs to think sequentially (CoT), from coarse-to-fine (SCoT), or from codeto-solution (CoC), simulating human-like problem-solving.Representing a shift towards more organized and sophisticated reasoning, these methods allow LLMs to address problems with increased cognitive fidelity.</p>
<p>Prompts Optimization: The design of prompts significantly affects the quality of generated BTs.It is crucial to check how the prompts affect the quality of outputs.Studies have found that the selection of demonstrations included in prompts significantly impacts accuracy across most tasks [111,112,113].Lu [114] thinks that altering the ordering of a fixed set of demonstrations can affect downstream accuracy.Prompts sensitive to demonstration permutation often exhibit lower accuracies [115], making them less reliable, particularly in low-resource domains.InstructEval [116] is an in-context learning evaluation suite to conduct a thorough assessment of these techniques.Using the suite, In-structEval evaluates the relative performance of seven popular instruction selection methods over five metrics relevant to in-context learning.</p>
<p>For the BT Generation Task.To produce functional and organized BTs, it is essential to create prompts that accurately reflect the structural intricacies of BTs, which include both composite nodes (sequences, selectors, parallels) and leaf nodes (actions or conditions).A well-designed prompt should clearly outline the objectives of the agent, the environmental factors, and any behavioral constraints while incorporating domain-specific terminology and constructs.This ensures that the resulting BTs are specific and adhere to the norms of automated planning and artificial intelligence.Prompts Optimization drawing inspiration from recent works such as InstructEval, aim to optimize our designed prompts by testing them on existing LLMs.evaluate the prompts using accuracy and sensitivity metrics.Accuracy measures whether BTs run without compilation and achieve the desired functions, while sensitivity uses the standard deviation of accuracies obtained with varying selection or permutation of the demonstrations.The average scores of accuracy and sensitivity serve as the final performance indicators for the designed prompts.</p>
<p>BTs organize the execution of action nodes similarly to how lines of code are executed in programming, highlighting control flow and data exchange among nodes.Their hierarchical nature suits the sequential processes found in CoT methods, which decompose goals into smaller tasks, map out possible actions, and assess them against current conditions.To leverage CoT techniques in generating BTs, we advocate two main ideas: Utilizing Control Structures: Drawing from SCoT method, initially use a large language model to discern the control structure from an abstract task description.This forms the basis for creating a logical BT.By combining this structure with task context, the LLM can build a BT architecture that embodies a logical sequence of behaviors to achieve the robotic objectives.Aligning to Code Generation: Aligning with the CoC approach, synthesize the BT by first framing a solution in code format using an LLM.This facilitates effective problem interpretation and leads to the translation of the coded solution into a BT.This technique leverages the parallel between coding logic and BT structures, ensuring the generated BTs accurately represent the required action sequences and controls for autonomous robot operation.</p>
<p>Agent Technologies</p>
<p>One significant problem with LLMs is their production of hallucinated content-responses that appear coherent but are not factually accurate or relevant.This issue is particularly critical when LLMs are used to create BTs, which turn abstract commands into specific actions for robots, Unmanned Aerial Vehicles (UAVs), and other hardware systems.In such applications, the exactness and domainspecific knowledge are vital because any errors in transforming digital instructions into physical actions can cause malfunctions or inefficiency.</p>
<p>Agent technology leads the way in overcoming these challenges by being more than a collection of advanced methods-it's an integrated approach that improves the effectiveness of the entire system.Integrating LLMs within agent frameworks has enriched question-answering systems significantly, representing a crucial advance in artificial intelligence.To develop dynamic and adaptive autonomous agents that can operate and grow within intricate environments, it's important to design sophisticated architectures.</p>
<p>Recent strides in integrating LLMs with agent-centric frameworks provide compelling evidence of progress toward achieving artificial general intelligence across multiple domains.For instance, the Ghost in the Minecraft (GITM) project [117] showcases how Generally Capable Agents (GCAs) can skillfully complete complex tasks like the ObtainDiamond challenge in the open-world game Minecraft, leveraging text-based knowledge and mem-ory without heavy reliance on GPU-intensive training approaches.Concurrently, the Voyager initiative [118] presents an LLM-inspired embodied agent exhibiting continuous learning and autonomous skill acquisition, surpassing existing benchmarks in tasks such as item collection, exploration, and mastering technology progression.Moreover, the Plan4mc program [119] aims to overcome the inherent limitations of Reinforcement Learning (RL) in multitasking within expansive, procedural environments.By fusing skill-based reinforcement learning with strategic planning and intrinsic motivation, this approach fosters a diverse skill set and employs LLMs to craft a skill graph that streamlines task achievement.Additionally, Hugging-GPT [120] places LLMs at its core, orchestrating a consortium of specialized AI models emanating from communities like Hugging Face.This synergistic approach substantially enhances problem-solving capabilities across numerous domains and modalities using linguistic interfaces.</p>
<p>The contemporary trend in leveraging LLMs suggests a shift from merely solving tasks to engaging in elaborate planning and orchestration within complex scenarios.This new era of autonomous agent ability extends significantly beyond previous capabilities, supported by an advanced structure comprising four interrelated modules: The Memory Module serves as the cornerstone for future decisionmaking by storing past interactions, akin to human memory.It's responsible for handling immediate sensory information, sustaining long-term knowledge, and includes reading, writing, and reflective processes that aid in the agent's evolution.The Action Module integrates insights from other modules to generate concrete actions.It deals with intention setting, crafting action sequences, assessing possible actions, and reviewing outcomes, ensuring a coherent interaction between the agent and its environment through contemplation, execution, and evaluation phases.The Planning Module equips the agent with strategic problem-solving skills.Mirroring human reasoning by breaking down complex issues into more manageable components, it offers static and dynamic planning techniques, the latter adjusting in response to environmental changes to preserve adaptability.The Profile Module defines the agent's identity and role for specific applications, embodying various personas such as a coder or teacher.</p>
<p>Memory Module</p>
<p>In the field of robotics, creating BTs requires specialized knowledge and the ability to adjust to changing environments.While LLMs are good at forming complex patterns, their training on fixed datasets limits them.To enhance LLMs in developing BTs, we've tried using carefully crafted prompts.However, this method often fails with new, unpredictable situations that were not part of the original data.</p>
<p>To address this issue, we can integrate a Retrieval-Augmented Generation (RAG) system, similar to how human memory works.This combines LLM with a database, letting the model access fresh and relevant information beyond what it learned initially.This "memory" stores past interactions, guiding the robot's future behaviors and decisions.Like our memory turns sensory input into lasting knowledge, this integrated system enables continual learning and adapting through read, write, and reflect processes for novel experiences.</p>
<p>The field of BT generation stands on the cusp of transformation with emerging technologies such as Self Reflective Retrieval Augmented Generation (Self-RAG) [121], Thought Propagation (TP) [122], Sketch-based Automatic Code Generation (SkCoder) [123], and Automatic Multi-Step Reasoning and Tool-Use (ART) [124].Self-RAG enhances traditional LLM functionalities by integrating a selfevaluation tool, pivotal for refining dynamic, accurate, and context-aware BTs.In contrast, TP eliminates the need for extensive prompting by utilizing solutions from similar past issues, enriching the model's cognitive faculties for crafting more complex and applicable BTs.SkCoder employs an incremental approach familiar to human programmers, starting with basic code sketches and progressively enhancing them, aligning well with the iterative nature of developing BTs.Lastly, ART bolsters the model's problem-solving acumen by adding sequential reasoning and the use of external computational tools, enabling the construction of BTs that exceed the intrinsic limitations of the model itself.</p>
<p>The effects of RAG on LLMs are both beneficial and challenging.On the one hand, incorporating RAG into LLMs enhances their performance by utilizing up-to-date external knowledge, improving context understanding and response precision.This can lead to better outcomes than models without access to such data integration [125].However, using RAG introduces the risk of incorporating poorquality data from external sources, which can lead to incorrect outputs [126].Over-reliance on one data source may cause overfitting and reduce the model's ability to generalize.Careful validation methods are essential to ensure that newly integrated information maintains the accuracy of LLMs.</p>
<p>For the BT Generation Task.It is critical to establish a comprehensive and accurate knowledge base.The effectiveness of a large language model relies heavily on accessing precise information, as inaccuracies can lead to irrelevant or incorrect output, particularly when designing BTs.A well-curated knowledge base enables the LLM to produce contextually relevant and factually sound BTs.Incorporating the RAG approach into the generation pipeline is essential and involves two main aspects.Data Engineering: The success of a RAG system depends on the quality of domain-specific data available.For creating BTs for specific scenarios, it's vital to have an extensive set of relevant facts organized effectively.If this data isn't prepared carefully, the resulting BTs may lack contextual relevance and fail to support effective planning.Retrieval Methods: The retrieval process must ensure a close semantic match between the user's query and the knowledge base content.Semantic similarity metrics help find and extract information closely related to the query.The caliber of retrieved data significantly influences the LLM's performance in generating BTs.Poor retrieval could introduce irrelevant details, undermining the content's validity.Thus, sophisticated retrieval techniques are imperative to fetch the most pertinent information for accurate and useful BT generation.</p>
<p>Action Module</p>
<p>BTs offer a structured methodology for formulating highlevel behaviors across various execution platforms, including robotic systems and Unmanned Aerial Vehicles.By representing behaviors as nodes within the BT, we abstract the intricacies of lower-level control mechanisms.In our approach, each node encapsulates a set of functionalities accessible via Application Programming Interfaces (APIs) or bespoke tools found in proprietary code libraries.</p>
<p>APIs are pivotal in software engineering, offering an abstraction that simplifies complex logic into more manageable, modular interfaces.This level of abstraction enables easier task delegation, diminishes interdependencies, and promotes modularity.LLMs to generate BTs involves prompting these models with specific API calls.In turn, the LLMs construct BTs that exhibit logical coherence and integrate seamlessly with extant systems or libraries.Through encapsulation, LLMs produce targeted snippets of code that conform to the unique specifications of the project at hand.</p>
<p>Several methods have been proposed for incorporating API usage into LLMs, thereby addressing related challenges.Search tools within frameworks such as Tool-Coder [127] and CRAFT [128] empower LLMs to identify and incorporate suitable APIs directly into generated code, ensuring precision and contextual appropriateness.These frameworks' toolsets support dynamic API retrieval and execution, which aids in crafting efficient code without necessitating model retraining.The LATM framework [129] casts LLMs both as creators and consumers of tools, fostering continuous utility function generation and application.Such strategies enhance reuse and cost-efficiency; they enable advanced models to develop intricate tools and allow simpler models to use them effectively.Open-source projects like the Toolink framework [130] employ a chainof-solving approach, wherein smaller models tackle specific tasks efficiently, rivaling proprietary alternatives at a fraction of the computational expense.This embodies a com-prehensive strategy for the development and utilization of specialized toolsets and intelligent API integration, tailored for robust and flexible coding solutions in private domains.</p>
<p>For the BT Generation Task, its efficacy hinges upon the strategic configuration of selected nodes that are attuned to the requirements of the intended platform.These nodes constitute integral segments of code that direct the operations of robotics or artificial intelligence agents.It is imperative to meticulously establish these nodes to ensure proper functionality.The action module should rigorously consider the following domains: Node Libraries: The construction of a comprehensive node library is a labor-intensive process that demands considerable reflection on the capabilities and constraints of the platform in question.Nodes must be tailored to align with the platform's functionalities, necessitating customization for seamless integration.The development of this library entails extensive strategic planning and an in-depth understanding of potential tasks the BT may be required to execute.Additionally, there is a need for flexibility to accommodate the creation of novel nodes in response to emergent behaviors.Node Selection: After the assembly of the node library, the selection of the appropriate nodes becomes pivotal in sculpting the BTs to fulfill its designated purpose.The employment of Retrieval-Augmented Generation (RAG) can facilitate the identification of optimal nodes.This approach leverages insights gleaned from expansive databases to recommend prime nodes while generating new contextual information.Such methodologies enhance the relevance and quality of the nodes selected.Constrain the Results: Ensuring that outcomes derived from Large Language Models are confined within the parameters of the pre-established node-set is a critical consideration.This constraint is vital to maintain systemic integrity and to guarantee the operability of BTs on their respective platforms.Integrating the BTs with the execution systems is essential for devising a coherent action plan.Furthermore, this forms the basis for subsequent phases of Validation -which ascertains the accurate functioning of the BTs -and Execution, whereby the AI or robotic entity purposefully engages with its environment.</p>
<p>Planning Module</p>
<p>The planning module is a critical element within the architecture of an autonomous agent, highlighting the substantial influence that LLMs exert in the realm of robotics, especially concerning the BT generation.LLMs are at the frontier of propelling robotic systems to interpret contexts and perform tasks autonomously, an attribute essential to genuine intelligence.</p>
<p>Forging a rational and executable strategy for problemsolving, whether it be through programming or natural language processing, is fundamental.Methods like the Chain-of-Thought process promote clarity in the reasoning trajectory, while RAG integrates specialized knowledge, increasing the precision of responses.The incorporation of these planning techniques into LLMs strengthens their ability to devise organized multi-step solutions.</p>
<p>Historically, automated planning draws upon classical frameworks such as the Planning Domain Definition Language (PDDL) [131] and the Stanford Research Institute Problem Solver (STRIPS), which utilize abstract representations and action-precondition schemes to generate plans sequentially.However, these conventional approaches may struggle in dynamic contexts due to their reliance on fixed models.Contrastingly, modern developments in Convolutional Neural Networks and Reinforcement Learning have ushered in alternative planning paradigms like Monte Carlo Tree Search (MCTS) [132], renowned for its sophisticated search capabilities.Despite their efficacy in controlled scenarios, these methods can become less reliable amidst incomplete data and the inherent unpredictability of realworld environments.Here, LLMs with their pattern recognition expertise have the potential to enhance analytical and decision-making processes when amalgamated with planning algorithms.</p>
<p>In the context of code generation, LLMs' planning faculties aid in comprehending and carrying out intricate commands.Models that split the task into separate planning and execution stages, along with methodologies such as Planning-Guided Transformer Decoding (PG-TD)[101], direct token generation toward more refined outputs.For robot task planning, directed graphs employed by LLMs facilitate the BT generation designed for complex environments.Approaches like Language Agent Tree Search (LATS) [133] and Reasoning via Planning (RAP) [134] use tree search methods informed by environmental input to improve decision-making.The neuro-symbolic approach of the LLM-DP model [135] outperforms standard planners in executing physical tasks, with recent research demonstrating GPT-4's adeptness in planning across various fields, underscoring the importance of automated debugging and summarization of Chain-of-Thought in this sphere.</p>
<p>For the BT Generation Task.Embedding LLM-based planning into BT generation offers notable advantages.These trees systematically arrange actions, allowing agents to handle diverse situations competently.By integrating LLMs endowed with advanced planning capabilities, BTs can evolve dynamically, embodying authentic decisionmaking structures.Sophisticated planning strategies within LLMs, such as those utilized by LATS and RAP, confer strategic insight upon BTs, enabling them to adapt to environmental shifts and make forward-looking decisions.This engenders a system capable of complex, human-like reasoning and planning, thereby enhancing its robustness and flexibility.The merger of LLM-enabled planning and BT generation heralds a transformative era for autonomous systems management, preparing them to navigate intricate and volatile conditions with agility paralleling human cognition.The intertwined progress of LLMs and planning methodologies promises to redefine the autonomy of future systems, signifying a stride towards an AI that reflects the nuance and complexity of human thought processes.</p>
<p>Profile Module</p>
<p>The versatility of LLMs lies in their capacity to adopt varied personas under the direction of specific prompts.Within an agent-based framework, LLMs can function across multiple modules, each with a unique application.The Profile module is pivotal in managing diverse roles during computational processes.</p>
<p>Recent research highlights the effective use of LLMs as team members in software development.[136] introduces a self-collaborative system where several ChatGPT instances serve as experts in specific fields such as analysis and testing, mimicking human teamwork to simplify processes and improve code quality autonomously.Similarly, [137] presents ChatDev, a virtual platform following the waterfall model, where communicative agents facilitate a seamless workflow through dialogue in all stages of software production.This method is cost-effective and expedites development while proactively addressing errors.Furthermore, the DyLAN framework proposed by [138] enhances LLM agent collaboration with a flexible interaction paradigm that forms optimal teams for tasks, especially in complex areas like logic and code creation.By assessing agent significance without supervision, DyLAN consistently outperforms single-agent models.Together, these advancements suggest a shift towards harnessing LLM agents' collective intelligence in automated software development, combining diverse cognitive skills with increased efficiency.</p>
<p>For the BT Generation Task. the LLM adopts distinct personas including a planner, who segments the task into smaller actionable subtasks, and a validator, who ascertains the accuracy of outputs and provides feedback for iterative enhancements, among others.The Profile module employs a multi-agent perspective to organize these varying roles, managing the assortment of prompts required to navigate the task's pipeline effectively.</p>
<p>Refinement: beside Agent</p>
<p>Refinement describes the process of incrementally enhancing computational outputs through cycles of evaluation and modification.Echoing human solution-refining practices, it employs a trial-and-error approach akin to programmers' iterative debugging and optimization of code.This concept, though not new, has been pivotal in the recent progress seen in LLM advancement.For instance, the Self-Refine model [139] illustrates the capability of LLMs to engage in self-improvement cycles, autonomously refining their outputs.Such mechanisms are integral to cuttingedge models, including GPT-4, highlighting the importance of self-evaluation.Additionally, Reflexion [140] introduces linguistic feedback loops into language learning, further refining the decision-making processes in language agents.These feedback mechanisms have made significant strides in code generation tasks, suggesting advances in AI systems that adapt with limited training data.In robotic task planning, the ISR-LLM (Iterative and Self-Refining LLM) model [141] integrates a verification phase in its iterative cycle, verifying the robustness and feasibility of proposed action plans.Similarly, the STOP (Self-Training with Optimistic Planning) framework [142] promotes recursive selfimprovement, illuminating the prospects for self-evolving AI systems.</p>
<p>For the BT Generation Task.It is unrealistic to expect perfect LLM outputs from the onset.Instead, iterative refinement serves as a strategy to progressively improve LLM-generated BTs, with an emphasis on executability and functional coherence.The initial output from the LLM acts as a baseline, subject to consecutive rounds of testing, evaluation, and adjustment.Drawing inspiration from successful LLM frameworks, such as ISR-LLM, we endeavor to facilitate the initial generation and continuous refinement of generated BTs.The central component of the refinement is the validator, which functions similarly to a code executor, acting as a world model to execute and offer feedback on the generated BTs.The iterative cycle includes automated simulations or manual assessments, tailored to specific domain requirements, involving detailed adjustments to the BTs and corresponding API calls to meet performance benchmarks.</p>
<p>Our BTGen Agent</p>
<p>Building upon the established agent framework, we have devised a BT generation framework intended to create execution BTs, named BTGen Agent.It comprises four main modules: memory module, action module, planning module, and profile module.In addition to these modules, it also incorporates a refinement mechanism to ensure usability.</p>
<p>Memory Module:</p>
<p>The memory module serves as the linchpin of our agent-based execution BT generation framework.Its purpose is to accumulate and utilize essential knowledge efficiently to construct sophisticated execution BTs.The design accommodates dynamic and rapid access to domain-specific knowledge required for tree generation.Comprising several components, it includes Short-Term Memory (STM), which retains transient contextual expertise from expert input, ongoing process cues, and initial LLM reasoning outcomes; Long-Term Memory (LTM), a durable store that aggregates and safeguards the agent's accumulated experiences and strategies, compatible with scalable vector databases for complex data sets and structured databases; Prompt Optimization and Retrieval Enhancement, which hone the LLM outputs to align with predefined leaf node ontologies and operational parameters of the agent, enriching its retrieval capabilities using long-term memory.</p>
<p>Action Module: The action module, essential in verifying the execution BT's ability to achieve the anticipated task performance, translates abstract task outlines into executable actions.It refines task descriptions and provides action nodes adaptable to diverse software and hardware platforms, designed for both scalability and practicality.Its three vital elements are the Action Node Ontology for categorizing and decoding various actions, Action Node Linking that binds leaf nodes to executable segments or APIs, and the Action Node Repository, which houses updatable resources for new tasks and platforms.Through these components, the module underscores the execution of the effectiveness of BTs and supports seamless functioning across different settings.</p>
<p>Planning Module: The planning module amalgamates LLMs' advanced planning abilities with classic planning algorithms, facilitating the transformation of user-supplied task descriptions to execution BTs.It leverages outputs from the Memory Module and employs MCTS and CoT algorithms to build precise and effective trees.By incorporating RL, the module iteratively optimizes tree generation based on feedback from the agent's interactions with its environment, consequently enhancing plan quality and effi-ciency.Furthermore, the alignment of tree generation with code generation tasks improves complexity and accuracy, enabling coherent high-level reasoning and meticulous execution of complex commands by the platform.</p>
<p>Profile Module: The profile module enables the generation of execution BTs across varied roles by configuring LLMs using distinct prompt templates.This Configuration Module designs role-specific prompts to excavate and amplify LLMs' performance in knowledge extraction, task decomposition, tool selection, and verification driving.Realtime prompt adjustments permit the model to adapt to different roles seamlessly, optimizing performance to suit operational scenarios within complex task environments.This methodology has significantly improved the LLMs' capacity in key areas, ensuring their applicability to the dynamic requisites of intricate tasks.</p>
<p>Refinement Mechanism: The refinement in our BTGen Agent is not an independent module, but rather a mechanism that ensures the correct execution of the BT generation task by incorporating feedback from the simulation.The refinement occurs at multiple levels.During the generation of the BTs, this refinement is fast, inexpensive, but not entirely accurate.It provides affordable yet effective feedback to guide the generation process.Additionally, the execution of the BTs is necessary for the final output.During the validation stage, it evaluates whether the final BTs can achieve the target goal.The evaluation results may lead to discarding the generated behavior and initiating a new generation.This multi-level refinement is key to generating useful and correct BTs.</p>
<p>Application</p>
<p>In this section, we detail the framework and methodologies employed to develop BT generation pipelines within production settings.Our emphasis is on the dual aspects of the application framework enabling such deployments and the evaluation of performance metrics crucial for a seamless, responsive user experience.The proposed application framework is an amalgam of back-end services complemented by a front-end user interface.These components synergistically facilitate the creation, administration, and application of BTs in robotic systems.</p>
<p>Back-end Services is the cornerstone of our approach, encompassing a comprehensive suite of APIs that provide robust support for the front-end interaction.These APIs are designed to handle a spectrum of operations that include the BT generation, iterative refinement of these structures, integration of executable action nodes or ancillary tools, and the employment of rigorous validation mechanisms to ensure structural and functional integrity.The Back-end architecture is conceived to function as the computational backbone of the system-processing complex requests and returning results with minimal latency, thus fostering a dynamic, re-silient environment conducive to sophisticated manipulations of BTs.</p>
<p>Front-end User Interface (UI) is architected to offer an intuitive, streamlined user engagement with BTs.Through the UI, users can access a diverse toolkit enabling tasks like the execution of BTs, verification of their architectural coherence and logical soundness, and graphical representation to elucidate and share concepts.The UI aids in real-time editing, simulates behavior execution, and provides analytics regarding performance.Collectively, these features empower users to efficiently iterate over the development cycle, optimizing the BTs for deployment in robots.</p>
<p>Verification and Validation</p>
<p>V&amp;V plays an important role in training and developing BTGen model and they ensure the functions correctly while meeting the specified requirements.On the one hand, verification focuses on checking whether the BTGen model and the generated BTs are built correctly according to the original design.On the other hand, validation focuses on checking whether the BTGen model can output the desired outcomes and the generated BTs could effectively perform the desired tasks.According to Figure 1, V&amp;V should cover all stages of training and developing the BTGen model.We summarize them from two aspects: V&amp;V for abilities of BTGen models and V&amp;V for the performance of BTs.</p>
<p>V&amp;V for Abilities of BTGen Models</p>
<p>These abilities have been introduced and required for the selection of foundation LLMs in Section 3.However, we still check these abilities in verifying and validating the BT-Gen model due to two reasons.First, these abilities are crucial for the BT generation task and they may be degraded during the steps of training and developing the BT-Gen model.We need to ensure that the BTGen model always has these abilities.Second, we also introduce the BT related benchmarks and metrics to assist verifying and validating these abilities.Thus, to generate the high quality BTs, we need to check these abilities of the BTGen model in V&amp;V.We summarize the metrics and benchmarks may be used in Table 3.</p>
<p>Most natural-language-related tasks and reasoningrelated tasks could be divided into two classes: classification tasks and generation tasks.In terms of the classification tasks, such as sentiment analysis, text classification, natural language inference, the inputs consist of a single sentence or sentence pairs, while the output labels denote the specific classes or indicate whether the two sentences are related.Since their outputs are class labels, the accuracy and F1-scores are always adopted as the metrics.In terms of the generation tasks, common tasks include translation, summarization and multi-turn dialogues.These tasks are challenging primarily due to diversity and flex- Natural language understanding accuracy, F1-scores, perplexity, ROUGE-L GLUE [143], SuperGLUE [144], CLUE [145] Natural language generation LMSYS-Chat-1M [146], MTbench [147], LongBench [148] In-context learning COIG [149], Flan [150], Flan 2022 [151], OPT-IML [152], SuperNI [153] Instruction following</p>
<p>Reasoning-Related</p>
<p>Commonsense reasoning accuracy, F1-scores CommonsenseQA [154], PIQA [155], Pep-3k [155],</p>
<p>Social IQA [156], HellaSWAG [157] Logical reasoning Alpaca-CoT [158], LSAT [159], MultiNLI [160],</p>
<p>LogicNLI [161], ConTRoL [162],</p>
<p>ReClor [163], LogiQA [164], LogiQA 2.0 [165] Planning</p>
<p>PlanBench [166] Tool-Related Retrieval precision, recall, F1-scores API-Bank [167], APIBench [168], ToolBench [169], ToolLLM [170] Tool manipulation accuracy, F1-scores, ROUGE-L, pass rate, success rate Code-Related ibility.ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation-Longest Common Subsequence) is an evaluation metric commonly used in natural language process and text summarization tasks.It is designed to measure the similarity between a generated summary and a reference summary.Moreover, perplexity is also adopted in text generation to assess the effectiveness of LLMs.It is a way to measure how surprised or uncertain the model is when trying to predict the next token in a sequence.Mathematically, perplexity is defined as the inverse probability of the test set, normalized by the number of words (or tokens) in the test set, which can be calculated using Eq 4.
P erplexity = N 1 P (w1, w2, • • • , wN )(4)
In this equation, N is the number of tokens in the test set and P (w 1 , w 2 , • • • , w N ) is the probability assigned by the language model to the test set.The current V&amp;V methods on tool-related abilities primarily focus on following three aspects: Assessing retrieval evaluates the retrieval ability involves assessing how well the system can find and present the most relevant information in response to a query or user need.Common metrics used to evaluate the retrieval ability are precision, recall, and F1-scores.Assessing feasibility assesses whether the model can successfully execute the given tools by comprehending them.Commonly used evaluation metrics in this dimension include the execution pass rate and tool operation success rate.Assessing performance evaluates how well it performs once it has been established that the model can achieve the task.It examines the correctness of the final answer by calculating the accuracy, F1-scores, and ROUGE-L depending on specific tasks.def incr_list(l: list): """Return list with elements incremented by 1. &gt;&gt;&gt; incr_list([1, 2, 3]) [2,3,4] &gt;&gt;&gt; incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) [6,4,6,3,4,4,10,1,124] """ return [i+1 for i in l] In terms of the code-related abilities, pass@k is the most important metric to evaluate the correctness of generated program codes.[179] evaluates functional correctness using the widely adopted metric, pass@k, where k code samples are generated per problem, a problem is considered solved if any sample passes the unit tests, and the total fraction of problems solved is reported.In each problem, the LLMs generate n ≥ k samples per task, counts the number of correct samples c ≤ n which pass unit tests, and calculates the unbiased estimator in Eq 5. HumanEval [54] has been widely adopted in assessing the ability of code generation by many research works and leaderboards 5 .Each problem in HumanEval, as shown in Figure 5, provides a prompt with descriptions of the function to be generated, function signature, and example test cases in the form of assertions.The LLM needs to complete a function given the prompt such that it can pass all provided test cases, thus measuring the performance by functional correctness.
pass@k = E problems 1 − C k n−c C k n (5</p>
<p>V&amp;V for the Performance of BTs</p>
<p>Second, V&amp;V checks the performance of BT to improve the credibility of generated BTs and further adjusts the generated BTs.As shown in Figure 6, existing V&amp;V methods could be summarized into three categories based on unit tests, simulators, and LLMs.We will introduce each of them as follows.</p>
<p>Unit-Tests-Based V&amp;V</p>
<p>Unit tests are essential practices in software development that involves testing individual units or components of a software system in isolation, including function testing, class testing, module testing, integration testing, and code coverage testing.They target various input scenarios of the function and check whether the function returns the expected outputs correctly.</p>
<p>As for testing BTs, these unit tests could test the BT nodes, tree execution, and logic integration.First, each node in a BT can be considered a unit, and thus unit tests can be written to verify that each node performs its intended function correctly.For example, the action nodes that perform specific tasks can be tested to ensure they handle edge cases and errors properly.Second, unit tests can be constructed to test the correct execution of the BTs itself.These tests can verify that the tree traversal is happening correctly, that nodes are being executed in the proper order, and that the correct branches are taken based on different conditions.Third, when a BT is part of a larger application, unit tests can be utilized to ensure that the BT interacts with other application components properly.This might involve mocking external dependencies and testing the behavior of the tree under various simulated conditions.Common test tools, such as JUnit6 , GoogleTest7 and manually crafted a set of unit tests checks whether the corresponding functions in generated BTs are effective.</p>
<p>Simulator-Based V&amp;V</p>
<p>Simulator, as a computational tool, encompasses the emulation of real-world processes or systems by employing mathematical formulas, algorithms, or computer-generated representations to imitate their behaviors or characteristics [180].The significance of simulation spans various domains, serving as a valuable tool for understanding, analyzing, and predicting intricate phenomena that might be impractical or impossible to observe directly in real life.Simulators aims to simulate the transition of states based on specified rules and object properties, which has been widely adopted in many tasks [118,181,182,183].Voyager [118] is a lifelong learning agent in Minecraft simulator8 that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.It is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize.Moreover, Zhu [117] also aims to create Generally Capable Agents (GCAs) in Minecraft.MindAgent [181] establishes a new gaming scenario and related benchmark based on a multiagent virtual kitchen environment, CuisineWorld.It adopts a minimal text-based game format and supports various planning task structures and difficulties, making it an ideal test bed for the emergent multi-agent planning (scheduling and coordination) capacity.In addition, ALFWorld [182] is a simulator that enables agents to learn abstract, textbased policies in TextWorld [184] and then execute goals from the ALFRED benchmark [185] in a rich visual environment.Specifically, TextWorld is an engine for interactive text-based games and ALFRED is a large scale dataset for vision-language instruction following in embodied environments.Similar thoughts exist in [186] where Puig introduces the VirtualHome simulator that allows researchers to create a large activity video dataset with rich ground-truth by using programs to drive an agent in a synthetic world.</p>
<p>By using simulators, we can simulate various scenarios and situations to observe the behavior and decision-making of agents under different conditions.However, building a high-quality simulator is not an easy task and requires sig-nificant time and resources.First, it is essential to gather data from the real world to create a precise simulation setting.This step might encompass laborious tasks like amassing data, refining it, and adding descriptive labels.Second, the creation and execution of the simulation's physics, behavior, and perception models is critical to guarantee the fidelity and dependability of the simulated context.Executing these steps demands much specialized knowledge.</p>
<p>LLM-Based V&amp;V</p>
<p>LLMs are a breaking achievement in the field of machine learning, demonstrating vast potential in tasks related to natural language understanding and text creation.Utilizing their impressive skills, LLMs are regarded as world models to represent the physical world, capable of simulating changes in the world's state in rseponse to various actions.They offer potential improvements to simulations through facilitating more sophisticated and lifelike portrayals of decision-making, communication, and adaptability in simulated scenarios.</p>
<p>Test cases generation from LLMs is a practical scenario of LLM-based V&amp;V to aid the software development.Code LLaMA [55] constructs the self-instruction dataset in the following: (1) Generate interview-style programming questions by prompting LLaMA-2 and the set of questions.(2) Generate unit tests and ten Python solutions by prompting Code LLaMA.(3) Run the unit tests on the ten solutions and add the first solution that passes the tests to the self-instruct dataset.Similar thoughts could be seen in [100,187].They use the generated test cases to validate the effectiveness of generated codes.Other works have attempted to directly replace simulators with LLMs.[188] employs GPT-4 as an inspector for compilation and runtime error.If errors are found, the inspector provides suggestions for corrections.The process iterates until either the code passes inspection or a maximum number of inspections is reached.[134] uses LLMs to understand the current environment state, comprehend the impact of actions on the environment state, and output the next environment state, thereby simulating state transitions.</p>
<p>LLMs can serve as a new paradigm for simulation with human-level intelligence.Integrating LLMs into simulation holds the potential to enrich the fidelity and complexity of simulations, potentially yielding deeper insights into system behaviors and emergent phenomena for the following reasons [180]: (1) LLMs can adaptively react and perform tasks based on the environment without predefined explicit instructions.(2) LLMs have strong intelligence to respond realistically and even actively take actions with selforiented planning and scheduling.However, effectiveness and accuracy of LLM-based V&amp;V still require further research and investigation.</p>
<p>BT-Simulator
BT</p>
<p>Our Method for V&amp;V</p>
<p>As shown in the above analysis, our method for V&amp;V could be divided into two steps.</p>
<p>First, we plan to introduce a benchmark for evaluating basic abilities of BTGen model in BT generation.It evaluates these natural-language-related, reasoning-related, toolrelated, and code-related abilities.Specifically, to measure the performance of BTGen model in natural language understanding, natural language generation, in-context learning, and instruction following, we select CLUE [145], MT-Bench [147], COIG [149], and Flan 2022 [151] as benchmarks to evaluate the BTGen model in terms of accuracy, F1-scores, and ROUGE-L.To measure the performance of BTGen model in commonsense reasoning, logical reasoning, and planning, we select CommonsenseQA [154], Alpaca-CoT [158], PlanBench [166] to evaluate the BTGen model in terms of the same metrics.ToolBench [169] and APIBench [168] are selected to measure the BTGen model in the tool-related tasks i terms of the accuracy, F1-scores, ROUGE-L, pass rate, and success rate.At last, we measure the code-related abilities, including code generation, code explanation, and code translation of BTGen model on HumanEval [54] and CodeXGLUE [176] in terms of pass@k.</p>
<p>Second, we measure the performance of BTs in simulation environments.Li [110] proposes an LMulator as a portmanteau of LLMs and code emulator.If the generated code is successfully executed, the program state is updated and the execution continues.Otherwise, the language model instead is used to simulate the execution.The program state is subsequently updated by the outputs of LLMs and the execution continues.Inspired by LMulator, we plan to propose a novel preliminary idea of BT simulator that interweaves the existing simulator with LLM in a feedback loop, dealing with both semantic and algorithmic reasoning.The detailed process could be shown in Figure 7. On the one hand, existing simulators can provide a basic framework for simulating.On the other hand, LLMs with world knowledge could assist the simulator achieving more generalization in different unseen scenarios and reduce labor overhead in designing simulators.Specifically, the intermediate message information can be passed between the simulator and LLM to provide more valuable information.LLM can exert its advantages in the following three aspects: setting environments, simulating states transition and actions generation, and designing feedback functions.Moreover, the BT simulator exists in the loop of BT generation where the outputs of it are regarded as the feedback to iteratively update the LLM to generate higher quality of BT codes.</p>
<p>Open Questions</p>
<p>Question.The success of LLMs like ChatGPT is largely dependent on the quality of data they are trained with.Acquiring high-caliber, representative datasets is a significant concern in this domain.Synthetic data generation has its merits, including scalability and customization; however, it also carries intrinsic limitations.Notably, when LLMs create data for a less advanced target model, the output may seem satisfactory but can lead to "hallucination issues"-instances where the data contains baseless components due to the training limitations of the source LLM.</p>
<p>Moreover, publicly sourced datasets are prone to contain 'dirty data'-information that is erroneous or extraneous-which can propagate bias or inaccuracies in the models.This highlights the crucial need for extensive datacleaning processes and the establishment of benchmarks for dataset quality.Striking a balance between the volume and integrity of data is intricate, necessitating precise attention in order to advance the creation of more precise and reliable LLMs.Future research should concentrate on devising sophisticated methodologies for automated data validation and refinement, thereby ensuring models are trained on a robust and credible dataset.</p>
<p>Training Question.In addition to data selection, the training strategies implemented for LLMs present a nuanced challenge.The complexities of pretraining and subsequent supervised fine-tuning have significant ramifications for an LLM's performance, which requires a deep understanding of the interplay between model scale and generalization capabilities.The appropriate configuration of hyperparameters and optimization techniques during finetuning is critical for task-specific adaptation, while avoiding pitfalls such as overfitting or catastrophic forgetting.</p>
<p>Further exploration is warranted to identify optimal practices for transfer learning in the LLM landscape, potentially employing meta-learning paradigms to promote quick acclimatization to new tasks or domains.There is also potential for innovation in refining LLM architectures, possibly through introducing modular elements or variations in attention mechanisms, which could improve the efficiency and effectiveness of training protocols.An in-depth exam-ination of these training approaches is imperative to clarify the factors contributing to the superior efficacy of certain LLMs relative to others under comparable conditions.</p>
<p>Planning Question.In the context of reasoning processes within LLMs, planning serves as a fundamental component for BT generation tasks.The input consists of the task objective, while the output manifest as structured executable actions in the form of a BT that robotic systems can enact.Presently, despite the demonstrated promise of LLMs in planning functions, there is a conspicuous disparity between these nascent skills and the necessities of practical applications.</p>
<p>To narrow this divide, research should focus on augmenting LLMs' understanding of sequential and causal relationships pertinent to tasks.The assimilation of external knowledge repositories and simulation platforms may provide ancillary support for grounding LLM-formulated plans in actuality.Moreover, it is essential to evolve from static planning models to accommodate dynamic settings, where real-time decisions are essential.Investigations should pivot toward composite models that blend LLMs' generative strengths with deterministic systems to manage the unpredictability of real-world circumstances effectively.Enhancing LLMs with contextual awareness and sensitivity may lead to innovative planning methodologies that reflect the intricacies of robotic operations more accurately.</p>
<p>Validation Question.A primary concern within our research is the verification of correctness in the outputs produced.Efficient validation of generated BTs represents a complex balancing act.We suggest that LLMs could streamline this process and offer novel insights compared to traditional simulators.</p>
<p>There is a pressing requirement for the development of stringent testing regimes capable of consistently assessing the functionality and safety of BTs.Such protocols should not merely test the logical consistency of sequences but also their responsiveness to environmental fluctuations or goal modifications.Additionally, establishing metrics for evaluating the interpretability and explicability of the trees is paramount, enabling end-users to trust and utilize them competently.Incorporating feedback mechanisms from actual deployments into the validation process may yield critical information for continuous enhancement.</p>
<p>Looking ahead, it is vital to explore the integration of simulation technologies with LLMs to craft virtual testing grounds where BTs can undergo rigorous assessment across diverse scenarios.This approach would facilitate comprehensive and economical validation prior to implementation in tangible robots, thus reducing risk and bolstering the dependability of autonomous actions.In essence, the goal is to cultivate a synergistic dynamic between LLM-guided design and empirical evaluations, potentially revolutionizing the standards of robotic system validation.</p>
<p>Conclusions</p>
<p>In conclusion, this paper has provided a comprehensive exploration of the nascent field of LLMs utilization for BT Generation.By harnessing the power of LLMs, we have showcased the potential to significantly enhance the adaptability, generality, and interpretability of BTs.Our investigation into the deployment of LLMs within BT generation reveals that it is possible to streamline this task.</p>
<p>The proposed phase-step prompt design and the use of self-instructive datasets represent pioneering steps towards more user-friendly and intuitive methodologies for BT generation.These approaches could potentially alleviate common issues such as hallucination, data bias, out-of-domain limitations, and lack of explainability and transparency in current models.</p>
<p>Furthermore, our work emphasizes the importance of V&amp;V driven pipeline designed to consistently yield highquality BTs.This pipeline serves to ensure that all stages of training and development meet stringent criteria for functionality and compliance with specified requirements.</p>
<p>It is imperative to acknowledge that while this field is still in its early developmental stages, the foundational work outlined in this paper sets forth a robust framework for future research.The strategies and insights presented here aim to catalyze progress, inviting further investigation and refinement of LLM applications in BT generation.As we advance, the intersection of AI automation and BT systems stands to gain significant innovations, ultimately benefiting a wide array of developers and researchers across diverse domains.</p>
<p>(Section 3 )Figure 1 .
31
Figure 1.The overview structure of our paper.</p>
<p>XML</p>
<p><Fallback instance name = 'fallback node'/> <Sequence instance name = 'sequence node'/> <Condition instance name = 'check-target detected'/> <Action instance name = 'warn-target' /> </Sequence> <Action instance name = 'move-to next-pos'/> </Fallback> Nodes check-target detected: Check if any suspicious targets have been detected.warn-target: Warn the target.move-to next-pos: Move to the next location in the route.</p>
<p>Figure 3 .
3
Figure 3. Illustration of the BT Generation method utilizing a framework inspired by Monte Carlo Tree Search (MCTS) for generating BTs.Each state represents a BT, with transitions informed by selection, expansion, validation, and iterative refinement processes.The approach integrates a language model for decision-making and node expansion.</p>
<p>Figure 4 .
4
Figure 4. Illustration of the BTGen Agent framework.</p>
<p>Figure 5 .
5
Figure 5.An example for the HumanEval benchmark.The prompt provided to the model is shown in green, and a successful modelgenerated completion is shown in orange.</p>
<p>Figure 6 .
6
Figure 6.V&amp;V of BTGen model could be classified into three categories based on unit tests, simulators, and LLMs.</p>
<p>Figure 7 .
7
Figure 7.The framework of BT simulator in the loop of training and developing BTGen model.</p>
<p>Table 1 .
1
Abilities of foundation LLMs related to the BT generation.
CategoriesAbilitiesDescriptionBT GenerationNatural-Language-RelatedNatural language understandingComprehend and interpret natural language.</p>
<p>Table 2 .
2
A piece of formatted BT data</p>
<p>Table 3 .
3
Benchmarks and metrics of verifying and validating abilities of BTGen model
CategoriesAbilitiesMetricsBenchmarksNatural-Language-Related
https://openai.com/chatgpt
https://github.com/microsoft/DeepSpeed
Within academic circles, the conception of a "prompt" is multifaceted. For our discussion, it is defined as a directive for a specific task, such as "Translate English to French," or a structured cue like "Let's dissect this problem step by step."
https://www.datalearner.com/ai-models/llm-codingevaluation,https://huggingface.co/spaces/bigcode/bigcode-modelsleaderboard,https://evalplus.github.io/leaderboard.html
https://junit.org/junit5/
https://google.github.io/googletest/
https://www.minecraft.net/
Code generation pass@k, perplexity, ROUGE-L HumanEval[54],MBPP[171], APPS[172],MultiPL-E[173], EvalPlus[174], HumanEval-X[175]Code explanation CodeXGLUE[176]Code translation XLCoST[177], HumanEvalPack[178]Code generation with generated tests.arXiv preprint arXiv:2207.10397,2022.13, 23 [101] Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B Tenenbaum, and Chuang Gan.Planning with large language models for code generation.arXiv preprint arXiv:2303.05510,2023.13, 18 [102] Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, and Steven Chu Hong Hoi.Coderl: Mastering code generation through pretrained models and deep reinforcement learning.Advances in Neural Information Processing Systems, 35:21314-21328, 2022.13
Yanzhen Wang, and Xuejun Yang. micros.bt: An eventdriven behavior tree framework for swarm robots. Yunlong Wu, Jinghua Li, Huadong Dai, Xiaodong Yi, IEEE International Conference on Intelligent Robots and Systems. IEEE2021</p>
<p>Combining planning and learning of behavior trees for robotic assembly. Jonathan Styrud, Matteo Iovino, Mikael Norrlöf, Mårten Björkman, Christian Smith, 2022 International Conference on Robotics and Automation. IEEE2022</p>
<p>Behavior trees in robotics and AI: An introduction. Michele Colledanchise, Petter Ögren, 2018CRC Press</p>
<p>An expressiveness hierarchy of behavior trees and related architectures. Oliver Biggar, Mohammad Zamani, Iman Shames, IEEE Robotics and Automation Letters. 632021</p>
<p>Improving the parallel execution of behavior trees. Michele Colledanchise, Lorenzo Natale, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE2018</p>
<p>Adding neural network controllers to behavior trees without destroying performance guarantees. Iliffe Christopher, Petter Sprague, Ögren, 2022 IEEE 61st Conference on Decision and Control. IEEE2022</p>
<p>Autonomous acquisition of behavior trees for robot control. Bikramjit Banerjee, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE2018</p>
<p>Learning behavior trees from demonstration. Kevin French, Shiyu Wu, Tianyang Pan, Zheming Zhou, Odest Chadwicke Jenkins, 2019 International Conference on Robotics and Automation. IEEE20191</p>
<p>Ql-bt: Enhancing behaviour tree design and implementation with q-learning. Rahul Dey, Chris Child, 2013 IEEE Conference on Computational Inteligence in Games. IEEE2013</p>
<p>Re: Bt-espresso: Improving interpretability and expressivity of behavior trees learned from robot demonstrations. Adam Wathieu, Thomas R Groechel, Jenny Haemin, Chloe Lee, Maja J Kuo, Matarić, 2022 International Conference on Robotics and Automation. IEEE2022</p>
<p>Synthesis of correct-by-construction behavior trees. Michele Colledanchise, Richard M Murray, Petter Ögren, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems. 2017</p>
<p>Representing robot task plans as robust logicaldynamical systems. Chris Paxton, Nathan Ratliff, Clemens Eppner, Dieter Fox, 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE2019</p>
<p>Towards blended reactive planning and acting using behavior trees. Michele Colledanchise, Diogo Almeida, Petter Ögren, 2019 International Conference on Robotics and Automation. IEEE201989</p>
<p>An autonomous task algorithm based on behavior trees for robot. Haotian Zhou, Huasong Min, Yunhan Lin, 2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence. IEEE2019</p>
<p>Costar: Instructing collaborative robots with behavior trees and vision. Chris Paxton, Andrew Hundt, Felix Jonathan, Kelleher Guerin, Gregory D Hager, IEEE international conference on robotics and automation. 12017. 2017IEEE</p>
<p>A behavior tree cognitive assistant system for emergency medical services. Sile Shu, Sarah Preum, Haydon M Pitchford, Ronald D Williams, John Stankovic, Homa Alemzadeh, 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE2019</p>
<p>Simulation and real time analysis of network protection tripping strategy based on behavior trees. Xiong Haijun, Zhang Qi, Cluster Computing. 2212019</p>
<p>Adaptive human behavior modeling for air combat simulation. Jian Yao, Qiwang Huang, Weiping Wang, 2015 IEEE/ACM 19th International Symposium on Distributed Simulation and Real Time Applications. IEEE2015</p>
<p>Modeling, learning, and simulating human activities of daily living with behavior trees. Yannick Francillette, Bruno Bouchard, Kévin Bouchard, Sébastien Gaboury, Knowledge and Information Systems. 62102020</p>
<p>A survey of behavior trees in robotics and ai. Matteo Iovino, Edvards Scukins, Jonathan Styrud, Petter Ögren, Christian Smith, Robotics and Autonomous Systems. 15411040962022</p>
<p>Synthesis of correct-by-construction behavior trees. Michele Colledanchise, Richard M Murray, Petter Ögren, IEEE/RSJ International Conference on Intelligent Robots and Systems. 201789</p>
<p>Autonomous task planning and acting for micro aerial vehicles. Menglu Lan, Shupeng Lai, Tong Heng Lee, Ben M Chen, 2019 IEEE 15th International Conference on Control and Automation. IEEE201989</p>
<p>Extended behavior trees for quick definition of flexible robotic tasks. Francesco Rovida, Bjarne Grossmann, Volker Krüger, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems. 810</p>
<p>Tree-structured policy planning with learned behavior models. Yuxiao Chen, Peter Karkus, Boris Ivanovic, Xinshuo Weng, Marco Pavone, IEEE International Conference on Robotics and Automation, ICRA 2023. London, UKIEEEMay 29 -June 2, 2023. 1 2023. 1, 8</p>
<p>Learning to adapt the parameters of behavior trees and motion generators to task variations. Faseeh Ahmad, Matthias Mayr, Volker Krueger, CoRR, abs/2303.082093 2023. 1, 8</p>
<p>Dream to control: Learning behaviors by latent imagination. Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi, 8th International Conference on Learning Representations. Addis Ababa, EthiopiaApril 26-30, 2020. 12 2020. 12020</p>
<p>Behavior tree design of intelligent behavior of non-player character (npc) based on unity3d. Xianwen Zhu, Journal of Intelligent and Fuzzy Systems. 3782019</p>
<p>Robot behavior-tree-based task generation with large language models. Yue Cao, C S George Lee, Proceedings of the AAAI 2023 Spring Symposium on Challenges Requiring the Combination of Machine Learning and Knowledge Engineering. CEUR Workshop Proceedings. CEUR-WS.org. the AAAI 2023 Spring Symposium on Challenges Requiring the Combination of Machine Learning and Knowledge EngineeringHyatt Regency, San Francisco Airport, California, USAMarch 27-29, 2023. 2023343311</p>
<p>ArXiv, abs/2303.08774OpenAI. Gpt-4 technical report. 2023. 1, 3, 4</p>
<p>Llama: Open and efficient foundation language models. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971202334arXiv preprint</p>
<p>Behavior-tree embeddings for robot task-level knowledge. Yue Cao, C S George Lee, IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2022. Kyoto, JapanOctober 23-27, 2022, volume 2022-October. 2022210</p>
<p>Llm-brain: Aidriven fast generation of robot behaviour tree based on large language model. Artem Lykov, Dzmitry Tsetserukou, arXiv:2305.193522023211arXiv preprint</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 202335arXiv preprint</p>
<p>Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, Jie Tang, Glm, arXiv:2103.10360General language model pretraining with autoregressive blank infilling. 202134arXiv preprint</p>
<p>Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, arXiv:2305.06161Starcoder: may the source be with you!. 202337arXiv preprint</p>
<p>Codefuse-13b: A pretrained multi-lingual code large language model. Peng Di, Jianguo Li, Hang Yu, Wei Jiang, Wenting Cai, Yang Cao, Chaoyu Chen, Dajun Chen, Hongwei Chen, Liang Chen, arXiv:2310.06266202337arXiv preprint</p>
<p>Deep learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016MIT press</p>
<p>Understanding deep learning (still) requires rethinking generalization. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals, Communications of the ACM. 6432021</p>
<p>On the opportunities and risks of foundation models. Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney Von Arx, Jeannette Michael S Bernstein, Antoine Bohg, Emma Bosselut, Brunskill, arXiv:2108.072582021arXiv preprint</p>
<p>What language model to train if you have one million gpu hours?. Le Teven, Thomas Scao, Daniel Wang, Lucile Hesslow, Stas Saulnier, Saiful Bekman, Stella Bari, Hady Biderman, Niklas Elsahar, Jason Muennighoff, Phang, arXiv:2210.154242022arXiv preprint</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>A survey for in-context learning. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Zhifang Sui, arXiv:2301.00234202245arXiv preprint</p>
<p>Noam Shazeer, arXiv:2002.05202Glu variants improve transformer. 2020arXiv preprint</p>
<p>Roformer: Enhanced transformer with rotary position embedding. Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, Yunfeng Liu, Neurocomputing. 41270632023</p>
<p>Llama 2: Open foundation and fine-tuned chat models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.092882023arXiv preprint</p>
<p>Glm-130b: An open bilingual pre-trained model. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, arXiv:2210.024142022arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 20223514</p>
<p>Augmented language models: a survey. Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Timo Baptiste Rozière, Jane Schick, Asli Dwivedi-Yu, Celikyilmaz, arXiv:2302.078422023arXiv preprint</p>
<p>Webgpt: Browser-assisted question-answering with human feedback. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, arXiv:2112.093322021arXiv preprint</p>
<p>Webshop: Towards scalable real-world web interaction with grounded language agents. Shunyu Yao, Howard Chen, John Yang, Karthik Narasimhan, Advances in Neural Information Processing Systems. 202235</p>
<p>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch, PMLR, 2022. 7International Conference on Machine Learning. </p>
<p>Inner monologue: Embodied reasoning through planning with language models. Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, arXiv:2207.056082022arXiv preprint</p>
<p>Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong, arXiv:2203.13474Codegen: An open large language model for code with multi-turn program synthesis. 2022arXiv preprint</p>
<p>Evaluating large language models trained on code. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, arXiv:2107.033742021. 7, 212223arXiv preprint</p>
<p>Code llama: Open foundation models for code. Jonas Baptiste Roziere, Fabian Gehring, Sten Gloeckle, Itai Sootla, Gat, Ellen Xiaoqing, Yossi Tan, Jingyu Adi, Tal Liu, Jérémy Remez, Rapin, arXiv:2308.129502023. 7, 131423arXiv preprint</p>
<p>Finding needles in a haystack: Sampling structurally-diverse training sets from synthetic data for compositional generalization. Inbar Oren, Jonathan Herzig, Jonathan Berant, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana. the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta CanaDominican RepublicAssociation for Computational Linguistics7-11 November, 2021. 2021</p>
<p>Learning to generate overlap summaries through noisy synthetic data. Naman Bansal, Mousumi Akter, Shubhra Kanti, Karmaker , Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022. the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 7-11, 2022. 2022</p>
<p>Synthetic data for model selection. Alon Shoshan, Nadav Bhonker, Igor Kviatkovsky, Matan Fintz, Gérard Medioni, Proceedings of the 40th International Conference on Machine Learning, ICML'23. JMLR.org. the 40th International Conference on Machine Learning, ICML'232023</p>
<p>New oracle-efficient algorithms for private synthetic data release. Giuseppe Vietri, Grace Tian, Mark Bun, Thomas Steinke, Zhiwei Steven Wu, Proceedings of the 37th International Conference on Machine Learning, ICML'20. JMLR.org. the 37th International Conference on Machine Learning, ICML'202020</p>
<p>Generating private synthetic data with genetic algorithms. Terrance Liu, Jingwu Tang, Giuseppe Vietri, Zhiwei Steven Wu, International Conference on Machine Learning, ICML 2023. Honolulu, Hawaii, USAPMLRJuly 2023. 2023202of Proceedings of Machine Learning Research</p>
<p>Beyond human data: Scaling self-training for problem-solving with language models. Avi Singh, John D Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Peter J Liu, James Harrison, Jaehoon Lee, Kelvin Xu, Aaron Parisi, arXiv:2312.065852023arXiv preprint</p>
<p>Constrained labeled data generation for low-resource named entity recognition. Ruohao Guo, Dan Roth, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021. Association for Computational LinguisticsAugust 1-6, 2021. 2021ACL/IJCNLP 2021 of Findings of ACL</p>
<p>A pipeline for generating, annotating and employing synthetic data for real world question answering. Matt Maufe, Filament Ai, James Ravenscroft, Rob Procter, Maria Liakata, Proceedings of the The 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022 -System Demonstrations. the The 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022 -System DemonstrationsAbu Dhabi, UAEAssociation for Computational LinguisticsDecember 7-11, 2022. 2022</p>
<p>3d-aware facial landmark detection via multi-view consistent training on synthetic data. Libing Zeng, Lele Chen, Wentao Bao, Zhong Li, Yi Xu, Junsong Yuan, Nima K Kalantari, IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023. Vancouver, BC, CanadaIEEEJune 17-24, 2023. 2023</p>
<p>Evolvingbehavior: Towards co-creative evolution of behavior trees for game npcs. Nathan Partlan, Luis Soto, Jim Howe, Sarthak Shrivastava, Magy Seif El-Nasr, Stacy Marsella, FDG '22: Proceedings of the 17th International Conference on the Foundations of Digital Games. Athens, GreeceACMSeptember 5-8, 2022. 9 202222</p>
<p>A framework for learning behavior trees in collaborative robotic applications. Matteo Iovino, Jonathan Styrud, Pietro Falco, Christian Smith, 19th IEEE International Conference on Automation Science and Engineering, CASE 2023. Auckland, New ZealandIEEEAugust 26-30, 2023. 3 2023</p>
<p>Optimization of parameterized behavior trees in rts games. Tomasz Machalewski, Mariusz Marek, Adrian Ochmann, International Conference on Artificial Intelligence and Soft Computing. Springer2022</p>
<p>Automatic generation of behavior trees for the execution of robotic manipulation tasks. Parikshit Verma, Mohammed Diab, Jan Rosell, 2021 26th IEEE International Conference on Emerging Technologies and Factory Automation. IEEE2021</p>
<p>Safe explainable agents for autonomous navigation using evolving behavior trees. Nicholas Potteiger, Xenofon Koutsoukos, 2023 IEEE International Conference on Assured Autonomy. IEEE2023</p>
<p>Evolutionary behavior tree approaches for navigating platform games. Miguel Nicolau, Diego Perez-Liebana, Michael Oneill, Anthony Brabazon, IEEE Trans. Comput. Intell. AI Games. 939 2017</p>
<p>Efficiently evolving swarm behaviors using grammatical evolution with ppa-style behavior trees. Aadesh Neupane, Michael A Goodrich, CoRR, abs/2203.15776, 3 2022. 8</p>
<p>Learning behavior trees with genetic programming in unpredictable environments. Matteo Iovino, Jonathan Styrud, Pietro Falco, Christian Smith, 2021 IEEE International Conference on Robotics and Automation. IEEE2021</p>
<p>Evolving instinctive behaviour in resourceconstrained autonomous agents using grammatical evolution. Ahmed Hallawa, Simon Schug, Giovanni Iacca, Gerd Ascheid, Applications of Evolutionary Computation: 23rd European Conference, EvoApplications 2020, Held as Part of EvoStar 2020. Seville, SpainSpringerApril 15-17, 2020, Proceedings 23. 2020</p>
<p>Modeling, learning, and simulating human activities of daily living with behavior trees. Yannick Francillette, Bruno Bouchard, Kevin Bouchard, Sebastien Gaboury, KNOWLEDGE AND INFORMATION SYSTEMS. 6210OCT 2020</p>
<p>Learning behavior trees from planning experts using decision tree and logic factorization. Simona Gugliermo, Erik Schaffernicht, Christos Koniaris, Federico Pecora, IEEE Robotics and Automation Letters. 92023</p>
<p>Specification-guided behavior tree synthesis and execution for coordination of autonomous systems. Expert Systems with Applications. Abdullah Tadewos G Tadewos, Al Redwan, Ali Newaz, Karimoddini, 2022201117022</p>
<p>Bt expansion: a sound and complete algorithm for behavior planning of intelligent robots with behavior trees. Zhongxuan Cai, Minglong Li, Wanrong Huang, Wenjing Yang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>Deliberative acting, planning and learning with hierarchical operational models. Sunandita Patra, James Mason, Malik Ghallab, Dana Nau, Paolo Traverso, Artificial Intelligence. 299101035232021</p>
<p>Automatic decentralized behavior tree synthesis and execution for coordination of intelligent vehicles. Knowledge-Based Systems. Laya Tadewos G Tadewos, Ali Shamgah, Karimoddini, 2023260110181</p>
<p>State-aware layered bts-behavior tree extensions for post-actions, preferences and local priorities in robotic applications. Guilherme De, Campos Affonso, Kei Okada, Masayuki Inaba, International Conference on Intelligent Autonomous Systems. Springer2022</p>
<p>Combining context awareness and planning to learn behavior trees from demonstration. Oscar Gustavsson, Matteo Iovino, Jonathan Styrud, Christian Smith, 2022 31st IEEE International Conference on Robot and Human Interactive Communication. IEEE2022</p>
<p>Self-optimizing agents using mixed initiative behavior trees. Mohamed Behery, Minh Trinh, Christian Brecher, Gerhard Lakemeyer, 2023 IEEE/ACM 18th Symposium on Software Engineering for Adaptive and Self-Managing Systems. IEEE2023</p>
<p>Active inference and behavior trees for reactive action planning and execution in robotics. Corrado Pezzato, Carlos Hernández Corbato, Stefan Bonhof, Martijn Wisse, IEEE Transactions on Robotics. 3922023</p>
<p>Task planning with belief behavior trees. Evgenii Safronov, Michele Colledanchise, Lorenzo Natale, 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE2020</p>
<p>Behavior-tree embeddings for robot task-level knowledge. Yue Cao, George Cs, Lee, 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE2022</p>
<p>Query-enabled behavior trees. Gonzalo Flórez-Puga, Marco Antonio Gómez-Martín, Pedro Pablo Gómez-Martín, Belén Díaz-Agudo, Pedro Antonio González-Calero, IEEE Transactions on Computational Intelligence and AI in Games. 11012 2009</p>
<p>To resume or not to resume: A behavior tree extension. Wafic El-Ariss, Naseem Daher, Imad H Elhajj, 2021</p>
<p>American Control Conference. IEEE2021</p>
<p>Action node graph: Graph design for mobile robot route planning in cities. Ryusuke Umeyama, Shun Niijima, Yoko Sasaki, Hiroshi Takemura, 2022 IEEE/SICE International Symposium on System Integration. IEEE2022</p>
<p>Behavior tree learning for robotic task planning through monte carlo dag search over a formal grammar. Emily Scheide, Graeme Best, Geoffrey A Hollinger, 2021 IEEE International Conference on Robotics and Automation. IEEE2021</p>
<p>Synthesis and online re-planning framework for timeconstrained behavior tree. Chuanxiang Gao, Yu Zhai, Biao Wang, Ben M Chen, 2021 IEEE International Conference on Robotics and Biomimetics. IEEE2021</p>
<p>Learning and executing re-usable behaviour trees from natural language instruction. Gavin Suddrey, Ben Talbot, Frederic Maire, IEEE Robotics and Automation Letters. 710 2022. 11</p>
<p>Skeleton-of-thought: Large language models can do parallel decoding. Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, Yu Wang, arXiv:2307.1533720231114arXiv preprint</p>
<p>Everything of thoughts: Defying the law of penrose triangle for thought generation. Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, arXiv:2311.042542023arXiv preprint</p>
<p>Self-instruct: Aligning language models with selfgenerated instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, arXiv:2212.105602023arXiv preprint</p>
<p>Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Daxin Jiang, arXiv:2304.12244Wizardlm: Empowering large language models to follow complex instructions. 2023arXiv preprint</p>
<p>Dobf: A deobfuscation pre-training objective for programming languages. Marie-Anne Lachaux, Baptiste Roziere, Marc Szafraniec, Guillaume Lample, Advances in Neural Information Processing Systems. 202134</p>
<p>Paras Jain, Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph E Gonzalez, Ion Stoica, arXiv:2007.04973Contrastive code representation learning. 2020arXiv preprint</p>
<p>Integrating tree path in transformer for code representation. Han Peng, Ge Li, Wenhan Wang, Yunfei Zhao, Zhi Jin, Advances in Neural Information Processing Systems. 202134</p>
<p>Competition-level code generation with alphacode. Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Science. 37866242022</p>
<p>. Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, Weizhu Chen, Codet</p>
<p>Jiate Liu, Yiqin Zhu, Kaiwen Xiao, Qiang Fu, Xiao Han, Wei Yang, Deheng Ye, arXiv:2307.04349Rltf: Reinforcement learning from unit test feedback. 2023arXiv preprint</p>
<p>P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks. Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, Jie Tang, arXiv:2110.076022021arXiv preprint</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021arXiv preprint</p>
<p>Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer, Qlora, arXiv:2305.14314Efficient finetuning of quantized llms. 202314arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.10601may 2023. 202314arXiv preprint</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, arXiv:2308.09687202314arXiv preprint</p>
<p>Structured chainof-thought prompting for code generation. Jia Li, Ge Li, Yongmin Li, Zhi Jin, arXiv:2305.06599202315arXiv preprint</p>
<p>Chain of code: Reasoning with a language model-augmented code emulator. Chengshu Li, Jacky Liang, Andy Zeng, Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, Brian Ichter, arXiv:2312.0447420231523arXiv preprint</p>
<p>Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu Chen, arXiv:2101.06804What makes good in-context examples for gpt-3?. 202115arXiv preprint</p>
<p>In-context examples selection for machine translation. Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, Marjan Ghazvininejad, arXiv:2212.02437202215arXiv preprint</p>
<p>Qiaoqiao She, and Yongdong Zhang. k nn prompting: Beyond-context learning with calibration-free nearest neighbor inference. Benfeng Xu, Quan Wang, Zhendong Mao, Yajuan Lyu, arXiv:2303.13824202315arXiv preprint</p>
<p>Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp, arXiv:2104.08786202115arXiv preprint</p>
<p>On the relation between sensitivity and accuracy in in-context learning. Yanda Chen, Chen Zhao, Zhou Yu, arXiv:2209.07661202215arXiv preprintKathleen McKeown, and He He</p>
<p>Ameet Deshpande, and Karthik Narasimhan. Instructeval: Systematic evaluation of instruction selection methods. Anirudh Ajith, Chris Pan, Mengzhou Xia, arXiv:2307.00259202315arXiv preprint</p>
<p>Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory. Xizhou Zhu, Yuntao Chen, Chenxin Hao Tian, Weijie Tao, Chenyu Su, Gao Yang, Bin Huang, Lewei Li, Xiaogang Lu, Wang, arXiv:2305.1714420231522arXiv preprint</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, arXiv:2305.16291Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. 20231622arXiv preprint</p>
<p>Plan4mc: Skill reinforcement learning and planning for open-world minecraft tasks. Haoqi Yuan, Chi Zhang, Hongcheng Wang, Feiyang Xie, Penglin Cai, Hao Dong, Zongqing Lu, arXiv:2303.16563202316arXiv preprint</p>
<p>Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang, arXiv:2303.17580202316arXiv preprint</p>
<p>Self-rag: Learning to retrieve, generate, and critique through self-reflection. Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, Hannaneh Hajishirzi, arXiv:2310.11511202316arXiv preprint</p>
<p>Thought propagation: An analogical approach to complex reasoning with large language models. Junchi Yu, Ran He, Rex Ying, arXiv:2310.03965202316arXiv preprint</p>
<p>Skcoder: A sketch-based approach for automatic code generation. Jia Li, Yongmin Li, Ge Li, Zhi Jin, Yiyang Hao, Xing Hu, arXiv:2302.06144202316arXiv preprint</p>
<p>Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, Marco Tulio, Ribeiro , arXiv:2303.09014Automatic multi-step reasoning and tool-use for large language models. Art202316arXiv preprint</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 20203316</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of naacL-HLT. Jacob Devlin, Ming-Wei Chang, Kenton , Lee Kristina, Toutanova , naacL-HLT2019116</p>
<p>Toolcoder: Teach code generation models to use apis with search tools. Kechi Zhang, Ge Li, Jia Li, Zhuo Li, Zhi Jin, arXiv:2305.04032202317arXiv preprint</p>
<p>Craft: Customizing llms by creating and retrieving from specialized toolsets. Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R Fung, Hao Peng, Heng Ji, arXiv:2309.17428202317arXiv preprint</p>
<p>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou, arXiv:2305.17126Large language models as tool makers. 202317arXiv preprint</p>
<p>Toolink: Linking toolkit creation and using through chain-of-solving on open-source model. Chenyan Cheng Qian, Zhenghao Xiong, Zhiyuan Liu, Liu, arXiv:2310.05155202317arXiv preprint</p>
<p>Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B Tenenbaum, Leslie Pack Kaelbling, Michael Katz, arXiv:2305.11014Generalized planning in pddl domains with pretrained large language models. 202318arXiv preprint</p>
<p>Monte carlo tree search: A review of recent modifications and applications. Maciej Świechowski, Konrad Godlewski, Bartosz Sawicki, Jacek Mańdziuk, Artificial Intelligence Review. 563182023</p>
<p>Language agent tree search unifies reasoning acting and planning in language models. Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, Yu-Xiong Wang, arXiv:2310.04406202318arXiv preprint</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992Reasoning with language model is planning with world model. 20231823arXiv preprint</p>
<p>Dynamic planning with a llm. Frank Gautier Dagan, Alex Keller, Lascarides, arXiv:2308.06391202318arXiv preprint</p>
<p>Selfcollaboration code generation via chatgpt. Yihong Dong, Xue Jiang, Zhi Jin, Ge Li, arXiv:2304.07590202318arXiv preprint</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, arXiv:2307.07924Communicative agents for software development. 202318arXiv preprint</p>
<p>Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization. Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, Diyi Yang, arXiv:2310.02170202318arXiv preprint</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, arXiv:2303.17651202319arXiv preprint</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Shunyu Karthik R Narasimhan, Yao, Thirtyseventh Conference on Neural Information Processing Systems. 202319</p>
<p>Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning. Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, Lei Ma, arXiv:2308.13724202319arXiv preprint</p>
<p>Self-taught optimizer (stop): Recursively self-improving code generation. Eric Zelikman, Eliana Lorch, Lester Mackey, Adam Tauman, Kalai , arXiv:2310.02304202319arXiv preprint</p>
<p>Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, arXiv:1804.07461Glue: A multi-task benchmark and analysis platform for natural language understanding. 2018arXiv preprint</p>
<p>Superglue: A stickier benchmark for general-purpose language understanding systems. Advances in neural information processing systems. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel Bowman, 201932</p>
<p>Clue: A chinese language understanding evaluation benchmark. Liang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chenjie Cao, Yudong Li, Yechen Xu, Kai Sun, Dian Yu, Cong Yu, arXiv:2004.0598620202123arXiv preprint</p>
<p>Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, arXiv:2309.11998Eric Xing, et al. Lmsys-chat-1m: A largescale real-world llm conversation dataset. 2023arXiv preprint</p>
<p>Judging llm-as-ajudge with mt-bench and chatbot arena. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, arXiv:2306.0568520232123arXiv preprint</p>
<p>Longbench: A bilingual, multitask benchmark for long context understanding. Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li, arXiv:2308.145082023arXiv preprint</p>
<p>Chinese open instruction generalist: A preliminary release. Ge Zhang, Yemin Shi, Ruibo Liu, Ruibin Yuan, Yizhi Li, Siwei Dong, Yu Shu, Zhaoqun Li, Zekun Wang, Chenghua Lin, arXiv:2304.0798720232123arXiv preprint</p>
<p>Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Quoc V Dai, Le, arXiv:2109.01652Finetuned language models are zero-shot learners. 2021arXiv preprint</p>
<p>The flan collection: Designing data and methods for effective instruction tuning. Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Barret Quoc V Le, Jason Zoph, Wei, arXiv:2301.1368820232123arXiv preprint</p>
<p>Opt-iml: Scaling language model instruction meta learning through the lens of generalization. Srinivasan Iyer, Xi Victoria Lin, Ramakanth Pasunuru, Todor Mihaylov, Daniel Simig, Ping Yu, Kurt Shuster, Tianlu Wang, Qing Liu, Punit Singh Koura, arXiv:2212.120172022arXiv preprint</p>
<p>Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, arXiv:2204.07705Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. 2022arXiv preprint</p>
<p>Commonsenseqa: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, arXiv:1811.0093720182123arXiv preprint</p>
<p>Piqa: Reasoning about physical commonsense in natural language. Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202034</p>
<p>Maarten Sap, Derek Hannah Rashkin, Ronan Chen, Yejin Le-Bras, Choi, Socialiqa, arXiv:1904.09728Commonsense reasoning about social interactions. 2019arXiv preprint</p>
<p>Hellaswag: Can a machine really finish your sentence?. Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi, arXiv:1905.078302019arXiv preprint</p>
<p>An empirical study of instructiontuning large language models in chinese. Qingyi Si, Tong Wang, Zheng Lin, Xu Zhang, Yanan Cao, Weiping Wang, arXiv:2310.0732820232123arXiv preprint</p>
<p>From lsat: The progress and challenges of complex reasoning. Siyuan Wang, Zhongkun Liu, Wanjun Zhong, Ming Zhou, Zhongyu Wei, Zhumin Chen, Nan Duan, IEEE/ACM Transactions on Audio, Speech, and Language Processing. 30212022</p>
<p>Adina Williams, Nikita Nangia, Samuel R Bowman, arXiv:1704.05426A broad-coverage challenge corpus for sentence understanding through inference. 2017arXiv preprint</p>
<p>Diagnosing the first-order logical reasoning ability through logicnli. Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao He, Yaohui Jin, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2021</p>
<p>Natural language inference in context-investigating contextual reasoning over long texts. Hanmeng Liu, Leyang Cui, Jian Liu, Yue Zhang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>Reclor: A reading comprehension dataset requiring logical reasoning. Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng, arXiv:2002.043262020arXiv preprint</p>
<p>Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, Yue Zhang, arXiv:2007.081242020arXiv preprint</p>
<p>Logiqa 2.0-an improved dataset for logical reasoning in natural language understanding. Hanmeng Liu, Jian Liu, Leyang Cui, Zhiyang Teng, Nan Duan, Ming Zhou, Yue Zhang, Speech, and Language Processing. 2023</p>
<p>Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change. Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 20232123</p>
<p>Api-bank: A benchmark for tool-augmented llms. Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, Yongbin Li, arXiv:2304.082442023arXiv preprint</p>
<p>Tianjun Shishir G Patil, Xin Zhang, Joseph E Wang, Gonzalez, arXiv:2305.15334Gorilla: Large language model connected with massive apis. 20232123arXiv preprint</p>
<p>On the tool manipulation capability of open-source large language models. Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, Jian Zhang, arXiv:2305.1650420232123arXiv preprint</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, arXiv:2307.16789Facilitating large language models to master 16000+ real-world apis. 2023arXiv preprint</p>
<p>Program synthesis with large language models. Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, arXiv:2108.077322021arXiv preprint</p>
<p>Measuring coding challenge competence with apps. Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, arXiv:2105.099382021arXiv preprint</p>
<p>Multipl-e: a scalable and polyglot approach to benchmarking neural code generation. Federico Cassano, John Gouwar, Daniel Nguyen, Sydney Nguyen, Luna Phipps-Costin, Donald Pinckney, Ming-Ho Yee, Yangtian Zi, Carolyn Jane Anderson, Molly Q Feldman, IEEE Transactions on Software Engineering. 212023</p>
<p>Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, Lingming Zhang, arXiv:2305.012102023arXiv preprint</p>
<p>Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x. Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, arXiv:2303.175682023arXiv preprint</p>
<p>Codexglue: A machine learning benchmark dataset for code understanding and generation. Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, arXiv:2102.0466420212123arXiv preprint</p>
<p>Ming Zhu, Aneesh Jain, Karthik Suresh, Roshan Ravindran, Sindhu Tipirneni, Chandan K Reddy, arXiv:2206.08474Xlcost: A benchmark dataset for cross-lingual code intelligence. 2022arXiv preprint</p>
<p>Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro Von Werra, Shayne Longpre, arXiv:2308.07124Octopack: Instruction tuning code large language models. 2023arXiv preprint</p>
<p>Spoc: Search-based pseudocode to code. Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, Percy S Liang, Advances in Neural Information Processing Systems. 201932</p>
<p>Large language models empowered agent-based modeling and simulation: A survey and perspectives. Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, Fengli Xu, Yong Li, arXiv:2312.1197020232223arXiv preprint</p>
<p>Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, arXiv:2309.09971Emergent gaming interaction. 202322arXiv preprint</p>
<p>Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, Matthew Hausknecht, arXiv:2010.03768Alfworld: Aligning text and embodied environments for interactive learning. 2020arXiv preprint</p>
<p>Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, Gang Yu, arXiv:2312.13771Appagent: Multimodal agents as smartphone users. 202322arXiv preprint</p>
<p>Textworld: A learning environment for text-based games. Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud Adada, Computer Games: 7th Workshop, CGW 2018, Held in Conjunction with the 27th International Conference on Artificial Intelligence. Stockholm, Sweden2018. July 13. 2018Revised Selected Papers 7</p>
<p>Alfred: A benchmark for interpreting grounded instructions for everyday tasks. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, Dieter Fox, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition202022</p>
<p>Virtualhome: Simulating household activities via programs. Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, Antonio Torralba, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition201822</p>
<p>Dong Huang, Qingwen Bu, Heming Cui, arXiv:2308.08784Codecot and beyond: Learning to program and test like a developer. 202323arXiv preprint</p>
<p>Fernanda De, La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier, Llmr, arXiv:2309.12276Real-time prompting of interactive worlds using large language models. 202323arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>