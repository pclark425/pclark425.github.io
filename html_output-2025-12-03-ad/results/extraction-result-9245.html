<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9245 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9245</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9245</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-275789826</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2501.11960v2.pdf" target="_blank">TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks. Despite the growing adoption of embedding-based methods, their effectiveness and generalizability across diverse application scenarios remain under-explored. To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection. TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms. Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks. These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9245.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9245.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenAI-embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI text-embedding models (text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pretrained transformer-based embedding models from OpenAI used to convert text sequences into dense vectors; evaluated as input features for classical anomaly detectors across spam, fake-news, and offensive-language datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>O-ada / O-small / O-large</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (embedding-focused variants of large language models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified (embedding dims reported: O-ada 1536, O-small 1536, O-large 3072)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (token sequences; sentence/document-level text)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Email and SMS spam, social-media posts (COVID fake news), fact-checked statements (LIAR2), tweets (OLID, Hate-Speech)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Rare/outlier textual classes (spam, fake news, hateful/offensive posts)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Embedding-based scoring: compute dense sentence embeddings from OpenAI models, then feed embeddings to standard anomaly detectors (kNN, INNE, ECOD, COPOD, LOF, OCSVM, iForest, HBOS) to produce anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD (PyOD implementations)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC (Area Under ROC Curve), averaged over 5 runs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>OpenAI embeddings deliver the most robust/consistent performance across datasets. Reported highlights: O-ada with ECOD achieved AUROC=0.8822 on SMS-Spam; O-ada with kNN AUROC=0.7921 on LIAR2; O-large with COPOD AUROC=0.9639 on Email-Spam; O-large with kNN AUROC=0.9537 on COVID-Fake. Overall average AUROC across datasets and detectors reported in the paper is higher for OpenAI embeddings (typical aggregate averages cited in the paper in the ~0.67–0.72 range depending on detector).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>OpenAI embeddings generally outperform other embedding models evaluated (BERT, MiniLM, Llama, stella, Qwen) when combined with the same anomaly detectors; nearest-neighbor and ECOD/INNE detectors perform particularly well with these embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Despite strong performance on spam and some fake-news tasks, OpenAI embeddings still struggle on offensive-language and hate-speech datasets (AUCs rarely exceed ~0.6); detector performance depends on the downstream algorithm and hyperparameters; embedding-only approach cannot fully compensate for lack of external factual/contextual knowledge required for some fake-news and context-dependent anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>OpenAI embeddings achieved both strong surface-pattern detection (spam) and comparatively better handling of nuanced stylistic anomalies (some fake-news cases), making them the most versatile embedding family in this benchmark. Best detector pairings included kNN and INNE; ECOD is a strong lightweight choice for SMS spam with O-ada.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9245.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9245.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT (bert-base-uncased)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bidirectional transformer encoder used to extract contextualized sentence embeddings (pooled from last hidden states) and then passed to classical anomaly detectors for text anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (bert-base-uncased)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (bidirectional encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>110M parameters (reported in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (short messages, tweets, statements, emails)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Email/SMS spam, fake news, LIAR2 statements, tweets (OLID, Hate-Speech)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Rare/outlier textual classes (spam, fake news, offensive posts)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute sentence embeddings by pooling BERT's hidden states (attention-weighted mean of last hidden states constrained to valid tokens) and apply PyOD anomaly detectors to embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC averaged over 5 runs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>BERT shows weaker separation of anomalies in embedding space compared to top-performing models; anomalies often overlap with normal clusters in t-SNE visualizations and AUCs are generally lower (in many tasks AUC rarely exceeds ~0.7; poor performance particularly on offensive-language datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Per-paper comparisons show BERT underperforms compared to OpenAI embeddings and some other lightweight embeddings (e.g., MiniLM) on many tasks, especially spam where other models more easily separate anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>BERT embeddings often place anomalies within normal clusters (poor separation); less effective at capturing distinctive surface-level noise patterns used in spam; limited by token length/pooled representation choices.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Despite wide use in NLP, BERT's generic pooled embeddings may be suboptimal for embedding-based anomaly detection tasks in which surface irregularities or stylistic features (captured well by other embeddings) are primary anomaly signals.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9245.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9245.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MiniLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MiniLM (all-MiniLM-L6-v2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Lightweight transformer distilled model producing compact sentence embeddings; evaluated as a fast, low-cost alternative for embedding-based text anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MiniLM (all-MiniLM-L6-v2)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (distilled encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>~22.7M parameters (reported in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (email, SMS, tweets, statements)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Email/SMS spam, fake news, tweets (OLID, Hate-Speech), LIAR2</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Rare/outlier textual classes (spam, fake news, offensive posts)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Extract compact sentence embeddings using MiniLM, then feed embeddings to classical anomaly detectors (kNN, INNE, ECOD, etc.) for scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC, averaged over 5 runs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>MiniLM is extremely fast and achieves very strong performance on tasks with explicit surface patterns: examples include AUROC up to 0.9526 with INNE and 0.9626 with OCSVM on Email-Spam (reported in the paper). However, MiniLM's performance declines on context-rich tasks (OLID, LIAR2).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>On explicit-pattern tasks (spam), MiniLM performs comparably to or even on par with larger embeddings (OpenAI, Llama) while being much faster; on nuanced tasks it underperforms compared to OpenAI embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lacks consistency across complex datasets that require deeper contextual or domain knowledge; weaker on hate-speech/offensive detection and some fake-news cases.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Lightweight models like MiniLM can be efficient and effective for anomaly detection when anomalies rely on surface-level/structural patterns (URLs, gibberish, punctuation). This suggests model selection can be guided by task characteristics to trade off accuracy and compute cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9245.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9245.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama (Llama-3.2-1B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An auto-regressive large language model repurposed for embedding extraction by computing attention-weighted means over last hidden states; used as a dense text representation for downstream anomaly detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA (Llama-3.2-1B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (autoregressive decoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>~1.24B parameters (reported in paper), embedding dim reported ~2048</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (emails, SMS, tweets, statements)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Email/SMS spam, fake news, OLID, Hate-Speech, LIAR2</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Textual outliers/anomalies (spam, fake news, offensive posts)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Repurposed as embedding encoder by averaging attention-weighted last hidden states (restricted to max token length 512 in experiments), then apply classical anomaly detectors to embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC, averaged over 5 runs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Llama-based embeddings provide moderate performance; better than some older encoders on some datasets but not as consistent as OpenAI embeddings. Performance varies substantially by detector and dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Llama with tuned detectors (e.g., INNE after hyperparameter search) can approach competitive performance on some datasets but generally lags behind OpenAI embeddings in overall robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>In experiments LLAMA and Qwen were constrained to 512 tokens due to compute limits, preventing them from leveraging longer-context strengths for datasets with long texts (LIAR2, Hate-Speech). Also higher computational cost than small models.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>When computational constraints force truncation, autoregressive LLMs repurposed for embeddings may lose advantages tied to longer context windows; hyperparameter tuning of detectors (INNE in particular) can notably improve results for these embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9245.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9245.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen (Qwen2.5-1.5B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Auto-regressive language model used for embedding extraction (attention-weighted mean pooling) and evaluated for embedding-based text anomaly detection alongside other models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen (Qwen2.5-1.5B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (autoregressive decoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>~1.5B parameters (reported in paper), embedding dim reported ~1536</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (email, SMS, tweets, statements)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Email/SMS spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Textual outliers/anomalies (spam, fake news, offensive posts)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute sentence embeddings by attention-weighted pooling of last hidden states (truncated to 512 tokens), then apply classical anomaly detectors (kNN, INNE, ECOD, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC (5-run average)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Qwen shows moderate to mixed performance across datasets; competitive in some detectors but not consistently outperforming OpenAI embeddings. Qwen is computationally expensive (reported embedding time up to 745.85s on Email-Spam in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Performance similar to or slightly below top OpenAI embeddings; computational cost is substantially higher, reducing practical attractiveness for large-scale pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High inference time (very slow embedding extraction on some datasets); truncated context (512 tokens) due to experiment constraints reduces advantage on long-text datasets; inconsistent performance on context-sensitive anomaly tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Large autoregressive models can be repurposed for embeddings but practical benefits depend heavily on ability to use full context and on compute budget; without full-length context they may not surpass specialized embedding models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9245.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9245.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>stella</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>stella_en_400M_v5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distilled embedding model (stella) evaluated as a mid-sized alternative to both MiniLM and larger LLMs for embedding-based text anomaly detection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>stella_en_400M_v5</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (encoder-style distilled embedding model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>~400M parameters (reported in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (emails, SMS, tweets, statements)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Email/SMS spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Textual outliers/anomalies (spam, fake news, offensive posts)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Extract sentence embeddings using stella, then apply classical anomaly detectors (kNN, INNE, ECOD, etc.) to detect anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC averaged over 5 runs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>stella achieves moderate performance on several tasks; it can be competitive after detector hyperparameter tuning but does not match the overall robustness of OpenAI embeddings. The paper reports stella as excelling in a limited subset of tasks but inconsistent across the whole benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>stella outperforms some larger autoregressive embeddings in specific pairings (after tuning), but overall is less consistent than OpenAI family and sometimes lags behind MiniLM on spam tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Inconsistent performance across datasets that require broader contextual reasoning; benefits are dataset- and detector-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Mid-sized distilled embeddings like stella can be effective in certain detector pairings (notably with INNE after tuning), suggesting a middle-ground trade-off between compute and representational power.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AD-NLP <em>(Rating: 2)</em></li>
                <li>NLP-ADBench <em>(Rating: 2)</em></li>
                <li>AD-LLM <em>(Rating: 2)</em></li>
                <li>Isolation-based Nearest Neighbor Ensembles <em>(Rating: 2)</em></li>
                <li>New embedding models and api updates <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9245",
    "paper_id": "paper-275789826",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "OpenAI-embeddings",
            "name_full": "OpenAI text-embedding models (text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large)",
            "brief_description": "Pretrained transformer-based embedding models from OpenAI used to convert text sequences into dense vectors; evaluated as input features for classical anomaly detectors across spam, fake-news, and offensive-language datasets.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "O-ada / O-small / O-large",
            "model_type": "Transformer (embedding-focused variants of large language models)",
            "model_size": "not specified (embedding dims reported: O-ada 1536, O-small 1536, O-large 3072)",
            "data_type": "Text sequences (token sequences; sentence/document-level text)",
            "data_domain": "Email and SMS spam, social-media posts (COVID fake news), fact-checked statements (LIAR2), tweets (OLID, Hate-Speech)",
            "anomaly_type": "Rare/outlier textual classes (spam, fake news, hateful/offensive posts)",
            "method_description": "Embedding-based scoring: compute dense sentence embeddings from OpenAI models, then feed embeddings to standard anomaly detectors (kNN, INNE, ECOD, COPOD, LOF, OCSVM, iForest, HBOS) to produce anomaly scores.",
            "baseline_methods": "kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD (PyOD implementations)",
            "performance_metrics": "AUROC (Area Under ROC Curve), averaged over 5 runs",
            "performance_results": "OpenAI embeddings deliver the most robust/consistent performance across datasets. Reported highlights: O-ada with ECOD achieved AUROC=0.8822 on SMS-Spam; O-ada with kNN AUROC=0.7921 on LIAR2; O-large with COPOD AUROC=0.9639 on Email-Spam; O-large with kNN AUROC=0.9537 on COVID-Fake. Overall average AUROC across datasets and detectors reported in the paper is higher for OpenAI embeddings (typical aggregate averages cited in the paper in the ~0.67–0.72 range depending on detector).",
            "comparison_to_baseline": "OpenAI embeddings generally outperform other embedding models evaluated (BERT, MiniLM, Llama, stella, Qwen) when combined with the same anomaly detectors; nearest-neighbor and ECOD/INNE detectors perform particularly well with these embeddings.",
            "limitations_or_failure_cases": "Despite strong performance on spam and some fake-news tasks, OpenAI embeddings still struggle on offensive-language and hate-speech datasets (AUCs rarely exceed ~0.6); detector performance depends on the downstream algorithm and hyperparameters; embedding-only approach cannot fully compensate for lack of external factual/contextual knowledge required for some fake-news and context-dependent anomalies.",
            "unique_insights": "OpenAI embeddings achieved both strong surface-pattern detection (spam) and comparatively better handling of nuanced stylistic anomalies (some fake-news cases), making them the most versatile embedding family in this benchmark. Best detector pairings included kNN and INNE; ECOD is a strong lightweight choice for SMS spam with O-ada.",
            "uuid": "e9245.0",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "BERT",
            "name_full": "BERT (bert-base-uncased)",
            "brief_description": "Bidirectional transformer encoder used to extract contextualized sentence embeddings (pooled from last hidden states) and then passed to classical anomaly detectors for text anomaly detection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BERT (bert-base-uncased)",
            "model_type": "Transformer (bidirectional encoder)",
            "model_size": "110M parameters (reported in paper)",
            "data_type": "Text sequences (short messages, tweets, statements, emails)",
            "data_domain": "Email/SMS spam, fake news, LIAR2 statements, tweets (OLID, Hate-Speech)",
            "anomaly_type": "Rare/outlier textual classes (spam, fake news, offensive posts)",
            "method_description": "Compute sentence embeddings by pooling BERT's hidden states (attention-weighted mean of last hidden states constrained to valid tokens) and apply PyOD anomaly detectors to embeddings.",
            "baseline_methods": "kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD",
            "performance_metrics": "AUROC averaged over 5 runs",
            "performance_results": "BERT shows weaker separation of anomalies in embedding space compared to top-performing models; anomalies often overlap with normal clusters in t-SNE visualizations and AUCs are generally lower (in many tasks AUC rarely exceeds ~0.7; poor performance particularly on offensive-language datasets).",
            "comparison_to_baseline": "Per-paper comparisons show BERT underperforms compared to OpenAI embeddings and some other lightweight embeddings (e.g., MiniLM) on many tasks, especially spam where other models more easily separate anomalies.",
            "limitations_or_failure_cases": "BERT embeddings often place anomalies within normal clusters (poor separation); less effective at capturing distinctive surface-level noise patterns used in spam; limited by token length/pooled representation choices.",
            "unique_insights": "Despite wide use in NLP, BERT's generic pooled embeddings may be suboptimal for embedding-based anomaly detection tasks in which surface irregularities or stylistic features (captured well by other embeddings) are primary anomaly signals.",
            "uuid": "e9245.1",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "MiniLM",
            "name_full": "MiniLM (all-MiniLM-L6-v2)",
            "brief_description": "Lightweight transformer distilled model producing compact sentence embeddings; evaluated as a fast, low-cost alternative for embedding-based text anomaly detection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "MiniLM (all-MiniLM-L6-v2)",
            "model_type": "Transformer (distilled encoder)",
            "model_size": "~22.7M parameters (reported in paper)",
            "data_type": "Text sequences (email, SMS, tweets, statements)",
            "data_domain": "Email/SMS spam, fake news, tweets (OLID, Hate-Speech), LIAR2",
            "anomaly_type": "Rare/outlier textual classes (spam, fake news, offensive posts)",
            "method_description": "Extract compact sentence embeddings using MiniLM, then feed embeddings to classical anomaly detectors (kNN, INNE, ECOD, etc.) for scoring.",
            "baseline_methods": "kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD",
            "performance_metrics": "AUROC, averaged over 5 runs",
            "performance_results": "MiniLM is extremely fast and achieves very strong performance on tasks with explicit surface patterns: examples include AUROC up to 0.9526 with INNE and 0.9626 with OCSVM on Email-Spam (reported in the paper). However, MiniLM's performance declines on context-rich tasks (OLID, LIAR2).",
            "comparison_to_baseline": "On explicit-pattern tasks (spam), MiniLM performs comparably to or even on par with larger embeddings (OpenAI, Llama) while being much faster; on nuanced tasks it underperforms compared to OpenAI embeddings.",
            "limitations_or_failure_cases": "Lacks consistency across complex datasets that require deeper contextual or domain knowledge; weaker on hate-speech/offensive detection and some fake-news cases.",
            "unique_insights": "Lightweight models like MiniLM can be efficient and effective for anomaly detection when anomalies rely on surface-level/structural patterns (URLs, gibberish, punctuation). This suggests model selection can be guided by task characteristics to trade off accuracy and compute cost.",
            "uuid": "e9245.2",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Llama",
            "name_full": "Llama (Llama-3.2-1B)",
            "brief_description": "An auto-regressive large language model repurposed for embedding extraction by computing attention-weighted means over last hidden states; used as a dense text representation for downstream anomaly detectors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA (Llama-3.2-1B)",
            "model_type": "Transformer (autoregressive decoder)",
            "model_size": "~1.24B parameters (reported in paper), embedding dim reported ~2048",
            "data_type": "Text sequences (emails, SMS, tweets, statements)",
            "data_domain": "Email/SMS spam, fake news, OLID, Hate-Speech, LIAR2",
            "anomaly_type": "Textual outliers/anomalies (spam, fake news, offensive posts)",
            "method_description": "Repurposed as embedding encoder by averaging attention-weighted last hidden states (restricted to max token length 512 in experiments), then apply classical anomaly detectors to embeddings.",
            "baseline_methods": "kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD",
            "performance_metrics": "AUROC, averaged over 5 runs",
            "performance_results": "Llama-based embeddings provide moderate performance; better than some older encoders on some datasets but not as consistent as OpenAI embeddings. Performance varies substantially by detector and dataset.",
            "comparison_to_baseline": "Llama with tuned detectors (e.g., INNE after hyperparameter search) can approach competitive performance on some datasets but generally lags behind OpenAI embeddings in overall robustness.",
            "limitations_or_failure_cases": "In experiments LLAMA and Qwen were constrained to 512 tokens due to compute limits, preventing them from leveraging longer-context strengths for datasets with long texts (LIAR2, Hate-Speech). Also higher computational cost than small models.",
            "unique_insights": "When computational constraints force truncation, autoregressive LLMs repurposed for embeddings may lose advantages tied to longer context windows; hyperparameter tuning of detectors (INNE in particular) can notably improve results for these embeddings.",
            "uuid": "e9245.3",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Qwen",
            "name_full": "Qwen (Qwen2.5-1.5B)",
            "brief_description": "Auto-regressive language model used for embedding extraction (attention-weighted mean pooling) and evaluated for embedding-based text anomaly detection alongside other models.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Qwen (Qwen2.5-1.5B)",
            "model_type": "Transformer (autoregressive decoder)",
            "model_size": "~1.5B parameters (reported in paper), embedding dim reported ~1536",
            "data_type": "Text sequences (email, SMS, tweets, statements)",
            "data_domain": "Email/SMS spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "anomaly_type": "Textual outliers/anomalies (spam, fake news, offensive posts)",
            "method_description": "Compute sentence embeddings by attention-weighted pooling of last hidden states (truncated to 512 tokens), then apply classical anomaly detectors (kNN, INNE, ECOD, etc.).",
            "baseline_methods": "kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD",
            "performance_metrics": "AUROC (5-run average)",
            "performance_results": "Qwen shows moderate to mixed performance across datasets; competitive in some detectors but not consistently outperforming OpenAI embeddings. Qwen is computationally expensive (reported embedding time up to 745.85s on Email-Spam in the paper).",
            "comparison_to_baseline": "Performance similar to or slightly below top OpenAI embeddings; computational cost is substantially higher, reducing practical attractiveness for large-scale pipelines.",
            "limitations_or_failure_cases": "High inference time (very slow embedding extraction on some datasets); truncated context (512 tokens) due to experiment constraints reduces advantage on long-text datasets; inconsistent performance on context-sensitive anomaly tasks.",
            "unique_insights": "Large autoregressive models can be repurposed for embeddings but practical benefits depend heavily on ability to use full context and on compute budget; without full-length context they may not surpass specialized embedding models.",
            "uuid": "e9245.4",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "stella",
            "name_full": "stella_en_400M_v5",
            "brief_description": "A distilled embedding model (stella) evaluated as a mid-sized alternative to both MiniLM and larger LLMs for embedding-based text anomaly detection tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "stella_en_400M_v5",
            "model_type": "Transformer (encoder-style distilled embedding model)",
            "model_size": "~400M parameters (reported in paper)",
            "data_type": "Text sequences (emails, SMS, tweets, statements)",
            "data_domain": "Email/SMS spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "anomaly_type": "Textual outliers/anomalies (spam, fake news, offensive posts)",
            "method_description": "Extract sentence embeddings using stella, then apply classical anomaly detectors (kNN, INNE, ECOD, etc.) to detect anomalies.",
            "baseline_methods": "kNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS, COPOD",
            "performance_metrics": "AUROC averaged over 5 runs",
            "performance_results": "stella achieves moderate performance on several tasks; it can be competitive after detector hyperparameter tuning but does not match the overall robustness of OpenAI embeddings. The paper reports stella as excelling in a limited subset of tasks but inconsistent across the whole benchmark.",
            "comparison_to_baseline": "stella outperforms some larger autoregressive embeddings in specific pairings (after tuning), but overall is less consistent than OpenAI family and sometimes lags behind MiniLM on spam tasks.",
            "limitations_or_failure_cases": "Inconsistent performance across datasets that require broader contextual reasoning; benefits are dataset- and detector-dependent.",
            "unique_insights": "Mid-sized distilled embeddings like stella can be effective in certain detector pairings (notably with INNE after tuning), suggesting a middle-ground trade-off between compute and representational power.",
            "uuid": "e9245.5",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AD-NLP",
            "rating": 2
        },
        {
            "paper_title": "NLP-ADBench",
            "rating": 2,
            "sanitized_title": "nlpadbench"
        },
        {
            "paper_title": "AD-LLM",
            "rating": 2
        },
        {
            "paper_title": "Isolation-based Nearest Neighbor Ensembles",
            "rating": 2,
            "sanitized_title": "isolationbased_nearest_neighbor_ensembles"
        },
        {
            "paper_title": "New embedding models and api updates",
            "rating": 1,
            "sanitized_title": "new_embedding_models_and_api_updates"
        }
    ],
    "cost": 0.014782999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</p>
<p>Yang Cao 
School of Computing and Information Technology
Great Bay University
China</p>
<p>Great Bay Institute for Advanced Study
Great Bay University
China</p>
<p>Tsinghua Shenzhen International Graduate School
Tsinghua University
China</p>
<p>Sikun Yang 
Chen Li 
School of Computing and Information Technology
Great Bay University
China</p>
<p>Great Bay Institute for Advanced Study
Great Bay University
China</p>
<p>D3 Center
Osaka University
Japan</p>
<p>Haolong Xiang 
School of Software
Nanjing University of Information Science and Technology
China</p>
<p>Lianyong Qi 
College of Computer Science
Technology China University of Petroleum</p>
<p>Bo Liu 
College of Cyberspace Security
Zhengzhou University
China</p>
<p>Rongsheng Li 
School of Computer
Harbin Engineering University
China</p>
<p>Ming Liu 
School of IT
Deakin University
Australia</p>
<p>East China), China</p>
<p>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection
0D7BB3D61519F9970B37A23F2C7AABD9
Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks.Despite the growing adoption of embeddingbased methods, their effectiveness and generalizability across diverse application scenarios remain insufficiently explored.To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection.TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms.Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks.These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.All the code are available at https://anonymous.4open.science/r/TAD-Bench-B4C6/.</p>
<p>Introduction</p>
<p>Anomaly detection (AD) is a critical task in machine learning, widely applied in fraud detection and content moderation to user behavior analysis (Pang et al., 2021).Within natural language processing (NLP), anomaly detection has become increasingly relevant for identifying outliers such as harmful content, phishing attempts, and spam reviews.However, while AD tasks in structured data (e.g., tabular, time series, graphs) (Steinbuss and Böhm, 2021;Blázquez-García et al., 2021;Qiao et al., 2024) have been extensively studied, anomaly detection in the unstructured and highdimensional domain of text remains underexplored.</p>
<p>The inherent complexity of textual data, driven by its diverse syntactic, semantic, and pragmatic structures, presents significant challenges for robust and reliable anomaly detection.</p>
<p>The rise of deep learning and transformer-based models has revolutionized NLP, enabling the development of contextualized embeddings that encode rich semantic and syntactic information.Techniques such as BERT (Devlin et al., 2019) and OpenAI's text-embedding models (OpenAI, 2024) have demonstrated remarkable success across a wide range of NLP tasks, offering dense, highdimensional representations that effectively capture linguistic nuances.These embeddings have become a cornerstone for many downstream tasks, providing powerful tools for applications such as text classification (da Costa et al., 2023) and retrieval (Zhu et al., 2023).Their ability to generalize across tasks and domains positions them as a promising foundation for complex challenges, including anomaly detection.gained significant attention in anomaly detection tasks due to their ability to capture semantic and contextual nuances in data (Wang et al., 2024).These methods typically involve two key stages: 1) extracting high-dimensional representations from textual data using pre-trained language models, which encode rich contextual and semantic features.Figure 1 demonstrates the anomaly distribution of SMS_Spam dataset embedding extracted from Ope-nAI model.2) Applying specialized algorithms to identify anomalies based on these embeddings.The embeddings serve as a compact and expressive feature space, enabling downstream algorithms to efficiently identify deviations or outliers.Figure 2 shows the steps involved in embedding-based anomaly detection.</p>
<p>Recent efforts, such as AD-NLP (Bejan et al., 2023), TAD (Xu et al., 2023) and NLP-ADBench (Li et al., 2024), have significantly advanced anomaly detection in NLP.AD-NLP (Bejan et al., 2023) finds that semantic and stylistic anomalies are easier to detect than those partially dependent on text; TAD (Xu et al., 2023) shows the effectiveness of embedding-based methods on multi language applications; NLP-ADBench (Li et al., 2024) reveals that no single model performs best across all datasets and high-dimensional embeddings improve detection.However, they only use a few embedding models, none of them explore the impact of embeddings quality to anomaly detection performance and tradeoffs between embedding models and anomaly detectors, raising questions about generalization capabilities of embedding-based methods in complex, real-world scenarios.</p>
<p>Our work aims to move beyond simply filling these gaps, by systematically exploring the following questions: 1) What types of tasks are LLMs (Large Language Models) embeddings paired with anomaly detectors most suitable for, and where do they face limitations?2) Which embedding methods consistently excel across different anomaly detection tasks? 3) Which anomaly detection algorithms perform robustly across various embeddings and tasks?</p>
<p>In this work, we introduce TAD-Bench, a novel benchmark specifically designed for text anomaly detection.Our objective is to enable a more comprehensive and systematic evaluation of state-ofthe-art embeddings, anomaly detection techniques, and their various combinations, offering valuable insights for a broad spectrum of NLP applications.The main contributions of this work are summa-rized as follows:</p>
<p>• Propose TAD-Bench, a benchmark integrating diverse datasets for text anomaly detection across domains such as spam, fake news, and offensive language.</p>
<p>• Conduct a systematic evaluation of LLMbased embeddings and anomaly detection algorithms, revealing their relative strengths and weaknesses.</p>
<p>• Provide insights into effective embeddingdetector configurations for improving robustness and generalizability in NLP anomaly detection tasks.</p>
<p>The key insights of TAD-Bench have been summarized as follows: 1) The effectiveness of embedding models varies significantly by task type: they can extract meaningful embeddings on tasks with explicit patterns (e.g.email spam with gibberish text) but struggle with context-dependent anomalies (e.g.offensive language).2) Among different detection algorithms applied to various embeddings, there are significant performance differences, but with default parameters, nearestneighbor-based methods including kNN and INNE show better robustness.3) Clustering patterns in embedding spaces reveal that spam anomalies form distinct, compact clusters, whereas hate speech and offensive language anomalies are scattered among normal instances, explaining why detection performance varies across domains despite using the same embedding-detector combinations.4) On texts with explicit linguistic patterns like email spam, lightweight embedding models (MINILM) perform comparably to larger models (e.g.OpenAI, Llama), suggesting efficient model selection based on task characteristics.</p>
<p>Related Work</p>
<p>Text representations</p>
<p>Early methods like TF-IDF (Term Frequency-Inverse Document Frequency) (Salton and Buckley, 1988) represented text in sparse vector spaces by measuring word importance relative to a corpus.While interpretable and computationally efficient, TF-IDF could not capture semantic relationships between words.Later, dense embeddings such as Word2Vec (Word to Vector) (Mikolov, 2013) and GloVe (Global Vectors for Word Representation) (Pennington et al., 2014) addressed this lim- itation by mapping words into continuous vector spaces based on their co-occurrence patterns in large corpora.However, these embeddings were static, assigning the same vector to a word regardless of its context.</p>
<p>To overcome the limitations of static embeddings, contextualized embeddings were introduced, with models like ELMo (Embeddings from Language Models) (Peters et al., 2018) producing word representations that vary based on context.This innovation was further advanced by transformer-based models like BERT (Bidirectional Encoder Representations from Transformers) (Devlin et al., 2019), which used bidirectional attention mechanisms to simultaneously capture left and right context.BERT set new benchmarks in NLP and inspired numerous improvements, including RoBERTa (Robustly Optimized BERT Approach) (Zhuang et al., 2021) and ALBERT (A Lite BERT) (Lan et al., 2020).</p>
<p>More recently, large language models such as GPT (Generative Pre-trained Transformer (Brown et al., 2020) have significantly advanced the capabilities of embedding methods.These models, trained on massive and diverse datasets, generate highly expressive embeddings that capture both deep semantic relationships and rich generative properties of text.LLMs have exhibited unprecedented performance across a broad spectrum of NLP tasks, solidifying their role as dominant tools for text representation in numerous applications, including anomaly detection, information retrieval, and text generation.</p>
<p>Anomaly Detection</p>
<p>Distance-based methods, such as kNN (k-Nearest Neighbors) (Ramaswamy et al., 2000), identify anomalies by measuring the distance of a given data point to its nearest neighbors.Points that are far from their neighbors are considered anomalous.These methods are intuitive and straightforward but suffer from the curse of dimensionality in highdimensional spaces, where distances lose their discriminative power, reducing their effectiveness.</p>
<p>Density-based methods identify points with significantly lower local density compared to their surroundings as anomaly.LOF (Local Outlier Factor) (Breunig et al., 2000) measures the local density of a point relative to its neighbors.HBOS (Histogram-Based Outlier Score) (Goldstein and Dengel, 2012) estimates densities using histograms for individual features.</p>
<p>Isolation-based methods assume anomalies are rare and different, iForest (Isolation Forest) (Liu et al., 2008(Liu et al., , 2012)), detect anomalies by recursively partitioning the feature space where anomalies require fewer partitions than normal points.Improved techniques, such as iNNE (Isolation-based Nearest Neighbor Ensembles) (Bandaragoda et al., 2018), use hypersphere to partition data space and assigns larger hyperspheres to anomalies, improving robustness in detecting local anomalies.</p>
<p>Probabilistic and statistical methods identify anomalies based on deviations from the data distribution.These approaches assume that normal instances follow a certain statistical pattern, and anomalies appear as outliers that do not conform to this pattern.ECOD (Empirical Cumulative Distribution Function-based Outlier Detection) (Li et al., 2022) uses cumulative distribution functions for efficient anomaly scoring, while COPOD (Copula-Based Outlier Detection) (Li et al., 2020) leverages copulas to model feature dependencies, handling multivariate data effectively.Projection-based methods, such as OCSVM (One-Class SVM) (Schölkopf et al., 2001), separate normal and anomalous data by learning a decision boundary in a high-dimensional feature space.(Ruff et al., 2018) and LUNAR (Unifying Local Outlier Detection Methods via Graph Neural Networks) (Goodge et al., 2022) capture nonlinear patterns but require substantial data and computational resources.</p>
<p>3 Benchmark Settings</p>
<p>Datasets</p>
<p>The scarcity of dedicated datasets poses a challenge to the development and evaluation of effective anomaly detection methods in NLP.To address this gap, we curated and transformed 6 existing classification datasets from three common NLP domains: spam detection, fake news detection, and offensive language detection.By incorporating datasets from diverse domains, our benchmark facilitates a comprehensive evaluation of embeddingbased anomaly detection methods across various NLP tasks.</p>
<p>Anomalies, as defined in our problem, are inherently rare.However, due to the lack of dedicated datasets for text anomaly detection, we adapted classification datasets by designating specific classes as anomalies and down-sampling them to simulate realistic anomaly rates (Li et al., 2024).For each dataset, the anomaly rate was set to approximately 3%, reflecting the typical rarity of anomalies in real-world scenarios.</p>
<p>While some studies treat anomaly detection as novelty detection-assuming only normal instances in training (e.g., NLP-ADBench (Li et al., 2024)).TAD-Bench removes this constraint and directly utilizes all available data for anomaly detection.Additionally, we retain the original text without extra pre-processing, as any token, word, or symbol may carry critical information indicative of an anomaly.This approach preserves linguis-tic, structural, and contextual features essential for detecting anomalies.Table 1 presents the statistics of the six pre-processed datasets used in this benchmark, including Email-Spam (Metsis et al., 2006), SMS-Spam(Almeida et al., 2011), COVID-Fake(Das et al., 2021), LIAR2 (Xu and Kechadi, 2024), OLID (Zampieri et al., 2019a), and Hate-Speech (Davidson et al., 2017).</p>
<p>Embedding Models</p>
<p>To extract high-quality embeddings from the datasets, 8 embedding models were utilized.These include BERT (bert-base-uncased) (Devlin et al., 2019), MiniLM (all-MiniLM-L6-v2) (Wang et al., 2020), LLAMA (Llama-3.2-1B),stella (stella_en_400M_v5) (Zhang et al., 2024), and Qwen (Qwen2.5-1.5B)(Yang et al., 2024a;Team, 2024) from the HuggingFace platform, as well as OpenAI-provided models: O-ada (text-embeddingada-002), O-small (text-embedding-3-small), and O-large (text-embedding-3-large) (OpenAI, 2024).All these models are based on the Transformer architecture, which has become the standard for representation learning in NLP tasks.The OpenAI models (O-ada, O-small, O-large) are specifically designed for embedding generation, offering embeddings with varying levels of granularity.On the other hand, LLAMA and Qwen are primarily auto-regressive language models optimized for text generation.In this paper, we repurposed these models for embedding extraction by computing the attention-weighted mean of their last hidden states, ensuring that only valid tokens contribute to the final sentence embeddings.</p>
<p>Notably, LLAMA and Qwen were constrained to a maximum token length of 512 tokens, same as BERT, due to computational resource limitations.Other models, such as MiniLM, Stella, and the OpenAI embeddings, utilized automatic truncation to process longer input sequences.This limitation may restrict LLAMA and Qwen's ability to fully leverage their extended context capabilities, particularly for datasets with longer text instances, such as LIAR2 and Hate-Speech.However, this unified token length ensures a fair comparison of runtime efficiency across models under consistent experimental conditions.It also highlights the trade-offs between computational cost and embedding quality, particularly when resource constraints are a factor in model deployment.</p>
<p>Anomaly Detectors</p>
<p>The embeddings derived from these models were subsequently used as input features for anomaly detection algorithms.To identify anomalous instances, we employed 8 anomaly detection methods sourced from the PyOD library1 (Zhao et al., 2019).These algorithms include KNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS and COPOD .These algorithms were selected to capture diverse anomaly detection paradigms, ensuring robust detection across datasets with varying characteristics, structures, and distributions.</p>
<p>For reproducibility and consistency, we implemented all algorithms using their default hyperparameter settings as specified in their original implementations and research papers.This approach minimizes subjective bias and enables fair comparison across different embedding models.Additionally, we conducted comprehensive grid search for optimal hyperparameter configurations, with search ranges detailed in Table 4.By evaluating both default and optimized settings across our diverse collection of embedding models and detection algorithms, we provide a thorough assessment of text anomaly detection performance in terms of both computational efficiency and detection effectiveness.</p>
<p>Evaluation Criteria and Trials</p>
<p>Performance was evaluated using the Area Under the Receiver Operating Characteristic Curve (AU-ROC), a widely adopted metric in anomaly detection tasks for measuring the trade-off between true positive and false positive rates.To ensure the reliability and robustness of the results, each experiment was repeated 5 times, and the average AUROC score was reported.</p>
<p>Experiments</p>
<p>Domain Generalization</p>
<p>Table 5 summarizes the performance of various anomaly detectors combined with LLM-derived embeddings across different datasets, while Figure 1 highlights their strong performance in specific tasks, particularly spam detection.In both the email spam and SMS spam detection tasks (Figure 5a and Figure 5d, many embedding-detector combinations achieve high AUC scores, with several exceeding 0.8.This strong performance can be attributed to the explicit nature of spam-related features, such as the presence of URLs, nonsensical text, or repetitive patterns.An example Case 1 from the Email Spam dataset is shown below:</p>
<p>Case 1: Subject: oxyccontttin no script needeeed your place to ggo too for all ur prreexxxxiscrlpt 10 n pi sx , paaaaain killerzxss noeoo presscippt http : / / hyyydroccodeeeine vicccodinne / vic geeet reeeliefff noowee http : / / offfmeebabyy Figure 3 shows that case 1 is located at the edge of the embedding space and deviates from the main data distribution, thus making it easy to be detected.</p>
<p>These features are effectively represented in the semantic spaces created by general-purpose embeddings, enabling anomaly detectors to distinguish spam messages from legitimate ones.Additionally, the relatively small variance in detection performance across embeddings suggests that spam detection primarily relies on surface-level linguistic patterns, which are effectively captured by the embeddings employed in this study.</p>
<p>For fake news detection, the results indicate a more mixed performance across datasets.On the Covid Fake News dataset (Figure 5b, multiple embedding-detector combinations achieve AUC scores close to or exceeding 0.8, suggesting that these methods are capable of identifying subtle stylistic and linguistic differences between fake and real news.These differences may include deviations in tone, phrasing, or structural composition of the text.However, on the LIAR2 dataset (Figure 5e, the AUC scores exhibit much greater variability across different combinations of embeddings and detectors.This variability likely stems from the greater factual complexity of the LIAR2 dataset, where detecting anomalies may require external knowledge or sophisticated reasoning that is not inherently encoded within the embeddings.Despite this variability, the relatively strong performance on the Covid Fake News dataset underscores the potential of embedding-based approaches for fake news detection, particularly when the anomalies are stylistic or linguistic in nature.</p>
<p>In contrast, the performance on hate speech and offensive language detection tasks (Figure 5c and Figure 5f) is consistently weaker, with AUC scores rarely exceeding 0.6 across embeddingdetector combinations.This suggests that the embeddings struggle to capture the nuanced and context-dependent features necessary for these tasks.For instance, hate speech often relies on implicit cues such as sarcasm, cultural references, or subtle forms of hostility, which may not be fully captured by standard embeddings.Similarly, offensive language detection, as observed in the OLID dataset, requires identifying fine-grained differences in tone, intent, and subjectivity, such as distinguishing between neutral, offensive, and sarcastic expressions.These distinctions often depend on broader contextual information, such as the discourse or dialogue in which the language appears.For example, without additional context, such as the speaker's intent or the conversational background, the following statement from OLID dataset remains ambiguous whether this statement qualifies as hate speech:</p>
<p>Case 2: @USER #metoo are all racist! Figure 4 shows that case 2 is mixed in the normal data distribution, making it difficult to be detected.</p>
<p>Comparative Effectiveness of Embeddings in Anomaly Detection</p>
<p>The results in In comparison, other embeddings, such as MINILM, exhibit strong performance in specific tasks but lack consistency across more complex datasets.For instance, MINILM achieves exceptional AUC scores of 0.9526 and 0.9626 on the Email Spam datasets when paired with INNE and OCSVM, respectively.However, its performance declines significantly on datasets like OLID and LIAR2, suggesting limitations in capturing deeper contextual or domain-specific cues essential for these tasks.Similarly, embeddings such as stella and Qwen exhibit moderate performance, excelling in a limited subset of tasks but failing to match the versatility of OpenAI embeddings.Their inconsistent performance across datasets indicates that while they may effectively capture certain linguistic patterns, they struggle with tasks requiring a broader understanding of context, intent, or nuanced semantics.</p>
<p>These observations suggest that OpenAI embeddings, deliver the most robust and consistent performance across a diverse set of tasks.Their ability to effectively capture both explicit textual features (e.g., in spam detection) and nuanced contextual variations (e.g., in Covid Fake News and OLID) highlights their versatility.This underscores their suitability for anomaly detection scenarios that demand both surface-level pattern recognition and deeper linguistic comprehension, making them well-equipped for handling a wide range of textbased anomalies.</p>
<p>Performance Across Anomaly Detectors</p>
<p>To evaluate the robustness of anomaly detection algorithms across various embeddings and tasks, we analyze their average rankings using OpenAI embeddings (O-ada, O-small, and O-large) as representative examples (Figure 6).These embeddings were selected based on their strong and consistent performance across datasets, as demonstrated in Section 4.2.The rankings provide insight into which detection algorithms perform reliably regardless of the embedding or task.This indicates their robustness and adaptability to the semantic structures of LLM-derived embeddings.kNN, in particular, excels due to its ability to effectively model local density variations in feature space, making it well-suited for both explicitpattern tasks like spam detection and nuanced tasks like fake news and hate speech detection.INNE, with its efficiency and strong generalization capabilities, complements kNN as a reliable alternative in diverse anomaly detection scenarios.</p>
<p>ECOD also ranks highly, consistently appearing among the top three detectors across embeddings.Its lightweight design and ability to estimate density-based anomalies make it a strong candidate for scenarios where computational efficiency is critical.On the other hand, methods like LOF, COPOD, and iForest consistently rank lower, highlighting their limitations in high-dimensional and semantically complex embedding spaces.These methods struggle with noise, data sparsity, and the nuanced patterns encoded in LLM embeddings, which limits their effectiveness across diverse tasks.</p>
<p>Conclusion</p>
<p>In this paper, we present a comprehensive benchmark for embedding-based text anomaly detection, systematically evaluating the interplay between LLM embeddings and classical anomaly detection algorithms across three diverse domains.Our results reveal both the strengths and limitations of embedding-based anomaly detection methods, demonstrating their effectiveness in tasks with explicit and well-defined patterns while highlighting challenges in capturing implicit, context-dependent anomalies that require broader contextual cues.These findings emphasize the need for more adaptive embeddings and hybrid detection strategies that integrate external knowledge and contextual reasoning.</p>
<p>Limitations</p>
<p>TAD-Bench evaluates anomaly detection across three domains: spam detection, fake news detection, and offensive language detection.While these tasks provide diverse and relevant benchmarks, they do not fully capture the complexity of realworld applications.Strong performance in spam detection highlights the ability of LLM embeddings to capture explicit patterns, while mixed results in fake news detection and poor performance in offensive language detection reveal their limitations in modeling implicit, context-sensitive cues.Expanding to domains like medical, financial, or legal texts that involve unique challenges, and exploring datasets with more implicit anomalies, could better evaluate the adaptability and robustness of these methods.</p>
<p>Moreover, TAD-Bench focuses solely on embedding-based methods, excluding end-to-end approaches that directly process raw text because due to modularity and efficiency of embeddingbased methods, and NLP-ADBench has also shown better performance of embedding-based methods than end-to-end methods.However, end-to-end models like autoencoders or transformer-based methods may capture richer contextual information and handle more complex anomalies.Future work should incorporate end-to-end models and explore hybrid approaches that combine the strengths of both paradigms, providing a more comprehensive evaluation of anomaly detection methods in NLP.</p>
<p>Ethic Statement</p>
<p>This study adheres to ethical research practices and considerations in the development and evaluation of text anomaly detection methods.</p>
<p>Use of Potentially Offensive Language.Some examples in this paper may contain offensive, harmful, or misleading language.These examples are used purely for illustrative purposes to demonstrate the challenges of text anomaly detection in realworld scenarios.They do not reflect the opinions, beliefs, or endorsements of the authors.</p>
<p>Data Sources and Usage.All datasets used in this study are sourced from publicly available research datasets that have been previously used in NLP and anomaly detection research.Proper citations and references to the original datasets are provided in the paper.No private, proprietary, or personally identifiable information was used in this study.</p>
<p>Risks and Responsible Use.Because anomaly detection models can be misused for purposes such as censorship, surveillance, or unfair content moderation.We strongly emphasize that our benchmark is intended for research and academic purposes only and should be used responsibly with consideration of ethical and societal implications.</p>
<p>Use of AI Assistance We acknowledge the use of AI-based writing assistants for grammar refinement, spelling correction, and improving the clarity of our manuscript.However, all intellectual contributions, experimental designs, analyses, and conclusions in this paper are solely the work of the authors.</p>
<p>A Problem Definitions</p>
<p>Let D = {x 1 , x 2 , . . ., x N } represent a corpus consisting of N textual instances, where each instance x i ∈ X is represented as a sequence of tokens:
x i = [t 1 , t 2 , . . . , t L i ],
where L i denotes the sequence length of x i .The goal of text anomaly detection is to identify a subset of instances D anomaly ⊂ D, such that D anomaly contains samples that deviate significantly from the majority of the dataset D normal = D \ D anomaly .</p>
<p>To achieve this, an anomaly detection algorithm g is applied to the representations of the textual instances to identify potential anomalies.</p>
<p>(1) Each text instance x i is first mapped to a fixeddimensional vector z i ∈ R d using an embedding model ϕ :
X → R d , such that z i = ϕ(x i ).
(2) The anomaly detection algorithm then assigns an anomaly score s i = g(z i ) to each instance, s i ∈ [0, 1].Based on a predefined threshold τ , an instance x i is classified as anomalous if:
x i ∈ D anomaly ⇐⇒ s i ≥ τ.
The objective of text anomaly detection is to ensure that g effectively distinguishes between normal and anomalous instances, even in the absence of labeled data, while being robust to the inherent variability and high dimensionality of textual data.</p>
<p>B Clarification Between Anomaly and Novelty Detection</p>
<p>Text Anomaly Detection (TAD), as defined in Section A, focuses on identifying instances that deviate significantly from the majority of a dataset, regardless of whether anomalies are present during training.While some prior studies (e.g., AD-NLP (Bejan et al., 2023), NLP-ADBench (Li et al., 2024) and AD-LLM (Yang et al., 2024b)) assume training data contains only normal instances and testing data includes both normal and anomalous samples, this setup aligns more closely with novelty detection (Pimentel et al., 2014).Novelty detection specifically targets never-before-seen anomalies that are absent from the training phase, often treating anomalies as entirely novel classes.In contrast, our benchmark evaluates a broader spectrum of anomaly detection scenarios.We do not restrict the training data to purely normal instances, allowing for potential partial supervision or contaminated training sets (e.g., realistic scenarios where anomalies may unintentionally exist in training data).This setup reflects real-world applications where anomaly types are not always fully known a prior, and detection systems must generalize across domains and anomaly types.</p>
<p>This distinction underscores our goal of advancing generalizable anomaly detection systems for real-world NLP applications, where anomalies may exhibit both explicit and context-dependent patterns.</p>
<p>C Datasets</p>
<p>Email-Spam2 (Metsis et al., 2006) contains 5,171 emails labeled as spam or ham, with spam treated as the anomaly class.We utilized the preprocessed version provided in (Li et al., 2024).</p>
<p>SMS-Spam3 (Almeida et al., 2011) comprises 5,574 SMS messages originally labeled as spam or ham.Spam messages are designated as the anomaly.</p>
<p>COVID-Fake4 (Das et al., 2021) comprises posts collected from social media platforms and fact-checking websites.Real news items were sourced from verified outlets providing accurate COVID-19 information, while fake news was gathered from tweets, posts, and articles containing misinformation about COVID-19.Fake news is treated as the anomaly class.</p>
<p>LIAR25 (Xu and Kechadi, 2024) consists of approximately 23,000 statements manually labeled by professional fact-checkers for fake news detection tasks.The "True" class, representing accurate statements, is considered the normal class, while the "Pants on Fire" class, representing highly misleading statements, is treated as the anomaly.</p>
<p>OLID6 (Zampieri et al., 2019b) (Zampieri et al., 2019a) contains 14,200 annotated English tweets, categorized using a three-level annotation model.For this benchmark, only the Level A (Offensive Language Detection) annotations are used, where tweets labeled as offensive are considered as anomalies, and non-offensive tweets are considered • Qwen 15 (Qwen2.5-1.5B)</p>
<p>Beyond model size and token limits, computational efficiency is a key factor in selecting embedding models, particularly for real-world applications where inference speed is critical.Table 3 presents the embedding time (in seconds) required to process six datasets using each embedding model.</p>
<p>From the Table 3, we observe a significant variation in embedding extraction time.MINILM is the fastest across all datasets, taking only a few seconds, making it ideal for applications requiring real-time embedding generation.BERT offers a moderate trade-off, with embedding times significantly lower than larger models but higher than MINILM.OpenAI's embeddings (O-ada, O-small, O-large) are relatively slow, likely due to their highdimensional output and extended token support.Llama and Qwen models require the most computation, with Qwen taking up to 745.85 seconds on the Email-Spam dataset, reflecting the high computational cost of large autoregressive models.</p>
<p>F Comparative Analysis of Anomaly Detection Algorithms</p>
<p>Anomaly detection algorithms vary in their underlying assumptions, computational efficiency, and effectiveness across different types of data distributions.In this section, we provide a comparative analysis of the eight anomaly detection methods used in this study: kNN, OCSVM, iForest, LOF, HBOS, ECOD, INNE and COPOD.Distance-based methods, such as kNN, define anomalies based on their relative distance to surrounding points.kNN anomaly detection computes the distance between a data point and its kth nearest neighbor, with larger distances indicating potential anomalies.This method is conceptually simple 15 https://huggingface.co/Qwen/Qwen2.5-1.5B and effective in low-dimensional spaces with clear separation between normal and anomalous points.However, its primary drawback is the curse of dimensionality, where distance metrics lose discriminative power as dimensionality increases.Additionally, kNN is computationally expensive, with a worst-case complexity of O(n 2 ), making it impractical for large datasets without optimizations such as approximate nearest neighbor search.</p>
<p>Density-based approaches assume that anomalies reside in low-density regions relative to normal points.LOF estimates the local density of a point by comparing it with the densities of its neighbors.It is highly effective in detecting anomalies in datasets with non-uniform density distributions, where global models may fail.However, LOF is computationally expensive complexity O(n 2 ) in the worst case and sensitive to the choice of neighborhood size, requiring careful hyperparameter tuning.</p>
<p>A more efficient density estimation approach is HBOS, which models feature distributions independently using histograms.This makes it computationally extremely fast O(n) and scalable to large datasets.However, HBOS assumes feature independence, limiting its effectiveness when strong feature correlations exist.In such cases, its effectiveness diminishes as it fails to capture intricate relationships between features, potentially leading to suboptimal anomaly detection performance.</p>
<p>Isolation-based approaches, such as iForest, take a different perspective by recursively partitioning the feature space.Since anomalies are typically isolated with fewer splits, iForest identifies them based on the depth required to isolate each point.iForest is computationally efficient O(nlogn) and performs well in high-dimensional spaces compared to distance-based methods, but it is struggle with local anomalies.An extension of iForest, INNE, replaces axis-aligned splits with hypersphere-based partitions.This enhances robustness in detecting anomalies in complex distributions, particularly local anomalies.</p>
<p>Statistical approaches model the underlying distribution of data and identify anomalies as points that significantly deviate from expected behavior.ECOD estimates anomaly scores based on the empirical cumulative distribution function (ECDF) for each feature independently.It is parameterfree and computationally efficient O(n), making it highly scalable.However, like HBOS, ECOD assumes feature independence, which can limit its effectiveness in multivariate settings.COPOD improves upon ECOD by leveraging copula functions to model dependencies between features, making it more effective for detecting anomalies in correlated data.However, this comes at the cost of increased computational complexity, making COPOD less scalable for very large datasets.</p>
<p>G Embedding Analysis</p>
<p>To better understand how different embedding models encode normal and anomalous instances, we visualize their embedding spaces using t-SNE projections across 6 datasets.Figure 6 presents the t-SNE plots for embeddings extracted from 8 embedding models, blue points represent normal instances, while red points denote anomalies.</p>
<p>Separation of Normal and Anomalous Instances.As defined in Section A, anomalies should ideally exhibit significant deviation from normal instances in the embedding space.The extent to which embeddings separate anomalies from normal data is a crucial factor in determining their effectiveness for anomaly detection.</p>
<p>Most embedding models exhibits clear separation, particularly in the Email Spam dataset, where anomalous points form distinct regions away from the normal distribution.BERT struggles with clear separation, with many anomalies still embedded within normal clusters.This indicates that these models may not encode sufficient discriminative features for anomaly detection tasks.</p>
<p>Dataset-Specific Challenges.The effectiveness of embedding-based anomaly detection varies significantly across datasets, highlighting the influence of domain characteristics:</p>
<p>• Spam Detection (Email Spam, SMS Spam): most embedding models perform well, reflecting their ability to capture explicit spam patterns (e.g., domain-specific keywords, unusual syntax).In contrast, BERT shows more overlap between spam and normal messages, leading to weaker anomaly separation.</p>
<p>• Fake News Detection (COVID-Fake, LIAR2):</p>
<p>The separation of anomalies is less pronounced across most embeddings, likely due to the subtle and nuanced nature of misinformation.This suggests that effective detection may require external knowledge or factual reasoning beyond what standard embeddings can provide.</p>
<p>• Offensive Language (Hate Speech, OLID): All embeddings perform poorly, with anomalies scattered among normal instances.This suggests that hate speech and offensive language often depend on implicit contextual cues rather than explicit linguistic differences, making them harder to distinguish using standard embeddings.</p>
<p>Clustered Anomalies in Spam Detection.For both Email Spam and SMS Spam datasets, the anomalies tend to form compact clusters rather than being scattered as isolated points.This behavior contrasts with other datasets, where anomalies are often more dispersed.</p>
<p>Unlike anomalies in misinformation or hate speech detection, which can manifest in subtle linguistic variations, spam messages tend to exhibit repetitive patterns, including URLs, phone numbers, irregular word spacing and excessive punctuation.Since these patterns are highly distinct but internally consistent, embeddings may cluster them into a well-defined anomaly group rather than spreading them across the feature space.</p>
<p>H Experiments Environment</p>
<p>The entire pipeline, including embedding extraction and anomaly detection, was implemented in Python 3.9.Experiments were executed on a computational setup equipped with a Ryzen 9 5900X 12-core CPU for data preprocessing and model orchestration, and an Nvidia RTX 3060 GPU with 12GB of memory for model inference and embedding generation.</p>
<p>Figure 1
1
Figure 1: t-SNE visualization of SMS_Spam dataset's embedding extracted by OpenAI model.Blue and red points are normal and anomaly points, respectively.</p>
<p>Figure 2 :
2
Figure 2: Illustration of the embedding-based anomaly detection pipeline, encompassing embedding extraction and anomaly scoring.</p>
<p>Figure 3
3
Figure 3: t-SNE demonstration of Case 1 (green star) embedding extracted by O-large.</p>
<p>Figure 4
4
Figure 4: t-SNE demonstration of Case 2 (green star) embedding extracted by O-large.</p>
<p>Figure 5 :
5
Figure 5: Boxplot of AUCROC scores for anomaly detectors on different embeddings across 6 datasets.</p>
<p>Figure 6 :
6
Figure 6: Average rank (lower the better) of 3 differernt OpenAI embeddings-based methods on AUCROC across 6 datasets.</p>
<p>Table 1 :
1
Dataset description.Nor. and Ano.stand for Normal and Anomaly.
Dataset# Samples # Nor. # Ano. % Ano.Email Spam357834321464.0805SMS Spam496948251442.8980COVID-Fake11731120534.5183LIAR221302068622.9108OLID641620213.2761Hate Speech428741631242.8925While effective for complex distributions.Deep learning-based methods train on normaldata to learn representations, identifying anoma-lies as deviations. Approaches like Deep SVDD(Deep Support Vector Data Description)</p>
<p>Table 2
2demonstrate the remark-able capabilities of the OpenAI family of embed-dings (O-ada, O-small, and O-large), consistentlyoutperforming other embeddings across a varietyof anomaly detection tasks. Specifically, O-adaachieves the highest average AUC scores withthe ECOD detector (0.8822) on the SMS Spamdataset and with kNN (0.7921) on the LIAR2dataset. Similarly, O-small demonstrates outstand-ing performance, achieving the highest AUC scoreswith kNN on the Hate Speech (0.6416) and OLID(0.5587) datasets. Additionally, O-large securestop AUC scores with COPOD (0.9639) on theEmail Spam dataset and with kNN (0.9537) onthe COVID Fake News dataset.</p>
<p>Table 2 :
2
Evaluation across 6 datasets in terms of AUROC.
Embeddings Detectors Email-Spam SMS-Spam COVID-Fake LIAR2 Hate-Speech OLID AveragekNN0.76250.44840.84670.65940.50330.51370.6223OCSVM0.73620.63230.78670.62370.48660.48660.6254IForest0.71520.61640.77010.60510.49250.47830.6129BERTLOF0.67860.32300.87130.67170.46320.49700.5841ECOD0.73090.62350.77220.61750.48890.49330.6211INNE0.77320.64970.80120.63620.48500.47400.6366HBOS0.71450.62510.76980.61900.49350.50020.5317COPOD0.64540.59290.77140.62420.49710.51890.5214kNN0.94140.31800.84130.72490.58040.50630.6520OCSVM0.96260.59150.78430.64700.40620.45200.6406IForest0.90780.54720.74550.59360.46970.45310.6195MINILMLOF0.55870.50240.74330.68040.50780.54220.5891ECOD0.95250.59340.75810.65320.37860.42080.6261INNE0.95260.57370.80350.66010.42230.48240.6491HBOS0.94780.61370.74410.64470.38880.43160.5387COPOD0.94530.63170.74160.66950.37100.40370.5375kNN0.88650.32120.90940.79210.63410.52430.6779OCSVM0.93100.82210.81430.71690.48070.50480.7116IForest0.88720.73760.74320.64210.46320.48910.6604O-adaLOF0.38080.50330.73160.75410.43280.53760.5567ECOD0.93800.88220.81500.72000.46100.49860.7191INNE0.85070.80310.85330.73780.48200.51020.7062HBOS0.94330.88130.81640.71860.45830.50980.6182COPOD0.95020.87590.81530.72010.45130.48110.6134kNN0.89210.22900.94000.77560.64160.55870.6728OCSVM0.94750.57550.89320.70240.45770.55470.6885IForest0.90580.61770.80850.59730.50250.55800.6650O-smallLOF0.38630.52570.78090.74890.41390.55810.5690ECOD0.94810.63010.88080.70220.42490.52950.6859INNE0.86730.60800.91850.71980.44910.53820.6835HBOS0.95220.62730.87190.70080.42450.51570.5846COPOD0.96050.57220.86640.69740.40170.49630.5706kNN0.82920.16980.95370.76870.62910.54970.6500OCSVM0.94030.56300.89240.66210.42600.49710.6635IForest0.89990.52970.80410.56870.45160.50680.6268O-largeLOF0.40480.47190.82330.73560.38330.51670.5559ECOD0.94870.64220.88750.65400.39590.49670.6708INNE0.82300.59700.92610.68760.41970.51700.6617HBOS0.95380.65250.88490.64040.38350.49890.5734COPOD0.96390.67980.88540.65360.35370.49800.5763kNN0.87150.36550.86680.72290.49910.40810.6223OCSVM0.90230.73790.81320.68920.47740.40570.6710IForest0.89620.72750.78330.68600.46470.40820.6610LlamaLOF0.60560.40530.86730.72740.43760.39720.5734ECOD0.88440.75730.78190.69890.46430.39980.6644INNE0.91220.70650.81600.69350.47020.39170.6650HBOS0.90170.78950.77580.70640.45800.38980.5745COPOD0.91530.81630.75840.72910.44350.35260.5736kNN0.86540.32120.90340.68840.47460.50160.6258OCSVM0.89220.71650.80630.51030.37290.44390.6237IForest0.88620.73770.77380.49990.35450.43250.6141stellaLOF0.39310.47330.71290.65490.40360.52850.5277ECOD0.90750.78940.81150.50230.34210.43950.6321INNE0.82710.69260.83660.53300.33250.45320.6125HBOS0.91780.80170.80860.49520.33550.42520.5406COPOD0.93000.85890.81670.49360.30180.37970.5401kNN0.86180.21100.84380.66260.51630.46020.5926OCSVM0.88040.62290.78680.62160.49160.48820.6486IForest0.88290.61950.76860.61550.48250.48690.6427QwenLOF0.60430.36000.85550.68940.46000.45180.5702ECOD0.86780.66480.76800.61720.48520.47730.6467INNE0.88390.59400.78330.63390.49020.46930.6424HBOS0.88540.68770.76380.61700.48470.46850.5582COPOD0.90440.73930.74630.62910.47940.43360.5617</p>
<p>Table 5 :
5
Embedding Models Overview.M and B are for million and billion, respectively.
ModelsMax Tokens # Dimensions # ParametersBERT512768110 MMINILM51238422.7 MO-ada81911536-O-small81911536-O-large81913072-LLAMA409620481.24 Bstella20481024435 MQwen819215361.54 B</p>
<p>Table 6 :
6
t-SNE visualization of embeddings from 8 models across 6 datasets.Blue points represent normal instances, while red points denote anomalies.</p>
<p>PyOD: https://pyod.readthedocs.io/en/latest/ index.html
https://huggingface.co/datasets/kendx/ NLP-ADBench/tree/main/datasets/email_spam
https://archive.ics.uci.edu/dataset/228/sms+ spam+collection
https://github.com/diptamath/covid_fake_news? tab=readme-ov-file
https://github.com/chengxuphd/liar2?tab= readme-ov-file
https://sites.google.com/site/ offensevalsharedtask/olid
D Evaluation with Hyperparameter SearchExperiments with hyperparameter search reveal significant insights into the performance dynamics of anomaly detection algorithms when paired with various embedding models.When comparing Table4with the default parameters results in Table2, we observe that kNN emerges as a particularly strong performer across multiple embedding models, especially with the OpenAI family of embeddings.This suggests that distance-based approaches effectively leverage the semantic information captured by these models, particularly in tasks like spam and fake news detection.INNE demonstrates the most balanced and robust performance profile when considering average scores across all datasets and embedding combinations.Its isolation-based approach with hypersphere partitioning appears particularly well-suited to the complex topological structure of embedding spaces, allowing it to identify local anomalies that other methods might miss.The performance improvement of INNE after hyperparameter optimization is especially notable with embedding models 7 https://github.com/t-davidson/hate-speech-and-offensive-language like Llama and stella, suggesting a strong complementarity between isolation-based algorithms and these embedding architectures.E Embedding ModelsTo effectively represent textual data, we use various pre-trained embedding models that transform text into dense vector representations.Table5summarizes the embedding models employed in this paper.These embeddings serve as feature inputs for anomaly detection models, enabling them to capture semantic similarities and deviations in text.We selected a diverse set of embedding models, balancing between model size, token length limits, and computational efficiency.The models used in this study are:• BERT 8 (bert-base-uncased)• MINILM 9 (all-MiniLM-L6-v2)• O-ada 10 (text-embedding-ada-002)• O-small 11 (text-embedding-3-small)• O-large 12 (text-embedding-3-large)• LLAMA 13 (Llama-3.2-1B)• stella 14 (stella_en_400M_v5)
Contributions to the study of sms spam filtering: new collection and results. José Tiago A Almeida, G María, Akebo Hidalgo, Yamakami, Proceedings of the 11th ACM symposium on Document engineering. the 11th ACM symposium on Document engineering2011</p>
<p>Isolation-based anomaly detection using nearest-neighbor ensembles. Kai Ming Tharindu R Bandaragoda, David Ting, Albrecht, Tony Fei, Ye Liu, Jonathan R Zhu, Wells, Computational Intelligence. 3442018</p>
<p>Ad-nlp: A benchmark for anomaly detection in natural language processing. Matei Bejan, Andrei Manolache, Marius Popescu, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>A review on outlier/anomaly detection in time series data. Ane Blázquez-García, Angel Conde, Usue Mori, Jose A Lozano, ACM computing surveys (CSUR). 5432021</p>
<p>Lof: identifying densitybased local outliers. Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, Jörg Sander, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data2000</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Text classification using embeddings: a survey. Liliane Soares Da Costa, Italo L Oliveira, Renato Fileto, Knowledge and Information Systems. 6572023</p>
<p>A heuristic-driven ensemble framework for covid-19 fake news detection. Dipta Sourya, Ayan Das, Saikat Basak, Dutta, Combating Online Hostile Posts in Regional Languages during Emergency Situation: First International Workshop, CONSTRAINT 2021, Collocated with AAAI 2021, Virtual Event. Springer2021. February 8, 20211</p>
<p>Automated hate speech detection and the problem of offensive language. Thomas Davidson, Dana Warmsley, Michael Macy, Ingmar Weber, Proceedings of the international AAAI conference on web and social media. the international AAAI conference on web and social media201711</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191</p>
<p>Histogram-based outlier score (hbos): A fast unsupervised anomaly detection algorithm. KI-2012: poster and demo track. Markus Goldstein, Andreas Dengel, 20121</p>
<p>Lunar: Unifying local outlier detection methods via graph neural networks. Adam Goodge, Bryan Hooi, See-Kiong Ng, Wee Siong Ng, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>Albert: A lite bert for self-supervised learning of language representations. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, arXiv:1909.119422020PreprintPiyush Sharma, and Radu Soricut</p>
<p>Yuangang Li, Jiaqi Li, Zhuo Xiao, Tiankai Yang, Yi Nian, Xiyang Hu, Yue Zhao, arXiv:2412.04784Nlpadbench: Nlp anomaly detection benchmark. 2024arXiv preprint</p>
<p>Copod: copula-based outlier detection. Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, Xiyang Hu, 2020 IEEE international conference on data mining (ICDM). IEEE2020</p>
<p>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions. Zheng Li, Yue Zhao, Xiyang Hu, Nicola Botta, Cezar Ionescu, George H Chen, IEEE Transactions on Knowledge and Data Engineering. 35122022</p>
<p>Isolation forest. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, 2008 eighth ieee international conference on data mining. IEEE2008</p>
<p>Isolation-based anomaly detection. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, ACM Transactions on Knowledge Discovery from Data (TKDD). 612012</p>
<p>Vangelis Metsis, Spam filtering with naive bayeswhich naive bayes? In CEAS. Mountain View, CA200617Ion Androutsopoulos, and Georgios Paliouras</p>
<p>Tomas Mikolov, arXiv:1301.3781Efficient estimation of word representations in vector space. 20133781arXiv preprint</p>
<p>New embedding models and api updates. 2024OpenAI</p>
<p>Longbing Cao, and Anton Van Den Hengel. 2021. Deep learning for anomaly detection: A review. Guansong Pang, Chunhua Shen, ACM computing surveys (CSUR). 54</p>
<p>Glove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). the 2014 conference on empirical methods in natural language processing (EMNLP)2014</p>
<p>Deep contextualized word representations. Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, 10.18653/v1/N18-1202Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational Linguistics20181</p>
<p>A review of novelty detection. A F Marco, David A Pimentel, Lei Clifton, Lionel Clifton, Tarassenko, Signal processing. 992014</p>
<p>Charu Aggarwal, and Guansong Pang. Hezhe Qiao, Hanghang Tong, Bo An, Irwin King, arXiv:2409.09957Deep graph anomaly detection: A survey and new perspectives. 2024arXiv preprint</p>
<p>Efficient algorithms for mining outliers from large data sets. Sridhar Ramaswamy, Rajeev Rastogi, Kyuseok Shim, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data2000</p>
<p>Deep one-class classification. Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Ahmed Shoaib, Alexander Siddiqui, Emmanuel Binder, Marius Müller, Kloft, International conference on machine learning. PMLR2018</p>
<p>Termweighting approaches in automatic text retrieval. Gerard Salton, Christopher Buckley, formation processing &amp; management. 198824</p>
<p>Estimating the support of a high-dimensional distribution. Bernhard Schölkopf, John C Platt, John Shawe-Taylor, Alex J Smola, Robert C Williamson, Neural computation. 1372001</p>
<p>Benchmarking unsupervised outlier detection with realistic synthetic data. Georg Steinbuss, Klemens Böhm, ACM Transactions on Knowledge Discovery from Data (TKDD). 1542021</p>
<p>Qwen Team. 2024. Qwen2.5: A party of foundation models. </p>
<p>Log2graphs: An unsupervised framework for log anomaly detection with efficient feature extraction. Caihong Wang, Du Xu, Zonghang Li, arXiv:2409.118902024arXiv preprint</p>
<p>Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers. Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, Ming Zhou, Advances in Neural Information Processing Systems. 202033</p>
<p>An enhanced fake news detection system with fuzzy deep learning. Cheng Xu, M-Tahar Kechadi, 10.1109/ACCESS.2024.3418340IEEE Access. 122024</p>
<p>Comparative analysis of anomaly detection algorithms in text data. Yizhou Xu, Jérôme Milleret, Frédérique Segond, Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing. the 14th International Conference on Recent Advances in Natural Language Processing2023</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, arXiv:2407.10671Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. 2024a. Qwen2 technical report. Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei ChuarXiv preprint</p>
<p>Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, arXiv:2412.11142Ad-llm: Benchmarking large language models for anomaly detection. 2024barXiv preprint</p>
<p>Predicting the Type and Target of Offensive Posts in Social Media. Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar, Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar, 10.18653/v1/N19-1144Proceedings of the 2019 Conference of the North American Chapter. Long and Short Papers. the 2019 Conference of the North American ChapterMinneapolis, MinnesotaAssociation for Computational Linguistics2019a. 2019b1Proceedings of NAACL</p>
<p>Dun Zhang, Jiacheng Li, Ziyang Zeng, Fulong Wang, arXiv:2412.19048Jasper and stella: distillation of sota embedding models. 2024arXiv preprint</p>
<p>Pyod: A python toolbox for scalable outlier detection. Yue Zhao, Zain Nasrullah, Zheng Li, Journal of Machine Learning Research. 20962019</p>
<p>Large language models for information retrieval: A survey. Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, Ji-Rong Wen, arXiv:2308.071072023arXiv preprint</p>
<p>A robustly optimized BERT pre-training approach with post-training. Liu Zhuang, Lin Wayne, Shi Ya, Zhao, Proceedings of the 20th Chinese National Conference on Computational Linguistics. the 20th Chinese National Conference on Computational LinguisticsHuhhot, ChinaChinese Information Processing Society of ChinaJun. 2021</p>            </div>
        </div>

    </div>
</body>
</html>