<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6397 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6397</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6397</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-126.html">extraction-schema-126</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <p><strong>Paper ID:</strong> paper-276618268</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2502.18600v2.pdf" target="_blank">Chain of Draft: Thinking Faster by Writing Less</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning. However, humans typically employ a more efficient strategy: drafting concise intermediate thoughts that capture only essential information. In this work, we propose Chain of Draft (CoD), a novel paradigm inspired by human cognitive processes, where LLMs generate minimalistic yet informative intermediate reasoning outputs while solving tasks. By reducing verbosity and focusing on critical insights, CoD matches or surpasses CoT in accuracy while using as little as only 7.6% of the tokens, significantly reducing cost and latency across various reasoning tasks. Our code and data are available at https://github.com/sileix/chain-of-draft.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6397.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6397.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoD (GSM8k, GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Draft prompting evaluated on GSM8k with GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Chain-of-Draft (CoD) is a prompting strategy that urges models to produce very concise intermediate reasoning steps (guideline: <=5 words per step). When applied few-shot to GPT-4o on GSM8k, CoD substantially reduces tokens and latency while retaining most of CoT's accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-4o-2024-08-06 (GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems (arithmetic: addition, subtraction, basic algebra/word problems)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (few-shot examples provided)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>few-shot Chain-of-Draft (CoD) — instruction: "Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most." Few-shot CoD examples included.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage), average output token count, latency (seconds)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>91.1% accuracy; avg output tokens 43.9; latency 1.0 s</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No mechanistic probing (attention/activation/logit lens) was performed. Authors report behavioral observations only: CoD produces concise symbolic/equation-like drafts; they hypothesize that CoD effectiveness depends on models' prior exposure to concise reasoning formats in training but present no internal interpretability analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Modest accuracy drop relative to CoT (≈4 percentage points on GPT-4o); CoD effectiveness degrades substantially without few‑shot examples; authors hypothesize failures arise from lack of CoD‑style training data and from models' tendency to 'overthink' or produce verbose steps if not guided.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>High-capability models like GPT-4o retain most CoT performance under CoD; smaller models exhibit larger performance gaps (see small-model results), indicating CoD benefits scale with model capability and training exposure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6397.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6397.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT (GSM8k, GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting evaluated on GSM8k with GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Chain-of-Thought (CoT) few-shot prompting elicits detailed step-by-step natural-language reasoning; on GPT-4o it yields very high accuracy at the cost of verbosity and higher latency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-4o-2024-08-06 (GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (few-shot examples following Wei et al. CoT appendix)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>few-shot Chain-of-Thought (CoT) per Wei et al. (detailed step-by-step solutions included in prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage), average output token count, latency (seconds)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>95.4% accuracy; avg output tokens 205.1; latency 4.2 s</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanistic probes performed; authors note CoT produces highly verbose reasoning that increases token cost and latency.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High token usage and latency; practical costs in latency-sensitive settings. No model-internal failure analysis provided.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>CoT gives very high accuracy for large models; not evaluated as fine-grained scaling in this paper beyond reported small-model comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6397.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6397.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Standard (GSM8k, GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Standard few-shot direct-answer prompting evaluated on GSM8k with GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard few-shot prompting asks for the final answer directly (no intermediate steps); it is low-cost in tokens but substantially less accurate for arithmetic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-4o-2024-08-06 (GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (few-shot examples, direct-answer)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>few-shot direct answer (Standard prompting)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage), average output token count, latency (seconds)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>53.3% accuracy; avg output tokens 1.1; latency 0.6 s</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No mechanistic probe; authors note direct-answering lacks transparency and often fails on multi-step arithmetic.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High error rate on multi-step arithmetic; prone to hallucination due to lack of intermediate verification.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Standard prompting performance is substantially lower than CoT/CoD for large models on GSM8k.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6397.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6397.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoD (GSM8k, Claude 3.5 Sonnet)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Draft prompting evaluated on GSM8k with Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying few-shot CoD to Claude 3.5 Sonnet produced major token and latency reductions while maintaining high accuracy close to CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>claude-3-5-sonnet-20240620 (Claude 3.5 Sonnet)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (few-shot examples)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>few-shot Chain-of-Draft (CoD) — guideline to limit each reasoning step to five words at most; few-shot CoD examples included.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage), average output token count, latency (seconds)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>91.4% accuracy; avg output tokens 39.8; latency 1.6 s</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanistic analysis. The paper reports behavior-level observations: CoD dramatically reduces verbosity for Claude and can even outperform CoT on some commonsense tasks, but authors do not provide neuron/attention analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Accuracy lower than CoT (95.8% vs 91.4%); CoD degrades without few-shot examples; CoD prompts sometimes ignored (authors note the 5‑word limit is a guideline, not enforced).</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Large Claude model retains high absolute performance with CoD; small models show larger relative drops, implying scaling and/or training-format exposure matters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6397.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6397.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT (GSM8k, Claude 3.5 Sonnet)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting evaluated on GSM8k with Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Few-shot CoT elicits detailed step-by-step reasoning in Claude 3.5 Sonnet, achieving very high accuracy but much larger token usage and latency than CoD.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>claude-3-5-sonnet-20240620 (Claude 3.5 Sonnet)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (few-shot CoT examples)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>few-shot Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage), average output token count, latency (seconds)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>95.8% accuracy; avg output tokens 190.0; latency 3.1 s</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No mechanistic analysis provided; behavioral note that CoT responses are verbose and increase cost.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Increased verbosity causes high latency and token cost; no internal failure-mode analysis shown.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>CoT produces very high accuracy on large models; behavior across sizes shown in small-model table (drops as size decreases).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6397.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6397.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Small models on GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evaluations of Qwen2.5-1.5B, Qwen2.5-3B, Llama3.2-3B, Zoom-SLM-2.3B on GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Multiple sub-3B models were evaluated on GSM8k with Standard, CoT, and CoD prompting; CoT substantially improves accuracy versus direct answering, while CoD gives partial improvements but lags CoT, showing larger performance gaps than for the flagship models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-1.5B, Qwen2.5-3B, Llama3.2-3B-Instruct, Zoom-SLM-2.3B</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><3B parameters (per-model sizes listed in name)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (few-shot examples)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>few-shot Standard, few-shot CoT, few-shot CoD (same CoD guideline: <=5 words per step)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage), avg output tokens</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Qwen2.5-1.5B: Standard 5.7% acc; CoT 32.5% acc (avg tokens 141.4); CoD 24.2% acc (avg tokens 75.1). Qwen2.5-3B: Standard 7.2%; CoT 59.1% (236.4 tokens); CoD 43.1% (41.2 tokens). Llama3.2-3B-Instruct: Standard 3.9%; CoT 70.7% (195.3 tokens); CoD 52.5% (98.1 tokens). Zoom-SLM-2.3B: Standard 5.9%; CoT 77.7% (129.0 tokens); CoD 50.9% (55.6 tokens).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanistic probes; authors interpret lower CoD performance as likely due to absence of CoD-style concise reasoning in pretraining/fine-tuning data and limited model capacity to generalize from few-shot concise drafts.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>CoD performance gap vs CoT is substantially larger for small models; CoD often underperforms CoT by large margins (e.g., 20+ percentage points); standard prompting nearly fails on GSM8k for these models.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Performance increases with model capability/size: CoT and CoD both improve as models grow, but CoD lags behind CoT more severely at small scales; authors suggest fine-tuning on CoD-formatted data may close the gap.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6397.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6397.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zero-shot CoD limitation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Observed inconsistency of Chain-of-Draft prompting in zero-shot settings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper reports that CoD's benefits rely on few-shot examples: in zero-shot, CoD's improvement over direct-answering is minimal for some models (e.g., about +3.6% for Claude 3.5 Sonnet on GSM8k).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>claude-3-5-sonnet-20240620 (Claude 3.5 Sonnet)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k (zero-shot)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems (zero-shot, CoD instruction only, no few-shot examples)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school / multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>zero-shot Chain-of-Draft (guideline to keep steps concise but no few-shot examples)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (percentage)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported improvement over direct answering for Claude 3.5 Sonnet: +3.6% (exact table values not fully shown in paper excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Authors attribute zero-shot weakness to the lack of CoD-formatted training data and reliance on few-shot exemplars for instructing concise-step behavior; no deeper mechanistic analysis was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>CoD without few-shot examples is inconsistent and provides only marginal gains over direct-answer prompting; models may ignore brevity guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Zero-shot CoD is weak across evaluated models; few-shot exemplars are crucial, particularly for smaller models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Chain of Draft: Thinking Faster by Writing Less', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 2)</em></li>
                <li>Concise thoughts: Impact of output length on llm reasoning and cost <em>(Rating: 2)</em></li>
                <li>Token-budget-aware llm reasoning <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 1)</em></li>
                <li>Training large language models to reason in a continuous latent space <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6397",
    "paper_id": "paper-276618268",
    "extraction_schema_id": "extraction-schema-126",
    "extracted_data": [
        {
            "name_short": "CoD (GSM8k, GPT-4o)",
            "name_full": "Chain-of-Draft prompting evaluated on GSM8k with GPT-4o",
            "brief_description": "Chain-of-Draft (CoD) is a prompting strategy that urges models to produce very concise intermediate reasoning steps (guideline: &lt;=5 words per step). When applied few-shot to GPT-4o on GSM8k, CoD substantially reduces tokens and latency while retaining most of CoT's accuracy.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "gpt-4o-2024-08-06 (GPT-4o)",
            "model_family": "Transformer (decoder-only)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "multi-step grade-school word problems (arithmetic: addition, subtraction, basic algebra/word problems)",
            "problem_format": "natural-language word problems (few-shot examples provided)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "few-shot Chain-of-Draft (CoD) — instruction: \"Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most.\" Few-shot CoD examples included.",
            "performance_metric": "accuracy (percentage), average output token count, latency (seconds)",
            "performance_value": "91.1% accuracy; avg output tokens 43.9; latency 1.0 s",
            "internal_analysis": "No mechanistic probing (attention/activation/logit lens) was performed. Authors report behavioral observations only: CoD produces concise symbolic/equation-like drafts; they hypothesize that CoD effectiveness depends on models' prior exposure to concise reasoning formats in training but present no internal interpretability analyses.",
            "failure_modes": "Modest accuracy drop relative to CoT (≈4 percentage points on GPT-4o); CoD effectiveness degrades substantially without few‑shot examples; authors hypothesize failures arise from lack of CoD‑style training data and from models' tendency to 'overthink' or produce verbose steps if not guided.",
            "scaling_trend": "High-capability models like GPT-4o retain most CoT performance under CoD; smaller models exhibit larger performance gaps (see small-model results), indicating CoD benefits scale with model capability and training exposure.",
            "uuid": "e6397.0",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "CoT (GSM8k, GPT-4o)",
            "name_full": "Chain-of-Thought prompting evaluated on GSM8k with GPT-4o",
            "brief_description": "Chain-of-Thought (CoT) few-shot prompting elicits detailed step-by-step natural-language reasoning; on GPT-4o it yields very high accuracy at the cost of verbosity and higher latency.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "gpt-4o-2024-08-06 (GPT-4o)",
            "model_family": "Transformer (decoder-only)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "multi-step grade-school word problems",
            "problem_format": "natural-language word problems (few-shot examples following Wei et al. CoT appendix)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "few-shot Chain-of-Thought (CoT) per Wei et al. (detailed step-by-step solutions included in prompts)",
            "performance_metric": "accuracy (percentage), average output token count, latency (seconds)",
            "performance_value": "95.4% accuracy; avg output tokens 205.1; latency 4.2 s",
            "internal_analysis": "No internal mechanistic probes performed; authors note CoT produces highly verbose reasoning that increases token cost and latency.",
            "failure_modes": "High token usage and latency; practical costs in latency-sensitive settings. No model-internal failure analysis provided.",
            "scaling_trend": "CoT gives very high accuracy for large models; not evaluated as fine-grained scaling in this paper beyond reported small-model comparisons.",
            "uuid": "e6397.1",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "Standard (GSM8k, GPT-4o)",
            "name_full": "Standard few-shot direct-answer prompting evaluated on GSM8k with GPT-4o",
            "brief_description": "Standard few-shot prompting asks for the final answer directly (no intermediate steps); it is low-cost in tokens but substantially less accurate for arithmetic reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "gpt-4o-2024-08-06 (GPT-4o)",
            "model_family": "Transformer (decoder-only)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "multi-step grade-school word problems",
            "problem_format": "natural-language word problems (few-shot examples, direct-answer)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "few-shot direct answer (Standard prompting)",
            "performance_metric": "accuracy (percentage), average output token count, latency (seconds)",
            "performance_value": "53.3% accuracy; avg output tokens 1.1; latency 0.6 s",
            "internal_analysis": "No mechanistic probe; authors note direct-answering lacks transparency and often fails on multi-step arithmetic.",
            "failure_modes": "High error rate on multi-step arithmetic; prone to hallucination due to lack of intermediate verification.",
            "scaling_trend": "Standard prompting performance is substantially lower than CoT/CoD for large models on GSM8k.",
            "uuid": "e6397.2",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "CoD (GSM8k, Claude 3.5 Sonnet)",
            "name_full": "Chain-of-Draft prompting evaluated on GSM8k with Claude 3.5 Sonnet",
            "brief_description": "Applying few-shot CoD to Claude 3.5 Sonnet produced major token and latency reductions while maintaining high accuracy close to CoT.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "claude-3-5-sonnet-20240620 (Claude 3.5 Sonnet)",
            "model_family": "Transformer (decoder-only)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "multi-step grade-school word problems",
            "problem_format": "natural-language word problems (few-shot examples)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "few-shot Chain-of-Draft (CoD) — guideline to limit each reasoning step to five words at most; few-shot CoD examples included.",
            "performance_metric": "accuracy (percentage), average output token count, latency (seconds)",
            "performance_value": "91.4% accuracy; avg output tokens 39.8; latency 1.6 s",
            "internal_analysis": "No internal mechanistic analysis. The paper reports behavior-level observations: CoD dramatically reduces verbosity for Claude and can even outperform CoT on some commonsense tasks, but authors do not provide neuron/attention analyses.",
            "failure_modes": "Accuracy lower than CoT (95.8% vs 91.4%); CoD degrades without few-shot examples; CoD prompts sometimes ignored (authors note the 5‑word limit is a guideline, not enforced).",
            "scaling_trend": "Large Claude model retains high absolute performance with CoD; small models show larger relative drops, implying scaling and/or training-format exposure matters.",
            "uuid": "e6397.3",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "CoT (GSM8k, Claude 3.5 Sonnet)",
            "name_full": "Chain-of-Thought prompting evaluated on GSM8k with Claude 3.5 Sonnet",
            "brief_description": "Few-shot CoT elicits detailed step-by-step reasoning in Claude 3.5 Sonnet, achieving very high accuracy but much larger token usage and latency than CoD.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "claude-3-5-sonnet-20240620 (Claude 3.5 Sonnet)",
            "model_family": "Transformer (decoder-only)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "multi-step grade-school word problems",
            "problem_format": "natural-language word problems (few-shot CoT examples)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "few-shot Chain-of-Thought (CoT)",
            "performance_metric": "accuracy (percentage), average output token count, latency (seconds)",
            "performance_value": "95.8% accuracy; avg output tokens 190.0; latency 3.1 s",
            "internal_analysis": "No mechanistic analysis provided; behavioral note that CoT responses are verbose and increase cost.",
            "failure_modes": "Increased verbosity causes high latency and token cost; no internal failure-mode analysis shown.",
            "scaling_trend": "CoT produces very high accuracy on large models; behavior across sizes shown in small-model table (drops as size decreases).",
            "uuid": "e6397.4",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "Small models on GSM8k",
            "name_full": "Evaluations of Qwen2.5-1.5B, Qwen2.5-3B, Llama3.2-3B, Zoom-SLM-2.3B on GSM8k",
            "brief_description": "Multiple sub-3B models were evaluated on GSM8k with Standard, CoT, and CoD prompting; CoT substantially improves accuracy versus direct answering, while CoD gives partial improvements but lags CoT, showing larger performance gaps than for the flagship models.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2.5-1.5B, Qwen2.5-3B, Llama3.2-3B-Instruct, Zoom-SLM-2.3B",
            "model_family": "Transformer (decoder-only)",
            "model_size": "&lt;3B parameters (per-model sizes listed in name)",
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "multi-step grade-school word problems",
            "problem_format": "natural-language word problems (few-shot examples)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "few-shot Standard, few-shot CoT, few-shot CoD (same CoD guideline: &lt;=5 words per step)",
            "performance_metric": "accuracy (percentage), avg output tokens",
            "performance_value": "Qwen2.5-1.5B: Standard 5.7% acc; CoT 32.5% acc (avg tokens 141.4); CoD 24.2% acc (avg tokens 75.1). Qwen2.5-3B: Standard 7.2%; CoT 59.1% (236.4 tokens); CoD 43.1% (41.2 tokens). Llama3.2-3B-Instruct: Standard 3.9%; CoT 70.7% (195.3 tokens); CoD 52.5% (98.1 tokens). Zoom-SLM-2.3B: Standard 5.9%; CoT 77.7% (129.0 tokens); CoD 50.9% (55.6 tokens).",
            "internal_analysis": "No internal mechanistic probes; authors interpret lower CoD performance as likely due to absence of CoD-style concise reasoning in pretraining/fine-tuning data and limited model capacity to generalize from few-shot concise drafts.",
            "failure_modes": "CoD performance gap vs CoT is substantially larger for small models; CoD often underperforms CoT by large margins (e.g., 20+ percentage points); standard prompting nearly fails on GSM8k for these models.",
            "scaling_trend": "Performance increases with model capability/size: CoT and CoD both improve as models grow, but CoD lags behind CoT more severely at small scales; authors suggest fine-tuning on CoD-formatted data may close the gap.",
            "uuid": "e6397.5",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "Zero-shot CoD limitation",
            "name_full": "Observed inconsistency of Chain-of-Draft prompting in zero-shot settings",
            "brief_description": "The paper reports that CoD's benefits rely on few-shot examples: in zero-shot, CoD's improvement over direct-answering is minimal for some models (e.g., about +3.6% for Claude 3.5 Sonnet on GSM8k).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "claude-3-5-sonnet-20240620 (Claude 3.5 Sonnet)",
            "model_family": "Transformer (decoder-only)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k (zero-shot)",
            "task_type": "multi-step grade-school word problems",
            "problem_format": "natural-language word problems (zero-shot, CoD instruction only, no few-shot examples)",
            "difficulty_level": "grade-school / multi-step arithmetic",
            "prompting_method": "zero-shot Chain-of-Draft (guideline to keep steps concise but no few-shot examples)",
            "performance_metric": "accuracy (percentage)",
            "performance_value": "Reported improvement over direct answering for Claude 3.5 Sonnet: +3.6% (exact table values not fully shown in paper excerpt).",
            "internal_analysis": "Authors attribute zero-shot weakness to the lack of CoD-formatted training data and reliance on few-shot exemplars for instructing concise-step behavior; no deeper mechanistic analysis was performed.",
            "failure_modes": "CoD without few-shot examples is inconsistent and provides only marginal gains over direct-answer prompting; models may ignore brevity guidance.",
            "scaling_trend": "Zero-shot CoD is weak across evaluated models; few-shot exemplars are crucial, particularly for smaller models.",
            "uuid": "e6397.6",
            "source_info": {
                "paper_title": "Chain of Draft: Thinking Faster by Writing Less",
                "publication_date_yy_mm": "2025-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 2,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        },
        {
            "paper_title": "Concise thoughts: Impact of output length on llm reasoning and cost",
            "rating": 2,
            "sanitized_title": "concise_thoughts_impact_of_output_length_on_llm_reasoning_and_cost"
        },
        {
            "paper_title": "Token-budget-aware llm reasoning",
            "rating": 2,
            "sanitized_title": "tokenbudgetaware_llm_reasoning"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 1,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Training large language models to reason in a continuous latent space",
            "rating": 1,
            "sanitized_title": "training_large_language_models_to_reason_in_a_continuous_latent_space"
        }
    ],
    "cost": 0.014093999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Chain of Draft: Thinking Faster by Writing Less</p>
<p>Silei Xu 
Wenhao Xie 
Lingxiao Zhao 
Pengcheng He 
Chain of Draft: Thinking Faster by Writing Less
6E40B468413A7C1BDFA8E6142737F89E
Large Language Models (LLMs) have demonstrated remarkable performance in solving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT) prompting, which emphasizes verbose, step-by-step reasoning.However, humans typically employ a more efficient strategy: drafting concise intermediate thoughts that capture only essential information.In this work, we propose Chain of Draft (CoD), a novel paradigm inspired by human cognitive processes, where LLMs generate minimalistic yet informative intermediate reasoning outputs while solving tasks.By reducing verbosity and focusing on critical insights, CoD matches or surpasses CoT in accuracy while using as little as only 7.6% of the tokens, significantly reducing cost and latency across various reasoning tasks.Our code and data are available at https://github.com/sileix/chain-of-draft.</p>
<p>Introduction</p>
<p>Recent advances in reasoning models such as Ope-nAI o1 (OpenAI, 2024) and DeepSeek R1 (Guo et al., 2025) have propelled large language models (LLMs) to unprecedented performance on complex tasks using techniques like Chain of Thought (CoT) (Wei et al., 2022).This paradigm encourages models to break down problems into step-bystep explorations, mimicking the structured reasoning process of humans.While effective, this approach demands substantially more computational resources at inference time, leading to verbose outputs and higher latency.Such verbosity contrasts sharply with how humans typically approach problem-solving: we rely on concise drafts or shorthand notes to capture essential insights without unnecessary elaboration.</p>
<p>Motivated by this difference, we propose Chain of Draft (CoD), a novel prompting strategy that † Correspondence to <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#115;&#105;&#108;&#101;&#105;&#46;&#120;&#117;&#64;&#122;&#111;&#111;&#109;&#46;&#117;&#115;">&#115;&#105;&#108;&#101;&#105;&#46;&#120;&#117;&#64;&#122;&#111;&#111;&#109;&#46;&#117;&#115;</a>aligns more closely with human reasoning by prioritizing efficiency and minimalism.Instead of verbose intermediate steps, Chain of Draft encourages LLMs to generate concise, dense-information outputs at each step.This approach reduces latency and computational costs without sacrifice of accuracy, making LLMs more practical for real-world applications where efficiency is paramount.</p>
<p>The intuition behind Chain of Draft is rooted in how humans externalize thought.When solving complex tasks -whether solving mathematical problems, drafting essays, or coding -we often jot down only the critical pieces of information that help us progress.By emulating this behavior, LLMs can focus on advancing toward solutions without the overhead of verbose reasoning.</p>
<p>arXiv:2502.18600v2 [cs.CL] 3 Mar 2025</p>
<p>To evaluate the effectiveness of Chain of Draft, we conducted experiments across a variety of benchmarks requiring multi-step reasoning, including arithmetic reasoning, common sense reasoning, and symbolic reasoning.Our results demonstrate that this minimalist approach maintains or even improves accuracy compared with standard Chain of Thought, while significantly reducing token usage and latency.</p>
<p>The contributions of this paper are threefold:</p>
<p>• We introduce Chain of Draft, a concise reasoning prompting strategy inspired by human cognitive processes.</p>
<p>• We empirically validate that Chain of Draft can achieve significantly reduced latency and cost without sacrificing accuracy.</p>
<p>• We discuss the implications of Chain of Draft for LLM design, deployment, and real-world usability.</p>
<p>Related Work</p>
<p>Structured Reasoning Frameworks for LLMs Recently, a variety of reasoning language models have emerged, including o1 by OpenAI (OpenAI, 2024), QwQ by Alibaba (Team, 2024), and R1 by DeepSeek (Guo et al., 2025), demonstrating substantial improvements in tackling complex tasks.These models leverage structured reasoning methods to enhance robustness and problem-solving capabilities.The concept of Chain-of-Thought reasoning (CoT) (Wei et al., 2022;Kojima et al., 2022), established a foundational approach to reasoning in LLMs.Building on this foundation, more sophisticated topologies have emerged, such as tree (Yao et al., 2024;Chen et al., 2024a;Yu et al., 2023) and graph (Besta et al., 2024;Lei et al., 2023;Jiang et al., 2023), enabling LLMs to address increasingly intricate problems.</p>
<p>Other enhancements include self-consistency CoT (Wang et al., 2022), which incorporates verification and reflection mechanisms to bolster reasoning reliability, and ReAct (Yao et al., 2022), which integrates tool usage into the reasoning process, allowing LLMs to access external resources and knowledge.These innovations collectively expand the reasoning capabilities of LLMs across a diverse range of applications.LLM Inference Latency Reduction Although structured reasoning greatly enhances LLMs' ability to solve complex questions, it significantly in-creases the token usage before arriving at a final answer.This makes it challenging to apply in costsensitive and latency-sensitive scenarios (Wang et al., 2024).Furthermore, the model's lack of awareness regarding task complexity often leads to overthinking (Chen et al., 2024b;Chiang and Lee, 2024) even on simple tasks, resulting in unnecessary resource consumption.</p>
<p>Techniques like streaming aim to reduce perceived latency by incrementally providing partial outputs as they are generated, rather than waiting for the entire output sequence.However, this approach cannot fully mitigate overall latency or computational cost, and it is often unsuitable for chain-of-thought reasoning, as intermediate steps are often not intended to be shown to end users.Ning et al. (2023) proposes Skeleton-of-Thought (SoT), a method that first guides LLMs to generate a skeleton outline of the answer, followed by parallel decoding to reduce latency.While SoT helps lower latency, it does not reduce computational cost and is limited to questions that can be parallelized effectively.Zhang et al. (2023) took a different approach, it first generates draft tokens at lower quality but higher speed through selective skipping of intermediate layers, and then validates the draft in a single forward pass.Our approach, CoD, can be combined with these approaches to further reduce the latency.Hao et al. (2024) proposes Coconut to train LLMs to perform reasoning in a continuous latent space rather than in the traditional natural language space using the final hidden state of the LLM to represent the reasoning process.While Coconut reduces latency and computational cost, it suffers from reduced accuracy in complex tasks, such as GSM8k.Additionally, it loses the interpretability of natural language reasoning and cannot be applied to black-box models like GPT and Claude.</p>
<p>The works closest to ours are Concise Thoughts (CCoT) (Nayab et al., 2024) and token-budgetaware LLM reasoning (TALE) (Han et al., 2024).CCoT proposes using a fixed global token budget for reasoning steps.However, different tasks may require varying budgets to achieve the optimal balance between performance and cost.Moreover, LLMs may fail to adhere to an impractical budget, often generating far more tokens than intended (Han et al., 2024).Han et al. (2024) extends this idea by dynamically estimating a global token budget for different problems based on reasoning complexity.However, this approach requires an additional LLM call to estimate the budget, which increases latency.Furthermore, it assumes that the model can accurately predict the complexity of requests, limiting its applicability to more complex tasks where reflection, self-correction, or external knowledge retrieval may be necessary during the reasoning process.In contrast, our approach employs a per-step budget, allowing unlimited reasoning steps, which makes it more adaptable to various structured reasoning techniques.</p>
<p>Chain-of-Draft Prompting</p>
<p>The Chain-of-Thought (CoT) prompting strategy has demonstrated significant effectiveness across a wide range of tasks, particularly those requiring complex multi-step reasoning.However, LLMs often produce excessively verbose reasoning steps, consuming a substantial number of tokens before arriving at a final answer.In contrast, humans tend to adopt a more concise approach when solving complex problems involving multi-step reasoning, such as mathematical or logical puzzles.Rather than elaborating on every detail, humans typically jot down only the essential intermediate resultsminimal drafts -to facilitate their thought processes.Inspired by this natural tendency, we propose a novel prompting strategy called Chain-of-Draft (CoD).This approach aims to reduce verbosity by limiting the number of words used in each reasoning step, focusing only on the essential calculations or transformations needed to progress.</p>
<p>To illustrate the difference between standard prompting, Chain-of-Thought prompting, and our proposed Chain-of-Draft prompting, consider the following simple arithmetic problem: Q: Jason had 20 lollipops.He gave Denny some lollipops.Now Jason has 12 lollipops.How many lollipops did Jason give to Denny?</p>
<p>The response generated by a standard prompting approach directly outputs the answer, often without any reasoning.While correct, this lacks transparency in how the answer was derived, and requires the language model to run multi-step reasoning without any help from intermediate result, which often leads to hallucination.Chain-of-Thought prompting, on the other hand, provides a detailed reasoning process.While this response is accurate and interpretable, it includes unnecessary details about Jason, Denny, and the lollipops, which are irrelevant to solving the mathematical problem.This verbosity inflates the token count and increases the response latency.</p>
<p>Chain-of-Thought Q: Jason had 20 lollipops.He gave Denny some lollipops.Now Jason has 12 lollipops.How many lollipops did Jason give to Denny?A: Let's think through this step by step: 1.Initially, Jason had 20 lollipops.2. After giving some to Denny, Jason now has 12 lollipops.3. To find out how many lollipops Jason gave to Denny, we need to calculate the difference between the initial number of lollipops and the remaining number.4. We can set up a simple subtraction problem: Initial number of lollipops -Remaining number of lollipops = Lollipops given to Denny 5. Putting in the numbers: 20 -12 = Lollipops given to Denny 6. Solving the subtraction: 20 -12 = 8 Therefore, Jason gave 8 lollipops to Denny.#### 8 lollipops By contrast, Chain-of-Draft prompting condenses the reasoning process into minimal, abstract representations.Here, the reasoning is distilled into a concise equation, focusing solely on the essential mathematical operation required to arrive at the solution.By abstracting away irrelevant contextual details, CoD significantly reduces the token count while maintaining transparency and correctness.</p>
<p>Chain-of-Draft</p>
<p>Q: Jason had 20 lollipops.He gave Denny some lollipops.Now Jason has 12 lollipops.How many lollipops did Jason give to Denny?A: 20 -x = 12; x = 20 -12 = 8. #### 8</p>
<p>Experiments</p>
<p>In empirical experiments, we follow the original CoT paper (Wei et al., 2022) to evaluate on 3 categories of tasks: arithmetic reasoning, commonsense reasoning, and symbolic reasoning.We pick representative tasks where original CoT significantly improves the accuracy over the baseline without reasoning.In particular, we pick GSM8k (Cobbe et al., 2021) for arithmetic reasoning; date understanding and sports understanding from BIG-bench (bench authors, 2023) for commonsense reasoning; and coin flip tasks introduced in the CoT paper (Wei et al., 2022) for symbolic reasoning.</p>
<p>Experimental Setup</p>
<p>We compare three different prompt strategies: CoT, CoD, and Standard prompting as a baseline.</p>
<p>Standard prompting.we use standard few-shot prompting (Brown et al., 2020), where the model is given input-output pairs as in-context examples.LLMs are asked to directly return the final answer, without any reasoning or explanation.Chain-of-Thought.We follow the exact few-shot examples provided in the appendix of the CoT paper with the exception of having the final answer after four hashtags (####) for a more stable answer extraction.Chain-of-Draft.In CoD, we also asked the model to think step by step.However, the model is asked to limit each reasoning step to five words at most.Note that we do not enforce such limitation in any way, it is just a general guideline to promte short reasoning steps.For each few-shot example, we also include the Chain of Draft written manually by the authors.</p>
<p>The complete system prompt for each prompting strategy is shown below.</p>
<p>Standard</p>
<p>Answer the question directly.Do not return any preamble, explanation, or reasoning.</p>
<p>Chain-of-Thought</p>
<p>Think step by step to answer the following question.Return the answer at the end of the response after a separator ####.</p>
<p>Chain-of-Draft</p>
<p>Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most.Return the answer at the end of the response after a separator ####.</p>
<p>We evaluated each task with two of the most popular flagship models: GPT-4o (gpt-4o-2024-08-06) from OpenAI and Claude 3.5 Sonnet (claude-3-5-sonnet-20240620) from Anthropic.</p>
<p>Arithmetic Reasoning</p>
<p>We first consider math problems that measure the arithmetic reasoning capabilities of LLMs.GSM8k (Cobbe et al., 2021) has emerged as the benchmark of choice for evaluating arithmetic reasoning in language models, providing a comprehensive dataset of 8,500 diverse grade-school-level mathematical problems.Each problem is paired with a detailed step-by-step solution, emphasizing arithmetic, geometry, algebra, and logical reasoning skills.</p>
<p>The evaluation results are presented in Table 1.The dataset poses significant challenges for both GPT-4o and Claude 3.5 Sonnet when using standard prompting, yielding accuracies of 53.3% and 64.6%, respectively.However, with the application of the CoT, both models surpass 95% accuracy, albeit at the expense of generating approximately 200 tokens per response.In contrast, CoD achieves an accuracy of 91% for both models while requiring only about 40 tokens per response, thereby reducing the average output token count by 80% and cutting the average latency by 76.2% and 48.4%, respectively.</p>
<p>Model</p>
<p>Commonsense Reasoning</p>
<p>We evaluate the tasks of date understanding and sports understanding from BIG-bench to demonstrate the effectiveness of CoD in common sense reasoning.For consistency, we use the same system prompts as those employed in the arithmetic reasoning evaluation.</p>
<p>The evaluation results, presented in Table 2, show that CoD significantly reduces both latency and cost by generating considerably fewer tokens in responses compared to CoT.Additionally, CoD outperforms CoT in accuracy in various cases.Notably, chain-of-thought prompting leads to excessively verbose responses for Claude 3.5 Sonnet, especially in the sports understanding task, where CoD reduces the average output tokens from 189.4 to 14.3 -a 92.4% reduction.</p>
<p>Symbolic Reasoning</p>
<p>The original CoT paper (Wei et al., 2022)   are asked to predict which side is up after a sequence of coin flip actions.Since the exact dataset is not published, we synthesize a test set of 250 examples following the same design.Specifically, we randomly chose 4 out of the top 1000 first names in the US region according to NameDataset (Remy, 2021) and randomly decided to flip the coin or not for each name.An example of the evaluation data is shown below.The evaluation results for GPT-4o and Claude 3.5 Sonnet are shown in Table 4.They achieve 73.2% and 85.2% with standard prompting, respectively.However, both models reach a perfect 100% accuracy with CoT and CoD.Again, CoD demonstrates significant reduction of tokens compared to CoT, from 68% for GPT-4o to 86% for Claude 3.5 Sonnet.</p>
<p>Model</p>
<p>Reduced Performance on Small Models</p>
<p>We tested CoD on several small language models with fewer than 3B parameters, including Qwen2.5 1.5B/3B instruct (Yang et al., 2024), Llama 3.2 3B instruct (Dubey et al., 2024), and our in-house Zoom SLM 2.3B model (Zoom, 2025).While CoD effectively reduces the number of tokens required per response and improves accuracy over direct answer, its performance gap compared to CoT is more pronounced in these models.Similar to the zero-shot setting, we suspect this is due to the absence of CoD-style data in the training process.We anticipate that fine-tuning these models with additional CoD-formatted data could significantly enhance their reasoning accuracy with CoD.The latency issue has often been overlooked in studies of the reasoning capabilities of LLMs.However, it is crucial for lots of real-time applications to have low latency while maintaining high-quality responses.In this work, we propose Chain of Draft (CoD), a novel approach that substantially reduces the latency required for reasoning while achieving comparable or even superior accuracy compared to standard Chain-of-Thought prompting strategies.Unlike traditional methods that often involve lengthy reasoning steps, CoD leverages concise reasoning drafts to speed up response generation without sacrificing correctness.Additionally, CoD offers significant cost advantages.By compacting the reasoning steps, it reduces the number of input tokens required for few-shot prompting and shortens the output token length, directly lowering computational cost.This token efficiency makes CoD especially appealing in cost-sensitive scenarios, such as large-scale deployments of LLMs or applications with strict budget constraints.</p>
<p>CoD demonstrates that effective reasoning in LLMs does not necessarily require lengthy outputs, offering an alternative approach where reasoning depth is maintained with minimal verbosity.Future work could explore combining CoD with other latency-reducing methods, such as adaptive parallel reasoning or multi-pass validation, to further optimize performance across different application domains.In addition, the principles behind the compact reasoning of CoD could inspire new strategies to improve reasoning models by training with compact reasoning data, while maintaining interpretability and efficiency in LLMs, helping bridge the gap between research-driven improvements in reasoning and the practical demands of real world systems.</p>
<p>Figure 1 :
1
Figure 1: Comparison of Claude 3.5 Sonnet's accuracy and token usage across different tasks with three different prompt strategies: direct answer (Standard), Chain of Thought (CoT), and Chain of Draft (CoD).CoD achieves similar accuracy as CoT while using significant fewer tokens.</p>
<p>StandardQ:</p>
<p>Jason had 20 lollipops.He gave Denny some lollipops.Now Jason has 12 lollipops.How many lollipops did Jason give to Denny?A: 8</p>
<p>Q: A coin is heads up.Robyn flips the coin.Peggy flips the coin.Grant flips the coin.Vanessa does not flip the coin.Is the coin still heads up?A: No.</p>
<p>Table 1 :
1
GSM8K evaluation results.
PromptAccuracy Token # LatencyStandard53.3%1.10.6 sGPT-4oCoT95.4%205.14.2 sCoD91.1%43.91.0 sStandard64.6%1.10.9 sClaude 3.5 SonnetCoT95.8%190.03.1 sCoD91.4%39.81.6 s</p>
<p>Table 2 :
2
Date understanding evaluation results.
ModelPromptAccuracy Token # LatencyStandard72.6%5.20.6 sGPT-4oCoT90.2%75.71.7 sCoD88.1%30.21.3 sStandard84.3%5.21.0 sClaude 3.5 SonnetCoT87.0%172.53.2 sCoD89.7%31.31.4 s</p>
<p>introduces the task of coin flipping, where the LLMs
ModelPromptAccuracy Token # LatencyStandard90.0%1.00.4 sGPT-4oCoT95.9%28.70.9 sCoD98.3%15.00.7 sStandard90.6%1.00.9 sClaude 3.5 SonnetCoT93.2%189.43.6 sCoD97.3%14.31.0 s</p>
<p>Table 3 :
3
Sports understanding evaluation results.</p>
<p>Table 4 :
4
Coin flip evaluation results.
PromptAccuracy Token # LatencyStandard73.2%1.00.4 sGPT-4oCoT100.0%52.41.4 sCoD100.0%16.80.8 sStandard85.2%1.01.2 sClaude 3.5 SonnetCoT100.0%135.33.1 sCoD100.0%18.91.6 s4.5 Limitaitons of CoDInconsistency Without Few-shot ExamplesWe evaluated the performance of CoD under zero-shot setting, where no few-shot examples were pro-vided. The results, presented in Table 5, indicate asignificant decline in CoD's effectiveness. Notably,for Claude 3.5 Sonnet, CoD improved performanceover direct answering by only 3.6%. Additionally,</p>
<p>Table 5 :
5
Zero-shot GSM8K evaluation results.</p>
<p>Table 6 :
6
GSM8K evaluation results on small language models.
ModelPromptAccuracy Token #Standard5.7%6.6Qwen2.5-1.5B-InstructCoT32.5%141.4CoD24.2%75.1Standard7.2%3.4Qwen2.5-3B-InstructCoT59.1%236.4CoD43.1%41.2Standard3.9%16.6Llama3.2-3B-InstructCoT70.7%195.3CoD52.5%98.1Standard5.9%3.8Zoom-SLM-2.3BCoT77.7%129.0CoD50.9%55.6</p>
<p>Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. BIG bench authors. 2023</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Alec Radford, Ilya Sutskever, and Dario Amodei. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlishCurran Associates, Inc202033Language models are few-shot learners</p>
<p>Boosting of thoughts: Trial-and-error problem solving with large language models. Sijia Chen, Baochun Li, Di Niu, arXiv:2402.111402024aarXiv preprint</p>
<p>Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, arXiv:2412.21187Do not think that much for 2+ 3=? on the overthinking of o1-like llms. 2024barXiv preprint</p>
<p>Cheng- , Han Chiang, Hung-Yi Lee, arXiv:2401.11467Overreasoning and redundant calculation of large language models. 2024arXiv preprint</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, arXiv:2407.21783The llama 3 herd of models. 2024arXiv preprint</p>
<p>Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, arXiv:2501.12948Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. 2025arXiv preprint</p>
<p>Tingxu Han, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen, Zhenting Wang, arXiv:2412.18547Token-budget-aware llm reasoning. 2024arXiv preprint</p>
<p>Training large language models to reason in a continuous latent space. Shibo Hao, Sainbayar Sukhbaatar, Dijia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian, arXiv:2412.067692024arXiv preprint</p>
<p>Resprompt: Residual connection prompting advances multi-step reasoning in large language models. Song Jiang, Zahra Shakeri, Aaron Chan, Maziar Sanjabi, Hamed Firooz, Yinglong Xia, Bugra Akyildiz, Yizhou Sun, Jinchao Li, Qifan Wang, arXiv:2310.047432023arXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Bin Lei, Chunhua Liao, Caiwen Ding, arXiv:2308.08614Boosting logical reasoning in large language models through a new framework: The graph of thought. 2023arXiv preprint</p>
<p>Sania Nayab, Giulio Rossolini, Giorgio Buttazzo, Nicolamaria Manes, Fabrizio Giacomelli, arXiv:2407.19825Concise thoughts: Impact of output length on llm reasoning and cost. 2024arXiv preprint</p>
<p>Skeleton-ofthought: Large language models can do parallel decoding. Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, Yu Wang, 2023Proceedings ENLSP-III</p>
<p>Openai o1 system card. 2024OpenAI</p>
<p>. Philippe Remy, 2021</p>
<p>Qwq: Reflect deeply on the boundaries of the unknown. Qwen Team, 2024</p>
<p>Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, Ben Athiwaratkun, arXiv:2406.06461Reasoning in token economies: Budget-aware evaluation of llm reasoning strategies. 2024arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712022arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. Curran Associates, Inc202235</p>
<p>An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, arXiv:2412.15115Qwen2. 5 technical report. 2024arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in Neural Information Processing Systems. 202436</p>
<p>Thought propagation: An analogical approach to complex reasoning with large language models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629arXiv:2310.03965React: Synergizing reasoning and acting in language models. 2022. 2023arXiv preprintJunchi Yu, Ran He, and Rex Ying</p>
<p>Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Sharad Mehrotra, arXiv:2309.08168Draft &amp; verify: Lossless large language model acceleration via self-speculative decoding. 2023arXiv preprint</p>
<p>How we're preparing for the next era of AI. 2025</p>            </div>
        </div>

    </div>
</body>
</html>