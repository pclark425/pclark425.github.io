<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2721 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2721</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2721</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-70.html">extraction-schema-70</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <p><strong>Paper ID:</strong> paper-210932334</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2001.10161v1.pdf" target="_blank">Bringing Stories Alive: Generating Interactive Fiction Worlds</a></p>
                <p><strong>Paper Abstract:</strong> World building forms the foundation of any task that requires narrative intelligence. In this work, we focus on procedurally generating interactive fiction worlds---text-based worlds that players"see"and"talk to"using natural language. Generating these worlds requires referencing everyday and thematic commonsense priors in addition to being semantically consistent, interesting, and coherent throughout. Using existing story plots as inspiration, we present a method that first extracts a partial knowledge graph encoding basic information regarding world structure such as locations and objects. This knowledge graph is then automatically completed utilizing thematic knowledge and used to guide a neural language generation model that fleshes out the rest of the world. We perform human participant-based evaluations, testing our neural model's ability to extract and fill-in a knowledge graph and to generate language conditioned on it against rule-based and human-made baselines. Our code is available at https://github.com/rajammanabrolu/WorldGeneration.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2721.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2721.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KG-agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge-graph-based text-game agents (Ammanabrolu & Riedl / Ammanabrolu et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced class of text-adventure game agents that use an explicit knowledge graph as the agent's state representation to guide action selection and learning in language-based reinforcement learning settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer in deep reinforcement learning using knowledge graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>KG-RL Agent (Ammanabrolu & Riedl et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Deep reinforcement learning agents that represent the environment as an explicit knowledge graph (entities, relations) and use that graph to constrain or inform action selection in natural-language action spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>text-adventure games / TextWorld (interactive fiction)</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>Parser-based text-adventure games where the agent must infer hidden state from textual observations and perform sequences of text actions (move, examine, use, etc.) to complete tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>graph-based memory (knowledge graph)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Explicit entity-relation graph encoding locations, objects, characters, and relations between them</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>World state: discovered locations, objects/containers, characters, relations/affordances and their properties</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>State representation for planning, constraining action selection in natural-language RL and supporting transfer across games</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Mentioned as effective in prior work for representing state in text games; this paper cites these works as examples that use knowledge graphs as state representations. (No quantitative results reported here.)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bringing Stories Alive: Generating Interactive Fiction Worlds', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2721.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2721.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AskBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AskBERT (ALBERT-based graph construction and completion)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method introduced in this paper that uses an ALBERT question-answering model to iteratively extract entities and relations from story plots and to fill missing thematic commonsense relations into a knowledge graph used as the skeleton for generating interactive fiction worlds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>AskBERT (ALBERT QA graph constructor)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not a game-playing agent; a pipeline that leverages an ALBERT QA model to (1) iteratively extract vertices (locations, characters, objects) by asking targeted QA prompts and masking found answers, and (2) construct and complete a knowledge graph by querying relations (e.g., 'What location can I visit from X?') and matching QA outputs to vertices.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>graph-based memory (knowledge graph produced as a world/state representation)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Entity–relation graph (vertices for locations/characters/objects, edges for 'has' and adjacency/'next to' relations and inferred affordances)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>Entities and relations extracted from story plots plus inferred thematic commonsense relations and affordances linking entities (locations, objects, characters)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td>QA-driven retrieval: queries the full story context with ALBERT and matches QA answer tokens to graph vertices by token overlap and answer probability</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Iterative: vertex extraction masks found answers and repeats until <no-answer>; relation edges added by posing relation questions and adding highest-probability matches, repeating until graph completed</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>Serves as the structural memory/skeleton to guide description generation and to assemble playable interactive fiction worlds</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative human evaluation: AskBERT (neural) graphs were judged more coherent and better matching genre than random-link graphs and often outperformed rule-based OpenIE5 graphs, particularly in the fairy-tale genre where thematic commonsense diverges from everyday knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>A random-link ablation (same vertices but random edges) performed worse on coherence and genre resemblance; rules-based OpenIE5 sometimes performed competitively (especially in mystery) but had different trade-offs (e.g., more objects but fewer correct locations/relations).</td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Filling in knowledge graphs using thematically relevant (QA-inferred) commonsense improves perceived coherence and genre adherence for generated worlds; the ablation connecting vertices randomly showed that accurate relation prediction (graph structure) materially affects coherence and interestingness, especially in genres with divergent thematic commonsense (fairy-tales).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>In some cases (mystery genre) rule-based extraction produced more relations than the neural AskBERT graphs; AskBERT may produce fewer relations or different entity counts depending on genre and the overlap between story/theme and the QA model's training data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td>The paper's results indicate AskBERT's QA-driven graph completion (thematic commonsense filling) performs best for generating coherent, genre-consistent worlds compared to a random-link ablation and a rule-based OpenIE5 pipeline, particularly for fairy-tale genre.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bringing Stories Alive: Generating Interactive Fiction Worlds', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2721.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2721.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenIE5-baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenIE5-rule-based graph construction baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A rule-based information-extraction baseline that uses OpenIE5 triples, NER and POS tagging to identify locations, characters, and objects and to construct knowledge graphs from story plots.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>OpenIE5-based extractor (rule-based)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Pipeline that runs OpenIE5 on story sentences to extract triples, uses location annotations and heuristics (assume persistent location between explicit mentions) plus NER/POS filtering to construct a knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>rule-extracted knowledge graph</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Triples (entity, relation, entity) converted/aggregated into a graph by associating triples with locations and linking entities within the same location span</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>Extracted triples: entities, relations, and location annotations (converted to nodes/edges in the graph)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Heuristic association: triples extracted per sentence are associated with the most recent explicit location mention until a new explicit location appears</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>Provides a graph-based skeleton used to generate templated descriptions and assemble games (rule-based description generation uses TextWorld templates)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Human evaluation: rule-based graphs had more objects overall and performed well on genre resemblance in the mystery genre; in full-game evaluations, rule-based games were sometimes preferred for 'interestingness' in mystery genre but underperformed in fairy-tales compared to AskBERT.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Rule-based extraction can be effective when themes closely match everyday commonsense (e.g., mysteries) but struggles when thematic commonsense diverges (e.g., fairy-tales) because it lacks the thematic, inferential filling that AskBERT provides.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>Often misses or misidentifies locations/characters, relies on heuristics assuming persistent location across sentence spans, and lacks thematic commonsense filling leading to less coherent thematic worlds in genres with non-everyday elements.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bringing Stories Alive: Generating Interactive Fiction Worlds', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2721.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2721.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Nail</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Nail: A general interactive fiction agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited prior work presenting an agent for interactive fiction; referenced in related work but not described in detail in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Nail: A general interactive fiction agent</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Nail</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Prior work's general interactive fiction agent (cited); the paper references it in the context of other systems that play text-based games but provides no architecture or memory details here.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>interactive fiction / text-adventure games</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>General-purpose interactive fiction playing agent evaluated on parser-based text-adventure games (citation only; specifics not given in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bringing Stories Alive: Generating Interactive Fiction Worlds', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transfer in deep reinforcement learning using knowledge graphs <em>(Rating: 2)</em></li>
                <li>Graph constrained reinforcement learning for natural language action spaces <em>(Rating: 2)</em></li>
                <li>Playing text-adventure games with graph-based deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Nail: A general interactive fiction agent <em>(Rating: 2)</em></li>
                <li>Generating interactive worlds with text <em>(Rating: 1)</em></li>
                <li>TextWorld: A learning environment for text-based games <em>(Rating: 1)</em></li>
                <li>Learning to speak and act in a fantasy text adventure game <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2721",
    "paper_id": "paper-210932334",
    "extraction_schema_id": "extraction-schema-70",
    "extracted_data": [
        {
            "name_short": "KG-agent",
            "name_full": "Knowledge-graph-based text-game agents (Ammanabrolu & Riedl / Ammanabrolu et al.)",
            "brief_description": "Referenced class of text-adventure game agents that use an explicit knowledge graph as the agent's state representation to guide action selection and learning in language-based reinforcement learning settings.",
            "citation_title": "Transfer in deep reinforcement learning using knowledge graphs",
            "mention_or_use": "mention",
            "agent_name": "KG-RL Agent (Ammanabrolu & Riedl et al.)",
            "agent_description": "Deep reinforcement learning agents that represent the environment as an explicit knowledge graph (entities, relations) and use that graph to constrain or inform action selection in natural-language action spaces.",
            "base_model_size": null,
            "game_benchmark_name": "text-adventure games / TextWorld (interactive fiction)",
            "game_description": "Parser-based text-adventure games where the agent must infer hidden state from textual observations and perform sequences of text actions (move, examine, use, etc.) to complete tasks.",
            "uses_memory": true,
            "memory_type": "graph-based memory (knowledge graph)",
            "memory_structure": "Explicit entity-relation graph encoding locations, objects, characters, and relations between them",
            "memory_content": "World state: discovered locations, objects/containers, characters, relations/affordances and their properties",
            "memory_capacity": null,
            "memory_retrieval_strategy": null,
            "memory_update_strategy": null,
            "memory_usage_purpose": "State representation for planning, constraining action selection in natural-language RL and supporting transfer across games",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_memory_ablation": null,
            "memory_effectiveness_findings": "Mentioned as effective in prior work for representing state in text games; this paper cites these works as examples that use knowledge graphs as state representations. (No quantitative results reported here.)",
            "memory_limitations": null,
            "comparison_with_other_memory_types": false,
            "best_memory_configuration": null,
            "uuid": "e2721.0",
            "source_info": {
                "paper_title": "Bringing Stories Alive: Generating Interactive Fiction Worlds",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "AskBERT",
            "name_full": "AskBERT (ALBERT-based graph construction and completion)",
            "brief_description": "A method introduced in this paper that uses an ALBERT question-answering model to iteratively extract entities and relations from story plots and to fill missing thematic commonsense relations into a knowledge graph used as the skeleton for generating interactive fiction worlds.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "AskBERT (ALBERT QA graph constructor)",
            "agent_description": "Not a game-playing agent; a pipeline that leverages an ALBERT QA model to (1) iteratively extract vertices (locations, characters, objects) by asking targeted QA prompts and masking found answers, and (2) construct and complete a knowledge graph by querying relations (e.g., 'What location can I visit from X?') and matching QA outputs to vertices.",
            "base_model_size": null,
            "game_benchmark_name": null,
            "game_description": null,
            "uses_memory": true,
            "memory_type": "graph-based memory (knowledge graph produced as a world/state representation)",
            "memory_structure": "Entity–relation graph (vertices for locations/characters/objects, edges for 'has' and adjacency/'next to' relations and inferred affordances)",
            "memory_content": "Entities and relations extracted from story plots plus inferred thematic commonsense relations and affordances linking entities (locations, objects, characters)",
            "memory_capacity": null,
            "memory_retrieval_strategy": "QA-driven retrieval: queries the full story context with ALBERT and matches QA answer tokens to graph vertices by token overlap and answer probability",
            "memory_update_strategy": "Iterative: vertex extraction masks found answers and repeats until &lt;no-answer&gt;; relation edges added by posing relation questions and adding highest-probability matches, repeating until graph completed",
            "memory_usage_purpose": "Serves as the structural memory/skeleton to guide description generation and to assemble playable interactive fiction worlds",
            "performance_with_memory": "Qualitative human evaluation: AskBERT (neural) graphs were judged more coherent and better matching genre than random-link graphs and often outperformed rule-based OpenIE5 graphs, particularly in the fairy-tale genre where thematic commonsense diverges from everyday knowledge.",
            "performance_without_memory": "A random-link ablation (same vertices but random edges) performed worse on coherence and genre resemblance; rules-based OpenIE5 sometimes performed competitively (especially in mystery) but had different trade-offs (e.g., more objects but fewer correct locations/relations).",
            "has_memory_ablation": true,
            "memory_effectiveness_findings": "Filling in knowledge graphs using thematically relevant (QA-inferred) commonsense improves perceived coherence and genre adherence for generated worlds; the ablation connecting vertices randomly showed that accurate relation prediction (graph structure) materially affects coherence and interestingness, especially in genres with divergent thematic commonsense (fairy-tales).",
            "memory_limitations": "In some cases (mystery genre) rule-based extraction produced more relations than the neural AskBERT graphs; AskBERT may produce fewer relations or different entity counts depending on genre and the overlap between story/theme and the QA model's training data.",
            "comparison_with_other_memory_types": false,
            "best_memory_configuration": "The paper's results indicate AskBERT's QA-driven graph completion (thematic commonsense filling) performs best for generating coherent, genre-consistent worlds compared to a random-link ablation and a rule-based OpenIE5 pipeline, particularly for fairy-tale genre.",
            "uuid": "e2721.1",
            "source_info": {
                "paper_title": "Bringing Stories Alive: Generating Interactive Fiction Worlds",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "OpenIE5-baseline",
            "name_full": "OpenIE5-rule-based graph construction baseline",
            "brief_description": "A rule-based information-extraction baseline that uses OpenIE5 triples, NER and POS tagging to identify locations, characters, and objects and to construct knowledge graphs from story plots.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "OpenIE5-based extractor (rule-based)",
            "agent_description": "Pipeline that runs OpenIE5 on story sentences to extract triples, uses location annotations and heuristics (assume persistent location between explicit mentions) plus NER/POS filtering to construct a knowledge graph.",
            "base_model_size": null,
            "game_benchmark_name": null,
            "game_description": null,
            "uses_memory": true,
            "memory_type": "rule-extracted knowledge graph",
            "memory_structure": "Triples (entity, relation, entity) converted/aggregated into a graph by associating triples with locations and linking entities within the same location span",
            "memory_content": "Extracted triples: entities, relations, and location annotations (converted to nodes/edges in the graph)",
            "memory_capacity": null,
            "memory_retrieval_strategy": null,
            "memory_update_strategy": "Heuristic association: triples extracted per sentence are associated with the most recent explicit location mention until a new explicit location appears",
            "memory_usage_purpose": "Provides a graph-based skeleton used to generate templated descriptions and assemble games (rule-based description generation uses TextWorld templates)",
            "performance_with_memory": "Human evaluation: rule-based graphs had more objects overall and performed well on genre resemblance in the mystery genre; in full-game evaluations, rule-based games were sometimes preferred for 'interestingness' in mystery genre but underperformed in fairy-tales compared to AskBERT.",
            "performance_without_memory": null,
            "has_memory_ablation": false,
            "memory_effectiveness_findings": "Rule-based extraction can be effective when themes closely match everyday commonsense (e.g., mysteries) but struggles when thematic commonsense diverges (e.g., fairy-tales) because it lacks the thematic, inferential filling that AskBERT provides.",
            "memory_limitations": "Often misses or misidentifies locations/characters, relies on heuristics assuming persistent location across sentence spans, and lacks thematic commonsense filling leading to less coherent thematic worlds in genres with non-everyday elements.",
            "comparison_with_other_memory_types": false,
            "best_memory_configuration": null,
            "uuid": "e2721.2",
            "source_info": {
                "paper_title": "Bringing Stories Alive: Generating Interactive Fiction Worlds",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Nail",
            "name_full": "Nail: A general interactive fiction agent",
            "brief_description": "Cited prior work presenting an agent for interactive fiction; referenced in related work but not described in detail in this paper.",
            "citation_title": "Nail: A general interactive fiction agent",
            "mention_or_use": "mention",
            "agent_name": "Nail",
            "agent_description": "Prior work's general interactive fiction agent (cited); the paper references it in the context of other systems that play text-based games but provides no architecture or memory details here.",
            "base_model_size": null,
            "game_benchmark_name": "interactive fiction / text-adventure games",
            "game_description": "General-purpose interactive fiction playing agent evaluated on parser-based text-adventure games (citation only; specifics not given in this paper).",
            "uses_memory": null,
            "memory_type": null,
            "memory_structure": null,
            "memory_content": null,
            "memory_capacity": null,
            "memory_retrieval_strategy": null,
            "memory_update_strategy": null,
            "memory_usage_purpose": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_memory_ablation": null,
            "memory_effectiveness_findings": null,
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "best_memory_configuration": null,
            "uuid": "e2721.3",
            "source_info": {
                "paper_title": "Bringing Stories Alive: Generating Interactive Fiction Worlds",
                "publication_date_yy_mm": "2020-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transfer in deep reinforcement learning using knowledge graphs",
            "rating": 2,
            "sanitized_title": "transfer_in_deep_reinforcement_learning_using_knowledge_graphs"
        },
        {
            "paper_title": "Graph constrained reinforcement learning for natural language action spaces",
            "rating": 2,
            "sanitized_title": "graph_constrained_reinforcement_learning_for_natural_language_action_spaces"
        },
        {
            "paper_title": "Playing text-adventure games with graph-based deep reinforcement learning",
            "rating": 2,
            "sanitized_title": "playing_textadventure_games_with_graphbased_deep_reinforcement_learning"
        },
        {
            "paper_title": "Nail: A general interactive fiction agent",
            "rating": 2,
            "sanitized_title": "nail_a_general_interactive_fiction_agent"
        },
        {
            "paper_title": "Generating interactive worlds with text",
            "rating": 1,
            "sanitized_title": "generating_interactive_worlds_with_text"
        },
        {
            "paper_title": "TextWorld: A learning environment for text-based games",
            "rating": 1,
            "sanitized_title": "textworld_a_learning_environment_for_textbased_games"
        },
        {
            "paper_title": "Learning to speak and act in a fantasy text adventure game",
            "rating": 1,
            "sanitized_title": "learning_to_speak_and_act_in_a_fantasy_text_adventure_game"
        }
    ],
    "cost": 0.012928499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Bringing Stories Alive: Generating Interactive Fiction Worlds</p>
<p>Prithviraj Ammanabrolu raj.ammanabrolu@gatech.edu 
School of Interactive Computing
Georgia Institute of Technology</p>
<p>Wesley Cheung wcheung8@gatech.edu 
School of Interactive Computing
Georgia Institute of Technology</p>
<p>Dan Tu 
School of Interactive Computing
Georgia Institute of Technology</p>
<p>William Broniec 
School of Interactive Computing
Georgia Institute of Technology</p>
<p>Mark O Riedl riedl@gatech.edu 
School of Interactive Computing
Georgia Institute of Technology</p>
<p>Bringing Stories Alive: Generating Interactive Fiction Worlds</p>
<p>World building forms the foundation of any task that requires narrative intelligence. In this work, we focus on procedurally generating interactive fiction worlds-text-based worlds that players "see" and "talk to" using natural language. Generating these worlds requires referencing everyday and thematic commonsense priors in addition to being semantically consistent, interesting, and coherent throughout. Using existing story plots as inspiration, we present a method that first extracts a partial knowledge graph encoding basic information regarding world structure such as locations and objects. This knowledge graph is then automatically completed utilizing thematic knowledge and used to guide a neural language generation model that fleshes out the rest of the world.We perform human participant-based evaluations, testing our neural model's ability to extract and fill-in a knowledge graph and to generate language conditioned on it against rule-based and human-made baselines. Our code is available at https://github.com/ rajammanabrolu/WorldGeneration.</p>
<p>Introduction</p>
<p>Interactive fictions-also called text-adventure games or textbased games-are games in which a player interacts with a virtual world purely through textual natural languagereceiving descriptions of what they "see" and writing out how they want to act, an example can be seen in Figure 1. Interactive fiction games are often structured as puzzles, or quests, set within the confines of given game world. Interactive fictions have been adopted as a test-bed for real-time game playing agents [Narasimhan et al., 2015;Côté et al., 2018;Hausknecht et al., 2019b]. Unlike other, graphical games, interactive fictions test agents' abilities to infer the state of the world through communication and to indirectly affect change in the world through language. Interactive fictions are typically modeled after real or fantasy worlds; commonsense knowledge is an important factor in successfully * Denotes equal contribution. playing interactive fictions [Ammanabrolu and Riedl, 2019a;Yin and May, 2019].</p>
<p>In this paper we explore a different challenge for artificial intelligence: automatically generating text-based virtual worlds for interactive fictions. A core component of many narrative-based tasks-everything from storytelling to game generation-is world building. The world of a story or game defines the boundaries of where the narrative is allowed and what the player is allowed to do. There are four core challenges to world generation: (1) commonsense knowledge: the world must reference priors that the player possesses so that players can make sense of the world and build expectations on how to interact with it. This is especially true in interactive fictions where the world is presented textually because many details of the world necessarily be left out (e.g., the pot is on a stove; kitchens are found in houses) that might otherwise be literal in a graphical virtual world. (2) Thematic knowledge: interactive fictions usually involve a theme or genre that comes with its own expectations. For example, light speed travel is plausible in sci-fi worlds but not realistic in the real world. (3) Coherence: the world must not appear to be an random assortment of locations. (3) Natural language: The descriptions of the rooms as well as the permissible actions must text, implying that the system has natural language generation capability.</p>
<p>Because worlds are conveyed entirely through natural language, the potential output space for possible generated worlds is combinatorially large. To constrain this space and to make it possible to evaluate generated world, we present an approach which makes use of existing stories, building on the worlds presented in them but leaving enough room for the worlds to be unique. Specifically, we take a story such as Sherlock Holmes or Rapunzel-a linear reading experience-and extract the description of the world the story is set in to make an interactive world the player can explore.</p>
<p>Our method first extracts a partial, potentially disconnected knowledge graph from the story, encoding information regarding locations, characters, and objects in the form of entity, relation, entity triples. Relations between these types of entities as well as their properties are captured in this knowledge graph. However, stories often do not explicitly contain all the information required to fully fill out such a graph. A story may mention that there is a sword stuck in a stone but not what you can do with the sword or where it is</p>
<p>Bank vault</p>
<p>It is about three feet in height, and one and a half in width. Exits: Baker Street and Wilson's shop You see: Archie, Helper and John Clay Action: Examine John Clay John Clay Short, stocky, and one of the taller kind, John Clay is the kind of man who lives and dies by the watch he keeps.</p>
<p>Action: Go to Baker Street Baker Street Like any other street in London, it is a-stage-set, with the best and the worst of society crammed into one place. in relation to everything else. Our method fills in missing relation and affordance information using thematic knowledge gained from training on stories in a similar genre. This knowledge graph is then used to guide the text description generation process for the various locations, characters, and objects. The game is then assembled on the basis of the knowledge graph and the corresponding generated descriptions.</p>
<p>We have two major contributions.</p>
<p>(1) A neural model and a rules-based baseline for each of the tasks described above. The phases are that of graph extraction and completion followed by description generation and game formulation. Each of these phases are relatively distinct and utilize their own models. (2) A human subject study for comparing the neural model and variations on it to the rules-based and human-made approaches. We perform two separate human subject studies-one for the first phase of knowledge graph construction and another for the overall game creation process-testing specifically for coherence, interestingness, and the ability to maintain a theme or genre.</p>
<p>Related Work</p>
<p>There has been a slew of recent work in developing agents that can play text games [Narasimhan et al., 2015;Haroush et al., 2018;Côté et al., 2018;Hausknecht et al., 2019a]. Ammanabrolu and Riedl [2019a;2019b;2020] in particular use knowledge graphs as state representations for game-playing agents.  propose QAit, a set of question answering tasks framed as text-based or interactive fiction games. QAit focuses on helping agents learn procedural knowledge through interaction with a dynamic environment. These works all focus on agents that learn to play a given set of interactive fiction games as opposed to generating them.</p>
<p>Scheherazade [Li et al., 2012] is a system that learns a plot graph based on stories written by crowd sourcing the task of writing short stories. The learned plot graph contains details relevant to ensure story coherence. It includes: plot events, temporal precedence, and mutual exclusion relations. Scheherazade-IF [Guzdial et al., 2015] extends the system to generate choose-your-own-adventure style interactive fictions in which the player chooses from prescribed options. Womack and Freeman [2019] explore a method of creating interactive narratives revolving around locations, wherein sentences are mapped to a real-world GPS location from a corpus of sentences belonging to a certain genre. Narratives are made by chaining together sentences selected based on the player's current real-world location. In contrast to these models, our method generates a parser-based interactive fiction in which the player types in a textual command, allowing for greater expressiveness.  define the problem of procedural content generation in interactive fiction games in terms of the twin considerations of world and quest generation and focus on the latter. They present a system in which quest content is first generated by learning from a corpus and then grounded into a given interactive fiction world. The work is this paper focuses on the world generation problem glossed in the prior work. Thus these two systems can be seen as complimentary.</p>
<p>Light [Urbanek et al., 2019] is a crowdsourced dataset of grounded text-adventure game dialogues. It contains information regarding locations, characters, and objects set in a fantasy world. The authors demonstrate that the supervised training of transformer-based models lets us contextually relevant dialog, actions, and emotes. Most in line with the spirit of this paper, Fan et al. [2019] leverage Light to generate worlds for text-based games. They train a neural network based model using Light to compositionally arrange locations, characters, and objects into an interactive world. Their model is tested using a human subject study against other machine learning based algorithms with respect to the cohesiveness and diversity of generated worlds. Our work, in contrast, focuses on extracting the information necessary for building interactive worlds from existing story plots.</p>
<p>World Generation</p>
<p>World generation happens in two phases. In the first phase, a partial knowledge graph is extracted from a story plot and then filled in using thematic commonsense knowledge. In the second phase, the graph is used as the skeleton to generate a full interactive fiction game-generating textual descriptions or "flavortext" for rooms and embedded objects. We present a novel neural approach in addition to a rule guided baseline for each of these phases in this section.</p>
<p>Knowledge Graph Construction</p>
<p>The first phase is to extract a knowledge graph from the story that depicts locations, characters, objects, and the relations between these entities. We present two techniques. The first uses neural question-answering technique to extract relations from a story text. The second, provided as a baseline, uses OpenIE5 1 , a commonly used rule-based information extrac-1 https://github.com/dair-iitd/OpenIE-standalone tion technique. For the sake of simplicity, we considered primarily the location-location and location-character/object relations, represented by the "next to" and "has" edges respectively in Figure 2.</p>
<p>Neural Graph Construction</p>
<p>While many neural models already exist that perform similar tasks such as named entity extraction and part of speech tagging, they often come at the cost of large amounts of specialized labeled data suited for that task. We instead propose a new method that leverages models trained for context-grounded question-answering tasks to do entity extraction with no task dependent data or fine-tuning necessary. Our method, dubbed AskBERT, leverages the Question-Answering (QA) model ALBERT [Lan et al., 2019]. AskBERT consists of two main steps as shown in Figure 3: vertex extraction and graph construction.</p>
<p>The first step is to extract the set of entities-graph vertices-from the story. We are looking to extract information specifically regarding characters, locations, and objects. This is done by using asking the QA model questions such as "Who is a character in the story?". Ribeiro et al. [2019] have shown that the phrasing of questions given to a QA model is important and this forms the basis of how we formulate our questions-questions are asked so that they are more likely to return a single answer, e.g. asking "Where is a location in the story?" as opposed to "Where are the locations in the story?". In particular, we notice that pronoun choice can be crucial; "Where is a location in the story?" yielded more consistent extraction than "What is a location in the story?". AL-BERT QA is trained to also output a special <no-answer> token when it cannot find an answer to the question within the story. Our method makes use of this by iteratively asking QA model a question and masking out the most likely answer outputted on the previous step. This process continues until the <no-answer> token becomes the most likely answer.</p>
<p>The next step is graph construction. Typical interactive fiction worlds are usually structured as trees, i.e. no cycles except between locations. Using this fact, we use an approach that builds a graph from the vertex set by one relation-or edge-at a time. Once again using the entire story plot as context, we query the ALBERT-QA model picking a random starting location x from the set of vertices previously extracted.and asking the questions "What location can I visit from x?" and "Who/What is in x?". The methodology for phrasing these questions follows that described for the vertex extraction. The answer given by the QA model is matched to the vertex set by picking the vertex u that contains the best word-token overlap with the answer. Relations between vertices are added by computing a relation probability on the basis of the output probabilities of the answer given by the QA model. The probability that vertices x, u are related:
P (x, u) = p(x, u) + p(u, x) 2 (1) where p(x, u) = o∈QA outputs p(o)1{u = argmax v (v ∩ o)}(2)
is the sum of the individual token probabilities of all the overlapping tokens in the answer from the QA model and u.</p>
<p>Rule-Based Graph Construction</p>
<p>We compared our proposed AskBERT method with a nonneural, rule-based approach. This approach is based on the information extracted by OpenIE5, followed by some post-processing such as named-entity recognition and partof-speech tagging. OpenIE5 combines several cutting-edge ideas from several existing papers [Saha and Mausam, 2018;Pal and Mausam, 2016;Christensen et al., 2011] to create a powerful information extraction tools. For a given sentence, OpenIE5 generates multiple triples in the format of entity, relation, entity as concise representations of the sentence, each with a confidence score. These triples are also occasionally annotated with location information indicating that a triple happened in a location. As in the neural AskBERT model, we attempt to extract information regarding locations, characters, and objects. The entire story plot is passed into the OpenIE5 and we receive a set of triples. The location annotations on the triples are used to create a set of locations. We mark which sentences in the story contain these locations. POS tagging based on marking noun-phrases is then used in conjunction with NER to further filter the set of triples-identifying the set of characters and objects in the story.</p>
<p>The graph is constructed by linking the set of triples on the basis of the location they belong to. While some sentences contain very explicit location information for OpenIE5 to mark it out in the triples, most of them do not. We therefore make the assumption that the location remains the same for all triples extracted in between sentences where locations are explicitly mentioned. For example, if there exists locationA in the 1st sentence and locationB in the 5th sentence of the story, all the events described in sentences 1-4 are considered to take place in locationA. The entities mentioned in these events are connected to locationA in the graph.</p>
<p>Description Generation</p>
<p>The second phase involves using the constructed knowledge graph to generate textual descriptions of the entities we have extracted, also known as flavortext. This involves generating descriptions of what a player "sees" when they enter a location and short blurbs for each object and character. These descriptions need to not only be faithful to the information present in the knowledge graph and the overall story plot but to also contain flavor and be interesting for the player.</p>
<p>Neural Description Generation</p>
<p>Here, we approach the problem of description generation by taking inspiration from conditional transformer-based generation methods [Shirish Keskar et al., 2019]. Our approach is outlined in Figure 4 and an example description shown in Figure 1. For any given entity in the story, we first locate it in the story plot and then construct a prompt which consists of the entire story up to and including the sentence when the entity is first mentioned in the story followed by a question asking to describe that entity. With respect to prompts, we found that more direct methods such as question-answering were more consistent than open-ended sentence completion. For example, "Q: Who is the prince? A:" often produced descriptions that were more faithful to the information already present about the prince in the story than "You see the prince. He is/looks". For our transformer-based generation, we use a pre-trained 355M GPT-2 model [Radford et al., 2019] finetuned on a corpus of plot summaries collected from Wikipedia. The plots used for finetuning are tailored specific to the genre of the story in order to provide more relevant generation for the target genre. Additional details regarding the datasets used are provided in Section 4. This method strikes a balance between knowledge graph verbalization techniques which often lack "flavor" and open ended generation which struggles to maintain semantic coherence.</p>
<p>Rules-Based Description Generation</p>
<p>In the rule-based approach, we utilized the templates from the built-in text game generator of TextWorld [Côté et al., 2018] to generate the description for our graphs. TextWorld is an open-source library that provides a way to generate textgame learning environments for training reinforcement learning agents using pre-built grammars.</p>
<p>Two major templates involved here are the Room Intro Templates and Container Description Templates from TextWorld, responsible for generating descriptions of locations and blurbs for objects/characters respectively. The location and object/character information are taken from the knowledge graph constructed previously.</p>
<p>• Example of Room Intro Templates: "This might come as a shock to you, but you've just #entered# a <location-name>"</p>
<p>• Example of Container Description Templates: "The <location-name> #contains# <object/person-name>"</p>
<p>Each token surrounded by # sign can be expanded using a select set of terminal tokens. For instance, #entered# could be filled with any of the following phrases here: entered; walked into; fallen into; moved into; stumbled into; come into. Additional prefixes, suffixes and adjectives were added to increase the relative variety of descriptions. Unlike the neural methods, the rule-based approach is not able to generate detailed and flavorful descriptions of the properties of the locations/objects/characters. By virtue of the templates, however, it is much better at maintaining consistency with the information contained in the knowledge graph.</p>
<p>Evaluation</p>
<p>We conducted two sets of human participant evaluations by recruiting participants over Amazon Mechanical Turk. The first evaluation tests the knowledge graph construction phase, in which we measure perceived coherence and genre or theme resemblance of graphs extracted by different models. The second study compares full games-including description generation and game assembly, which can't easily be isolated from graph construction-generated by different methods. This study looks at how interesting the games were to the players in addition to overall coherence and genre resemblance. Both studies are performed across two genres: mystery and fairy-tales. This is done in part to test the relative effectiveness of our approach across different genres with varying thematic commonsense knowledge. The dataset used was compiled via story summaries that were scraped from Wikipedia via a recursive crawling bot. The bot searched pages for both for plot sections as well as links to other potential stories. From the process, 695 fairy-tales and 536 mystery stories were compiled from two categories: novels and short stories. We note that the mysteries did not often contain many fantasy elements, i.e. they consisted of mysteries set in our world such as Sherlock Holmes, while the fairy-tales were much more removed from reality. Details regarding how each of the studies were conducted and the corresponding setup are presented below.</p>
<p>Knowledge Graph Construction Evaluation</p>
<p>We first select a subset of 10 stories randomly from each genre and then extract a knowledge graph using three different models. Each participant is presented with the three graphs extracted from a single story in each genre and then asked to rank them on the basis of how coherent they were and how well the graphs match the genre. The graphs resembles the one shown in in Figure 2 and are presented to the  participant sequentially. The exact order of the graphs and genres was also randomized to mitigate any potential latent correlations. Overall, this study had a total of 130 participants.This ensures that, on average, graphs from every story were seen by 13 participants. In addition to the neural AskBERT and rules-based methods, we also test a variation of the neural model which we dub to be the "random" approach. The method of vertex extraction remains identical to the neural method, but we instead connect the vertices randomly instead of selecting the most confident according to the QA model. We initialize the graph with a starting location entity. Then, we randomly sample from the vertex set and connect it to a randomly sampled location in the graph until every vertex has been connected. This ablation in particular is designed to test the ability of our neural model to predict relations between entities. It lets us observe how accurately linking related vertices effects each of the metrics that we test for. For a fair comparison between the graphs produced by different approaches, we randomly removed some of the nodes and edges from the initial graphs so that the maximum number of locations per graph and the maximum number of objects/people per location in each story genre are the same.</p>
<p>The results are shown in Table 3. We show the median rank of each of the models for both questions across the genres. Ranked data is generally closely interrelated and so we perform Friedman's test between the three models to vali-  date that the results are statistically significant. This is presented as the p-value in table (asterisks indicate significance at p &lt; 0.05). In cases where we make comparisons between specific pairs of models, when necessary, we additionally perform the Mann-Whitney U test to ensure that the rankings differed significantly.</p>
<p>In the mystery genre, the rules-based method was often ranked first in terms of genre resemblance, followed by the neural and random models. This particular result was not statistically significant however, likely indicating that all the models performed approximately equally in this category. The neural approach was deemed to be the most coherent followed by the rules and random. For the fairy-tales, the neural model ranked higher on both of the questions asked of the participants. In this genre, the random neural model also performed better than the rules based approach.</p>
<p>Tables 1 and 2 show the statistics of the constructed knowledge graphs in terms of vertices and edges. We see that the rules-based graph construction has a lower number of locations, characters, and relations between entities but far more objects in general. The greater number of objects is likely due to the rules-based approach being unable to correctly identify locations and characters. The gap between the methods is less pronounced in the mystery genre as opposed to the fairy-tales, in fact the rules-based graphs have more relations than the neural ones. The random and neural models have the same number of entities in all categories by construction but random in general has lower variance on the number of relations found. In this case as well, the variance is lower for mystery as opposed to fairy-tales. When taken in the context of the results in Table 3, it appears to indicate that leveraging thematic commonsense in the form of AskBERT for graph construction directly results in graphs that are more coherent and maintain genre more easily. This is especially true in the case of the fairy-tales where the thematic and everyday commonsense diverge more than than in the case of the mysteries.</p>
<p>Full Game Evaluation</p>
<p>This participant study was designed to test the overall game formulation process encompassing both phases described in Section 3. A single story from each genre was chosen by hand from the 10 stories used for the graph evaluation process. From the knowledge graphs for this story, we generate descriptions using the neural, rules, and random approaches described previously. Additionally, we introduce a human-authored game for each story here to provide an additional benchmark. This author selected was familiar with text-adventure games in general as well as the genres of detective mystery and fairy tale. To ensure a fair comparison, we ensure that the maximum number of locations and maximum number of characters/objects per location matched the other methods. After setting general format expectations, the author read the selected stories and constructed knowledge graphs in a corresponding three step process of: identifying the n most important entities in the story, mapping positional relationships between entities, and then synthesizing flavor text for the entities based off of said location, the overall story plot, and background topic knowledge.</p>
<p>Once the knowledge graph and associated descriptions are generated for a particular story, they are then automatically turned into a fully playable text-game using the text game engine Evennia 2 . Evennia was chosen for its flexibility and customization, as well as a convenient web client for end user testing. The data structures were translated into builder commands within Evennia that constructed the various layouts, flavor text, and rules of the game world. Users were placed in one "room" out of the different world locations within the game they were playing, and asked to explore the game world that was available to them. Users achieved this by moving between rooms and investigating objects. Each time a new room was entered or object investigated, the player's total number of explored entities would be displayed as their score.</p>
<p>Each participant was was asked to play the neural game and then another one from one of the three additional models within a genre. The completion criteria for each game is collect half the total score possible in the game, i.e. explore half of all possible rooms and examine half of all possible entities. This provided the participant with multiple possible methods of finishing a particular game. On completion, the participant was asked to rank the two games according to overall perceived coherence, interestingness, and adherence to the genre. We additionally provided a required initial tutorial game which demonstrated all of these mechanics. The order in which participants played the games was also randomized as in the graph evaluation to remove potential correlations. We had 75 participants in total, 39 for mystery and 36 for fairy-tales. As each player played the neural model created game and one from each of the other approaches-this gave us 13 on average for the other approaches in the mystery genre and 12 for fairy-tales.</p>
<p>The summary of the results of the full game study is shown in  participants prefer the baseline game over the neural game. Once again, as this is highly interrelated ranked data, we perform the Mann-Whitney U test between each of the pairs to ensure that the rankings differed significantly. This is also indicated on the table.</p>
<p>In the mystery genre, the neural approach is generally preferred by a greater percentage of participants than the rules or random. The human-made game outperforms them all. A significant exception to is that participants thought that the rules-based game was more interesting than the neural game. The trends in the fairy-tale genre are in general similar with a few notable deviations. The first deviation is that the rulesbased and random approaches perform significantly worse than neural in this genre. We see also that the neural game is as coherent as the human-made game.</p>
<p>As in the previous study, we hypothesize that this is likely due to the rules-based approach being more suited to the mystery genre, which is often more mundane and contains less fantastical elements. By extension, we can say that thematic commonsense in fairy-tales has less overlap with everyday commonsense than for mundane mysteries. This has a few implications, one of which is that this theme specific information is unlikely to have been seen by OpenIE5 before. This is indicated in the relatively improved performance of the rules-based model in this genre across in terms of both interestingness and coherence.The genre difference can also be observed in terms of the performance of the random model. This model also lacking when compared to our neural model across all the questions asked especially in the fairy-tale setting. This appears to imply that filling in gaps in the knowledge graph using thematically relevant information such as with AskBERT results in more interesting and coherent descriptions and games especially in settings where the thematic commonsense diverges from everyday commonsense.</p>
<p>Conclusion</p>
<p>Procedural world generation systems are required to be semantically consistent, comply with thematic and everyday commonsense understanding, and maintain overall interestingness. We describe an approach that transform a linear reading experience in the form of a story plot into a interactive narrative experience. Our method, AskBERT, extracts and fills in a knowledge graph using thematic commonsense and then uses it as a skeleton to flesh out the rest of the world. A key insight from our human participant study reveals that the ability to construct a thematically consistent knowledge graph is critical to overall perceptions of coherence and interestingness particularly when the theme diverges from everyday commonsense understanding.</p>
<p>Figure 1 :
1Example player interaction in the deep neural generated mystery setting.</p>
<p>Figure 2 :Figure 3 :
23Example knowledge graph constructed by AskBERT. Overall AskBERT pipeline for graph construction.</p>
<p>Table 2 :
2Edge and degree statistics: Average edge count , average degree count, and degree standard deviation of the graphs per genre.</p>
<p>Table 3 :
3Results of the knowledge graph evaluation study.</p>
<p>Table 4 .
4As the comparisons made in this study are all made pairwise between our neural model and one of the baselines-they are presented in terms of what percentage of 2 http://www.evennia.com/Genre 
Questions 
Random 
Rules 
Human </p>
<p>Mystery </p>
<p>Interesting 
45 
72<em> 
69</em> 
Coherence 
36<em> 
45</em> 
69<em> 
Resembles Genre 
45 
38</em> 
75* </p>
<p>Fairy-tale </p>
<p>Interesting 
42 
37<em> 
64</em> 
Coherence 
25<em> 
25</em> 
45 
Resembles Genre 
25<em> 
37</em> 
69* </p>
<p>Table 4 :
4Results of the full game evaluation participant study. *Indicates statistical significance (p &lt; 0.05).</p>
<p>Ammanabrolu and Riedl, 2019a] Prithviraj Ammanabrolu and Mark Riedl. Transfer in deep reinforcement learning using knowledge graphs. Prithviraj Ammanabrolu, Matthew Hausknecht, International Conference on Learning Representations. Hong KongAssociation for Computational LinguisticsTextGraphs-13 at EMNLP-19[Ammanabrolu and Hausknecht, 2020] Prithviraj Am- manabrolu and Matthew Hausknecht. Graph constrained reinforcement learning for natural language action spaces. In International Conference on Learning Representations, 2020. [Ammanabrolu and Riedl, 2019a] Prithviraj Ammanabrolu and Mark Riedl. Transfer in deep reinforcement learning using knowledge graphs. In TextGraphs-13 at EMNLP-19, pages 1-10, Hong Kong, November 2019. Association for Computational Linguistics.</p>
<p>An analysis of open information extraction based on semantic role labeling. Riedl Ammanabrolu, Prithviraj Ammanabrolu, Mark O Riedl, Ammanabrolu, arXiv:1806.11532Proceedings of 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew HausknechtMahmoud AdadaarXiv preprintProceedings of the sixth international conference on Knowledge capture. et al. Textworld: A learning environment for text-based games[Ammanabrolu and Riedl, 2019b] Prithviraj Ammanabrolu and Mark O. Riedl. Playing text-adventure games with graph-based deep reinforcement learning. In Proceedings of 2019 Annual Conference of the North American Chap- ter of the Association for Computational Linguistics: Hu- man Language Technologies, NAACL-HLT 2019, 2019. [Ammanabrolu et al., 2019] Prithviraj Ammanabrolu, William Broniec, Alex Mueller, Jeremy Paul, and Mark O Riedl. Toward automated quest generation in text-adventure games. Proceedings of the 4th Work- shop on Computational Creativity in Natural Language Generation in INLG-19, 2019. [Christensen et al., 2011] Janara Christensen, Stephen Soderland, Oren Etzioni, and Mausam. An analysis of open information extraction based on semantic role label- ing. In Proceedings of the sixth international conference on Knowledge capture, pages 113-120. ACM, 2011. [Côté et al., 2018] Marc-Alexandre Côté,Ákos Kádár, Xingdi Yuan, Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mah- moud Adada, et al. Textworld: A learning environment for text-based games. arXiv preprint arXiv:1806.11532, 2018.</p>
<p>[ Fan, arXiv:1911.09194Generating interactive worlds with text. arXiv preprint[Fan et al., 2019] Angela Fan, Jack Urbanek, Pratik Ring- shia, Emily Dinan, Emma Qian, Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rocktaschel, Arthur Szlam, et al. Generating interactive worlds with text. arXiv preprint arXiv:1911.09194, 2019.</p>
<p>Learning How Not to Act in Text-Based Games. Workshop Track at. FDG[Guzdial et al., 2015] Matthew Guzdial, Brent Harrison, Boyang Li, and Mark Riedl. Crowdsourcing open inter- active narrative. In FDG, 2015. [Haroush et al., 2018] Matan Haroush, Tom Zahavy, Daniel J Mankowitz, and Shie Mannor. Learning How Not to Act in Text-Based Games. In Workshop Track at ICLR 2018, pages 1-4, 2018.</p>
<p>. [ Hausknecht, Interactive fiction games: A colossal adventure. CoRR, abs/1909.05398[Hausknecht et al., 2019a] Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Côté, and Xingdi Yuan. Interactive fiction games: A colossal adventure. CoRR, abs/1909.05398, 2019.</p>
<p>Nail: A general interactive fiction agent. [ Hausknecht, abs/1902.04259CoRR[Hausknecht et al., 2019b] Matthew Hausknecht, Ricky Loynd, Greg Yang, Adith Swaminathan, and Jason D. Williams. Nail: A general interactive fiction agent. CoRR, abs/1902.04259, 2019.</p>
<p>[ Lan, arXiv:1909.11942Piyush Sharma, and Radu Soricut. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. arXiv e-prints. [Lan et al., 2019] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Sori- cut. ALBERT: A Lite BERT for Self-supervised Learn- ing of Language Representations. arXiv e-prints, page arXiv:1909.11942, Sep 2019.</p>
<p>Karthik Narasimhan, Tejas Kulkarni, and Regina Barzilay. Language Understanding for Text-based Games Using Deep Reinforcement Learning. Conference on Empirical Methods in Natural Language Processing (EMNLP). 1Advances in Cognitive Systemset al., 2012] Boyang Li, Stephen Lee-Urban, Dar- ren Scott Appling, and Mark O. Riedl. Crowdsourcing Narrative Intelligence . In Advances in Cognitive Systems, volume 1, pages 1-18, 2012. [Narasimhan et al., 2015] Karthik Narasimhan, Tejas Kulka- rni, and Regina Barzilay. Language Understanding for Text-based Games Using Deep Reinforcement Learning. In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2015.</p>
<p>Are red roses red? evaluating consistency of question-answering models. ; Mausam, Radford, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsHarinder Pal and Mausam. Demonyms and compound relational nouns in nominal open ieand Mausam, 2016] Harinder Pal and Mausam. De- monyms and compound relational nouns in nominal open ie. In Proceedings of the 5th Workshop on Automated Knowledge Base Construction, pages 35-39, 2016. [Radford et al., 2019] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019. [Ribeiro et al., 2019] Marco Tulio Ribeiro, Carlos Guestrin, and Sameer Singh. Are red roses red? evaluating consis- tency of question-answering models. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6174-6184, 2019.</p>
<p>Learning to speak and act in a fantasy text adventure game. Mausam ; Swarnadeep Saha, Mausam ; Nitish Shirish Keskar, Bryan Mccann, Lav R Varshney, Caiming Xiong, Richard Socher, arXiv:1909.05858CTRL: A Conditional Transformer Language Model for Controllable Generation. arXiv e-prints. Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily Dinan, Tim Rocktäschel, Douwe Kiela, Arthur Szlam, and Jason WestonProceedings of EMNLP-IJCNLPand Mausam, 2018] Swarnadeep Saha and Mausam. Open information extraction from conjunctive sentences. In Proceedings of the 27th International Conference on Computational Linguistics, pages 2288-2299, 2018. [Shirish Keskar et al., 2019] Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. CTRL: A Conditional Transformer Language Model for Controllable Generation. arXiv e-prints, page arXiv:1909.05858, Sep 2019. [Urbanek et al., 2019] Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily Dinan, Tim Rocktäschel, Douwe Kiela, Arthur Szlam, and Jason Weston. Learning to speak and act in a fantasy text ad- venture game. In Proceedings of EMNLP-IJCNLP, pages 673-683, 2019.</p>
<p>Interactive narrative generation using location and genre specific context. Jon Womack, William Freeman, Interactive Storytelling. Chamand Freeman, 2019] Jon Womack and William Freeman. Interactive narrative generation using location and genre specific context. In Interactive Storytelling, pages 343-347, Cham, 2019.</p>
<p>Comprehensible context-driven text game playing. Xusen Yin, Jonathan May, abs/1905.02265CoRRand May, 2019] Xusen Yin and Jonathan May. Com- prehensible context-driven text game playing. CoRR, abs/1905.02265, 2019.</p>
<p>Interactive language learning by question answering. Conference on Empirical Methods in Natural Language Processing. et al., 2019] Xingdi Yuan, Marc-Alexandre Côté, Jie Fu, Zhouhan Lin, Christopher Pal, Yoshua Bengio, and Adam Trischler. Interactive language learning by ques- tion answering. In Conference on Empirical Methods in Natural Language Processing, 2019.</p>            </div>
        </div>

    </div>
</body>
</html>