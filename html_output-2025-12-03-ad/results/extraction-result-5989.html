<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5989 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5989</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5989</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-120.html">extraction-schema-120</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <p><strong>Paper ID:</strong> paper-259375597</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2307.03699v1.pdf" target="_blank">Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media</a></p>
                <p><strong>Paper Abstract:</strong> Social media platforms such as Instagram and Twitter have emerged as critical channels for drug marketing and illegal sale. Detecting and labeling online illicit drug trafficking activities becomes important in addressing this issue. However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on having access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection. To overcome this limitation, we conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media. We propose an analytical framework to compose \emph{knowledge-informed prompts}, which serve as the interface that humans can interact with and use LLMs to perform the detection task. Additionally, we design a Monte Carlo dropout based prompt optimization method to further to improve performance and interpretability. Our experimental findings demonstrate that the proposed framework outperforms other baseline language models in terms of drug trafficking detection accuracy, showing a remarkable improvement of nearly 12\%. By integrating prior knowledge and the proposed prompts, ChatGPT can effectively identify and label drug trafficking activities on social networks, even in the presence of deceptive language and euphemisms used by drug dealers to evade detection. The implications of our research extend to social networks, emphasizing the importance of incorporating prior knowledge and scenario-based prompts into analytical tools to improve online security and public safety.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5989.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5989.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge-prompted ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge-prompted ChatGPT framework for drug trafficking detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-centric framework that fuses prior domain knowledge and knowledge extracted from ChatGPT into a composite prompt [K,Q,x] and uses optimized prompts (via Monte Carlo dropout) to perform few-/zero-shot classification of Instagram posts as drug-trafficking related.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Knowledge-prompted ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that (1) extracts knowledge from ChatGPT with a few-shot set of labeled examples, (2) fuses that acquired knowledge with prior domain knowledge (hashtags, contact-info, special symbols), (3) composes knowledge-informed prompts [K,Q,x], and (4) optimizes prompts via a Monte Carlo dropout based procedure to improve ChatGPT (GPT-Turbo 3.5) classification of social-media posts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-Turbo 3.5 (via ChatGPT API)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Textual Instagram posts/comments drawn from the authors' IDDIG dataset (886 total samples after deduplication; 486 positive, 400 negative). In each prompt-design experiment a random set of 40 labeled samples was used for prompt construction; the remainder used as test data.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Not a literature-theory distillation system per se: uses prompt engineering as the mechanism to surface and fuse knowledge. Approach includes few-shot knowledge extraction from an LLM, fusion with curated domain knowledge, and prompt-optimization (word-masking Monte Carlo dropout) to elicit informative model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Binary classification label (y ∈ {0,1}) for each post, plus LLM-generated explanations/responses used to inform detection; internally it also outputs word importance scores and optimized prompt variants.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Standard classification metrics (accuracy, precision, recall, F1) measured on the held-out portion of the IDDIG dataset; ablation studies removing knowledge components; experiments varying number of shots; comparisons with multiple supervised baselines (BERT, XLNet, ALBERT, DistilBERT, RoBERTa).</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>The full system (40 shots + all domain knowledge + Monte Carlo dropout prompt optimization) achieved accuracy 94.58%, precision 96.60%, recall 93.42%, F1 94.98% on the IDDIG test set. Increasing shot count improved performance up to ~40 shots. Ablations showed domain-knowledge components and dropout-based optimization each contributed to gains.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>IDDIG (custom Instagram illicit-drug dataset assembled by the authors; final size 886 samples with 486 positives and 400 negatives).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Relies heavily on the quality and comprehensiveness of domain knowledge integrated into prompts; sensitivity to noisy inputs and special-symbol obfuscation; evaluated only on one dataset/task so generalizability is not established; interpretability could be improved (authors suggest attention mapping/explainable AI as future work).</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Direct comparison to supervised transformer baselines (BERT, XLNet, ALBERT, DistilBERT, RoBERTa) on the same dataset: the knowledge-prompted ChatGPT framework outperformed all listed baselines (reported ~12% accuracy improvement over baselines in aggregate statements). Ablation comparisons also showed advantages of fused knowledge prompts and Monte Carlo dropout optimization over no-prompt or partial-knowledge prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5989.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5989.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MC-dropout Prompt Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt Optimization with Monte Carlo Dropout (word-importance scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative prompt-optimization procedure introduced in this paper that masks words stochastically (Monte Carlo dropout over prompt tokens), measures changes in downstream F1, and accumulates word importance scores to refine prompts for improved LLM performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MC-dropout Prompt Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Algorithm that (a) splits a candidate prompt into words, (b) repeatedly masks random subsets of words according to a dropout probability, (c) queries the LLM with masked prompts and measures resulting performance metrics, and (d) aggregates per-word score changes to identify and refine influential words in prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-Turbo 3.5 (used in conjunction with the knowledge-prompted ChatGPT pipeline in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Designed prompt text and a few-shot labeled sample set (authors used up to 40-shot examples for design); evaluated on the IDDIG dataset (886 samples).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Perturbation-based importance estimation: masking tokens (Monte Carlo dropout) to estimate contribution of each token to task performance and then optimizing prompt text accordingly. This is a prompt-optimization/elicitation method, not document-to-theory distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Optimized prompt(s) and per-token importance scores used to modify prompts (remove negative words, emphasize positive words).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Comparison of downstream classification metrics (accuracy, precision, recall, F1) with and without MC-dropout optimization; ablation showing effect of dropout and number of shots.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>Without dropout and with 40 shots + AK: accuracy 91.87% and F1 92.04%; with dropout (40 shots + AK) the full system improved to accuracy 94.58% and F1 94.98%, demonstrating measurable gains from the optimization procedure.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td>IDDIG (authors' Instagram dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Masking-based importance can be sensitive to special characters and noisy inputs; optimization is tied to the evaluation metric used (F1) and the small in-domain sample used for prompt design; may not generalize across domains or different LLM versions without re-optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Compared internally against the same pipeline without dropout and against ablated prompt variants (no prompt, domain-only prompts, extracted-knowledge-only prompts). The Monte Carlo dropout optimization produced superior performance relative to those ablations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5989.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5989.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoPrompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoPrompt: Eliciting knowledge from language models with automatically generated prompts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited method that automatically generates prompts using a small set of labeled examples to elicit task-relevant knowledge from pretrained language models and improve performance on downstream tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autoprompt: Eliciting knowledge from language models with automatically generated prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoPrompt</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Automatic prompt generation technique that searches for token sequences (triggers) which, when appended to input, steer pretrained language models to produce desired outputs; leverages a small labeled set to optimize trigger tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Described as leveraging a small set of labeled examples to automatically generate prompts; exact sizes not specified in this paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Prompt-search / trigger-finding to elicit latent knowledge from LMs rather than training a new model; an elicitation/transfer technique rather than large-scale literature distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Automatically-generated prompts/triggers that improve LM task performance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Referenced claim in this paper: AutoPrompt achieved significant gains across various NLP benchmarks (no further experimental detail provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>Mentioned as having achieved significant performance gains across benchmarks in its original work; no new quantitative results provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper here notes AutoPrompt does not take advantage of domain knowledge integration (motivation for the authors' knowledge-fusion approach).</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Described in related work as an automated prompt-design baseline; paper argues existing prompt methods (including AutoPrompt) do not incorporate domain knowledge the way their proposed framework does.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5989.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5989.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting methodology that encourages language models to produce intermediate reasoning steps (a chain of thought), enabling improved performance on complex reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A prompting strategy that elicits step-by-step internal reasoning by asking models to produce intermediate steps, which improves reasoning capabilities emergently in larger LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Not specified in this paper beyond general statement that chain-of-thought prompts require sequences of intermediate steps; no dataset details provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Elicits internal multi-step reasoning from LLMs (used to solve complex tasks), not a document-level literature distillation technique.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Multi-step reasoning traces plus final answers (textual explanations).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not detailed in this paper (cited as prior work demonstrating improved reasoning), no quantitative details provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper mentions chain-of-thought as a methodological advance but does not discuss limitations in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Mentioned as shedding light on emergent reasoning abilities with model scale; not directly compared in experiments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5989.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5989.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based systems or methods for distilling theories or synthesizing knowledge from large numbers of scholarly papers, including details about the LLMs used, the distillation approach, input and output types, evaluation methods, results, datasets, challenges, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PromptChainer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PromptChainer: Chaining large language model prompts through visual programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited interactive system that enables users (including non-experts) to prototype AI applications by visually chaining LLM prompts into pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Promptchainer: Chaining large language model prompts through visual programming.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PromptChainer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A visual programming tool for composing chains of LLM prompts to build more complex LLM-driven applications; emphasizes usability for non-experts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_type_and_size</strong></td>
                            <td>Not specified in this paper; described as a visual programming interface to chain prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_approach</strong></td>
                            <td>Chaining/compose prompts to implement multi-step LLM workflows; not a literature distillation system.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Chained prompt workflows and their textual outputs; application prototypes built from LLM chains.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not described in this paper; cited as a usability/engineering tool.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_or_benchmarks</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Mentioned as enabling prototyping but not taking advantage of domain-knowledge fusion specific to the detection task studied here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons_to_other_methods</strong></td>
                            <td>Presented in related work as a tool for composing LLM prompts, not empirically compared within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Autoprompt: Eliciting knowledge from language models with automatically generated prompts. <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models. <em>(Rating: 2)</em></li>
                <li>Promptchainer: Chaining large language model prompts through visual programming. <em>(Rating: 2)</em></li>
                <li>Language models are few-shot learners. <em>(Rating: 2)</em></li>
                <li>Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. <em>(Rating: 2)</em></li>
                <li>A survey of large language models. <em>(Rating: 1)</em></li>
                <li>Llama: Open and efficient foundation language models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5989",
    "paper_id": "paper-259375597",
    "extraction_schema_id": "extraction-schema-120",
    "extracted_data": [
        {
            "name_short": "Knowledge-prompted ChatGPT",
            "name_full": "Knowledge-prompted ChatGPT framework for drug trafficking detection",
            "brief_description": "A prompt-centric framework that fuses prior domain knowledge and knowledge extracted from ChatGPT into a composite prompt [K,Q,x] and uses optimized prompts (via Monte Carlo dropout) to perform few-/zero-shot classification of Instagram posts as drug-trafficking related.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Knowledge-prompted ChatGPT",
            "system_description": "A system that (1) extracts knowledge from ChatGPT with a few-shot set of labeled examples, (2) fuses that acquired knowledge with prior domain knowledge (hashtags, contact-info, special symbols), (3) composes knowledge-informed prompts [K,Q,x], and (4) optimizes prompts via a Monte Carlo dropout based procedure to improve ChatGPT (GPT-Turbo 3.5) classification of social-media posts.",
            "llm_model_used": "GPT-Turbo 3.5 (via ChatGPT API)",
            "input_type_and_size": "Textual Instagram posts/comments drawn from the authors' IDDIG dataset (886 total samples after deduplication; 486 positive, 400 negative). In each prompt-design experiment a random set of 40 labeled samples was used for prompt construction; the remainder used as test data.",
            "distillation_approach": "Not a literature-theory distillation system per se: uses prompt engineering as the mechanism to surface and fuse knowledge. Approach includes few-shot knowledge extraction from an LLM, fusion with curated domain knowledge, and prompt-optimization (word-masking Monte Carlo dropout) to elicit informative model behavior.",
            "output_type": "Binary classification label (y ∈ {0,1}) for each post, plus LLM-generated explanations/responses used to inform detection; internally it also outputs word importance scores and optimized prompt variants.",
            "evaluation_methods": "Standard classification metrics (accuracy, precision, recall, F1) measured on the held-out portion of the IDDIG dataset; ablation studies removing knowledge components; experiments varying number of shots; comparisons with multiple supervised baselines (BERT, XLNet, ALBERT, DistilBERT, RoBERTa).",
            "results": "The full system (40 shots + all domain knowledge + Monte Carlo dropout prompt optimization) achieved accuracy 94.58%, precision 96.60%, recall 93.42%, F1 94.98% on the IDDIG test set. Increasing shot count improved performance up to ~40 shots. Ablations showed domain-knowledge components and dropout-based optimization each contributed to gains.",
            "datasets_or_benchmarks": "IDDIG (custom Instagram illicit-drug dataset assembled by the authors; final size 886 samples with 486 positives and 400 negatives).",
            "challenges_or_limitations": "Relies heavily on the quality and comprehensiveness of domain knowledge integrated into prompts; sensitivity to noisy inputs and special-symbol obfuscation; evaluated only on one dataset/task so generalizability is not established; interpretability could be improved (authors suggest attention mapping/explainable AI as future work).",
            "comparisons_to_other_methods": "Direct comparison to supervised transformer baselines (BERT, XLNet, ALBERT, DistilBERT, RoBERTa) on the same dataset: the knowledge-prompted ChatGPT framework outperformed all listed baselines (reported ~12% accuracy improvement over baselines in aggregate statements). Ablation comparisons also showed advantages of fused knowledge prompts and Monte Carlo dropout optimization over no-prompt or partial-knowledge prompts.",
            "uuid": "e5989.0",
            "source_info": {
                "paper_title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "MC-dropout Prompt Optimization",
            "name_full": "Prompt Optimization with Monte Carlo Dropout (word-importance scoring)",
            "brief_description": "An iterative prompt-optimization procedure introduced in this paper that masks words stochastically (Monte Carlo dropout over prompt tokens), measures changes in downstream F1, and accumulates word importance scores to refine prompts for improved LLM performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "MC-dropout Prompt Optimization",
            "system_description": "Algorithm that (a) splits a candidate prompt into words, (b) repeatedly masks random subsets of words according to a dropout probability, (c) queries the LLM with masked prompts and measures resulting performance metrics, and (d) aggregates per-word score changes to identify and refine influential words in prompts.",
            "llm_model_used": "GPT-Turbo 3.5 (used in conjunction with the knowledge-prompted ChatGPT pipeline in experiments)",
            "input_type_and_size": "Designed prompt text and a few-shot labeled sample set (authors used up to 40-shot examples for design); evaluated on the IDDIG dataset (886 samples).",
            "distillation_approach": "Perturbation-based importance estimation: masking tokens (Monte Carlo dropout) to estimate contribution of each token to task performance and then optimizing prompt text accordingly. This is a prompt-optimization/elicitation method, not document-to-theory distillation.",
            "output_type": "Optimized prompt(s) and per-token importance scores used to modify prompts (remove negative words, emphasize positive words).",
            "evaluation_methods": "Comparison of downstream classification metrics (accuracy, precision, recall, F1) with and without MC-dropout optimization; ablation showing effect of dropout and number of shots.",
            "results": "Without dropout and with 40 shots + AK: accuracy 91.87% and F1 92.04%; with dropout (40 shots + AK) the full system improved to accuracy 94.58% and F1 94.98%, demonstrating measurable gains from the optimization procedure.",
            "datasets_or_benchmarks": "IDDIG (authors' Instagram dataset).",
            "challenges_or_limitations": "Masking-based importance can be sensitive to special characters and noisy inputs; optimization is tied to the evaluation metric used (F1) and the small in-domain sample used for prompt design; may not generalize across domains or different LLM versions without re-optimization.",
            "comparisons_to_other_methods": "Compared internally against the same pipeline without dropout and against ablated prompt variants (no prompt, domain-only prompts, extracted-knowledge-only prompts). The Monte Carlo dropout optimization produced superior performance relative to those ablations.",
            "uuid": "e5989.1",
            "source_info": {
                "paper_title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "AutoPrompt",
            "name_full": "AutoPrompt: Eliciting knowledge from language models with automatically generated prompts",
            "brief_description": "A cited method that automatically generates prompts using a small set of labeled examples to elicit task-relevant knowledge from pretrained language models and improve performance on downstream tasks.",
            "citation_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts.",
            "mention_or_use": "mention",
            "system_name": "AutoPrompt",
            "system_description": "Automatic prompt generation technique that searches for token sequences (triggers) which, when appended to input, steer pretrained language models to produce desired outputs; leverages a small labeled set to optimize trigger tokens.",
            "llm_model_used": null,
            "input_type_and_size": "Described as leveraging a small set of labeled examples to automatically generate prompts; exact sizes not specified in this paper's discussion.",
            "distillation_approach": "Prompt-search / trigger-finding to elicit latent knowledge from LMs rather than training a new model; an elicitation/transfer technique rather than large-scale literature distillation.",
            "output_type": "Automatically-generated prompts/triggers that improve LM task performance.",
            "evaluation_methods": "Referenced claim in this paper: AutoPrompt achieved significant gains across various NLP benchmarks (no further experimental detail provided here).",
            "results": "Mentioned as having achieved significant performance gains across benchmarks in its original work; no new quantitative results provided in this paper.",
            "datasets_or_benchmarks": null,
            "challenges_or_limitations": "Paper here notes AutoPrompt does not take advantage of domain knowledge integration (motivation for the authors' knowledge-fusion approach).",
            "comparisons_to_other_methods": "Described in related work as an automated prompt-design baseline; paper argues existing prompt methods (including AutoPrompt) do not incorporate domain knowledge the way their proposed framework does.",
            "uuid": "e5989.2",
            "source_info": {
                "paper_title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Chain-of-Thought",
            "name_full": "Chain-of-thought prompting",
            "brief_description": "A prompting methodology that encourages language models to produce intermediate reasoning steps (a chain of thought), enabling improved performance on complex reasoning tasks.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models.",
            "mention_or_use": "mention",
            "system_name": "Chain-of-Thought prompting",
            "system_description": "A prompting strategy that elicits step-by-step internal reasoning by asking models to produce intermediate steps, which improves reasoning capabilities emergently in larger LLMs.",
            "llm_model_used": null,
            "input_type_and_size": "Not specified in this paper beyond general statement that chain-of-thought prompts require sequences of intermediate steps; no dataset details provided here.",
            "distillation_approach": "Elicits internal multi-step reasoning from LLMs (used to solve complex tasks), not a document-level literature distillation technique.",
            "output_type": "Multi-step reasoning traces plus final answers (textual explanations).",
            "evaluation_methods": "Not detailed in this paper (cited as prior work demonstrating improved reasoning), no quantitative details provided here.",
            "results": null,
            "datasets_or_benchmarks": null,
            "challenges_or_limitations": "Paper mentions chain-of-thought as a methodological advance but does not discuss limitations in this context.",
            "comparisons_to_other_methods": "Mentioned as shedding light on emergent reasoning abilities with model scale; not directly compared in experiments in this paper.",
            "uuid": "e5989.3",
            "source_info": {
                "paper_title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "PromptChainer",
            "name_full": "PromptChainer: Chaining large language model prompts through visual programming",
            "brief_description": "A cited interactive system that enables users (including non-experts) to prototype AI applications by visually chaining LLM prompts into pipelines.",
            "citation_title": "Promptchainer: Chaining large language model prompts through visual programming.",
            "mention_or_use": "mention",
            "system_name": "PromptChainer",
            "system_description": "A visual programming tool for composing chains of LLM prompts to build more complex LLM-driven applications; emphasizes usability for non-experts.",
            "llm_model_used": null,
            "input_type_and_size": "Not specified in this paper; described as a visual programming interface to chain prompts.",
            "distillation_approach": "Chaining/compose prompts to implement multi-step LLM workflows; not a literature distillation system.",
            "output_type": "Chained prompt workflows and their textual outputs; application prototypes built from LLM chains.",
            "evaluation_methods": "Not described in this paper; cited as a usability/engineering tool.",
            "results": null,
            "datasets_or_benchmarks": null,
            "challenges_or_limitations": "Mentioned as enabling prototyping but not taking advantage of domain-knowledge fusion specific to the detection task studied here.",
            "comparisons_to_other_methods": "Presented in related work as a tool for composing LLM prompts, not empirically compared within this paper.",
            "uuid": "e5989.4",
            "source_info": {
                "paper_title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts.",
            "rating": 2,
            "sanitized_title": "autoprompt_eliciting_knowledge_from_language_models_with_automatically_generated_prompts"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models.",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Promptchainer: Chaining large language model prompts through visual programming.",
            "rating": 2,
            "sanitized_title": "promptchainer_chaining_large_language_model_prompts_through_visual_programming"
        },
        {
            "paper_title": "Language models are few-shot learners.",
            "rating": 2,
            "sanitized_title": "language_models_are_fewshot_learners"
        },
        {
            "paper_title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.",
            "rating": 2,
            "sanitized_title": "pretrain_prompt_and_predict_a_systematic_survey_of_prompting_methods_in_natural_language_processing"
        },
        {
            "paper_title": "A survey of large language models.",
            "rating": 1,
            "sanitized_title": "a_survey_of_large_language_models"
        },
        {
            "paper_title": "Llama: Open and efficient foundation language models.",
            "rating": 1,
            "sanitized_title": "llama_open_and_efficient_foundation_language_models"
        }
    ],
    "cost": 0.013620499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media
7 Jul 2023</p>
<p>Chuanbo Hu 
Lane Department of Computer Science and Electrical Engineering
West Virginia University
395 Evansdale Dr26505MorgantownWest VirginiaUnited States</p>
<p>Bin Liu 
Department of Management Information Systems
West Virginia University
83 Beechurst Avenue26505MorgantownWest VirginiaUnited States</p>
<p>Xin Li 
Lane Department of Computer Science and Electrical Engineering
West Virginia University
395 Evansdale Dr26505MorgantownWest VirginiaUnited States</p>
<p>Yanfang Ye 
Department of Computer Science and Engineering
University of Notre Dame
257 Fitzpatrick Hall of Engineering</p>
<p>Notre Dame
46556INUnited States</p>
<p>Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media
7 Jul 2023EAA4C96E06EC61AFABDC077981B32EFCarXiv:2307.03699v1[cs.CL]Large language modelsChatGPTPrompt engineeringDrug traffickingSocial media
We conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media.• We propose an analytical framework to compose knowledge-informed prompts, which serve as the interface that humans can interact with and use LLMs for the detection of drug trafficking activities.• We design a prompt optimization method to further enhance the effectiveness of the prompts.• We demonstrate the effectiveness of the proposed framework through extensive experiments on an illicit drug trafficking dateset we collected from Instagram.</p>
<p>Introduction</p>
<p>Drug trafficking, the illegal sale or transport of prohibited drugs, is a global issue that has far-reaching impacts on communities, families, and individuals.</p>
<p>Illegal drug trade and usage lead to addiction and health problems and have broader social impacts.Drug trafficking organizations are often associated with violence, corruption, and other forms of criminal activity [1,2,3].Social media has provided drug dealers with a convenient platform to market and sell their illicit products [4,5].Social media platforms offer a broad audience reach and provide drug dealers with a level of anonymity that was previously unattainable.</p>
<p>These platforms also facilitate communication between dealers and customers, enabling them to coordinate transactions [6].Detection of drug trafficking on social networks has become critical in tackling drug trafficking.However, detecting drug trafficking activities on social media poses difficulties due to the use of disguised language and euphemisms by drug dealers [7].Drug dealers employ code words, acronyms, and other disguised language to avoid detection by law enforcement agencies and social media platforms.Consequently, although social media platforms have implemented some mechanisms to combat drug trafficking, they are ineffective due to the aforementioned challenges.</p>
<p>Several research studies are building task-specific machine learning models to detect drug trafficking activities on social media, including detection of drug deal-ers [8,9], drug trafficking events [10,7,11], and drug-related hashtags [12].The problem of detection of illicit drug trafficking can be formulated as a supervised machine learning problem, where the input is typically the text or/and images on social media, and the output is drug trafficking activities to be detected.As such, different machine learning approaches, such as Convolutional Neural Networks (CNN) [7,8,11], long short-term memory networks (LSTM) [9], and Transformer networks [7], can be applied to process the social media data.However, such taskspecific models have several limits.First, task-specific models apply supervised learning to train the models, requiring high-quality labeled data to achieve good performance.Unfortunately, annotating a large dataset on social media can be challenging and time-consuming.Second, as platforms improve their detection capabilities, drug dealers constantly adapt their text-based trafficking techniques to avoid detection.This poses a substantial challenge for supervised learning models, as they may struggle to decipher disguised language and euphemisms, potentially resulting in the oversight of crucial information related to drug trafficking activities.</p>
<p>Meanwhile, recent years have observed the emergence of powerful large language models (LLMs) such as GPT [13] and LLaMA [14].These models, trained on huge datasets, have demonstrated surprising capabilities in various natural language processing (NLP) tasks, such as natural language understanding, generating coherent and contextually relevant responses, and solving complex tasks through text generation.LLMs have shown promise in helping with various realworld tasks, including complex math problems [15], clinical decision support [16], public health [17], open education [18], and global warming [19].Unlike the supervised learning paradigm, which requires large labeled data to train a task-specific model, LLMs can perform NLP tasks with just a few or no examples, achieving results similar to those of state-of-the-art supervised models [20].</p>
<p>Therefore, LLMs provide an alternative solution to detect illicit drug trafficking on social media.</p>
<p>Inspired by the advance in large language models (LLMs), in this paper, we propose to apply LLMs to detect illicit drug trafficking activities from text data on social media (e.g., textual information of posts on Instagram).Although images often go with text data on social media, previous studies [7,8] show that text data dominate the detection of illicit drug trafficking activities.Unlike supervised learning that trains a model with input-label pairs, the LLM-based approach performs a downstream task by reformulating the task with an appropriate textual prompt, which bridges the task and the LLMs to enable in-context learning in an autoregressive manner [13].To apply LLMs for prediction tasks, we must modify the original text into a textual prompt [21].Consequently, the problem of LLMbased drug trafficking detection boils down to the design of appropriate prompts.</p>
<p>To this end, we propose an analytical framework to compose knowledge-informed prompts, which serve as the interface that humans can interact with and use LLMs for the detection of drug trafficking activities.The prompt is the combination of knowledge, question, and original text to detect.To construct meaningful prompt knowledge, our proposed framework integrates prior domain knowledge regarding drug trafficking behaviors, terminologies, and strategies used by drug dealers, and acquired knowledge extracted from an LLM, ChatGPT in particular, with a few examples.We further design an optimization method to optimize the prompts.</p>
<p>The prompt optimization use an iterative strategy [22] to elicit more accurate factual knowledge about drug trafficking than manually created prompts on the benchmark.Meanwhile, Monte Carlo dropout [23] is applied to effectively incorporate prior knowledge specific to drug trafficking behaviors than supervised relation extraction models.</p>
<p>Finally, we assess our proposed framework through extensive experiments on an illicit drug trafficking dateset we collected from Instagram.Our framework demonstrates superior performance compared to baseline models.Furthermore, through conducting thorough evaluations, including ablation experiments and assessments with varying input shots, we demonstrate the importance of prompt design, the value of domain knowledge integration, and the optimal threshold of input shots to maximize performance.In summary, our research makes the following contributions:</p>
<p>• We conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media.</p>
<p>• We propose an analytical framework to compose knowledge-informed prompts, which serve as the interface that humans can interact with and use LLMs for the detection of drug trafficking activities.</p>
<p>• We design a prompt optimization method to further enhance the effectiveness of the prompts.</p>
<p>• We demonstrate the effectiveness of the proposed framework through extensive experiments on an illicit drug trafficking dateset we collected from Instagram.</p>
<p>Our research contributes to the broader objective of improving online security and public safety.Through the integrated prompts of prior knowledge and Chat-GPT knowledge, our approach provides an effective tool to detect drug trafficking activity on social media.Our research offers a practical and applicable tool for law enforcement agencies, social media managers, and other stakeholders concerned with online security and public safety.</p>
<p>The remainder of this paper is organized as follows: Section 2 provides an overview of related work in drug trafficking detection and large language models, Section 3 describes the proposed method in detail, Section 4 presents experimental results and analysis, and Section 5 concludes the article while outlining potential future avenues of research.</p>
<p>Related Work</p>
<p>Drug trafficking detection on social media</p>
<p>As social media platforms have emerged critical channels for drug marketing and illegal sale, how to effectively and efficiently detect illicit drug trafficking activities becomes important in addressing this issue.There are a few studies that build task-specific machine learning models to detect drug trafficking activities on social media, including detection of drug dealers [8,9], drug trafficking events [10,7,11], and drug-related hashtags [12].For example, Li et al. [9] applied long short-term memory networks (LSTM) to process textual data of Instagram posts to detect and characterize illicit drug dealers on Instagram.Similarly, Zhao et al. [11] combined both SVM and TextCNN to detect illicit drug ads.Since social media posts contain both textual and image data, there are some research on apply multimodal approach to drug trafficking detection [8,7,10].Qian et al. [24] employed heterogeneous graph to capture multi-modal content and relational structured information from social media to detect illicit drug traffickers.</p>
<p>More recently, Hu et al. [12] proposed a framework that combined Bidirectional Encoder Representations from Transformers (BERT) with Graph Convolutional Network (GCN) to classify drug-related hashtags on Instagram.</p>
<p>Existing studies that built task-specific models for drug trafficking detection have several limits.First, they need large amount of high-quality labeled data to train the models, however, data annotation is time-consuming and resourceintensive.Second, as drug dealers constantly update their deceptive language and euphemisms to avoid detection, a well-trained model might fail to perform the detection task.As large language models advance, the challenges associated with drug trafficking detection in social media are expected to be effectively addressed.</p>
<p>Large language models</p>
<p>Large language model (LLMs) are sophisticated artificial intelligence models trained on vast amounts of text data and demonstrate advanced language pro-cessing capabilities [25].Several notable large language models have been developed, including OpenAI's GPT (Generative Pre-trained Transformer) series and Google's BERT (Bidirectional Encoder Representations from Transformers).These large language models are typically pre-trained on massive datasets, often comprising billions of sentences from various sources such as books, websites, and articles.During pre-training, the models learn to predict missing words in sentences, thereby gaining a deep understanding of grammar, context, and semantic relationships.One prominent example of a large language model is ChatGPT [13] developed by OpenAI.</p>
<p>Once pre-training is completed, LLMs can can perform various natural language processing (NLP) tasks with just a few or no examples, achieving results similar to those of state-of-the-art supervised models [20].LLMs also have shown promise in helping with various real-world tasks, including complex math problems [15], clinical decision support [16], public health [17].</p>
<p>Prompt engineering based on language models</p>
<p>Prompts are the interface for humans to interact with and use LLMs.LLMbased approach performs a downstream task by reformulating the task with an appropriate textual prompt, which bridges the task and the LLMs to enable incontext learning in an autoregressive manner [13].Prompt engineering [21] has received increasing attention in recent years.Researchers have explored different methods to design prompts that can improve the performance of language models on specific tasks.For example, Shin et al. [22] proposed a method for designing prompts to improve the performance of language models on various natural language processing tasks.Their approach, AutoPrompt, leverages a small set of labeled examples to automatically generate prompts that guide the language model toward the desired task.They achieved significant performance gains across various benchmarks by fine-tuning the model with task-specific prompts.A proposed method facilitates a chain-of-thought prompting approach, enabling expansive language models to tackle intricate reasoning tasks by generating a sequence of intermediate steps [26].This methodology sheds light on the emergent property of model scale while expanding the repertoire of reasoning tasks language models can proficiently undertake.An interactive system called PromptChainer has been developed to facilitate the visual programming of LLM chains, empowering individuals without AI expertise to prototype AI-infused applications [27].However, these methods fail to take advantage of domain knowledge to enhance the performance of the large-language model.</p>
<p>Methodology</p>
<p>In this section, we first formulate the problem of drug trafficking detection on social media, and then introduce the knowledge-prompted large-language model approach to the problem.</p>
<p>Problem Formulation</p>
<p>Our goal is to design an effective system to detect drug trafficking activities on social media platforms accurately.Specifically, our objective is to classify whether a social media post (e.g., a post on Instagram or a tweet on Twitter) contains information related to the marketing and sales of illicit drugs so that the classification can be applied to monitor drug trafficking activities on social media platforms.</p>
<p>In this paper, we use only the textual data from the posts.However, images often go with text on social media, but textual data have a dominating role in detecting illicit drug trafficking activities [7,8].Let x denote the textual data in a post, our goal is to build a predictive model that takes x as input and predicts a drug trafficking label y ∈ {0, 1}, where y = 1 denotes the post is related to drug trafficking activities and y = 0 otherwise.The block highlighted in green in Figure 1 shows an example of the textual data of an Instagram post annotated as a drug trafficking post.In particular, we propose to leverage large language models (LLMs), such as ChatGPT, so that we can (1) To leverage the rich knowledge of LLMs acquired through training with large datasets, and (2) To enable the detection with a few (i.e., few-shot learning where the LLM model is given a few demonstrations of the task) or even no (i.e., zero-shot learning) examples.</p>
<p>Different supervised learning, which trains a model with large size of inputlabel pairs {(x i , y i )} i∈[N ] , we need to modify the original text x into a textual prompt x to perform the drug trafficking task.However, how to design appropriate prompts is not a nontrivial task, as the prompts have an important impact on the effectiveness of LLMs.As a result, the problem of LLM-based drug trafficking detection boils down to the design of appropriate prompts, which is the focus of this paper.</p>
<p>Overview of Proposed Framework</p>
<p>As shown in Figure 1, our proposed knowledge-informed prompt x : [K, Q, x] is composed of knowledge K, question Q, and original text x.Then the knowledge-</p>
<p>Notation Meaning Req k</p>
<p>Request knowledge discovery based on a few-shot Instagram comments.</p>
<p>Res k</p>
<p>Response extracted knowledge from a few-shot Instagram comments.</p>
<p>Req s</p>
<p>Request the combination and summarization of the extracted knowledge.</p>
<p>Res s</p>
<p>Response that combines and summarizes the extracted knowledge.</p>
<p>Req f u</p>
<p>Request the fusion of extracted knowledge and domain knowledge.</p>
<p>Res f u</p>
<p>Response the fusion of extracted knowledge and domain knowledge.</p>
<p>Req di</p>
<p>Request the detection of Instagram comments using the prompt after randomly dropping out the ith iteration.</p>
<p>Res di</p>
<p>Response for the prediction of each input Instagram comment data.</p>
<p>informed prompt x is the interface that humans can interact with and use Chat-GPT for the detection of drug trafficking.ChatGPT utilizes this prompt to generate responses that help detect drug trafficking activities.The response component represents the system output, providing valuable insights and detection results.To design effective knowledge-informed prompts so as to leverage the capabilities of large language models (LLMs) for the detection of drug trafficking activities on social media, we propose an advanced analytical framework that integrates prior domain knowledge and acquired knowledge extracted from an LLM, ChatGPT in particular.As shown in Figure 2, the framework builds upon ChatGPT as its core, combining the power of the large language model with prior knowledge and acquired knowledge extracted from ChatGPT.Different notations in the framework, as shown in Table 1, represent distinct meanings and functions in terms of knowledge request and response.This framework encompasses a series of steps to design effective prompts to improve the model's effectiveness in detecting drug trafficking activities.</p>
<ol>
<li>Knowledge extraction from ChatGPT.In this step, we leverage the capabilities of ChatGPT to extract knowledge with a few shots of labeled data
{(x i , y i )} i∈[N ] ,
where N is a small number.We input relevant text passages or queries into ChatGPT and utilize its language comprehension and generation capabilities to extract key facts, insights, and relationships related to drug trafficking activities.Various sources such as news articles, online forums, and social networks are used to extract valuable information.We elaborate the details for each part in subsequent sections.Incorporating domain-specific knowledge related to hashtags, contact information, and special symbols provides valuable contextual insights that help uncover drug-trafficking discussions and improve the precision and recall of the detection system.This domain knowledge will be fused with acquired knowledge extracted from ChatGPT to design prompts.</li>
</ol>
<p>Incorporating Prior Domain Knowledge</p>
<p>Knowledge Fusion and Prompt Engineering</p>
<p>Note that given a text data x, our proposed knowledge-informed prompt x :
[K, Q, x]</p>
<p>Prompt -Knowledge</p>
<p>In particular, we compose the knowledge part K with prior domain knowledge and acquired knowledge extracted from ChatGPT with a few shots of labeled data.</p>
<p>Knowledge</p>
<p>Prompt -Question</p>
<p>To further enhance the design of knowledge prompts, we identify specific types of questions that generate informative responses related to the detection of drug trafficking.These questions are designed to target key aspects of drug trafficking activities, methods, or indicators.For instance, questions like "What are the signs of drug trafficking in online communications?" or "How can drug smuggling be detected at border checkpoints?"guide the model to provide relevant information in its responses.By incorporating carefully crafted questions into the prompts, we guide the ChatGPT model to generate more focused and informative outputs for drug trafficking detection tasks.</p>
<p>Prompt Optimization with Monte Carlo Dropout</p>
<p>In this section, we present the methodology for prompt optimization, leveraging the Monte Carlo dropout technique to enhance the performance of the knowledge-prompt design framework for drug trafficking detection.</p>
<p>The prompt optimization process aims to fine-tune the designed prompts to maximize the performance of the ChatGPT model on drug trafficking detection tasks.We can identify keywords that significantly influence the model's decisions by systematically analyzing the impact of individual words in the prompt.The prompt optimization is shown in Algorithm 1.</p>
<p>The algorithm, "Prompt Optimization with Monte Carlo Dropout," takes the designed prompt, the number of Monte Carlo dropout iterations, and the dropout probability as input.The algorithm iteratively performs the following steps:</p>
<p>• Create a copy of the designed prompt, optimized_prompt, to preserve the original prompt (Step 1).</p>
<p>• Split optimized_prompt into a list of words.</p>
<p>• For each word in the prompt, perform the Monte Carlo dropout by replacing the word with a "MASK" token (Steps 4-6).</p>
<p>• Perform Monte Carlo simulation on the modified prompt to obtain performance metrics.</p>
<p>• Calculate the change in F1 score, score_change, based on the original and simulated F1 scores.</p>
<p>Algorithm 1 Word Importance Score Calculation with Monte Carlo Dropout for Prompt Optimization.Initialize an empty dictionary word_scores 3:</p>
<p>Split the paragraph into a list of words 4:</p>
<p>for iter in 1 to num_iterations do 5:</p>
<p>Create a copy of the list of words called masked_words 6:</p>
<p>Initialize an empty list called dropout_list 7:</p>
<p>for word_index in 0 to length(masked_words) − 1 do 8:</p>
<p>if random.random()&lt; dropout_prob then 9:</p>
<p>Append word_index to dropout_list 10:</p>
<p>Set masked_words[word_index] as "MASK" return sorted_scores 25: end procedure</p>
<p>• Update the importance score of each word in the prompt by incrementing it with score_change.</p>
<p>• Repeat Steps 2-6 for the desired number of iterations.</p>
<p>By optimizing the prompt using Monte Carlo dropout, we can identify and refine the words that significantly impact the model's performance in drug trafficking detection tasks.</p>
<p>The resulting optimized prompt provides valuable insight into the specific words and their contributions to the model's decision-making process.This en-hanced understanding enables us to fine-tune the prompt and align the model's behavior more closely with the desired drug trafficking detection outcomes.</p>
<p>Experiments</p>
<p>Experimental Settings</p>
<p>In this subsection, we describe the experimental setup used to evaluate the performance of the knowledge-prompted ChatGPT framework for drug trafficking detection.The experimental setup encompasses the dataset, model configuration, evaluation metrics, and baselines.</p>
<p>• Dataset.To evaluate the framework's effectiveness, we carefully selected a comprehensive dataset called IDDIG that contains text samples related to drug trafficking on Instagram.Similar samples were removed from the IDDIG data, resulting in a final set of 886 samples for the evaluation experiments.There are 486 positive samples (i.e., drug trafficking) and 400 negative samples (i.e., non-drug trafficking).We propose a framework for identifying positive samples.The dataset consists of labeled data for validation and testing, facilitating the computation of performance metrics.It is thoughtfully curated to encompass various drug trafficking scenarios, regions, and languages, ensuring the framework's generalizability.Specifically, a random set of 40 samples was selected as input for the design of knowledge prompts in each experiment.In contrast, the remaining samples were set aside as a test set to assess the performance of the proposed method.</p>
<p>• Model Configuration.Our framework is based on the ChatGPT API, specifically using the GPT Turbo 3.5 model.This model undergoes pre-training on a significant corpus of text data to establish a robust language understanding.To accurately detect drug trafficking, we optimize the ChatGPT request prompt by incorporating the knowledge prompt design and optimization techniques mentioned earlier.The model configuration involves</p>
<p>Model</p>
<p>Accuracy Precision Recall F1 Score BERT [28] 76.23% 75.39% 85.91% 79.78% XLNet [29] 76.13% 75.44% 86.76% 79.92% ALBERT [30] 77.62% 78.06% 83.14% 80.13% DistilBERT [31]  • Baselines.To compare the performance of the knowledge-prompted Chat-GPT framework, it is important to establish appropriate baselines.Baselines include BERT [28], XLNet [29], ALBERT [30], DistilBERT [31], and RoBERTa [32] for the detection of drug trafficking.These baselines provide reference points to evaluate the effectiveness and superiority of the proposed framework.Baseline models are trained and evaluated on the same dataset as the knowledge-prompted ChatGPT framework, using the same evaluation metrics to ensure a fair comparison.</p>
<p>Evaluation of knowledge-prompted ChatGPT for drug trafficking detection</p>
<p>This section presents the evaluation results of our knowledge-prompted Chat-GPT framework for drug trafficking detection.We compare the performance of our framework with several baseline models, including BERT, XLNet, ALBERT, DistilBERT, and RoBERTa.The evaluation metrics include accuracy, precision, recall, and F1 score (See Table 3).</p>
<p>We noted a significant enhancement across all evaluation metrics after comparing the outcomes with the baseline models.Our framework demonstrated superior performance in drug trafficking detection tasks by achieving higher accuracy, precision, recall, and F1 scores than all other models.Notably, the proposed framework exhibited exceptional improvements, with nearly a 12% increase in drug trafficking detection accuracy and an approximately 10% improvement in F1 score, surpassing other baseline language models.</p>
<p>The significant performance gains can be attributed to incorporating domainspecific knowledge, effective prompt design, and knowledge optimization techniques employed in our framework.The integration of relevant knowledge and the guidance provided through carefully designed prompts contribute to the framework's ability to detect drug trafficking activities accurately.</p>
<p>Assessing the performance of knowledge prompt ChatGPT with varying input shots</p>
<p>To evaluate the impact of varying input shots on the performance of the knowledgedriven ChatGPT framework for drug trafficking detection, we conducted experiments using different numbers of input shots.The evaluation metrics include accuracy, precision, recall, and F1 score.</p>
<p>The framework's performance consistently improved with an increasing number of input shots.Using 40 shots yielded the best results, achieving an accuracy of 89.84% and an F1 score of 90.24%, while using five shots resulted in an accuracy of 86.23% and an F1 score of 86.94%.These results indicate that the knowledge-driven ChatGPT framework benefits from increasing input shots up  to a certain point, leading to improved performance in drug trafficking detection tasks.However, after reaching the optimal point (in this case, around 40 shots), further increases in input shots may not necessarily yield significant performance gains.</p>
<p>Evaluating Model Components through Ablation Experiments</p>
<p>To assess the individual contributions of different model components in the knowledge-driven ChatGPT framework for drug trafficking detection, we conducted ablation experiments.We evaluated the performance when removing or modifying specific prompt sources and knowledge components.The evaluation metrics include accuracy, precision, recall, and F1 score.The evaluation results are summarized in Table 5.</p>
<p>Removing the prompt knowledge components, resulting in no prompt and no knowledge, led to an accuracy of 87.81%, and an F1 score of 88.70%.When the domain expert provided a drug-related hashtag as the knowledge prompt source, the performance remained consistent with an accuracy of 87.81%.Still, the precision increased to 92.76%, albeit with a slightly lower recall of 84.36% and an F1 score of 88.36%.Using the domain expert's contact information as the prompt source improved precision significantly to 97.46%.However, this change resulted in a decreased recall of 79.01% and a slightly lower accuracy of 87.36%, with an F1 score of 87.27%.Replacing the prompt source with a special symbol guided by the domain expert yielded an accuracy of 90.52%, precision of 89.11%, recall of 94.24%, and an F1 score of 91.60%.These results indicate that the special symbol prompt source effectively captures the model's attention and improves its ability to identify drug trafficking activities.When all knowledge components provided by the domain expert were included, the performance further improved.</p>
<p>The framework achieved an accuracy of 90.74% and an F1 score of 90.95%.This highlights the significance of incorporating comprehensive domain knowledge to enhance the framework's performance.</p>
<p>Removing prompt knowledge components resulted in an accuracy of 87.81%</p>
<p>and an F1 score of 88.70%.Utilizing a drug-related hashtag as the knowledge prompt source maintained an accuracy of 87.81%, but precision increased to 92.76% with a slightly lower recall of 84.36% and an F1 score of 88.36%.Using the domain expert's contact information as the prompt source significantly improved precision to 97.46%, albeit with decreased recall of 79.01%, accuracy of 87.36%, and an F1 score of 87.27%.Replacing the prompt source with a special symbol guided by the domain expert yielded an accuracy of 90.52%, precision of 89.11%, recall of 94.24%, and an F1 score of 91.60%.Including all knowledge components provided by the domain expert further enhanced performance, resulting in an accuracy of 90.74% and an F1 score of 90.95%.These results demonstrate the effectiveness of different prompt sources and highlight the importance of incorporating comprehensive domain knowledge to enhance the framework's performance in drug trafficking detection.</p>
<p>Next, we examine the effect of Monte Carlo dropout and the number of input shots.Without dropout, our framework with 40 shots achieved an accuracy of 89.84%, precision of 95.41%, recall of 85.60%, and an F1 score of 90.24%.However, the performance significantly improved when incorporating dropout with the same number of shots.The framework achieved an accuracy of 91.87%, precision of 99.52%, recall of 85.60%, and an F1 score of 92.04%.Finally, our complete framework with 40 shots and all knowledge components achieved the best performance, with an accuracy of 94.58%, precision of 96.60%, recall of 93.42%, and an impressive F1 score of 94.98%.</p>
<p>These experiments demonstrate the significance of prompt sources, knowledge components, and the utilization of Monte Carlo dropout in enhancing the accuracy and effectiveness of our framework for drug trafficking detection.The comprehensive integration of domain knowledge and the optimization of model components contribute to the superior performance of our proposed approach.</p>
<p>Drug Trafficking Detection Case Studies</p>
<p>Leveraging Monte Carlo Dropout for a Knowledge Prompt Example</p>
<p>In this subsection, we present case studies to demonstrate the effectiveness of our proposed method for drug trafficking detection.The case studies involve the use of positive words and negative words as prompts, highlighting the top 10 words ranked by their calculated importance scores (See Table 6).</p>
<p>The prompts are designed to capture the characteristics of drug trafficking discussions observed in comments on Instagram.The identified positive words, represented in green font, indicate significant features associated with drug traffickings, such as drug names, delivery, non-standard communication platforms, and evasion of law enforcement.For example, "address" and "delivery" are considered strong positive words that express key features of drug trafficking.These words play a crucial role in improving the performance of ChatGPT in the detection of drug trafficking.The presence of "address" signifies the use of email addresses as a means of communication, while "delivery" emphasizes fast delivery.These features may have been missing in ChatGPT's understanding of drug Top10 on-standard and trafficking, and their inclusion enhances the model's ability to identify drug trafficking activities accurately.On the contrary, the negative words, represented in red font, signify the words that negatively affect the performance of ChatGPT in detecting drug trafficking activities.These words hinder the model's ability to detect illicit drug-related content on social media platforms accurately.To enhance the performance of drug trafficking detection, negative words will be removed from the analysis.</p>
<p>The calculated importance scores provide information on the relevance and significance of each word on the detection of drug trafficking.The top-ranked words offer valuable clues to identify and monitor drug trafficking activities on social media platforms.By utilizing these prompts, our method enables a more targeted and effective approach to detecting drug-related content and identifying potential drug dealers.</p>
<p>The case studies highlight the capabilities of our proposed method in capturing key characteristics of drug trafficking discussions, shedding light on the covert nature of such activities, and providing law enforcement agencies and social media managers with valuable insights for intervention and prevention efforts.</p>
<p>A Comparative Analysis: Proposed Framework vs. Alternative Prompts</p>
<p>In this subsection, we present a comparative analysis of our proposed method for the detection of drug trafficking, contrasting it with alternative prompts.There are three alternative prompts: a prompt with no specific topic, a prompt focused on domain knowledge, and a prompt based on extracted knowledge.</p>
<p>• Prompt a.No prompt.</p>
<p>• In Case 1, ChatGPT-based methods accurately detect drug trafficking despite the presence of contact information (e.g., WhatsApp, Wickr, Kik, Snapchat) and drug-related hashtags suggest potential drug trafficking activity.This showcases the effectiveness of our approach in identifying drug trafficking activities even when perpetrators employ deceptive techniques.However, there are instances where ChatGPT makes mistakes.Case 2, although unrelated to drug trafficking, shares similarities that may lead to erroneous predictions without prompts.This highlights the importance of prompts in guiding the model and minimizing false positives.Interestingly, Case 3 reveals that ChatGPT can also make mistakes even when provided with domain knowledge as a prompt.In some cases, including domain knowledge may introduce noise and negatively impact the model's per-  These case studies provide valuable insights into the performance of our method, highlighting its ability to distinguish between positive and negative samples based on the prompts used.The results showcase the importance of prompt design and the integration of domain knowledge in enhancing drug trafficking detection mechanisms.</p>
<p>Discussions</p>
<p>This section discusses the key findings and implications of our research on the knowledge prompted ChatGPT framework for drug trafficking detection.We address the framework's performance, the effectiveness of different model components, and the potential limitations and future directions of the research.</p>
<p>Performance of the Framework</p>
<p>The evaluation results demonstrate the superior performance of our knowledgeprompted ChatGPT framework compared to baseline models.Our framework achieved an accuracy of 94.58%, precision of 96.60%, recall of 93.42%, and an F1 score of 94.98%.These results highlight the effectiveness of leveraging domainspecific knowledge, well-designed prompts, and prompt optimization techniques in enhancing drug trafficking detection capabilities.</p>
<p>Comparisons with state-of-the-art models such as BERT, XLNet, ALBERT, Dis-tilBERT, and RoBERTa further validate the superiority of our framework.It consistently outperformed these models regarding accuracy, precision, recall, and F1 score, indicating its ability to capture drug trafficking activities accurately and make informed predictions.</p>
<p>Effectiveness of Model Components</p>
<p>The ablation experiments provided valuable insights into the effectiveness of different model components.Removing the prompt source and knowledge components significantly decreased performance, underscoring the importance of incorporating domain knowledge and well-crafted prompts.Our framework's abil-ity to fuse domain knowledge into the prompts, guided by request-related questions and knowledge optimization techniques, played a crucial role in achieving the observed performance gains.</p>
<p>The analysis of varying input shots showed that the framework's performance improved with increasing shots up to an optimal point.Beyond that point, further increases in input shots did not yield significant performance gains.This suggests a threshold beyond which additional knowledge may not contribute substantially to drug trafficking detection tasks.</p>
<p>Limitations and Future Directions</p>
<p>While our knowledge prompted ChatGPT framework demonstrated impressive performance, several limitations should be considered.First, the framework's effectiveness heavily relies on the quality and comprehensiveness of the domain knowledge integrated into the prompts.Further efforts are required to continuously update and refine the knowledge base to adapt to evolving drug trafficking patterns and techniques.</p>
<p>Second, the evaluation focused on a specific dataset and task.Additional evaluations across different datasets and scenarios are needed to validate the generalizability of the framework.</p>
<p>Furthermore, the interpretability of the framework can be enhanced by exploring techniques such as attention mapping or explainable AI methods.This would enable a better understanding of the model's decision-making process and help address potential biases or limitations.</p>
<p>Future research directions could involve exploring more advanced language models, such as GPT-4 or similar architectures, to improve the framework's performance.Additionally, investigating multi-modal approaches that combine text with other forms of data, such as images or network traffic, could provide a more comprehensive understanding of drug trafficking activities.</p>
<p>Conclusions</p>
<p>This The knowledge-prompted ChatGPT framework has great potential in addressing real-world challenges related to drug trafficking detection.By combining the power of language models with domain expertise, the framework contributes to advancing natural language processing techniques for combating illicit activities.</p>
<p>Its performance superiority over baseline models shows its practical applicability and potential for implementation in real-world settings.</p>
<p>Overall, this research contributes to the growing body of knowledge-driven approaches in natural language processing and highlights the importance of incorporating domain-specific knowledge to enhance model performance.The framework of knowledge-prompted ChatGPT is a stepping stone for future advancements in the field, with potential applications in various domains beyond drug trafficking detection such as community and key player detection.</p>
<p>Figure 1 :
1
Figure 1: Illustration of the proposed knowledge-informed prompt, which is the interface for humans to interact with and use ChatGPT for drug trafficking detection.The prompt x : [K, Q, x] is a tuple of knowledge K, question Q, and original text x.The pink font represents knowledge K with masked words in purple, the blue font represents question Q, green font represents original text x (e.g., Instagram post captions/comments).</p>
<p>Figure 2 :
2
Figure 2: Framework of our proposed knowledge prompted ChatGPT.Blue arrows represent requests to ChatGPT, while red arrows signify the corresponding responses from ChatGPT.Inputs to the framework are indicated by text in blue, whereas outputs are denoted by text in red.</p>
<p>2 . 3 . 4 .
234
Knowledge fusion.The knowledge extracted from ChatGPT is then integrated with domain-specific knowledge to improve the drug trafficking detection capabilities of the framework.Domain-specific knowledge includes information from experts, research articles, and curated databases, providing a deep understanding of drug trafficking patterns, terminology, smuggling techniques, and key entities involved.The integration process aligns and reconciles the extracted knowledge with the domain knowledge, capturing nuanced insights from both sources.Prompt design based on integrated knowledge.To effectively prompt the ChatGPT model, we design prompts that leverage integrated knowledge and exploit areas of potential confusion.Confusion knowledge refers to specific aspects or concepts that ChatGPT might struggle to understand or disambiguate accurately.By addressing and clarifying these confusion points in the prompts, we guide the model's attention and enhance its understanding of drug trafficking-related text.The prompts may involve specific questions, context framing, or the inclusion of key keywords related to drug trafficking activities.Prompt optimization.Prompt optimization aims to fine-tune the designed prompts to maximize the performance of the ChatGPT model on drug trafficking detection tasks.Monte Carlo drop is employed to iteratively improve the prompts' effectiveness.By analyzing the model's responses to different prompts and measuring their impact on performance, we iteratively refine the prompts to align the model's behavior more closely with the desired drug trafficking detection outcomes.The pipeline of knowledge extraction, knowledge fusion, prompt design based on confusion knowledge, and prompt optimization is crucial in enhancing the model's understanding and performance in identifying drug trafficking activities.</p>
<p>Domain-specific knowledge holds an immense importance in improving the detection of drug trafficking activities on social media platforms.Domain experts possess specialized knowledge and insights into drug trafficking behaviors, terminologies, and strategies used by drug dealers.By integrating this knowledge into the detection framework, we can improve the accuracy and effectiveness of identifying drug trafficking.To leverage domain knowledge, we focus on three key aspects: hashtags, contact information, and special symbols commonly used by drug dealers to avoid detection.</p>
<p>is the combination of knowledge K, question Q, and original text x. Figure 3 shows the workflow to compose the prompt.</p>
<p>Figure 3 :
3
Figure 3: Illustration of the workflow to compose prompt x : [K, Q, x], which is a tuple of knowledge K, question Q, and original text x.The pink font represents knowledge K, blue font represents question Q, green font represents original text x (e.g., Instagram post captions/comments).</p>
<p>Discovery with ChatGPT.Beyond the prior domain knowledge as discussed in Section 3.3, we also extract relevant knowledge with ChatGPT since ChatGPT is trained on very large datasets.Specifically, we query ChatGPT with a few shots of labeled data {(x i , y i )} i∈[N ] , where N is a small number, to guide ChatGPT to generate informative and relevant responses.During fine-tuning, the model learns to identify patterns, relationships, and insights within the drug trafficking domain.This allows the model to acquire implicit knowledge from the dataset and generate informed responses when asked for drug-trafficking-related queries.Knowledge Fusion as Prompt.Knowledge fusion is a critical component of the prompt design process.It involves integrating relevant information from domain knowledge and knowledge discovered by ChatGPT into the prompts provided to the model.By fusing knowledge into the prompts, we provide the ChatGPT model with additional context and cues related to drug trafficking.This integration helps the model to make more accurate predictions and generate responses that align with the nuances of drug trafficking detection tasks.For example, a prompt could include a snippet of domain knowledge about common drug trafficking routes or the characteristics of illicit drug concealment methods.This prompts the model to focus its attention on these aspects and generate more insightful responses.</p>
<p>Prompt b.Drug dealers on Instagram utilize various methods to sell illicit drugs.They typically comment with contact information (such as wickr, Kik, snapchat, telegram, or telephone number), employ specific hashtags (including names, sale locations, or bitcoin payment), and use obfuscated descriptions with emojis, special symbols, and Greek characters to evade tracking, effectively showcasing the drugs they have for sale.• Prompt c.The characteristics of drug trafficking include using coded language and aliases, promoting the availability of drugs, using non-standard platforms, and encouraging customers to contact the seller discreetly.The comments also often lack legal verifications or prescriptions for drug purchasing and may emphasize fast delivery or anonymity.These characteristics can indicate a desire to operate covertly and evade detection by law enforcement, pointing to illegal drug trafficking.• Prompt d.The characteristics of drug trafficking include using coded language and aliases, promoting drug availability, employing drug-related hash-tags, utilizing non-standard communication platforms, and encouraging discreet customer contact.The comments often lack legal verifications or prescriptions while emphasizing fast delivery and anonymity.These characteristics suggest a desire to operate covertly and evade law enforcement, indicating illegal drug trafficking.Specifically, drug dealers on Instagram sell illicit drugs by commenting with various contact information (such as Wickr, Kik, Snapchat, Telegram, email addresses, and telephone numbers), utilizing specific hashtags related to drug names, sale location, and Bitcoin payment, and using obfuscated descriptions that are difficult to track, including emojis, special symbols, and Greek characters.Based on the alternative prompts and the proposed prompt (i.e., Prompt d.), we utilize sample data and examine the effectiveness of different prompts in identifying drug trafficking activities, as shown in Table 7.It illustrates the comparison by providing four different prompts: prompt a, representing no prompt; prompt b, which includes all knowledge; prompt c, comprising extracted knowledge; and prompt d, a fusion of prompt b and prompt c.Each sample in the table is labeled with either a positive (P) or negative (N) indication based on the presence or absence of drug trafficking elements.</p>
<p>4 M 5 Self
45
.D.M.A n N.E.M.B.U.T.A.L, K.U.S.H, C.O.C.A.I.N.E,A.C.I.D,(L.s.d n C.a.r.t) Txt/WhatsApp ..+1,<strong><em> Telegram:</em></strong> Wickr: *** M.Md,L.s.d n M.o.l.l.y ,a.d.i.e.s Label P Prompt a. P Prompt b.P Prompt c. N Prompt d.P Medicated ?#weed #marijuana #cbd #stoner #ganja #indica #sativa #kush #maryjane #dank #medicalmarijuana #bong #hemp #stoned #bhfyp Label N Prompt a. N Prompt b.P Prompt c. N Prompt d.P formance compared to having no prompt at all.This suggests that the prompt design and knowledge extraction must be carefully considered.When Instagram drug trafficking events involve special characters such as punctuation marks, the automatically extracted knowledge may hurt ChatGPT's predictions.These cases emphasize the need for robust methods to handle different types of input data and ensure accurate detection.Prompt d, which includes prompt b (domain knowledge), may sometimes lead to similar mistakes, as observed in Case 5.This highlights the complexity of balancing the inclusion of domain knowledge and avoiding potential pitfalls associated with prompt-based approaches.</p>
<p>research presented a knowledge-prompted ChatGPT framework for drug trafficking detection.The framework leverages domain-specific knowledge, welldesigned prompts, and prompt optimization techniques to improve the performance of the ChatGPT model in accurately identifying and labeling drug trafficking activities.Our framework demonstrates superior performance compared to baseline models, achieving an accuracy of 94.58%, precision of 96.60%, recall of 93.42%, and an F1 score of 94.98%.By integrating domain knowledge into the prompts, our framework captures nuanced insights, identifies key indicators, and provides actionable information for the detection of drug trafficking.The knowledge fusion technique, guided by request-related questions and knowledge optimization, contributes to the interpretability and effectiveness of the framework.We conducted thorough evaluations, including ablation experiments and assessments with varying input shots, to understand the impact of different model components and input variations.The results revealed the importance of prompt design, the value of domain knowledge integration, and the optimal threshold of input shots to maximize performance.Although our framework exhibits promising results, there are limitations to consider.The framework's effectiveness is heavily dependent on the quality and comprehensiveness of the domain knowledge integrated into the prompts.The generalizability of the framework should be further validated by applying it to diverse datasets and scenarios.Enhancing the interpretability of the framework and exploring advanced language models are potential areas for future research.</p>
<p>Table 1 :
1
List of symbols used to describe the proposed method.</p>
<p>Table 2
2provides examples and meanings for</p>
<p>Table 2 :
2
Types of domain knowledge for drug trafficking detection.
NameMeaningExampleHashtagDrug sale-related hashtags #MDMA #Cocaine #LSDContact informationTelephone number, email address, and other private social media accountsTxt/WhatsApp.+1,7<strong>.</strong><em>.9414 Wichr/snapchat james</em><strong><em>*52 kik james</em></strong>**52Special symbolUsing Punctuation, special characters, and emojis to evade detectionM.D.M.A, C.O.C.A.I.N.E, L.s.d M.o.l.l.y, SHRΘΘMS CΘKEhashtags like "#MDMA" or "#Cocaine" often indicate the sale or discussionof specific drugs.
• Contact Information: Drug dealers often share contact information, such as phone numbers or alternative social media accounts, to establish communication with potential buyers.By monitoring and analyzing this contact information, we can detect and track drug trafficking activities.Examples of contact information include phone numbers with specific area codes or messaging app usernames like "Telegram" or "Wickr."•Special Symbols: To evade detection, drug dealers frequently use various techniques, including the use of punctuation marks, special characters, or emojis, to mask content related to drug trafficking.When we recognize and interpret these special symbols, we can reveal the underlying drug-related messages.Examples include variations in drug names using special characters such as "M.D.M.A" or "C.O.C.A.I.N.E," or substituting letters with similar-looking symbols like "SHRΘΘMS."</p>
<p>Table 3 :
3
Performance Metrics of Different Models</p>
<p>Table 4 :
4
Performance Metrics of Different Models
Shot number Accuracy Precision Recall F1 Score5 shots86.23%90.63%83.54% 86.94%10 shots88.71%91.77%87.24% 89.45%20 shots87.81%90.91%86.42% 88.61%30 shots87.13%95.15%80.66% 87.31%40 shots89.84%95.41%85.60% 90.24%</p>
<p>Table 5 :
5
Performance Metrics of Different Models
Prompt sourceknowledgeAccuracy Precision RecallF1 ScoreNo promptNo knowledge87.81%90.21%87.24% 88.70%Domain expertHashtag87.81%92.76%84.36% 88.36%Domain expertContact information 87.36%97.46%79.01% 87.27%Domain expertSpecial symbol90.52%89.11%94.24% 91.60%Domain expertAll Knowledge (AK) 90.74%98.10%84.77% 90.95%Ours w/o dropout 40 shots89.84%95.41%85.60% 90.24%Ours w/o dropout 40 shots + AK91.87%99.52%85.60% 92.04%Ours w/ dropout40 shots + AK94.58%96.60%93.42% 94.98%</p>
<p>Table 6 :
6
Example Prompts by the proposed method.Green font Represents Positive words, and Red font Represents Negative words.
Prompt</p>
<p>Table 7 :
7
Contrasting the Proposed Method with Alternative Prompts: A Comparative Analysis.Prompt a. Represents no prompt, Prompt b.Represents Prompt with All Knowledge, Prompt c. Represents Prompt with Extracted Knowledge, Prompt d.Represents Prompt that fusing Prompt b. and Prompt c. "P" represents drug trafficking label or prediction, while "N" represents non-drug trafficking.Red fonts indicate wrong predictions.
IDCasesWHαTSαP // TEXT +1 760<strong><em>*</em>43 ωICKR// KIK //Snαpchαt -X</strong>**ver1SECURED/DISCREET DELIVERY BUY LSD, MDMA, DMT,SHRΘΘMS, PILLS, CΘKE &amp; more #lsd#shrooms #shroomforsale #magicshrooms? #tabsLabel P Prompt a. P Prompt b. P Prompt c. P Prompt d. PHOW TO AVOID RELIANCE ON PILLS ? #medication Synovation MedicalGroup offers a Functional Restoration Program where our physicians helppatients overcome chronic pain through an interdisciplinary approach so2they can return to normal work and life. This program helps -Increasingthe reliance on one's self-Decreasing pain medications #painmedication#healthcare #medicalcare #chronicpain #healthiswealth #opioidcrisis "Label N Prompt a. P Prompt b. N Prompt c. N Prompt d. N#psychedelic #psy #psytime #psychedelicrock #magicmushrooms #lsdtabs3#shrooms #trippyvibes #mdmaofficials #microdot #purpleacid #blotteracidLabel P Prompt a. P Prompt b. N Prompt c P Prompt d. P
ACKNOWLEDGEMENTSThe NSF partially supports this work under grant CMMI-2146076 and CNS-2125958.
Corruption, drug trafficking, and violence in mexico. S D Morris, The Brown Journal of World Affairs. 1822012</p>
<p>Drug trafficking, corruption, and violence in mexico: mapping the linkages. S D Morris, Trends in organized crime. 162013</p>
<p>A uav search and rescue scenario with human body detection and geolocalization. P Doherty, P Rudol, Australasian Joint Conference on Artificial Intelligence. Springer2007</p>
<p>Drug dealing on facebook, snapchat and instagram: A qualitative analysis of novel drug markets in the nordic countries. J Demant, S A Bakken, A Oksanen, H Gunnlaugsson, Drug and alcohol review. 3842019</p>
<p>Prevalence and global health implications of social media in direct-to-consumer drug advertising. B A Liang, T K Mackey, Journal of Medical Internet Research. 133e17752011</p>
<h1>drugsforsale: An exploration of the use of social media and encrypted messaging apps to supply and access drugs. L Moyle, A Childs, R Coomber, M J Barratt, International Journal of Drug Policy. 632019</h1>
<p>Detection of illicit drug trafficking events on instagram: A deep multimodal multilabel learning approach. C Hu, M Yin, B Liu, X Li, Y Ye, Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management. the 30th ACM International Conference on Information &amp; Knowledge Management2021</p>
<p>Identifying illicit drug dealers on instagram with large-scale multimodal data fusion. C Hu, M Yin, B Liu, X Li, Y Ye, ACM Transactions on Intelligent Systems and Technology (TIST). 1252021</p>
<p>A machine learning approach for the detection and characterization of illicit drug dealers on instagram: model evaluation study. J Li, Q Xu, N Shah, T K Mackey, Journal of medical Internet research. 216e138032019</p>
<p>Tracking illicit drug dealing and abuse on instagram using multimodal analysis. X Yang, J Luo, ACM Transactions on Intelligent Systems and Technology (TIST). 842017</p>
<p>Computational approaches to detect illicit drug ads and find vendor communities within social media platforms. F Zhao, P Skums, A Zelikovsky, E L Sevigny, M H Swahn, S M Strasser, Y Huang, Y Wu, IEEE/ACM Transactions on Computational Biology and Bioinformatics. 1912022</p>
<p>Fine-grained classification of drug trafficking based on instagram hashtags. C Hu, B Liu, Y Ye, X Li, Decision Support Systems. 1651138962023</p>
<p>Language models are fewshot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in neural information processing systems. 332020</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. I Drori, S Zhang, R Shuttleworth, L Tang, A Lu, E Ke, K Liu, L Chen, S Tran, N Cheng, Proceedings of the National Academy of Sciences. 11932e21234331192022</p>
<p>Using AI-generated suggestions from ChatGPT to optimize clinical decision support. S Liu, A P Wright, B L Patterson, J P Wanderer, R W Turer, S D Nelson, A B Mccoy, D F Sittig, A Wright, Journal of the American Medical Informatics Association. 3072023</p>
<p>Role of chat gpt in public health. S S Biswas, Annals of biomedical engineering. 5152023</p>
<p>How chat gpt can transform autodidactic experiences and open education, Department of Distance Education. M Firat, 2023Open Education Faculty, Anadolu Unive</p>
<p>Potential use of chat gpt in global warming. S S Biswas, Annals of biomedical engineering. 5162023</p>
<p>J Wei, Y Tay, R Bommasani, C Raffel, B Zoph, S Borgeaud, D Yogatama, M Bosma, D Zhou, D Metzler, E H Chi, T Hashimoto, O Vinyals, P Liang, J Dean, W Fedus, Emergent abilities of large language models. 2022</p>
<p>Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. P Liu, W Yuan, J Fu, Z Jiang, H Hayashi, G Neubig, ACM Comput. Surv. 559jan 2023</p>
<p>Autoprompt: Eliciting knowledge from language models with automatically generated prompts. T Shin, Y Razeghi, R L Logan, I V , E Wallace, S Singh, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language Processing2020</p>
<p>On the robustness of monte carlo dropout trained with noisy labels. P Goel, L Chen, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2021</p>
<p>Distilling meta knowledge on heterogeneous graph for illicit drug trafficker detection on social media. Y Qian, Y Zhang, Y Ye, C Zhang, Advances in Neural Information Processing Systems. 202134</p>
<p>W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint</p>
<p>J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, arXiv:2201.11903Chain of thought prompting elicits reasoning in large language models. 2022arXiv preprint</p>
<p>Promptchainer: Chaining large language model prompts through visual programming. T Wu, E Jiang, A Donsbach, J Gray, A Molina, M Terry, C J Cai, CHI Conference on Human Factors in Computing Systems Extended Abstracts. 2022</p>
<p>J Devlin, M.-W Chang, K Lee, K Toutanova, Bert , arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. 2018arXiv preprint</p>
<p>Xlnet: Generalized autoregressive pretraining for language understanding. Z Yang, Z Dai, Y Yang, J Carbonell, R R Salakhutdinov, Q V Le, Advances in neural information processing systems. 322019</p>
<p>Z Lan, M Chen, S Goodman, K Gimpel, P Sharma, R Soricut, arXiv:1909.11942A lite bert for self-supervised learning of language representations. Albert2019arXiv preprint</p>
<p>V Sanh, L Debut, J Chaumond, T Wolf, arXiv:1910.01108Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. 2019arXiv preprint</p>
<p>Y Liu, M Ott, N Goyal, J Du, M Joshi, D Chen, O Levy, M Lewis, L Zettlemoyer, V Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>