<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-405 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-405</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-405</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-272550863</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.05890v1.pdf" target="_blank">Automating the Practice of Science -- Opportunities, Challenges, and Implications</a></p>
                <p><strong>Paper Abstract:</strong> Automation transformed various aspects of our human civilization, revolutionizing industries and streamlining processes. In the domain of scientific inquiry, automated approaches emerged as powerful tools, holding promise for accelerating discovery, enhancing reproducibility, and overcoming the traditional impediments to scientific progress. This article evaluates the scope of automation within scientific practice and assesses recent approaches. Furthermore, it discusses different perspectives to the following questions: Where do the greatest opportunities lie for automation in scientific practice?; What are the current bottlenecks of automating scientific practice?; and What are significant ethical and practical consequences of automating scientific practice? By discussing the motivations behind automated science, analyzing the hurdles encountered, and examining its implications, this article invites researchers, policymakers, and stakeholders to navigate the rapidly evolving frontier of automated scientific practice.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e405.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e405.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian OED</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Optimal Experimental Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formal active-learning approach that selects experimental conditions to maximize expected information gain (or other utility) about competing models or parameters; widely used to choose informative experiments across scientific domains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Bayesian optimal experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A computational procedure that uses Bayesian inference and an explicit utility function (e.g., mutual information, model-discrimination score) to evaluate candidate experiments and select the one expected to be most informative for updating posterior beliefs about models or parameters. It typically requires (i) a generative/modeling framework that maps experimental conditions to predicted data, (ii) a prior over model parameters or models, and (iii) an objective (utility) to optimize, and is implemented via Monte Carlo, MCMC, or analytic approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / experimental design algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>statistics / machine learning / experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>psychology, neuroscience, physics, biology, chemistry, materials science, engineering</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>In practice across domains the core Bayesian OED framework is adapted by (a) specifying domain-specific generative models and priors, (b) tailoring the utility function (e.g., model discrimination vs. parameter precision), and (c) using domain-appropriate approximations or computational backends (e.g., specialized simulators, surrogate models, or problem-specific heuristics) to make optimization tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - the method has been successfully applied in many domains (psychology, neuroscience, physics, biology, chemistry, materials science, engineering) producing domain-relevant discoveries (e.g., new models in psychology), but its performance can degrade when model assumptions are violated or when computational costs are prohibitive; simulation studies reported cases where random or uniform sampling outperformed theory-driven adaptive approaches under misspecification.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>sensitivity to model misspecification and prior choice, high computational cost for evaluating expected utilities, need for accurate domain generative models, and possible failures when assumptions (noise model, stationarity) are violated.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>availability of explicit probabilistic models in the target domain, increasing computational resources, development of surrogate/simulation-based approximations, and prior domain knowledge to specify informative priors and utility functions.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>domain-specific generative/modeling frameworks, sufficient computational resources (for Monte Carlo/MCMC/optimization), and expertise to specify priors and utility appropriate to the scientific question.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>highly generalizable in principle across domains that can provide a generative model and priors; however, practical success depends on model fidelity and computational tractability, so transfer to domains lacking reliable generative models is limited.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e405.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adam / Eve (robot scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientist (Adam) and successor Eve</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated laboratory systems that integrate hypothesis generation, experimental design, and robotic execution to discover biological knowledge (Adam) and to perform automated drug-screening and repositioning (Eve).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Closed-loop robot scientist (automated hypothesis generation + laboratory execution)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>An integrated automated pipeline that (1) generates testable hypotheses (often via symbolic/algorithmic reasoning), (2) plans experiments to test those hypotheses, (3) executes experiments using laboratory robotics and assays, and (4) analyzes results to update hypotheses in iterative cycles, enabling autonomous discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>closed-loop experimental protocol / laboratory automation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>functional genomics / laboratory automation</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>drug discovery / chemical screening (early-stage pharmacology)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>To move from functional genomics (Adam) to drug discovery (Eve) the system was adapted to handle chemical compound libraries and assay protocols: changes include different assay modalities, compound handling and storage, high-throughput screening workflows, and domain-specific hypothesis-generation heuristics focused on compound activity and repositioning.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - Adam discovered gene functions in yeast; Eve identified chemical compounds (including suggesting triclosan as having antimalarial activity) that outperformed standard screening in its domain, demonstrating successful transfer to drug-discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>required development of specialized wet-lab robotics and assays for new experimental modalities, increased hardware complexity and cost, and the need to encode domain-specific experimental protocols and safety constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>modular design of the robot scientist concept, availability of high-throughput assay technologies, and explicit formalization of experimental protocols that could be automated.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>specialized laboratory robotics, validated assay protocols for the target domain, domain expertise to encode hypothesis-generation rules and to validate automated findings, and substantial capital investment.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>the closed-loop robot scientist paradigm is generalizable to other wet-lab domains that have standardized assays and high-throughput capabilities, but adaptation effort and equipment cost make transfers to more complex or less standardized domains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e405.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>A-Lab / Self-driving lab</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous laboratory for accelerated materials synthesis (A-Lab / self-driving laboratory)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Modular robotic platforms combined with machine learning and active learning that autonomously propose synthesis conditions, run experiments, and optimize material properties in a closed-loop manner.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An autonomous laboratory for the accelerated synthesis of novel materials.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Self-driving laboratory for materials synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A modular robotic platform orchestrated by active-learning and machine-learning models that (a) proposes candidate synthesis conditions or compositions (often trained on literature or databases), (b) executes synthesis experiments automatically, (c) measures target material properties, and (d) iteratively updates models to converge on optimized or novel materials.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>closed-loop experimental platform / automation + ML-driven design</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>robotic laboratory automation and active-learning from chemistry and ML</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>materials science (solid-state inorganic powder synthesis, thin-film materials, polymers, superconductors)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Integration of materials-specific synthesis hardware (e.g., powder handling, furnaces, deposition tools), measurement modalities for materials properties, use of literature-trained ML models and domain-specific surrogate models, and design of experimental condition spaces suitable to materials synthesis constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - autonomous laboratories like A-Lab and self-driving labs have accelerated synthesis and optimization of novel materials and produced large candidate sets (e.g., millions proposed by ML in materials discovery) and demonstrable optimizations in property targets across multiple studies.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>high hardware complexity and cost, need for domain-specific measurement instruments, handling of noisy sensors and variable experimental conditions, and constraints imposed by synthesis chemistry and safety.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>availability of materials databases, modular robotics, active learning algorithms, and cloud-based decision-making systems.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>specialized synthesis and measurement hardware, integration of ML models with laboratory control, domain expertise to define realistic experimental bounds and safety protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>relatively generalizable to other experimental domains with modularizable laboratory workflows and standardized measurements, but less applicable where bespoke hardware or highly variable naturalistic conditions are required.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e405.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoRA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated Research Assistant for Closed-Loop Computational Discovery (AutoRA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source closed-loop platform that integrates automated model discovery, experimental design, and web-based experimentation to conduct behavioral science studies with minimal human intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AutoRA: Automated Research Assistant for Closed-Loop Computational Discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Closed-loop web-based experimentation integrated with automated model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A software framework that automates the cycle of (1) proposing computational models, (2) designing experiments (often via adaptive or active-learning-driven designs), (3) deploying experiments to web-based platforms for participant data collection, and (4) performing automated model fitting and selection to iterate on hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method + experimental protocol integration</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computational discovery / machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>behavioral science (online human experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Adaptation included interfacing automated model-discovery engines with online experimental platforms and participant recruitment systems, implementing human-subjects protocols suitable for web deployment, and tailoring experimental designs to behavioral paradigms and measurement constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - AutoRA enabled automated closed-loop behavioral experiments and served as a computational testbed revealing cases where random experimentation outperformed model-guided approaches; it enabled practical closed-loop workflows but also highlighted limitations of current automated experimental design strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>ethical and procedural constraints for human subject research, need for participant recruitment and consent workflows, variability in human data, and cases where adaptive model-guided designs underperform.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>maturing web-based experimental platforms, open-source tooling, and established online participant pools (e.g., MTurk, Prolific).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>compliance with ethical research standards, integration with web experiment platforms, and safeguards for participant privacy and data quality.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>generalizable to other areas of behavioral research amenable to web deployment, but less applicable where in-lab instrumentation or ecological validity require physical presence.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and instrumental/technical skills</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e405.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM literature synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models for scientific literature synthesis and experiment planning (e.g., Elicit, BrainGPT, chemical 'coscientist')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of large pretrained or finetuned language models to synthesize large bodies of scientific literature, propose hypotheses and experimental variables, assist in experimental planning, and document research processes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Elicit: AI literature review research assistant.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Large language model-based literature synthesis and planning</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>LLMs process large corpora of scientific text (abstracts, full texts) to extract, summarize, and synthesize findings, propose research gaps and hypotheses, and assist in planning experiments by suggesting variables, protocols, and documentation. Domain-specific instances often involve fine-tuning on target-literature or code and integration with external tools (chemical retrosynthesis planners, lab documentation).</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / knowledge synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>natural language processing / machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>scientific literature review, chemistry (synthesis planning), neuroscience (predicting experiment outcomes), general experimental design across domains</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Domain adaptation via fine-tuning on domain literature (e.g., BrainGPT on neuroscience papers), combining LLM outputs with domain-specific databases and tools (chemical databases, experimental hardware documentation), and constraining generation to reduce hallucination and improve factuality.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - tools like Elicit and chemical coscientist improved literature extraction and synthesis; BrainGPT (per citation) outperformed human experts in predicting neuroscience experiment results in some evaluations, but risks remain including hallucinations, reproducing literature bias, and inclusion of low-quality or fraudulent sources.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>propagation of biases and errors from training data, hallucinations, sensitivity to low-quality or fraudulent literature, and requirement for domain expert validation.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>large-scale digitized scientific corpora, advances in transformer architectures, ability to fine-tune models on domain-specific corpora, and integration with external knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>access to extensive domain-specific text datasets, compute resources for fine-tuning, mechanisms for quality control and human oversight, and domain expertise for validating outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>broadly generalizable across domains with substantial textual literature; effectiveness depends on availability and quality of domain corpora and on proper fine-tuning and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and interpretive frameworks (document/knowledge synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e405.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BacterAI transfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BacterAI (active-learning microbial metabolism modeling) transfer across species</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active-learning framework for mapping microbial metabolism that benefits from transfer of prior metabolic models trained on one species when applied to a different but related species, improving efficiency of model discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bacterai maps microbial metabolism without prior knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Active-learning metabolic model transfer (BacterAI)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>An active-learning pipeline that iteratively proposes experiments to map metabolic capabilities and learns metabolic models; when a model pretrained on one bacterial species is retrained on another species, learning converges faster than training from scratch, leveraging shared metabolic structures.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / active-learning + transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>microbial systems biology / computational metabolism modeling</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>related bacterial species (cross-species model transfer within microbiology)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (transfer learning)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>The pretrained metabolic model from species A is used as initialization and then retrained on species B data; this requires mapping of features/assays between species and possibly adjusting priors or model components to account for species-specific metabolic differences.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - retraining from a related-species model discovered the metabolic model of the target species more efficiently than learning from scratch, as reported in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>differences in metabolic capabilities between species (feature mismatches), requirement to map experimental assays consistently, and risk that pretrained priors mischaracterize the new species if too dissimilar.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>shared biological principles across related species, existence of transferable representations of metabolism, and an active-learning framework that exploits informative experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>comparable experimental assay types across species, annotated metabolic features or consistent measurement protocols, and computational infrastructure for active retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>generalizable within phylogenetically or functionally related organisms where metabolic architectures are similar; less effective across highly divergent species.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and theoretical principles (transfer learning and active-learning protocols)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e405.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic regression / equation discovery</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic regression and computational equation discovery (e.g., AI-Feynman, genetic programming, PySR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Computational methods (genetic algorithms, reinforcement learning, gradient-based search, and other heuristics) that search over symbolic expression space to discover mathematical equations that describe data, used to rediscover known laws and in some cases identify novel scaling relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Symbolic regression / equation discovery</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Algorithms that perform search in the space of symbolic mathematical expressions to find concise equations that model empirical data, using approaches like genetic programming, reinforcement learning, mixed-integer programming, MCMC, or gradient-based methods, often with mechanisms to impose parsimony, exploit modularity, or incorporate priors.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational data-analysis / model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer science / symbolic AI / applied mathematics</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>physics, materials science, biology, plasma physics, cognitive science</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>hybrid approach combining with existing methods and domain knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>To operate in different scientific domains, symbolic-regression pipelines incorporate domain-specific priors (e.g., units, invariances), literature-derived equation priors, specialized loss functions to handle noise characteristics, and sometimes reduced-order models or latent representations for high-dimensional data.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - symbolic regression has routinely rediscovered known physical laws and, in some cases, produced novel scaling laws (e.g., in plasma physics) and new models in cognitive science; however, many discoveries are rediscoveries and success depends on noise levels and choice of priors.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>high computational complexity for large search spaces, sensitivity to noisy data, need for appropriate priors or constraints (units, invariances), and difficulty scaling to very high-dimensional raw data without preprocessing.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>improved search algorithms, increased computational power, availability of high-quality datasets and domain priors (e.g., units, symmetries), and hybrid approaches combining data-driven methods with knowledge-driven constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>clean/adequate-quality datasets, domain knowledge to specify priors/constraints, and computational resources suited to the chosen search algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>broadly applicable across domains where phenomena can be expressed by compact symbolic relationships and where sufficient data quality exists; less applicable for unstructured/high-dimensional raw data without dimensionality reduction.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e405.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e405.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reduced-order modeling transfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reduced-order modeling (autoencoders + SINDy / latent dynamics discovery) applied to high-dimensional datasets</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Techniques that learn low-dimensional latent representations of high-dimensional dynamical data (e.g., fluid dynamics videos) and then discover governing equations of the latent dynamics, enabling equation discovery and interpretable models from complex datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Machine Learning Methods for Reduced Order Modeling in Model Order Reduction and Applications: Cetraro, Italy 2021. Jn Kutz, 2023</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Reduced-order modeling via learned latent embeddings and symbolic discovery (autoencoders + SINDy)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A two-stage pipeline: (1) learn a low-dimensional latent representation of high-dimensional dynamics using dimensionality-reduction or deep autoencoders, and (2) apply symbolic/regression techniques (e.g., SINDy) in the latent space to identify governing equations of the reduced dynamics, enabling interpretable dynamic models from video or neural recordings.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational data-analysis / model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>fluid dynamics / applied physics (reduced-order modeling)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>neuroscience (neural data embeddings), cognitive science, and other high-dimensional empirical domains</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context (analogical transfer)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Adaptation requires changing encoder architectures and loss functions to match domain data modalities (e.g., neural spike trains vs. fluid flow fields), selecting domain-appropriate latent dimension sizes, and potentially altering the form of candidate functions used in symbolic discovery to reflect plausible domain dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - these methods have enabled discovery of low-dimensional dynamical descriptions for fluid dynamics and neural data, and revealed embeddings correlated with behavior, but success depends on the existence of low-dimensional structure and on adequate model/encoder training.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>need for large, high-quality datasets, risk of overfitting or learning spurious latent dynamics, sensitivity to encoder architecture and hyperparameters, and interpretability challenges mapping latent variables to physical/biological quantities.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>advances in deep learning for representation learning, mature symbolic-discovery tools, and availability of high-resolution spatiotemporal datasets (video, neural recordings).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>sufficiently large labeled or unlabeled datasets capturing dynamics, compute for deep model training, and domain expertise to interpret latent variables and discovered equations.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>applicable to many high-dimensional dynamical domains that exhibit low-dimensional latent structure, but effectiveness varies with signal-to-noise ratio and degree to which dynamics are compressible.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating the Practice of Science -- Opportunities, Challenges, and Implications', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist. <em>(Rating: 2)</em></li>
                <li>An autonomous laboratory for the accelerated synthesis of novel materials. <em>(Rating: 2)</em></li>
                <li>AutoRA: Automated Research Assistant for Closed-Loop Computational Discovery. <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models. <em>(Rating: 2)</em></li>
                <li>Bacterai maps microbial metabolism without prior knowledge. <em>(Rating: 2)</em></li>
                <li>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. <em>(Rating: 2)</em></li>
                <li>Machine Learning Methods for Reduced Order Modeling in Model Order Reduction and Applications: Cetraro, Italy 2021. Jn Kutz, 2023 <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-405",
    "paper_id": "paper-272550863",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "Bayesian OED",
            "name_full": "Bayesian Optimal Experimental Design",
            "brief_description": "A formal active-learning approach that selects experimental conditions to maximize expected information gain (or other utility) about competing models or parameters; widely used to choose informative experiments across scientific domains.",
            "citation_title": "",
            "mention_or_use": "mention",
            "procedure_name": "Bayesian optimal experimental design",
            "procedure_description": "A computational procedure that uses Bayesian inference and an explicit utility function (e.g., mutual information, model-discrimination score) to evaluate candidate experiments and select the one expected to be most informative for updating posterior beliefs about models or parameters. It typically requires (i) a generative/modeling framework that maps experimental conditions to predicted data, (ii) a prior over model parameters or models, and (iii) an objective (utility) to optimize, and is implemented via Monte Carlo, MCMC, or analytic approximations.",
            "procedure_type": "computational method / experimental design algorithm",
            "source_domain": "statistics / machine learning / experimental design",
            "target_domain": "psychology, neuroscience, physics, biology, chemistry, materials science, engineering",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "In practice across domains the core Bayesian OED framework is adapted by (a) specifying domain-specific generative models and priors, (b) tailoring the utility function (e.g., model discrimination vs. parameter precision), and (c) using domain-appropriate approximations or computational backends (e.g., specialized simulators, surrogate models, or problem-specific heuristics) to make optimization tractable.",
            "transfer_success": "partially successful - the method has been successfully applied in many domains (psychology, neuroscience, physics, biology, chemistry, materials science, engineering) producing domain-relevant discoveries (e.g., new models in psychology), but its performance can degrade when model assumptions are violated or when computational costs are prohibitive; simulation studies reported cases where random or uniform sampling outperformed theory-driven adaptive approaches under misspecification.",
            "barriers_encountered": "sensitivity to model misspecification and prior choice, high computational cost for evaluating expected utilities, need for accurate domain generative models, and possible failures when assumptions (noise model, stationarity) are violated.",
            "facilitating_factors": "availability of explicit probabilistic models in the target domain, increasing computational resources, development of surrogate/simulation-based approximations, and prior domain knowledge to specify informative priors and utility functions.",
            "contextual_requirements": "domain-specific generative/modeling frameworks, sufficient computational resources (for Monte Carlo/MCMC/optimization), and expertise to specify priors and utility appropriate to the scientific question.",
            "generalizability": "highly generalizable in principle across domains that can provide a generative model and priors; however, practical success depends on model fidelity and computational tractability, so transfer to domains lacking reliable generative models is limited.",
            "knowledge_type": "theoretical principles and explicit procedural steps",
            "uuid": "e405.0",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Adam / Eve (robot scientist)",
            "name_full": "Robot Scientist (Adam) and successor Eve",
            "brief_description": "Automated laboratory systems that integrate hypothesis generation, experimental design, and robotic execution to discover biological knowledge (Adam) and to perform automated drug-screening and repositioning (Eve).",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "mention_or_use": "mention",
            "procedure_name": "Closed-loop robot scientist (automated hypothesis generation + laboratory execution)",
            "procedure_description": "An integrated automated pipeline that (1) generates testable hypotheses (often via symbolic/algorithmic reasoning), (2) plans experiments to test those hypotheses, (3) executes experiments using laboratory robotics and assays, and (4) analyzes results to update hypotheses in iterative cycles, enabling autonomous discovery.",
            "procedure_type": "closed-loop experimental protocol / laboratory automation",
            "source_domain": "functional genomics / laboratory automation",
            "target_domain": "drug discovery / chemical screening (early-stage pharmacology)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "To move from functional genomics (Adam) to drug discovery (Eve) the system was adapted to handle chemical compound libraries and assay protocols: changes include different assay modalities, compound handling and storage, high-throughput screening workflows, and domain-specific hypothesis-generation heuristics focused on compound activity and repositioning.",
            "transfer_success": "successful - Adam discovered gene functions in yeast; Eve identified chemical compounds (including suggesting triclosan as having antimalarial activity) that outperformed standard screening in its domain, demonstrating successful transfer to drug-discovery tasks.",
            "barriers_encountered": "required development of specialized wet-lab robotics and assays for new experimental modalities, increased hardware complexity and cost, and the need to encode domain-specific experimental protocols and safety constraints.",
            "facilitating_factors": "modular design of the robot scientist concept, availability of high-throughput assay technologies, and explicit formalization of experimental protocols that could be automated.",
            "contextual_requirements": "specialized laboratory robotics, validated assay protocols for the target domain, domain expertise to encode hypothesis-generation rules and to validate automated findings, and substantial capital investment.",
            "generalizability": "the closed-loop robot scientist paradigm is generalizable to other wet-lab domains that have standardized assays and high-throughput capabilities, but adaptation effort and equipment cost make transfers to more complex or less standardized domains challenging.",
            "knowledge_type": "instrumental/technical skills and explicit procedural steps",
            "uuid": "e405.1",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "A-Lab / Self-driving lab",
            "name_full": "Autonomous laboratory for accelerated materials synthesis (A-Lab / self-driving laboratory)",
            "brief_description": "Modular robotic platforms combined with machine learning and active learning that autonomously propose synthesis conditions, run experiments, and optimize material properties in a closed-loop manner.",
            "citation_title": "An autonomous laboratory for the accelerated synthesis of novel materials.",
            "mention_or_use": "mention",
            "procedure_name": "Self-driving laboratory for materials synthesis",
            "procedure_description": "A modular robotic platform orchestrated by active-learning and machine-learning models that (a) proposes candidate synthesis conditions or compositions (often trained on literature or databases), (b) executes synthesis experiments automatically, (c) measures target material properties, and (d) iteratively updates models to converge on optimized or novel materials.",
            "procedure_type": "closed-loop experimental platform / automation + ML-driven design",
            "source_domain": "robotic laboratory automation and active-learning from chemistry and ML",
            "target_domain": "materials science (solid-state inorganic powder synthesis, thin-film materials, polymers, superconductors)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Integration of materials-specific synthesis hardware (e.g., powder handling, furnaces, deposition tools), measurement modalities for materials properties, use of literature-trained ML models and domain-specific surrogate models, and design of experimental condition spaces suitable to materials synthesis constraints.",
            "transfer_success": "successful - autonomous laboratories like A-Lab and self-driving labs have accelerated synthesis and optimization of novel materials and produced large candidate sets (e.g., millions proposed by ML in materials discovery) and demonstrable optimizations in property targets across multiple studies.",
            "barriers_encountered": "high hardware complexity and cost, need for domain-specific measurement instruments, handling of noisy sensors and variable experimental conditions, and constraints imposed by synthesis chemistry and safety.",
            "facilitating_factors": "availability of materials databases, modular robotics, active learning algorithms, and cloud-based decision-making systems.",
            "contextual_requirements": "specialized synthesis and measurement hardware, integration of ML models with laboratory control, domain expertise to define realistic experimental bounds and safety protocols.",
            "generalizability": "relatively generalizable to other experimental domains with modularizable laboratory workflows and standardized measurements, but less applicable where bespoke hardware or highly variable naturalistic conditions are required.",
            "knowledge_type": "instrumental/technical skills and explicit procedural steps",
            "uuid": "e405.2",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "AutoRA",
            "name_full": "Automated Research Assistant for Closed-Loop Computational Discovery (AutoRA)",
            "brief_description": "An open-source closed-loop platform that integrates automated model discovery, experimental design, and web-based experimentation to conduct behavioral science studies with minimal human intervention.",
            "citation_title": "AutoRA: Automated Research Assistant for Closed-Loop Computational Discovery.",
            "mention_or_use": "mention",
            "procedure_name": "Closed-loop web-based experimentation integrated with automated model discovery",
            "procedure_description": "A software framework that automates the cycle of (1) proposing computational models, (2) designing experiments (often via adaptive or active-learning-driven designs), (3) deploying experiments to web-based platforms for participant data collection, and (4) performing automated model fitting and selection to iterate on hypotheses.",
            "procedure_type": "computational method + experimental protocol integration",
            "source_domain": "computational discovery / machine learning",
            "target_domain": "behavioral science (online human experiments)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Adaptation included interfacing automated model-discovery engines with online experimental platforms and participant recruitment systems, implementing human-subjects protocols suitable for web deployment, and tailoring experimental designs to behavioral paradigms and measurement constraints.",
            "transfer_success": "partially successful - AutoRA enabled automated closed-loop behavioral experiments and served as a computational testbed revealing cases where random experimentation outperformed model-guided approaches; it enabled practical closed-loop workflows but also highlighted limitations of current automated experimental design strategies.",
            "barriers_encountered": "ethical and procedural constraints for human subject research, need for participant recruitment and consent workflows, variability in human data, and cases where adaptive model-guided designs underperform.",
            "facilitating_factors": "maturing web-based experimental platforms, open-source tooling, and established online participant pools (e.g., MTurk, Prolific).",
            "contextual_requirements": "compliance with ethical research standards, integration with web experiment platforms, and safeguards for participant privacy and data quality.",
            "generalizability": "generalizable to other areas of behavioral research amenable to web deployment, but less applicable where in-lab instrumentation or ecological validity require physical presence.",
            "knowledge_type": "explicit procedural steps and instrumental/technical skills",
            "uuid": "e405.3",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "LLM literature synthesis",
            "name_full": "Large Language Models for scientific literature synthesis and experiment planning (e.g., Elicit, BrainGPT, chemical 'coscientist')",
            "brief_description": "Use of large pretrained or finetuned language models to synthesize large bodies of scientific literature, propose hypotheses and experimental variables, assist in experimental planning, and document research processes.",
            "citation_title": "Elicit: AI literature review research assistant.",
            "mention_or_use": "mention",
            "procedure_name": "Large language model-based literature synthesis and planning",
            "procedure_description": "LLMs process large corpora of scientific text (abstracts, full texts) to extract, summarize, and synthesize findings, propose research gaps and hypotheses, and assist in planning experiments by suggesting variables, protocols, and documentation. Domain-specific instances often involve fine-tuning on target-literature or code and integration with external tools (chemical retrosynthesis planners, lab documentation).",
            "procedure_type": "computational method / knowledge synthesis",
            "source_domain": "natural language processing / machine learning",
            "target_domain": "scientific literature review, chemistry (synthesis planning), neuroscience (predicting experiment outcomes), general experimental design across domains",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Domain adaptation via fine-tuning on domain literature (e.g., BrainGPT on neuroscience papers), combining LLM outputs with domain-specific databases and tools (chemical databases, experimental hardware documentation), and constraining generation to reduce hallucination and improve factuality.",
            "transfer_success": "partially successful - tools like Elicit and chemical coscientist improved literature extraction and synthesis; BrainGPT (per citation) outperformed human experts in predicting neuroscience experiment results in some evaluations, but risks remain including hallucinations, reproducing literature bias, and inclusion of low-quality or fraudulent sources.",
            "barriers_encountered": "propagation of biases and errors from training data, hallucinations, sensitivity to low-quality or fraudulent literature, and requirement for domain expert validation.",
            "facilitating_factors": "large-scale digitized scientific corpora, advances in transformer architectures, ability to fine-tune models on domain-specific corpora, and integration with external knowledge bases.",
            "contextual_requirements": "access to extensive domain-specific text datasets, compute resources for fine-tuning, mechanisms for quality control and human oversight, and domain expertise for validating outputs.",
            "generalizability": "broadly generalizable across domains with substantial textual literature; effectiveness depends on availability and quality of domain corpora and on proper fine-tuning and validation.",
            "knowledge_type": "explicit procedural steps and interpretive frameworks (document/knowledge synthesis)",
            "uuid": "e405.4",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "BacterAI transfer",
            "name_full": "BacterAI (active-learning microbial metabolism modeling) transfer across species",
            "brief_description": "An active-learning framework for mapping microbial metabolism that benefits from transfer of prior metabolic models trained on one species when applied to a different but related species, improving efficiency of model discovery.",
            "citation_title": "Bacterai maps microbial metabolism without prior knowledge.",
            "mention_or_use": "mention",
            "procedure_name": "Active-learning metabolic model transfer (BacterAI)",
            "procedure_description": "An active-learning pipeline that iteratively proposes experiments to map metabolic capabilities and learns metabolic models; when a model pretrained on one bacterial species is retrained on another species, learning converges faster than training from scratch, leveraging shared metabolic structures.",
            "procedure_type": "computational method / active-learning + transfer learning",
            "source_domain": "microbial systems biology / computational metabolism modeling",
            "target_domain": "related bacterial species (cross-species model transfer within microbiology)",
            "transfer_type": "adapted/modified for new context (transfer learning)",
            "modifications_made": "The pretrained metabolic model from species A is used as initialization and then retrained on species B data; this requires mapping of features/assays between species and possibly adjusting priors or model components to account for species-specific metabolic differences.",
            "transfer_success": "successful - retraining from a related-species model discovered the metabolic model of the target species more efficiently than learning from scratch, as reported in the cited work.",
            "barriers_encountered": "differences in metabolic capabilities between species (feature mismatches), requirement to map experimental assays consistently, and risk that pretrained priors mischaracterize the new species if too dissimilar.",
            "facilitating_factors": "shared biological principles across related species, existence of transferable representations of metabolism, and an active-learning framework that exploits informative experiments.",
            "contextual_requirements": "comparable experimental assay types across species, annotated metabolic features or consistent measurement protocols, and computational infrastructure for active retraining.",
            "generalizability": "generalizable within phylogenetically or functionally related organisms where metabolic architectures are similar; less effective across highly divergent species.",
            "knowledge_type": "explicit procedural steps and theoretical principles (transfer learning and active-learning protocols)",
            "uuid": "e405.5",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Symbolic regression / equation discovery",
            "name_full": "Symbolic regression and computational equation discovery (e.g., AI-Feynman, genetic programming, PySR)",
            "brief_description": "Computational methods (genetic algorithms, reinforcement learning, gradient-based search, and other heuristics) that search over symbolic expression space to discover mathematical equations that describe data, used to rediscover known laws and in some cases identify novel scaling relations.",
            "citation_title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity.",
            "mention_or_use": "mention",
            "procedure_name": "Symbolic regression / equation discovery",
            "procedure_description": "Algorithms that perform search in the space of symbolic mathematical expressions to find concise equations that model empirical data, using approaches like genetic programming, reinforcement learning, mixed-integer programming, MCMC, or gradient-based methods, often with mechanisms to impose parsimony, exploit modularity, or incorporate priors.",
            "procedure_type": "computational data-analysis / model discovery",
            "source_domain": "computer science / symbolic AI / applied mathematics",
            "target_domain": "physics, materials science, biology, plasma physics, cognitive science",
            "transfer_type": "hybrid approach combining with existing methods and domain knowledge",
            "modifications_made": "To operate in different scientific domains, symbolic-regression pipelines incorporate domain-specific priors (e.g., units, invariances), literature-derived equation priors, specialized loss functions to handle noise characteristics, and sometimes reduced-order models or latent representations for high-dimensional data.",
            "transfer_success": "partially successful - symbolic regression has routinely rediscovered known physical laws and, in some cases, produced novel scaling laws (e.g., in plasma physics) and new models in cognitive science; however, many discoveries are rediscoveries and success depends on noise levels and choice of priors.",
            "barriers_encountered": "high computational complexity for large search spaces, sensitivity to noisy data, need for appropriate priors or constraints (units, invariances), and difficulty scaling to very high-dimensional raw data without preprocessing.",
            "facilitating_factors": "improved search algorithms, increased computational power, availability of high-quality datasets and domain priors (e.g., units, symmetries), and hybrid approaches combining data-driven methods with knowledge-driven constraints.",
            "contextual_requirements": "clean/adequate-quality datasets, domain knowledge to specify priors/constraints, and computational resources suited to the chosen search algorithm.",
            "generalizability": "broadly applicable across domains where phenomena can be expressed by compact symbolic relationships and where sufficient data quality exists; less applicable for unstructured/high-dimensional raw data without dimensionality reduction.",
            "knowledge_type": "theoretical principles and explicit procedural steps",
            "uuid": "e405.6",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Reduced-order modeling transfer",
            "name_full": "Reduced-order modeling (autoencoders + SINDy / latent dynamics discovery) applied to high-dimensional datasets",
            "brief_description": "Techniques that learn low-dimensional latent representations of high-dimensional dynamical data (e.g., fluid dynamics videos) and then discover governing equations of the latent dynamics, enabling equation discovery and interpretable models from complex datasets.",
            "citation_title": "Machine Learning Methods for Reduced Order Modeling in Model Order Reduction and Applications: Cetraro, Italy 2021. Jn Kutz, 2023",
            "mention_or_use": "mention",
            "procedure_name": "Reduced-order modeling via learned latent embeddings and symbolic discovery (autoencoders + SINDy)",
            "procedure_description": "A two-stage pipeline: (1) learn a low-dimensional latent representation of high-dimensional dynamics using dimensionality-reduction or deep autoencoders, and (2) apply symbolic/regression techniques (e.g., SINDy) in the latent space to identify governing equations of the reduced dynamics, enabling interpretable dynamic models from video or neural recordings.",
            "procedure_type": "computational data-analysis / model discovery",
            "source_domain": "fluid dynamics / applied physics (reduced-order modeling)",
            "target_domain": "neuroscience (neural data embeddings), cognitive science, and other high-dimensional empirical domains",
            "transfer_type": "adapted/modified for new context (analogical transfer)",
            "modifications_made": "Adaptation requires changing encoder architectures and loss functions to match domain data modalities (e.g., neural spike trains vs. fluid flow fields), selecting domain-appropriate latent dimension sizes, and potentially altering the form of candidate functions used in symbolic discovery to reflect plausible domain dynamics.",
            "transfer_success": "partially successful - these methods have enabled discovery of low-dimensional dynamical descriptions for fluid dynamics and neural data, and revealed embeddings correlated with behavior, but success depends on the existence of low-dimensional structure and on adequate model/encoder training.",
            "barriers_encountered": "need for large, high-quality datasets, risk of overfitting or learning spurious latent dynamics, sensitivity to encoder architecture and hyperparameters, and interpretability challenges mapping latent variables to physical/biological quantities.",
            "facilitating_factors": "advances in deep learning for representation learning, mature symbolic-discovery tools, and availability of high-resolution spatiotemporal datasets (video, neural recordings).",
            "contextual_requirements": "sufficiently large labeled or unlabeled datasets capturing dynamics, compute for deep model training, and domain expertise to interpret latent variables and discovered equations.",
            "generalizability": "applicable to many high-dimensional dynamical domains that exhibit low-dimensional latent structure, but effectiveness varies with signal-to-noise ratio and degree to which dynamics are compressible.",
            "knowledge_type": "theoretical principles and explicit procedural steps",
            "uuid": "e405.7",
            "source_info": {
                "paper_title": "Automating the Practice of Science -- Opportunities, Challenges, and Implications",
                "publication_date_yy_mm": "2024-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "rating": 2,
            "sanitized_title": "functional_genomic_hypothesis_generation_and_experimentation_by_a_robot_scientist"
        },
        {
            "paper_title": "An autonomous laboratory for the accelerated synthesis of novel materials.",
            "rating": 2,
            "sanitized_title": "an_autonomous_laboratory_for_the_accelerated_synthesis_of_novel_materials"
        },
        {
            "paper_title": "AutoRA: Automated Research Assistant for Closed-Loop Computational Discovery.",
            "rating": 2,
            "sanitized_title": "autora_automated_research_assistant_for_closedloop_computational_discovery"
        },
        {
            "paper_title": "Autonomous chemical research with large language models.",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Bacterai maps microbial metabolism without prior knowledge.",
            "rating": 2,
            "sanitized_title": "bacterai_maps_microbial_metabolism_without_prior_knowledge"
        },
        {
            "paper_title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity.",
            "rating": 2,
            "sanitized_title": "ai_feynman_20_paretooptimal_symbolic_regression_exploiting_graph_modularity"
        },
        {
            "paper_title": "Machine Learning Methods for Reduced Order Modeling in Model Order Reduction and Applications: Cetraro, Italy 2021. Jn Kutz, 2023",
            "rating": 1,
            "sanitized_title": "machine_learning_methods_for_reduced_order_modeling_in_model_order_reduction_and_applications_cetraro_italy_2021_jn_kutz_2023"
        }
    ],
    "cost": 0.0184575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>D R A F T Automating the Practice of Science -Opportunities, Challenges, and Implications
September 27, 2024</p>
<p>Sebastian Musslick sebastian.musslick@uos.de 
Institute of Cognitive Science
Department of Cognitive, Linguistic, &amp; Psychological Sciences
Osnabr ck University
49090 Osnabr ckGermany</p>
<p>Brown University
02912ProvidenceRI, ORCIDUSA</p>
<p>Laura K Bartlett 
Centre for Philosophy of Natural and Social Science
London School of Economics
Lakatos Building, Houghton StreetWC2A 2AELondonUK</p>
<p>ORCID</p>
<p>Suyog H Chandramouli 
Department of Information and Communications Engineering
Department of Computing Science
Aalto University
P.O. Box 110001B) FI-00076Otakaari, AALTOFinland</p>
<p>University of Alberta
8900 114 St NWT6G 2S4EdmontonABCanada</p>
<p>ORCID; d Cognitive Science Program
Indiana University
1101 E 10th St47405BloomingtonINUSA</p>
<p>ORCID</p>
<p>Marina Dubova 
Fernand Gobet 
Centre for Philosophy of Natural and Social Science
London School of Economics
Lakatos Building, Houghton StreetWC2A 2AELondonUK</p>
<p>ORCID</p>
<p>School of Psychology
University of Roehampton
SW15 4JDLondonUK</p>
<p>ORCID</p>
<p>Thomas L Griffiths 
Departments of Psychology and Computer Science
Princeton University
PrincetonNJUSA</p>
<p>ORCID</p>
<p>Jessica Hullman 
Department of Computer Science
Northwestern University
ILUSA</p>
<p>ORCID</p>
<p>Ross D King 
Department of Chemical Engineering and Biotechnology
Department of Computer Science and Engineering
University of Cambridge
CB3 0ASCambridgeUK</p>
<p>Chalmers University of Technology
412 96GothenburgSweden; ORCID</p>
<p>J Nathan Kutz 
Department of Applied Mathematics and Electrical and Computer Engineering
University of Washington
98195SeattleUSA</p>
<p>ORCID</p>
<p>Christopher G Lucas 
School of Informatics
University of Edinburgh
10 Crichton StEH8 9ABUnited Kingdom</p>
<p>ORCID</p>
<p>Suhas Mahesh 
Department of Materials Science and Engineering
University of Toronto
Canada</p>
<p>ORCID</p>
<p>Franco Pestilli 
Department of Psychology and Department of Neuroscience
The University of Texas
AustinTXUSA</p>
<p>ORCID</p>
<p>Sabina J Sloman 
Department of Computer Science
University of Manchester
M13 9PLUK ORCID</p>
<p>William R Holmes </p>
<p>In-stitute of Cognitive Science
Wachsbleiche 27, 49090 Osnabr ckGermany</p>
<p>D R A F T Automating the Practice of Science -Opportunities, Challenges, and Implications
September 27, 202498411D25EBD3D0346E02ECC8F32238E910.1073/pnas.XXXXXXXXXXarXiv:2409.05890v1[cs.CY]
Automation transformed various aspects of our human civilization, revolutionizing industries and streamlining processes.In the domain of scientific inquiry, automated approaches emerged as powerful tools, holding promise for accelerating discovery, enhancing reproducibility, and overcoming the traditional impediments to scientific progress.This article evaluates the scope of automation within scientific practice and assesses recent approaches.Furthermore, it discusses different perspectives to the following questions: Where do the greatest opportunities lie for automation in scientific practice?;What are the current bottlenecks of automating scientific practice?; and What are significant ethical and practical consequences of automating scientific practice?By discussing the motivations behind automated science, analyzing the hurdles encountered, and examining its implications, this article invites researchers, policymakers, and stakeholders to navigate the rapidly evolving frontier of automated scientific practice.Automation| Computational Scientific Discovery | Metascience | AI for Science "Though the world does not change with a change of paradigm, the scientist afterward works in a different world."-Thomas S. Kuhn, The Structure of Scientific Revolutions</p>
<p>Automation is transforming every domain of scientific inquiry, from the study of functional genomics in biology (1,2) to the derivation of conjectures in mathematics (3,4).Recent advances in automation are accelerating hypothesis generation in chemistry (5)(6)(7)(8), material discovery in materials science (9,10), and theory development in psychology (11).These breakthroughs are not only garnering attention but also an uptick in funding and prizes dedicated to the automation of scientific practice (12)(13)(14).Furthermore, concurrent advancements in artificial intelligence, software, and computing hardware are setting the stage for even more extensive automation within the scientific process (15)(16)(17).</p>
<p>The impact of automation in industry serves as a parallel to its potential in science.In the early 20th century, industrial automation began with mechanized assembly lines, revolutionizing manufacturing efficiency and output.The introduction of robotics and computer-aided manufacturing marked another leap, enabling precision and consistency previously unattainable by human labor.Today, industry-wide automation facilitates not just cost-efficient mass production, but also customized, adaptable, and intelligent manufacturing processes.This evolution demonstrates the capacity of automation to radically redefine operational paradigms.</p>
<p>Drawing parallels to scientific practice, one can anticipate a similar trajectory of profound change, where automation could accelerate discovery, reshape research methodologies, and redefine the very nature of scientific inquiry.At the same time, automation in industry had significant impacts on workers and the kind of products that dominate the marketplace.It is thus important to consider parallel impacts in the scientific setting which may have negative consequences for science and society.</p>
<p>In this perspective, we evaluate what automation should and can achieve for scientific practice.In doing so, we outline the current state of science automation, drawing on recent examples from different domains of science.Furthermore, we examine technological advancements that open new avenues for automation in science, and discuss current bottlenecks.Finally, we highlight a selection of practical and ethical considerations, and discuss how automation may lead scientists to work in a different world, one where traditional methodologies are redefined and new metaparadigms for science emerge.</p>
<p>What are the bounds of automating scientific practice?</p>
<p>Scientific practice can be defined as the set of methods and processes used by scientists to acquire knowledge about the natural world.Automation, in its broadest sense, refers to the use of technology to perform tasks with minimal human intervention.In the context of scientific practice, automation specifically denotes the use of technological tools and systems to carry out scientific tasks or processes traditionally performed by human scientists.</p>
<p>The bounds of automation within scientific practice hinge on at least two questions: First, is there a desire and justification for automating a given scientific practice?This question touches upon goal-related bounds-the alignment of automation with the overarching goals of science.Second, what factors characterizing D R A F T a scientific practice influence the feasibility of automating that practice?This aspect focuses on the technological bounds, assessing the practicality and potential constraints of applying automation in science.</p>
<p>Goal-related bounds: what automation should (not) achieve.</p>
<p>Science is driven by normative and epistemic goals.Here, we discuss arguments for and against automation serving these goals.</p>
<p>The normative goals of science involve ethical, moral, and societal values guiding both basic and applied science.One such goal may be to enable cheap and fast discoveries that advance human health.Along these lines, automation can serve to yield faster scientific discoveries with fewer resources.This is particularly desirable in the applied sciences, e.g., for identifying novel drugs or treatments.Thus, automation can aid scientific practice if societal needs are clear and research questions are well defined.However, the process of identifying a research question itself requires considering societal needs or the interests of the scientific community.As noted in the Opportunities section below, generative artificial intelligence (AI) can integrate large bodies of literature to identify societally and scientifcally important gaps in our knowledge that are worth filling.However, since the relevant normative considerations inherently depend on evolving human contexts, it can be argued that humans ought to always be involved in and monitor the degree to which scientific practices achieve these objectives (18).Consequently, full automation in these areas might not only be impractical but also undesirable, underscoring the indispensable role of human scientists in addressing the normative dimensions of science.</p>
<p>The epistemic goal of science is to understand the natural world through description, prediction, explanation, and control.As discussed in the sections that follow, advances in machine learning can aid in automating the description or explanation of natural phenomena.Such automation can help reduce human errors and biases, leading to more accurate predictions and better control of natural phenomena.Even more so, automation may help bypass or augment the cognitive capacities of human researchers (19), enabling degrees of prediction and control unachievable for human cognition alone.For example, machine learning models can generate millions of proposals for novel materials that lie beyond human intuition (9).Yet, the increase in precision achieved through automation presents an epistemic dilemma, as automation can limit human understanding.In the basic sciences, advancement of human understanding may be more desirable than merely improving predictability through automation.The complexity of a machine learning model, for example, might enhance its ability to accurately predict new stable materials, but concurrently obscure the process by which these predictions are made for human scientists.This scenario illustrates a potential conflict between the scientific objectives of enhancing prediction, on the one hand, and enabling human understanding, on the other (see Practical Implications).This suggests keeping human scientists involved in the scientific process rather than minimizing their involvement.Meanwhile, in applied sciences and engineering, the focus might shift towards maximizing prediction and control, providing a stronger case for automation of scientific practice.</p>
<p>Technological bounds: what automation can (not) achieve.</p>
<p>The technological bounds of automation hinge on the difficulty of automating scientific tasks.Here, we discuss four factors characterizing this difficulty (Figure 1).opportunities and barriers to automation, thereby guiding the identification of areas within scientific practice where automation can be most effectively implemented or where it may face challenges.</p>
<p>The first factor concerns the availability and quality of inputs that a scientific task requires.Some tasks, such as identifying a research question, rely on diverse and sometimes subjective inputs, including peer opinions, news articles, or funding announcements.Such inputs may not be trustworthy, widely accessible or structured for machine processing, posing a challenge to automation.</p>
<p>Another limiting factor for automation is the computational complexity of algorithms available to perform a scientific task.For example, identifying an appropriate experiment for testing a research question may require taking into account numerous decision variables (e.g., internal validity, resources needed, novelty) and searching an exponentially increasing space of possible experimental paradigms, which can be computationally intractable.</p>
<p>A related, yet often overlooked, factor influencing the automation of scientific tasks is the complexity of required hardware engineering.As stated in Moravec's paradox, sensorimotor tasks, like executing invasive brain recordings or social experiments, require advanced solutions in robotics to facilitate automation, which can pose more significant challenges to automation compared to cognitive tasks (20).</p>
<p>Finally, some tasks are difficult to automate because of the subjectivity of the task goal.Some scientific goals cannot be easily turned into a well-defined objective, which is required to communicate it to a machine.For instance, choosing between scientific models can be a matter of personal preference (21).</p>
<p>While the four factors collectively dictate the automatability of scientific tasks, they can be considered interdependent.For example, the automated discovery of scientific equations long relied on search methods with high computational complexity, such as evolutionary computation or brute force search, to identify a set of equations that best describes a given data set (22,23).However, the ability to collect large datasets cheaply, paired with improvements in computing hardware, enables the application of "data-hungry" but computationally tractable machine learning algorithms for equation discovery (24)(25)(26)(27).This approach reduces computational complexity, illustrating how enhancements in one factor can compensate for limitations in another.</p>
<p>Automation in current scientific practice</p>
<p>Existing approaches to automating science target tasks with readily available inputs, computational complexity and hardware demands that align well with current technological capabilities, and clear task goals.Accordingly, efforts at automatization in science have mostly been confined to tasks characterized by clearly specified objectives and well-defined subtasks, which include instances of quantitative hypothesis generation, experimental design, data collection, and quantitative analysis and inference.While covering all advances D R A F T is out of the scope of this article, we highlight a subset of these approaches, focusing on cases that facilitated novel discoveries.</p>
<p>Hypothesis generation.</p>
<p>Hypothesis generation is the development of testable statements that are based on observations, existing knowledge, or theory.Advances in automated hypothesis generation were primarily driven by two factors: improvements in computer algorithms, and the availability of large datasets.</p>
<p>Initial automated hypothesis formation approaches relied on symbolic reasoning systems.For example, in organic chemistry, logical deduction based on existing knowledge was employed to formulate hypotheses about the chemical constituents of body fluids (28).Furthermore, quantum simulations, facilitated through cloud computing, became the backbone of hypothesis generation for materials properties (29,30).The development of efficient search algorithms further expanded the scope of automated hypothesis formation to areas with large hypothesis spaces (3).For instance, hypothesis generation in mathematics leveraged efficient machine learning algorithms to identify novel conjectures about fundamental constants (3).Finally, deep learning enabled more breakthroughs in chemistry.A landmark achievement in this area is AlphaFold, which predicts 3D protein structures from amino acid sequences, facilitating the development of drugs (6).</p>
<p>The availability of large data sets led to further advances in automated hypothesis formation.One example is the field of biomedicine, where large gene databases led to a surge in hypothesis generation with computational methods, e.g., using data mining and network analysis to propose genes that may be linked to diseases (31,32).Similarly, existing materials databases provided sufficient information for machine learning methods to generate over 2.2 million proposals for novel materials that, so far, escaped human intuition (9).</p>
<p>Experimental design.</p>
<p>The problem of automated experimental design is to systematically identify the most informative experiment to address a particular hypothesis or scientific question.The informativeness of an experiment can be evaluated in various ways.Some automated experimental design methods are geared towards identifying the experimental conditions that minimize the influence of nuisance variables--experimental variables that are not of interest but can pollute the informativeness of intended experimental manipulations (33,34).Other methods aim to find experimental conditions that are well suited to identify a scientific model of interest (35)(36)(37).This problem of experimental design is closely related to the problem of active learning in machine learning research (2,(38)(39)(40), which seeks to identify data points that can best inform a machine learning model when included as training data.A prominent active learning method used for scientific practice is Bayesian optimal experimental design, which has been successfully applied in various fields, including psychology (36,37,41,42), neuroscience (43), physics (44,45), biology (46,47), chemistry (48,49), materials science (50)(51)(52), and engineering (53).For example, in the domain of psychology, Bayesian optimal experimental design led to the discovery of novel models of how humans discount the future relative to the present (54).</p>
<p>While automated experimental design methods can facilitate efficient data collection and strong inferences, their efficacy can be compromised if the underlying assumptions are violated or if the scientific model is incorrectly specified (55)(56)(57).This limitation led to unexpected findings in simulation studies, where random sampling of experimental conditions outperformed automated theory-driven approaches to experimental design (38,58), and where uniform sampling outperformed adaptive approaches in learning continuous relationships (59).</p>
<p>Another limitation of current approaches to automated experimental design pertains to their scope, as they focus on navigating a pre-defined space of experimental manipulations.Exploring novel research directions, however, often involves identifying completely new experimental manipulations (60).</p>
<p>Data collection.Data collection, often a time-consuming and costly aspect of empirical research, is a significant bottleneck in scientific discovery.Accordingly, automated tools for data collection emerged as some of the most impactful innovations in accelerating the pace of science.These tools span a wide range of applications and fields: fitness trackers revolutionized public health studies (61), continuous glucose monitors are providing critical insights into nutrition and diabetes research (62), and automated weather stations enhanced meteorological predictions (63).In addition to providing streams of real-time data for ongoing analysis, these automated systems can minimize human observation and experimenter biases.Experimenter bias occurs when the beliefs, expectations, or preferences of the researcher unconsciously influence the conduct or outcome of an experiment.Automating data collection in animal studies helped to eliminate experimenter bias, resulting in refutations of previous results, such as the evidence for statistical learning ability in newborn chicks (64).A particularly noteworthy advancement in the behavioral sciences was the adoption of web-based experiments, especially during the COVID-19 pandemic.Online platforms and interfaces for recruiting and conducting experiments did not only facilitate the collection of behavioral data at a time when traditional lab-based studies were impractical, but they also broadened the scope and diversity of participants (65)(66)(67).Automating data collection also generated opportunities for automating other elements of behavioral science, such as adopting adaptive experimental designs that change based on the responses of participants (68) or collecting larger datasets that can support the use of machine-learning algorithms (11).</p>
<p>Statistical inference.The automation of statistical inference transformed dramatically from the era of manual computations, a reality echoed in old statistical textbooks filled with computationsimplifying shortcuts.The introduction of computers altered statistical methodologies, sometimes even leading to their replacement by machine learning techniques.For example, modern statistical inference engines, like Stan, leverage techniques such as Markov Chain Monte Carlo (MCMC) for efficient sampling of model parameters (69).Tools for likelihood-free inference enable the analysis of statistical models that are not mathematically tractable.Furthermore, frameworks such as Bayesian Workflow (70) and platforms such as the Automatic Statistician (71) are streamlining complex processes like Bayesian inference and the construction of traditional statistical models.The automation of statistical inference, however, is mostly confined to the deduction of new knowledge based on pre-specified statistical models.</p>
<p>Scientific inference and model discovery.Scientific inference, unlike statistical inference, involves generating hypotheses about observations (abduction) and generalizing from observations to laws or broader theories (induction).The automation of scientific inference is termed computational scientific discovery and has so far centered on identifying models or laws that elucidate specific phenomena (22,23,72).One instance of computational scientific D R A F T discovery involves the identification of equations ("symbolic regression") to uncover quantitative laws governing a given data set.Early efforts relied on heuristic search techniques to rediscover insights from mathematics (73,74) or physics (75).Advances in machine learning and high-performance computing facilitated equation discovery, building on reinforcement learning (26), genetic algorithms (25,76,77), MCMC sampling (78), mixed-integer nonlinear programming (79), or gradient-based search techniques (24,27,80,81).However, most forms of computational model discovery are limited to the rediscovery of existing knowledge.Possible exceptions include the discovery of scaling laws and boundary equations in plasma physics (82) and novel models of human decision-making (11).</p>
<p>Closed-loop automation spanning multiple scientific practices.Demonstrations of successful closed-loop automation in empirical research-implementing iterations between experimental design, data collection and model discovery-mark a significant progression for automated scientific practice.One pioneering example is the robot scientist Adam (Figure 2A), which was the first fully automated machine to discover novel scientific knowledge (2).Adam investigated the functional genomics of the yeast S. cerevisiae, and discovered the function of locally orphan enzymesenzymes known to be in yeast but for which the gene(s) encoding them were unknown.The successor of Adam, Eve, is a robot scientist designed for early-stage drug development (39), which identified chemical compounds that outperformed standard drug screening.Eve's most significant discovery is that triclosan (an antimicrobial compound commonly used in toothpastes) may aid against malaria (39,83,84).Another example of a closed-loop discovery system in biology is Wormbot-AI, a platform designed to autonomously conduct experiments on the longevity of worms, capable of testing thousands of interventions annually (85,86).</p>
<p>Complete automation also gained momentum in materials science and chemistry, where efforts are focused on integrating hypothesis generation, decentralized experimentation, and cloudbased decision-making.For instance, modular robotic platforms, driven by machine learning algorithms, were used to optimize material properties by varying synthesis conditions (87-89).One notable example is A-Lab (Figure 2B), an autonomous laboratory for the solid-state synthesis of inorganic powders, which leverages a combination of active learning and machine learning models trained on the literature, to propose novel material candidates (10).</p>
<p>Additionally, behavioral research became amenable to closedloop automation with the ability to collect data via online experiments.Open-source tools like AutoRA (90) facilitate closed-loop research by integrating automated model discovery, experimental design, and experimentation in empirical research.AutoRA effectively interfaces with web-based platforms for automated data collection, integrating the acquisition of behavioral data from human participants.While the potential to yield novel discoveries stands to test, AutoRA served as a computational testbed for philosophy of science, exposing cases where random experimentation outperforms model-guided experimentation (38).</p>
<p>Finally, researchers introduced an LLM-based agent for automating empirical machine learning research, from idea development and experimental design to execution and data analysis, e.g., for improving existing machine learning models (91).Notably, this system also leveraged LLMs to automate the writing and peer review of the resulting research manuscript, with the computational cost of one article estimated to be just 15 USD.</p>
<p>Future opportunities</p>
<p>Existing approaches for automating scientific practice primarily target tasks for which (a) high-quality data is available, (b) the computational complexity can be addressed by current algorithms, and (c) hardware complexity is manageable.The most promising prospects for future automation in scientific practice are found in tasks traditionally limited by human cognitive capacities.This includes areas requiring the processing of large volumes of highdimensional data or exhaustive literature searches.In this section, we highlight a few technological trends that promise to push the boundaries of science automation along these lines.</p>
<p>Data collection, standardization, and sharing.Advancements in cost-effective data collection, standardization, and sharing significantly boost the automatability of scientific practices, particularly those dependent on empirical data.For example, in the behavioral sciences, the utilization of crowd-sourced experimentation platforms like Amazon Mechanical Turk and Prolific revolutionized the efficiency of behavioral data collection.Additionally, LLMs that can mimic human behavior were proposed as proxies for participants, aiding in the acquisition of large-scale datasets (92).Once acquired, such large-yet cost-efficient-datasets can empower datahungry machine learning algorithms, enabling them to uncover novel, and more precise models of human behavior (93)(94)(95)(96).Largescale data collection, however, still bears significant hardware</p>
<p>D R A F T</p>
<p>challenges, e.g., for collecting biological samples from a large number of participants (see Future challenges).Nevertheless, the data quality needed for automated analysis techniques should be complemented by data standardization and sharing.</p>
<p>Scientific data sharing platforms, such as the Open Science Framework, facilitated the availability and accessibility of data needed for automated analyses and computational discovery.The potential of data sharing and standardization is perhaps best illustrated in materials science, where databases for stable materials enabled the prediction of large quantities of new materials (9).Other scientific domains profit from similar efforts.For example, in neuroscience, archives like DANDI, OpenNeuro, DABI and BossDB allow researchers to share data using community standards (97), such as BIDS for neural data (98).</p>
<p>Combining data-driven and knowledge-driven discovery.</p>
<p>A particularly promising approach to automating scientific discovery is the integration of pre-existing human knowledge into the discovery process.Traditionally, data-driven discovery methods operated with minimal prior knowledge about the specific domain of scientific inquiry.This pure data-driven approach makes such methods particularly susceptible to noisy data.However, recent work demonstrates that incorporating prior theoretical knowledge can significantly aid in recovering scientific models from noisy datasets.For example, Bayesian symbolic regression exhibits greater efficacy in recovering equations from noisy data when given priors about scientific equations extracted from Wikipedia (78,99).Similarly, embedding prior knowledge in the form of general logical axioms proved instrumental in rediscovering complex scientific laws, including Kepler's third law of planetary motion and Einstein's relativistic time-dilation law (79,100).Furthermore, experiments with the BacterAI, which uses active learning for the automated study of microbial metabolisms, have demonstrated the advantage of leveraging relevant prior knowledge (101).Specifically, when the metabolic model trained on one bacterial species was retrained for the species of interest, it more efficiently discovered its metabolic model compared to starting the learning process from scratch, despite the two species differing in their metabolic capabilities.These examples highlight the benefits of combining data-driven and knowledge-driven approaches for automated model discovery.</p>
<p>The benefits of knowledge-driven discovery are, however, fundamentally limited by the quality of prior knowledge.For example, Bayesian adaptive experimentation can be misled if prior knowledge mischaracterizes the data (102,103).Thus, data-driven approaches to computational model discovery become particularly beneficial when dominant scientific models in the empirical sciences are more informed by (wrong) theory versus data.This is evident in computational models of human reinforcement learning, which predominantly rely on classic machine learning algorithms (104).Recent work demonstrated that a data-driven model discovery can uncover novel reinforcement learning models that better explain human learning than traditional models (95).</p>
<p>Finally, a notable area of progress in automated model discovery is the analysis of high-dimensional datasets, such as fluid dynamics captured in video format, through reduced-order modeling.This process involves learning a low-dimensional representation of the dynamics inherent in complex data and then decoding the governing equations of these latent dynamics (105)(106)(107)(108). Similar approaches were developed to automate the discovery of neural data embeddings correlating with behavioral dynamics (109).These approaches promise to extend the reach of automated model discovery to high-dimensional naturalistic datasets.beyond experimental control.</p>
<p>Generative AI and LLMs.Generative AI and LLMs offer paths towards automating scientific practices that have historically been challenging due to their computational complexity and qualitative nature (8,16,91,110).Among these are the synthesis and integration of literature, and documentation of findings.</p>
<p>Researchers argued that LLMs show promise in enhancing literature reviews, a task currently limited by the cognitive constraints and language barriers of human scientists (111,112).Whereas humans may only be able to parse and integrate a few hundred articles into a literature review-the scope of which is heavily influenced by the expertise and biases of the researcher-LLMs may accomplish literature synthesis in the order of thousands or millions of articles.Critically, LLMs can take into account articles written in different languages, thus helping to counter the dominance of Western perspectives in scientific literature.Thus, LLMs can assist in extending or even bypassing human researchers' cognitive limitations.A notable application of LLMs for the purpose of literature synthesis is Elicit, which utilizes LLMs trained on paper abstracts to support and help researchers extract relevant information from the scientific literature (112).Another instance of such assistance is an LLM-based "coscientist" for chemical research, which improved the planning of chemical syntheses based on extensive information available on the internet, and aided in the navigation of extensive hardware documentation (8).Additionally, BrainGPT-an LLM fine-tuned to the neuroscience literature-demonstrated the capability to outperform human experts in predicting the results of neuroscience experiments (113).</p>
<p>Combined with their capability for literature synthesis, LLMs can foster the discovery of new research directions and hypotheses (91).Along these lines, LLMs have the potential to expand experimental design spaces, addressing a common bottleneck in automated scientific practice.While traditional automated experimentation is confined to researcher-defined variables (cf. Figure 2), LLMs could identify novel experimental variables of interest, thus broadening the scope of scientific inquiry.However, it can be argued that LLMs risk rediscovering already known hypotheses and experiments (18).</p>
<p>Once experiments are designed, LLMs may aid in the balanced documentation and communication of the research study, including the automated documentation of research code (114,115).Apart from aiding in the construction of research articles, LLMs can enable automated translation into multiple languages.This advancement is particularly beneficial for non-native English speakers and is an example of how automation and AI can address ethical challenges in science.Nevertheless, literature reviews conducted by human scientists serve not only to synthesize knowledge but also to build and refine the conceptual frameworks of evolving scientists-a process that is critical to scientific training and that is challenged by the overuse of LLMs for literature synthesis.</p>
<p>Future challenges</p>
<p>Despite recent advances and opportunities for the automation of science, there remain substantial obstacles.This section examines technological bounds rooted in four bottlenecks (cf. Figure 1): limited availability and quality of data, intractable computational complexity of certain scientific tasks, lack of required hardware, and subjectivity in assessing the outputs of scientific tasks.These</p>
<p>D R A F T</p>
<p>bottlenecks highlight why barriers to automation remain difficult to surmount in the basic sciences (as opposed to engineering), at least with the technologies and methodologies currently at our disposal.Addressing these challenges will require significant interdisciplinary efforts to identify solutions that enable automation beyond a few selected domains of scientific inquiry.</p>
<p>Limited availability and quality of inputs.Prior applications of computational discovery, such as in chemistry (5,7,116) and materials science (9,10), relied on standardized formats for both data and scientific hypotheses that are easily parsed by machine learning algorithms.However, most tasks of scientific practice rely on a diversity of representations for scientific knowledge.For example, computational models in the natural sciences are expressed in various formats, such as equations embedded in scientific articles or computer code written in different programming languages.Without standardization across disciplines, automated systems face significant challenges in drawing parallels or applying concepts from one domain to another.Efforts to standardize the representation of scientific models and other forms of scientific knowledge promise to ease the automation of scientific practices relying on such knowledge (117).However, even if data is standardized and widely available, ensuring its quality remains critical.For instance, literature synthesis enabled by LLMs may be unfruitful or even misleading if fraudulent or unreproducible papers are included as inputs to these models.Therefore, robust quality control measures must accompany standardization efforts to maintain the integrity and usefulness of automated systems.</p>
<p>Computational complexity.One of the fundamental bottlenecks in the automation of scientific practice lies in the computational complexity of many scientific tasks.For example, complexity analyses within the realm of cognitive science indicate that scientific discovery in cognitive science may be computationally intractable in principle, even with unlimited availability of data (118).These theoretical results suggest that uncovering a definitive "ground-truth" theory may be beyond the reach of computation.</p>
<p>One potential critique of leveraging computational methods for scientific discovery hinges on the incomplete comprehension of the cognitive processes, and the concomitant computational complexity underlying it.One may argue that without a full grasp of how humans tackle scientific inquiries, designing algorithms capable of similar feats seems implausible.However, at least two counterarguments challenge this perspective.First, replicating natural processes is not a prerequisite for solving problems.For instance, modern airplanes achieve superior lift not by emulating the flapping motion of birds but through aerodynamically efficient designs.Second, a deep understanding of cognitive phenomena is not a strict requirement for automation, as evidenced by the capabilities of LLMs to produce coherent natural language sequences without humans having a complete scientific understanding of language generation.Nonetheless, this gap in understanding underscores the importance of implementing robust evaluation methods to ensure the accuracy and mitigate any potential negative impacts of automating scientific processes.</p>
<p>Hardware engineering.The advancement of automated science is significantly hindered by current limitations in laboratory robotics and hardware engineering.For instance, executing complex biological or physics experiments remains challenging.Moreover, while robotic automation has been successfully implemented in certain areas, such as with the robot scientist concept (1,2,101,119), its application is primarily limited to clearly defined engineering problems.Yet, even well-defined engineering problems must manage the noise and variability inherent in the data collected by sensors, which can dramatically affect the reliability of scientific outcomes.Therefore, while progress has been made in automating scientific practice, developing more sophisticated robotics to handle complex, noisy data is crucial for its broader adoption and effectiveness.</p>
<p>The automation of hardware tasks in scientific practice is also hindered by the need for highly specialized equipment, leading to significant capital expenditures, often exceeding millions of dollars.Such custom-built hardware is typically field-specific and lacks versatility for reuse in other scientific domains.This challenge is evident in the limited cross-utilization of hardware between disciplines, as seen in the relatively small amount of equipment that materials scientists have been able to adapt from the more heavily automated field of drug discovery.Addressing this issue requires a strategic approach where, for each scientific field, scientists identify and develop a core set of automated hardware that can deliver the greatest impact.This not only involves designing equipment that meets the unique needs of each field but also balancing specificity with adaptability, to maximize utility and cost-effectiveness.</p>
<p>Subjective goals of scientific tasks.More than in engineering, practices in basic science are inherently subjective in how the outcomes of those practices are evaluated.This challenge is particularly evident in developing AI capable of generating novel and impactful scientific ideas.Novelty and impact involve a high degree of subjectivity and variability, making it difficult for these systems to replicate human judgment in the space of scientific inquiry (16).This issue is compounded by the personal aspect of scientific practice.The selection of scientific projects is guided by the personal experience and perspective of human scientists.Diversity in such perspectives paired with interdisciplinary exchange can lead to a greater diversity of ideas in human scientific systems (120)-a dimension that AI currently cannot emulate without explicit instruction.Furthermore, the lack of standardized solutions in many scientific areas means that automating these tasks risks constraining exploration, which is vital for scientific advancement.</p>
<p>Moreover, interpretation of data patterns and hypothesis generation often necessitates human judgment to translate statistical regularities into meaningful scientific interpretations.Techniques like topic modeling, while effective in identifying text co-occurrence patterns, require human insight to align these patterns with relevant scientific constructs (121).The role of human judgment is perhaps best exemplified in serendipitous discovery, often stemming from unexpected failures or results.For example, Alexander Fleming's discovery of penicillin began with the accidental contamination of a Petri dish.Instead of discarding it, his observation of the bacteria being killed by the mold led to the development of the first antibiotic.These aspects highlight the crucial role of human judgment in scientific discovery.</p>
<p>Implications</p>
<p>Although the automation of science currently faces significant limitations, the extent to which it will evolve in the mid-to longterm remains an open empirical question.As advancements in hardware and algorithms continue, the range of practices subject to automation is likely to expand.In this section, we explore the practical and ethical consequences of this trend.</p>
<p>D R A F T</p>
<p>Practical implications.</p>
<p>The role of human scientists and the paradox of automation.The advancement of automation in scientific practice raises considerations regarding the future role of human scientists.On the one hand, it can be argued that automation reduces the need for human involvement.Scientific discovery systems may become able to monitor themselves and tune themselves to optimal performancepotentially excluding humans from the scientific discovery loop.On the other hand, it can argued that the greater the efficiency of an automated system, the more vital the role of human oversight (122).A critical assumption underlying this "paradox of automation" is that automation is not perfect; the potential for accumulating errors necessitates human intervention.If automation were flawless, human oversight would be unnecessary, and the paradox would not exist.However, for tasks with sufficient complexity and uncertainty, this paradox suggests that, in highly automated environments, human contributions, though less frequent, are more critical.This may specifically apply to tasks that demand subjective assessment or the synthesis of complex data, such as reviewing scientific literature, as well as high-level responsibilities such as strategic allocation of funds for scientific inquiry.</p>
<p>Even in the absence of subjective assessment, there are inherent risks associated with automation.For instance, an error within an automated system can lead to a cascade of compounded errors, persisting and potentially amplifying until the system is either corrected or deactivated.This may be particularly problematic for automation methods whose decisionmaking processes are not completely predictable, as is the case for many machine learning algorithms.This unpredictability raises the issue of responsibility for unintended consequences such as injuries.Given the potential severe legal and financial implications of compounding errors in automation, the involvement of human scientists, even in areas where automation is technically feasible, may prove to be more efficient, practical, and safe in the near future.Thus, the paradox of automation underscores the lasting importance of human expertise and the need for a balanced approach that combines automated systems with human judgment.</p>
<p>Research training.With increased automation of science, there arises a need to reevaluate and adapt scientific education.This new landscape calls for training that encompasses not only traditional scientific knowledge but also skills for effectively working alongside automated scientific discovery systems.For instance, obtaining valuable outputs from LLMs is becoming an essential skill.Moreover, scientists will need to develop competencies in understanding and evaluating the functioning and outputs of automated systems, as is already demanded for statistical software (47).This shift implies a growing demand for engineers, scientists, and technicians proficient in advanced STEM skills.</p>
<p>Research evaluation.The current pace of science is primarily determined by our capacity to carry out the research itself.Laboratory studies in fields like biology and chemistry can take years, contrasting with the relatively quick peer review process.However, if advancements in automation enable research to be conducted and documented several magnitudes faster (91), this could lead to a substantial increase in the rate of research article submissions.Such a scenario would further strain the already pressured peer review system.One potential solution could be the automation of peer review, possibly through the use of LLMs; however, this approach has already faced restrictions and bans in certain contexts due to concerns about its efficacy, reliability, and confidentiality (123).Another potential solution is for journals to require that articles generated by automated systems be accompanied by critical evaluations from corresponding human authors.This ensures that human researchers retain comprehension and oversight of what is being submitted while also serving as initial reviewers of the work generated by their automated systems.Either way, this shift would necessitate a reevaluation of the peer review process, ensuring it remains rigorous and effective in the face of increased scientific productivity.</p>
<p>Scientific methods.The automation of scientific practice has the potential to bring about a shift in scientific methods that goes beyond mere acceleration of scientific discovery.As discussed above, the use of machines for scientific discovery allows us to move beyond the cognitive and physical constraints inherent to human scientists (19).Consider, for example, the principle of parsimony in the construction of scientific models.Traditionally, parsimonious models have been favored for their superior generalization, ease of interpretation and communicability among human scientists.However, as discussed in (21), recent studies suggest that highly complex models can, under certain conditions, surpass the generalization capabilities of simpler ones (124), leading to unprecedented advances in scientific research (e.g., for 3D protein folding (6) or material discovery ( 9)).Moreover, as explored in ( 21), the development of such complex models is often a prerequisite for discovering successful parsimonious models (e.g., (125)(126)(127)).This ability of machines to explore and develop models with a level of complexity beyond what is readily interpretable by humans opens up new avenues for scientific progress, less constrained by human cognitive limitations.However, as discussed above, for basic science, there is epistemic value in human understanding that may outweigh the predictive power of AI scientists.</p>
<p>Another consequence of automation concerns the ways in which empirical research is conducted.For example, automated systems can hypothesize and experiment in design spaces far beyond the reach of human cognitive capabilities (9,119).Furthermore, the ability to collect large amounts of data cheaply may obviate frequent iterations between hypothesis generation, experimental design, and data collection.Instead, with the availability of large data sets, the problem of scientific discovery can be transformed into a model discovery problem more amenable to machine learning (11,94,128).However, it is important to recognize that the success of a one-time large-scale data collection hinges on a well-defined experimental design space and the stability of the system under study, as constant changes in the system can undermine the effectiveness of this approach.Accordingly, adaptive experimental design may be needed to identify suitable design spaces (58).</p>
<p>Ethical implications.</p>
<p>Biases.While human biases influence every aspect of scientific work, automated systems are not immune to bias.They can inherit biases from their creators, the construction process, the data they use, and their training format (129).Examples include discriminatory biases in facial recognition technology (130), unrepresentative sampling in psychological experiments (116), and discrimination in automated participant recruitment processes (131).Moreover, automated literature reviews don't escape the biases inherent to the existing literature.These biases can be democratized and exacerbated by the pace of these systems, especially when D R A F T they are uninterpretable or operate as "black boxes."However, a potential advantage is that biases in automated systems may be easier to correct than in humans, such as by using more diverse data, or by aligning automated systems with societal norms.</p>
<p>Value alignment and responsibility.The risk of harmful biases and outcomes of automated processes call for their value alignment with broader societal norms.This is particularly crucial as automation could potentially ease the path for malevolent entities to conduct research detrimental to society, such as developing chemical or biological weapons.Such outcomes underscore the necessity of ethics dedicated to addressing these issues, ensuring that automated scientific advancements align with human values.</p>
<p>Consequences of automation also bring about the issue of responsibility: If a scientific discovery that affects the wider society is based on an automated process, who is responsible?The accountability for effects arising from harmful scientific practice remains ambiguous-whether it lies with the system's creator, its user, or the implementer of societal changes based on the system's output.This issue parallels broader debates in AI, such as liability in self-driving car accidents or the creation of automated artwork.Additionally, the potential misuse of powerful systems (e.g., a system suggesting harmful drug treatments) necessitates robust safeguards.The same applies to potential violations of data privacy.When automated systems generate contentious theories or design ethically questionable experiments, human oversight and responsibility are imperative.Importantly, ethical guidelines are often formulated by the institutions developing the systems (132), highlighting the need for an external framework that can hold institutions accountable.</p>
<p>Conclusion</p>
<p>While the automation of scientific practice is currently confined mostly to well-defined engineering and discovery problems, there is the potential for automation to pervade a large part of scientific practice.We suggest that this trend represents not merely a series of quantitative changes, such as increased efficiency or precision in science, but brings about a fundamental shift in the conduct of science.The integration of AI into scientific practice has the potential to overcome human cognitive limitations, thereby expanding our capabilities for discovery.Yet, this advance is not without challenges-data availability, computational complexity, engineering demands, and subjectivity of scientific task goals mark the technical boundaries of current automatability.Furthermore, normative goals of science-anchored on societal valuespotentially make complete automation of scientific practice neither desirable nor feasible.Finally, this qualitative shift comes with practical and ethical challenges that call for interdisciplinary and collective efforts from researchers, policymakers, and the broader community to navigate the future of science.</p>
<p>D R A F T</p>
<p>Fig. 1 .
1
Fig. 1.Factors determining the technological reach of automation in scientific practice.</p>
<p>Fig. 2 .
2
Fig. 2. Closed-loop automation systems.(A) Adam for functional genomics.(B) A-Lab for materials science.(C) AutoRA for behavioral science.Dashed boxes list knowledge and processes provided by human researchers.</p>
<p>of 10 -www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX Musslick et al.
PNAS -September 27, 2024 -vol. XXX -no. XX -3
of 10 -www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX Musslick et al.
of 10 -www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX Musslick et al.
PNAS -September 27, 2024 -vol. XXX -no. XX -7
of 10 -www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX Musslick et al.
PNAS -September 27, 2024 -vol. XXX -no. XX -9
of 10 -www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX Musslick et al.
AcknowledgmentsS. Musslick  and S. Mahesh were supported by Schmidt Science Fellows, in partnership with the Rhodes Trust.S. Musslick was also supported by the Carney BRAINSTORM program at Brown University and the National Science Foundation (2318549).S. Mahesh also acknowledges the support of the Acceleration Consortium fellowship.S.J. Sloman acknowledges support from the UKRI Turing AI World-Leading Researcher Fellowship, [EP/W002973/1].S. Chandramouli was supported by the Finnish Center for Artificial Intelligence, and Academy of Finland (328813); he also acknowledges the support from the Jorma Ollila Mobility Grant by Nokia Foundation.L. Bartlett and F. Gobet were supported by European Research Council Grant ERC-ADG-835002-GEMS. T. L. Griffiths was supported by a grant from the NOMIS Foundation.R. D. King was supported by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation, by Chalmers Artificial Intelligence Research Centre (CHAIR), and by the UK EPSRC grants EP/R022925/2 and EP/W004801/1.The authors thank Solomon Oyakhire for valuable feedback.DisclosuresThe authors have no competing interests to report.
Functional genomic hypothesis generation and experimentation by a robot scientist. Rd King, Nature. 4272004Nature Publishing Group UK London</p>
<p>The automation of science. Rd King, Science. 3242009American Association for the Advancement of Science</p>
<p>Generating conjectures on fundamental constants with the Ramanujan Machine. Raayoni, Nature. 5902021Nature Publishing Group UK London</p>
<p>Advancing mathematics by guiding human intuition with AI. Davies, Nature. 6002021Nature Publishing Group UK London</p>
<p>Synthetic organic chemistry driven by artificial intelligence. R Af De Almeida, Moreira, Rodrigues, Nat. Rev. Chem. 32019Nature Publishing Group UK London</p>
<p>Highly accurate protein structure prediction with AlphaFold. Jumper, Nature. 5962021Nature Publishing Group</p>
<p>Applications of artificial intelligence for organic chemistry: the DENDRAL project. Lindsay Rk, No Title)1980</p>
<p>Autonomous chemical research with large language models. Boiko, Macknight, Kline, Nature. 6242023Nature Publishing Group</p>
<p>Scaling deep learning for materials discovery. Merchant, Nature. 2023</p>
<p>An autonomous laboratory for the accelerated synthesis of novel materials. Nj, Szymanski, Nature. 2023</p>
<p>Using large-scale experiments and machine learning to discover theories of human decision-making. Jc Peterson, Dd Bourgin, Agrawal, Reichman, Griffiths, Science. 3722021American Association for the Advancement of Science</p>
<p>Foundation Models for Scientific Discovery (FoundSci). Velasquez, Def. Adv. Res. Proj. Agency (DARPA) Program Solicitation. 2023</p>
<p>Nobel Turing Challenge: creating the engine for scientific discovery. Kitano, Syst. Biol. Appl. 7292021Nature Publishing Group UK London</p>
<p>The future of fundamental science led by generative closed-loop artificial intelligence. Zenil, arXiv:2307.075222023arXiv preprint</p>
<p>Science in the age of large language models. Birhane, Kasirzadeh, S Leslie, Wachter, Nat. Rev. Phys. pp. 2023Nature Publishing Group UK London</p>
<p>Scientific discovery in the age of artificial intelligence. Wang, Nature. 6202023Nature Publishing Group UK London</p>
<p>How should the advent of large language models affect the practice of science?. Binz, arXiv:2312.037592023arXiv preprint</p>
<p>Cognitive science of augmented intelligence. Dubova, Galesic, Rl Goldstone, Cogn. Sci. 46e132292022Wiley Online Library</p>
<p>Mind children: The future of robot and human intelligence. Moravec, Harv. UP. 1988</p>
<p>Is ockham's razor losing its edge? new perspectives on the principle of model parsimony. Dubova, 10.31222/osf.io/bs5xe2024MetaArXiv preprint</p>
<p>Scientific discovery: Computational explorations of the creative processes. Langley, 1987MIT press</p>
<p>Computational discovery of scientific knowledge in Computational discovery of scientific knowledge: introduction, techniques, and applications in environmental and life sciences. Deroski, L Langley, Todorovski, 2007Springer</p>
<p>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. Sm Udrescu, Adv. Neural Inf. Process. Syst. 332020</p>
<p>Interpretable machine learning for science with PySR and SymbolicRegression. Cranmer, arXiv:2305.015822023jl. arXiv preprint</p>
<p>Discovering symbolic policies with deep reinforcement learning. Landajuela, 2021</p>
<p>GFN-SR: Symbolic Regression with Generative Flow Networks. Li, Marinescu, Musslick, 2023</p>
<p>DENDRAL: a case study of the first expert system for scientific hypothesis formation. Rk Lindsay, Buchanan, Feigenbaum, Lederberg, Artif. intelligence. 611993Elsevier</p>
<p>Materials design and discovery with high-throughput density functional theory: the open quantum materials database (OQMD). Je Saal, Kirklin, Aykol, C Meredig, Wolverton, Jom. 652013Springer</p>
<p>Commentary: The Materials Project: A materials genome approach to accelerating materials innovation. Jain, APL materials. 12013AIP Publishing</p>
<p>BioGraph: unsupervised biomedical knowledge discovery via automated hypothesis generation. Am Liekens, Publisher: BioMed Central. 122011Genome biology</p>
<p>Automated cognome construction and semi-automated hypothesis generation. Jb, Voytek, Voytek, J. neuroscience methods. 2082012Elsevier</p>
<p>SweetPea: A standard language for factorial experimental design. Musslick, Behav. Res. Methods pp. 2020Springer</p>
<p>Mix, a program for pseudorandomization. Van Casteren, Davis, Behav. research methods. 382006Springer</p>
<p>Assessing the distinguishability of models and the informativeness of data. M A Dj Navarro, Pitt, Myung Ij, Cogn. psychology. 492004Elsevier</p>
<p>Optimal experimental design for model discrimination. M A Ji Myung, Pitt, Psychol. review. 1162009American Psychological Association</p>
<p>Adaptive design optimization: A mutual information-based approach to model discrimination in cognitive science. Dr Cavagnaro, M A Myung, Pitt, Kujala, Neural computation. 222010MIT Press</p>
<p>An evaluation of experimental sampling strategies for autonomous empirical research in cognitive science. Musslick, 20234545</p>
<p>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. Williams, J. Royal society Interface. 1220141289. 2015The Royal Society</p>
<p>Closed-loop cycles of experiment design, execution, and learning accelerate systems biology model development in yeast. Coutant, Proc. Natl. Acad. Sci. Natl. Acad. SciNational Acad Sciences2019116</p>
<p>QUEST+: A general multidimensional Bayesian adaptive psychometric method. Ab Watson, J. Vis. 172017The Association for Research in Vision and Ophthalmology</p>
<p>Valentin, arXiv:2305.07721Designing Optimal Behavioral Experiments Using Machine Learning. 2023arXiv preprint</p>
<p>Bayesian inference and online experimental design for mapping neural microcircuits. Shababo, Paige, L Pakman, Paninski, Adv. Neural Inf. Process. Syst. 262013</p>
<p>Sequential Bayesian experiment design for optically detected magnetic resonance of nitrogen-vacancy centers. Dushenko, Ambal, Mcmichael, Phys. review applied. 14540362020APS</p>
<p>Simulation-based optimal Bayesian experimental design for nonlinear systems. Huan, Marzouk, J. Comput. Phys. 2322013Elsevier</p>
<p>Robotic search for optimal cell culture in regenerative medicine. Gn Kanda, Elife. 11e770072022Publisher: eLife Sciences Publications Limited</p>
<p>Accelerating bayesian optimization for biological sequence design with denoising autoencoders. Stanton, 2022</p>
<p>Chembo: Bayesian optimization of small organic molecules with synthesizable recommendations. Korovina, 2020</p>
<p>Constrained Bayesian optimization for automatic chemical design using variational autoencoders. Rr Griffiths, Jm Hern ndez-Lobato, Chem. science. 112020Royal Society of Chemistry</p>
<p>Bayesian optimization for materials design with mixed quantitative and qualitative variables. Zhang, Apley, Chen, Sci. reports. 102020Nature Publishing Group UK London</p>
<p>On-the-fly closed-loop materials discovery via bayesian active learning. Ag Kusne, Nat. communications. 1159662020</p>
<p>Benchmarking the performance of Bayesian optimization across multiple experimental materials science domains. Liang, Comput. Mater. 71882021Nature Publishing Group UK London</p>
<p>Optimal sensor placement methodology for parametric identification of structural systems. Papadimitriou, J. sound vibration. 2782004Elsevier</p>
<p>Data-driven experimental design and model development using Gaussian process with active learning. Chang, Kim, M A Zhang, J I Pitt, Myung, Cogn. Psychol. 1251013602021Elsevier</p>
<p>Inconsistency of Bayesian Inference for Misspecified Linear Models, and a Proposal for Repairing It. T P Gr nwald, Van Ommen, Bayesian Analysis. 122017</p>
<p>Rainforth, Foster, Ivanova, Smith, arXiv:2302.14545Modern bayesian experimental design. 2023arXiv preprint</p>
<p>Towards Robust Bayesian Adaptive Design Methods for the Study of Human Behavior. Sj Sloman, 2022Carnegie Mellon UniversityPhD thesis</p>
<p>Against theory-motivated experimentation in science. Dubova, Moskvichev, Zollman, MetaArXiv. June. 242022</p>
<p>Sampling heuristics for active function. Gelpi, Saxena, Lifchits, Buchsbaum, Lucas, Proceedings of the 43rd Annual Meeting of the Cognitive Science Society. (cognitivesciencesociety.org). the 43rd Annual Meeting of the Cognitive Science Society. (cognitivesciencesociety.org)2021</p>
<p>Explore your experimental designs and theories before you exploit them! Behav. Dubova, Sj Sloman, Andrew, Nassar, Musslick, Brain Sci. 472024Cambridge University Press</p>
<p>Wearable activity trackers, accuracy, adoption, acceptance and health impact: A systematic literature review. Shin, J. biomedical informatics. 932019Elsevier</p>
<p>Juvenile Diabetes Research Foundation Continuous Glucose Monitoring Study Group, Effectiveness of continuous glucose monitoring in a clinical care environment: evidence from the Juvenile Diabetes Research Foundation continuous glucose monitoring (JDRF-CGM) trial. Diabetes care. 332010Publisher: Am Diabetes Assoc</p>
<p>Antarctic automatic weather station program: 30 years of polar observation. Ma Lazzara, Weidner, Keller, Thom, Cassano, Bull. Am. Meteorol. Soc. 932012American Meteorological Society</p>
<p>Automated study challenges the existence of a foundational statistical-learning ability in newborn chicks. Sm Wood, Johnson, Wood, Psychol. Sci. 302019Sage Publications Sage CA</p>
<p>psiTurk: An open-source framework for conducting replicable behavioral experiments online. Tm Gureckis, Behav. research methods. 482016Springer</p>
<p>Conducting behavioral research on Amazon's Mechanical Turk. Mason, Suri, Behav. research methods. 442012Springer</p>
<p>Prolific. ac-A subject pool for online experiments. S Palan, Schitter, J. Behav. Exp. Finance. 172018Elsevier</p>
<p>Complex cognitive algorithms preserved by selective social learning in experimental populations. Thompson, Van Opheusden, Sumers, Griffiths, Science. 3762022</p>
<p>Stan: A probabilistic programming language. Carpenter, J. statistical software. 762017NIH Public Access</p>
<p>. Gelman, arXiv:2011.018082020Bayesian workflow. arXiv preprint</p>
<p>The automatic statistician. Autom. machine learning: Methods, systems, challenges pp. Steinruecken, Smith, Janz, Z Lloyd, Ghahramani, 2019Springer International Publishing</p>
<p>Introduction: Scientific discovery in the social sciences. Gobet, Addis, Lane, Sozou, Sci. discovery social sciences. 2019Springer</p>
<p>Integrating quantitative and qualitative discovery: the ABACUS system. Bc Falkenhainer, Michalski, Mach. Learn. 11986Springer</p>
<p>The ubiquity of discovery. Db Lenat, Artif. Intell. 91977Elsevier</p>
<p>Data-driven discovery of physical laws. Langley, Cogn. Sci. 51981Elsevier</p>
<p>Genetic programming for developing simple cognitive models. Bartlett, Pirrone, Javed, Lane, Gobet, 20234545</p>
<p>Automatic generation of cognitive theories using genetic programming. Minds Mach. F Frias-Martinez, Gobet, 2007Springer17</p>
<p>A Bayesian machine scientist to aid in the solution of challenging scientific problems. Guimer , Sci. advances. 669712020American Association for the Advancement of Science</p>
<p>Combining data and theory for derivable scientific discovery with AI-Descartes. Cornelio, Nat. Commun. 1417772023Nature Publishing Group UK London</p>
<p>A unified framework for deep symbolic regression. Landajuela, Adv. Neural Inf. Process. Syst. 352022</p>
<p>Musslick, Recovering Quantitative Models of Human Information Processing with Differentiable Architecture Search. 20214345</p>
<p>Data driven theory for knowledge discovery in the exact sciences with applications to thermonuclear fusion. Murari, Sci. Reports. 1019858. 2020Nature Publishing Group UK London</p>
<p>Yeast-based automated high-throughput screens to identify anti-parasitic lead compounds. Bilsland, Open Biol. 31201582013The Royal Society</p>
<p>Plasmodium dihydrofolate reductase is a second enzyme target for the antimalarial action of triclosan. Bilsland, Sci. Reports. 810382018Nature Publishing Group UK London</p>
<p>The million-molecule challenge: a moonshot project to rapidly advance longevity intervention discovery. Mb Lee, Blue, M Muir, Kaeberlein, GeroScience pp. 2023Springer</p>
<p>WormBot, an open-source robotics platform for survival and behavior analysis in C. elegans. Jn Pitt, GeroScience. 412019Springer</p>
<p>Machine learning on a robotic platform for the design of polymer-protein hybrids. Mj Tamasi, Adv. Mater. 3422018092022Wiley Online Library</p>
<p>Self-driving laboratory for accelerated discovery of thin-film materials. Bp Macleod, Sci. Adv. 688672020American Association for the Advancement of Science</p>
<p>Closed-loop superconducting materials discovery. Ea Pogue, Comput. Mater. 91812023</p>
<p>AutoRA: Automated Research Assistant for Closed-Loop Computational Discovery. Musslick, Strittmatter, Holland, 2023</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Lu, arXiv:2408.062922024arXiv preprint</p>
<p>Can ai language models replace human participants?. D Dillion, Tandon, K Gu, Gray, Trends Cogn. Sci. 272023</p>
<p>Bk Petersen, Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients in International Conference on Learning Representations. 2021</p>
<p>Beyond playing 20 questions with nature: Integrative experiment design in the social and behavioral sciences. Almaatouq, Behav. Brain Sci. pp. 2022Cambridge University Press</p>
<p>Predictive and Interpretable: Combining Artificial Neural Networks and Classic Cognitive Models to Understand Human Learning and Decision Making. Mk Eckstein, Summerfield, Daw, Miller, 2023Publisher: Cold Spring Harbor Laboratory</p>
<p>Automatic Discovery of Cognitive Strategies with Tiny Recurrent Neural Networks. Ji-An, Benna, Mattar, 2023Publisher: Cold Spring Harbor Laboratory</p>
<p>A comparison of neuroelectrophysiology databases. Subash, Sci. Data. 107192023</p>
<p>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Kj Gorgolewski, Sci. data. 32016Nature Publishing Group</p>
<p>Bayesian Machine Scientist for Model Discovery in Psychology. Hewson, Strittmatter, Marinescu, S Williams, Musslick, 2023</p>
<p>Evolving scientific discovery by unifying data and background knowledge with ai hilbert. C Cory-Wright, Cornelio, Dash, L El Khadir, Horesh, Nat. Commun. 1559222024</p>
<p>Bacterai maps microbial metabolism without prior knowledge. Ac Dama, Nat. Microbiol. 82023</p>
<p>Characterizing the robustness of Bayesian adaptive experimental designs to active learning bias. Sj Sloman, Oppenheimer, Broomell, Shalizi, arXiv:2205.136982022arXiv preprint</p>
<p>Knowing what to know: Implications of the choice of prior distribution on the behavior of adaptive design optimization. Sj Sloman, Cavagnaro, Broomell, Behav. Res. Methods pp. 2024</p>
<p>Reinforcement learning: An introduction. A G Rs Sutton, Barto, 2018MIT press</p>
<p>Machine Learning Methods for Reduced Order Modeling in Model Order Reduction and Applications: Cetraro, Italy 2021. Jn Kutz, 2023Springer</p>
<p>Reduced order modeling of parametrized systems through autoencoders and SINDy approach: continuation of periodic solutions. Conti, Gobat, Fresca, Manzoni, Frangi, Comput. Methods Appl. Mech. Eng. 4111160722023Elsevier</p>
<p>Dimensionality reduction and reduced-order modeling for traveling wave physics. Mendible, Brunton, Ay Aravkin, Lowrie, Kutz, Theor. Comput. Fluid Dyn. 342020Springer</p>
<p>Automated discovery of fundamental variables hidden in experimental data. Chen, Nat. Comput. Sci. 22022Nature Publishing Group</p>
<p>Learnable latent embeddings for joint behavioural and neural analysis. Schneider, Lee, Mathis, Nature pp. 2023Nature Publishing Group UK London</p>
<p>Large language models for scientific synthesis, inference and explanation. Zheng, arXiv:2310.079842023arXiv preprint</p>
<p>Artificial Intelligence Research in Business and Management: A Literature Review Leveraging Machine Learning and Large Language Models. Guler, Kirshner, Vidgen, Available at SSRN. 45408342023</p>
<p>Elicit: AI literature review research assistant. M A Whitfield, Hofmann, Public Serv. Q. 192023Taylor &amp; Francis</p>
<p>Large language models surpass human experts in predicting neuroscience results. Luo, 2024</p>
<p>Chen, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>HotGPT: How to Make Software Documentation More Useful with a Large Language Model. Su, 2023</p>
<p>The weirdest people in the world?. Henrich, Sj Heine, Norenzayan, Behav. brain sciences. 332010Cambridge University Press</p>
<p>Integrating model development across computational neuroscience, cognitive science, and machine learning. P Gleeson, Neuron. 1112023Elsevier</p>
<p>How hard is cognitive science?. Rich, De Haan, I Wareham, Van Rooij, 20214343</p>
<p>A mobile robotic chemist. Burger, Nature. 5832020Nature Publishing Group UK London</p>
<p>Artificial intelligence and illusions of understanding in scientific research. Messeri, Crockett, Nature. 6272024</p>
<p>Reading tea leaves: How humans interpret topic models. Chang, Gerrish, J Wang, D Boyd-Graber, Blei, Adv. neural information processing systems. 222009</p>
<p>Ironies of automation in Analysis, design and evaluation of man-machine systems. Bainbridge, 1983Elsevier</p>
<p>The Use of Generative Artificial Intelligence Technologies is Prohibited for the NIH Peer Review Process (2023) Published: Available from NIH Grants. National Institutes of Health</p>
<p>Reconciling modern machine-learning practice and the classical bias-variance trade-off. Belkin, Hsu, S Ma, Mandal, Proc. Natl. Acad. Sci. Natl. Acad. Sci2019116</p>
<p>The lottery ticket hypothesis: Finding sparse, trainable neural networks. Frankle, Carbin, arXiv:1803.036352018arXiv preprint</p>
<p>Li, Train big, then compress: Rethinking model size for efficient training and inference of transformers in International Conference on machine learning. 2020</p>
<p>Scaling up psychology via scientific regret minimization. Agrawal, Peterson, Griffiths, Proc. Natl. Acad. Sci. Natl. Acad. SciNational Acad Sciences2020117</p>
<p>Manifesto for a new (computational) cognitive revolution. Griffiths, Cognition. 1352015Elsevier</p>
<p>. L Daston, Galison, Objectivity, 2021Princeton University Press</p>
<p>Gender shades: Intersectional accuracy disparities in commercial gender classification. Buolamwini, Gebru, 2018</p>
<p>Algorithmic equity in the hiring of underrepresented IT job candidates. Cobb Yarger, B Payton, Neupane, Online information review. 442020Emerald Publishing Limited</p>
<p>The ethics of AI ethics: An evaluation of guidelines. Minds machines. Hagendorff, 2020Springer30</p>            </div>
        </div>

    </div>
</body>
</html>