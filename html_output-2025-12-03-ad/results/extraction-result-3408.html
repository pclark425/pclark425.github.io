<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3408 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3408</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3408</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-79.html">extraction-schema-79</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <p><strong>Paper ID:</strong> paper-270358007</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.04593v2.pdf" target="_blank">SynAsk: unleashing the power of large language models in organic synthesis</a></p>
                <p><strong>Paper Abstract:</strong> The field of natural language processing (NLP) has witnessed a transformative shift with the emergence of large language models (LLMs), revolutionizing various language tasks and applications, and the integration of LLMs into specialized domains enhances their capabilities for domain-specific applications. Notably, NLP has made significant strides in organic chemistry, particularly in predicting synthetic tasks, paving the way for the development of LLMs tailored to the organic chemistry field. In this work, we introduce SynAsk, a comprehensive organic chemistry domain-specific LLM platform developed by AIChemEco Inc. By fine-tuning an LLM with domain-specific data and integrating it with a chain of thought approach, SynAsk seamlessly accesses our knowledge base and advanced chemistry tools in a question-and-answer format. This includes functionalities such as a basic chemistry knowledge base, molecular information retrieval, reaction performance prediction, retrosynthesis prediction, chemical literature acquisition, and more. This novel methodology synergizes fine-tuning techniques with external resource integration, resulting in an organic chemistry-specific model poised to facilitate research and discovery in the field. Accessible at https://synask.aichemeco.com, SynAsk represents a significant advancement in leveraging NLP for synthetic applications.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3408.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3408.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SynAsk</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SynAsk (AIChemEco) Organic Chemistry LLM Platform</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific large language model platform for organic synthesis that fine-tunes an open-source foundation LLM and integrates chain-of-thought prompting with LangChain-connected chemoinformatics tools to perform retrosynthesis, yield prediction, condition recommendation, and derivative exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SynAsk (fine-tuned on Qwen-1.5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Built on an open-source foundation LLM (Qwen-1.5, ~14B parameters) and fine-tuned in two stages (supervised then instruction-based) using LoRA and optionally quantization; integrates chain-of-thought prompting and LangChain to invoke 22+ internal/external chemistry tools (e.g., Retrosynthesis, YieldPredict, DerivatePredict). Fine-tuning datasets ranged from small (≈200 entries for quantized fine-tune) to >4,000 examples (non-quantized fine-tune) as reported.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM-driven prompt parsing and chain-of-thought reasoning that emits structured tool-invocation actions; chemical-design outputs are produced by (a) calling an internal Retrosynthesis tool which uses reaction templates + RL agent to generate stepwise routes to buyable precursors, (b) DerivatePredict to propose derivatives, and (c) YieldPredict/ReactionPlanner to propose products, reagents, and expected yields — i.e., hybrid LLM + specialized tool generation rather than pure SMILES-only generation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Organic synthesis planning and drug-molecule retrosynthesis (computer-assisted synthetic planning), reaction performance (yield) prediction, reagent/condition recommendation, derivative exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Retrosynthesis coverage (fraction of queried molecules with a suggested route), comparison to baseline retrosynthesis tool coverage, reaction-yield prediction MAE on HTE test set and external literature set, standard LLM benchmarks (MMLU, CMMLU, C-Eval, GSM8K) for general ability; qualitative case studies versus other LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Retrosynthesis: for 11,549 ChEMBL small-molecule drugs SynAsk produced stepwise routes for 6,358 molecules (55% coverage) versus AIZynthFinder's 3,118 (27%); yielded human-comparable route for Gilmelisib in a 7-step plan. Reaction-yield prediction: in-house SNAr model embedded in SynAsk achieved MAE ≈11.5% on held-out HTE test data and MAE ≈14.1% on 60 randomly collected literature SNAr reactions (2022–2024). General benchmarks: SynAsk shows improved chemistry-focused scores (e.g., College Chemistry C-Eval score 70.83%) compared to foundation models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Outperformed the open-source retrosynthesis baseline (AIZynthFinder) in coverage on the ChEMBL set; outperformed its own foundation Qwen baselines on chemistry benchmarks after fine-tuning; in qualitative comparisons SynAsk provided more comprehensive reaction pathway options than ChemCrow and avoided some molecule misidentification errors seen in ChatGPT-4 in the given examples.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Reported limitations include decreased yield-prediction accuracy when moving from controlled HTE datasets to diverse literature reactions (attributed to more complex/unseen substrates and broader chemical space), a lack of experimental validation for many generated retrosynthetic routes in the ESI, dependence on the reliability of external tools, limited fine-tuning dataset size for some experiments, precision loss risks when using quantization, and constraints from using only open-source foundation models (GPT-4 not used because not open-sourced/paid).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SynAsk: unleashing the power of large language models in organic synthesis', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3408.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3408.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen-1.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen-1.5 foundation LLM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source foundation large language model (Qwen series) selected as the base model for SynAsk because of strong multi-task benchmark performance among open-source models at the ~14B parameter scale.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen-1.5 (~14B parameters)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source transformer-based foundation LLM in the Qwen family; used in this work at the ≥14B parameter scale and fine-tuned via LoRA and quantization approaches to produce SynAsk. Benchmarked on MMLU, CMMLU, C-Eval, GSM8K and other suites as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Serves as the base autoregressive LLM that is fine-tuned and then used to produce structured tool calls and textual chemical reasoning (CoT); chemical-design outputs arise via its integration with chemistry tools rather than directly from base model token sampling alone.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Foundation model for chemistry-specialized LLM (SynAsk) used in organic synthesis assistance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Evaluated via OpenCompass on MMLU, CMMLU, C-Eval, GSM8K, BBH; used as baseline for chemistry-specific C-Eval scores (e.g., Qwen-14B-Chat scored ≈50% on College Chemistry in the paper's comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>As a foundation model, Qwen-1.5 enabled SynAsk to achieve substantially improved chemistry performance after domain-specific fine-tuning; Qwen models were selected over other open-source models based on comparative benchmark performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Reported to outperform other open-source models of similar size (e.g., LLaMA2, ChatGLM2, InterLM, Baichuan2, Yi) on the authors' assessment of the selected benchmarks; GPT-4 remains higher-scoring but was not used due to access/open-source constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Noted limitations include lower absolute performance versus proprietary GPT-4, potential precision loss/tradeoffs when using quantization to permit fine-tuning on limited GPU memory, and the requirement (per authors' experiments) to use models ≥14B parameters for adequate tool-selection and CoT behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SynAsk: unleashing the power of large language models in organic synthesis', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3408.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3408.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously proposed chemistry-focused LLM framework that augments general LLMs with external chemistry tools and chain-of-thought prompting to assist chemistry tasks; cited and used as a comparator in qualitative examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemCrow (tool-augmented LLM system)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An approach that augments general LLMs via chain-of-thought strategies and tool integration (LangChain-style) to solve chemistry tasks by coordinating LLM reasoning with external tools; specifics of the underlying base LLM and fine-tuning were not detailed in this paper's text.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Tool-augmented LLM with chain-of-thought prompting and external tool calls to provide task solutions (e.g., reaction suggestions). In the paper's comparative example, ChemCrow returned a single predicted reaction (N-acylation) for a given SMILES-pair query.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Synthetic chemistry assistance: reaction identification and product suggestion.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative case-comparison in the manuscript (number/detail of proposed reaction pathways) rather than quantitative benchmarks presented here.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>In the presented professional synthetic question, ChemCrow produced a single plausible reaction (N-acylation) and corresponding product, in contrast to SynAsk which provided multiple plausible transformations; this highlighted ChemCrow's more concise but less comprehensive output in that instance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Compared qualitatively against SynAsk and ChatGPT-4 in a single-case example; SynAsk provided broader suggestions while ChemCrow provided a succinct single answer.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Authors note general limitations of such tool-augmented LLM methods: reliance on tool reliability, potential failure to choose/link to correct tools, and limited coverage of alternative plausible transformations in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SynAsk: unleashing the power of large language models in organic synthesis', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3408.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3408.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemLLM: A Chemical Large Language Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific LLM approach that transforms structured chemical data into formats suitable for fine-tuning foundation models (e.g., LLaMA) to perform cheminformatics programming and chemical tasks; cited as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChemLLM: A Chemical Large Language Model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemLLM (LLaMA-based fine-tuned chemical LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An approach described by others that converts structured chemical datasets into text-like forms to fine-tune LLaMA-family models for chemistry tasks; reported to excel in cheminformatics programming tasks but (per authors) may not reach the robustness of larger/commercial models like GPT-4 for broader tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Fine-tuning a foundation LLM (LLaMA) on transformed structured chemical data to perform chemical reasoning/programming tasks; not described here as performing direct novel molecule generation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Cheminformatics programming and chemistry-related question-answering/automation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not detailed in this paper beyond qualitative comparison; authors reported ChemLLM performs well at cheminformatic programming.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited as an approach that demonstrated strengths in cheminformatics programming, but possibly less robust than ChatGPT-4 in some broader benchmarks per the manuscript discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Compared qualitatively to GPT-4/ChatGPT-4 where ChemLLM may be weaker on general tasks; included as prior art for domain-specific chemical LLM development.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Authors note potential bias and reduced robustness possibly due to human biases in assembling incomplete structural chemical data used for fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SynAsk: unleashing the power of large language models in organic synthesis', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Augmenting large language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>ChemLLM: A Chemical Large Language Model <em>(Rating: 2)</em></li>
                <li>What can Large Language Models do in chemistry? <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
                <li>Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction <em>(Rating: 1)</em></li>
                <li>Aizynthfinder: a fast, robust and flexible open-source software for retrosynthetic planning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3408",
    "paper_id": "paper-270358007",
    "extraction_schema_id": "extraction-schema-79",
    "extracted_data": [
        {
            "name_short": "SynAsk",
            "name_full": "SynAsk (AIChemEco) Organic Chemistry LLM Platform",
            "brief_description": "A domain-specific large language model platform for organic synthesis that fine-tunes an open-source foundation LLM and integrates chain-of-thought prompting with LangChain-connected chemoinformatics tools to perform retrosynthesis, yield prediction, condition recommendation, and derivative exploration.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "SynAsk (fine-tuned on Qwen-1.5)",
            "model_description": "Built on an open-source foundation LLM (Qwen-1.5, ~14B parameters) and fine-tuned in two stages (supervised then instruction-based) using LoRA and optionally quantization; integrates chain-of-thought prompting and LangChain to invoke 22+ internal/external chemistry tools (e.g., Retrosynthesis, YieldPredict, DerivatePredict). Fine-tuning datasets ranged from small (≈200 entries for quantized fine-tune) to &gt;4,000 examples (non-quantized fine-tune) as reported.",
            "generation_method": "LLM-driven prompt parsing and chain-of-thought reasoning that emits structured tool-invocation actions; chemical-design outputs are produced by (a) calling an internal Retrosynthesis tool which uses reaction templates + RL agent to generate stepwise routes to buyable precursors, (b) DerivatePredict to propose derivatives, and (c) YieldPredict/ReactionPlanner to propose products, reagents, and expected yields — i.e., hybrid LLM + specialized tool generation rather than pure SMILES-only generation.",
            "application_domain": "Organic synthesis planning and drug-molecule retrosynthesis (computer-assisted synthetic planning), reaction performance (yield) prediction, reagent/condition recommendation, derivative exploration.",
            "evaluation_metrics": "Retrosynthesis coverage (fraction of queried molecules with a suggested route), comparison to baseline retrosynthesis tool coverage, reaction-yield prediction MAE on HTE test set and external literature set, standard LLM benchmarks (MMLU, CMMLU, C-Eval, GSM8K) for general ability; qualitative case studies versus other LLMs.",
            "results_summary": "Retrosynthesis: for 11,549 ChEMBL small-molecule drugs SynAsk produced stepwise routes for 6,358 molecules (55% coverage) versus AIZynthFinder's 3,118 (27%); yielded human-comparable route for Gilmelisib in a 7-step plan. Reaction-yield prediction: in-house SNAr model embedded in SynAsk achieved MAE ≈11.5% on held-out HTE test data and MAE ≈14.1% on 60 randomly collected literature SNAr reactions (2022–2024). General benchmarks: SynAsk shows improved chemistry-focused scores (e.g., College Chemistry C-Eval score 70.83%) compared to foundation models.",
            "comparison_to_baselines": "Outperformed the open-source retrosynthesis baseline (AIZynthFinder) in coverage on the ChEMBL set; outperformed its own foundation Qwen baselines on chemistry benchmarks after fine-tuning; in qualitative comparisons SynAsk provided more comprehensive reaction pathway options than ChemCrow and avoided some molecule misidentification errors seen in ChatGPT-4 in the given examples.",
            "limitations_challenges": "Reported limitations include decreased yield-prediction accuracy when moving from controlled HTE datasets to diverse literature reactions (attributed to more complex/unseen substrates and broader chemical space), a lack of experimental validation for many generated retrosynthetic routes in the ESI, dependence on the reliability of external tools, limited fine-tuning dataset size for some experiments, precision loss risks when using quantization, and constraints from using only open-source foundation models (GPT-4 not used because not open-sourced/paid).",
            "uuid": "e3408.0",
            "source_info": {
                "paper_title": "SynAsk: unleashing the power of large language models in organic synthesis",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Qwen-1.5",
            "name_full": "Qwen-1.5 foundation LLM",
            "brief_description": "An open-source foundation large language model (Qwen series) selected as the base model for SynAsk because of strong multi-task benchmark performance among open-source models at the ~14B parameter scale.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen-1.5 (~14B parameters)",
            "model_description": "Open-source transformer-based foundation LLM in the Qwen family; used in this work at the ≥14B parameter scale and fine-tuned via LoRA and quantization approaches to produce SynAsk. Benchmarked on MMLU, CMMLU, C-Eval, GSM8K and other suites as a baseline.",
            "generation_method": "Serves as the base autoregressive LLM that is fine-tuned and then used to produce structured tool calls and textual chemical reasoning (CoT); chemical-design outputs arise via its integration with chemistry tools rather than directly from base model token sampling alone.",
            "application_domain": "Foundation model for chemistry-specialized LLM (SynAsk) used in organic synthesis assistance.",
            "evaluation_metrics": "Evaluated via OpenCompass on MMLU, CMMLU, C-Eval, GSM8K, BBH; used as baseline for chemistry-specific C-Eval scores (e.g., Qwen-14B-Chat scored ≈50% on College Chemistry in the paper's comparisons).",
            "results_summary": "As a foundation model, Qwen-1.5 enabled SynAsk to achieve substantially improved chemistry performance after domain-specific fine-tuning; Qwen models were selected over other open-source models based on comparative benchmark performance.",
            "comparison_to_baselines": "Reported to outperform other open-source models of similar size (e.g., LLaMA2, ChatGLM2, InterLM, Baichuan2, Yi) on the authors' assessment of the selected benchmarks; GPT-4 remains higher-scoring but was not used due to access/open-source constraints.",
            "limitations_challenges": "Noted limitations include lower absolute performance versus proprietary GPT-4, potential precision loss/tradeoffs when using quantization to permit fine-tuning on limited GPU memory, and the requirement (per authors' experiments) to use models ≥14B parameters for adequate tool-selection and CoT behavior.",
            "uuid": "e3408.1",
            "source_info": {
                "paper_title": "SynAsk: unleashing the power of large language models in organic synthesis",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow",
            "brief_description": "A previously proposed chemistry-focused LLM framework that augments general LLMs with external chemistry tools and chain-of-thought prompting to assist chemistry tasks; cited and used as a comparator in qualitative examples.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "ChemCrow (tool-augmented LLM system)",
            "model_description": "An approach that augments general LLMs via chain-of-thought strategies and tool integration (LangChain-style) to solve chemistry tasks by coordinating LLM reasoning with external tools; specifics of the underlying base LLM and fine-tuning were not detailed in this paper's text.",
            "generation_method": "Tool-augmented LLM with chain-of-thought prompting and external tool calls to provide task solutions (e.g., reaction suggestions). In the paper's comparative example, ChemCrow returned a single predicted reaction (N-acylation) for a given SMILES-pair query.",
            "application_domain": "Synthetic chemistry assistance: reaction identification and product suggestion.",
            "evaluation_metrics": "Qualitative case-comparison in the manuscript (number/detail of proposed reaction pathways) rather than quantitative benchmarks presented here.",
            "results_summary": "In the presented professional synthetic question, ChemCrow produced a single plausible reaction (N-acylation) and corresponding product, in contrast to SynAsk which provided multiple plausible transformations; this highlighted ChemCrow's more concise but less comprehensive output in that instance.",
            "comparison_to_baselines": "Compared qualitatively against SynAsk and ChatGPT-4 in a single-case example; SynAsk provided broader suggestions while ChemCrow provided a succinct single answer.",
            "limitations_challenges": "Authors note general limitations of such tool-augmented LLM methods: reliance on tool reliability, potential failure to choose/link to correct tools, and limited coverage of alternative plausible transformations in some cases.",
            "uuid": "e3408.2",
            "source_info": {
                "paper_title": "SynAsk: unleashing the power of large language models in organic synthesis",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "ChemLLM",
            "name_full": "ChemLLM: A Chemical Large Language Model",
            "brief_description": "A domain-specific LLM approach that transforms structured chemical data into formats suitable for fine-tuning foundation models (e.g., LLaMA) to perform cheminformatics programming and chemical tasks; cited as related work.",
            "citation_title": "ChemLLM: A Chemical Large Language Model",
            "mention_or_use": "mention",
            "model_name": "ChemLLM (LLaMA-based fine-tuned chemical LLM)",
            "model_description": "An approach described by others that converts structured chemical datasets into text-like forms to fine-tune LLaMA-family models for chemistry tasks; reported to excel in cheminformatics programming tasks but (per authors) may not reach the robustness of larger/commercial models like GPT-4 for broader tasks.",
            "generation_method": "Fine-tuning a foundation LLM (LLaMA) on transformed structured chemical data to perform chemical reasoning/programming tasks; not described here as performing direct novel molecule generation.",
            "application_domain": "Cheminformatics programming and chemistry-related question-answering/automation.",
            "evaluation_metrics": "Not detailed in this paper beyond qualitative comparison; authors reported ChemLLM performs well at cheminformatic programming.",
            "results_summary": "Cited as an approach that demonstrated strengths in cheminformatics programming, but possibly less robust than ChatGPT-4 in some broader benchmarks per the manuscript discussion.",
            "comparison_to_baselines": "Compared qualitatively to GPT-4/ChatGPT-4 where ChemLLM may be weaker on general tasks; included as prior art for domain-specific chemical LLM development.",
            "limitations_challenges": "Authors note potential bias and reduced robustness possibly due to human biases in assembling incomplete structural chemical data used for fine-tuning.",
            "uuid": "e3408.3",
            "source_info": {
                "paper_title": "SynAsk: unleashing the power of large language models in organic synthesis",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Augmenting large language models with chemistry tools",
            "rating": 2,
            "sanitized_title": "augmenting_large_language_models_with_chemistry_tools"
        },
        {
            "paper_title": "ChemLLM: A Chemical Large Language Model",
            "rating": 2,
            "sanitized_title": "chemllm_a_chemical_large_language_model"
        },
        {
            "paper_title": "What can Large Language Models do in chemistry?",
            "rating": 2,
            "sanitized_title": "what_can_large_language_models_do_in_chemistry"
        },
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction",
            "rating": 1,
            "sanitized_title": "molecular_transformer_a_model_for_uncertaintycalibrated_chemical_reaction_prediction"
        },
        {
            "paper_title": "Aizynthfinder: a fast, robust and flexible open-source software for retrosynthetic planning",
            "rating": 1,
            "sanitized_title": "aizynthfinder_a_fast_robust_and_flexible_opensource_software_for_retrosynthetic_planning"
        }
    ],
    "cost": 0.0148835,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>SynAsk: Unleashing the Power of Large Language Models in Organic Synthesis
14 Jun 2024</p>
<p>Chonghuan Zhang 
Guangzhou National Laboratory
510005Guangzhou, GuangdongPR China</p>
<p>Qianghua Lin 
Guangzhou National Laboratory
510005Guangzhou, GuangdongPR China</p>
<p>Biwei Zhu 
AIChemEco Inc
510005Guangzhou, GuangdongPR China</p>
<p>Haopeng Yang 
AIChemEco Inc
510005Guangzhou, GuangdongPR China</p>
<p>Xiao Lian 
AIChemEco Inc
510005Guangzhou, GuangdongPR China</p>
<p>Hao Deng 
AIChemEco Inc
510005Guangzhou, GuangdongPR China</p>
<p>Jiajun Zheng 
AIChemEco Inc
510005Guangzhou, GuangdongPR China</p>
<p>Kuangbiao Liao liao_kuangbiao@gzlab.ac.cn 
Guangzhou National Laboratory
510005Guangzhou, GuangdongPR China</p>
<p>SynAsk: Unleashing the Power of Large Language Models in Organic Synthesis
14 Jun 20245FA69C9DCBD2145530219843E2E18253arXiv:2406.04593v2[physics.chem-ph]Large Language ModelAI in Chemistryorganic synthesisretrosynthesis
The field of natural language processing (NLP) has witnessed a transformative shift with the emergence of large language models (LLMs), revolutionizing various language tasks and applications, and the integration of LLM into specialized domains enhances their capabilities for domain-specific applications.Notably, NLP has made significant strides in organic chemistry, particularly in predicting synthetic tasks, paving the way for the development of LLMs tailored to the organic chemistry field.In this work, we introduce SynAsk, a comprehensive organic chemistry domain-specific LLM platform developed by AIChemEco Inc.By finetuning an LLM with domain-specific data and integrating it with a chain of thought approach, SynAsk seamlessly accesses our knowledge base and advanced chemistry tools in a question-and-answer format.This includes functionalities such as a basic chemistry knowledge base, molecular information retrieval, reaction performance prediction, retrosynthesis prediction, chemical literature acquisition, and more.This novel methodology synergizes fine-tuning techniques with external resource integration, resulting in an organic chemistryspecific model poised to facilitate research and discovery in the field.Accessible via https://synask.aichemeco.com,SynAsk represents a significant advancement in leveraging NLP for synthetic applications.</p>
<p>Introduction</p>
<p>In recent years, the field of natural language processing (NLP) has undergone a revolutionary shift with the emergence of large language models (LLMs), advanced artificial intelligence systems trained on massive datasets to understand and generate humanlike text across various language tasks and applications.At the core of LLMs lies the remarkable technology of generative pre-trained transformers (GPT) [1].Developed by OpenAI, GPT models like ChatGPT [2] have gained widespread attention and adoption for their capacity to produce coherent and contextually relevant text.Chat-GPT, in particular, represents a milestone in conversational AI, enabling human-like interactions that go beyond scripted responses.Evolving from ChatGPT to GPT-4 [3] through continual learning from vast datasets allows these models to grasp nuances of language and context, making them versatile tools for diverse tasks, from assisting in creative writing to generating videos.While GPT models have dominated the landscape, other models like Qwen [4] and LLaMA [5] also make significant contributions to the field, and these models are open-sourced for the community to utilize.Qwen, primarily trained from Mandarin Chinese language sources, is renowned for its robustness in question-answering tasks, leveraging a different architecture and training approach.On the other hand, LLaMA specializes in language understanding and inference tasks, offering unique capabilities in semantic analysis and knowledge extraction.</p>
<p>Beyond ChatGPT and other models, LLMs encompass a spectrum of applications across vertical domains.Domain-specific and customized data have been collected and labeled to fine-tune these LLMs.One of the key benefits of vertically specialized LLMs is their capacity to bolster domain-specific applications.By refining their expertise within a particular domain, these models possess the capability to delve deeply into the nuances of the subject matter, rendering them invaluable tools for professionals operating in specialized domains.For instance, a legally specialized LLM, namely DISC-LawLLM [6], can provide precise legal counsel, draft contracts, and facilitate intricate legal research, thereby streamlining processes and conserving resources for legal practitioners.Similarly, a medically specialized LLM, namely MultiMedQA [7], can assist physicians in diagnosing rare conditions, proposing tailored treatment plan, and staying updated on the latest technologies in medical research.</p>
<p>The integration of NLP into organic chemistry has brought about a revolution in research and discovery.Molecules and reactions can now be represented using SMILES (Simplified Molecular Input Line Entry System), a textual notation for depicting highdimensional chemical structures [8].NLP techniques have been employed to tackle organic synthesis tasks using SMILES strings, treating the synthesis problem as a sequence generation task.This approach involves training machine learning models to predict the sequence of molecules and reactions necessary to synthesize a target molecule based on desired products.These models learn from extensive datasets of annotated reactions, where each reaction is represented as a sequence of SMILES strings.Leveraging the patterns and rules encoded in the data, these models can generate plausible synthesis pathways [9,10].</p>
<p>LLMs have found applications in organic chemistry as well.However, without further tuning with organic chemistry domain-specific data, researchers have evaluated five LLMs in tasks related to organic chemistry, including reaction prediction and retrosynthesis.While these models provide reasonable results in classification or ranking tasks like yield prediction and reagent selection, they face challenges in generative tasks that require a deep understanding of molecular structures [11].This difficulty may stem from the highly experimental nature of organic chemistry, the lack of labeled data, and the limited scope and applicability of computational tools in this field [12].To bridge this gap and motivate further exploration of LLM potential in chemistry, several domain-specific LLMs for organic chemistry have been developed.ChemCrow [12] was the first proposed LLM in chemistry aimed at enhancing its capabilities through external tools.It employs chain-of-thought (CoT) strategies [13], which are a series of intermediate reasoning steps to improve LLMs' ability to understand tasks from prompts.ChemCrow also utilizes LangChain [14], a framework to connect the LLM with multiple external tools downstream to solve specific tasks and return answers back to the LLM.However, this method relies on the reliability of tools, and general LLMs may not comprehensively understand prompts and link to the correct tools to solve specific tasks.Another approach, ChemLLM [15], was proposed to transform structured chemical data into forms suitable for LLMs to fine-tune the LLaMA model.ChemLLM excels in tasks such as cheminformatic programming.However, its performance may not be as robust as comprehensive models like ChatGPT-4, possibly due to human biases in the collection of incomplete structural chemical data.We has long been dedicated to AI in chemistry research, developing a series of machine learning and computational based tools to solve fundamental organic chemistry tasks.However, we recognize that directly connecting these tools to large language models (LLMs) may not yield appropriate results.Here we introduce a comprehensive domain-specific LLM for organic chemistry developed by AIChemEco, named SynAsk, as shown in Figure 1.An LLM was refined using a limited set of domain-specific chemistry data and integrate it with a chain-of-thought approach to understand user prompts.Our aim is to utilize Langchain to seamlessly connect SynAsk with our existing suite of tools, addressing specific user inquiries, drawing on the framework of Langchain−chatchat [16].This methodology allows us to combine fine-tuning techniques with the integration of external resources, resulting in the development of an organic chemistry-specific model.The model can be accessed at https://synask.aichemeco.com.</p>
<p>Methods</p>
<p>To construct the comprehensive model integration platform, our approach unfolds along three primary dimensions: utilizing a powerful foundation LLM as the base for SynAsk, crafting more effective prompts and implementing fine-tuning to the foundation model, and connecting with multiple tools to assemble a chemistry domain-specific model platform.</p>
<p>Selection of a foundation LLM</p>
<p>Through various experiments, we have recognized that for the foundation LLM to effectively understand prompts from end-users and apply insights to decide whether to provide LLM inference answers or use specific tools to resolve downstream tasks, it needs to have at least 14 billion parameters.Therefore, only foundation models with over 14 billion parameters were considered.The capabilities of the LLM was assessed using indicators such as Massive Multi-task Language Understanding (MMLU) [17], Multi-level multi-discipline chinese evaluation (C-Eval) [18], GSM8K [19], (BIG-Bench-Hard) BBH [20] and Measuring massive multitask language understanding in Chinese (CMMLU) [21], as elaborated in Section S1 of Electronic Supplementary Information (ESI).These indicators collectively offer a comprehensive assessment of a model's proficiency, covering areas such as linguistic understanding, mathematical reasoning, contextual comprehension, multi-modal integration, and the application of Chain-of-Thought (CoT), which evaluates the fluency of LLMs' integration with external tools.This evaluation framework underscores the essential and diverse skills a model must possess to adeptly address complex real-world problems.</p>
<p>As indicated in Table S1 [4], the Qwen series [4] outperforms other models with equivalent parameter counts, including LLaMA2 [22], ChatGLM2 [23], InterLM [24], Baichuan2 [25] and Yi [26] in these areas.Additionally, our testing has confirmed that the Qwen series is more compatible with our framework, especially with the release of Qwen-1.5, which provides us with more options.We acknowledge that GPT series [2], particularly GPT-4 [3], scores higher than Qwen.However, at the time of this work, GPT-4 has not been open-sourced and requires paid API tokens to use as a foundation model.To ensure SynAsk remains publicly accessible, we opted to use only open-sourced foundation LLMs and developed an architecture that allows for smooth switching of the foundation LLM, as discussed in Section 2.4.</p>
<p>Refinement to more Reasonable Prompt</p>
<p>To improve the model's performance in two key areas-providing more targeted responses in the chemical domain and enhancing its ability to efficiently utilize tools-we refined our prompt templates through iterative testing and adjustments.We guide the model to generate responses that are not only accurate but also consistent with specific demand expectations.This process encourages the model to become more deeply involved in the task at hand, reducing ambiguity and focusing its attention.These optimized guidance models function as both competent chemists and skilled tool users, establishing a more focused, efficient, and effective interaction between the model and the user.</p>
<p>In our integrated platform, utilizing the classification function of LLMs is particularly crucial, as illustrated in Figure 2. Since this platform extends from our existing NLP project, we believe it inherently possesses enhanced capabilities.To further train it, we employ a tailored hint project, where the model's role is set as a chemist evaluating and scoring the generated results.This project provides several examples to guide the model.This setup enables the model to discern whether responses augmented by the knowledge database meet the criteria, thereby classifying the results into those that meet expectations and those that do not.</p>
<p>Fine-tuning of the LLM</p>
<p>The selected model underwent fine-tuning to specialize it further in the field of chemistry, ensuring its engagement in professional chemical dialogues, particularly in organic synthesis.The fine-tuning process comprised two iterations, with data processed accordingly for each iteration.</p>
<p>• The first iteration was supervised fine-tuning: This stage focused on enhancing the model's cognitive abilities, reinforcing its identity as an expert in chemistry.</p>
<p>The objective was to delve deeper into the model's capabilities within the chemistry domain without expanding its original data source.This approach allowed the model to utilize existing data more effectively to solve chemical problems.• The second iteration was instruction-based fine-tuning: The aim here was to improve the model's reasoning and tool invocation capabilities, thereby enhancing its chain of thought.It learned to differentiate between various types of chemical identifiers, such as SMILES and CAS numbers, rather than treating them as ordinary words or sequences of numbers.The rationale for dividing the fine-tuning into two stages is threefold:</p>
<p>Prompt:</p>
<p>What is the SMILES of toluene?Response:</p>
<p>Action: get_SMILES Action Input: {"query": "toluene"} Prompt:</p>
<p>What is the name of CC1=CC=CC=C1?Response:</p>
<p>Action: CAStoName Action Input: {"query": "CC1=CC=CC=C1"} Notably, the power of these fine-tuned results is significantly enhanced when used in conjunction with appropriately designed prompting strategies and specially designed tool formats.These responses demonstrate the model's ability to identify the required action and its corresponding input from the prompts.However, within our framework, these responses are not the final outcome.Instead, they serve as intermediate prompts to be re-fed into the model.This intermediary step is pivotal, enabling the model to discern the specific tool it requires (e.g., 'get_SMILES' for the initial example) and to process the "Action Input" (e.g., "query: 'toluene'") utilizing the designated tool.Subsequently, the expansive model amalgamates the tool's output with its vast knowledge base, culminating in the generation of a final answer.</p>
<p>SynAsk Architecture</p>
<p>In the final phase, we implemented the LangChain framework to seamlessly integrate our local knowledge base with both internal and external open-source tools and APIs.Its primary role is to interpret the outputs from the language models, converting them into a format understandable by external tools, thus facilitating the execution of corresponding actions.Simultaneously, it translates the responses from these tools back into a form comprehensible by the language models.Furthermore, LangChain's support for context management enables it to track the interaction history between users and the system.This enhances the system's ability to understand user intentions and maintain session continuity during interactions with external tools.Its scalability ensures that the system can adapt to technological advancements and changing user demands, providing a dynamic and responsive framework for our integration needs.The LangChain framework serves as a pivotal bridge, culminating in a logically coherent and systematically robust integration platform known as SynAsk.</p>
<p>The structural framework of SynAsk is illustrated in Figure 2. Initially, it can accept both voice and text inputs as queries, which are then segmented into multiple tasks by a LLM and matched against our knowledge base.At this stage, users also have the option to upload their local files as supplementary knowledge or directly engage in conversations with the uploaded files.Once matching texts are obtained, the large model synthesizes the content along with its understanding of the question to deduce a conclusion, thereby generating a result.Subsequently, the model evaluates this result to determine if it meets the expected criteria.If the outcome is deemed satisfactory, it is directly outputted as the Final Answer.Conversely, if the results do not meet expectations, we will enter our customized Agent Q&amp;A mode and call our tools to answer.Finally, the tool output is combined with the LLM's self-knowledge to generate the final answer.In the SynAsk architecture, although we currently utilize Qwen-1.5 as the foundation LLM, we recognize the ongoing revolutions in LLM technology.Consequently, we have developed a workflow to swiftly adjust the foundation model and fine-tune the domain-specific data.This approach ensures that SynAsk can continuously update and iterate, leveraging the latest advancements in foundation LLMs.</p>
<p>SynAsk Toolsets</p>
<p>Chemoinformatic tools are seamlessly connected with SynAsk through LangChain to provide comprehensive organic synthesis answers.This includes a variety of machine learning-powered tools developed both internally and by external teams, all dedicated to solving organic synthesis tasks.At the time of publishing this work, 12 internal tools and 10 external tools have been integrated into SynAsk.External tools are appropriately cited with their origins.With the rapid development of this field, we anticipate an increasing influx of tools joining SynAsk.These tools are categorized into molecular, reaction tools, and others, with a number of advanced in-house tools elaborated in Section 2.5.5.</p>
<p>Molecular Information Retrieval</p>
<p>This category encompasses tools designed for querying various molecular identifiers and properties.Functions include retrieving Chemical Abstracts Service (CAS) numbers, Simplified Molecular Input Line Entry System (SMILES) strings, molecular weights, assessing molecular similarity, identifying types of functional groups, and checking the regulatory status of molecules.The respective tools for these purposes are:</p>
<p>• get_cas -for CAS numbers retrieval [27] • get_smiles -for obtaining SMILES strings [27] • CAStoName -to convert CAS numbers to chemical names [28] • SMILEStoName -to convert SMILES strings to chemical names [28] • get_mol_weight -for calculating molecular weights • get_mol_similarity -to determine molecular similarity • check_functional_groups -for functional group identification • ControlmolCheck -to check if a molecule is controlled</p>
<p>Chemical Reaction and Retrosynthesis</p>
<p>This category aids in querying chemical reaction conditions, planning chemical reaction pathways, predicting chemical reaction yields, performing retrosynthetic analysis, and predicting reaction derivatives.Tools provided for these functions include:</p>
<p>• Get_condition -to query chemical reaction conditions • ReactionPlanner -for planning chemical reaction pathways [29] • ReagentsPredict -to predict reagents in chemical reactions • YieldPredict -for predicting chemical reaction yields • Retrosynthesis -to perform retrosynthetic analysis • DerivatePredict -to predicts the derivatives from a chemical reaction, using reactants' names or SMILES, enhancing the exploration of reaction outcomes.• AutoMapping -to identify the position of each atom in the molecules before and after a chemical reaction [30][31]</p>
<p>Acquisition of Chemical Literature and Knowledge</p>
<p>Dedicated to acquiring chemical literature and extracting chemical knowledge, tools in this section include:</p>
<p>• Get_literature -for retrieving literature [32][33]</p>
<p>• get_knowledge -to obtain chemical knowledge [33] • Rxn_literature -for sourcing reaction-specific literature</p>
<p>Miscellaneous</p>
<p>This section covers a diverse array of functions including drawing chemical molecular structures and balancing chemical equations.Tools include:</p>
<p>• Moldraw -for drawing chemical molecular structures • calculate -a general-purpose calculation tool • automatic_balance -to automatically balance chemical equations [34] • image_gen -for generating and searching images [33]</p>
<p>Advanced In-House Analytical Tools</p>
<p>YieldPredict</p>
<p>This is an API tool linked with our self-developed reaction yield prediction tool.By inputting at least two substrates, either in their molecular name or molecular SMILES, this tool can identify the possible reaction types of the molecules by querying our reaction template library.With the known reaction types, the molecules are passed into the reaction models as substrates.The models then suggest products and the most suitable reaction reagents and conditions for the substrates.For example, by asking the reaction yield of triethoxy(naphthalen-1-yl)silane and 5-bromobenzothiazole, the tool first parses the two molecules into the reaction templates as substrates Figure 3.This suggests Hiyama cross-coupling reactions.The two substrates are then parsed into the Hiyama reaction models, generating products and possible reaction yields under specific reaction reagents and conditions.We have dedicated our efforts to developing data-driven reaction yield prediction models for common reaction types [35][36][37][38].For each model of a specific reaction type, we conduct chemical reaction experiments using high-throughput experimentation (HTE) techniques with various substrates.This enables us to draw insights from existing literature data and identify areas where experimental data collection is necessary to augment an equitable data space for refining model training, thus facilitating more robust interpolation.We develop reaction models using machine learning techniques such as support vector machine (SVM) and NLP deep learning models like BERT (Bidirectional Encoder Representations from Transformers) [39].These models are validated using external literature test data, achieving reasonable Mean Absolute Error (MAE), commonly below 0.15.As of the publication of this work, we have included 18 reaction types in this tool.</p>
<p>Get_Conditions</p>
<p>This tool is a simplified version of YieldPredict.Instead of predicting the reaction product and yield, it provides rapid responses and suggests only the suitable reaction conditions and reagents for the substrates.</p>
<p>Retrosynthesis</p>
<p>By inputting the desired target products, this tool generates numerous reaction pathways of molecules starting from buyable precursors.We have developed our own retrosynthesis model for this purpose.For a desired product, it is parsed into the reaction template library to find possible substrates and, consequently, the suitable reaction site for bond breakage.A reinforcement learning-trained agent selects the most suitable reaction from the candidates based on the forecasted synthesis difficulty and predicted reaction yield of the substrates (desired products at the previous step).This process is conducted recursively until the last substrates are buyable.At the output, we present the results in both textual form and as retrosynthetic route images.The algorithm of our retrosynthesis model will be published elsewhere.</p>
<p>SynAsk Performance</p>
<p>We evaluate the performance of SynAsk from two perspectives: its general ability as a large language model (LLM), and its proficiency in synthetic chemistry.Additionally, we provide several examples of SynAsk's outputs to demonstrate the platform's comprehension capabilities.</p>
<p>General ability of SynAsk</p>
<p>We evaluate the performance enhancements achieved through our first fine-tuning method on the SynAsk model based on OpenCompass [40], which serves as a universal evaluation platform for foundation LLMs.The efficacy of the method is demonstrated by its superior scores across various assessment indicators, particularly in its application to chemistry.The definitions of the general indicators used in Figure 4   Furthermore, the scores in other key benchmarks such as MMLU, GSM8K and CMMLU also reflect the overall enhancement of the SynAsk model.In CMMLU, which assesses cross-model multitask learning, SynAsk scored 75.03%, indicating its proficiency in integrating textual and visual information, crucial for multi-model applications.Similarly, its performance in MMLU and GSM8K benchmarks demonstrate its improved global knowledge comprehension and multi-step mathematical reasoning, respectively.</p>
<p>The advancements in SynAsk are attributed to the fine-tuning approach that leverages existing data sources more efficiently, thus enhancing the model's ability to address nuanced chemical contexts and complex reasoning tasks.This is particularly crucial for applications requiring deep understanding and contextual awareness, as indicated by the improvements in C-Eval scores.</p>
<p>These results collectively underscore the effectiveness of our fine-tuning methodology, confirming its potential to significantly boost performance across diverse linguistic and cognitive challenges, thereby reinforcing the model's utility in academic and practical applications.</p>
<p>Proficiency in synthetic chemistry</p>
<p>The primary proficiency of SynAsk in synthetic chemistry lies in its ability to predict reaction performance, such as yield, and to conduct retrosynthetic planning of target molecules, utilizing the embedded tools within SynAsk.Several case studies are presented and compared with benchmarks to evaluate the model's performance.Additionally, the other functions of SynAsk are compared with ChatGPT-4.0answers to highlight its advancements in various areas.</p>
<p>Reaction yield prediction</p>
<p>A number of reaction yield prediction models have been developed and widely used to forecast the performance of reactions for frequently encountered reaction classes.For instance, Doyle et al.'s palladium-catalysed Buchwald-Hartwig cross-coupling reaction model [41] and Richardson et al.'s Suzuki-Miyaura cross-coupling reaction model [42] are among the notable examples.These models were trained using self-developed high-throughput experimentation (HTE) reaction data employing machine learning algorithms.Schwaller et al. [43] further enhanced the performance of these models using the same datasets through pre-trained BERT model.While these methods effectively predict the product yield within the self-developed HTE reaction dataset, their applicability to predicting the product yield of external literature recorded reactions may be limited.</p>
<p>We tested our in-house nucleophilic aromatic substitution (S N Ar) reaction model embedded in SynAsk with tboth a test set and external literature reaction data.The model test set comprises unseen HTE reaction data, yielding a mean absolute error (MAE) of 11.5%.For the external literature reaction data, to minimize bias, we randomly collected 60 recently published S N Ar reactions from the last three years (2022-2024), including new substrate molecules never seen by the reaction model.The comparison between the model-predicted yield and literature-reported yield is presented in Figure 5b, yielding an MAE of 14.1%.These recent published reactions encompass seven different reaction conditions.For example, N-methyl-1phenylmethanamine reacting with 2-fluoro-5-methoxybenzaldehyde under K 2 CO 3 and DMF is illustrated in Figure 5c.The literature-reported yield of the product 2-(benzyl(methyl)amino)-5-methoxybenzaldehyde is 75% [44], whilst our model predicts 80% and our HTE experimental yield is 70%.Additional results are provided in Section S4 of the ESI.</p>
<p>The decay in prediction accuracy observed when transitioning from HTE reactions to literature-reported reactions is primarily attributed to the increased complexity of substrates in literature reactions.These substrates are often more intricate and unseen by the model, thereby encompassing a wider range within the chemical space, as depicted in Figure 5a.To compute the chemical space, we digitized the reactions using RXNFP pretrained reaction fingerprint [45] and reduced into two dimensions.Figure 5a also weakly show three clusters of the S N Ar reaction.Despite the challenges posed by the complexity of literature-reported reactions, our in-house S N Ar model demonstrates the capability to predict the reaction performance of these reactions.This is particularly valuable as it enables predictions closer to the reactions of interest to synthetic chemists.</p>
<p>Retrosynthetic route planning</p>
<p>We tasked SynAsk with planning retrosynthetic routes for 11,549 small molecule drugs recorded in the ChEMBL database [46].SynAsk successfully predicted retrosynthetic routes for 6,358 molecules, suggesting step-by-step routes starting from buyable precursors.This accounts for 55% of the queried molecules.In contrast, the State of the Art (SOTA) open-sourced retrosynthetic planning tool, AIZynthFinder [47], only suggested 3,118 retrosynthetic routes, covering 27% of the queried molecules.</p>
<p>As a case study, let's consider the retrosynthesis of Gilmelisib, a novel small molecule under investigation as a selective inhibitor of PIK3Cα, potentially treating cancers characterized by PIK3Cα mutations.SynAsk proposes a seven-step synthetic route with four precursors (as shown in Figure 6a), matching the route suggested by an experienced human chemist in terms of length and number of precursors (as shown in Figure 6b).SynAsk utilizes inexpensive precursors to rapidly obtain key heterocyclic fused ring intermediates through straightforward Knoevenagel condensation and addition-elimination reactions.In contrast, AIZynthFinder fails to provide a synthesis route for the target molecule, even after enriching its starting materials with our lists of buyable precursors.Additional synthetic routes for small molecule drugs are detailed in Section S5 of the ESI.</p>
<p>While we refrain from concluding that SynAsk is smarter or approaching the intelligence of a human chemist in retrosynthesis, as this determination would necessitate passing the Turing test [48,49] or experimental validation, we acknowledge that SynAsk's retrosynthetic ability offers valuable insights for synthetic chemists and assists in synthesis planning.</p>
<p>Examples of the SynAsk platform outputs vesus other LLMs</p>
<p>Here we present a comparative analysis of the performance of three LLMs -SynAsk, ChatGPT-4.0,and ChemCrow -in addressing synthetic chemistry queries.We evaluated their capabilities by inputting a set of synthetic questions, encompassing both general and professional inquiries, to assess their aptitude in providing accurate and relevant responses.</p>
<p>General inquiries</p>
<p>Queries such as "Can you recommend me some reaction conditions for Suzuki crosscoupling?" or "Please help me find some literature related to C-H activation" were presented to all three LLMs.Across the board, each model exhibited proficiency in generating appropriate responses, showcasing their utility in aiding chemists with routine inquiries, details in Section S6 of the ESI.</p>
<p>Professional synthetic questions</p>
<p>A more rigorous evaluation was conducted by inputting a specific synthetic question: "Tell me what reaction can occur between Nc1ccc2nccnc2c1.O=C(O)Cc1cc(F)cc(F)c1 and what the product is."Here "Nc1ccc2nccnc2c1.O=C(O)Cc1cc(F)cc(F)c1" represents the SMILES syntax for quinoxalin-6-amine and 3,5-Difluorophenylacetic acid as substrates.The deliberate use of SMILES allows us to assess the LLMs' ability to recognize molecules from SMILES.As shown in Figure 7, SynAsk demonstrates its specialization in organic chemistry by providing a comprehensive list of potential reactions and their corresponding products.Leveraging its domain-specific knowledge, SynAsk offers a diverse array of feasible transformations, including N-acylation, Buchwald-Hartwig amination, Minisci reaction, among others.This exhaustive output underscores SynAsk's capacity to analyze complex molecular interactions and propose multiple viable pathways.</p>
<p>In contrast, ChemCrow delivers a singular response, identifying the reaction as Nacylation and providing the corresponding product.While ChemCrow offers a concise solution, its limitation in providing alternative reaction pathways restricts its utility in scenarios where multiple transformation possibilities exist.</p>
<p>ChatGPT-4, although proficient in understanding the query, encounters a misinterpretation in identifying the compounds involved.While it accurately delineates the structure and classification of the provided molecules, it erroneously labels Nc1ccc2nccnc2c1 as nicotinic acid derivative, instead of recognizing it as quinoxalin-6-amine.This discrepancy underscores the model's susceptibility to misinterpretation of chemical structures, particularly in complex contexts.</p>
<p>SynAsk distinguishes itself as a specialized LLM tailored specifically for organic chemistry tasks.Its domain-specific training and integration of fine-tuning techniques result in a robust model capable of providing detailed insights and accurate predictions for complex synthetic queries.While ChatGPT-4 and ChemCrow offer general language processing capabilities, they lack the nuanced understanding and domain expertise exhibited by SynAsk in the context of organic chemistry applications.Therefore, for researchers seeking nuanced insights and comprehensive analyses in organic synthesis, SynAsk stands as a valuable tool for augmenting chemical exploration and discovery.</p>
<p>Conclusions and Future Works</p>
<p>In this work, we have developed SynAsk, a specialized LLM-powered platform for synthetic chemistry.It represents the first publicly accessible chemistry domain-specific LLM, fine-tuned with selected chemistry data and connected with both in-house and external chemoinformatic tools.Through comparative analyses with foundation LLMs, we have demonstrated SynAsk's proficiency and specialization in synthetic chemistry.Results obtained in reaction yield prediction and retrosynthesis further validate SynAsk's capability in providing valuable chemical insights to synthetic chemists across multiple domains.Looking ahead, our future endeavors aim to enhance the functionality of SynAsk by empowering the language model and fine-tuning it with additional data for more seamless and appropriate responses.Additionally, we envision SynAsk playing a pivotal role in driving autonomous reaction laboratories [50].Traditionally, reaction robots have been constrained by written scripts to define their scopes.Recent research has showcased the potential of LLMs to drive robotic chemists effectively [51].Leveraging SynAsk's capabilities such as retrosynthesis, inference, and programming script writing, we foresee it being instrumental in driving autonomous laboratories, representing the next phase of our fusion of LLM and hardware research.</p>
<p>SynAsk: Unleashing the Power of Large Language Models in Organic Synthesis</p>
<p>Electronic Supplementary Information</p>
<p>Chonghuan Zhang1 † , Qianghua Lin</p>
<p>S1 The indicators used to assess LLMs</p>
<p>We evaluated the LLM's capabilities using various metrics including Massive Multitask Language Understanding (MMLU), Multi-level multi-discipline chinese evaluation (C-Eval), GSM8K, BIG-Bench-Hard (BBH), and Measuring massive multitask language understanding in Chinese (CMMLU).These metrics collectively provide a thorough assessment of a model's proficiency, encompassing linguistic understanding, mathematical reasoning, contextual comprehension, multi-modal integration, and the application of CoT, which examines the fluency of LLMs' integration with external tools.This evaluation framework emphasizes the diverse and essential skills a model needs to effectively tackle complex real-world problems.</p>
<p>S2 Fine-tuning techniques and procedures</p>
<p>In our experiments, we explored two distinct fine-tuning methodologies for LLMs.The first approach involved techniques such as quantization to enable the operation of a 14-billion-parameter model within a 24GB GPU environment.The second approach was direct fine-tuning without additional quantization techniques.</p>
<p>For our experiments, we selected a model with 14 billion parameters.We applied Low-Rank Adaptation (LoRA) by incorporating low-rank matrices into the fully connected layers.The parameter details are presented in Table S1.The fine-tuning with quantization process, conducted on a dataset of 200 entries with a batch size of 2, was completed within an hour.This method is a viable solution for managing large model training on hardware with limited memory without significantly compromising precision.Leveraging a single GeForce RTX 4090 with 24GB of VRAM for fine-tuning a 14-billion-parameter model, we initially applied quantization to reduce the memory usage and accelerate inference, though at the potential cost of precision loss.During loading, the model was quantized to 4-bit precision and subsequently converted to 16-bit for computations.Post-loading, neither the original nor the quantized weights were retained in memory.</p>
<p>The fine-tuning without quantization approach utilized LoRA under the deepspeed's ZeRO-3 optimization.We employed three GeForce RTX 4090 GPUs, each with 24GB of memory, which allowed the fine-tuning of the model on a dataset of over 4,000 entries.The process took approximately seven hours to complete.</p>
<p>Both fine-tuning methodologies proved to be effective, demonstrating the practical applicability of our approaches to large-scale model optimization.</p>
<p>S4 Reaction yield prediction results</p>
<p>We randomly collected 60 recent published S N Ar reactions from the last three years (2022-2024), which includes new substrate molecules and never seen by the reaction model.The model predicted yield versus literature reported yield are compared in the attached spreadsheet file, SI.xlsx, with an MAE of 14.1%.These recent published reactions consist of seven different reaction conditions.</p>
<p>S5 Retrosynthetic pathway of selected target molecules</p>
<p>Figure S1, Figure S2, Figure S3 and Figure S4 shows numbers of retrosynthetic pathways generated by SynAsk, which provide insights for synthetic chemists.The routes indicate the ability of SynAsk in computer assisted synthetic planning (CASP).We are developing strategies towards generation of more reasonable retrosynthetic pathways.This will be published elsewhere, and integrated into SynAsk.Till now, no efforts were made to experimentally validate the synthetic routes provided in the ESI, and more synthetic routes to other target molecules can be generated via command to SynAsk.</p>
<p>S6 Examples of the SynAsk platform outputs versus other LLMs</p>
<p>Fig. S5 The first example of the outputs from the LLMs.</p>
<p>Fig. S6 The second example of the outputs from the LLMs.</p>
<p>Fig. S7 The third example of the outputs from the LLMs.</p>
<p>Fig. 1
1
Fig.1The overview of SynAsk platform.</p>
<p>•</p>
<p>Clear and Controllable Training: Each fine-tuning task addressed a specific sub-problem, ensuring clarity and controllability in the training process and outcomes.This approach facilitates adjustments and improvements based on the results of previous fine-tuning, gradually enhancing the model's performance on specific tasks.• Prevention of Interference: Segregating the tasks prevents confusion and interference between them.Combining all tasks into a single fine-tuning session might lead to instability in training or reduced performance.• Accelerated Training: This approach speeds up the training process.By simplifying each fine-tuning task, the training becomes more efficient, yielding quicker results and feedback.The shorter training times for each task contribute to a faster overall training cycle.After fine-tuning, detailed techniques, procedures, and the necessary equipment are elaborated in Section S2 of the ESI.Post-fine-tuning, our emphasis mainly lies on the model's ability to demonstrate Chain of Thought (CoT) in its output.Following the fine-tuning process, we provide two examples of the model's simplified output format:</p>
<p>Fig. 2
2
Fig.2The workflow of the SynAsk platform: from the input to the final answer.</p>
<p>Fig. 3
3
Fig. 3 An example of the YieldPredict tool workflow for predicting the reaction yield of triethoxy(naphthalen-1-yl)silane and 5-bromobenzothiazole: (a) the user interface of SynAsk, (b) the thinking process of the YieldPredict tool.</p>
<p>are provided in Section S1 of the ESI, while the chemistry-related indicators are outlined in Section S3 along with examples.It's noteworthy that indicators such as College Chemistry, High School Chemistry, and Middle School Chemistry in the figure all stem from C-Eval.. SynAsk significantly outperforms its foundation model predecessors.For example, in the area of College Chemistry, SynAsk achieves a remarkable score of 70.83%, compared to 50% by both Qwen-14B-Chat and Qwen1.5-14B-Chat.This signifies a substantial improvement, highlighting the model's enhanced ability to effectively utilize existing data sources for solving complex chemical problems..</p>
<p>Fig. 4
4
Fig.4 The comparison of general ability between SynAsk and Qwen in seven aspects, including its applications in chemistry.</p>
<p>Fig. 5
5
Fig. 5 The S N Ar reaction model results: (a) the chemical space of S N Ar reactions under the HTE and literature recorded datasets, (b) the predicted yield versus experimental yield of the test dataset from the three different models, and (c) an example of S N Ar reaction: N-methyl-1-phenylmethanamine reacting with 2-fluoro-5-methoxybenzaldehyde.</p>
<p>Fig. 6
6
Fig. 6 The comparison among synthetic routes of the target molecule Gilmelisib: planned by (a) SynAsk's retrosynthetic tool and (b) an experienced synthetic chemist.</p>
<p>Fig. 7
7
Fig. 7 The comparison of SynAsk, ChatGPT-4, and ChemCrow output on a professional synthetic question.</p>
<p>Fig. S1
S1
Fig. S1 The synthetic route of the target molecule mitoquinone planned by SynAsk's retrosynthetic tool.</p>
<p>Fig. S2
S2
Fig. S2 The synthetic route of the target molecule L-778123 planned by SynAsk's retrosynthetic tool.</p>
<p>Fig. S4
S4
Fig. S4 The synthetic route of the target molecule azaloxan planned by SynAsk's retrosynthetic tool.</p>
<p>1 † , Biwei Zhu 2 † , Haopeng Yang 2 , Xiao Lian 2 , Hao Deng 2 , Jiajun Zheng 2 , Kuangbiao Liao 1*</p>
<p>Table S1
S1
Parameter quantity of the 14-billion-parameter model
Total Parameters Trainable Parameters Percentage of Total14,209,134,12041,843,040≈ 0.294%</p>
<p>Table S2
S2
Memory usage before and after quantization
Before Quantization After 4-bit QuantizationDuring loading14 × 10 9 × 4 bytes14 × 10 9 × 0.5 bytesDuring computation14 × 10 9 × 2 bytesMemory Consumption≈ 56 GB≈ 7 GB during loading
Guangzhou National Laboratory, Guangdong, PR China, 510005
AIChemEco Inc., Guangdong, PR China, 510005
AcknowledgementsWe are grateful for financial support from Guangzhou National Laboratory, and the National Natural Science Foundation of China (22071249, 22393892).Conflict of InterestWe have a patent application in China with the application number 202410714040.6titled "A Human-Computer Interaction Method and Electronic Device Based on a Large Language Model".S3 Chemistry related indicators and examplesWe assessed the chemistry ability of the LLMs using the chemistry test questions from C-Eval, which comprises multiple discipline questions in multiple levels in Chinese (Section S1).This test was completed in Chinese since SynAsk's original language is Chinese.However, we acknowledge that with the LLMs' powerful language ability, testing of the LLMs with different major languages in the world would reach close results.We provide a set of example questions for the chemistry question in C-Eval at multiple levels.Sections Section S3.1, Section S3.2, and Section S3.3 refers to the chemistry questions at college, high school and middle school levels, respectively.The dataset format consists of multiple-choice questions and answers.The Prediction contains the answers predicted by three models: SynAsk, Qwen1.5-14B-Chat, and Qwen-14B-Chat.S3.1 C-Eval (College Chemistry)English translation:The following are single-choice questions on university chemistry exams in China.Which of the following statements is correct?
Improving language understanding by generative pre-training. A Radford, K Narasimhan, T Salimans, I Sutskever, 2018</p>
<p>T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, arXiv:2005.14165Language models are few-shot learners. 2020arXiv preprint</p>
<p>. : Openai, J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, R Avila, I Babuschkin, S Balaji, V Balcom, P Baltescu, H Bao, M Bavarian, J Belgum, I Bello, J Berdine, G Bernadett-Shapiro, C Berner, L Bogdonoff, O Boiko, M Boyd, A.-L Brakman, G Brockman, T Brooks, M Brundage, K Button, T Cai, R Campbell, A Cann, B Carey, C Carlson, R Carmichael, B Chan, C Chang, F Chantzis, D Chen, S Chen, R Chen, J Chen, M Chen, B Chess, C Cho, C Chu, H W Chung, D Cummings, J Currier, Y Dai, C Decareaux, T Degry, N Deutsch, D Deville, A Dhar, D Dohan, S Dowling, S Dunning, A Ecoffet, A Eleti, T Eloundou, D Farhi, L Fedus, N Felix, S P Fishman, J Forte, I Fulford, L Gao, E Georges, C Gibson, V Goel, T Gogineni, G Goh, R Gontijo-Lopes, J Gordon, M Grafstein, S Gray, R Greene, J Gross, S S Gu, Y Guo, C Hallacy, J Han, J Harris, Y He, M Heaton, J Heidecke, C Hesse, A Hickey, W Hickey, P Hoeschele, B Houghton, K Hsu, S Hu, X Hu, J Huizinga, S Jain, S Jain, J Jang, A Jiang, R Jiang, H Jin, D Jin, S Jomoto, B Jonn, H Jun, T Kaftan, Kaiser, A Kamali, I Kanitscheider, N S Keskar, T Khan, L Kilpatrick, J W Kim, C Kim, Y Kim, H Kirchner, J Kiros, M Knight, D Kokotajlo, Kondraciuk, A Kondrich, A Konstantinidis, K Kosic, G Krueger, V Kuo, M Lampe, I Lan, T Lee, J Leike, J Leung, D Levy, C M Li, R Lim, M Lin, S Lin, M Litwin, T Lopez, R Lowe, P Lue, A Makanju, K Malfacini, S Manning, T Markov, Y Markovski, B Martin, K Mayer, A Mayne, B Mcgrew, S M Mckinney, C Mcleavey, P Mcmillan, J Mcneil, D Medina, A Mehta, J Menick, L Metz, A Mishchenko, P Mishkin, V Monaco, E Morikawa, D Mossing, T Mu, M Murati, O Murk, D Mély, A Nair, R Nakano, R Nayak, A Neelakantan, R Ngo, H Noh, L Ouyang, C O'keefe, J Pachocki, A Paino, J Palermo, A Pantuliano, G Parascandolo, J Parish, E Parparita, A Passos, M Pavlov, A Peng, A Perelman, F Avila Belbute Peres, M Petrov, H P Oliveira Pinto, Michael, Pokorny, M Pokrass, V Pong, T Powell, A Power, B Power, E Proehl, R Puri, A Radford, J Rae, A Ramesh, C Raymond, F Real, K Rimbach, C Ross, B Rotsted, H Roussez, N Ryder, M Saltarelli, T Sanders, S Santurkar, G Sastry, H Schmidt, D Schnurr, J Schulman, D Selsam, K Sheppard, T Sherbakov, J Shieh, S Shoker, P Shyam, S Sidor, E Sigler, M Simens, J Sitkin, K Slama, I Sohl, B Sokolowsky, Y Song, N Staudacher, F P Such, N Summers, I Sutskever, J Tang, N Tezak, M Thompson, P Tillet, A Tootoonchian, E Tseng, P Tuggle, N Turley, J Tworek, J F C Uribe, A Vallone, A Vijayvergiya, C Voss, C Wainwright, J J Wang, A Wang, B Wang, J Ward, J Wei, C Weinmann, A Welihinda, P Welinder, J Weng, L Weng, M Wiethoff, D Willner, C Winter, S Wolrich, H Wong, L Workman, S Wu, J Wu, M Wu, K Xiao, T Xu, S Yoo, K Yu, Q Yuan, W Zaremba, R Zellers, C Zhang, M Zhang, S Zhao, T Zheng, J Zhuang, W Zhuk, 2023Zoph, B.: GPT-4 Technical Report</p>
<p>. J Bai, S Bai, Y Chu, Z Cui, K Dang, X Deng, Y Fan, W Ge, Y Han, F Huang, B Hui, L Ji, M Li, J Lin, R Lin, D Liu, G Liu, C Lu, K Lu, J Ma, R Men, X Ren, X Ren, C Tan, S Tan, J Tu, P Wang, S Wang, W Wang, S Wu, B Xu, J Xu, A Yang, H Yang, J Yang, S Yang, Y Yao, B Yu, H Yuan, Z Yuan, J Zhang, X Zhang, Y Zhang, Z Zhang, C Zhou, J Zhou, X Zhou, T Zhu, 2023Qwen Technical Report</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, A Rodriguez, A Joulin, E Grave, G Lample, LLaMA: Open and Efficient Foundation Language Models. 2023</p>
<p>S Yue, W Chen, S Wang, B Li, C Shen, S Liu, Y Zhou, Y Xiao, S Yun, X Huang, Z Wei, DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services. 2023</p>
<p>Large language models encode clinical knowledge. K Singhal, S Azizi, T Tu, S S Mahdavi, J Wei, H W Chung, N Scales, A Tanwani, H Cole-Lewis, S Pfohl, Nature. 62079722023</p>
<p>Smiles. 2. algorithm for generation of unique smiles notation. D Weininger, A Weininger, J L Weininger, 10.1021/ci00062a008Journal of Chemical Information and Computer Sciences. 2921989</p>
<p>Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction. P Schwaller, T Laino, T Gaudin, P Bolgar, C A Hunter, C Bekas, A A Lee, 10.1021/acscentsci.9b0057631572784ACS Central Science. 592019</p>
<p>Chemical data intelligence for sustainable chemistry. J M Weber, Z Guo, C Zhang, A M Schweidtmann, A A Lapkin, 10.1039/D1CS00477HChem. Soc. Rev. 502021</p>
<p>What can Large Language Models do in chemistry?. T Guo, K Guo, B Nan, Z Liang, Z Guo, N V Chawla, O Wiest, X Zhang, 2023A comprehensive benchmark on eight tasks</p>
<p>Augmenting large language models with chemistry tools. M Bran, A Cox, S Schilter, O Baldassari, C White, A D Schwaller, P , Nature Machine Intelligence. 2024</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in neural information processing systems. 352022</p>
<p>Creating large language model applications utilizing langchain: A primer on developing llm apps fast. O Topsakal, T C Akinci, International Conference on Applied Engineering and Natural Sciences. 12023</p>
<p>D Zhang, W Liu, Q Tan, J Chen, H Yan, Y Yan, J Li, W Huang, X Yue, D Zhou, S Zhang, M Su, H Zhong, Y Li, W Ouyang, ChemLLM: A Chemical Large Language Model. 2024</p>
<p>chatchat-space: Langchain-Chatchat. </p>
<p>D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt, arXiv:2009.03300Measuring massive multitask language understanding. 2020arXiv preprint</p>
<p>C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models. Y Huang, Y Bai, Z Zhu, J Zhang, J Zhang, T Su, J Liu, C Lv, Y Zhang, Y Fu, Advances in Neural Information Processing Systems. 362024</p>
<p>K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Challenging big-bench tasks and whether chain-of-thought can solve them. M Suzgun, N Scales, N Schärli, S Gehrmann, Y Tay, H W Chung, A Chowdhery, Q V Le, E H Chi, D Zhou, J Wei, arXiv:2210.092612022arXiv preprint</p>
<p>H Li, Y Zhang, F Koto, Y Yang, H Zhao, Y Gong, N Duan, T Baldwin, Measuring massive multitask language understanding in Chinese. 2023CMMLU</p>
<p>H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>Glm: General language model pretraining with autoregressive blank infilling. Z Du, Y Qian, X Liu, M Ding, J Qiu, Z Yang, J Tang, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics20221</p>
<p>Internlm: A multilingual language model with progressively enhanced capabilities. I Team, 2023</p>
<p>A Yang, B Xiao, B Wang, B Zhang, C Bian, C Yin, C Lv, D Pan, D Wang, D Yan, arXiv:2309.10305Baichuan 2: Open large-scale language models. 2023arXiv preprint</p>
<p>. Ai, A Young, B Chen, C Li, C Huang, G Zhang, G Zhang, H Li, J Zhu, J Chen, J Chang, K Yu, P Liu, Q Liu, S Yue, S Yang, S Yang, T Yu, W Xie, W Huang, X Hu, X Ren, X Niu, P Nie, Y Xu, Y Liu, Y Wang, Y Cai, Z Gu, Z Liu, Z Dai, Yi: Open Foundation Models by 01.AI (2024</p>
<p>S Kim, J Chen, T Cheng, A Gindulyte, J He, S He, Q Li, B A Shoemaker, P A Thiessen, B Yu, Pubchem 2023 update. 202351</p>
<p>ChemSpider: an online chemical information resource. H E Pence, A Williams, 2010ACS Publications</p>
<p>I R Chemistry Team, rxn4chemistry: Python wrapper for the IBM RXN for Chemistry API. 2023</p>
<p>Unsupervised attention-guided atom-mapping. P Schwaller, B Hoover, J.-L Reymond, H Strobelt, T Laino, 2020</p>
<p>Precise atom-to-atom mapping for organic reactions via human-in-the-loop machine learning. S Chen, S An, R Babazade, Y Jung, Nature Communications. 15122502024</p>
<p>Arxiv at 20. P Ginsparg, Nature. 47673592011</p>
<p>SerpAPI: SerpAPI -Google Search Results API. 2023</p>
<p>Chempy: A package useful for chemistry written in python. B Dahlgren, Journal of Open Source Software. 3245652018</p>
<p>High-throughput experimentation and machine learning-assisted optimization of iridium-catalyzed cross-dimerization of sulfoxonium ylides. Y Xu, Y Gao, L Su, H Wu, H Tian, M Zeng, C Xu, X Zhu, K Liao, 10.1002/anie.202313638Angewandte Chemie International Edition. 62482023136382023</p>
<p>Auto machine learning assisted preparation of carboxylic acid by tempo-catalyzed primary alcohol oxidation. J Qiu, Y Xu, S Su, Y Gao, P Yu, Z Ruan, K Liao, 10.1002/cjoc.202200555Chinese Journal of Chemistry. 4122023</p>
<p>Hte and machine learning-assisted development of iridium (i)-catalyzed selective o-h bond insertion reactions toward carboxymethyl ketones. Y Xu, F Ren, L Su, Z Xiong, X Zhu, X Lin, N Qiao, H Tian, C Tian, K Liao, Organic Chemistry Frontiers. 1052023</p>
<p>Hte-and ai-assisted development of dhp-catalyzed decarboxylative selenation. Z Yu, Y Kong, B Li, S Su, J Rao, Y Gao, T Tu, H Chen, K Liao, Chemical Communications. 59202023</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, M Chang, K Lee, K Toutanova, 1810.048052018</p>
<p>O Contributors, OpenCompass: A Universal Evaluation Platform for Foundation Models. 2023</p>
<p>Predicting reaction performance in c-n cross-coupling using machine learning. D T Ahneman, J G Estrada, S Lin, S D Dreher, A G Doyle, Science. 36063852018</p>
<p>A platform for automated nanomole-scale reaction screening and micromole-scale synthesis in flow. D Perera, J W Tucker, S Brahmbhatt, C J Helal, A Chong, W Farrell, P Richardson, N W Sach, Science. 35963742018</p>
<p>Prediction of chemical reaction yields using deep learning. P Schwaller, A C Vaucher, T Laino, J.-L Reymond, Machine learning: science and technology. 21150162021</p>
<p>Imidazol-5-ones as a substrate for [1, 5]-hydride shift triggered cyclization. E R Zaitseva, A Y Smirnov, I N Myasnyanko, K S Mineev, A I Sokolov, T N Volkhina, A A Mikhaylov, N S Baleeva, M S Baranov, New Journal of Chemistry. 4542021</p>
<p>Mapping the space of chemical reactions using attention-based neural networks. P Schwaller, D Probst, A C Vaucher, V H Nair, D Kreutter, T Laino, J.-L Reymond, Nature Machine Intelligence. 322021</p>
<p>. European Bioinformatics Institute: ChEMBL Drug Database. 2024</p>
<p>Aizynthfinder: a fast, robust and flexible open-source software for retrosynthetic planning. S Genheden, A Thakkar, V Chadimová, J.-L Reymond, O Engkvist, E Bjerrum, Journal of cheminformatics. 121702020</p>
<p>Computational planning of the synthesis of complex natural products. B Mikulak-Klucznik, P Gołębiowska, A A Bayly, O Popik, T Klucznik, S Szymkuć, E P Gajewska, P Dittwald, O Staszewska-Krajewska, W Beker, Nature. 58878362020</p>
<p>Planning chemical syntheses with deep neural networks and symbolic ai. M H Segler, M Preuss, M P Waller, Nature. 55576982018</p>
<p>A mobile robotic chemist. B Burger, P M Maffettone, V V Gusev, C M Aitchison, Y Bai, X Wang, X Li, B M Alston, B Li, R Clowes, Nature. 58378152020</p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, G Gomes, Nature. 6242023</p>
<p>Model MMLU (5-shot). </p>
<p>. C-Eval , 5-shot</p>
<p>Table S1 Performance of Different Models on Various Benchmarks. </p>            </div>
        </div>

    </div>
</body>
</html>