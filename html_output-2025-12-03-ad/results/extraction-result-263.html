<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-263 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-263</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-263</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-14.html">extraction-schema-14</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <p><strong>Paper ID:</strong> paper-267500101</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.03822v2.pdf" target="_blank">RevOrder: A Novel Method for Enhanced Arithmetic in Language Models</a></p>
                <p><strong>Paper Abstract:</strong> This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks. Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to $\mathcal{O}(1)$, a new metric we introduce to assess equation complexity. Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle. Implementation of RevOrder is cost-effective for both training and inference phases. Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e263.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e263.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CSID</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Count of Sequential Intermediate Digits</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A metric introduced in this paper that counts digits missing from the immediate context but required to generate the next output digit (e.g., carry/borrow digits), used to quantify arithmetic equation complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>analytic metric applying to addition, subtraction, multiplication, division (general)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>metric definition and complexity analysis</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Formalizes that digits needed to produce a higher-order output digit but not present in the prior tokens (SIDs) create difficulty for LMs; shows addition/subtraction have CSID O(n), multiplication/division have CSID O(n^2) or O(n^2 - m^2) without intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Predicts performance degrades with increasing CSID; authors show empirically performance falls as CSID increases and larger models help but with diminishing returns on high-CSID tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High CSID correlates with LM failure to reliably generate correct multi-digit arithmetic results (errors amplified with digit length).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used to compare standard (direct-output) arithmetic vs RevOrder (which reduces CSID).</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>CSID quantifies why LMs fail on large-digit arithmetic: sequential hidden dependencies (carries/borrows) scale with digit length and exceed LM capacity unless reduced.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e263.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e263.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RevOrder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RevOrder (reverse-order output technique)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that trains / prompts LMs to emit arithmetic results with digits in reverse order (low-order to high-order), thereby reducing required sequential intermediate digits (CSID) to O(1) for addition, subtraction and nD-by-1D multiplication and improving reliability and token-efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, nD-by-1D multiplication, multiplication composed from nD-by-1D, division (with caveats)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>Evaluated up to 16-digit additions/subtractions, up to 16D dividends and 12D÷6D division examples in experiments (see paper for details).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>reverse-order digit output (special token 'r|' or @@ markers), decomposition of multi-digit operations into sub-operations, and a rollback symbol 'W' for division quotient correction; also compact forms to reduce token overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>When applied and trained (RevOrder-1B), the paper reports 100% exact-match accuracy on addition, subtraction and multiplication tasks across tested digit ranges; near-perfect division performance with 99.4% on a challenging 12D ÷ 6D test (improvement of ~10.1% vs best baseline reported). Finetuning LLaMA2-7B on GSM8K with RevOrder improved equation accuracy from 88.9% to 94.1% and overall score from 41.6 to 44.4; reduces calculation errors by 46% overall (and specific reductions: 94% addition, 87% subtraction).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>RevOrder reduces the need to predict unresolved carry/borrow digits by producing lower-order digits first, so each generated digit depends at most on the previous output (at most 1 SID); this transforms CSID from O(n) to O(1) enabling LMs to learn arithmetic as a sequence of local operations rather than long-range dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Reduces required training data (authors report achieving 100% on Big-bench arithmetic with ~0.5M equations vs larger datasets for other methods); inference token overhead is minimal (one extra token 'r|' for add/sub) and remains more token-efficient than full chain-of-thought; for very large multiplication/division token cost grows and may eventually exceed tool use.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Division remains vulnerable because quotient-estimation steps are heuristic and can cause unpredictable CSID; errors primarily occur from incorrect quotient guesses (off-by-one or wrong digit) and failures to emit the rollback marker, leading to cascading incorrect outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against GOAT-7B, MathGLM-2B, GPT-4 (reported results); authors compare with Scratchpad-style chain-of-thought methods and external tool use and report better token-efficiency and accuracy on many tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Reversing output digits (RevOrder) collapses long-range carry/borrow dependencies into local, learnable steps (CSID = O(1)), enabling high-accuracy arithmetic in LMs with low token overhead, except for quotient estimation in division.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e263.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e263.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RevOrder-1B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RevOrder-1B (1.1B TinyLLaMA finetuned with RevOrder)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 1.1B-parameter TinyLLaMA-based model finetuned on synthetically generated RevOrder-formatted arithmetic data that demonstrates the effectiveness of RevOrder across many arithmetic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RevOrder-1B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.1B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>decoder-only transformer (TinyLLaMA framework)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication (incl. nD-by-1D and composed nD×nD), division (low- and large-digit tested)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>Training included up to 16D numbers for add/sub, up to 8D×8D and 16D×1D for multiplication, dividends up to 16D for division; evaluations include Big-bench and extra high-digit tasks (e.g., 12D÷6D).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>finetuning on RevOrder-formatted synthetic dataset (~1.7M total training samples in paper; authors state 0.5M needed for 100% on Big-bench for RevOrder-1B), rollback-included training for division.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Reported 100% exact-match accuracy on Big-bench addition, subtraction and multiplication tasks across tested digit ranges; near-perfect division results with 99.4% on 12D ÷ 6D; authors claim 100% on many Big-bench subtasks. Table reports RevOrder-1B achieved 100% on many listed tasks where baselines fall off with digit size.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Operates reliably by learning to emit reversed digits so carry/borrow dependencies are local; rollback training teaches handling of misestimated quotient steps in division, but division errors still stem from quotient estimation rather than local arithmetic operations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Authors claim RevOrder-1B requires fewer training examples to reach high precision than other methods (noting larger models typically need less data), suggesting favorable scaling of training efficiency; inference token overhead is small.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Division errors due to incorrect quotient estimation (lack of rollback trigger); otherwise RevOrder-1B shows no errors when CSID kept at 1.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Benchmarked against published results for GOAT-7B, MathGLM-2B and reported GPT-4 numbers (authors used those as baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>A relatively small (1.1B) model finetuned with RevOrder can achieve near-perfect arithmetic performance across many digit ranges by turning global carry dependencies into local steps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e263.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e263.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA2-7B (RevOrder finetuned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA2-7B fine-tuned on GSM8K with RevOrder-format equations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter LLaMA2 model finetuned on GSM8K modified to use RevOrder formatting (plus synthetic enhancement data), yielding measurable improvements on math word problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA2-7B (finetuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>decoder-only transformer (LLaMA2)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>math word problems (GSM8K) involving addition, subtraction, multiplication and polynomial operations; multi-digit multiplication/division rare in dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>GSM8K grade-school word problems (diverse, not extreme multi-digit arithmetic); specifics not strictly bounded in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>fine-tuning on GSM8K with RevOrder formatting, plus a small synthetic RevOrder dataset; special markers (@@) introduced to denote reversed numbers when training a 7B model.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Equation accuracy improved from 88.9% to 94.1% and overall GSM8K score increased from 41.6 to 44.4 after RevOrder finetuning; calculation errors reduced by 46% overall (94% addition, 87% subtraction).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Finetuning on RevOrder reduces arithmetic calculation errors by teaching the model to perform local-digit computations (reversed digits), improving reliability of arithmetic sub-steps inside word-problem reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Authors note that limited additional synthetic training was necessary and that excessive fine-tuning risks catastrophic forgetting; RevOrder yields notable gains at 7B scale with moderate extra data.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Errors often due to insufficient training for RevOrder-specific tokens/symbols and occasional failures to reverse or re-order outputs correctly; some errors traceable to fine-tuning stage limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared before vs after finetuning on GSM8K; baseline LLaMA2-7B (original GSM8K fine-tuning) vs RevOrder-adapted fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Applying RevOrder in finetuning reduces arithmetic calculation errors inside math word-problem solving and increases final GSM8K scores, demonstrating utility beyond synthetic arithmetic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e263.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e263.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GOAT-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GOAT (fine-tuned LLaMA) - 7B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A finetuned LLaMA-7B variant (from Liu and Low 2023) that decomposes arithmetic operations and was used in this paper as a baseline for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GOAT-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>LLaMA-derived decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division (decomposition-based arithmetic)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>Benchmarks include multi-digit tasks (table lists up to 16D additions/subtractions and multi-digit multiplications/divisions).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>finetuning with decomposition into sub-operations (chain-of-thought / decomposition style), used as reported baseline results.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Reported strong performance on many tasks but accuracy declines with digit size; examples cited in paper: addition ~100% down to ~97.6% on largest add tasks, multiplication high but degrades on certain large multiplies, division drops (e.g., ~89.3% on 12D ÷ 6D in the table).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Relies on decomposition of complex ops into basic operations; authors note small errors in basic steps amplify when composing larger arithmetic operations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Performance improves with finetuning and model size but still degrades on high-digit (high CSID) problems; decomposition reduces CSID to O(n) but not to O(1).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Errors often from amplification of small errors in basic operations when composing multi-step arithmetic.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared by the paper as a baseline to RevOrder-1B and other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>A decomposition-based finetuned 7B model performs well but is outperformed by RevOrder on high-digit arithmetic due to residual CSID and error amplification.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e263.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e263.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MathGLM-2B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MathGLM-2B (GLM-2B finetuned version)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GLM-2B-based model finetuned extensively on step-by-step arithmetic examples (Yang et al., 2023) and used here as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gpt can solve mathematical problems without a calculator.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MathGLM-2B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>2B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td>GLM-family model (decoder-only / gated transformer variant as in GLM-2B)</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division (trained with extensive step-by-step examples)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>Reported coverage includes many digit sizes; paper cites their claims for solving math without external calculators.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>large-scale step-by-step finetuning (1m-50m instances according to authors' reporting referenced in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Cited as strong on some tasks but not achieving perfect reliability across high-digit arithmetic; paper's Table 1 lists MathGLM-2B high on small tasks but not perfect on all larger-digit tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>Depends on large amounts of step-by-step training data to internalize algorithmic arithmetic behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Authors referenced that MathGLM-2B required much larger training datasets (1M–50M) compared to RevOrder-1B to reach high performance.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Residual errors on large-digit tasks when basic operations are not perfectly reliable.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as a baseline in the paper's empirical comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Large-scale step-by-step finetuning can enable strong arithmetic but at much higher data cost than RevOrder according to the paper's comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e263.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e263.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-capacity LM referenced as a strong generalist baseline that nevertheless sometimes uses external tools for precise arithmetic in practice; reported in this paper via cited prior results.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GPT-4 technical report.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division (direct generation; often augmented with external calculator tools in practice)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>Benchmarks include multi-digit arithmetic up to sizes in Big-bench; specific digits vary across cited results.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>direct generation; service often uses external Python tools for reliable large-number arithmetic (noted in paper introduction).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Cited as strong on small-digit arithmetic but performance declines with very large digits; authors cite prior reports and use those numbers for baseline comparison (exact table entries taken from Liu & Low 2023).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>When used without external tools, GPT-4 suffers the same carry/long-dependency problems; practical deployments often route arithmetic to external calculators to avoid errors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Larger capacity helps but authors note diminishing improvements on very high-CSID tasks; external tooling is used in production to guarantee correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Struggles with large-digit arithmetic when asked to generate direct numeric answers (carry/borrow dependencies across many digits).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as a reference baseline (reported results) against which RevOrder and other methods are compared.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Even very large models like GPT-4 are unreliable at direct large-digit arithmetic generation without tool support; RevOrder aims to obviate such tool dependence for many cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Show your work: Scratchpads for intermediate computation with language models. <em>(Rating: 2)</em></li>
                <li>Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks. <em>(Rating: 2)</em></li>
                <li>Gpt can solve mathematical problems without a calculator. <em>(Rating: 2)</em></li>
                <li>Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. <em>(Rating: 2)</em></li>
                <li>Program-aided language models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-263",
    "paper_id": "paper-267500101",
    "extraction_schema_id": "extraction-schema-14",
    "extracted_data": [
        {
            "name_short": "CSID",
            "name_full": "Count of Sequential Intermediate Digits",
            "brief_description": "A metric introduced in this paper that counts digits missing from the immediate context but required to generate the next output digit (e.g., carry/borrow digits), used to quantify arithmetic equation complexity.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "model_architecture": null,
            "arithmetic_operation_type": "analytic metric applying to addition, subtraction, multiplication, division (general)",
            "number_range_or_complexity": null,
            "method_or_intervention": "metric definition and complexity analysis",
            "performance_result": null,
            "mechanistic_insight": "Formalizes that digits needed to produce a higher-order output digit but not present in the prior tokens (SIDs) create difficulty for LMs; shows addition/subtraction have CSID O(n), multiplication/division have CSID O(n^2) or O(n^2 - m^2) without intervention.",
            "performance_scaling": "Predicts performance degrades with increasing CSID; authors show empirically performance falls as CSID increases and larger models help but with diminishing returns on high-CSID tasks.",
            "failure_modes": "High CSID correlates with LM failure to reliably generate correct multi-digit arithmetic results (errors amplified with digit length).",
            "comparison_baseline": "Used to compare standard (direct-output) arithmetic vs RevOrder (which reduces CSID).",
            "key_finding": "CSID quantifies why LMs fail on large-digit arithmetic: sequential hidden dependencies (carries/borrows) scale with digit length and exceed LM capacity unless reduced.",
            "uuid": "e263.0",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RevOrder",
            "name_full": "RevOrder (reverse-order output technique)",
            "brief_description": "A method that trains / prompts LMs to emit arithmetic results with digits in reverse order (low-order to high-order), thereby reducing required sequential intermediate digits (CSID) to O(1) for addition, subtraction and nD-by-1D multiplication and improving reliability and token-efficiency.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "model_architecture": null,
            "arithmetic_operation_type": "addition, subtraction, nD-by-1D multiplication, multiplication composed from nD-by-1D, division (with caveats)",
            "number_range_or_complexity": "Evaluated up to 16-digit additions/subtractions, up to 16D dividends and 12D÷6D division examples in experiments (see paper for details).",
            "method_or_intervention": "reverse-order digit output (special token 'r|' or @@ markers), decomposition of multi-digit operations into sub-operations, and a rollback symbol 'W' for division quotient correction; also compact forms to reduce token overhead.",
            "performance_result": "When applied and trained (RevOrder-1B), the paper reports 100% exact-match accuracy on addition, subtraction and multiplication tasks across tested digit ranges; near-perfect division performance with 99.4% on a challenging 12D ÷ 6D test (improvement of ~10.1% vs best baseline reported). Finetuning LLaMA2-7B on GSM8K with RevOrder improved equation accuracy from 88.9% to 94.1% and overall score from 41.6 to 44.4; reduces calculation errors by 46% overall (and specific reductions: 94% addition, 87% subtraction).",
            "mechanistic_insight": "RevOrder reduces the need to predict unresolved carry/borrow digits by producing lower-order digits first, so each generated digit depends at most on the previous output (at most 1 SID); this transforms CSID from O(n) to O(1) enabling LMs to learn arithmetic as a sequence of local operations rather than long-range dependencies.",
            "performance_scaling": "Reduces required training data (authors report achieving 100% on Big-bench arithmetic with ~0.5M equations vs larger datasets for other methods); inference token overhead is minimal (one extra token 'r|' for add/sub) and remains more token-efficient than full chain-of-thought; for very large multiplication/division token cost grows and may eventually exceed tool use.",
            "failure_modes": "Division remains vulnerable because quotient-estimation steps are heuristic and can cause unpredictable CSID; errors primarily occur from incorrect quotient guesses (off-by-one or wrong digit) and failures to emit the rollback marker, leading to cascading incorrect outputs.",
            "comparison_baseline": "Compared against GOAT-7B, MathGLM-2B, GPT-4 (reported results); authors compare with Scratchpad-style chain-of-thought methods and external tool use and report better token-efficiency and accuracy on many tasks.",
            "key_finding": "Reversing output digits (RevOrder) collapses long-range carry/borrow dependencies into local, learnable steps (CSID = O(1)), enabling high-accuracy arithmetic in LMs with low token overhead, except for quotient estimation in division.",
            "uuid": "e263.1",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RevOrder-1B",
            "name_full": "RevOrder-1B (1.1B TinyLLaMA finetuned with RevOrder)",
            "brief_description": "A 1.1B-parameter TinyLLaMA-based model finetuned on synthetically generated RevOrder-formatted arithmetic data that demonstrates the effectiveness of RevOrder across many arithmetic tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "RevOrder-1B",
            "model_size": "1.1B",
            "model_architecture": "decoder-only transformer (TinyLLaMA framework)",
            "arithmetic_operation_type": "addition, subtraction, multiplication (incl. nD-by-1D and composed nD×nD), division (low- and large-digit tested)",
            "number_range_or_complexity": "Training included up to 16D numbers for add/sub, up to 8D×8D and 16D×1D for multiplication, dividends up to 16D for division; evaluations include Big-bench and extra high-digit tasks (e.g., 12D÷6D).",
            "method_or_intervention": "finetuning on RevOrder-formatted synthetic dataset (~1.7M total training samples in paper; authors state 0.5M needed for 100% on Big-bench for RevOrder-1B), rollback-included training for division.",
            "performance_result": "Reported 100% exact-match accuracy on Big-bench addition, subtraction and multiplication tasks across tested digit ranges; near-perfect division results with 99.4% on 12D ÷ 6D; authors claim 100% on many Big-bench subtasks. Table reports RevOrder-1B achieved 100% on many listed tasks where baselines fall off with digit size.",
            "mechanistic_insight": "Operates reliably by learning to emit reversed digits so carry/borrow dependencies are local; rollback training teaches handling of misestimated quotient steps in division, but division errors still stem from quotient estimation rather than local arithmetic operations.",
            "performance_scaling": "Authors claim RevOrder-1B requires fewer training examples to reach high precision than other methods (noting larger models typically need less data), suggesting favorable scaling of training efficiency; inference token overhead is small.",
            "failure_modes": "Division errors due to incorrect quotient estimation (lack of rollback trigger); otherwise RevOrder-1B shows no errors when CSID kept at 1.",
            "comparison_baseline": "Benchmarked against published results for GOAT-7B, MathGLM-2B and reported GPT-4 numbers (authors used those as baselines).",
            "key_finding": "A relatively small (1.1B) model finetuned with RevOrder can achieve near-perfect arithmetic performance across many digit ranges by turning global carry dependencies into local steps.",
            "uuid": "e263.2",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "LLaMA2-7B (RevOrder finetuned)",
            "name_full": "LLaMA2-7B fine-tuned on GSM8K with RevOrder-format equations",
            "brief_description": "A 7B-parameter LLaMA2 model finetuned on GSM8K modified to use RevOrder formatting (plus synthetic enhancement data), yielding measurable improvements on math word problems.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA2-7B (finetuned)",
            "model_size": "7B",
            "model_architecture": "decoder-only transformer (LLaMA2)",
            "arithmetic_operation_type": "math word problems (GSM8K) involving addition, subtraction, multiplication and polynomial operations; multi-digit multiplication/division rare in dataset.",
            "number_range_or_complexity": "GSM8K grade-school word problems (diverse, not extreme multi-digit arithmetic); specifics not strictly bounded in paper.",
            "method_or_intervention": "fine-tuning on GSM8K with RevOrder formatting, plus a small synthetic RevOrder dataset; special markers (@@) introduced to denote reversed numbers when training a 7B model.",
            "performance_result": "Equation accuracy improved from 88.9% to 94.1% and overall GSM8K score increased from 41.6 to 44.4 after RevOrder finetuning; calculation errors reduced by 46% overall (94% addition, 87% subtraction).",
            "mechanistic_insight": "Finetuning on RevOrder reduces arithmetic calculation errors by teaching the model to perform local-digit computations (reversed digits), improving reliability of arithmetic sub-steps inside word-problem reasoning.",
            "performance_scaling": "Authors note that limited additional synthetic training was necessary and that excessive fine-tuning risks catastrophic forgetting; RevOrder yields notable gains at 7B scale with moderate extra data.",
            "failure_modes": "Errors often due to insufficient training for RevOrder-specific tokens/symbols and occasional failures to reverse or re-order outputs correctly; some errors traceable to fine-tuning stage limitations.",
            "comparison_baseline": "Compared before vs after finetuning on GSM8K; baseline LLaMA2-7B (original GSM8K fine-tuning) vs RevOrder-adapted fine-tuning.",
            "key_finding": "Applying RevOrder in finetuning reduces arithmetic calculation errors inside math word-problem solving and increases final GSM8K scores, demonstrating utility beyond synthetic arithmetic tasks.",
            "uuid": "e263.3",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "GOAT-7B",
            "name_full": "GOAT (fine-tuned LLaMA) - 7B",
            "brief_description": "A finetuned LLaMA-7B variant (from Liu and Low 2023) that decomposes arithmetic operations and was used in this paper as a baseline for comparison.",
            "citation_title": "Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks.",
            "mention_or_use": "mention",
            "model_name": "GOAT-7B",
            "model_size": "7B",
            "model_architecture": "LLaMA-derived decoder-only transformer",
            "arithmetic_operation_type": "addition, subtraction, multiplication, division (decomposition-based arithmetic)",
            "number_range_or_complexity": "Benchmarks include multi-digit tasks (table lists up to 16D additions/subtractions and multi-digit multiplications/divisions).",
            "method_or_intervention": "finetuning with decomposition into sub-operations (chain-of-thought / decomposition style), used as reported baseline results.",
            "performance_result": "Reported strong performance on many tasks but accuracy declines with digit size; examples cited in paper: addition ~100% down to ~97.6% on largest add tasks, multiplication high but degrades on certain large multiplies, division drops (e.g., ~89.3% on 12D ÷ 6D in the table).",
            "mechanistic_insight": "Relies on decomposition of complex ops into basic operations; authors note small errors in basic steps amplify when composing larger arithmetic operations.",
            "performance_scaling": "Performance improves with finetuning and model size but still degrades on high-digit (high CSID) problems; decomposition reduces CSID to O(n) but not to O(1).",
            "failure_modes": "Errors often from amplification of small errors in basic operations when composing multi-step arithmetic.",
            "comparison_baseline": "Compared by the paper as a baseline to RevOrder-1B and other methods.",
            "key_finding": "A decomposition-based finetuned 7B model performs well but is outperformed by RevOrder on high-digit arithmetic due to residual CSID and error amplification.",
            "uuid": "e263.4",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "MathGLM-2B",
            "name_full": "MathGLM-2B (GLM-2B finetuned version)",
            "brief_description": "A GLM-2B-based model finetuned extensively on step-by-step arithmetic examples (Yang et al., 2023) and used here as a baseline.",
            "citation_title": "Gpt can solve mathematical problems without a calculator.",
            "mention_or_use": "mention",
            "model_name": "MathGLM-2B",
            "model_size": "2B",
            "model_architecture": "GLM-family model (decoder-only / gated transformer variant as in GLM-2B)",
            "arithmetic_operation_type": "addition, subtraction, multiplication, division (trained with extensive step-by-step examples)",
            "number_range_or_complexity": "Reported coverage includes many digit sizes; paper cites their claims for solving math without external calculators.",
            "method_or_intervention": "large-scale step-by-step finetuning (1m-50m instances according to authors' reporting referenced in this paper)",
            "performance_result": "Cited as strong on some tasks but not achieving perfect reliability across high-digit arithmetic; paper's Table 1 lists MathGLM-2B high on small tasks but not perfect on all larger-digit tasks.",
            "mechanistic_insight": "Depends on large amounts of step-by-step training data to internalize algorithmic arithmetic behaviors.",
            "performance_scaling": "Authors referenced that MathGLM-2B required much larger training datasets (1M–50M) compared to RevOrder-1B to reach high performance.",
            "failure_modes": "Residual errors on large-digit tasks when basic operations are not perfectly reliable.",
            "comparison_baseline": "Used as a baseline in the paper's empirical comparisons.",
            "key_finding": "Large-scale step-by-step finetuning can enable strong arithmetic but at much higher data cost than RevOrder according to the paper's comparisons.",
            "uuid": "e263.5",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "A large-capacity LM referenced as a strong generalist baseline that nevertheless sometimes uses external tools for precise arithmetic in practice; reported in this paper via cited prior results.",
            "citation_title": "GPT-4 technical report.",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_size": null,
            "model_architecture": null,
            "arithmetic_operation_type": "addition, subtraction, multiplication, division (direct generation; often augmented with external calculator tools in practice)",
            "number_range_or_complexity": "Benchmarks include multi-digit arithmetic up to sizes in Big-bench; specific digits vary across cited results.",
            "method_or_intervention": "direct generation; service often uses external Python tools for reliable large-number arithmetic (noted in paper introduction).",
            "performance_result": "Cited as strong on small-digit arithmetic but performance declines with very large digits; authors cite prior reports and use those numbers for baseline comparison (exact table entries taken from Liu & Low 2023).",
            "mechanistic_insight": "When used without external tools, GPT-4 suffers the same carry/long-dependency problems; practical deployments often route arithmetic to external calculators to avoid errors.",
            "performance_scaling": "Larger capacity helps but authors note diminishing improvements on very high-CSID tasks; external tooling is used in production to guarantee correctness.",
            "failure_modes": "Struggles with large-digit arithmetic when asked to generate direct numeric answers (carry/borrow dependencies across many digits).",
            "comparison_baseline": "Used as a reference baseline (reported results) against which RevOrder and other methods are compared.",
            "key_finding": "Even very large models like GPT-4 are unreliable at direct large-digit arithmetic generation without tool support; RevOrder aims to obviate such tool dependence for many cases.",
            "uuid": "e263.6",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Show your work: Scratchpads for intermediate computation with language models.",
            "rating": 2,
            "sanitized_title": "show_your_work_scratchpads_for_intermediate_computation_with_language_models"
        },
        {
            "paper_title": "Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks.",
            "rating": 2,
            "sanitized_title": "goat_finetuned_llama_outperforms_gpt4_on_arithmetic_tasks"
        },
        {
            "paper_title": "Gpt can solve mathematical problems without a calculator.",
            "rating": 2,
            "sanitized_title": "gpt_can_solve_mathematical_problems_without_a_calculator"
        },
        {
            "paper_title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.",
            "rating": 2,
            "sanitized_title": "beyond_the_imitation_game_quantifying_and_extrapolating_the_capabilities_of_language_models"
        },
        {
            "paper_title": "Program-aided language models.",
            "rating": 1,
            "sanitized_title": "programaided_language_models"
        }
    ],
    "cost": 0.014189750000000001,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>RevOrder: A Novel Method for Enhanced Arithmetic in Language Models
24 Feb 2024</p>
<p>Si Shen 
Nanjing University of Science and Technology
NanjingChina</p>
<p>Peijun Shen shenpeijun@henu.edu.cn 
Henan University
KaifengChina</p>
<p>Danhao Zhu 
Jiangsu Police Institute
NanjingChina</p>
<p>RevOrder: A Novel Method for Enhanced Arithmetic in Language Models
24 Feb 20242700B5939647649AED136CF676999FF1arXiv:2402.03822v2[cs.AI]
This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks.Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to O(1), a new metric we introduce to assess equation complexity.Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle.Implementation of RevOrder is cost-effective for both training and inference phases.Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4. 1 2</p>
<p>Introduction</p>
<p>Large language models (LLMs) have gained significant attention in recent years, excelling in natural language understanding and generation tasks (Zhao et al., 2023).Despite their advancements, the leading models like ChatGPT (OpenAI, 2022) and GPT-4 (OpenAI, 2023) struggle with basic arithmetic, particularly with large digits.The GPT-4 website service 3 addresses this by switching to external Python tools, as depicted in Fig. 1(a).This shift not only adds a cumbersome step but also leads to excessive token usage, significantly disrupting the language processing flow and efficiency.</p>
<p>Arithmetic reasoning has long focused on solving arithmetic problems with LMs (Lu et al., 2022).Typically, LMs generate the solutions step-by-step 1 Corresponding authors: Danhao Zhu 2 The data and code for this paper are available on Github. 3https://chat.openai.com/,2024-1-26 Figure 1: An illustration of performing addition using various methods.In the RevOrder method, the 'r|' symbol indicates that the subsequent digits are presented in reverse order.in a chain-of-thought (COT) manner, common in reasoning tasks (Wei et al., 2022b;Kojima et al., 2022;Zhou et al., 2022).For instance, Nye et al. (2021) used a 'Scratchpad' to generate intermediate steps, achieving high accuracy in 8D addition tasks, as shown in Fig. 1(b).Similar methods are applied for subtraction, multiplication, division, and other arithmetic operations (Liu and Low, 2023;Yang et al., 2023).</p>
<p>However, practical application of arithmetic reasoning in LMs faces significant challenges.Firstly, LMs lack consistency in providing accurate results, and there is no established theory to measure equation complexity or to determine if an equation is within an LM's capabilities.For example, Liu and Low (2023) posited that addition is learnable by LLMs, but their experiments with large-digit addition contained minor errors.Secondly, current decomposition methods are token-intensive, making them more expensive than tool-based solutions during inference.Even for a simple 2D addition, the Scratchpad method (Nye et al., 2021), shown in Fig. 1(b), is not more token-efficient than Python tools (Fig. 1(a)).</p>
<p>To address these challenges, we introduce two novel concepts.First, we propose the Count of Sequential Digits (CSID) as an indicator to measure the difficulty of arithmetic equations.A larger CSID suggests more omitted reasoning steps, indicating a more complex equation.We demonstrate that the CSID complexity grows at O(n) for addition and subtraction, where n is the digit count.Empirical evidence suggests that advanced language models struggle considerably with high-CSID problems.This indicates a notable limitation: LLMs are unreliable in directly producing results for even basic arithmetic tasks, such as single additions or subtractions, when the digits involved are large.</p>
<p>Second, we propose RevOrder, a technique that reduces the CSID to a constant 1 for addition, subtraction, and nD by 1D multiplication operations.Illustrated in Fig. 1(c), RevOrder reverses the output order of addition.This approach aligns with the natural human reasoning sequence, where higherorder digits are resolved after the lower ones.Unlike previous methods such as Scratchpad (Nye et al., 2021), RevOrder requires virtually no additional tokens for these basic operations.Building upon these, we can construct more complex operations with significantly reduced token usage.</p>
<p>RevOrder, evaluated on the Big-bench arithmetic task (Srivastava et al., 2022) and an expanded set with larger digits, achieved 100% accuracy in addition, subtraction, multiplication, and low-digit division tasks, and nearly 100% in large-digit division, outperforming baseline methods.The experimental section highlights its training and inference efficiency.Finetuning LLAMA2 (Touvron et al., 2023) with RevOrder on the GSM8K dataset (Cobbe et al., 2021) significantly improved equation accuracy and overall scores (from 88.9% to 94.1%, and 41.6 to 44.4, respectively).These results affirm RevOrder's effectiveness and token economy in a range of arithmetic tasks, especially in addition and subtraction.</p>
<p>Section 2 reviews related work, Section 3 introduces the CSID metric, Section 4 details the RevOrder technique, Section 5 reports on experiments on arithmetic calculation, Section 6 discusses finetuning on GSM8K, and Section 7 concludes the paper.</p>
<p>Related Works</p>
<p>Arithmetic ability, a cornerstone of mathematics, has long served as a benchmark for assessing model capabilities, evolving from statistical methods (Hosseini et al., 2014) through machine learning techniques (Kushman et al., 2014), deep learning approaches (Wang et al., 2017) to LLM methods (Wei et al., 2022a).</p>
<p>While scaling laws for LLMs suggest that model capacity increases with model size, compute resources, and training data (Kaplan et al., 2020;Hoffmann et al., 2022), LLMs often struggle to directly generate arithmetic results.Consequently, step-by-step arithmetic reasoning methods have been developed.ScratchPad (Nye et al., 2021) introduces this concept for additions, achieving nearperfect accuracy on 8D addition tasks.This idea has since been expanded to more complex operations, such as multiplication and division (Liu and Low, 2023;Yang et al., 2023).These complex operations depend on the assumption that LLMs can efficiently perform basic operations such as addition and subtraction.Otherwise, token usage quickly becomes unsustainable.However, these socalled basic operations often fail to achieve 100% accuracy with large digits, making the more complex operations built upon them even more prone to error.Our CSID theory provides a framework to assess the complexity of equations, showing that LLMs' ability to perform basic operations diminishes as digit size grows.Conversely, RevOrder introduces an efficient method to keep equations' CSID low, ensuring their manageability within constrained token budgets.</p>
<p>Given the limitations and high token consumption of previous arithmetic reasoning methods, more pragmatic solutions have emerged, such as utilizing external tools or programming (Schick et al., 2023;Chen et al., 2022;Gao et al., 2023).RevOrder stands out by offering reliability and efficiency in addition and subtraction, positioning itself as a resource-saving alternative to these methods.</p>
<p>Sequential Intermediate Digits in Arithmetic Computation</p>
<p>Arithmetic reasoning in language models (LMs) is challenging, mainly due to the sequential prediction of digits.This complexity is exacerbated when contextual digits required for accurate predictions are not inferred from previous steps.For example, in addition, LMs may predict higher-order digits before lower-order ones, contradicting the logical computation order.This paper introduces a novel metric to quantify and understand this complexity.</p>
<p>Definition of Sequential Intermediate Digits (SIDs)</p>
<p>A Sequential Intermediate Digit (SID) is a numeral crucial for the accurate prediction of the next digit in a sequence, yet not present in the preceding sequence.Within the framework of chain-of-thought reasoning, SIDs represent indispensable steps that, despite being missing, are vital for the computational process.Consequently, the Count of SIDs (CSIDs) is employed as a metric to assess the complexity of a generation step, with a higher CSID denoting a more demanding and intricate task.The CSID of an equation is thus defined as the maximum CSID required for generating each step of the result.The primary types of SIDs include:</p>
<p>• Carry-over or borrow digits in addition and subtraction.For example, in 123 + 179 = 302, the digit 3 in the hundreds place requires the carry-over from the tens and units places, resulting in a maximum CSID of 2.</p>
<p>• Digits from omitted reasoning steps, such as the intermediate sum 3 in 1 + 2 + 4 = 7.</p>
<p>It is postulated that basic operations like 1D by 1D addition, subtraction, multiplication, division, counting, and copying do not require SIDs, as their straightforward nature falls within the capabilities of modern LMs.Directly generating results for complex operations, such as multi-digit multiplication and division, requires more SIDs due to the omitted steps for decomposing these into multiple basic operations.</p>
<p>Reducing an equation's CSIDs, thereby lowering its solving difficulty, can be achieved by expanding the equation step-by-step in a chain-of-thought manner.For instance, the CSID for the calculation 1+2+4 = 3+4 = 7 is lower than for 1+2+4 = 7 because the intermediate sum 3 is included in the reasoning process, effectively reducing the number of SIDs.</p>
<p>The CSIDs for Arithmetic Operations</p>
<p>In our CSID analysis of standard arithmetic operations, which is akin to analyzing space or time complexity in algorithms, we focus on the
b m−1 . . . b 2 b 1 , result- ing in c = c t c t−1 . . . c 2 c 1 , with m ≤ n.
When involving negative numbers, the minus sign '-' is also treated as a digit.</p>
<p>• In addition and subtraction, the computation sequence
a n a n−1 . . . a 2 a 1 ± b m b m−1 . . . b 2 b 1 = c t c t−1 . . . c 2 c 1 depends on each c i involving a i , b i ,
and possibly c i−1 for carry-overs or borrows.Hence, the CSID for c t includes all lower digits as SIDs, indicating a complexity of O(n).</p>
<p>• For multiplication and division, the CSIDs are O(n 2 ) and O(n 2 − m 2 ) respectively, as detailed in Appendix A.</p>
<p>LLM Performance on Large CSID Equations</p>
<p>We trained various models on arithmetic tasks involving 15D+15D calculations, maintaining identical hyper-parameters, training data, and training steps across all models to ensure a fair comparison.</p>
<p>The test equations, strictly in 15D+15D format, were classified into various CSID levels according to the maximum number of continuous carry-over digits.The findings, as depicted in Fig. 2, demonstrate that:</p>
<p>• CSID effectively measures the complexity of arithmetic equations, where the performance consistently declines with increasing CSIDs.</p>
<p>• Larger models exhibit improved performance on equations with higher CSIDs.</p>
<p>• The benefit of increasing model size diminishes on high CSID equations.For instance, a 7B model shows more significant improvement on equations with CSIDs of 4 and 5 than on those with 6-9.This trend suggests that even advanced LLMs, like GPT-4, encounter difficulties with large digit addition tasks.Given that CSIDs have a complexity of at least O(n), arithmetic problems quickly surpass the capacity of LLMs when dealing with large digits.Therefore, LLMs cannot serve as reliable calculators for immediate result generation in complex arithmetic tasks.</p>
<p>4 RevOrder: Reversing the Order of Output Digits</p>
<p>We introduce RevOrder, an innovative technique devised to maintain low CSID in equations, thereby ensuring their solvability by LMs.Additionally, RevOrder is designed to minimize token usage, enhancing overall efficiency.</p>
<p>Addition and Subtraction</p>
<p>For addition and subtraction, we reverse the output digits' order:
a ± b = r|c 1 c 2 . . . c t = c t . . . c 2 c 1
Here, r| is a special token indicating that the followed digits are in a reversed order.To generate each c i in r|c 1 c 2 . . .c t , only a i , b i , and at most a SID for the carry-over or borrow number from c i−1 are required.Thus, both addition and subtraction only consume at most 1 SID regardless of number length.Therefore, the complexity of CSID drop to O(1) from O(n), by applying RevOrder.The cost of RevOrder for addition and subtraction is quite cheap during both training and inference.In training, RevOrder simply reverses the result digit orders.During inference, almost no additional tokens are required since the recovery of the result sequence can be done with rules.</p>
<p>Multiplication and Division</p>
<p>More complex operations like multiplication and division, can be decomposed to basic operations.</p>
<p>Multiplication</p>
<p>Firstly, consider the simplest form of multiplication, nD by 1D, e.g, 12*7=r|48, which consistently requires only 1 SID.This efficiency originates from the definition that 1D by 1D multiplication does not incur any SIDs, with the only one SID being the carry-over number in the addition.</p>
<p>Next, let's examine a more general multiplication example.</p>
<p>12 × 4567 =12 × 4000 + 12 × 500 + 12 × 60 + 12 × 7</p>
<p>(1)
=r|00084 + r|0006 + r|027 + r|48 (2) =(r|00084 + r|0006) + (r|027 + r|48) (3) =r|00045 + r|408 (4) =r|40845 =54804
First, decompose the multiplication as shown in Eqn.(1), which does not require any SIDs (require only count and copy operations that does not use SID in our definition).Second, output the results of each sub-multiplication in reverse order, as demonstrated in Eqn.(2).The zeros in these results can be efficiently generated through a copy operation from previous sequences.The nD by 1D multiplication in reverse order has a CSID of 1. Finally, iteratively combine the adjacent addition results until the final outcome is achieved, as illustrated in Eqn.</p>
<p>(3) and (4).As each addition operation involves only two numbers, the CSID remains constant at 1 throughout the process.</p>
<p>In conclusion, the CSID in this multiplication process never exceeds 1, with a complexity of O(1).</p>
<p>Division</p>
<p>Consider the division 948 ÷ 12 = 79:
948 ÷ 12 =7 Rem (948 − 12 × 70) (5) =7 Rem (948 − r|048) =7 Rem r|801 =79 Rem (r|801 − 12 * 9) (6) =79 Rem (r|801 − r|801) =79 Rem (0) =79
Utilizing traditional long division alongside RevOrder, the CSID typically remains at 1, with the exception of quotient estimation, as noted in Eqn.</p>
<p>(5) and Eqn.(6).Since the CSID analysis here is similar to that of multiplication, we omit it for brevity, .However, it's important to note that quotient estimation often involves heuristic guesswork, making precise CSID measurement challenging.In practice, we observed instances where the language model incorrectly estimated the quotient.To address this challenge, we implemented a rollback mechanism.If an incorrect quotient is detected, as illustrated in Eqn. ( 7), we insert a symbol 'W' after the line.This serves as a signal to adjust the process and re-estimate the quotient, as demonstrated in Eqn. ( 8).This method ensures more accurate quotient estimations in the long division process.In practice, a proportion of rollback scenarios are included in training to enhance the model's capability to correct such errors.
948 ÷ 12 =8 Rem (948 − 12 × 80) =8 Rem (948 − r|069) =8 Rem (−r|21)W (7) =7 Rem (948 − 12 × 70) (8) ...
However, the quotient estimation in division is inherently unpredictable, rendering the CSID of this operation less controllable.Consequently, unlike other arithmetic operations, the CSID for division cannot be consistently maintained at O(1).This limitation makes division with RevOrder less robust compared to addition, subtraction, and multiplication, as will be evidenced in our experimental results.</p>
<p>Towards More Compact Forms</p>
<p>To reduce token usage, we propose compact forms while maintaining CSID unchangeable.</p>
<p>For the multiplication example, it can be succinctly rewritten as: '12×4567 = 12×4000 + 12×500 + 12×60+ 12×7=r|00084 + r|0006 + r|027 + r|48 = r|00045 + r|408 = r|40845 = 54804'.Similarly, the division example can be condensed to: '948÷12 = 7R -(12×70)(r|048)(r|801) # 9R -(12×9)(r|801)(0) = 79', where R denotes REM and # denotes a new quotient estimation.</p>
<p>Two principles guide these simplifications: 1. Maintaining CSID: No digits essential for generating subsequent tokens are removed, ensuring the CSID remains unchanged.2. Eliminating Redundancy: Duplicated digits are removed, but care is taken to avoid introducing ambiguities that might confuse the LM.</p>
<p>Experiments on Arithmetic Problems</p>
<p>In this section, we aim to address two key research questions (RQs):</p>
<p>• RQ1: Does RevOrder enable a language model to function as a reliable calculator?(Section 5.2)</p>
<p>• RQ2: Is RevOrder a cost-effective solution for practical using?(Section 5.4)</p>
<p>Setup</p>
<p>Dataset</p>
<p>Our training dataset is synthetically generated using a Python script, with each sample being an equation formatted with RevOrder, e.g., '123+46=r|961'.The dataset comprises positive integers, except in subtraction where negative numbers may result.Each division equation is assigned a probability of 0.5 to be selected for generating a rollback version.This involves intentionally misestimating a quotient step by a number ±1, followed by a correction through the rollback process to the accurate estimation.The detailed of the training data is shown in Appendix B.</p>
<p>Training and evaluation protocol</p>
<p>We train a model named RevOrder-1B, which has 1.1 billion parameters.This model is trained on the TinyLLaMA 1.1B framework (Zhang et al., 2024), utilizing their released finetuning script.Specifically, the learning rate is set to 1e-4 for first 2 epochs and 1e-5 for the last epoch.The batch size is 500.</p>
<p>For evaluation, we employ the BIG-bench Arithmetic sub-task (Srivastava et al., 2022) and additional challenging tasks proposed in the GOAT-7B paper (Liu and Low, 2023).Each task has 1000 equations.We meticulously ensure that there is no overlap between the evaluation datasets and our training dataset, except for unavoidable overlaps in small digits tasks.The evaluation metric is exact match precision.</p>
<p>Baselines</p>
<p>As baselines, we compare against three methods:</p>
<p>• GOAT-7B (Liu and Low, 2023): This model, finetuned with 1 million instruction data on LLAMA-7B (Touvron et al., 2023), decomposes multiplication and division similarly to our approach.However, it relies on direct result generation for subtraction and addition.</p>
<p>• MathGLM-2B (Yang et al., 2023): Finetuned on the GLM-2B model for various arithmetic tasks, MATHGLM-2B claims that extensive step-by-step training data (1m-50m instances) enables GPT models to solve math problems without external calculators.</p>
<p>• GPT-4 (OpenAI, 2023): Currently one of the most powerful LMs, GPT-4's results are based on direct mathematical problem-solving, without auxiliary tools or equation decomposition.</p>
<p>Main Results (RQ1)</p>
<p>The results, as presented in Table 1, demonstrate several key findings.Firstly, RevOrder-1B proves to be a reliable method for addition, subtraction, multiplication, and low-digit division tasks, achieving 100% accuracy across all corresponding tasks.In contrast, the accuracy of all baseline methods decreases with the increase in digit size.Secondly, while RevOrder-1B shows slight imperfections in large-digit division tasks, it still significantly outperforms baseline models.For instance, RevOrder-1B attains a 99.4% accuracy on the challenging 12D ÷ 6D tasks, with an increasing of 10.1% than that of the best-performing baseline, GOAT-7B.</p>
<p>The major success of RevOrder in multiplication and division can be attributed to its precise execution of basic operations, including addition, subtraction, and nD-1D multiplication.While GOAT-7B and MathGLM-2B also decompose these operations into basic ones, minor errors in these fundamental steps are amplified in subsequent composite operations, leading to a rapid decline in accuracy with larger digits.</p>
<p>In summary, RevOrder emerges as an effective technique, enabling language models to perform exact arithmetic calculations in addition, subtraction, multiplication, and low-digit division tasks.</p>
<p>In-Depth Analysis on Division</p>
<p>Large-digit division represents the sole operation where RevOrder encounters notable difficulties, warranting additional focus.</p>
<p>Upon examining division errors case by case, we discovered that all errors stemmed from incorrect quotient estimations.Fig. 3 illustrates such an error, where RevOrder-1B erroneously estimated the 3rd quotient as 8 (marked in red) instead of 9, without triggering the 'W' symbol for a rollback.Consequently, this led to a series of nonsensical outputs.It's notable that when a constant CSID  of 1 is maintained in all four arithmetic operations, no errors occur.Errors only arise during quotient estimation, where CSID is unmeasurable.These results validate our theory regarding CSID.</p>
<p>We also assessed the effectiveness of the rollback mechanism.Fig. 4(a) presents the test precision for 12D ÷ 6D division across varying rollback ratios.A stark precision decline to 0.84 is observed with no rollback (ratio = 0).Precision does not significantly improve when the ratio exceeds 0.4, though this is partly due to the high baseline precision of 0.99.Fig. 4(b) illustrates the frequency of rollbacks during testing, indicating a higher incidence of rollbacks with larger digits.This trend underscores the importance of the rollback technique, particularly as it compensates for the increased likelihood of errors in quotient estimation with larger numbers.</p>
<p>The Cost of RevOrder (RQ2)</p>
<p>Cost of Training</p>
<p>By maintaining a low CSID, RevOrder simplifies the learning process for arithmetic problems, thereby reducing the volume of training data required.precision with at most half the training equations compared to other methods.Recent studies indicate that larger models often require less training data for task mastery (Hoffmann et al., 2022;Xia et al., 2022).Consequently, the training cost advantage of RevOrder is likely to be even more pronounced with larger LLMs.</p>
<p>Cost of Inference</p>
<p>The inference cost is assessed based on the number of additional tokens required for performing arithmetic calculations with RevOrder.We make two assumptions: 1) Each character (digit, symbol, etc.) is counted as one token, and 2) if the final result is output in reverse, the recovery process is handled by the tokenizer's decode function.</p>
<p>For addition and subtraction equations, only one extra token ('r|') is required.For multiplication and division equations, the number of extra tokens used is illustrated in Fig. 5. RevOrder is more token-efficient in both types of equations.Firstly, the compact form introduced in Section 3.3 significantly reduces the token requirement for division, approximately halving the number of extra tokens.Secondly, the iterative combination approach in multiplication, as exemplified in Eqn.</p>
<p>(3), also notably reduces token usage in multiplication.However, it must be acknowledged that for largedigit multiplication and division tasks, the token consumption of RevOrder increases polynomially and may eventually exceed the cost of using external tools.LLM service providers can set a threshold of digit number to decide between RevOrder and tool-based solutions.</p>
<p>Additional Experiments on Math Word Problems</p>
<p>In this section, we delve into finetuning scenarios to address the research question:</p>
<p>• RQ3: How does applying RevOrder affect finetuning performance on mathematical tasks?</p>
<p>Setup</p>
<p>The experiment is conducted on GSM8K (Cobbe et al., 2021), a dataset of 8.5K high quality linguistically diverse grade school math word problems created by human problem writers.Our experiments utilize LLAMA2-7B (Touvron et al., 2023) as the foundational model.We modified the equations in the GSM8K training set to adopt the RevOrder format.This adaptation involved two major updates: Firstly, we presented the outcomes for addition, subtraction, and multiplication in reverse order.Secondly, polynomial equations were expanded and solved iteratively, in pairs.Noted that we did not decompose multi-digit multiplications and divisions, as these cases are infrequent in the GSM8K dataset.To further enhance the model's proficiency with RevOrder, we supplemented the training set with a small, synthetically generated dataset using a Python script.The comprehensive details of the dataset and the training parameters are provided in Appendix C.</p>
<p>Results</p>
<p>From the analysis, it is evident that RevOrder significantly reduces calculation errors, by 94% for addition, 87% for subtraction, and 46% for overall equation errors, thereby enhancing the final score.This improvement underscores the potential of seamlessly integrating RevOrder into fine-tuning processes to achieve substantial performance gains.</p>
<p>We also observe the errors, and find most of the errors are due to lack of enough training.Table 3: Fine-tuning results on GSM8K Dataset.This table compares the performance of models fine-tuned with the original GSM8K dataset (baseline) against those finetuned using the RevOrder-modified GSM8K dataset.The Score is measured by the correctness ratio of final results.</p>
<p>stage rather than the fine-tuning stage.The primary rationale is that excessive fine-tuning can lead to catastrophic forgetting, thereby impairing the general capabilities of LMs (Luo et al., 2023;Ramasesh et al., 2021).</p>
<p>Conclusion</p>
<p>In this paper, we introduce the CSID as a metric to evaluate the complexity of arithmetic equations and demonstrate that even large-scale LLMs struggle with high-CSID equations.We propose RevOrder, an innovative technique that ensures accurate arithmetic calculations by minimizing CSID, thereby enhancing precision while reducing both training and inference costs.Our experiments confirm that RevOrder significantly outperforms previous methods in terms of accuracy and efficiency.</p>
<p>For future work, we identify two possible paths: Firstly, developing token-efficient decomposition algorithms suitable for larger LLMs, which can handle higher CSIDs for complex arithmetic operations.Secondly, integrating RevOrder into LLMs' pretraining could enhance arithmetic capabilities more fundamentally than finetuning, reducing the risk of catastrophic forgetting and ensuring broader model proficiency.</p>
<p>Ultimately, RevOrder stands out as a particularly promising approach for arithmetic operations, especially addition and subtraction, due to its precision and efficiency.This positions it as a competitive alternative to existing methods in enhancing LLMs' arithmetic reasoning.</p>
<p>A The CSID Analysis of Multiplication and Division</p>
<p>This section extends the CSID analysis to nD by nD multiplication and nD by mD division, following the algorithmic approach outlined in Section 4.2 but excluding the RevOrder technique.</p>
<p>A.1 Multiplication</p>
<p>The decomposition of an nD by nD multiplication into n sub-multiplications, each an nD by 1D operation, serves as the initial step.This phase does not generate SIDs, as all required digits for a × b are immediately accessible.Addressing these sub-multiplications yields up to n 2 + n × (n + 1) = 2n 2 + n SIDs, with n 2 SIDs allocated for the sub-multiplications and n×(n+1) SIDs dedicated to storing the outcomes.</p>
<p>Aggregating the results of these submultiplications necessitates a maximum of 4n 2 SIDs, with each addition consuming 4n SIDs, 2n for carry-overs and another 2n for storing the results.</p>
<p>Consequently, directly generating an nD by nD multiplication outcome requires a maximum of 6n 2 + n SIDs, indicating a complexity of O(n 2 ).This substantial complexity explains the difficulty models face with even 2D by 2D multiplications.</p>
<p>Decomposition methods, as applied in models like GOAT-7B and MathGLM-2B, reduce the CSID to O(n), by omitting intermediate results from the SID count, though carry-overs are still considered.</p>
<p>A.2 Division</p>
<p>For an nD by mD division, typically n − m iterations are needed, each estimating a quotient digit.</p>
<p>Each iteration involves an nD by 1D multiplication and a subtraction, with the multiplication incurring 2m SIDs for result and carry-over digit storage, and the subtraction using up to 2n SIDs for result storage and borrow digits.</p>
<p>Thus, the total CSID for an nD by mD division reaches (2m+2n) * (n−m) = 2n 2 −2m 2 , amounting to a complexity of O(n 2 − m 2 ).</p>
<p>This estimation excludes the quotient estimation step's complexity, which could further complicate large number divisions, potentially surpassing the O(n 2 − m 2 ) complexity.</p>
<p>In models like GOAT-7B and MathGLM-2B, using decomposition methods keeps the CSID at O(n), with the subtraction's borrow digits being the primary complexity factor.</p>
<p>B Training Data for Arithmetic Experiments</p>
<p>The training dataset comprises 1.7 million equations.For addition and subtraction tasks, equations involve numbers as large as 16D on both sides.Multiplication tasks are capped at 8D by 8D, supplemented by 16D by 1D equations to enhance generalization in the test set.Division tasks feature dividends up to 16D.Fig. 6 illustrates the distribution of these equations.The major training samples are division, since the quotient estimation steps require more training samples to achieve a high precision.</p>
<p>C Settings for Math Word Experiments C.1 Training Data</p>
<p>Our approach involved two types of instructional data to train models on arithmetic tasks using RevOrder.</p>
<p>Firstly, we modified the original GSM8K dataset to reflect RevOrder formatting.An example of this adaptation is illustrated in Fig. 7.</p>
<p>Secondly, to further bolster the model's proficiency in RevOrder calculations, we compiled an additional enhancement dataset.A sample from this dataset is depicted in Fig. 8.</p>
<p>Given the limited size of the training data, the 7B model faced challenges in mastering the use of the reverse symbol r|.To address this, we introduced a notation where all numbers enclosed by @@, signify reverse order.</p>
<p>C.2 Training Details</p>
<p>The models were trained with a batch size of 32 and a learning rate of 5e-5, employing a warm-up ratio of 0.08 over 3 epochs.During each epoch, the model was exposed to both the additional datasets and the GSM8K datasets sequentially.</p>
<p>C.3 Equation Errors</p>
<p>Fig. 9 showcases representative errors encountered in the GSM8K test set, attributable to difficulties in adhering to RevOrder instructions.For instance, while the model successfully solved the second equation in reverse order, it faltered in performing the simple task of reversing the solution to arrive at the final result.</p>
<p>Figure 2 :
2
Figure 2: LLM performance on equations with varying CSIDs.</p>
<p>Figure 3 :
3
Figure 3: An error example of division by RevOrder.</p>
<p>Figure 4 :
4
Figure 4: Analysis of the rollback ratio in division.(a) Test precision vs. rollback ratio for 12D ÷ 6D division.(b) Probability of rollbacks during testing across different digit sizes.</p>
<p>Figure 5 :
5
Figure 5: The number of extra tokens required for multiplication and division.</p>
<p>Figure 6 :
6
Figure 6: The distribution of the equations in training set.</p>
<p>Figure 7 :
7
Figure 7: A data sample from the GSM8K dataset formatted in RevOrder.</p>
<p>Figure 8 :
8
Figure 8: A sample from the additional enhancement dataset for RevOrder calculations.</p>
<p>Figure 9 :
9
Figure 9: Illustrative errors from the GSM8K test set encountered by the model trained with RevOrder.</p>
<p>Table 1 :
1
Liu and Low (2023) number of training equations needed for various methods.Despite being a smaller model, RevOrder-1B achieves perfect Performance comparison on various arithmetic tasks.The results of the baseline methods are taken from their original paper, while the result of GPT-4 is taken fromLiu and Low (2023).
TaskBIG-benchExtra TasksADD1D2D3D4D5D8D+8D16D+8D 16D+16DGPT-4100 100 99.6 98.8 94.192.19.494.1GOAT-7B100 100 99.4 98.3 98.197.897.197.6MathGLM-2B 100 100100100 99.4---RevOrder-1B100 100100100100100100100SUB1D2D3D4D5D8D-8D16D-8D16D-16DGPT-4100 100 99.2 98.9 92.470.510.659.6GOAT-7B100 100 99.7 98.6 98.496.895.896.3MathGLM-2B 100 100 99.9 99.8 98.9---RevOrder-1B100 100100100100100100100MUL1D2D3D4D5D16D × 1D 8D × 4D6D×6DGPT-4100 99.4 30.35.30.061.50.00.0GOAT-7B100 100 97.8 96.9 96.799.788.196.8MathGLM-2B 100 99.9 98.3 94.9 89.9---RevOrder-1B100 100100100100100100100DIV1D2D3D4D5D16D÷1D6D÷3D12D÷6DGPT-4100 100 94.5 90.9 53.4546.40.0GOAT-7B100 100 99.59996.59994.189.3MathGLM-2B 100 100 99.4 100 94.9---RevOrder-1B100 10010010010099.210099.4Model# Equations 100% ACCRevOrder-1B0.5mYesMathGLM-2B1m-50mNoGOAT-7B1.7mNo</p>
<p>Table 2 :
2
Number of training equations for different methods.This table reports the dataset size required for RevOrder-1B to achieve 100% accuracy on all Bigbench arithmetic sub-tasks.# Equations denotes the number of training equations.</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Wenhu Chen, Xueguang Ma, Xinyi Wang, William W Cohen, arXiv:2211.125882022arXiv preprint</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Pal: Program-aided language models. Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, International Conference on Machine Learning. PMLR2023</p>
<p>Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego De Las, Lisa Anne Casas, Johannes Hendricks, Aidan Welbl, Clark, arXiv:2203.15556Training compute-optimal large language models. 2022arXiv preprint</p>
<p>Learning to solve arithmetic word problems with verb categorization. Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, Nate Kushman, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)2014</p>
<p>Jared Kaplan, Sam Mccandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, arXiv:2001.08361Scaling laws for neural language models. 2020arXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Learning to automatically solve algebra word problems. Nate Kushman, Yoav Artzi, Luke Zettlemoyer, Regina Barzilay, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 52nd Annual Meeting of the Association for Computational Linguistics20141</p>
<p>Tiedong Liu, Bryan Kian, Hsiang Low, arXiv:2305.14201Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks. 2023arXiv preprint</p>
<p>Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, Kai-Wei Chang, arXiv:2212.10535A survey of deep learning for mathematical reasoning. 2022arXiv preprint</p>
<p>An empirical study of catastrophic forgetting in large language models during continual fine-tuning. Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, Yue Zhang, arXiv:2308.087472023arXiv preprint</p>
<p>Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, arXiv:2112.00114Show your work: Scratchpads for intermediate computation with language models. 2021arXiv preprint</p>
<p>Introducing chatgpt. Gpt-4 technical report. 2022OpenAI</p>
<p>Effect of scale on catastrophic forgetting in neural networks. Vinay Venkatesh Ramasesh, Aitor Lewkowycz, Ethan Dyer, 2021In International Conference on Learning Representations</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, arXiv:2302.047612023arXiv preprint</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal, Md Shoeb, Abubakar Abid, Adam Fisch, Adam Adam R Brown, Aditya Santoro, Adrià Gupta, Garriga-Alonso, arXiv:2206.04615Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. 2022arXiv preprint</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>Deep neural solver for math word problems. Yan Wang, Xiaojiang Liu, Shuming Shi, Proceedings of the 2017 conference on empirical methods in natural language processing. the 2017 conference on empirical methods in natural language processing2017</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022aarXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 2022b35</p>
<p>Training trajectories of language models across scales. Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, Ves Stoyanov, arXiv:2212.098032022arXiv preprint</p>
<p>Zhen Yang, Ming Ding, Qingsong Lv, Zhihuan Jiang, Zehai He, Yuyi Guo, Jinfeng Bai, Jie Tang, arXiv:2309.03241Gpt can solve mathematical problems without a calculator. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>