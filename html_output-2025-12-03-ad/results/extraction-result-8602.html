<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8602 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8602</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8602</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-155.html">extraction-schema-155</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-274597466</p>
                <p><strong>Paper Title:</strong> LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments</p>
                <p><strong>Paper Abstract:</strong> This paper introduces DebateBrawl, an innovative AI-powered debate platform that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and Adversarial Search (AS) to create an adaptive and engaging debating experience. DebateBrawl addresses the limitations of traditional LLMs in strategic planning by incorporating evolutionary optimization and game-theoretic techniques. The system demonstrates remarkable performance in generating coherent, contextually relevant arguments while adapting its strategy in real-time. Experimental results involving 23 debates show balanced outcomes between AI and human participants, with the AI system achieving an average score of ${2. 7 2}$ compared to the human average of ${2. 6 7}$ out of 10. User feedback indicates significant improvements in debating skills and a highly satisfactory learning experience, with 85% of users reporting improved debating abilities and ${7 8 \%}$ finding the AI opponent appropriately challenging. The system’s ability to maintain high factual accuracy (92% compared to ${7 8 \%}$ in human-only debates) while generating diverse arguments addresses critical concerns in AI-assisted discourse. DebateBrawl not only serves as an effective educational tool but also contributes to the broader goal of improving public discourse through AI-assisted argumentation. The paper discusses the ethical implications of AI in persuasive contexts and outlines the measures implemented to ensure responsible development and deployment of the system, including robust fact-checking mechanisms and transparency in decision-making processes.</p>
                <p><strong>Cost:</strong> 0.007</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8602.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8602.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bhowmik et al. hybrid MLM+GAN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid masked language model combined with generative adversarial networks for molecular generation (Bhowmik et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced work proposing a hybrid architecture that combines masked language models with GANs to generate virtual libraries of molecules for drug discovery and materials science, aiming to improve efficiency over traditional inverse design methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing molecular design efficiency: Uniting language models and generative networks with genetic algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>masked language model + GAN (hybrid architecture)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>masked language model (transformer-style) combined with a generative adversarial network</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>drug discovery and materials science (virtual molecular library generation)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Generative approach: MLM-based sequence/modeling combined with GANs to produce novel molecular candidates (virtual library generation); hybrid architecture intended to improve sampling and diversity</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Paper is cited as having examined the effectiveness of generative models in creating virtual molecule libraries and proposed the hybrid MLM+GAN architecture to efficiently generate new molecules; this DebateBrawl paper does not report quantitative results from that study.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Claimed to overcome limitations of traditional inverse design methods (per citation), but no quantitative comparison details are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>This paper only mentions the approach at a high level; specific limitations or failure cases from the cited work are not reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8602.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8602.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs in molecular/materials design (general mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Use of large language models and generative models in drug discovery and materials science (general discussion in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper briefly discusses prior research applying generative models, including LLMs, to drug discovery and materials science as promising avenues to address limitations of traditional inverse design.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>generative models / large language models (general)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>drug discovery and materials science</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>General generative-model-based design (the paper references approaches such as LLM-driven generation and hybrid generative architectures but provides no implementation details)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Only a high-level statement that generative models (including LLMs) show promise for creating virtual molecule libraries and facilitating drug discovery; no experimental data or metrics are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Stated qualitatively that generative/LLM methods may overcome limitations of traditional inverse design, but no direct comparisons or performance numbers are given here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>No detailed limitations specific to chemical design are provided beyond general mentions of ethical/robustness concerns for LLMs in other sections; the paper does not analyze synthesizability, validity, or other chemistry-specific failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Enhancing molecular design efficiency: Uniting language models and generative networks with genetic algorithms. <em>(Rating: 2)</em></li>
                <li>Large language models as evolutionary optimizers. <em>(Rating: 1)</em></li>
                <li>When large language models meet evolutionary algorithms <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8602",
    "paper_id": "paper-274597466",
    "extraction_schema_id": "extraction-schema-155",
    "extracted_data": [
        {
            "name_short": "Bhowmik et al. hybrid MLM+GAN",
            "name_full": "Hybrid masked language model combined with generative adversarial networks for molecular generation (Bhowmik et al.)",
            "brief_description": "Referenced work proposing a hybrid architecture that combines masked language models with GANs to generate virtual libraries of molecules for drug discovery and materials science, aiming to improve efficiency over traditional inverse design methods.",
            "citation_title": "Enhancing molecular design efficiency: Uniting language models and generative networks with genetic algorithms.",
            "mention_or_use": "mention",
            "model_name": "masked language model + GAN (hybrid architecture)",
            "model_type": "masked language model (transformer-style) combined with a generative adversarial network",
            "model_size": null,
            "training_data": null,
            "application_domain": "drug discovery and materials science (virtual molecular library generation)",
            "generation_method": "Generative approach: MLM-based sequence/modeling combined with GANs to produce novel molecular candidates (virtual library generation); hybrid architecture intended to improve sampling and diversity",
            "novelty_of_chemicals": null,
            "application_specificity": null,
            "evaluation_metrics": null,
            "results_summary": "Paper is cited as having examined the effectiveness of generative models in creating virtual molecule libraries and proposed the hybrid MLM+GAN architecture to efficiently generate new molecules; this DebateBrawl paper does not report quantitative results from that study.",
            "comparison_to_other_methods": "Claimed to overcome limitations of traditional inverse design methods (per citation), but no quantitative comparison details are provided in this paper.",
            "limitations_and_challenges": "This paper only mentions the approach at a high level; specific limitations or failure cases from the cited work are not reported here.",
            "uuid": "e8602.0",
            "source_info": {
                "paper_title": "LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "LLMs in molecular/materials design (general mention)",
            "name_full": "Use of large language models and generative models in drug discovery and materials science (general discussion in this paper)",
            "brief_description": "The paper briefly discusses prior research applying generative models, including LLMs, to drug discovery and materials science as promising avenues to address limitations of traditional inverse design.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "generative models / large language models (general)",
            "model_size": null,
            "training_data": null,
            "application_domain": "drug discovery and materials science",
            "generation_method": "General generative-model-based design (the paper references approaches such as LLM-driven generation and hybrid generative architectures but provides no implementation details)",
            "novelty_of_chemicals": null,
            "application_specificity": null,
            "evaluation_metrics": null,
            "results_summary": "Only a high-level statement that generative models (including LLMs) show promise for creating virtual molecule libraries and facilitating drug discovery; no experimental data or metrics are provided in this paper.",
            "comparison_to_other_methods": "Stated qualitatively that generative/LLM methods may overcome limitations of traditional inverse design, but no direct comparisons or performance numbers are given here.",
            "limitations_and_challenges": "No detailed limitations specific to chemical design are provided beyond general mentions of ethical/robustness concerns for LLMs in other sections; the paper does not analyze synthesizability, validity, or other chemistry-specific failure modes.",
            "uuid": "e8602.1",
            "source_info": {
                "paper_title": "LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Enhancing molecular design efficiency: Uniting language models and generative networks with genetic algorithms.",
            "rating": 2,
            "sanitized_title": "enhancing_molecular_design_efficiency_uniting_language_models_and_generative_networks_with_genetic_algorithms"
        },
        {
            "paper_title": "Large language models as evolutionary optimizers.",
            "rating": 1,
            "sanitized_title": "large_language_models_as_evolutionary_optimizers"
        },
        {
            "paper_title": "When large language models meet evolutionary algorithms",
            "rating": 1,
            "sanitized_title": "when_large_language_models_meet_evolutionary_algorithms"
        }
    ],
    "cost": 0.0069495,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments</p>
<p>Aryan Prakash h20230010@dubai.bits-pilani.ac.in 
Department of Computer Science
Birla Institute of Technology and Science
Pilani -Dubai Campus Dubai
UAE</p>
<p>IEEE Conference on Engineering Informatics (ICEI)
2024</p>
<p>LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments
32E069F37D2766B267F67A27650E127E10.1109/ICEI64305.2024.10912343Machine LearningDeep LearningGenerative AILarge Language ModelsGenetic AlgorithmsAdversarial Search
This paper introduces DebateBrawl, an innovative AI-powered debate platform that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and Adversarial Search (AS) to create an adaptive and engaging debating experience.DebateBrawl addresses the limitations of traditional LLMs in strategic planning by incorporating evolutionary optimization and game-theoretic techniques.The system demonstrates remarkable performance in generating coherent, contextually relevant arguments while adapting its strategy in real-time.Experimental results involving 23 debates show balanced outcomes between AI and human participants, with the AI system achieving an average score of 2.72 compared to the human average of 2.67 out of 10.User feedback indicates significant improvements in debating skills and a highly satisfactory learning experience, with 85% of users reporting improved debating abilities and 78% finding the AI opponent appropriately challenging.The system's ability to maintain high factual accuracy (92% compared to 78% in human-only debates) while generating diverse arguments addresses critical concerns in AI-assisted discourse.DebateBrawl not only serves as an effective educational tool but also contributes to the broader goal of improving public discourse through AI-assisted argumentation.The paper discusses the ethical implications of AI in persuasive contexts and outlines the measures implemented to ensure responsible development and deployment of the system, including robust fact-checking mechanisms and transparency in decision-making processes.</p>
<p>I. INTRODUCTION</p>
<p>The convergence of artificial intelligence (AI) and argumentation has emerged as a new platform, promising to reform debates, improve critical thinking, and foster more informed discourse.As language models become increasingly sophisticated, their potential as intelligent debate partners and argumentation assistants has captured the imagination of researchers and educators.This paper introduces DebateBrawl, a novel system that utilizes Large Language Models (LLMs), Genetic Algorithms (GA), and Adversarial Search (AS) to create an adaptive and engaging debate platform.</p>
<p>However, current AI-powered debate systems face several critical challenges that limit their effectiveness as educational and practice tools.First, while LLMs excel at generating fluent responses, they lack strategic depth in extended debates, often failing to maintain consistent argumentation strategies across multiple exchanges.Second, existing systems typically operate with fixed response patterns, unable to adapt to different debate styles or learn from past interactions.Third, most platforms lack sophisticated planning capabilities needed to anticipate and effectively counter opponent arguments.These limitations result in debate experiences that, while technologically advanced, fail to provide the dynamic, adaptive, and educational interaction necessary for meaningful debate practice.DebateBrawl addresses these fundamental challenges through a novel integration of three complementary technologies: LLMs for natural language understanding and generation, Genetic Algorithms for strategic evolution and adaptation, and Adversarial Search for predictive planning and counterargument generation.</p>
<p>The development of transformer-based language models, based on GPT architectures, has marked a paradigm shift in natural language processing [1].These models, trained on vast corpora of text, have demonstrated remarkable capabilities in generating coherent, context-aware text across diverse domains.However, while LLMs excel at generating fluent and contextually relevant responses, they often lack the strategic depth and adaptability required for nuanced, multi-turn debates.This limitation stems from their fundamentally reactive nature, where responses are generated based on immediate context rather than long-term strategic planning [2].</p>
<p>DebateBrawl addresses this challenge by incorporating genetic algorithms and adversarial search techniques.Genetic algorithms, inspired by natural selection and evolution, have proven effective in optimizing complex, multi-dimensional problems [3].In the context of debate, GAs evolve and refine argumentation strategies over time, adapting to the specific topic, opponent, and flow of the debate.This evolutionary approach allows the system to discover and hone effective combinations of rhetorical devices, logical structures, and persuasive techniques.</p>
<p>Adversarial search provides a framework for anticipating and planning responses to potential counterarguments [4].By simulating possible debate trajectories and evaluating their outcomes, AS enables the system to make more informed decisions about argument selection and presentation.In De-bateBrawl, this is made possible through a debate move predictor that anticipates opponent strategies and suggests effective counter-moves.The synergy between GAs and AS creates a debate engine that can not only generate coherent arguments but also strategically plan its approach to maximize persuasiveness and effectiveness.The integration of LLMs, GAs, and AS in DebateBrawl represents a significant advancement in AI-assisted argumentation systems.Previous work in this field has primarily focused on argument mining [5], stance detection [6], and automated fact-checking [7].While these approaches have made valuable contributions to computational argumentation, they often operate on a more granular level, focusing on individual arguments or claims rather than the holistic process of debate.DebateBrawl builds upon these foundations but takes a more comprehensive approach, addressing the full lifecycle of a debate from argument generation to strategic planning and adaptive response.</p>
<p>The development of DebateBrawl is motivated by the growing recognition of the importance of critical thinking and argumentation skills in education and public discourse.In an era characterized by information overload and rapid spread of misinformation, the ability to construct, analyze, and evaluate arguments is more crucial than ever [8].Traditional debate training methods, while valuable, are often limited by resource constraints and the availability of skilled human opponents and coaches.</p>
<p>II. RELATED WORKS</p>
<p>The integration of Large Language Models (LLMs) with evolutionary algorithms and other optimization techniques has proved to be a promising area of research, offering new possibilities for improving AI systems' capabilities across various domains.This section explores the diverse applications and methodologies that combine LLMs with evolutionary computation, genetic algorithms, and other optimization strategies.</p>
<p>A. Evolutionary Algorithms and LLMs</p>
<p>The synergy between evolutionary algorithms (EAs) and LLMs has been explored in several studies, showcasing the potential for improved optimization and problem-solving capabilities.Liu et al. [9] introduced LLM-driven Evolutionary Algorithms (LMEA), a novel approach that uses LLMs as evolutionary combinatorial optimizers.Their work demonstrates that LLMs can be effectively used to select parent solutions, perform crossover and mutation operations, and generate offspring solutions with minimal domain knowledge and human intervention.The authors applied LMEA to classical traveling salesman problems (TSPs), showing competitive performance compared to traditional heuristics for instances with up to 20 nodes.</p>
<p>In a related study, Chao et al. [10] explored the parallels between LLMs and EAs, identifying common characteristics such as token representation and individual representation, position encoding and fitness shaping, and model training and parameter adaptation.The authors analyzed existing interdisciplinary research, focusing on evolutionary fine-tuning and LLM-enhanced EAs.</p>
<p>B. LLMs in Game Design and Creative Tasks</p>
<p>The application of LLMs in creative tasks, such as game design, has also been explored.Lanzi and Loiacono [11] presented a collaborative game design framework that combines interactive evolution and LLMs to simulate the human design process.Their approach uses an interactive genetic algorithm to exploit user feedback for selecting promising ideas, while LLMs are employed for the complex creative task of recombining and varying ideas.This framework demonstrates the potential of LLMs in augmenting human creativity and facilitating collaborative design processes.</p>
<p>C. LLMs in Decision-Making and Planning</p>
<p>Several studies have investigated the use of LLMs in decision-making and planning tasks.Zhou et al. [12] introduced Language Agent Tree Search (LATS), a framework that integrates Monte Carlo Tree Search with LLMs to enable more effective reasoning, acting, and planning.LATS uses the in-context learning ability of LLMs and incorporates LMpowered value functions and self-reflections for proficient exploration and improved decision-making.The framework demonstrated state-of-the-art performance in various domains, including programming, interactive question-answering, web navigation, and math problems.</p>
<p>Similarly, Wan et al. [13] proposed an AlphaZero-like treesearch learning framework for LLMs (TS-LLM), which uses a learned value function to guide LLM decoding.Their approach is adaptable to a wide range of tasks, language models of various sizes, and tasks with varying search depths.TS-LLM showed improved performance in reasoning, planning, alignment, and decision-making tasks, demonstrating the potential of combining tree search algorithms with LLMs for improved problem-solving capabilities.</p>
<p>D. LLMs in Recommender Systems</p>
<p>The integration of LLMs into recommender systems has been explored to improve user interaction and personalization.Friedman et al. [14] proposed a roadmap for building large-scale conversational recommender systems using LLMs.Their work addresses challenges in understanding user preferences and dialogue management by introducing RecLLM, a YouTube video-based conversational recommender system that facilitates natural conversations and personalized recommendations.</p>
<p>E. LLMs in Neural Architecture Search and Model Optimization</p>
<p>The application of LLMs and evolutionary techniques in optimizing neural network architectures has been an area of active research.Sarah et al. [15] proposed an effective method for finding Pareto-optimal network architectures based on LLaMA2-7B using one-shot Neural Architecture Search (NAS).Their approach combines fine-tuning with genetic algorithm-based search to identify smaller, less computationally complex network architectures.The study demonstrated significant reductions in model size and improvements in throughput for certain tasks, with minimal accuracy loss.</p>
<p>Zhong et al. [16] introduced a novel LLM-assisted optimizer (LLMO) for addressing adversarial robustness in neural architecture search (ARNAS).Their approach uses the Gemini LLM to generate solutions for ARNAS instances, demonstrating competitive performance compared to well-known metaheuristic algorithms.This research highlights the potential of LLMs as effective combinatorial optimizers in the context of neural architecture design and optimization.</p>
<p>F. LLMs in Molecular Design and Materials Science</p>
<p>The application of generative models, including LLMs, in drug discovery and materials science has shown promise in overcoming limitations of traditional inverse design methods.Bhowmik et al. [17] examined the effectiveness of generative models in creating virtual libraries of molecules and facilitating drug discovery.The authors proposed a hybrid architecture combining masked language models with generative adversarial networks (GANs) to efficiently generate new molecules.</p>
<p>G. Explainable AI and LLMs in Genetic Programming</p>
<p>The integration of explainable AI (XAI) techniques with genetic programming and LLMs has been explored to improve the interpretability of complex algorithms.Maddigan et al. [18] introduced GP4NLDR, an XAI dashboard that combines genetic programming with an LLM-powered chatbot to provide comprehensive, user-centered explanations for nonlinear dimensionality reduction.Their study demonstrates the potential of using LLMs to generate intuitive and insightful narratives about high-dimensional data reduction processes, while also addressing important considerations such as data privacy and the challenges of hallucinatory outputs from LLMs.</p>
<p>H. LLMs in Artificial Evolutionary Intelligence</p>
<p>The concept of Artificial Evolutionary Intelligence (AEI), which combines evolutionary computation with artificial general intelligence, has been proposed as a promising direction for future research.He et al. [19] discussed a paradigm of LLMs for evolutionary computation, addressing three main issues: multi-modal representation capability, general models for versatile learning, and the ability to understand evolutionary computation concepts and behaviors.</p>
<p>I. Challenges and Ethical Considerations</p>
<p>While the integration of LLMs with evolutionary and optimization techniques shows great promise, it also raises important challenges and ethical considerations.Gaudi [20] conducted a comprehensive survey on adversarial aspects in LLMs, discussing issues such as harmful generation, fairness, privacy, and robustness.The study highlights the need for adversarial training techniques, fine-tuning methods, and mitigation strategies to address these challenges.</p>
<p>Zhang et al. [21] provided a comprehensive study on knowledge editing for LLMs, proposing a unified categorization criterion for knowledge editing methods.Their work introduces a new benchmark, KnowEdit, for evaluating knowledge editing approaches and discusses potential applications and implications of this technology.This research underscores the importance of developing methods to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs.</p>
<p>The integration of LLMs with evolutionary algorithms and optimization techniques represents a rapidly evolving and promising field of research.From healthcare applications to game design, from molecular modeling to neural architecture search, LLMs are being combined with various computational techniques to improve problem-solving capabilities, improve decision-making processes, and generate novel solutions across diverse domains.As this field continues to develop, addressing ethical considerations, improving explainability, and optimizing performance on resource-constrained hardware will be crucial areas of focus for future research.</p>
<p>III. METHODOLOGY</p>
<p>The DebateBrawl system represents an innovative approach to AI-powered debate platforms, integrating advanced natural language processing techniques with adaptive learning algorithms.This section provides a detailed overview of the system architecture, key components, and methodologies employed in the development and implementation of DebateBrawl.</p>
<p>A. System Architecture</p>
<p>DebateBrawl employs a client-server architecture, designed for modularity, scalability, and efficiency.Figure 1 illustrates the overall system architecture.The system is divided into frontend and backend components, connected through well-defined APIs.This separation allows for independent development and scaling of each component.The architecture is designed to handle multiple concurrent debates while maintaining low latency and high throughput, crucial for a responsive and engaging user experience.</p>
<p>1) Frontend Architecture: The frontend of DebateBrawl is built using Next.js, a React-based framework that provides server-side rendering capabilities and optimized performance.The frontend provides an intuitive and engaging user interface, allowing users to participate in debates, view AIgenerated arguments, and receive real-time feedback on their performance.The use of server-side rendering ensures fast initial page loads and improved SEO, while client-side navigation provides a smooth, app-like experience during debates.</p>
<p>2) Backend Architecture: The backend of DebateBrawl is powered by FastAPI, a modern, high-performance web framework for building APIs with Python.Figure 3 illustrates the backend architecture.allows for easy integration of different LLMs and simplifies the process of generating and evaluating arguments.</p>
<p>The backend architecture is designed to handle multiple concurrent debates while maintaining low latency and high throughput.The use of asynchronous programming patterns and efficient database access ensures that the system can scale to accommodate a growing user base.</p>
<p>B. Large Language Models (LLMs)</p>
<p>DebateBrawl uses multiple LLMs to generate diverse and contextually relevant responses.The system integrates three main models:</p>
<p>• LLaMA Model: Used for generating debate topics, arguments, and evaluating argument quality.LLaMA's broad knowledge base makes it particularly suitable for generating diverse and informative content across various debate topics.• Gemma Model: Specialized in generating AI opponent responses.Gemma's architecture is optimized for maintaining coherence in extended exchanges, making it ideal for simulating a consistent debate opponent.</p>
<p>• Phi Model: Focused on providing debate assistant responses and feedback.Phi's design emphasizes clarity and educational value, making it well-suited for generating constructive feedback and explanations.</p>
<p>Figure 4 illustrates the LLM Interface and its interactions with the various models and functionalities.The LLM Interface serves as an abstraction layer, allowing seamless integration and interaction with these models.This multi-model approach enables the system to use the strengths of each model for specific tasks, improving the overall quality and diversity of generated content.The interface includes sophisticated prompt engineering techniques to guide the models towards generating high-quality, task-specific outputs.</p>
<p>C. Genetic Algorithm (GA) for Strategy Evolution</p>
<p>The GA Strategy Evolver is a crucial component that adapts and optimizes debate strategies over time.Figure 5 illustrates the GA process flow.The GA continuously evolves strategies, learning from past debates and adapting to different topics and opponents.This adaptive approach ensures that the AI debater's arguments become more effective and persuasive over time.</p>
<p>D. Adversarial Search (AS) for Move Prediction</p>
<p>The AS Move Predictor uses game theory principles to anticipate opponent moves and plan counter-arguments.Figure 6 illustrates the AS process flow.Carlo Tree Search (MCTS) algorithm to explore the game tree and select the best move.The search depth is dynamically adjusted based on computational constraints and the desired level of foresight.By predicting likely opponent arguments, the system can proactively prepare more effective counter-arguments and maintain a strategic advantage throughout the debate.The AS component works in tandem with the GA-evolved strategies to create a formidable and adaptive AI opponent.</p>
<p>E. Debate Flow and Argument Generation</p>
<p>The debate process in DebateBrawl follows a structured flow, designed to create an engaging and educational experience for users.The key steps include:</p>
<p>1) Topic Selection: Users choose from pre-generated debate topics or request a new topic generated by the LLaMA model.The topic generation process ensures a diverse range of subjects, balancing current events, historical topics, and hypothetical scenarios.2) Position Assignment: Users select their position (for or against) on the chosen topic.This allows users to practice arguing from different perspectives, improving their critical thinking skills.3) Argument Submission: Users and the AI take turns submitting arguments.Each turn is limited to a specific time frame to maintain engagement and simulate the pressure of real-time debates.4) Argument Evaluation: Each argument is evaluated based on relevance, persuasiveness, and logical consistency using a combination of LLM-based analysis and pre-defined rubrics.5) Strategy Adaptation: The GA evolves strategies based on the effectiveness of arguments and overall debate performance.6) Move Prediction: The AS predicts the opponent's next move to inform the AI's response, creating more dynamic and realistic exchanges.7) Feedback Generation: The system provides real-time feedback and suggestions to users for improving their arguments, fostering learning and skill development.Figure 7 illustrates the detailed sequence of interactions between the user, frontend, backend, and various AI components during a debate session.The debate flow sequence proceeds as follows:</p>
<p>1) The user initiates a debate through the frontend interface.</p>
<p>2) The frontend sends a POST request to the backend to start the debate.</p>
<p>3) The backend initializes the debate, including setting up the GA Strategy Evolver and AS Move Predictor.</p>
<p>4) The backend returns a debate ID to the frontend, which then displays the debate UI to the user.5) The debate enters a loop of rounds, where:</p>
<p>• The user submits an argument through the frontend.</p>
<p>• The frontend sends the argument to the backend.</p>
<p>• The backend generates an AI response using the LLM Interface.• The GA Strategy Evolver updates its strategies based on the debate progress.• The AS Move Predictor anticipates the next user move.</p>
<p>• The backend sends the AI response, feedback, and scores back to the frontend.• The frontend displays the AI response and feedback to the user.6) Once the debate concludes, the frontend requests the final debate state from the backend.7) The backend returns the final state, which the frontend uses to display the debate results to the user.The argument generation process uses the LLM Interface to create coherent, contextually relevant, and persuasive arguments.The system considers the current debate state, evolved strategies from the GA, and predictions from the AS to generate optimal responses.</p>
<p>F. Evaluation and Feedback Mechanism</p>
<p>DebateBrawl implements a comprehensive evaluation and feedback system to assess argument quality and provide constructive feedback to users.The evaluation process considers multiple factors:</p>
<p>• Relevance: How well the argument addresses the debate topic and responds to previous points.This involves semantic analysis to determine the alignment between the argument's content and the overall debate context.• Persuasiveness: The strength and impact of the argument in supporting the debater's position.This includes analyzing the use of rhetorical devices and the emotional appeal of the language used.• Logical Consistency: The coherence and validity of the reasoning presented.This involves identifying logical fallacies and assessing the strength of causal relationships presented in the argument.• Evidence Usage: The effective incorporation of facts, examples, or expert opinions to support claims.This includes verifying the credibility of sources cited and the relevance of the evidence to the argument.The evaluation feedback is generated using a combination of LLM-based analysis and pre-defined rubrics.This feedback helps users understand the strengths and weaknesses of their arguments, promoting learning and skill development.</p>
<p>G. Data Management and Security</p>
<p>DebateBrawl prioritizes data security and efficient management through the use of Firebase for user authentication and Firestore for data storage.Key considerations include:</p>
<p>• Secure authentication flows using Firebase Auth, supporting multiple authentication methods.• Role-based access control for different user types, ensuring that users only have access to appropriate data and functionalities.• Encrypted storage of sensitive user information and debate content, both in transit and at rest.• Efficient indexing and querying of debate data for performance optimization, ensuring fast retrieval of relevant information.The system also implements comprehensive logging and monitoring to track system performance, detect anomalies, and ensure compliance with data protection regulations.</p>
<p>In conclusion, the methodology behind DebateBrawl represents a comprehensive and innovative approach to AI-assisted debate platforms.By integrating advanced language models with adaptive learning algorithms and game theory principles, and focusing on user engagement and skill development, DebateBrawl aims to provide a unique and valuable tool for improving critical thinking and argumentation skills</p>
<p>IV. EXPERIMENTAL RESULTS</p>
<p>To evaluate the effectiveness of the DebateBrawl system, which integrates Large Language Models (LLMs) with Genetic Algorithms (GA) and Adversarial Search (AS) for adaptive debate arguments, we conducted a series of experiments.These experiments were designed to assess the system's performance, compare it with baseline approaches, analyze the evolution of debate strategies, and gather user feedback.</p>
<p>A. Performance Metrics of the Integrated System</p>
<p>The DebateBrawl system's performance was evaluated across multiple debates on various topics.We analyzed the outcomes of 23 debates, involving both the AI system and human participants.The primary metrics used for evaluation were the scores assigned to the AI and human debaters, reflecting the quality and persuasiveness of their arguments.Fig. 8 illustrates the distribution of AI versus User scores across all debates.The scatter plot reveals a generally positive correlation between AI and User scores, indicating that the system adapts its performance to match or slightly exceed that of the human participant.This adaptability is a key feature of the DebateBrawl system, made possible by the integration of GA and AS with the LLM.</p>
<p>Further analysis of the performance metrics reveals interesting insights into the system's capabilities.The average scores for both AI and human participants were calculated across all debates:</p>
<p>• Average AI Score: 2.72 (out of a possible 10)</p>
<p>• Average User Score: 2.67 (out of a possible 10) These scores indicate that, on average, the AI system performed slightly better than human participants, although the difference is minimal.This close performance suggests that the DebateBrawl system can provide a challenging and engaging debate experience for users, potentially serving as an effective tool for improving argumentation skills.</p>
<p>B. Comparison with Baseline Systems</p>
<p>To contextualize the performance of the DebateBrawl system, we compared it with two baseline approaches: an LLMonly system and human-only debates.</p>
<p>1) Comparison with LLM-only System: A series of debates were conducted using an LLM-only system, which lacked the adaptive capabilities provided by the GA and AS components.The results showed that the DebateBrawl system outperformed the LLM-only approach in several key areas: Table I summarizes the performance comparison between the DebateBrawl system and the LLM-only system.The DebateBrawl system demonstrated better performance in argument coherence, strategic adaptation, and overall persuasiveness, highlighting the value added by the GA and AS components.</p>
<p>2) Comparison with Human-only Debates: We also compared the DebateBrawl-mediated debates with traditional human-only debates on similar topics.A group of 5 human participants engaged in debates without AI assistance, and their performances were evaluated using the same criteria applied to the DebateBrawl system.</p>
<p>Table II presents a comparative analysis of DebateBrawlmediated debates versus human-only debates.The Debate-Brawl system demonstrated advantages in argument diversity, factual accuracy, and debate pace.Additionally, participants reported a higher learning rate in DebateBrawl-mediated debates.</p>
<p>C. Analysis of Strategy Evolution over Multiple Debates</p>
<p>One of the key features of the DebateBrawl system is its ability to evolve debate strategies using Genetic Algorithms.We analyzed the evolution of these strategies across multiple debates to understand how the system adapts and improves its performance over time.</p>
<p>Fig. 9 illustrates the effectiveness of different GA-evolved strategies in terms of average user scores.The data reveals several interesting trends:</p>
<p>1) Emphasis on Pathos: The most successful strategies tend to place a greater emphasis on pathos (emotional appeal) compared to ethos (credibility) and logos (logical reasoning).2) Balanced Approach: While pathos is dominant, the topperforming strategies maintain a balance between all three elements of persuasion.3) Adaptability: The variety of successful strategies demonstrates the system's ability to adapt to different debate topics and opponents.4) Evolution Over Time: Analysis of strategy evolution across consecutive debates showed a general trend towards more refined and effective strategies.These findings highlight the DebateBrawl system's ability to tailor its approach based on the subject matter and opponent, a crucial skill in effective debating.</p>
<p>D. User Feedback and Experience Analysis</p>
<p>To gain insights into the user experience and perceived effectiveness of the DebateBrawl system, we conducted surveys and interviews with participants after their engagement with the platform.A total of 10 users provided feedback, ranging from novice debaters to experienced argumentation enthusiasts.Table III summarizes the key findings from user feedback.The high positive response rates across various aspects indicate that users found the DebateBrawl system to be an effective and engaging tool for improving their debate skills.</p>
<p>Authorized licensed use limited to the terms of the applicable license agreement with IEEE.Restrictions apply.Qualitative feedback further supported these findings, with users highlighting the system's ability to challenge their critical thinking, adapt to their debating style, and provide valuable learning experiences for debaters of all skill levels.</p>
<p>E. User Interface and Interaction</p>
<p>To provide a comprehensive view of the DebateBrawl system's functionality and user experience, we present key screenshots from the application interface.</p>
<p>1) Debate Interface: Figure 10 shows the main debate interface of DebateBrawl.</p>
<p>This interface displays the current debate topic, round information, and areas for user input and AI responses.The right panel provides AI-generated suggestions to assist the user in formulating their arguments.</p>
<p>2) AI Argument Generation: Figure 11 demonstrates an example of an AI-generated argument in the DebateBrawl system.</p>
<p>This sample shows how the AI constructs a coherent and structured argument, addressing multiple aspects of the debate topic.</p>
<p>3) Evaluation Feedback: Figure 12 illustrates the evaluation feedback provided by the system.</p>
<p>The feedback covers various aspects of the argument, including strength, relevance, and persuasiveness, providing users with constructive criticism to improve their debating skills.This interface demonstrates how the GA suggests debate strategies and the AS predicts the next move, improving the AI's adaptability and strategic thinking.</p>
<p>4) GA and AS Integration:</p>
<p>These interface elements collectively demonstrate the comprehensive and user-friendly nature of the DebateBrawl system, highlighting its potential as an effective tool for debate practice and skill development.</p>
<p>The experimental results demonstrate the DebateBrawl system's effectiveness in generating adaptive and persuasive debate arguments.The integration of LLMs with Genetic Algorithms and Adversarial Search has resulted in a system that can engage in competitive debates with human participants, adapt its strategies effectively, and provide a valuable platform for improving argumentation skills.</p>
<p>V. CONCLUSION</p>
<p>The DebateBrawl system opens up numerous pathway for future research and development in AI-assisted argumentation and education.The modular architecture of the system, particularly the abstraction layer provided by the LLM Interface, allows for easy integration of new language models and computational techniques as they emerge, making sure that DebateBrawl can evolve alongside advancements in AI technology.Future work could explore the integration of multimodal inputs and outputs, enabling the system to Authorized licensed use limited to the terms of the applicable license agreement with IEEE.Restrictions apply.Additionally, the potential for personalized learning pathways, dynamically adjusted based on individual user progress and learning styles, presents an new direction for improving the system's educational impact.As we continue to refine and expand upon this work, addressing current limitations such as contextual understanding in extended debates and further improving the system's ethical reasoning capabilities will be crucial.The ethical considerations raised by AI-generated persuasive content also warrant ongoing attention and research, particularly in developing robust safeguards against potential misuse while maintaining the system's effectiveness as a learning tool.Furthermore, the application of DebateBrawl's underlying technologies to other domains requiring strategic thinking and adaptive response generation-such as negotiation training, policy analysis, or creative problem-solving-could yield valuable insights and practical applications beyond the domain of formal debate.</p>
<p>Ultimately, the DebateBrawl system not only serves as a powerful tool for improving individual argumentation skills but also contributes to the broader goal of providing more informed, nuanced, and constructive public discourse in an era of complex global challenges.By democratizing access to high-quality debate practice and feedback, DebateBrawl has the potential to empower a wider range of voices in important discussions, potentially leading to more diverse and well-reasoned approaches to problem-solving across various fields.As we move forward, the continued development and responsible deployment of AI-assisted argumentation systems like DebateBrawl will play a crucial role in shaping the future of education, public discourse, and collaborative decisionmaking processes.</p>
<p>Fig. 1 .
1
Fig. 1.Overall System Architecture of DebateBrawl</p>
<p>Figure 2
2
details the frontend architecture.</p>
<p>Fig. 2 .
2
Fig. 2. Frontend Architecture of DebateBrawl Key components of the frontend include: • Chakra UI: A component library used for building the user interface, ensuring a consistent and responsive design across devices.Chakra UI's modular approach allows for rapid development and easy customization of UI elements.• TypeScript: Employed for improved type safety and improved developer experience.TypeScript's static typing helps catch errors early in the development process and improves code maintainability.• Firebase Auth: Integrated for secure user authentication and authorization.This component handles user sign-up, login, and session management, ensuring secure access to the platform.• API Client: A custom module handling communication with the backend API.This module encapsulates all API calls, handling request formatting, response parsing, and error management.• Debate State Management: Manages the state of ongoing debates.This component uses React's Context API and hooks to provide a centralized state management solution, ensuring that all components have access to the current debate state.• User Management: Handles user-related functionalities, including profile management, debate history tracking, and performance analytics.</p>
<p>Fig. 3 .
3
Fig. 3. Backend Architecture of DebateBrawl</p>
<p>Fig. 4 .
4
Fig. 4. LLM Interface and Model Interactions</p>
<p>Fig. 5 . 2 )
52
Fig. 5. Genetic Algorithm Process Flow</p>
<p>Fig. 6 . 4 )
64
Fig. 6.Adversarial Search Process Flow The AS implementation involves: 1) State Representation: Model the current debate state, including past arguments, topic context, and relevant metadata.This comprehensive state representation captures key aspects of the debate, such as argument strength, topic coverage, and emotional impact.2) Move Generation: Generate possible next moves or arguments for both the AI and the opponent.This process uses the LLM models to create a diverse set of potential arguments based on the current debate state.3) Evaluation Function: Assess the strength and potential impact of each possible move.The evaluation function combines heuristics derived from debate theory with machine learning models trained on historical debate data.4) Search Algorithm: Implement a minimax or MonteCarlo Tree Search (MCTS) algorithm to explore the game tree and select the best move.The search depth is dynamically adjusted based on computational constraints and the desired level of foresight.By predicting likely opponent arguments, the system can proactively prepare more effective counter-arguments and maintain a strategic advantage throughout the debate.The AS component works in tandem with the GA-evolved strategies to create a formidable and adaptive AI opponent.</p>
<p>Fig. 7 .
7
Fig. 7. Debate Flow Sequence Diagram</p>
<p>Fig. 8 .
8
Fig. 8. AI vs User Performance in Debates</p>
<p>Fig. 9 .
9
Fig. 9. Average User Score by GA Strategy: Comparison of Different Strategic Approaches</p>
<p>Figure 13
13
shows how the Genetic Algorithm (GA) and Adversarial Search (AS) components are integrated into the debate process.</p>
<p>Fig. 10 .
10
Fig. 10.DebateBrawl Main Debate Interface: Interactive Platform Showing Topic Selection, User Input Area, and AI Response Section</p>
<p>Authorized licensed use limited to the terms of the applicable license agreement with IEEE. Restrictions apply.</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, arXiv:2005.141652020arXiv preprint</p>
<p>On the dangers of stochastic parrots: Can language models be too big?. E M Bender, T Gebru, A Mcmillan-Major, S Shmitchell, Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. the 2021 ACM Conference on Fairness, Accountability, and Transparency2021</p>
<p>Authorized licensed use limited to the terms of the applicable license agreement with IEEE. Restrictions apply. Fig. 11. Example of AI-Generated Argument Fig. M Mitchell, 1998MIT press12Evaluation Feedback Sample</p>
<p>Artificial intelligence: a modern approach. S J Russell, P Norvig, 2010Pearson Education Limited</p>
<p>Argument mining: A survey. J Lawrence, C Reed, Computational Linguistics. 4642020</p>
<p>Stance detection: A survey. D Küc ¸ük, F Can, ACM Computing Surveys (CSUR). 5312020</p>
<p>The fact extraction and verification (fever) shared task. J Thorne, A Vlachos, C Christodoulopoulos, A Mittal, Proceedings of the First Workshop on Fact Extraction and VERification (FEVER). the First Workshop on Fact Extraction and VERification (FEVER)2018</p>
<p>Learning to engage in scientific argumentation. D Kuhn, A Modrek, W Sandoval, E Ruzek, Contemporary Educational Psychology. 582019</p>
<p>GA Strategy Suggestion and AS Prediction. </p>
<p>Large language models as evolutionary optimizers. S Liu, C Chen, X Qu, K Tang, Y S Ong, IEEE Congress on Evolutionary Computation. 2024. 2024CEC 2024 -Proceedings</p>
<p>When large language models meet evolutionary algorithms. W Chao, J Zhao, L Jiao, L Li, F Liu, S Yang, 2024</p>
<p>Chatgpt and other large language models as evolutionary engines for online interactive collaborative game design. P L Lanzi, D Loiacono, 10.1145/3583131.3590351GECCO 2023 -Proceedings of the 2023 Genetic and Evolutionary Computation Conference. 7 2023</p>
<p>Language agent tree search unifies reasoning acting and planning in language models. A Zhou, K Yan, M Shlapentokh-Rothman, H Wang, Y X Wang, Proceedings of Machine Learning Research. Machine Learning Research10 2023235</p>
<p>Alphazero-like tree-search can guide large language model decoding and training. Z Wan, X Feng, M Wen, S M Mcaleer, Y Wen, W Zhang, J Wang, Proceedings of Machine Learning Research. Machine Learning Research9 2023235920</p>
<p>Leveraging large language models in conversational recommender systems. L Friedman, S Ahuja, D Allen, Z Tan, H Sidahmed, C Long, J Xie, G Schubiner, A Patel, H Lara, B Chu, Z Chen, M Tiwari, G Research, 2023</p>
<p>Llama-nas: Efficient neural architecture search for large language models. A Sarah, S N Sridhar, M Szankin, S Sundaresan, 2024</p>
<p>Large language model assisted adversarial robustness neural architecture search. R Zhong, Y Cao, J Yu, M Munetomo, 2024</p>
<p>Enhancing molecular design efficiency: Uniting language models and generative networks with genetic algorithms. D Bhowmik, P Zhang, Z Fox, S Irle, J Gounley, Patterns. 54 2024</p>
<p>Explaining genetic programming trees using large language models. P Maddigan, A Lensen, B Xue, 2024</p>
<p>Artificial evolutionary intelligence (aei): Evolutionary computation evolves with large language models. C He, Y Tian, Z Lu, Online</p>
<p>All things adversarial in llms: A survey. S Gaudi, </p>
<p>A comprehensive study of knowledge editing for large language models. N Zhang, Y Yao, B Tian, P Wang, S Deng, M Wang, Z Xi, S Mao, J Zhang, Y Ni, S Cheng, Z Xu, X Xu, J.-C Gu, Y Jiang, P Xie, F Huang, L Liang, Z Zhang, X Zhu, J Zhou, H Chen, 2024</p>            </div>
        </div>

    </div>
</body>
</html>