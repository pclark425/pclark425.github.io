<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9521 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9521</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9521</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-279070481</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.23789v1.pdf" target="_blank">Conversational Exploration of Literature Landscape with LitChat</a></p>
                <p><strong>Paper Abstract:</strong> We are living in an era of"big literature", where the volume of digital scientific publications is growing exponentially. While offering new opportunities, this also poses challenges for understanding literature landscapes, as traditional manual reviewing is no longer feasible. Recent large language models (LLMs) have shown strong capabilities for literature comprehension, yet they are incapable of offering"comprehensive, objective, open and transparent"views desired by systematic reviews due to their limited context windows and trust issues like hallucinations. Here we present LitChat, an end-to-end, interactive and conversational literature agent that augments LLM agents with data-driven discovery tools to facilitate literature exploration. LitChat automatically interprets user queries, retrieves relevant sources, constructs knowledge graphs, and employs diverse data-mining techniques to generate evidence-based insights addressing user needs. We illustrate the effectiveness of LitChat via a case study on AI4Health, highlighting its capacity to quickly navigate the users through large-scale literature landscape with data-based evidence that is otherwise infeasible with traditional means.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9521.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9521.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LitChat (GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LitChat conversational literature agent using GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end, conversational literature exploration system that uses GPT-4o LLM agents to (i) design search queries and interact with users and (ii) select and orchestrate data-driven discovery tools (e.g., topic modeling, bibliographic knowledge graph analysis, and a 'scientific discovery' module) to synthesize evidence-based insights from large corpora of paper metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>The paper states LitChat uses GPT-4o for its two conversational agents (query design and tool selection/response generation). No model size, parameter count, or architecture details are provided in the paper; GPT-4o is described only by name and role (controller/dialogue agent), not as fine-tuned for qualitative-law extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Scientific literature exploration broadly; demonstrated in the AI4Health (applications of LLMs in healthcare) domain.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>For the AI4Health case study LitChat retrieved ≈3,700–3,789 papers from the Web of Science (WoS) via API; metadata fields include abstract, authors, venues, dates, citations. By default LitChat uses metadata (not full texts) unless PDFs are open access or uploaded by a user.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Thematic patterns and cross-domain research-idea inferences (i.e., identification of dominant research topics and inferred 'research ideas' or hidden patterns across the bibliographic knowledge graph).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>From topic modeling on the AI4Health corpus, LitChat identified major healthcare task clusters and their sizes, e.g., Named Entity Recognition (495 papers), Medical Image Segmentation (388 papers), Mental Health Consultation (289 papers), Medical Question-Answering (222 papers), Medical Education (198 papers). The paper frames such topic-size summaries as objective, transparent evidence about prevalent research themes.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>LLM-driven orchestration: (1) GPT-4o interprets the user's natural-language query and crafts boolean search strings; (2) system retrieves metadata via WoS API; (3) metadata are organized into a heterogeneous bibliographic knowledge graph (BKG) with node embeddings; (4) GPT-4o selects data-mining tools from a library (e.g., topic modeling/BERTtopic, graph analysis, and a 'scientific discovery' module cited to Krenn et al. and Bai et al.) to extract latent themes or hidden patterns; (5) results are composed into natural-language responses by filling templates. Retrieval-augmented generation (RAG) and standard summarization/QA pipelines are also supported for paper-level questions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Demonstration via a single case study (AI4Health): qualitative inspection of outputs, presentation of topic clusters and topic sizes, and interactive drill-down by user; no formal quantitative evaluation (e.g., no held-out ground truth of 'laws', no expert-annotated benchmark, no precision/recall metrics) reported for the extraction of qualitative laws or generalizable rules.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>The system successfully retrieved thousands of records (≈3.7k) and produced topic-level syntheses, a 2D literature landscape visualization, representative-paper recommendations, and topic summaries grounded in metadata. The paper highlights token-efficiency (LLMs are not asked to ingest full corpora) and improved transparency by reporting topic sizes. However, the paper does not present formal validation of any discovered 'laws' or generalizable principles — the outputs are demonstrated qualitatively in a case study and meant to be evidence-based via data-mining tools rather than claiming provable laws.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Qualitative comparison only: the paper contrasts LitChat with other LLM-based literature systems (Autosurvey, PaperQA2) and argues LitChat is more token-efficient because it does not prompt the LLM to ingest entire corpora; no quantitative benchmarking or performance numbers vs. baselines are provided for the task of extracting qualitative laws or rules.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Key limitations reported include: LLMs' limited context windows (making direct ingestion of full large corpora infeasible), reliance on metadata rather than full texts unless open access, copyright constraints on full-paper retrieval, and lack of formal evaluation procedures for discovered hypotheses or 'scientific discovery' outputs. The paper also notes that LitChat uses data-mining tools to mitigate some LLM weaknesses but does not claim elimination of those weaknesses.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>The paper explicitly cites hallucination and the black-box nature of LLMs as trust issues: LLMs are 'prone to hallucinations' which may lead to incorrect or misleading information violating 'objective' and 'transparent' principles. LitChat's design mitigates this by grounding outputs in data-driven analyses (topic modeling, BKG) and by exposing topic sizes and provenance, but no empirical assessment of hallucination rates for law/extraction tasks is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Conversational Exploration of Literature Landscape with LitChat', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9521.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9521.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Topic Modeling (BERTopic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Topic modeling (BERTopic / class-based TF–IDF procedure)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A data-mining technique applied to the bibliographic knowledge graph to uncover latent research themes and their temporal evolution; used in LitChat to cluster thousands of retrieved papers into interpretable topics and to quantify topic sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>N/A (selected and orchestrated by GPT-4o; topic modeling itself is a separate algorithm)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>The paper does not describe topic-model internals beyond referencing Grootendorst/BERTopic; topic modeling is treated as a non-LLM data-mining tool whose outputs are consumed and narrated by the LLM agent.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Applied to the AI4Health literature corpus to identify research task clusters (healthcare tasks using LLMs).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Same WoS-derived metadata corpus (≈3.7k papers); abstracts used as node attributes and transformed into embeddings (voyage-3-large 4 model was used to embed abstracts before topic modeling).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Thematic pattern identification (i.e., frequent co-occurring concepts and dominant research topics across the corpus).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Identification of 49 major healthcare topics involving LLMs with counts for several: Named entity recognition (495 papers), Medical image segmentation (388), Mental health consultation (289), Medical question-answering (222), Medical education (198).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Embeddings of paper abstracts were computed (voyage-3-large 4) and topic modeling (BERTopic referenced) was applied to cluster documents; GPT-4o then reported topic labels, sizes, visualized 2D layouts, and generated summaries grounded on representative papers from each topic.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>No formal evaluation of topic-model quality (no coherence scores, human labeling agreement metrics, or downstream validation) is reported; evaluation is demonstrated through qualitative case-study inspection and interactive exploration by users.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Topic modeling allowed LitChat to objectively report topic sizes and provide topic-level drill-downs and representative papers; this served as the principal mechanism for deriving generalizable thematic insights from a large corpus. The paper presents counts and visualizations but does not quantify topic-model accuracy or compare different topic-model algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No quantitative comparison to alternative theme-extraction methods is provided, though the paper situates topic modeling alongside other bibliometric analyses (e.g., citation networks) and contrasts LLM-centric methods that try to ingest entire corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Limitations include lack of full-text analysis when only metadata are available, no reported validation metrics for the topics, and dependence on embedding quality (voyage-3-large 4) and chosen clustering parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Topic modeling itself is not subject to 'hallucination' in the LLM sense, but the final narrative and summaries about topics are generated by GPT-4o and thus susceptible to hallucination or biased framing; the paper emphasizes grounding narratives in data (topic sizes, representative papers) to mitigate such risks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Conversational Exploration of Literature Landscape with LitChat', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9521.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9521.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scientific Discovery Module (cited)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scientific discovery / hidden-pattern inference module (as cited to Krenn et al., Bai et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced class of methods intended to learn hidden patterns in bibliographic knowledge graphs to infer cross-domain research ideas or higher-level hypotheses; described as one of the data-mining techniques available to LitChat for extracting insights that 'transcend individual knowledge'.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>N/A (module is a data-mining approach referenced in the paper; selection of the tool is made by GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Not described in detail in the paper; authors cite Krenn et al. (2023) and Bai et al. (2024) as related work on using link-prediction / knowledge-network-based discovery to forecast or infer future research directions.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General bibliometric/scientific discovery across literature landscapes; suggested applicability in cross-domain hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Presumably the constructed bibliographic knowledge graph derived from WoS metadata (nodes: papers, authors, keywords, citations; edges: citation, co-authorship, keyword co-occurrence); exact input sizes for this module are not specified beyond the case-study corpus scale.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Inferred research hypotheses or cross-domain 'research ideas' and hidden structural patterns in the knowledge graph (conceptually akin to emergent rules about research frontiers).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>No concrete example of a discovered qualitative law from this module is provided in the paper; the paper only states this module can 'infer meaningful research ideas that transcend existing individual knowledge and cross-domain boundaries'.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Described at a high level: the LLM agent can choose the 'scientific discovery' tool from its library and run it on the BKG to learn hidden patterns; specific algorithms (e.g., link prediction, graph-embedding-based hypothesis generation) are not detailed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not specified in the paper; no empirical validation or expert assessment of purported discoveries from this module is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>The paper lists 'scientific discovery' as an available capability but does not demonstrate concrete, validated discoveries or generalizable rules produced by this module in the presented case study.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No comparisons or baselines presented for this module within the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Paper does not provide implementation or validation details; therefore limitations include lack of specification, lack of presented outcomes, and absence of evaluation of correctness or novelty of inferred discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Because outputs from such graph-based inference would be narrated by GPT-4o, the paper warns that LLM narration can hallucinate or misrepresent inferred patterns; no module-specific hallucination analysis is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Conversational Exploration of Literature Landscape with LitChat', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Autosurvey <em>(Rating: 2)</em></li>
                <li>PaperQA2 <em>(Rating: 2)</em></li>
                <li>Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network <em>(Rating: 2)</em></li>
                <li>Retrieval-augmented generation for large language models: A survey <em>(Rating: 1)</em></li>
                <li>Survey of hallucination in natural language generation <em>(Rating: 1)</em></li>
                <li>BERTtopic: Neural topic modeling with a class-based TF-IDF procedure <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9521",
    "paper_id": "paper-279070481",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [
        {
            "name_short": "LitChat (GPT-4o)",
            "name_full": "LitChat conversational literature agent using GPT-4o",
            "brief_description": "An end-to-end, conversational literature exploration system that uses GPT-4o LLM agents to (i) design search queries and interact with users and (ii) select and orchestrate data-driven discovery tools (e.g., topic modeling, bibliographic knowledge graph analysis, and a 'scientific discovery' module) to synthesize evidence-based insights from large corpora of paper metadata.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_model_name": "GPT-4o",
            "llm_model_description": "The paper states LitChat uses GPT-4o for its two conversational agents (query design and tool selection/response generation). No model size, parameter count, or architecture details are provided in the paper; GPT-4o is described only by name and role (controller/dialogue agent), not as fine-tuned for qualitative-law extraction.",
            "application_domain": "Scientific literature exploration broadly; demonstrated in the AI4Health (applications of LLMs in healthcare) domain.",
            "input_corpus_description": "For the AI4Health case study LitChat retrieved ≈3,700–3,789 papers from the Web of Science (WoS) via API; metadata fields include abstract, authors, venues, dates, citations. By default LitChat uses metadata (not full texts) unless PDFs are open access or uploaded by a user.",
            "qualitative_law_type": "Thematic patterns and cross-domain research-idea inferences (i.e., identification of dominant research topics and inferred 'research ideas' or hidden patterns across the bibliographic knowledge graph).",
            "qualitative_law_example": "From topic modeling on the AI4Health corpus, LitChat identified major healthcare task clusters and their sizes, e.g., Named Entity Recognition (495 papers), Medical Image Segmentation (388 papers), Mental Health Consultation (289 papers), Medical Question-Answering (222 papers), Medical Education (198 papers). The paper frames such topic-size summaries as objective, transparent evidence about prevalent research themes.",
            "extraction_methodology": "LLM-driven orchestration: (1) GPT-4o interprets the user's natural-language query and crafts boolean search strings; (2) system retrieves metadata via WoS API; (3) metadata are organized into a heterogeneous bibliographic knowledge graph (BKG) with node embeddings; (4) GPT-4o selects data-mining tools from a library (e.g., topic modeling/BERTtopic, graph analysis, and a 'scientific discovery' module cited to Krenn et al. and Bai et al.) to extract latent themes or hidden patterns; (5) results are composed into natural-language responses by filling templates. Retrieval-augmented generation (RAG) and standard summarization/QA pipelines are also supported for paper-level questions.",
            "evaluation_method": "Demonstration via a single case study (AI4Health): qualitative inspection of outputs, presentation of topic clusters and topic sizes, and interactive drill-down by user; no formal quantitative evaluation (e.g., no held-out ground truth of 'laws', no expert-annotated benchmark, no precision/recall metrics) reported for the extraction of qualitative laws or generalizable rules.",
            "results_summary": "The system successfully retrieved thousands of records (≈3.7k) and produced topic-level syntheses, a 2D literature landscape visualization, representative-paper recommendations, and topic summaries grounded in metadata. The paper highlights token-efficiency (LLMs are not asked to ingest full corpora) and improved transparency by reporting topic sizes. However, the paper does not present formal validation of any discovered 'laws' or generalizable principles — the outputs are demonstrated qualitatively in a case study and meant to be evidence-based via data-mining tools rather than claiming provable laws.",
            "comparison_to_baseline": "Qualitative comparison only: the paper contrasts LitChat with other LLM-based literature systems (Autosurvey, PaperQA2) and argues LitChat is more token-efficient because it does not prompt the LLM to ingest entire corpora; no quantitative benchmarking or performance numbers vs. baselines are provided for the task of extracting qualitative laws or rules.",
            "reported_limitations": "Key limitations reported include: LLMs' limited context windows (making direct ingestion of full large corpora infeasible), reliance on metadata rather than full texts unless open access, copyright constraints on full-paper retrieval, and lack of formal evaluation procedures for discovered hypotheses or 'scientific discovery' outputs. The paper also notes that LitChat uses data-mining tools to mitigate some LLM weaknesses but does not claim elimination of those weaknesses.",
            "bias_or_hallucination_issues": "The paper explicitly cites hallucination and the black-box nature of LLMs as trust issues: LLMs are 'prone to hallucinations' which may lead to incorrect or misleading information violating 'objective' and 'transparent' principles. LitChat's design mitigates this by grounding outputs in data-driven analyses (topic modeling, BKG) and by exposing topic sizes and provenance, but no empirical assessment of hallucination rates for law/extraction tasks is reported.",
            "uuid": "e9521.0",
            "source_info": {
                "paper_title": "Conversational Exploration of Literature Landscape with LitChat",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Topic Modeling (BERTopic)",
            "name_full": "Topic modeling (BERTopic / class-based TF–IDF procedure)",
            "brief_description": "A data-mining technique applied to the bibliographic knowledge graph to uncover latent research themes and their temporal evolution; used in LitChat to cluster thousands of retrieved papers into interpretable topics and to quantify topic sizes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_model_name": "N/A (selected and orchestrated by GPT-4o; topic modeling itself is a separate algorithm)",
            "llm_model_description": "The paper does not describe topic-model internals beyond referencing Grootendorst/BERTopic; topic modeling is treated as a non-LLM data-mining tool whose outputs are consumed and narrated by the LLM agent.",
            "application_domain": "Applied to the AI4Health literature corpus to identify research task clusters (healthcare tasks using LLMs).",
            "input_corpus_description": "Same WoS-derived metadata corpus (≈3.7k papers); abstracts used as node attributes and transformed into embeddings (voyage-3-large 4 model was used to embed abstracts before topic modeling).",
            "qualitative_law_type": "Thematic pattern identification (i.e., frequent co-occurring concepts and dominant research topics across the corpus).",
            "qualitative_law_example": "Identification of 49 major healthcare topics involving LLMs with counts for several: Named entity recognition (495 papers), Medical image segmentation (388), Mental health consultation (289), Medical question-answering (222), Medical education (198).",
            "extraction_methodology": "Embeddings of paper abstracts were computed (voyage-3-large 4) and topic modeling (BERTopic referenced) was applied to cluster documents; GPT-4o then reported topic labels, sizes, visualized 2D layouts, and generated summaries grounded on representative papers from each topic.",
            "evaluation_method": "No formal evaluation of topic-model quality (no coherence scores, human labeling agreement metrics, or downstream validation) is reported; evaluation is demonstrated through qualitative case-study inspection and interactive exploration by users.",
            "results_summary": "Topic modeling allowed LitChat to objectively report topic sizes and provide topic-level drill-downs and representative papers; this served as the principal mechanism for deriving generalizable thematic insights from a large corpus. The paper presents counts and visualizations but does not quantify topic-model accuracy or compare different topic-model algorithms.",
            "comparison_to_baseline": "No quantitative comparison to alternative theme-extraction methods is provided, though the paper situates topic modeling alongside other bibliometric analyses (e.g., citation networks) and contrasts LLM-centric methods that try to ingest entire corpora.",
            "reported_limitations": "Limitations include lack of full-text analysis when only metadata are available, no reported validation metrics for the topics, and dependence on embedding quality (voyage-3-large 4) and chosen clustering parameters.",
            "bias_or_hallucination_issues": "Topic modeling itself is not subject to 'hallucination' in the LLM sense, but the final narrative and summaries about topics are generated by GPT-4o and thus susceptible to hallucination or biased framing; the paper emphasizes grounding narratives in data (topic sizes, representative papers) to mitigate such risks.",
            "uuid": "e9521.1",
            "source_info": {
                "paper_title": "Conversational Exploration of Literature Landscape with LitChat",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Scientific Discovery Module (cited)",
            "name_full": "Scientific discovery / hidden-pattern inference module (as cited to Krenn et al., Bai et al.)",
            "brief_description": "A referenced class of methods intended to learn hidden patterns in bibliographic knowledge graphs to infer cross-domain research ideas or higher-level hypotheses; described as one of the data-mining techniques available to LitChat for extracting insights that 'transcend individual knowledge'.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "llm_model_name": "N/A (module is a data-mining approach referenced in the paper; selection of the tool is made by GPT-4o)",
            "llm_model_description": "Not described in detail in the paper; authors cite Krenn et al. (2023) and Bai et al. (2024) as related work on using link-prediction / knowledge-network-based discovery to forecast or infer future research directions.",
            "application_domain": "General bibliometric/scientific discovery across literature landscapes; suggested applicability in cross-domain hypothesis generation.",
            "input_corpus_description": "Presumably the constructed bibliographic knowledge graph derived from WoS metadata (nodes: papers, authors, keywords, citations; edges: citation, co-authorship, keyword co-occurrence); exact input sizes for this module are not specified beyond the case-study corpus scale.",
            "qualitative_law_type": "Inferred research hypotheses or cross-domain 'research ideas' and hidden structural patterns in the knowledge graph (conceptually akin to emergent rules about research frontiers).",
            "qualitative_law_example": "No concrete example of a discovered qualitative law from this module is provided in the paper; the paper only states this module can 'infer meaningful research ideas that transcend existing individual knowledge and cross-domain boundaries'.",
            "extraction_methodology": "Described at a high level: the LLM agent can choose the 'scientific discovery' tool from its library and run it on the BKG to learn hidden patterns; specific algorithms (e.g., link prediction, graph-embedding-based hypothesis generation) are not detailed in the paper.",
            "evaluation_method": "Not specified in the paper; no empirical validation or expert assessment of purported discoveries from this module is provided.",
            "results_summary": "The paper lists 'scientific discovery' as an available capability but does not demonstrate concrete, validated discoveries or generalizable rules produced by this module in the presented case study.",
            "comparison_to_baseline": "No comparisons or baselines presented for this module within the paper.",
            "reported_limitations": "Paper does not provide implementation or validation details; therefore limitations include lack of specification, lack of presented outcomes, and absence of evaluation of correctness or novelty of inferred discoveries.",
            "bias_or_hallucination_issues": "Because outputs from such graph-based inference would be narrated by GPT-4o, the paper warns that LLM narration can hallucinate or misrepresent inferred patterns; no module-specific hallucination analysis is provided.",
            "uuid": "e9521.2",
            "source_info": {
                "paper_title": "Conversational Exploration of Literature Landscape with LitChat",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Autosurvey",
            "rating": 2,
            "sanitized_title": "autosurvey"
        },
        {
            "paper_title": "PaperQA2",
            "rating": 2
        },
        {
            "paper_title": "Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network",
            "rating": 2,
            "sanitized_title": "forecasting_the_future_of_artificial_intelligence_with_machine_learningbased_link_prediction_in_an_exponentially_growing_knowledge_network"
        },
        {
            "paper_title": "Retrieval-augmented generation for large language models: A survey",
            "rating": 1,
            "sanitized_title": "retrievalaugmented_generation_for_large_language_models_a_survey"
        },
        {
            "paper_title": "Survey of hallucination in natural language generation",
            "rating": 1,
            "sanitized_title": "survey_of_hallucination_in_natural_language_generation"
        },
        {
            "paper_title": "BERTtopic: Neural topic modeling with a class-based TF-IDF procedure",
            "rating": 2,
            "sanitized_title": "berttopic_neural_topic_modeling_with_a_classbased_tfidf_procedure"
        }
    ],
    "cost": 0.010273000000000001,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Conversational Exploration of Literature Landscape with LitChat
25 May 2025</p>
<p>Mingyu Huang 
College of Computer Science and Engineering
University of Electronic Science and Technology of China
Xiyuan Avenue 2006ChengduChina</p>
<p>Shasha Zhou 
Department of Computer Science
University of Exeter
EX4 4QFExeterUnited Kingdom</p>
<p>Yuxuan Chen 
James Watt School of Engineering
University of Glasgow
G12 8QQGlasgowUnited Kindom</p>
<p>Ke Li k.li@exeter.ac.uk 
College of Computer Science and Engineering
University of Electronic Science and Technology of China
Xiyuan Avenue 2006ChengduChina</p>
<p>Conversational Exploration of Literature Landscape with LitChat
25 May 2025768D3AFEF3174BB540E05A20CFDAC313arXiv:2505.23789v1[cs.CL]
We are living in an era of "big literature", where the volume of digital scientific publications is growing exponentially.While offering new opportunities, this also poses challenges for understanding literature landscapes, as traditional manual reviewing is no longer feasible.Recent large language models (LLMs) have shown strong capabilities for literature comprehension, yet they are incapable of offering "comprehensive, objective, open and transparent" views desired by systematic reviews due to their limited context windows and trust issues like hallucinations.Here we present LitChat, an end-toend, interactive and conversational literature agent that augments LLM agents with data-driven discovery tools to facilitate literature exploration.LitChat automatically interprets user queries, retrieves relevant sources, constructs knowledge graphs, and employs diverse data-mining techniques to generate evidence-based insights addressing user needs.We illustrate the effectiveness of LitChat via a case study on AI4Health, highlighting its capacity to quickly navigate the users through large-scale literature landscape with data-based evidence that is otherwise infeasible with traditional means.</p>
<p>Introduction</p>
<p>The past decade has witnessed an unprecedented expansion of scientific literature on many topics.This deluge of digital data on publications offers unprecedented opportunities for scholars and practitioners to explore patterns characterizing the structure and evolution of the underlying literature landscapes while simultaneously confronting them with new challenges.Scholars often develop systematic literature reviews (SLRs) [Kitchenham et al., 2009] to obtain comprehensive overviews of the relevant topics by manually reviewing a set of relevant publications.However, the exponentially increasing volume of literature means that the provision of "comprehensive, objective, open and transparent" (COOT) principles is no longer feasible by traditional means.For example, the number of publications on the applications of artificial intelligence in healthcare has reached 100,000 in 2023, which is far beyond the capacity of human experts to review.</p>
<p>Large language models (LLMs) [OpenAI, 2023] have now emerged as transformative tools that promise to revolutionize scientific literature exploration and understanding.Autosurvey [Wang et al., 2024] is a recent example of such a system that uses LLMs to automatically generate literature reviews.Another system, PaperQA2 [Skarlinski et al., 2024], leverages LLMs and retrieval-augmented generation (RAG) [Gao et al., 2023] to answer questions about scientific publications.While they have shown some promise, they also fail to provide COOT views of literature landscapes.For example, due to the limited context windows of LLMs, it is infeasible to feed the entire literature corpus, which may contain thousands of papers, into the LLMs.This is in contrast to the "comprehensive" principle of SLR.Similarly, as probablistic models, LLMs function as black boxes and are prone to hallucinations [Ji et al., 2023], which may lead to incorrect or misleading information that violates the "objective" and "transparent" principles.</p>
<p>Long before the emergence of LLMs, scholars have explored the use of data-driven methods to generate insights that can guide literature exploration.For example, Schmallenbach et al. leverages topic modeling to explore latent themes in large corpora of literature on the use of artificial intelligence in life science research.Jeong et al. uses community detection techniques to explore key research topics in authentication.Our recent work [Huang and Li, 2024] combines these with author collaboration network analysis to provide a holistic view on the research landscape of multi-objective optimization research.These methods could provide quantitative evidence to facilitate SLR under the COOT principles.</p>
<p>Inspired by this, here we present LitChat, an end-to-end, interactive and conversational literature agent that combines LLM agents and data-driven discovery tools to facilitate literature exploration.LitChat can automatically interpret user queries, design search queries, retrieves relevant sources from online databases, constructs bibliographic knowledge graphs, and employs diverse data-mining techniques to deliver evidence-based insights addressing user needs.It is able to perform explorations of different granularities, from providing an overview of the literature landscape to drilling down into the details of individual papers or researchers.We demonstrate the effectiveness of LitChat through a case study on AI4Health, highlighting its capacity to guide users through a timely, large-scale and rapidly evolving research landscape.</p>
<p>LitChat</p>
<p>A schematic overview of LitChat is depicted in Figure 1 on page 2. Overall, LitChat consists of two LLM agents, both of which can interact with users in a conversational manner.The first agent (upper) takes user queries and devises boolean search queries to retrieve relevant publications from online databases.The collected papers along with metadata are then used to construct a bibliographic knowledge graph (BKG).The second agent (lower) then selects appropriate data-mining techniques to explore the obtained BKG and generate responses to user queries based on the analysis results.At a higher level, the whole system is connected to a frontend built using JavaScript and React, which allows users to interact through a web interface.This frontend is connected to a backend using a Python Flask web app.The backend holds the LLM agents, the BKG (via Neo4j graph database), the paper metadata (via SQLite databases), and the data mining library.Below we delineate each component of LitChat.Note on the choice of LLMs: Unlike other LLM-based literature agents like Autosurvey and GraphRAG, which prompt LLMs to scrutinize the entire text corpus before reaching the final outputs, LitChat only uses LLMs to directly interact with the users for essential communications like discussing the query, explaining the results, and answering questions.This makes LitChat significantly more "token-efficient" and thus more affordable for broader applications.We thereby choose GPT-4o to enhance performance, though any other LLMs can also be used.</p>
<p>Query Design and Data Acquisition</p>
<p>Interactive refinement.The initial query will then be sent to the user for confirmation.The user can either approve it or provide feedback to refine, e.g., by adding or removing keywords.In the latter case, the LLM agent will update the query accordingly and ask for confirmation again.This process continues until the user is satisfied with the query.Database search and metadata.Once the query is confirmed, the LLM agent forwards it to an online database via API calls to retrieve relevant publications.Here we use the WoS API for this purpose, which is one of the most comprehensive literature databases and a common choice for SLR.The WoS API returns the matched publications in JSON format, which consists of rich curated metadata such as abstract, authors, venues, publication date, citations.The agent stores this information in a SQLite database for further processing.</p>
<p>Note on full paper data: Due to copyright issues, LitChat typically only retrieves paper metadata from online databases, unless the full paper is open access.Yet, a user is able to upload PDF documents to LitChat for further analysis.</p>
<p>Bibliographic Knowledge Graph Construction</p>
<p>Once the paper metadata is collected, LitChat parses it to construct a BKG, which essentially contains all the information regarding the underlying literature landscape.Notably, this graph is heterogeneous, as it consists of different types of entities, e.g., papers, authors, venues, keywords, institutions, etc., and complex relationships among them (e.g., citation, co-authorship, keyword co-occurrence, etc.).Paper abstracts are also integrated as part of node attributes, and we generate embeddings for them using the voyage-3-large 4 model, a top performer on the MTEB leaderboard.The final BKG provides the basis for all the subsequent data mining and response generation tasks.Upon construction, the BKG will be stored in a Neo4j graph database to allow for efficient querying and analysis.</p>
<p>Data Mining and Response Generation</p>
<p>After obtaining the BKG, the second LLM agent, also based on GPT-4o, would take another look at the user query and select one or more data mining approaches from a predefined library that can be helpful for answering the query.While an exhaustive list of data mining techniques is not feasible here, some important ones include:</p>
<p>• Topics and keywords: Applying topic modeling [Grootendorst, 2022] to uncover latent research themes and their temporal evolution in the BKG;   • Scientific discovery: Learning hidden patterns embedded in the BKG to infer meaningful research ideas that transcend existing individual knowledge and crossdomain boundaries [Krenn et al., 2023;Bai et al., 2024].After LitChat executes a tool, it composes the results of the operations into a natural language response that it returns to the user.LitChat generates these responses by filling in templates associated with each operation based on the results.The responses also include sufficient context to understand the results and opportunities for following up.In addition to these advanced data-driven tools, LitChat also supports basic tasks like question-answering and summarization based on RAG techniques just as many other literature chatbots.</p>
<p>Case Study on AI4Health</p>
<p>To demonstrate the effectiveness of LitChat, here we present a case study on the AI4Health domain.Specifically, as shown in Figure 2 on page 3, the user first asks "I want to know what healthcare tasks researchers have explored using LLMs for?"As one can imagine, answering this requires a comprehensive audit of the relevant literature, which is beyond the capacity of human experts.To address this, LitChat first creates a candidate search query and engages with the user to refine it to allow for a comprehensive coverage of relevant literature.The final query is then sent to the Web of Science database, from which 3,700+ papers are retrieved and synthesized into a BKG.Given the large volume of papers, traditional LLMbased systems would struggle to process them all, and this is where LitChat's data-driven tools come into play.</p>
<p>Since the user is interested in an overview of certain research topics, LitChat chooses topic modeling to analyze the BKG.This function clusters the retrieved papers into different topics based on their semantic proximity (e.g., in the upper left region are topics related to brain and recognition, e.g., "Alzheimer", "Mental Health", and "Speech Recognition").LitChat then generates response by highlighting the most prominent topics, and also provides a 2D visualization of the literature landscape (see Figure 3 on page 3).Note that in the response, LitChat is able to explicitly indicate the size of each topic as determined by the topic model, which conforms to the "objective" and "transparent" principles of SLR.</p>
<p>When the user asks for more details on a specific topic (here "mental health"), LitChat can use the topic tool to recommend representative papers, and generate topic summaries based on them.This conversation can continue to drill down into the details of one specific paper in this topic, historical trends of the topic, or the authors involved, etc., and each response would also be grounded on data-based evidence.</p>
<p>Conclusion</p>
<p>In this paper we introduced LitChat, an interactive LLM agent that is augmented with data-driven discovery tools to aid the exploration of large-scale literature landscapes.With a case study on AI4Health, we demonstrated how LitChat can help users to quickly navigate the terrain of LLM applications in healthcare research in an end-to-end fashion, which is otherwise infeasible with traditional manual reviewing or pure LLM-based systems.We hope that LitChat opens up new possibilities for scholars and practitioners to understand scientific literature in this era of literature explosion.</p>
<p>Figure 1 :
1
Figure 1: Schematic overview of LitChat.</p>
<p>Initial query design.When a user enters a query, e.g., "I want to know what healthcare tasks researchers have explored using LLMs for" (see Figure2on page 3), the first LLM agent identifies the key research domains involved and synthesizes them into a boolean search query that can be used on established databases like Web of Science 1 , Scopus 2 , or Semantic Scholar 3 .Benefiting from the extensive training on largescale corpora, LLMs have shown human-level performance in query formulation[Wang et al., 2023].To further ensure the quality of the designed query, 10 in-context-learning examples are provided to the LLM agent.These examples are extracted from established SLRs from diverse domains in which domain experts explicitly describe the search queries they used for literature search.</p>
<p>Hi, how can I help you today?I want to know what healthcare tasks researchers have explored using LLMs for.Sure, I will first craft a search query to gather relevant literature metadata.I have designed the following search query: ("large language model<em>" OR "foundation model</em>" OR "large generative model<em>" OR LLM</em>) Do you think it is ok to proceed with this?With topic modeling I identified 49 major healthcare topics that studied LLMs, among which the most prominent ones include: -Named entity recognition (495 papers) -Medical image segmentation (388 papers) -Mental health consultation (289 papers) -Medical question-answering (222 papers) -Medical Education (198 papers) A full list of these domains are provided below, along with a 2D interative plot showing their distributions.If you would like to dive more into any of these topics, please feel free to tell me!In general this is fine to me, but you can explicitly mention ChatGPT and GPT-4 series Sure!I will refine this query by adding… By applying the refined query I have now acquired 3,789 relevant papers.I will next perform topic modeling to identify the research domains involved.I am interested in how LLMs are used for mental health consultation.Please tell me more about this topic.Sure! LLMs aid mental health by enhancing empathy in peer support, assessing emotional awareness, analyzing suicide risk, facilitating empathic conversations, and powering chatbots for public health.Specialized models like MentalBERT improve mental health detection… (more responses are omitted due to page limit) References: [1] A. Sharma et al., Human-AI collaboration enables more empathic conversations in text-based peer-topeer mental health support.Nat.Mac.Intell.(2023).[2] Z. Elyoseph et al., ChatGPT outperforms humans in emotional awareness eval.Front.Psychol.(2023) [3] ...</p>
<p>Figure 2 :Figure 3 :
23
Figure 2: An example of LitChat in action.</p>
<p>https://www.webofscience.com
https://www.scopus.com
https://www.semanticscholar.org/</p>
<p>Co-citation analysis, bibliographic coupling, and direct citation: Which citation approach represents the research front most accurately?. Bai, Boyack and Klavans. 2024. 2024. 2010. 201015Nat. Commun.</p>
<p>Retrievalaugmented generation for large language models: A survey. Gao, CoRR, abs/2312.109972023. 2023</p>
<p>A survey of decomposition-based evolutionary multi-objective optimization: Part II -A data science perspective. Maarten Grootendorst, Mingyu Grootendorst, Ke Huang, Li, CoRR, abs/2404.142282022. 2022. 2024Bertopic: Neural topic modeling with a class-based TF-IDF procedure</p>
<p>Examining the current status and emerging trends in continuous authentication technologies through citation network analysis. Jeong , ACM Comput. Surv. 556312023. 2023</p>
<p>Survey of hallucination in natural language generation. Ji , ACM Comput. Surv. 5512382023. 2023</p>
<p>Systematic literature reviews in software engineering -A systematic literature review. Kitchenham, Inf. Softw. Technol. 5112009. 2009</p>
<p>Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network. Krenn, Nat. Mac. Intell. 5112023. 2023. 2022. 2022Nat. Hum. Behav.</p>
<p>Can chatgpt write a good boolean query for systematic review literature search?. Palla Openai, CoRR, abs/2409.13740SIGIR'23: Proc. of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM2023. 2023. 2007. 2007. 2024. 2024. 2024. 2024. 2023. 2023. 2024. 2021446Nat. Commun.</p>            </div>
        </div>

    </div>
</body>
</html>