<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9184 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9184</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9184</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-259213474</p>
                <p><strong>Paper Title:</strong> Large language models are universal biomedical simulators</p>
                <p><strong>Paper Abstract:</strong> Computational simulation of biological processes can be a valuable tool in accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Recently, large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks by generating human language at a very large scale. Here we explore the potential of leveraging LLMs as simulators of biological systems. We establish proof-of-concept of a text-based simulator, SimulateGPT, that uses LLM reasoning . We demonstrate good prediction performance for various biomedical applications, without requiring explicit domain knowledge or manual tuning. LLMs thus enable a new class of versatile and broadly applicable biological simulators. This text-based simulation paradigm is well-suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulation, but for which extensive knowledge and context is available as written text.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9184.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9184.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SimulateGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT: a stepwise GPT-4-based text simulator for biomedical systems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that uses GPT-4 to perform structured, step-by-step, text-based simulation of biological processes across molecular, cellular, organ, and organismal levels by enforcing a multi-step schema (level, facts, entities, assumptions, consequence, probability, explanation, novelty).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 accessed via API (April–May 2023); described as a very large pre-trained transformer trained on massive text corpora including scientific literature and web text; exact parameter count not reported in this paper. Temperature was set to 0 and max length to 2048 for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>General biomedical simulation (cross-cutting: molecular biology, cellular biology, immunology, oncology, physiology)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>General-purpose, qualitative and quantitative text-based simulation of biological scenarios, producing stepwise intermediate states and a final outcome (e.g., survival time, treatment recommendation, gene essentiality classification).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Blinded expert Likert-scale evaluation for qualitative scenarios; standard classification metrics (accuracy, precision, recall) for gene-essentiality; regression error and correlation coefficients for progression-free survival (PFS) predictions; comparison vs. direct-inference prompting (same LLM without the structured stepwise schema).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Reported superior outcome-prediction performance versus direct-inference GPT-4 across four qualitative scenarios (expert ranking; no single numeric aggregate provided). For quantitative tasks, example: gene-essentiality accuracy = 86% (class-balanced dataset), direct-inference accuracy = 64%; colorectal PFS: SimulateGPT produced substantially smaller error and higher correlation vs direct inference (numerical values not provided in text).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Structured stepwise prompting (SimulateGPT schema), number of simulation steps (more steps improved PFS predictions), complexity of output format (low-complexity variant produced more steps but was judged worse by experts while improving numeric PFS error), few-shot calibration (used 4 examples for colorectal PFS), dataset variance and heterogeneity, prompt engineering (e.g., 'Focus on more novelty'), potential training-data leakage concerns, model temperature and API settings, lack of domain-specific fine-tuning, and intrinsic limits of LLMs for structured predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct-inference GPT-4 prompting (same base model without SimulateGPT stepwise structure); human expert (postdoctoral biologists) blinded survey for qualitative tasks; ground-truth experimental datasets (DepMap for gene essentiality, cBioPortal colorectal datasets for PFS) for quantitative validation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Final explanations were sometimes not self-contained because intermediate steps contained parts of the explanation; tendency to underestimate variance in regression tasks (predictions closer to the median); low-complexity variants judged worse by experts despite numerical improvement on PFS; domain heterogeneity (e.g., glioblastoma) limits predictive power and makes numeric validation difficult; possible training-data leakage cannot be fully excluded; GPT-4 was not fine-tuned for biomedical simulation in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>The authors recommend stepwise structured simulation (improves outcome prediction), few-shot calibration where appropriate, and future enhancements including interactivity, knowledge augmentation (dynamic retrieval), self-consistency (multiple stochastic runs), built-in math/code execution, self-reflection, modeling bifurcations and reverse simulation, multimodality, fine-tuning on biomedical experiment data, and feeding real-world experimental feedback to anchor simulations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9184.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9184.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gene essentiality (SimulateGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT application: predicting gene essentiality in cancer cell lines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Zero-shot binary classification using GPT-4 (via SimulateGPT) to predict whether individual genes are essential for survival of specific cancer cell lines, validated against DepMap CRISPR-derived ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-4 accessed April–May 2023; large pretrained transformer; no further model fine-tuning reported for this task.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Molecular and cellular biology / functional genomics (cancer cell-line gene essentiality)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Zero-shot binary classification of gene essentiality for specific cancer cell lines, framed as a simulation of molecular/cellular consequences of gene perturbation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Classification metrics vs DepMap ground truth: accuracy, precision, recall (class-balanced dataset used).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Accuracy = 86% on a class-balanced dataset of 50 genes (25 broadly essential, 25 broadly non-essential); reported as having high precision and recall. Direct-inference GPT-4 accuracy reported at 64% (biased toward predicting non-essential).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Stepwise SimulateGPT structure (improves structured inference), class balance of evaluation set, reliance on general-domain knowledge encoded in GPT-4, absence of task-specific fine-tuning, prompt framing (zero-shot vs few-shot), and potential dataset bias/selection.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct-inference GPT-4 prompting (baseline) which showed strong bias toward non-essential predictions and lower accuracy; ground truth = DepMap CRISPR-derived essential/non-essential gene lists.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Evaluation performed on a small random subset (n=50) derived from DepMap lists; possible selection effects and limited scope; no reported confidence calibration or per-gene uncertainty estimates; generalization to less common genes or cell-line-specific contexts not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Structured, stepwise prompting (SimulateGPT) markedly improves binary classification of structured biological properties; authors suggest further improvements via fine-tuning, knowledge augmentation and self-consistency methods to reduce biases.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9184.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9184.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Colorectal PFS (SimulateGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT application: predicting progression-free survival in colorectal cancer patients</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SimulateGPT predicted progression-free survival (PFS) in months from grouped clinical presentation data, calibrated via four few-shot examples from the test dataset, and evaluated against aggregated cBioPortal ground truth groups.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4 via API (temperature=0, max length=2048), used with few-shot calibration in prompts; no model fine-tuning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Clinical oncology / prognostic modeling</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Quantitative regression: predict progression-free survival (months) for patient groups described by clinical features (stage, site, grade, carcinomatosis, age).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Regression error (unspecified metric reported as 'smaller error'), correlation coefficients between predicted and observed PFS, and comparison to direct-inference GPT-4 performance. Confidence intervals shown as standard error in figures (numeric values not stated in text).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>SimulateGPT achieved substantially smaller error and increased correlation coefficients compared to direct inference; both methods underestimated dataset variance (predictions regressed toward the median). Exact numeric error and correlation values are not provided in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Few-shot calibration (4 examples) improved alignment with dataset; number of simulation steps (enforcing ≥5 steps improved performance); complexity of output format (low-complexity variant changed step count and performance tradeoffs); dataset heterogeneity and group aggregation; prompt design and inclusion of prior facts; model tendency to reduce variance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct-inference GPT-4 prompting (baseline). Ground truth derived from cBioPortal colorectal cancer cohort. Experts did not directly provide numeric evaluation for this quantitative task; numeric validation done against dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Tendency to underestimate variance (predicted PFS closer to median), numeric results not exhaustively reported in text (figures referenced), reliance on aggregated groups to reduce patient-to-patient variation, potential sensitivity to choice of few-shot examples.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors found that enforcing more simulation steps improves numeric prediction performance and recommend using stepwise simulation plus few-shot calibration; suggest future integration of built-in math/program execution and knowledge augmentation to improve quantitative accuracy.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9184.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9184.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Glioblastoma survival (SimulateGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT application: estimating survival deviation for glioblastoma genotypes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SimulateGPT simulated groups of glioblastoma cases stratified by binary mutation profiles (top-10 mutated genes) to estimate deviation from the median overall survival (15 months); heterogeneous tumor biology limited ability of simple classifiers, so SimulateGPT results were selected for expert assessment where they matched ground truth best.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4 via API (no fine-tuning); genotype and methylation data from TCGA/CPTAC-3 and cBioPortal were provided as input parameters to the simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Cancer genomics / clinical oncology (glioblastoma prognosis)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Qualitative and semi-quantitative simulation: infer whether survival is increased/decreased relative to median and estimate months of deviation given tumor genotype (mutational profile and MGMT methylation).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Expert assessment for qualitative plausibility; selection of the genotype-scenario that best coincided with ground-truth outcome for expert review. No aggregate numeric accuracy reported due to high variance and heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported as a single numeric measure; authors note heterogeneity and high variance in glioblastoma, with linear classifiers unable to beat random for survival prediction—SimulateGPT outputs were used qualitatively and the most concordant genotype-scenario was chosen for expert evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>High biological heterogeneity of glioblastoma, limited sample sizes per mutation group, noisy/outcome data, complexity of genotype–phenotype mapping, and the absence of fine-tuning to capture tumor-specific prognostic relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Linear classifiers (not better than random) and direct-inference GPT-4; expert assessment used to evaluate plausibility of SimulateGPT outputs for selected scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Strong dataset heterogeneity and variance prevented robust numeric validation; predictions may be overconfident if asked to 'ignore inherent uncertainty' (some prompts requested bold estimates), and the simulator's outputs were sometimes not self-contained.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors caution about using LLM simulations for highly heterogeneous prognostic tasks without substantial grounding/real-world feedback and recommend iterative validation and incorporation of experimental/clinical feedback to anchor intermediary states.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9184.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9184.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Immunology (mouse & trained immunity)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT applications: mouse in vivo immunology and trained immunity scenarios</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SimulateGPT was applied to simulate simple in vivo mouse perturbations (cyanide injection and YUMM1.7 melanoma transplantation) and trained-immunity scenarios (beta-glucan training, low-dose LPS training, high-dose LPS tolerance) to predict immunological outcomes, evaluated via blinded expert surveys.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4 via API; prompts included minimal experimental descriptions and explicit request to report the 'most relevant final outcome'; no model fine-tuning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Immunology / preclinical in vivo experimentation</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Qualitative simulation of in vivo experimental outcomes (toxicity, tumor progression) and innate immune memory phenotypes (training vs tolerance) upon rechallenge.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Blinded expert evaluation using a 7-level Likert scale across statements assessing correctness, explanation, completeness, and novelty; aggregated pairwise comparisons vs direct-inference GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>SimulateGPT outperformed direct-inference GPT-4 on outcome prediction across the four scenarios evaluated by experts (visualized in Fig. 2a); exact numeric scores per question are in supplementary figures but not enumerated in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Prompt detail / minimal experimental setup, domain complexity of immunology, SimulateGPT's stepwise schema, number of steps produced, and the experts' subjective judgments; novelty-focused prompting could increase creative/novel reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct-inference GPT-4 prompting; expert (postdoctoral biologists) blinded assessment served as gold-standard for judged plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Explanations from SimulateGPT were not consistently judged superior (not ranked better than direct inference), and expert judgments can be subjective; the simulations were qualitative and not quantitatively validated against experimental outcome data.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Stepwise simulation helps outcome prediction in complex immunological scenarios; authors recommend interactive follow-up, knowledge augmentation, and real-world validation to reduce risks of incorrect outputs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9184.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9184.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sepsis treatment (SimulateGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT application: treatment recommendation for sepsis phenotypes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SimulateGPT was used to recommend novel treatment options for two sepsis patient phenotypes (immunoparalysis vs hyperinflammation) based only on two clinical parameters (HLA-DR expression on monocytes and ferritin levels), with expert evaluation of recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4 via API prompted to simulate clinical reasoning from minimal clinical features; no task-specific fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Critical care medicine / clinical decision support (sepsis therapy stratification)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Qualitative clinical decision-support simulation: recommend treatment strategies for sepsis patients stratified by immunoparalysis (low HLA-DR) vs hyperinflammation (high HLA-DR and ferritin).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Blinded expert Likert-scale evaluation comparing SimulateGPT and low-complexity SimulateGPT and direct-inference GPT-4 for outcome and explanation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>SimulateGPT outperformed conventional GPT-4 direct inference on outcome prediction as judged by experts; specific numeric scores are provided in supplementary materials but not in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Input sparsity (only two clinical parameters), stepwise reasoning format, prompt complexity (full vs low-complexity variant), and domain difficulty (sepsis pathophysiology); experts judged explanation quality variably.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct-inference GPT-4 and a low-complexity SimulateGPT variant; expert assessment served as the comparative standard.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limited input features (two parameters) constrain realism; expert evaluation subjective; low-complexity variants can produce conflicting tradeoffs between perceived explanation quality and numeric predictive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors suggest more interactive simulations, knowledge augmentation, and real-world feedback loops to better ground treatment recommendations and reduce clinical risk.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9184.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9184.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conway's Game of Life proof-of-concept</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conway's Game of Life (glider) simulated by GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proof-of-concept demonstration where GPT-4 simulated the 4-step glider cycle of Conway's Game of Life using provided update rules and output formatting (LaTeX matrix), showing ability to perform deterministic rule-based state updates without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4 via API; prompted with the Game-of-Life rules and a 4x4 initial grid; requested LaTeX-formatted grid outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Computational simulation / cellular automata (toy validation of simulation capability)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Deterministic simulation of cellular automaton state evolution (glider pattern) over multiple generations according to explicit rules.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Qualitative correctness of generated state sequences; compared to prior reports that neural networks struggle to learn Game of Life dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>GPT-4 successfully simulated the full 4-step glider cycle without manual adaptation. No formal numeric accuracy metric provided; success noted as contrast to prior neural-net failures.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Explicitness of rules included in the system prompt, output formatting constraints (LaTeX), and autoregressive generation determinism (temperature=0).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Prior reports that neural networks struggle to learn Game of Life (cited in paper); here GPT-4 performed the deterministic simulation successfully under prompt guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>This is a toy, rule-specified task and does not imply general numeric simulation fidelity for real-world biochemical systems; authors present it as a simple feasibility demonstration.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>The success on this toy task supports the feasibility of LLMs performing sequential state-update style simulations when given explicit rules and strong prompting; authors use this as conceptual grounding for more complex biological simulations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large Language Models Encode Clinical Knowledge <em>(Rating: 2)</em></li>
                <li>GPT-4 Technical Report <em>(Rating: 2)</em></li>
                <li>Capabilities of GPT-4 on Medical Challenge Problems <em>(Rating: 2)</em></li>
                <li>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models <em>(Rating: 1)</em></li>
                <li>Self-Consistency Improves Chain of Thought Reasoning in Language Models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9184",
    "paper_id": "paper-259213474",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "SimulateGPT",
            "name_full": "SimulateGPT: a stepwise GPT-4-based text simulator for biomedical systems",
            "brief_description": "A method that uses GPT-4 to perform structured, step-by-step, text-based simulation of biological processes across molecular, cellular, organ, and organismal levels by enforcing a multi-step schema (level, facts, entities, assumptions, consequence, probability, explanation, novelty).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 accessed via API (April–May 2023); described as a very large pre-trained transformer trained on massive text corpora including scientific literature and web text; exact parameter count not reported in this paper. Temperature was set to 0 and max length to 2048 for experiments.",
            "scientific_subdomain": "General biomedical simulation (cross-cutting: molecular biology, cellular biology, immunology, oncology, physiology)",
            "simulation_task": "General-purpose, qualitative and quantitative text-based simulation of biological scenarios, producing stepwise intermediate states and a final outcome (e.g., survival time, treatment recommendation, gene essentiality classification).",
            "evaluation_metric": "Blinded expert Likert-scale evaluation for qualitative scenarios; standard classification metrics (accuracy, precision, recall) for gene-essentiality; regression error and correlation coefficients for progression-free survival (PFS) predictions; comparison vs. direct-inference prompting (same LLM without the structured stepwise schema).",
            "simulation_accuracy": "Reported superior outcome-prediction performance versus direct-inference GPT-4 across four qualitative scenarios (expert ranking; no single numeric aggregate provided). For quantitative tasks, example: gene-essentiality accuracy = 86% (class-balanced dataset), direct-inference accuracy = 64%; colorectal PFS: SimulateGPT produced substantially smaller error and higher correlation vs direct inference (numerical values not provided in text).",
            "factors_affecting_accuracy": "Structured stepwise prompting (SimulateGPT schema), number of simulation steps (more steps improved PFS predictions), complexity of output format (low-complexity variant produced more steps but was judged worse by experts while improving numeric PFS error), few-shot calibration (used 4 examples for colorectal PFS), dataset variance and heterogeneity, prompt engineering (e.g., 'Focus on more novelty'), potential training-data leakage concerns, model temperature and API settings, lack of domain-specific fine-tuning, and intrinsic limits of LLMs for structured predictions.",
            "comparison_baseline": "Direct-inference GPT-4 prompting (same base model without SimulateGPT stepwise structure); human expert (postdoctoral biologists) blinded survey for qualitative tasks; ground-truth experimental datasets (DepMap for gene essentiality, cBioPortal colorectal datasets for PFS) for quantitative validation.",
            "limitations_or_failure_cases": "Final explanations were sometimes not self-contained because intermediate steps contained parts of the explanation; tendency to underestimate variance in regression tasks (predictions closer to the median); low-complexity variants judged worse by experts despite numerical improvement on PFS; domain heterogeneity (e.g., glioblastoma) limits predictive power and makes numeric validation difficult; possible training-data leakage cannot be fully excluded; GPT-4 was not fine-tuned for biomedical simulation in these experiments.",
            "author_recommendations_or_insights": "The authors recommend stepwise structured simulation (improves outcome prediction), few-shot calibration where appropriate, and future enhancements including interactivity, knowledge augmentation (dynamic retrieval), self-consistency (multiple stochastic runs), built-in math/code execution, self-reflection, modeling bifurcations and reverse simulation, multimodality, fine-tuning on biomedical experiment data, and feeding real-world experimental feedback to anchor simulations.",
            "uuid": "e9184.0"
        },
        {
            "name_short": "Gene essentiality (SimulateGPT)",
            "name_full": "SimulateGPT application: predicting gene essentiality in cancer cell lines",
            "brief_description": "Zero-shot binary classification using GPT-4 (via SimulateGPT) to predict whether individual genes are essential for survival of specific cancer cell lines, validated against DepMap CRISPR-derived ground truth.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI GPT-4 accessed April–May 2023; large pretrained transformer; no further model fine-tuning reported for this task.",
            "scientific_subdomain": "Molecular and cellular biology / functional genomics (cancer cell-line gene essentiality)",
            "simulation_task": "Zero-shot binary classification of gene essentiality for specific cancer cell lines, framed as a simulation of molecular/cellular consequences of gene perturbation.",
            "evaluation_metric": "Classification metrics vs DepMap ground truth: accuracy, precision, recall (class-balanced dataset used).",
            "simulation_accuracy": "Accuracy = 86% on a class-balanced dataset of 50 genes (25 broadly essential, 25 broadly non-essential); reported as having high precision and recall. Direct-inference GPT-4 accuracy reported at 64% (biased toward predicting non-essential).",
            "factors_affecting_accuracy": "Stepwise SimulateGPT structure (improves structured inference), class balance of evaluation set, reliance on general-domain knowledge encoded in GPT-4, absence of task-specific fine-tuning, prompt framing (zero-shot vs few-shot), and potential dataset bias/selection.",
            "comparison_baseline": "Direct-inference GPT-4 prompting (baseline) which showed strong bias toward non-essential predictions and lower accuracy; ground truth = DepMap CRISPR-derived essential/non-essential gene lists.",
            "limitations_or_failure_cases": "Evaluation performed on a small random subset (n=50) derived from DepMap lists; possible selection effects and limited scope; no reported confidence calibration or per-gene uncertainty estimates; generalization to less common genes or cell-line-specific contexts not reported.",
            "author_recommendations_or_insights": "Structured, stepwise prompting (SimulateGPT) markedly improves binary classification of structured biological properties; authors suggest further improvements via fine-tuning, knowledge augmentation and self-consistency methods to reduce biases.",
            "uuid": "e9184.1"
        },
        {
            "name_short": "Colorectal PFS (SimulateGPT)",
            "name_full": "SimulateGPT application: predicting progression-free survival in colorectal cancer patients",
            "brief_description": "SimulateGPT predicted progression-free survival (PFS) in months from grouped clinical presentation data, calibrated via four few-shot examples from the test dataset, and evaluated against aggregated cBioPortal ground truth groups.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "GPT-4 via API (temperature=0, max length=2048), used with few-shot calibration in prompts; no model fine-tuning reported.",
            "scientific_subdomain": "Clinical oncology / prognostic modeling",
            "simulation_task": "Quantitative regression: predict progression-free survival (months) for patient groups described by clinical features (stage, site, grade, carcinomatosis, age).",
            "evaluation_metric": "Regression error (unspecified metric reported as 'smaller error'), correlation coefficients between predicted and observed PFS, and comparison to direct-inference GPT-4 performance. Confidence intervals shown as standard error in figures (numeric values not stated in text).",
            "simulation_accuracy": "SimulateGPT achieved substantially smaller error and increased correlation coefficients compared to direct inference; both methods underestimated dataset variance (predictions regressed toward the median). Exact numeric error and correlation values are not provided in the main text.",
            "factors_affecting_accuracy": "Few-shot calibration (4 examples) improved alignment with dataset; number of simulation steps (enforcing ≥5 steps improved performance); complexity of output format (low-complexity variant changed step count and performance tradeoffs); dataset heterogeneity and group aggregation; prompt design and inclusion of prior facts; model tendency to reduce variance.",
            "comparison_baseline": "Direct-inference GPT-4 prompting (baseline). Ground truth derived from cBioPortal colorectal cancer cohort. Experts did not directly provide numeric evaluation for this quantitative task; numeric validation done against dataset.",
            "limitations_or_failure_cases": "Tendency to underestimate variance (predicted PFS closer to median), numeric results not exhaustively reported in text (figures referenced), reliance on aggregated groups to reduce patient-to-patient variation, potential sensitivity to choice of few-shot examples.",
            "author_recommendations_or_insights": "Authors found that enforcing more simulation steps improves numeric prediction performance and recommend using stepwise simulation plus few-shot calibration; suggest future integration of built-in math/program execution and knowledge augmentation to improve quantitative accuracy.",
            "uuid": "e9184.2"
        },
        {
            "name_short": "Glioblastoma survival (SimulateGPT)",
            "name_full": "SimulateGPT application: estimating survival deviation for glioblastoma genotypes",
            "brief_description": "SimulateGPT simulated groups of glioblastoma cases stratified by binary mutation profiles (top-10 mutated genes) to estimate deviation from the median overall survival (15 months); heterogeneous tumor biology limited ability of simple classifiers, so SimulateGPT results were selected for expert assessment where they matched ground truth best.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "GPT-4 via API (no fine-tuning); genotype and methylation data from TCGA/CPTAC-3 and cBioPortal were provided as input parameters to the simulator.",
            "scientific_subdomain": "Cancer genomics / clinical oncology (glioblastoma prognosis)",
            "simulation_task": "Qualitative and semi-quantitative simulation: infer whether survival is increased/decreased relative to median and estimate months of deviation given tumor genotype (mutational profile and MGMT methylation).",
            "evaluation_metric": "Expert assessment for qualitative plausibility; selection of the genotype-scenario that best coincided with ground-truth outcome for expert review. No aggregate numeric accuracy reported due to high variance and heterogeneity.",
            "simulation_accuracy": "Not reported as a single numeric measure; authors note heterogeneity and high variance in glioblastoma, with linear classifiers unable to beat random for survival prediction—SimulateGPT outputs were used qualitatively and the most concordant genotype-scenario was chosen for expert evaluation.",
            "factors_affecting_accuracy": "High biological heterogeneity of glioblastoma, limited sample sizes per mutation group, noisy/outcome data, complexity of genotype–phenotype mapping, and the absence of fine-tuning to capture tumor-specific prognostic relationships.",
            "comparison_baseline": "Linear classifiers (not better than random) and direct-inference GPT-4; expert assessment used to evaluate plausibility of SimulateGPT outputs for selected scenarios.",
            "limitations_or_failure_cases": "Strong dataset heterogeneity and variance prevented robust numeric validation; predictions may be overconfident if asked to 'ignore inherent uncertainty' (some prompts requested bold estimates), and the simulator's outputs were sometimes not self-contained.",
            "author_recommendations_or_insights": "Authors caution about using LLM simulations for highly heterogeneous prognostic tasks without substantial grounding/real-world feedback and recommend iterative validation and incorporation of experimental/clinical feedback to anchor intermediary states.",
            "uuid": "e9184.3"
        },
        {
            "name_short": "Immunology (mouse & trained immunity)",
            "name_full": "SimulateGPT applications: mouse in vivo immunology and trained immunity scenarios",
            "brief_description": "SimulateGPT was applied to simulate simple in vivo mouse perturbations (cyanide injection and YUMM1.7 melanoma transplantation) and trained-immunity scenarios (beta-glucan training, low-dose LPS training, high-dose LPS tolerance) to predict immunological outcomes, evaluated via blinded expert surveys.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "GPT-4 via API; prompts included minimal experimental descriptions and explicit request to report the 'most relevant final outcome'; no model fine-tuning reported.",
            "scientific_subdomain": "Immunology / preclinical in vivo experimentation",
            "simulation_task": "Qualitative simulation of in vivo experimental outcomes (toxicity, tumor progression) and innate immune memory phenotypes (training vs tolerance) upon rechallenge.",
            "evaluation_metric": "Blinded expert evaluation using a 7-level Likert scale across statements assessing correctness, explanation, completeness, and novelty; aggregated pairwise comparisons vs direct-inference GPT-4.",
            "simulation_accuracy": "SimulateGPT outperformed direct-inference GPT-4 on outcome prediction across the four scenarios evaluated by experts (visualized in Fig. 2a); exact numeric scores per question are in supplementary figures but not enumerated in the main text.",
            "factors_affecting_accuracy": "Prompt detail / minimal experimental setup, domain complexity of immunology, SimulateGPT's stepwise schema, number of steps produced, and the experts' subjective judgments; novelty-focused prompting could increase creative/novel reasoning.",
            "comparison_baseline": "Direct-inference GPT-4 prompting; expert (postdoctoral biologists) blinded assessment served as gold-standard for judged plausibility.",
            "limitations_or_failure_cases": "Explanations from SimulateGPT were not consistently judged superior (not ranked better than direct inference), and expert judgments can be subjective; the simulations were qualitative and not quantitatively validated against experimental outcome data.",
            "author_recommendations_or_insights": "Stepwise simulation helps outcome prediction in complex immunological scenarios; authors recommend interactive follow-up, knowledge augmentation, and real-world validation to reduce risks of incorrect outputs.",
            "uuid": "e9184.4"
        },
        {
            "name_short": "Sepsis treatment (SimulateGPT)",
            "name_full": "SimulateGPT application: treatment recommendation for sepsis phenotypes",
            "brief_description": "SimulateGPT was used to recommend novel treatment options for two sepsis patient phenotypes (immunoparalysis vs hyperinflammation) based only on two clinical parameters (HLA-DR expression on monocytes and ferritin levels), with expert evaluation of recommendations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "GPT-4 via API prompted to simulate clinical reasoning from minimal clinical features; no task-specific fine-tuning.",
            "scientific_subdomain": "Critical care medicine / clinical decision support (sepsis therapy stratification)",
            "simulation_task": "Qualitative clinical decision-support simulation: recommend treatment strategies for sepsis patients stratified by immunoparalysis (low HLA-DR) vs hyperinflammation (high HLA-DR and ferritin).",
            "evaluation_metric": "Blinded expert Likert-scale evaluation comparing SimulateGPT and low-complexity SimulateGPT and direct-inference GPT-4 for outcome and explanation quality.",
            "simulation_accuracy": "SimulateGPT outperformed conventional GPT-4 direct inference on outcome prediction as judged by experts; specific numeric scores are provided in supplementary materials but not in the main text.",
            "factors_affecting_accuracy": "Input sparsity (only two clinical parameters), stepwise reasoning format, prompt complexity (full vs low-complexity variant), and domain difficulty (sepsis pathophysiology); experts judged explanation quality variably.",
            "comparison_baseline": "Direct-inference GPT-4 and a low-complexity SimulateGPT variant; expert assessment served as the comparative standard.",
            "limitations_or_failure_cases": "Limited input features (two parameters) constrain realism; expert evaluation subjective; low-complexity variants can produce conflicting tradeoffs between perceived explanation quality and numeric predictive performance.",
            "author_recommendations_or_insights": "Authors suggest more interactive simulations, knowledge augmentation, and real-world feedback loops to better ground treatment recommendations and reduce clinical risk.",
            "uuid": "e9184.5"
        },
        {
            "name_short": "Conway's Game of Life proof-of-concept",
            "name_full": "Conway's Game of Life (glider) simulated by GPT-4",
            "brief_description": "A proof-of-concept demonstration where GPT-4 simulated the 4-step glider cycle of Conway's Game of Life using provided update rules and output formatting (LaTeX matrix), showing ability to perform deterministic rule-based state updates without fine-tuning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "GPT-4 via API; prompted with the Game-of-Life rules and a 4x4 initial grid; requested LaTeX-formatted grid outputs.",
            "scientific_subdomain": "Computational simulation / cellular automata (toy validation of simulation capability)",
            "simulation_task": "Deterministic simulation of cellular automaton state evolution (glider pattern) over multiple generations according to explicit rules.",
            "evaluation_metric": "Qualitative correctness of generated state sequences; compared to prior reports that neural networks struggle to learn Game of Life dynamics.",
            "simulation_accuracy": "GPT-4 successfully simulated the full 4-step glider cycle without manual adaptation. No formal numeric accuracy metric provided; success noted as contrast to prior neural-net failures.",
            "factors_affecting_accuracy": "Explicitness of rules included in the system prompt, output formatting constraints (LaTeX), and autoregressive generation determinism (temperature=0).",
            "comparison_baseline": "Prior reports that neural networks struggle to learn Game of Life (cited in paper); here GPT-4 performed the deterministic simulation successfully under prompt guidance.",
            "limitations_or_failure_cases": "This is a toy, rule-specified task and does not imply general numeric simulation fidelity for real-world biochemical systems; authors present it as a simple feasibility demonstration.",
            "author_recommendations_or_insights": "The success on this toy task supports the feasibility of LLMs performing sequential state-update style simulations when given explicit rules and strong prompting; authors use this as conceptual grounding for more complex biological simulations.",
            "uuid": "e9184.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large Language Models Encode Clinical Knowledge",
            "rating": 2,
            "sanitized_title": "large_language_models_encode_clinical_knowledge"
        },
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 2,
            "sanitized_title": "gpt4_technical_report"
        },
        {
            "paper_title": "Capabilities of GPT-4 on Medical Challenge Problems",
            "rating": 2,
            "sanitized_title": "capabilities_of_gpt4_on_medical_challenge_problems"
        },
        {
            "paper_title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
            "rating": 1,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
            "rating": 1,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        }
    ],
    "cost": 0.01625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large language models are universal biomedical simulators</p>
<p>Moritz Schaefer 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Stephan Reichl 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Rob Ter Horst 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Adele M Nicolas 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Thomas Krausgruber 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Francesco Piras 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Peter Stepper 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Christoph Bock 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Matthias Samwald matthias.samwald@meduniwien.ac.at&amp;christoph.bock@meduniwien.ac.at 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>Large language models are universal biomedical simulators
1 * These authors contributed equally § Correspondence:
Computational simulation of biological processes can be a valuable tool in accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Recently, large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks by generating human language at a very large scale. Here we explore the potential of leveraging LLMs as simulators of biological systems. We establish proof-of-concept of a text-based simulator, SimulateGPT, that uses LLM reasoning. We demonstrate good prediction performance for various biomedical applications, without requiring explicit domain knowledge or manual tuning. LLMs thus enable a new class of versatile and broadly applicable biological simulators. This text-based simulation paradigm is well-suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulation, but for which extensive knowledge and context is available as written text.Main TextLarge language models (LLMs) have an impressive ability to use human language generation for problem solving, for example to answer complex questions and to build arguments step-by-step 1-3 . LLMs generate text auto-regressively, by incrementally predicting the next text token from preceding text 4 . Despite the simplicity of this underlying process, LLMs can solve tasks across diverse domains including medicine and biology, exceeding human experts on certain tasks 1,5-8 . Novel methods such as chain-ofthought reasoning further enhance their capabilities by imitating complex, causal reasoning patterns 9,10 .Here we describe, implement, and evaluate a new simulation paradigm based on LLMs. Our approach takes LLMs beyond imitating human writing and thinking. It employs LLMs to simulate biological systems in a qualitative, text-based manner without explicit domain knowledge or manual tuning.Computational modeling of molecular, cellular, and physiological biological processes can be used to gain scientific insights, guide experimental research, and potentially facilitate personalized medicine[11][12][13]. LLM-based simulation may complement existing simulation paradigms, in particular by exploiting the large implicit knowledgebase of LLMs and the versatile sequential model that LLMs operate on.This study provides proof-of-concept of a text-based biological simulator based on GPT-4 1 , evaluates this system in diverse biomedical scenarios, and outlines a roadmap for systematic development and application of LLMs as artificial intelligence (AI) simulators of complex biological processes(Fig. 1a).</p>
<p>Development and evaluation of the SimulateGPT method for LLM-based biological simulation</p>
<p>We first demonstrate the feasibility of LLM-based biological simulation in a simple and well-defined test case, by emulating Conway's Game of Life 14 in GPT-4. In contrast to neural networks, which have been reported to struggle with this task 15 , GPT-4 was able to simulate the "glider" pattern's entire cycle using the provided update rules without manual adaption or dedicated training (Fig. 1b, Supp. Text 1).</p>
<p>Beyond this simple proof-of-concept for GPT-4 based biological simulation, we anticipate that GPT-4 may be particularly useful for qualitative, text-based simulation of complex biological processes that are difficult or impossible to model based on their physical and chemical foundations. GPT-4 contains extensive relevant knowledge, as it has been trained on massive text corpora that appear to include a large percentage of the scientific literature in biology and medicine, as well as websites and discussions about various scientific and non-scientific topics. We found that GPT-4 can be prompted to infer meaningful estimates about cancer progression of cancer patients (Supp. Text 2,3). We thus hypothesized that the comprehensive knowledge incorporated in LLMs could be leveraged as an implicit rule set for simulating systems in biomedical, translational and life sciences disciplines. GPT-4 may thus take on a role similar to human expert panels evaluating biological scenarios, while avoiding some of their pitfalls.</p>
<p>We developed the SimulateGPT method of using GPT-4 as a biomedical simulator. This method enforces stepwise simulation, where each step is composed of a reasoning structure designed to facilitate simulation across multiple levels of biological organization (Supp. Text 4, Fig. 1c). Initial tests showed that our method provided meaningful explanations and probabilities and was generally able to provide correct scientific references to substantiate its reasoning (Fig. 1c, Supp. Text 5). To systematically evaluate the performance of SimulateGPT in terms of its ability to simulate complex biomedical scenarios in a stepwise manner toward outcome predictions, we compared its performance to direct inference prompting (Supp. Text 2) through expert-based and data-driven validations (Fig. 1d).</p>
<p>First, we evaluated SimulateGPT's ability to simulate biological processes in areas of established scientific knowledge through blinded expert surveys with Likert scale questions covering the correctness, explanation, and completeness of the simulation. We formulated four scenarios spanning different levels of complexity (Supp. Text 6): (i) In vivo mouse experiments with known outcomes; (ii) experiments exploring trained immunity, a recent and less well understood immunological concept of immune memory in innate cells; (iii) reasoning about novel treatment decision support based on limited clinical parameters in sepsis; and (iv) tumor mutation effects on overall survival in glioblastoma patients.</p>
<p>For each scenario, the simulation seeks to establish a specific outcome (e.g., progression-free survival of individual patients with colorectal cancer patients, as in Fig. 1c) along with an explanation of the path toward the simulated outcome. We simulated between one and three conditions for each scenario, and the performance was ranked by postdoctoral biologists in a blinded manner. SimulateGPT outperformed conventional GTP-4 based reasoning on outcome prediction in all four scenarios (Fig. 2a, Supp. Fig  S1a). In contrast, the explanations provided by SimulateGPT were not ranked better than those of direct inference prompting (Supp. Fig S1b). This is likely because SimulateGPT's final explanation was often not self-contained, as some of its parts were already provided by preceding simulation steps (Fig. 1c).</p>
<p>Application and extension of the SimulateGPT method to classification and regression tasks</p>
<p>LLMs excel in verbal reasoning tasks but struggle with structured predictions. We hypothesized that the structure that SimulateGPT imposes on LLM reasoning helps address this weakness and thereby improves the performance also for classification and regression tasks. We simulated two scenarios with outcomes for which ground truth data was publicly available for validation, but only accessible through domain-specific data repositories, thus making it highly unlikely that such information was incorporated into the training process of GPT-4. To further control for the possibility of data leakage during GPT-4's training, we evaluated the performance against conventional GTP-4 based reasoning.</p>
<p>In the first scenario, we focused on molecular and cellular mechanisms by simulating the essentiality of individual genes for cancer cell survival framed as a zero-shot binary classification task. The ground truth was provided by large-scale experimental data for the corresponding cancer cell lines. Simu-lateGPT exhibited high precision and recall, and achieved an accuracy of 86% on the class-balanced dataset (Fig. 2c). In contrast, direct inference exhibited a strong bias toward genes being predicted as non-essential, resulting in an accuracy of only 64% (Fig. 2b, Table S1).</p>
<p>In the second scenario, we predicted the expected progression-free survival of patients with colorectal cancer, given their clinical presentation (Fig. 1c, Supp. Text 5). To reduce the considerable variation across cancer datasets, we calibrated our model by few-shot learning with four example outcomes from the test dataset as part of the prompt. Both SimulateGPT and direct inference showed a tendency to underestimate variance in the dataset (i.e., on average they predicted progression-free survival closer to the median than suggested by the data). Nevertheless, SimulateGPT achieved substantially smaller error and increased correlation coefficients compared to direct inference (Fig. 2c, Supp. Table 2).</p>
<p>Investigating our simulation results, we noted that SimulateGPT typically produces three steps before concluding. We wanted to see whether more steps would improve the overall performance. To this end, we derived a low-complexity variant of SimulateGPT with reduced output features (Supp. Text 7), which generated more steps, presumably due to GPT-4's tendency to generate responses of similar length.</p>
<p>The low-complexity variant of SimulateGPT performed worse according to our experts (Fig. 2d), but progression-free survival prediction significantly improved (Fig. 2e). To validate these results, we modified SimulateGPT to enforce at least five simulation steps (Supp. Text 8). This modification led to improved performance (Fig. 2f), adding further support for the use of stepwise simulation in SimulateGPT.</p>
<p>Collectively, our experiments show good predictive performance of SimulateGPT across a diverse range of biomedical scenarios, suggesting that LLMs can be configured as explainable simulators that improve on complex outcome prediction over models that do not follow the step-by-step simulation implemented in SimulateGPT. Our method is readily applicable to a broad range of processes and applications in biology and medicine, facilitating the exploration and prediction of scenarios with minimal configuration. </p>
<p>Structured text-based reasoning using LLMs as a new paradigm for scientific simulation</p>
<p>The results achieved are remarkable given that GPT-4 was not specifically trained on biomedical data nor to operate as a scientific simulator. Nevertheless, this proof-of-concept study can only constitute an initial step toward the promising new research area of LLM-powered biological simulation. We propose ten components that will jointly enable universal biomedical simulation using LLMs. 1) Interactivity: Enabling follow-up dialogs after initial simulations to ask clarifying questions or to re-run simulations with hypothetical "what if" and "zoom in" scenarios at intermediary and terminal states.</p>
<p>2) Knowledge augmentation: Expanding the model's knowledge and reducing risk of LLMs generating incorrect output by allowing dynamic retrieval of information from external sources such as biomedical literature or knowledge graphs 16 .</p>
<p>3) Self-consistency: Running models multiple times with induced stochastic variation, in order to establish consensus results and quantify existing variation 17 . 4) Built-in mathematics and programming: Enabling the model to include mathematical models or run programming code, for example for numeric simulations as well as inline quantitative modeling 16 . 5) Self-reflection: Instructing the model to critique and revise its own simulation results to iteratively improve simulation quality 18 . 6) Bifurcation: Simulations may reach bifurcation points with multiple trajectories of varying probabilities, which could be modeled by splitting autoregressive generation into separate streams. 7) Reverse simulation: Running simulations backward in time to identify causes of an observed state. 8) Multi-modality: LLMs are increasingly capable of using multimodal data, allowing for seamless integration for example of imaging data into simulations. 9) Fine-tuning of simulation models: Creating new and optimized models by fine-tuning existing LLMs on data from biomedical experiments could greatly improve simulation capabilities. 10) Real-world feedback: Simulation is often most powerful when it guides further experimentation, and feeding the results of validation experiments back into the simulations can anchor their intermediary states to reality, enhancing accuracy and simulation breadth.</p>
<p>In conclusion, we envision that the SimulateGPT paradigm will be an important building block of future AI-augmented research infrastructures for biology, medicine, and potentially other scientific fields.</p>
<p>Online Methods</p>
<p>The SimulateGPT method</p>
<p>SimulateGPT (Supp. Text 4) leverages GPT-4 to create a text-based simulator of biological processes. It employs a structured approach to guide GPT-4 in generating a step-by-step simulation of biological processes based on the input parameters provided. SimulateGPT consists of the following main components, driving GPT-4 toward detailed and logically consistent output:</p>
<ol>
<li>input parameters corresponding to the user request 2. a flexible number of simulation steps 3. a final conclusion, comprising an outcome and an explanation Each simulation step is divided into level, facts, entities, assumptions, consequence, probability, explanation, and novelty. To use SimulateGPT effectively, users provide a biological or medical scenario as a starting point for the simulation. Optionally, a perturbation can be included or implied in the input. Users can further describe the type of outcome they are interested in. To increase the novelty of concepts used in the simulation, users can add the phrase "Focus on more novelty" to their prompt.</li>
</ol>
<p>GPT-4 was accessed for SimulateGPT experiments described in this paper in April and May 2023 via their Playground and the API via the langchain library. Default parameters were kept, except for the temperature (0) and the 'Maximum length' (2048). Our simulator prompts were provided as system prompts, whereas the simulation scenarios were provided as user prompts.</p>
<p>Simulating Conway's Game of Life</p>
<p>The simulation rules were described as system prompts, which further included instructions to output each completed configuration in a LaTeX-visualizable matrix format. The human_prompt contained the initial configuration of the grid, in our example the glider. We simulated a complete cycle of the glider (4 steps) without providing intermediary user input. The rendered LaTeX is shown in Fig. 1b.</p>
<p>Application scenario 1: Mouse immunology (qualitative)</p>
<p>Preclinical mouse models and in vivo experiments constitute a cornerstone in the field of biomedical and translational research. Nevertheless, they can be extremely challenging (time, labor, and animal welfare), and according to the 3Rs of animal research (replacement, reduction, and refinement) the reduction of animal experiments, due to ethical considerations, has always been an important objective in biomedical research and motivation for simulations. Immunology is one the most complex biological fields with pronounced organism-wide reciprocal cellular interplay and crosstalk. Advances in understanding immunology are directly translatable to address diseases like cancer, inflammatory and autoimmune disorders, which affect a large proportion of society. To test simple in vivo experimental setups in basic biology and immunology with well-established outcomes we simulated a wild-type mouse model subjected to two different perturbations: injection of cyanide as a chemical toxin 19 and transplantation of YUMM1.7 melanoma cancer cell lines 20 . We chose these two in vivo perturbations as cyanide poisoning and melanoma tumor progression experiments have been well described in literature with a bulk of robust in vivo scientific findings. We chose a prompt describing the most minimal experimental setup and instructions to report the "most relevant final outcome" (Supp. Text 6).</p>
<p>Application scenario 2: Trained immunity (qualitative)</p>
<p>Trained immunity, the concept of immunological memory in innate immune cells, has emerged over the last decade. Two phenotypes are described in the literature, after a primary stimulus: (i) training, characterized by an enhanced immune response upon re-challenge with a secondary stimulus (i.e., unspecific); and (ii) tolerance, characterized by a suppressed immune response upon re-challenge with the primary stimulus 21 . To determine if the (conservative) simulator correctly applies modern immunological concepts to more complex experimental setups, we devised three complementary scenarios. They only differed in their primary stimulus, which should result in innate memory. Concretely, we used beta-glucan for training, low-dose LPS for training, and high-dose LPS for tolerance (Supp. Text 6).</p>
<p>Application scenario 3: Sepsis treatment (qualitative)</p>
<p>Sepsis is a systemic inflammatory response syndrome accompanied with multiple organ dysfunctions 22 . It is a leading cause of death among intensive care patients with treatment options including anti-inflammatory agents and immunomodulators 23 . Sepsis therapies are limited with emerging personalized-medicine centered research attempting to bring forward novel therapies, diagnostic and prognostic markers by patients substratification into two distinct groups: (i) immunoparalysis, characterized by low HLA-DR expression on monocytes; and (ii) hyperinflammation, characterized by high HLA-DR expression on monocytes and increased circulating ferritin concentrations 24 . To test the simulator's reasoning on guiding novel treatment options based on only two reported clinical parameters, we used two scenarios describing the clinical features of each patient group (immunoparalysis and hyperinflammation) in a complementary manner followed by a concrete question for recommended treatment (Supp. Text 6).</p>
<p>Application scenario 4: Glioblastoma (qualitative)</p>
<p>Glioblastoma clinical data was downloaded from TCGA via the web portal for the CPTAC-3 study 25 and enriched with methylation data for the MGMT gene from cBioPortal. Genotypes for the tumors of each clinical data point were further obtained using the TCGA API. Only cases with a valid death date were considered and genotype information was only kept for the top 10 mutated genes in glioblastoma (derived from TCGA). Cases were grouped based on their binary mutation profile (gene mutated or not for the top-10 most frequently altered genes), leading to ten mutation groups with two or more cases each. We simulated each group's genotype using SimulateGPT towards an estimate of overall survival, to be provided as the months-deviation from the 15 month median glioblastoma survival derived from the dataset. Given the heterogeneous nature of this cancer type and the high variance in the dataset (we found linear classifiers to be unable to predict survival rates better than random), we selected the genotype-scenario for which the simulation outcome coincided best with the ground-truth outcome and which comprised at least four cases and asked for expert-assessment.</p>
<p>Application scenario 5: Colorectal cancer (quantitative)</p>
<p>Patient and sample data from a colorectal cancer study 26 were downloaded from cBioPortal. To account for patient-to-patient variation, the data was grouped by (carcinomatosis, tumor stage, tumor site, differentiation grade, cancer type) and aggregated (mean age, median progression-free survival). Groups of common clinical presentation were filtered to contain at least four cases. From these groups, we picked four diverse ones that we provided as few-shot examples in the prompt, to calibrate the model outcome.</p>
<p>The remaining groups (n=18) were simulated toward progression-free survival (in months) as outcome.</p>
<p>Application scenario 6: Gene essentiality in cancer cell-lines (quantitative)</p>
<p>We randomly selected 25 genes that are broadly essential and 25 genes that are broadly non-essential in cancer cell lines, based on gene lists extracted from DepMap (https://depmap.org) 27 . Specifically, we downloaded the essential gene list "CRISPRInferredCommonEssentials.csv" (n=1856), and the nonessential gene list "AchillesNonessentialControls.csv" (n=781) from DepMap Public release 22Q4. We randomly subsetted these gene lists to 25 genes each using the R function "sample" (random seed=42).</p>
<p>Expert evaluation</p>
<p>The qualitative evaluation of the simulation outcomes of application scenarios 1-4 was performed by three domain experts (postdoctoral researchers) that were blinded and not otherwise involved in the study design. We designed a questionnaire consisting of 9 statements, to be judged using a 7-level Likert scale, of which 7 were chosen based on previous studies in the field 28 , one was added to ask for novelty, and one to give experts the chance to judge their qualifications to evaluate this topic (Supp. Text 9). To ensure comparability and rigor we only compared the two coinciding fields (by design) of the direct inference and SimulateGPT system namely, outcome and explanation, in a blinded/randomized fashion. Additionally, we let them evaluate the full simulation output of SimulateGPT and low complexity system (Supp. Text 7) for the sepsis treatment experiments. The results were computationally unblinded and quantified using a direct comparison between the direct inference and SimulateGPT, yielding a count for worse, same, or better for each question and scenario, depending on the nature of the question. Thereby, we were able to account for inter-expert variation and potential biases due to the unbalanced number of cases per experiment. The final result was aggregated into percentages and visualized using stacked bar plots per experiment, across experiments, and per question across experiments ( Fig.  2a/d, Supp. Fig S1). Statistical analysis was performed for each direct comparison group (each row in all bar plots) using a two-sided Wilcoxon signed-rank test on the relative comparison data. Exact pvalues for all tested comparisons are provided with our code repository.</p>
<p>Code &amp; Data availability </p>
<p>Competing interests</p>
<p>CB is a cofounder and scientific advisor of Aelian Biotechnology and Neurolentech. The other authors declare no competing interests. Figure S1 Comprehensive expert evaluation results a, Simulation outcome expert evaluation as in Fig. 2a </p>
<p>Supplementary Material</p>
<p>Supplementary Text 1: Conway's Game of Life "glider" simulation</p>
<p>GPT-4 SYSTEM PROMPT</p>
<p>As a large language model, simulate and describe the evolution of a given configuration in Conway's Game of Life for one generation. Conway's Game of Life takes place on a finite 4x4 grid of square cells where each cell can be either alive or dead and dead cells surrounding it. The rules for each generation are as follows:</p>
<p>1 In addition, provide the new generation also in a LaTex bracketed matrix format. This is purely for providing feedback to the user and should not be used to simulate downstream simulations. Provide the latex using an empty space for dead and \blacksquare for alive cells as follows:
\begin{bmatrix} &amp; \blacksquare &amp; &amp; \ ... \end{bmatrix}
Following this entire description, simulate as many generations as indicated by the user. </p>
<p>GPT-4 USER PROMPT</p>
<p>Supplementary Text 2: GPT-4 prompt for direct inference</p>
<p>GPT-4 SYSTEM PROMPT</p>
<p>You are a science-based, comprehensive and mechanistic AI system with knowledge of biomedical processes across all levels of biology: molecular, cellular, organ, and organism. Your input consists of parameters describing a biomedical scenario and an outcome request. Based on the input, you infer the requested outcome. Format your response in YAML, following this schema: conclusion: outcome: <Infer the final outcome based on the provided input.> explanation: <Offer a good explanation as evidence that supports the final outcome.></p>
<p>Supplementary Text 3: Example simulation for colorectal cancer patient prognosis</p>
<p>GPT-4 USER PROMPT</p>
<p>Consider a 60 year old patient who is diagnosed with stage IV colon adenocarcinoma on the right side of the colon. The tumor exhibits moderately differentiated differentiation histology, has metastasized and shows no signs of carcinomatosis.</p>
<p>Given the general effectiveness of colon adenocarcinoma therapies, explore how the disease progresses under an optimal standard of care treatment plan, focusing on the molecular and higher-level processes impacting tumor progression. As the final outcome, report the expected progression-free survival in months.</p>
<p>GPT-4 OUTPUT</p>
<p>conclusion: outcome: 8-12 months explanation: The patient is diagnosed with stage IV colon adenocarcinoma, which indicates that the cancer has metastasized to distant organs. The moderately differentiated histology suggests that the tumor cells are somewhat similar to normal cells, which may make them more responsive to treatment than poorly differentiated cells. However, the advanced stage of the cancer and the patient's age may limit the effectiveness of treatment. Under an optimal standard of care treatment plan, which may include surgery, chemotherapy, and targeted therapy, the expected progression-free survival for stage IV colon cancer patients is typically between 8-12 months. This estimate takes into account the molecular and higher-level processes impacting tumor progression, such as the ability of cancer cells to evade the immune system, develop resistance to therapy, and establish new blood vessels to support their growth.</p>
<p>Supplementary Text 4: GPT-4 prompt for stepwise simulation used by SimulateGPT</p>
<p>GPT-4 SYSTEM PROMPT</p>
<p>You are a science-based, comprehensive and mechanistic simulator of biomedical processes across all levels of biology: molecular, cellular, organ, and organism.</p>
<p>Your input consists of simulation parameters. Based on the input, you simulate all relevant processes that unfold step-by-step until a final outcome can be directly inferred from the simulation Simulation rules: -Begin the simulation at the level of biology matching the input best.</p>
<p>-Ensure that each step logically informs the next step.</p>
<p>-Use as many steps as necessary.</p>
<p>-Conclude the simulation with a final outcome, once it can be directly inferred from the simulation steps.</p>
<p>Aim for an informative level of detail. Ensure that every step logically follows up on all previous steps and that processes in subsequent steps are informed by previous steps. Format your response in YAML, following this schema:</p>
<p>parameters:</p>
<p>-<first relevant parameter for simulation> -<second relevant parameter for simulation> -... simulation:</p>
<p>-step: 1 level: <Indicate the level of biology of this step.> facts: <Provide a comprehensive overview of facts about the entities and processes you are considering, including facts that are not stated in the query. Attempt to include gene regulation, protein interactions, cell types, tissue functions, and organ functions that might influence the step and its consequences. Avoid repeating any facts that you already provided. Mention facts that might become relevant later. Provide references for all facts you list at the end only using the provided structure and indicate it using [1].> entities: <Enumerate all involved entities such as genes, proteins, cell types, tissues, organs, etc. by their name.> assumptions: <Integrate the stated facts and previous consequences into assumptions about the current step.> consequence: <Generate the most probable consequence, given the facts, assumptions, and any previously generated consequences. Given the level of biology of this step, provide fitting specifics like different types of entities (e.g. small molecules, RNA, DNA, proteins, metabolites, cell types, tissues, organs) and processes (e.g., interactions, pathways, biological processes, biochemical reactions, tissue function, organ function). For example: decreased \<gene X> expression by \<cell type X>, increased \<metabolite X> levels in the blood, changed \<morphology X> in \<tissue X>, increased \<organ X> function, systemic \<phenotype X>, etc.> probability: <The probability of the consequence happening on a scale of 0 to 100.> explanation: <Offer a good explanation as evidence that supports the listed consequence.> novelty: <How novel or unconventional is your reasoning on a scale of 0 to 100.> -step: 2 ... conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome.> references: "[1]": "<authors> <year> <journal> <title of the publication>" " [2]": "<authors> <year> <journal> <title of the publication>" …</p>
<p>Supplementary Text 5: Example SimulateGPT simulation for colorectal cancer prognosis</p>
<p>GPT-4 USER PROMPT (same as in Supp. Text 3)</p>
<p>Consider a 60 year old patient who is diagnosed with stage IV colon adenocarcinoma on the right side of the colon. The tumor exhibits moderately differentiated differentiation histology, has metastasized and shows no signs of carcinomatosis.</p>
<p>Given the general effectiveness of colon adenocarcinoma therapies, explore how the disease progresses under an optimal standard of care treatment plan, focusing on the molecular and higher-level processes impacting tumor progression. As the final outcome, report the expected progression-free survival in months.</p>
<p>GPT-4 OUTPUT</p>
<p>parameters:</p>
<p>-age: 60 -diagnosis: stage IV colon adenocarcinoma -tumor_location: right side of the colon -differentiation_histology: moderately differentiated -metastasis: present -carcinomatosis: absent -treatment: optimal standard of care simulation: -step: 1 level: molecular facts: The standard of care for stage IV colon adenocarcinoma typically includes chemotherapy, targeted therapy, and immunotherapy [1]. Chemotherapy drugs, such as 5-fluorouracil (5-FU), oxaliplatin, and irinotecan, target rapidly dividing cancer cells [2]. Targeted therapies, like bevacizumab and cetuximab, inhibit specific molecular pathways involved in tumor growth and progression [3]. Immunotherapies, such as pembrolizumab, enhance the immune system's ability to recognize and destroy cancer cells [4]. entities: 5-fluorouracil, oxaliplatin, irinotecan, bevacizumab, cetuximab, pembrolizumab assumptions: The patient receives the optimal standard of care treatment, which includes a combination of chemotherapy, targeted therapy, and immunotherapy.</p>
<p>consequence: Decreased tumor cell proliferation and increased cancer cell death. probability: 80 explanation: The combination of chemotherapy, targeted therapy, and immunotherapy is expected to effectively target and kill cancer cells, reducing tumor growth and progression. novelty: 0 -step: 2 level: cellular facts: Tumor cells can develop resistance to chemotherapy and targeted therapies through various mechanisms, such as drug efflux, DNA repair, and alterations in drug targets [5]. Immunotherapies can also become less effective due to immune evasion by cancer cells [6]. entities: drug resistance, immune evasion assumptions: The patient's cancer cells may develop resistance to the administered treatments over time.</p>
<p>consequence: Reduced treatment effectiveness and potential tumor progression. probability: 60 explanation: The development of drug resistance and immune evasion can lead to reduced treatment effectiveness, allowing the tumor to progress despite the optimal standard of care.</p>
<p>novelty: 0 -step: 3 level: organ facts: Metastatic colon cancer can spread to other organs, such as the liver, lungs, and peritoneum [7]. The presence of metastasis can complicate treatment and negatively impact prognosis [8].</p>
<p>entities: liver, lungs, peritoneum assumptions: The patient's cancer has already metastasized, which may affect the treatment response and prognosis.</p>
<p>consequence: Increased difficulty in achieving complete tumor control and potential for further metastasis.</p>
<p>probability: 70 explanation: The presence of metastasis increases the complexity of treatment and the likelihood of further metastatic spread, which can negatively impact the patient's prognosis.</p>
<p>novelty: 0 conclusion: outcome: The expected progression-free survival is approximately 12 months. explanation: The optimal standard of care treatment plan, including chemotherapy, targeted therapy, and immunotherapy, is expected to initially control tumor growth and progression. However, the development of drug resistance, immune evasion, and the presence of metastasis may eventually lead to treatment failure and disease progression. Based on the simulation, the expected progression-free survival for this patient is approximately 12 months [9]. </p>
<p>GPT-4 USER PROMPTS</p>
<p>Mouse immunology: Cyanide</p>
<p>A wild type mouse is injected with Cyanide. Report the most relevant final outcome.</p>
<p>YUMM_1_7</p>
<p>A wild type mouse is injected with YUMM 1.7. Report the most relevant final outcome. </p>
<p>Sepsis treatment: sepsis_hyperinflammation</p>
<p>A patient with sepsis has high ferritin levels and a high percentage of CD45/CD14-monocytes that express HLA-DR. What treatment would be recommended? sepsis_immunoparalysis A patient with sepsis has low ferritin levels and a low percentage of CD45/CD14-monocytes that express HLA-DR. What treatment would be recommended?</p>
<p>Supplementary Text 7: GPT-4 prompt used by low-complexity SimulateGPT simulation</p>
<p>You are a science-based, comprehensive and mechanistic simulator of biomedical processes across all levels of biology: molecular, cellular, organ, and organism.</p>
<p>Your input consists of simulation parameters. Based on the input, you simulate all relevant processes that unfold step-by-step until a final outcome can be directly inferred from the simulation Simulation rules: -Begin the simulation at the level of biology matching the input best.</p>
<p>-Ensure that each step logically informs the next step.</p>
<p>-Use as many steps as necessary.</p>
<p>-Conclude the simulation with a final outcome, once it can be directly inferred from the simulation steps. Aim for an informative level of detail. Ensure that every step logically follows up on all previous steps and that processes in subsequent steps are informed by previous steps. Format your response in YAML, following this schema: simulation:</p>
<p>-step: 1 level: <Indicate the level of biology of this step.> consequence: <Generate the most probable consequence, given any previously generated consequences. Given the level of biology of this step, provide fitting specifics like different types of entities (e.g. small molecules, RNA, DNA, proteins, metabolites, cell types, tissues, organs) and processes (e.g., interactions, pathways, biological processes, biochemical reactions, tissue function, organ function).> probability: <The probability of the consequence happening on a scale of 0 to 100.> explanation: <Offer a good explanation as evidence that supports the listed consequence.> -step: 2 ... conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome.></p>
<p>Supplementary Text 8: GPT-4 prompt used by high-complexity SimulateGPT simulation</p>
<p>You are a science-based, comprehensive and mechanistic simulator of biomedical processes across all levels of biology: molecular, cellular, organ, and organism.</p>
<p>Your input consists of simulation parameters. Based on the input, you simulate all relevant processes that unfold step-by-step until a final outcome can be directly inferred from the simulation Simulation rules: -Begin the simulation at the level of biology matching the input best.</p>
<p>-Ensure that each step logically informs the next step.</p>
<p>-Use at least 5 steps and as many more as necessary.</p>
<p>-Conclude the simulation with a final outcome, once it can be directly inferred from the simulation steps.</p>
<p>Aim for an informative level of detail. Ensure that every step logically follows up on all previous steps and that processes in subsequent steps are informed by previous steps. Format your response in YAML, following this schema:</p>
<p>parameters: -<first relevant parameter for simulation> -<second relevant parameter for simulation> -... simulation:</p>
<p>-step: 1 level: <Indicate the level of biology of this step.> facts: <Provide a comprehensive overview of facts about the entities and processes you are considering, including facts that are not stated in the query. Attempt to include gene regulation, protein interactions, cell types, tissue functions, and organ functions that might influence the step and its consequences. Avoid repeating any facts that you already provided. Mention facts that might become relevant later. Provide references for all facts you list at the end only using the provided structure and indicate it using [1].> entities: <Enumerate all involved entities such as genes, proteins, cell types, tissues, organs, etc. by their name.> assumptions: <Integrate the stated facts and previous consequences into assumptions about the current step.> consequence: <Generate the most probable consequence, given the facts, assumptions, and any previously generated consequences. Given the level of biology of this step, provide fitting specifics like different types of entities (e.g. small molecules, RNA, DNA, proteins, metabolites, cell types, tissues, organs) and processes (e.g., interactions, pathways, biological processes, biochemical reactions, tissue function, organ function). For example: decreased \<gene X> expression by \<cell type X>, increased \<metabolite X> levels in the blood, changed \<morphology X> in \<tissue X>, increased \<organ X> function, systemic \<phenotype X>, etc.> probability: <The probability of the consequence happening on a scale of 0 to 100.> explanation: <Offer a good explanation as evidence that supports the listed consequence.> novelty: <How novel or unconventional is your reasoning on a scale of 0 to 100.> -step: 2 ... </p>
<p>Supplementary Text 9: Expert evaluation questions</p>
<p>Figure 1 .
1Implementation and testing of a universal biological simulator based on GPT-4. a, Schematic overview of SimulateGPT, a GPT-4 based biological simulator. b, Depiction of the use of GPT-4 in a simulation of Conway's Game of Life. c, Example prompts and output of SimulateGPT. d, Overview of the evaluation methods used to validate SimulateGPT.</p>
<p>Figure 2
2Qualitative and quantitative evaluation of SimulateGPT. a, Expert evaluation of the simulation for four biomedical scenarios, comparing SimulateGPT to conventional GTP-4 based reasoning. b, Performance of SimulateGPT in predicting broadly essential genes in cancer cell lines. c, Performance of SimulateGPT in predicting progression-free survival in patients with colorectal cancer. d, Expert evaluation of simulation results of the sepsis treatment experiment using SimulateGPT versus 'low complexity SimulateGPT'. e-f, Performance of SimulateGPT in predicting progression-free survival in colorectal cancer patients with the low complexity simulation (panel e) and high complexity simulation with a minimum of 5 simulation steps (panel f). Confidence intervals represent standard error. Significance: * = P ≤ 0.05, ** = P ≤ 0.01. *** = P ≤ 0.001.</p>
<p>-
Level: The level of biology addressed in this step (e.g., molecular, cellular, organ, organism) -Facts: An overview of relevant facts, including gene regulation, protein interactions, etc. -Entities: A list of all entities in the step, such as genes, proteins, cell types, tissues, and organs -Assumptions: Integration of stated facts and previous consequences into assumptions about the current step -Consequence: The most probable consequence based on facts, assumptions, and previously generated consequences, including specific entities and processes -Probability: The likelihood of the consequence happening, on a scale of 0 to 100 -Explanation: A well-reasoned explanation supporting the listed consequence -Novelty: A rating of how novel or unconventional the reasoning is, on a scale of 0 to 100</p>
<p>the eight adjacent cells, horizontally, vertically, and diagonally. For each generation, describe how you simulate the new grid in excruciating detail: For each cell in the grid (i, j) indicate all its neighbors with their states, count the number of living ones (just count the number of listed neighbors with state 'live'). Then, state the current state of the current cell of interest and derive its next generation's state following the rules stated above. Simulate each cell as just described in the format (<i,j>)$[[<neighbors>]#COUNT=<num-ber_of_alive_neighbors>]$$$oldstate=<new_state> where <neighbors> is a list of all neighbors and their states, as in "(0,1):dead|alive, ...". Finally, after the new states of all cells have been computed, print the new generation as indicated by the provided initial generation (Generation 0).</p>
<p>": "Van Cutsem E, Cervantes A, Nordlinger B, Arnold D; ESMO Guidelines Working Group. 2014. Ann Oncol. ESMO consensus guidelines for the management of patients with metastatic colorectal cancer." "[2]": "Longley DB, Harkin DP, Johnston PG. 2003. Nat Rev Cancer. 5-fluorouracil: mechanisms of action and clinical strategies." "[3]": "Cunningham D, Humblet Y, Siena S, et al. 2004. N Engl J Med. Cetuximab monotherapy and cetuximab plus irinotecan in irinotecan-refractory metastatic colorectal cancer." "[4]": "Le DT, Uram JN, Wang H, et al. 2015. N Engl J Med. PD-1 Blockade in Tumors with Mismatch-Repair Deficiency." "[5]": "Holohan C, Van Schaeybroeck S, Longley DB, Johnston PG. 2013. Nat Rev Cancer. Cancer drug resistance: an evolving paradigm." "[6]": "Sharma P, Hu-Lieskovan S, Wargo JA, Ribas A. 2017. Cell. Primary, Adaptive, and Acquired Resistance to Cancer Immunotherapy." "[7]": "Manfredi S, Lepage C, Hatem C, Coatmeur O, Faivre J, Bouvier AM. 2006. Br J Cancer. Epidemiology and management of liver metastases from colorectal cancer." "[8]": "Van Cutsem E, Köhne CH, Láng I, et al. 2011. J Clin Oncol. Cetuximab Plus Irinotecan, Fluorouracil, and Leucovorin As First-Line Treatment for Metastatic Colorectal Cancer: Updated Analysis of Overall Survival According to Tumor KRAS and BRAF Mutation Status." "[9]": "Heinemann V, von Weikersthal LF, Decker T, et al. 2014. Lancet Oncol. FOLFIRI plus cetuximab versus FOLFIRI plus bevacizumab as first-line treatment for patients with metastatic colorectal cancer (FIRE-3): a randomised, open-label, phase 3 trial." Supplementary Text 6: Expert-evaluated scenarios</p>
<p>-
The output reflects the consensus in the scientific and clinical community. -The output contains evidence of correct recall of knowledge. -The output contains evidence of incorrect recall of knowledge. -The output contains evidence of correct reasoning steps. -The output contains evidence of incorrect reasoning steps. -The output contains content it shouldn't contain. -The output omits content it shouldn't omit. -The answer contains (novel) concepts that are not typically known in the scientific and clinical community. -I felt qualified to evaluate this topic.</p>
<p>Singhal, K. et al. Large Language Models Encode Clinical Knowledge. arXiv (2022) doi:10.48550/arxiv.2212.13138. original draft, visualization. AN: expertise, validation. FP: expertise, validation. TK: expertise, validation. PS: Investigation, Resources. CB: supervision, funding acquisition, writing -review &amp; editing, MaS: conceptualization, supervision, funding acquisition, project administration, writing -original draft.All relevant data, including full text simulations, expert validation and code to reproduce our results are 
available from the following repository: https://github.com/OpenBioLink/SimulateGPT </p>
<p>A runnable version of SimulateGPT is available through Google Colab (for SimulateGPT to use GPT-4 
securely, the user needs to provide a personal OpenAI API key that allows for GPT-4 access): 
https://colab.research.google.com/github/OpenBioLink/SimulateGPT/blob/main/SimulateGPT.ipynb 
20. 
Meeth, K., Wang, J. X., Micevic, G., Damsky, W. &amp; Bosenberg, M. W. The YUMM lines: a se-
ries of congenic mouse melanoma cell lines with defined genetic alterations. Pigment Cell Mela-
noma Res. 29, 590-597 (2016). </p>
<ol>
<li>
<p>Netea, M. G. et al. Defining trained immunity and its role in health and disease. Nat. Rev. Im-
munol. 20, 375-388 (2020). </p>
</li>
<li>
<p>Hotchkiss, R. S. et al. Sepsis and septic shock. Nat. Rev. Dis. Primers 2, 16045 (2016). </p>
</li>
<li>
<p>Jarczak, D., Kluge, S. &amp; Nierhaus, A. Sepsis-Pathophysiology and Therapeutic Concepts. 
Front Med (Lausanne) 8, 628302 (2021). </p>
</li>
<li>
<p>Leventogiannis, K. et al. Toward personalized immunotherapy in sepsis: The PROVIDE ran-
domized clinical trial. Cell Rep. Med. 3, 100817 (2022). </p>
</li>
<li>
<p>Wang, L.-B. et al. Proteogenomic and metabolomic characterization of human glioblastoma. 
Cancer Cell 39, 509-528.e20 (2021). </p>
</li>
<li>
<p>Mondaca, S. et al. Specific mutations in APC, but not alterations in DNA damage response, 
associate with outcomes of patients with metastatic colorectal cancer. Gastroenterology 159, 
1975-1978.e4 (2020). </p>
</li>
<li>
<p>DepMap, B. DepMap 22Q4 Public. Figshare (2022) doi:10.6084/m9.figshare.21637199.v2. </p>
</li>
<li>
<p>Author contributions </p>
</li>
</ol>
<p>MoS: project administration, investigation, formal analysis, methodology, software, writing -original 
draft, validation. SR: project administration, investigation, formal analysis, methodology, writing -original 
draft, validation, resources. RtH: project administration, investigation, formal analysis, methodology, 
writing -</p>
<p>Trained immunity :
immunitytolerance_LPSA mouse is injected with high-dose LPS. What is the innate immune response upon rechallenge with high-dose LPS after 90 days? Focus on novelty.training_LPSA mouse is injected with low-dose LPS. What is the innate immune response upon rechallenge with high-dose LPS after 90 days? Focus on novelty. training_betaglucan A mouse is injected with beta-glucan. What is the innate immune response upon rechallenge with high-dose LPS after 90 days? Focus on novelty.</p>
<p>. Openai, 10.48550/arxiv.2303.08774GPT-4 Technical ReportOpenAI. GPT-4 Technical Report. arXiv (2023) doi:10.48550/arxiv.2303.08774.</p>
<p>A Chowdhery, 10.48550/arxiv.2204.02311Scaling Language Modeling with Pathways. arXiv (2022). Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. arXiv (2022) doi:10.48550/arxiv.2204.02311.</p>
<p>. V Sanh, 10.48550/arxiv.2110.08207Multitask Prompted Training Enables Zero-Shot Task Generalization. arXivSanh, V. et al. Multitask Prompted Training Enables Zero-Shot Task Generalization. arXiv (2021) doi:10.48550/arxiv.2110.08207.</p>
<p>Attention is all you need. A Vaswani, 10.48550/arxiv.1706.03762Vaswani, A. et al. Attention is all you need. arXiv (2017) doi:10.48550/arxiv.1706.03762.</p>
<p>H Nori, N King, S M Mckinney, D Carignan, E Horvitz, 10.48550/arxiv.2303.13375Capabilities of GPT-4 on Medical Challenge Problems. arXiv. Nori, H., King, N., McKinney, S. M., Carignan, D. &amp; Horvitz, E. Capabilities of GPT-4 on Medi- cal Challenge Problems. arXiv (2023) doi:10.48550/arxiv.2303.13375.</p>
<p>Towards Expert-Level Medical Question Answering with Large Language Models. K Singhal, 10.48550/arxiv.2305.09617Singhal, K. et al. Towards Expert-Level Medical Question Answering with Large Language Models. arXiv (2023) doi:10.48550/arxiv.2305.09617.</p>
<p>Can large language models reason about medical questions?. V Liévin, C E Hother, O Winther, 10.48550/arxiv.2207.08143Liévin, V., Hother, C. E. &amp; Winther, O. Can large language models reason about medical ques- tions? arXiv (2022) doi:10.48550/arxiv.2207.08143.</p>
<p>Emergent autonomous scientific research capabilities of large language models. D A Boiko, R Macknight, G Gomes, 10.48550/arxiv.2304.05332arXivBoiko, D. A., MacKnight, R. &amp; Gomes, G. Emergent autonomous scientific research capabilities of large language models. arXiv (2023) doi:10.48550/arxiv.2304.05332.</p>
<p>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. J Wei, 10.48550/arxiv.2201.11903Wei, J. et al. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv (2022) doi:10.48550/arxiv.2201.11903.</p>
<p>Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. E Kıcıman, R Ness, A Sharma, C Tan, 10.48550/arxiv.2305.00050Kıcıman, E., Ness, R., Sharma, A. &amp; Tan, C. Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. arXiv (2023) doi:10.48550/arxiv.2305.00050.</p>
<p>The challenges of in silico biology. B Palsson, Nat. Biotechnol. 18Palsson, B. The challenges of in silico biology. Nat. Biotechnol. 18, 1147-1150 (2000).</p>
<p>The virtual physiological human: ten years after. M Viceconti, P Hunter, Annu. Rev. Biomed. Eng. 18Viceconti, M. &amp; Hunter, P. The virtual physiological human: ten years after. Annu. Rev. Bio- med. Eng. 18, 103-123 (2016).</p>
<p>F Pappalardo, G Russo, F M Tshinanu, M Viceconti, silico clinical trials: concepts and early adoptions. 20Pappalardo, F., Russo, G., Tshinanu, F. M. &amp; Viceconti, M. In silico clinical trials: concepts and early adoptions. Brief. Bioinformatics 20, 1699-1708 (2019).</p>
<p>. M Gardner, Mathematical Games. Sci. Am. 223Gardner, M. Mathematical Games. Sci. Am. 223, 120-123 (1970).</p>
<p>It's Hard for Neural Networks To Learn the. J M Springer, G T Kenyon, 10.48550/arxiv.2009.01398Game of Life. arXiv. Springer, J. M. &amp; Kenyon, G. T. It's Hard for Neural Networks To Learn the Game of Life. arXiv (2020) doi:10.48550/arxiv.2009.01398.</p>
<p>G Mialon, 10.48550/ar-xiv.2302.07842Augmented Language Models: a Survey. arXiv. Mialon, G. et al. Augmented Language Models: a Survey. arXiv (2023) doi:10.48550/ar- xiv.2302.07842.</p>
<p>Self-Consistency Improves Chain of Thought Reasoning in Language Models. X Wang, 10.48550/arxiv.2203.11171Wang, X. et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv (2022) doi:10.48550/arxiv.2203.11171.</p>
<p>Reflexion: an autonomous agent with dynamic memory and self-reflection. N Shinn, B Labash, A Gopinath, 10.48550/arxiv.2303.11366arXivShinn, N., Labash, B. &amp; Gopinath, A. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv (2023) doi:10.48550/arxiv.2303.11366.</p>
<p>Cyanide toxicokinetics: the behavior of cyanide, thiocyanate and 2-amino-2-thiazoline-4-carboxylic acid in multiple animal models. R K Bhandari, J. Anal. Toxicol. 38Bhandari, R. K. et al. Cyanide toxicokinetics: the behavior of cyanide, thiocyanate and 2- amino-2-thiazoline-4-carboxylic acid in multiple animal models. J. Anal. Toxicol. 38, 218-225 (2014).</p>
<p>Glioblastoma survival. Glioblastoma survival:</p>
<p>As final outcome, provide two values, first indicating whether the patient's survival is more likely to be 'increased' or 'decreased' relative to the median overall glioblastoma survival (15 months), and second, the number of months by which you estimate the survival to deviate from that median. Focus on novelty and ignore the inherent uncertainty of this scenario to provide bold estimates based on your knowledge. Identified mutations: PTEN: mutations found EGFR: mutations found MGMT methylation status: high TP53: no mutations found PIK3CA: no mutations found NF1: no mutations found MUC16: no mutations found RB1: no mutations found conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome. Consider a patient diagnosed with a glioblastoma with genetic alterations, as indicated below. Explore the tumor progression under standard of care with genotype-informed treatment (if applicable). > references: "[1]": "<authors> <year> <journal> <title of the publication>" "[2]": "<authors> <year> <journal> <title of the publication>" …Consider a patient diagnosed with a glioblastoma with genetic alterations, as indicated below. Explore the tumor progression under standard of care with genotype-informed treat- ment (if applicable). As final outcome, provide two values, first indicating whether the patient's survival is more likely to be 'increased' or 'decreased' relative to the median overall glioblastoma survival (15 months), and second, the number of months by which you estimate the survival to deviate from that median. Focus on novelty and ignore the inher- ent uncertainty of this scenario to provide bold estimates based on your knowledge. Identified mutations: PTEN: mutations found EGFR: mutations found MGMT methylation status: high TP53: no mutations found PIK3CA: no mutations found NF1: no mutations found MUC16: no mutations found RB1: no mutations found conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome.> references: "[1]": "<authors> <year> <journal> <title of the publication>" "[2]": "<authors> <year> <journal> <title of the publication>" …</p>            </div>
        </div>

    </div>
</body>
</html>