<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7365 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7365</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7365</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-265067109</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.05462v2.pdf" target="_blank">ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</a></p>
                <p><strong>Paper Abstract:</strong> Cybersecurity breaches targeting electrical substations constitute a significant threat to the integrity of the power grid, necessitating comprehensive defense and mitigation strategies. Any anomaly in information and communication technology (ICT) should be detected for secure communications between devices in digital substations. This paper proposes large language models (LLM), e.g., ChatGPT, for the cybersecurity of IEC 61850-based digital substation communications. Multicast messages such as generic object oriented system event (GOOSE) and sampled value (SV) are used for case studies. The proposed LLM-based cybersecurity framework includes, for the first time, data pre-processing of communication systems and human-in-the-loop (HITL) training (considering the cybersecurity guidelines recommended by humans). The results show a comparative analysis of detected anomaly data carried out based on the performance evaluation metrics for different LLMs. A hardware-in-the-loop (HIL) testbed is used to generate and extract dataset of IEC 61850 communications.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7365.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7365.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-4.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT 4.0</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Used as an LLM-based intrusion detection system with a human-in-the-loop (HITL) workflow to detect anomalies in IEC 61850 GOOSE and SV packet datasets extracted from a hardware-in-the-loop (HIL) testbed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4.0</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>HITL prompt-based classification: convert IDS rules/recommendations to textual instructions and use LLM inference to label individual packet records as normal or anomalous (no model weight fine-tuning reported).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Not provided verbatim in paper; authors state they converted the IDS algorithm and human recommendations into text prompts that ask the model to label GOOSE/SV packet rows as normal or anomalous and provide reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>GOOSE and SV packet logs extracted from a HIL testbed (pcap -> feature tables). Three HITL training levels applied to prompts/data: 'without' (no recommendations), 'partial' (human recommendations for DI and DoS), and 'full' (all human recommendations covering DI, DoS, RE, system problems). No model fine-tuning of weights reported; supervision is via HITL textual instructions/prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Network packet logs / tabular time-series (GOOSE and SV features: time, DM, SM, APPID, datSet, goID, gocbRef, stNum, sqNum, data1, data2 for GOOSE; svID, smpCnt, etc. for SV).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GOOSE and SV datasets extracted from IEC 61850 HIL testbed (pcap captures).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>TPR (recall), FPR, FNR, Precision, F1-score.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Full training (HITL full recommendations): GOOSE — TPR 98.18%, FPR 4.00%, FNR 1.82%, Precision 98.18%, F1-score 98.18%. SV — TPR 96.67%, FPR 0.00%, FNR 3.33%, Precision 100.00%, F1-score 98.30%. (Results reported in Table I of the paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against Anthropic's Claude 2 and Google Bard/PaLM 2 on the same datasets and HITL training levels; ChatGPT 4.0 outperformed these LLMs across reported metrics at all training levels.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>HITL prompt-based supervision (not described as zero-shot or standard few-shot). Experiments used three supervision levels via human recommendations (without, partial, full) rather than model weight fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes computational speed limitations (online detection focus, not real-time), privacy/security concerns when LLMs access critical infrastructure data, and that LLMs can produce false positives/negatives depending on training level; no detailed failure-case breakdown beyond comparative metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7365.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7365.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anthropic's Claude 2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evaluated as an LLM-based IDS with the same HITL prompt-based procedure on GOOSE and SV datasets from the HIL testbed; performance reported alongside other LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Anthropic Claude 2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>HITL prompt-based classification using human-converted IDS rules and recommendations as prompts; labels packet entries as anomalous or normal (no weight fine-tuning reported).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Not provided verbatim; described as converted IDS rules and human recommendations presented to the model to label packet records.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Same GOOSE and SV datasets from HIL testbed; three HITL levels: without, partial (DI & DoS), full (all recommendations). No model fine-tuning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Network packet logs / tabular time-series (GOOSE and SV features).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GOOSE and SV datasets extracted from IEC 61850 HIL testbed (pcap captures).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>TPR (recall), FPR, FNR, Precision, F1-score.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Full training (HITL full recommendations): GOOSE — TPR 89.09%, FPR 32.00%, FNR 10.91%, Precision 85.96%, F1-score 87.50%. SV — TPR 88.30%, FPR 0.00%, FNR 11.67%, Precision 100.00%, F1-score 93.80%. (Reported in Table I.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to ChatGPT 4.0 (see reported metrics) and Google Bard/PaLM 2; Claude 2 had competitive precision on SV but lower TPR/F1 than ChatGPT 4.0 in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>HITL prompt-based supervision at three levels; not described as zero-shot/few-shot or as model fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Higher false positive rate on GOOSE (noted FPR = 32% at full training) relative to ChatGPT; general limitations include computational speed and privacy risks as discussed for all LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7365.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7365.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bard/PaLM-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google Bard / PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evaluated as an LLM-based IDS under the same HITL prompt-based framework on GOOSE and SV packet datasets from an HIL testbed; used for comparative performance analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Google Bard / PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>HITL prompt-based classification: IDS rules and human recommendations converted to text prompts to have the model label packet rows as anomalous or normal; no model weight fine-tuning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Not provided verbatim; authors converted IDS logic and recommendations into prompts instructing the model to classify packet entries and explain anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>GOOSE and SV datasets from HIL testbed; three HITL levels (without, partial, full). No fine-tuning of model weights reported.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Network packet logs / tabular time-series (GOOSE and SV features).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GOOSE and SV datasets extracted from IEC 61850 HIL testbed (pcap captures).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>TPR (recall), FPR, FNR, Precision, F1-score.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Full training (HITL full recommendations): GOOSE — TPR 89.10%, FPR 20.00%, FNR 10.90%, Precision 90.70%, F1-score 90.70%. SV — TPR 81.60%, FPR 25.00%, FNR 18.34%, Precision 91.70%, F1-score 85.90%. (Reported in Table I.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to ChatGPT 4.0 and Anthropic Claude 2 on identical datasets and HITL training levels; performed worse than ChatGPT 4.0 in reported TPR/F1 metrics and showed higher FPR on SV.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>HITL prompt-based supervision (without, partial, full) rather than classical zero-shot/few-shot or fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relatively higher false positive rates in some cases (e.g., SV FPR 25% at full training) and lower recall versus ChatGPT 4.0; general LLM limitations and privacy concerns noted.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Ereno: A framework for generating realistic iec-61850 intrusion detection datasets for smart grids <em>(Rating: 2)</em></li>
                <li>Unsupervised learning based intrusion detection for GOOSE messages in digital substation <em>(Rating: 2)</em></li>
                <li>Automated cybersecurity tester for IEC 61850-based digital substations <em>(Rating: 2)</em></li>
                <li>A deep learning-based cyberattack detection system for transmission protective relays <em>(Rating: 1)</em></li>
                <li>From ChatGPT to ThreatGPT: Impact of Generative AI in cybersecurity and privacy <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7365",
    "paper_id": "paper-265067109",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "ChatGPT-4.0",
            "name_full": "ChatGPT 4.0",
            "brief_description": "Used as an LLM-based intrusion detection system with a human-in-the-loop (HITL) workflow to detect anomalies in IEC 61850 GOOSE and SV packet datasets extracted from a hardware-in-the-loop (HIL) testbed.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT 4.0",
            "model_description": "",
            "model_size": null,
            "anomaly_detection_approach": "HITL prompt-based classification: convert IDS rules/recommendations to textual instructions and use LLM inference to label individual packet records as normal or anomalous (no model weight fine-tuning reported).",
            "prompt_template": "Not provided verbatim in paper; authors state they converted the IDS algorithm and human recommendations into text prompts that ask the model to label GOOSE/SV packet rows as normal or anomalous and provide reasoning.",
            "training_data": "GOOSE and SV packet logs extracted from a HIL testbed (pcap -&gt; feature tables). Three HITL training levels applied to prompts/data: 'without' (no recommendations), 'partial' (human recommendations for DI and DoS), and 'full' (all human recommendations covering DI, DoS, RE, system problems). No model fine-tuning of weights reported; supervision is via HITL textual instructions/prompts.",
            "data_type": "Network packet logs / tabular time-series (GOOSE and SV features: time, DM, SM, APPID, datSet, goID, gocbRef, stNum, sqNum, data1, data2 for GOOSE; svID, smpCnt, etc. for SV).",
            "dataset_name": "GOOSE and SV datasets extracted from IEC 61850 HIL testbed (pcap captures).",
            "evaluation_metric": "TPR (recall), FPR, FNR, Precision, F1-score.",
            "performance": "Full training (HITL full recommendations): GOOSE — TPR 98.18%, FPR 4.00%, FNR 1.82%, Precision 98.18%, F1-score 98.18%. SV — TPR 96.67%, FPR 0.00%, FNR 3.33%, Precision 100.00%, F1-score 98.30%. (Results reported in Table I of the paper.)",
            "baseline_comparison": "Compared against Anthropic's Claude 2 and Google Bard/PaLM 2 on the same datasets and HITL training levels; ChatGPT 4.0 outperformed these LLMs across reported metrics at all training levels.",
            "zero_shot_or_few_shot": "HITL prompt-based supervision (not described as zero-shot or standard few-shot). Experiments used three supervision levels via human recommendations (without, partial, full) rather than model weight fine-tuning.",
            "limitations_or_failure_cases": "Paper notes computational speed limitations (online detection focus, not real-time), privacy/security concerns when LLMs access critical infrastructure data, and that LLMs can produce false positives/negatives depending on training level; no detailed failure-case breakdown beyond comparative metrics.",
            "computational_cost": null,
            "uuid": "e7365.0",
            "source_info": {
                "paper_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Claude-2",
            "name_full": "Anthropic's Claude 2",
            "brief_description": "Evaluated as an LLM-based IDS with the same HITL prompt-based procedure on GOOSE and SV datasets from the HIL testbed; performance reported alongside other LLMs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Anthropic Claude 2",
            "model_description": "",
            "model_size": null,
            "anomaly_detection_approach": "HITL prompt-based classification using human-converted IDS rules and recommendations as prompts; labels packet entries as anomalous or normal (no weight fine-tuning reported).",
            "prompt_template": "Not provided verbatim; described as converted IDS rules and human recommendations presented to the model to label packet records.",
            "training_data": "Same GOOSE and SV datasets from HIL testbed; three HITL levels: without, partial (DI & DoS), full (all recommendations). No model fine-tuning reported.",
            "data_type": "Network packet logs / tabular time-series (GOOSE and SV features).",
            "dataset_name": "GOOSE and SV datasets extracted from IEC 61850 HIL testbed (pcap captures).",
            "evaluation_metric": "TPR (recall), FPR, FNR, Precision, F1-score.",
            "performance": "Full training (HITL full recommendations): GOOSE — TPR 89.09%, FPR 32.00%, FNR 10.91%, Precision 85.96%, F1-score 87.50%. SV — TPR 88.30%, FPR 0.00%, FNR 11.67%, Precision 100.00%, F1-score 93.80%. (Reported in Table I.)",
            "baseline_comparison": "Compared to ChatGPT 4.0 (see reported metrics) and Google Bard/PaLM 2; Claude 2 had competitive precision on SV but lower TPR/F1 than ChatGPT 4.0 in reported experiments.",
            "zero_shot_or_few_shot": "HITL prompt-based supervision at three levels; not described as zero-shot/few-shot or as model fine-tuning.",
            "limitations_or_failure_cases": "Higher false positive rate on GOOSE (noted FPR = 32% at full training) relative to ChatGPT; general limitations include computational speed and privacy risks as discussed for all LLMs.",
            "computational_cost": null,
            "uuid": "e7365.1",
            "source_info": {
                "paper_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Bard/PaLM-2",
            "name_full": "Google Bard / PaLM 2",
            "brief_description": "Evaluated as an LLM-based IDS under the same HITL prompt-based framework on GOOSE and SV packet datasets from an HIL testbed; used for comparative performance analysis.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Google Bard / PaLM 2",
            "model_description": "",
            "model_size": null,
            "anomaly_detection_approach": "HITL prompt-based classification: IDS rules and human recommendations converted to text prompts to have the model label packet rows as anomalous or normal; no model weight fine-tuning reported.",
            "prompt_template": "Not provided verbatim; authors converted IDS logic and recommendations into prompts instructing the model to classify packet entries and explain anomalies.",
            "training_data": "GOOSE and SV datasets from HIL testbed; three HITL levels (without, partial, full). No fine-tuning of model weights reported.",
            "data_type": "Network packet logs / tabular time-series (GOOSE and SV features).",
            "dataset_name": "GOOSE and SV datasets extracted from IEC 61850 HIL testbed (pcap captures).",
            "evaluation_metric": "TPR (recall), FPR, FNR, Precision, F1-score.",
            "performance": "Full training (HITL full recommendations): GOOSE — TPR 89.10%, FPR 20.00%, FNR 10.90%, Precision 90.70%, F1-score 90.70%. SV — TPR 81.60%, FPR 25.00%, FNR 18.34%, Precision 91.70%, F1-score 85.90%. (Reported in Table I.)",
            "baseline_comparison": "Compared to ChatGPT 4.0 and Anthropic Claude 2 on identical datasets and HITL training levels; performed worse than ChatGPT 4.0 in reported TPR/F1 metrics and showed higher FPR on SV.",
            "zero_shot_or_few_shot": "HITL prompt-based supervision (without, partial, full) rather than classical zero-shot/few-shot or fine-tuning.",
            "limitations_or_failure_cases": "Relatively higher false positive rates in some cases (e.g., SV FPR 25% at full training) and lower recall versus ChatGPT 4.0; general LLM limitations and privacy concerns noted.",
            "computational_cost": null,
            "uuid": "e7365.2",
            "source_info": {
                "paper_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Ereno: A framework for generating realistic iec-61850 intrusion detection datasets for smart grids",
            "rating": 2,
            "sanitized_title": "ereno_a_framework_for_generating_realistic_iec61850_intrusion_detection_datasets_for_smart_grids"
        },
        {
            "paper_title": "Unsupervised learning based intrusion detection for GOOSE messages in digital substation",
            "rating": 2,
            "sanitized_title": "unsupervised_learning_based_intrusion_detection_for_goose_messages_in_digital_substation"
        },
        {
            "paper_title": "Automated cybersecurity tester for IEC 61850-based digital substations",
            "rating": 2,
            "sanitized_title": "automated_cybersecurity_tester_for_iec_61850based_digital_substations"
        },
        {
            "paper_title": "A deep learning-based cyberattack detection system for transmission protective relays",
            "rating": 1,
            "sanitized_title": "a_deep_learningbased_cyberattack_detection_system_for_transmission_protective_relays"
        },
        {
            "paper_title": "From ChatGPT to ThreatGPT: Impact of Generative AI in cybersecurity and privacy",
            "rating": 1,
            "sanitized_title": "from_chatgpt_to_threatgpt_impact_of_generative_ai_in_cybersecurity_and_privacy"
        }
    ],
    "cost": 0.00959725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</p>
<p>Graduate Student Member, IEEEAydin Zaboli 
Member, IEEESeong Lok Choi 
Member, IEEETai-Jin Song 
Senior Member, IEEEJunho Hong </p>
<p>Department of Electrical and Computer Engineering
University of Michigan -Dearborn
48128DearbornMIUSA</p>
<p>Power Systems Engineering Center
National Renewable Energy Laboratory (NREL)
80401GoldenCOUSA</p>
<p>Department of Urban Engineering
Chungbuk National University
28644CheongjuSouth Korea</p>
<p>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications
9D19C63013D83CAEC93F46B603C0E479
Cybersecurity breaches targeting electrical substations constitute a significant threat to the integrity of the power grid, necessitating comprehensive defense and mitigation strategies.Any anomaly in information and communication technology (ICT) should be detected for secure communications between devices in digital substations.This paper proposes large language models (LLMs), e.g., ChatGPT, for the cybersecurity of IEC 61850-based communications.Multi-cast messages such as generic object oriented system events (GOOSE) and sampled values (SV) are used for case studies.The proposed LLMbased cybersecurity framework includes, for the first time, data pre-processing of communication systems and human-in-theloop (HITL) training (considering the cybersecurity guidelines recommended by humans).The results show a comparative analysis of detected anomaly data carried out based on the performance evaluation metrics for different LLMs.A hardwarein-the-loop (HIL) testbed is used to generate and extract dataset of IEC 61850 communications.Index Terms-Cybersecurity, generic object oriented system event (GOOSE), ChatGPT, human-in-the-loop (HITL), large language model (LLM), sampled value (SV), substations.</p>
<p>I. INTRODUCTION</p>
<p>Digital substations serve as crucial elements within modern power systems, characterized by their escalating complexity and integration.GOOSE and SV are instrumental in facilitating rapid and dependable communication in the context of digital substations.Nevertheless, the open architecture intrinsic to these protocols makes them vulnerable to cyberattacks.The focal point of scholarly endeavors is the refinement and implementation of complex algorithms tailored for the contemporaneous oversight and scrutiny of network traffic [1].</p>
<p>Intrusion detection system (IDS)-based machine learning (ML) methods have been the foundation for detecting and mitigating anomalies in GOOSE and SV messages.While these methods offer precision and are data-driven, they come with a significant challenge.Every time a new attack pattern emerges, the models need to be re-trained.This necessity for re-training consumes time and resources and leaves the system vulnerable during the interim periods when the new threats are not yet incorporated into the model's knowledge base [2].On the other hand, LLMs such as ChatGPT 4.0 offer a more dynamic and adaptable approach.Unlike ML models, LLMs are designed to understand context, allowing them to recognize and respond to novel threats even if they have not been explicitly trained in them.This contextual understanding minimizes the efforts required in the face of evolving cyber threats.Instead of frequent re-training sessions, LLMs can interpret and adapt to new information, providing a more resilient and efficient solution for anomaly detection in digital substations [3], [4].In the area of cybersecurity for digital substations, LLMs can play a pivotal role in anomaly detection, enhancing the security layers.These models can analyze vast datasets, identify patterns, and detect anomalies indicative of potential cyberattacks.These models are designed to investigate through extensive data, including GOOSE and SV messages, to effectively distinguish regular patterns from irregularities [5].The incorporation of artificial intelligence (AI) aids into real-time monitoring is crucial to accelerate responses to security breaches.A unique deep learning-based system tailored for detecting cyberattacks on protective relays was developed based on extensive real-world datasets [6].GOOSE and SV messages are vulnerable to replay and message injection attacks, involving the re-transmission of unaltered messages or the transmission of fake, malicious ones.These attacks disrupt system operations either by replaying old messages or by injecting new, deceptive messages that mimic legitimate behavior [7], [8].However, the diversity and complexity of cyberattacks necessitate advanced detection mechanisms.Also, balancing the model's sensitivity to detect minor anomalies while avoiding false positives (FPs) is crucial.In [9], a novel unsupervised learning approach for an IDS of GOOSE messages is suggested based on a combination of autoencoders and clustering techniques for efficient detection.According to literature surveys, challenges in the applicability of ML models in IDSs can include ensuring the reliability and robustness of the model in real-time power grids considering new cyberattacks, a trade-off between complexity and accuracy due to large datasets, and the adaptability of the ML model to evolving cyberattacks and changing the substation infrastructure.Furthermore, a re-training process is required for new cyberattacks; however, LLMs can handle these challenges effectively and reduce the processing time.</p>
<p>This paper proposes for the first time the employment of LLMs based on HITL interactions to detect anomalies in GOOSE and SV datasets for cybersecurity considerations in substations.Hence, this paper focuses on the cybersecurity of multicast messages, and we will focus on other protocols in substations in the future.This paper suggests human recommendations for data pre-processing for these communication arXiv:2311.05462v2[cs.CR] 25 Feb 2024 protocols.This process minimizes efforts (unlike applying ML methods) when encountering new cyberattacks (or anomalies).It does not affect the model's complexity/precision and is faster to implement.Moreover, this paper makes a comparison between LLMs (i.e., ChatGPT 4.0 [10], Anthropic's Claude 2 [11], and Google Bard/PaLM 2 [12]) to evaluate their performance.The actual datasets for GOOSE and SV packets are extracted from the HIL testbed.The main contributions of this paper can be summarized as follows:</p>
<p>• This paper proposes the usage of different LLMs in the cybersecurity of digital substations in terms of performance evaluation metrics.• LLM-based HITL is considered an IDS to detect abnormal data in IEC 61850 communication protocols.• A conversion of the IDS algorithm to text is employed for training datasets to detect anomalies in LLMs.The remainder of the paper is organized as follows: Section II states a representation of the cybersecurity of digital substations using LLMs.The proposed HITL technique, along with the feature extraction and analysis of datasets, are mentioned in Section III.Section IV presents the results and discussion of the evaluation metrics according to different levels of training.Finally, this paper is deduced in Section V.</p>
<p>II. CYBERSECURITY OF DIGITAL SUBSTATIONS USING LARGE LANGUAGE MODELS</p>
<p>A. Cybersecurity of Digital Substations</p>
<p>A cyber-physical power system testbed serves as an instrumental platform for studying the causal relationships associated with cyber intrusions, the robustness of power systems, and the dependability of applications in a realistic environment.Within such a real-time HIL testbed, all constituent elements, encompassing hardware, software, communication mechanisms, and emulators, are coordinated in alignment with the global positioning system (GPS).The real-time dynamics pertinent to communication and information processing become imperative in the context of analyzing cyber intrusions, detection mechanisms, and mitigation strategies [13].As seen in Fig. 1, the testbed consists of protective intelligent electronic devices (IEDs), software-defined networking (SDN) switches, a satellite-synchronized clock, a merging unit, a supervisory control and data acquisition (SCADA) system, a real-time digital simulator, and the amplifier.The distributed management system (DMS) SCADA system can get measurements and issue a control command via DNP3 communication.Various IEDs are implemented, including the merging unit IED and protective IEDs.These IEDs possess the proficiency to transmit control commands (e.g., GOOSE messages) pertinent to a circuit breaker (CB).Conversely, a CB IED (modeled in a real-time simulator) is specifically configured to subscribe to GOOSE messages and publish the status (open or closed) to protective IEDs.The merging unit IED has the ability to forward digital current and voltage values (i.e., SV), taking into account the amplifier from the digital simulator, to the protective IED.Furthermore, the proposed HITL LLM-based IDS is engineered to identify anomalies and potential security threats within the substation automation framework and maintains a connection to SDN switches [13].The purpose of this paper is to demonstrate an IDS considering the LLMbased HITL process.Hence, the GOOSE and SV packets are extracted from the HIL testbed for further analysis in different LLMs considering the human recommendations that are described in the subsequent section.</p>
<p>B. Large Language Model-Based Human-in-the-loop Process</p>
<p>Generative AI (GenAI) models, constructed through deep neural network methods, are designed to discern patterns and structures from extensive training datasets, subsequently producing similar content.The capabilities of GenAI encompass the creation of diverse content types, ranging from text and images to sounds and various data forms.The introduction of ChatGPT has markedly influenced the broader AI/ML domain, exemplifying GenAI's potential to resonate with the wider populace and altering prevailing conceptions of AI/ML.The technological sector is actively pursuing the refinement of advanced LLMs aimed at simulating authentic human interactions, as evidenced by innovations (e.g., Microsoft's GPT and Google Bard/PaLM 2).Over the past year, GenAI has strengthened its presence as a prevalent online tool [5].</p>
<p>LLMs and GenAI systems present considerable opportunities to augment productivity and operational efficiency.However, their application, especially in sectors characterized by high risk and stringent regulations, brings about notable challenges.A potential strategy to mitigate risks is adopting the HITL process, as illustrated in Fig. 1 by the HITL LLM box.Incorporating human interactions during training, validation, and testing stages can expedite the learning process and improve the confidence level of outputs.Initially, individuals can explain the execution of specific tasks and subsequently offer insights into the model's efficacy.This involvement can be manifested in modifying the model's results.Drawing insights from a fusion of human demonstrations and assessments has proven to surpass the efficiency and speed of ML methods.The HITL paradigm becomes indispensable when confronted with constraints (e.g., when data presents anomalies or lacks comprehensiveness), leading to uncertainties about the model's capability to address all scenarios.Moreover, consistent human oversight and verification are useful, especially when inaccuracies in model predictions could have severe consequences [14].In the proposed model, there are human recommendations to improve the model efficiency based on GOOSE and SV message features.Thus, this method is helpful in minimizing the trials by entering new data into the normal dataset and avoiding the re-training process.Also, the adaptability and robustness of models can be improved quickly.</p>
<p>Allowing a language model unrestricted access to data pertaining to critical infrastructure necessitates meticulous study, given the significant security and privacy implications.Implementing accurate access controls and encryption and authentication protocols is imperative to mitigate unauthorized data access.It is vital for human specialists to exercise continuous supervision and assess the outputs of the model, ensuring the validity and dependability of AI-facilitated cybersecurity methodologies.In addition, there exists the potential for LLMs to unintentionally disclose confidential information during engagements, especially if they lack appropriate training or protection [5].The cybersecurity of LLMs is out of scope for this research, and the purpose is solely to employ LLMs as tools for detecting anomalies in communication messages.</p>
<p>III. IEC 61850-BASED COMMUNICATION DATASETS AND HUMAN RECOMMENDATIONS PROCESS</p>
<p>A. GOOSE and SV Datasets</p>
<p>The GOOSE and SV packets are extracted from the HIL testbed.The ".pcap" means that these packets are captured using Wireshark (a network packet analyzer), as seen in Fig. 2. As shown, there are 10 data points for GOOSE packets based on the extracted features.The SV datasets follow the same procedures, with the 7 most important features as dataset columns."Time" shows the time at which the packet is actually sent, and the format of this feature is based on hour, minute, and second (including microsecond level).The features "DM" and "SM" refer to the destination and source media access control (MAC) addresses, respectively.This specific "DM" address (01 00 03) of GOOSE messages shows the target devices (sent to the device that subscribes to this MAC address).Also, the "SM" address of GOOSE messages is 27 34 31 which shows the sender's IED.The indicators for GOOSE and SV are shown as "type," which is 88 b8 and 88 ba, respectively.The "APPID" values for GOOSE and SV communications are 3 and 40, respectively.Also, "datSet" and "goID" are assigned based on "DM" and indicate the dataset name and GOOSE identification, respectively.Based on Fig. 2, there is a GOOSE block reference ("gocbRef") that indicates the name of the GOOSE in the "goosePdu.""stNum" and "sqNum" express the state and sequence numbers in GOOSE communications, respectively.Furthermore, two data types ("data1" and "data2") are considered based on GOOSE packets.In the SV dataset, there are "svID" and "smpCnt" in the "savPdu," which indicate SV identification and sample count number.A large number of datasets have been used to train the GOOSE and SV communications to check the performance evaluation of LLMs.</p>
<p>B. Human Recommendations for Intrusion Detection Systems</p>
<p>According to the given datasets, a series of human recommendations based on the violations in the GOOSE and SV datasets can be described.Some different attacks and errors were considered, such as the data injection (DI) attack, the denial-of-service (DoS) attack, the system problem, and the replay (RE) attack for GOOSE and SV communications.These attacks can be described as follows.A failure to satisfy at least one recommendation leads to the relevant attack.Regarding the DoS attack for SV, the sample/cycle is 80 and the frequency is 60 Hz, so there are a total of 4, 800 samples per second.If 1/4800 is calculated, 208 microseconds can be achieved.Hence, the normal time for a DoS attack should be around this time.The process can be done for GOOSE messages as well.The "heartbeat" of GOOSE packets refers to a regular, periodic message sent over the network to indicate the status of the system.The heartbeat (e.g., 2 seconds) ensures continuous monitoring and quick detection of any changes or failures in the system.The frequency of these heartbeat messages can vary depending on the configuration and requirements of the specific substation system.Typically, GOOSE messages are sent at intervals ranging from a few milliseconds to several seconds.Regarding SV packets, a heartbeat indicates the operational status or health of a system.The exact frequency or interval of the heartbeat for SV packets can vary depending on the specific implementation and requirements of the digital substation system.</p>
<p>• Attacks/errors on GOOSE datasets -DI: If data has the same "DM" and "SM," "sqNum" should be increased every time.</p>
<p>-DI: If there is any change in "data1" or "data2," "stNum" should be increased by 1 and "sqNum" should be reset to 0.</p>
<p>-DI: If data has the same "DM" and "SM," once "stNum" is increased, it cannot go back to smaller numbers.</p>
<p>-DoS: There are up to 10 packets (rows) within 10 ms.</p>
<p>-System Problem: There should be a packet (dataset) within 10 s.</p>
<p>-RE: If there is any change in "data1" or "data2," "stNum" should be increased 1 and "sqNum" should be reset to 0.</p>
<p>• Attacks/errors on SV datasets -DI: The range of "smpCnt" is from 0 to 4799.</p>
<p>-DI: Once the "smpCnt" is increased, it should be increased up to 4799 and then reset to 0.</p>
<p>-DI: "smpCnt" cannot be decreased until it reaches 4799 and resets to 0.</p>
<p>-DoS: A normal time interval should be around 208 ms.</p>
<p>-DoS: There are up to 12 packets within 2.083 ms.</p>
<p>-System Problem: "smpCnt" should be increased every time by 1.The recommended considerations are applied to datasets to train LLMs.This helps to improve the accuracy of the pretrained model based on the ML model, even though there is new data.The purpose is to show the performance evaluation based on datasets generated at three different levels, including a dataset without training (without human recommendations), with partial training (recommendations of DI and DoS attacks), and with full training.Then, the performance evaluation metrics of different LLMs are compared.This process assists in minimizing the trials for re-training ML models and the adaptability of the model in cases where there is new data.The next section presents the performance evaluation results, considering the HITL process in different LLMs.</p>
<p>IV. RESULTS AND DISCUSSION</p>
<p>This section presents a comparison of results between LLMs at different levels.Precision is a preferable performance metric, denoting the rate at which an IDS correctly detects anomalies.However, relying solely on precision metric might be misleading when evaluating anomaly detection techniques, especially in scenarios characterized by significant differences between FPs and false negatives (FNs).Therefore, this section presents the performance analysis of different LLMs considering the HITL for the GOOSE and SV datasets.The fundamental performance metrics for anomaly detection analysis are described and discussed in this section.A description of evaluation metrics based on the detection of anomaly data in GOOSE and SV communication protocols, along with the results based on case studies, is shown in Table I.Due to the limitations of LLMs and computational speed, this paper focuses on online detection, not real-time intrusion detection.</p>
<p>A. Case Studies: GOOSE and SV Anomaly Detection</p>
<p>This section presents the results of the performance evaluation metrics for different LLMs based on the training levels.The formulations of the performance assessment are given in the previous part, including true positive rate (TPR), false positive rate (FPR), false negative rate (FNR), precision, and F1-score metrics.A comparison of anomaly detection results considering the different LLMs (i.e., ChatGPT 4.0, Anthropic's Claude 2, and Google Bard/PaLM 2) with the HITL process is presented in this table.The results show that ChatGPT 4.0 outperforms the two other LLMs in both case studies for anomaly detection as an IDS.A higher TPR indicates a better model, as it is able to identify more of the actual positives.It also shows the detection rate of anomalies, where ChatGPT 4.0 has values of 98.18% and 96.67% for detection of anomalies in GOOSE and SV messages, respectively.These percentages are the highest rates in comparison with other LLMs at full training levels.It happened for all other training levels as well.Lower FPR and FNR indicate a superior model, as it is less possible to misclassify positive and negative values, respectively.It occurs for ChatGPT 4.0 considering FPR and FNR in both communications.At full training levels, these values are less than 4% which represents a good performance of this LLM.Also, Claude 2 shows great performance in the detection of normal SV data that was wrongly detected as anomalies.The precision metric represents the accuracy of anomalies detection in GOOSE and SV communications.The precision values for ChatGPT 4.0 and Claude 2 are 100% in comparison with Google Bard (91.7%) in the SV dataset.F1-score is a harmonic mean of precision and recall, which means that it gives equal importance to both the ability of the algorithm to identify true anomalies and its ability to avoid FPs.This metric shows the highest value based on ChatGPT 4.0.The impact of the HITL process can be observed at different training levels in Table I.A portion of the human recommendations are considered for the partial training.Therefore, better performance at different rates, precisions, and F1-scores can be perceived by applying the HITL process.All human recommendations based on the defined attacks/errors are considered at the full training level.</p>
<p>To recap, ChatGPT 4.0 served as the best LLM in comparison with Anthropic's Claude 2 and Google Bard/PaLM 2 in all rates and measurements.However, there are challenges in using LLMs based on the HITL process in cybersecurity studies on digital substations.Cybersecurity anomalies entail a level of complexity that may exceed AI's contextual discernment capabilities.The necessity for LLMs to process sensitive data introduces data privacy and security considerations.AI's enhancement in cybersecurity is hindered by the need for continuous data input, reflecting the dynamic nature of the field.The integrity of anomaly detection in AI is dependent on its training data, with potential inaccuracies manifesting as FPs or FNs.Hence, task-oriented dialogues (ToD) and fine-tuning are posited to enhance anomaly detection accuracy through the provision of structured interactive patterns that augment LLMs' effectiveness in cybersecurity-specific responses.They enable more targeted and context-aware queries, thereby refining the decision-making process.Additionally, they promote an improved feedback mechanism where human experts can iteratively refine AI performance on designated tasks, thereby optimizing its learning trajectory over time.Rule-based detection systems, known for their effectiveness in identifying known threats, often demonstrate superior results in specific scenarios.However, LLMs bring a unique advantage to the field of anomaly detection.Unlike rule-based systems that rely on predefined criteria, LLMs possess the capability to identify unexpected or novel attacks, a critical feature in the constantly evolving landscape of cybersecurity threats.This ability to detect anomalies that deviate from known patterns or behaviors allows LLMs to address a broader range of potential attacks.Consequently, integrating LLMs into anomaly detection efforts can significantly reduce the manual labor and complexity involved in continuously updating and maintaining rule-based systems, especially in environments where new and unforeseen attack vectors are a constant challenge.</p>
<p>V. CONCLUSION</p>
<p>This paper proposes the use of LLMs based on the HITL process for cybersecurity in substations, as evaluated by various performance metrics.LLMs are employed as IDSs to identify anomalies in communication protocols.An IDS algorithm is converted to text to train datasets for anomaly detection.In comparison, ChatGPT 4.0 outperformed the two other LLMs in all metrics.This LLM demonstrated better precision and performance at different levels of training.These models have privacy issues regarding confidential data.Thus, using the ToD and fine-tuning are necessary to enhance the accuracy of LLMs.In the future, it will be the intention to consider other LLMs with ToD and fine-tuning processes with more attacks and errors to improve the LLMs' efficiency, along with analyses on all multicast messages in digital substations.</p>
<p>Fig. 1 .
1
Fig. 1.HIL Testbed considering the IDS with human recommendations.</p>
<p>Fig. 2 .
2
Fig. 2. A pre-processing step based on the feature extraction for a log of GOOSE message (actual data from an HIL testbed).</p>
<p>TABLE I A
I
COMPARISON OF DETECTION RESULTS (WITHOUT, PARTIAL AND FULL TERMS SHOW THE LEVELS OF TRAINING PROCESS).
IEC 61850-based CommunicationGOOSELLMsChatGPT 4.0Anthropic's Claude 2Google Bard/PaLM 2MetricsDescriptionwithoutpartialfullwithoutpartialfullwithoutpartialfullTPRA ratio of correct GOOSE anomalies that were correctly identified (also, named recall).78.18%85.45%98.18%78.18%83.64%89.09%74.5%81.8%89.1%FPRA ratio of normal GOOSE data that were wrongly identified as anomalies.48%32%4%56%44%32%56%40%20%FNRA ratio of correct GOOSE anomalies that the system failed to detect.21.82%14.55%1.82%21.82%16.36%10.91%25.5%18.18%10.9%PrecisionMeasures accuracy of detected GOOSE anomalies.78.18%85.45%98.18%75.43%80.7%85.96%74.5%81.8%90.7%F1-ScoreProvides a trade-off between precision and recall.78.18%85.45%98.18%76.78%82.3%87.5%74.5%81.8%90.7%IEC 61850-based CommunicationSVLLMsChatGPT 4.0Anthropic's Claude 2Google Bard/PaLM 2MetricsDescriptionwithoutpartialfullwithoutpartialfullwithoutpartialfullTPRA ratio of correct SV anomalies that were correctly identified (also, named recall).70%95%96.67%50%70%88.3%50%63.3%81.6%FPRA ratio of normal SV data that were wrongly identified as anomalies.50%15%0%50%20%0%50%40%25%FNRA ratio of correct SV anomalies that the system failed to detect.30%5%3.33%50%30%11.67%50%36.6%18.34%PrecisionMeasures accuracy of detected SV anomalies.80.77%95%100%75%91.3%100%75%82.6%91.7%F1-ScoreProvides a trade-off between precision and recall.75%95%98.3%60%79.2%93.8%60%71.7%85.9%</p>
<p>A novel hybrid methodology to secure GOOSE messages against cyberattacks in smart grids. S Hussain, A Iqbal, S S Hussain, S Zanero, A Shikfa, E Ragaini, I Khan, R Alammari, Scientific Reports. 13118572023</p>
<p>Automated cybersecurity tester for IEC 61850-based digital substations. J Hong, T.-J Song, H Lee, A Zaboli, Energies. 152178332022</p>
<p>ChatGPT: Vision and challenges. S S Gill, R Kaur, Internet of Things and Cyber-Physical Systems. 32023</p>
<p>Anomaly detection for cybersecurity of the substations. C.-W Ten, J Hong, C.-C Liu, IEEE Transactions on Smart Grid. 242011</p>
<p>From ChatGPT to ThreatGPT: Impact of Generative AI in cybersecurity and privacy. M Gupta, C Akiri, K Aryal, E Parker, L Praharaj, IEEE Access. 2023</p>
<p>A deep learning-based cyberattack detection system for transmission protective relays. Y M Khaw, A A Jahromi, M F Arani, S Sanner, D Kundur, M Kassouf, IEEE Transactions on Smart Grid. 1232020</p>
<p>Ereno: A framework for generating realistic iec-61850 intrusion detection datasets for smart grids. S E Quincozes, C Albuquerque, D Passos, D Mossé, IEEE Transactions on Dependable and Secure Computing. 2023</p>
<p>Cyber attacks on power grids: Causes and propagation of cascading failures. V S Rajkumar, A ¸tefanov, A Presekal, P Palensky, J L R Torres, IEEE Access. 112023</p>
<p>Unsupervised learning based intrusion detection for GOOSE messages in digital substation. D Jay, H Goyel, U Manickam, G Khare, 2022 22nd National Power Systems Conference (NPSC). IEEE2022</p>
<p>. Openai -Introducing Chatgpt, </p>
<p>. Anthropic -Claude, </p>
<p>Cyber-physical security testbed for substations in a power grid. J Hong, Y Chen, C.-C Liu, M Govindarasu, 2015Cyber Physical Systems Approach to Smart Electric Power Grid</p>            </div>
        </div>

    </div>
</body>
</html>