<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-471 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-471</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-471</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-19.html">extraction-schema-19</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <p><strong>Paper ID:</strong> paper-237439298</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2109.03383v1.pdf" target="_blank">DeepZensols: Deep Natural Language Processing Framework</a></p>
                <p><strong>Paper Abstract:</strong> Reproducing results in publications by distributing publicly available source code is becoming ever more popular. Given the difficulty of reproducing machine learning (ML) experiments, there have been significant efforts in reducing the variance of these results. As in any science, the ability to consistently reproduce results effectively strengthens the underlying hypothesis of the work, and thus, should be regarded as important as the novel aspect of the research itself. The contribution of this work is a framework that is able to reproduce consistent results and provides a means of easily creating, training, and evaluating natural language processing (NLP) deep learning (DL) models.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e471.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e471.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RandomStateControl</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Saving and restoring global random state (utility libraries, scientific libraries, PyTorch, GPU)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework capability that captures and restores the entire random state (including utility/scientific libraries, PyTorch, and GPU state) when saving/loading models to ensure deterministic behavior across runs of the same Python interpreter execution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing / Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Training, evaluation and testing of deep learning NLP models with deterministic re-runs</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Randomness originating from utility libraries, scientific libraries, PyTorch, GPU state, and implicit random seeds that influence training and evaluation; order of mini-batches (seeded by RNG) also affects outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Non-determinism across runs due to unfixed/global random states and GPU nondeterminism.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Capture and persist the full random state when saving a model and restore/reset it when loading to reproduce identical run-time randomness and outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Controlling and persisting the entire random state (including GPU state) is a primary mitigation the framework implements to reduce run-to-run variability, though no quantitative reduction metrics are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DeepZensols: Deep Natural Language Processing Framework', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e471.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e471.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BatchOrderPersistence</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recording and persisting mini-batch and dataset ordering and splits</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The framework records and saves the order of all data, including dataset splits and the ordering of items within each mini-batch, so that training, validation and test runs can be reproduced exactly.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing / Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Deterministic re-execution of model training, validation and testing</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Variation induced by different orders of mini-batches and different ordering of items within mini-batches across runs; differing dataset splits between runs.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Model performance sensitivity to ordering of training data and mini-batches can lead to inconsistent outcomes when order is not preserved.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Record complete ordering of dataset partitions and mini-batches to filesystem and distribute these artifacts along with source code so runs can be duplicated exactly.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Persisting dataset splits and exact mini-batch ordering prevents ordering-induced variability and enables exact duplication of training/validation/testing, though no quantitative reproducibility comparison is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DeepZensols: Deep Natural Language Processing Framework', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e471.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e471.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BatchEncoding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Batch encoding/decoding and persistent vectorized mini-batches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A process that segments datasets into chunks, vectorizes them in parallel subprocesses, writes ready-to-load tensor mini-batches to disk, and later decodes/reassembles them deterministically for training to avoid brittle ad-hoc preprocessing and variability from repeated on-the-fly vectorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing / Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Efficient and reproducible mini-batch creation and feature swapping for model comparison</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Re-parsing and re-vectorizing data on each epoch producing non-deterministic pipelines; ad-hoc preprocessing scripts causing irreproducible dataset artifacts; differences between frozen precomputed embeddings and dynamic/trainable embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Inefficient or ad-hoc preprocessing leads to brittle, hard-to-reproduce datasets and changes in vectorization across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Batch encoding: chunk data, vectorize in parallel subprocesses, save mini-batch tensors to a structured filesystem layout; batch decoding: deterministic reassembly, optional caching to CPU/GPU memory; support for swapping feature sets via configuration rather than reprocessing ad-hoc.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Persisting vectorized mini-batches and a deterministic reassembly process reduces variability arising from on-the-fly preprocessing and enables fast, repeatable feature-swapping experiments, but no quantitative metrics are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DeepZensols: Deep Natural Language Processing Framework', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e471.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e471.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ConfigAndMemoryPersistence</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Saving configuration and in-memory training state with models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The framework saves the configuration that recreates the in-memory state (model structure, parameters, hyper-parameters, and other train-time memory) when saving models to enable identical reconstruction of training-time memory during testing and re-runs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing / Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Exact reconstruction of model state for reproducible evaluation and testing</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Differences in hyper-parameters, model architecture instantiation, or other in-memory configuration between runs leading to irreproducible behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Changes or drift in configuration and in-memory state across runs and environments can break reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Persist the full run configuration together with the model so the same model structure, parameters, hyper-parameters, and training-time memory can be recreated on load.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Saving complete configuration and memory state alongside models is recommended to duplicate exact model behavior across runs; effectiveness is asserted but not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DeepZensols: Deep Natural Language Processing Framework', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e471.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e471.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CIUnitTests</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated unit and integration tests with continuous integration for functionality and reproducibility</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The project includes extensive automated testing (236 unit tests and six integration tests) run in continuous integration to validate both functionality and reproducibility of framework components.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Software engineering for ML / NLP experimentation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Ensuring functional correctness and reproducibility of framework behaviors across versions</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Code changes, regressions, or environment differences that can alter experiment behavior across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Software regressions and untested changes can impair reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Automated unit and integration tests executed via continuous integration to detect regressions that could affect reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Comprehensive automated testing and CI are used to improve reproducibility of the framework; quantitative impact on experiment reproducibility is not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DeepZensols: Deep Natural Language Processing Framework', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e471.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e471.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT_family</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT, RoBERTa and DistilBERT pretrained transformer models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pretrained transformer language models supported by the framework as embeddings vectorizers and used for sentence and token classification; BERT, RoBERTa and DistilBERT have been tested with the framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DeepZensols: Deep Natural Language Processing Framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT / RoBERTa / DistilBERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Sentence and token classification and embedding concatenation in NLP models</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Differences between using frozen precomputed embeddings versus trainable embeddings (file sizes/load-time and pipeline differences), and potential non-determinism in transformer outputs if not controlled; dependency on external pretrained model versions.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Large precomputed embedding files and differing embedding computation strategies (frozen vs trainable) can affect reproducibility and resource use; external model versioning can also cause mismatch across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Support for embedding vectorizers, mapping spaCy linguistic features to word-piece embeddings, and batch-encoding strategies to deterministically store and reload embedding tensors to reduce variability in embedding pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The framework supports and has tested BERT-family models and provides deterministic vectorization and batch persistence mechanisms to reduce variability introduced by embedding computation, though no quantitative reproducibility metrics are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DeepZensols: Deep Natural Language Processing Framework', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>DeepDIVA: A Highly-Functional Python Framework for Reproducible Experiments <em>(Rating: 2)</em></li>
                <li>Reproducibility in Machine Learning-Based Studies: An Example of Text Mining <em>(Rating: 2)</em></li>
                <li>Artificial intelligence faces reproducibility crisis <em>(Rating: 1)</em></li>
                <li>The Extent and Consequences of P-Hacking in Science <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-471",
    "paper_id": "paper-237439298",
    "extraction_schema_id": "extraction-schema-19",
    "extracted_data": [
        {
            "name_short": "RandomStateControl",
            "name_full": "Saving and restoring global random state (utility libraries, scientific libraries, PyTorch, GPU)",
            "brief_description": "A framework capability that captures and restores the entire random state (including utility/scientific libraries, PyTorch, and GPU state) when saving/loading models to ensure deterministic behavior across runs of the same Python interpreter execution.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Natural Language Processing / Machine Learning",
            "experimental_task": "Training, evaluation and testing of deep learning NLP models with deterministic re-runs",
            "variability_sources": "Randomness originating from utility libraries, scientific libraries, PyTorch, GPU state, and implicit random seeds that influence training and evaluation; order of mini-batches (seeded by RNG) also affects outcomes.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": null,
            "reproducibility_assessed": true,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Non-determinism across runs due to unfixed/global random states and GPU nondeterminism.",
            "mitigation_methods": "Capture and persist the full random state when saving a model and restore/reset it when loading to reproduce identical run-time randomness and outcomes.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": null,
            "number_of_runs": null,
            "key_findings": "Controlling and persisting the entire random state (including GPU state) is a primary mitigation the framework implements to reduce run-to-run variability, though no quantitative reduction metrics are reported.",
            "uuid": "e471.0",
            "source_info": {
                "paper_title": "DeepZensols: Deep Natural Language Processing Framework",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "BatchOrderPersistence",
            "name_full": "Recording and persisting mini-batch and dataset ordering and splits",
            "brief_description": "The framework records and saves the order of all data, including dataset splits and the ordering of items within each mini-batch, so that training, validation and test runs can be reproduced exactly.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Natural Language Processing / Machine Learning",
            "experimental_task": "Deterministic re-execution of model training, validation and testing",
            "variability_sources": "Variation induced by different orders of mini-batches and different ordering of items within mini-batches across runs; differing dataset splits between runs.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": null,
            "reproducibility_assessed": true,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Model performance sensitivity to ordering of training data and mini-batches can lead to inconsistent outcomes when order is not preserved.",
            "mitigation_methods": "Record complete ordering of dataset partitions and mini-batches to filesystem and distribute these artifacts along with source code so runs can be duplicated exactly.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": null,
            "number_of_runs": null,
            "key_findings": "Persisting dataset splits and exact mini-batch ordering prevents ordering-induced variability and enables exact duplication of training/validation/testing, though no quantitative reproducibility comparison is provided.",
            "uuid": "e471.1",
            "source_info": {
                "paper_title": "DeepZensols: Deep Natural Language Processing Framework",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "BatchEncoding",
            "name_full": "Batch encoding/decoding and persistent vectorized mini-batches",
            "brief_description": "A process that segments datasets into chunks, vectorizes them in parallel subprocesses, writes ready-to-load tensor mini-batches to disk, and later decodes/reassembles them deterministically for training to avoid brittle ad-hoc preprocessing and variability from repeated on-the-fly vectorization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Natural Language Processing / Machine Learning",
            "experimental_task": "Efficient and reproducible mini-batch creation and feature swapping for model comparison",
            "variability_sources": "Re-parsing and re-vectorizing data on each epoch producing non-deterministic pipelines; ad-hoc preprocessing scripts causing irreproducible dataset artifacts; differences between frozen precomputed embeddings and dynamic/trainable embeddings.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": null,
            "reproducibility_assessed": true,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Inefficient or ad-hoc preprocessing leads to brittle, hard-to-reproduce datasets and changes in vectorization across runs.",
            "mitigation_methods": "Batch encoding: chunk data, vectorize in parallel subprocesses, save mini-batch tensors to a structured filesystem layout; batch decoding: deterministic reassembly, optional caching to CPU/GPU memory; support for swapping feature sets via configuration rather than reprocessing ad-hoc.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": null,
            "number_of_runs": null,
            "key_findings": "Persisting vectorized mini-batches and a deterministic reassembly process reduces variability arising from on-the-fly preprocessing and enables fast, repeatable feature-swapping experiments, but no quantitative metrics are reported.",
            "uuid": "e471.2",
            "source_info": {
                "paper_title": "DeepZensols: Deep Natural Language Processing Framework",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "ConfigAndMemoryPersistence",
            "name_full": "Saving configuration and in-memory training state with models",
            "brief_description": "The framework saves the configuration that recreates the in-memory state (model structure, parameters, hyper-parameters, and other train-time memory) when saving models to enable identical reconstruction of training-time memory during testing and re-runs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Natural Language Processing / Machine Learning",
            "experimental_task": "Exact reconstruction of model state for reproducible evaluation and testing",
            "variability_sources": "Differences in hyper-parameters, model architecture instantiation, or other in-memory configuration between runs leading to irreproducible behavior.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": null,
            "reproducibility_assessed": true,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Changes or drift in configuration and in-memory state across runs and environments can break reproducibility.",
            "mitigation_methods": "Persist the full run configuration together with the model so the same model structure, parameters, hyper-parameters, and training-time memory can be recreated on load.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": false,
            "number_of_runs": null,
            "key_findings": "Saving complete configuration and memory state alongside models is recommended to duplicate exact model behavior across runs; effectiveness is asserted but not quantified.",
            "uuid": "e471.3",
            "source_info": {
                "paper_title": "DeepZensols: Deep Natural Language Processing Framework",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "CIUnitTests",
            "name_full": "Automated unit and integration tests with continuous integration for functionality and reproducibility",
            "brief_description": "The project includes extensive automated testing (236 unit tests and six integration tests) run in continuous integration to validate both functionality and reproducibility of framework components.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Software engineering for ML / NLP experimentation",
            "experimental_task": "Ensuring functional correctness and reproducibility of framework behaviors across versions",
            "variability_sources": "Code changes, regressions, or environment differences that can alter experiment behavior across runs.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": null,
            "reproducibility_assessed": true,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Software regressions and untested changes can impair reproducibility.",
            "mitigation_methods": "Automated unit and integration tests executed via continuous integration to detect regressions that could affect reproducibility.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": null,
            "number_of_runs": null,
            "key_findings": "Comprehensive automated testing and CI are used to improve reproducibility of the framework; quantitative impact on experiment reproducibility is not provided.",
            "uuid": "e471.4",
            "source_info": {
                "paper_title": "DeepZensols: Deep Natural Language Processing Framework",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "BERT_family",
            "name_full": "BERT, RoBERTa and DistilBERT pretrained transformer models",
            "brief_description": "Pretrained transformer language models supported by the framework as embeddings vectorizers and used for sentence and token classification; BERT, RoBERTa and DistilBERT have been tested with the framework.",
            "citation_title": "DeepZensols: Deep Natural Language Processing Framework",
            "mention_or_use": "use",
            "model_name": "BERT / RoBERTa / DistilBERT",
            "model_size": null,
            "scientific_domain": "Natural Language Processing",
            "experimental_task": "Sentence and token classification and embedding concatenation in NLP models",
            "variability_sources": "Differences between using frozen precomputed embeddings versus trainable embeddings (file sizes/load-time and pipeline differences), and potential non-determinism in transformer outputs if not controlled; dependency on external pretrained model versions.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": null,
            "reproducibility_assessed": true,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Large precomputed embedding files and differing embedding computation strategies (frozen vs trainable) can affect reproducibility and resource use; external model versioning can also cause mismatch across runs.",
            "mitigation_methods": "Support for embedding vectorizers, mapping spaCy linguistic features to word-piece embeddings, and batch-encoding strategies to deterministically store and reload embedding tensors to reduce variability in embedding pipelines.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": null,
            "number_of_runs": null,
            "key_findings": "The framework supports and has tested BERT-family models and provides deterministic vectorization and batch persistence mechanisms to reduce variability introduced by embedding computation, though no quantitative reproducibility metrics are provided.",
            "uuid": "e471.5",
            "source_info": {
                "paper_title": "DeepZensols: Deep Natural Language Processing Framework",
                "publication_date_yy_mm": "2021-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "DeepDIVA: A Highly-Functional Python Framework for Reproducible Experiments",
            "rating": 2,
            "sanitized_title": "deepdiva_a_highlyfunctional_python_framework_for_reproducible_experiments"
        },
        {
            "paper_title": "Reproducibility in Machine Learning-Based Studies: An Example of Text Mining",
            "rating": 2,
            "sanitized_title": "reproducibility_in_machine_learningbased_studies_an_example_of_text_mining"
        },
        {
            "paper_title": "Artificial intelligence faces reproducibility crisis",
            "rating": 1,
            "sanitized_title": "artificial_intelligence_faces_reproducibility_crisis"
        },
        {
            "paper_title": "The Extent and Consequences of P-Hacking in Science",
            "rating": 1,
            "sanitized_title": "the_extent_and_consequences_of_phacking_in_science"
        }
    ],
    "cost": 0.0112325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>DeepZensols: Deep Natural Language Processing Framework
8 Sep 2021</p>
<p>Paul Landes plande2@uic.edu 
Department of Computer Science
University of Illinois at Chicago</p>
<p>Barbara Di 
Department of Computer Science
University of Illinois at Chicago</p>
<p>Eugenio Cornelia Caragea 
Department of Computer Science
University of Illinois at Chicago</p>
<p>DeepZensols: Deep Natural Language Processing Framework
8 Sep 2021
Reproducing results in publications by distributing publicly available source code is becoming ever more popular. Given the difficulty of reproducing machine learning (ML) experiments, there have been significant efforts in reducing the variance of these results. As in any science, the ability to consistently reproduce results effectively strengthens the underlying hypothesis of the work, and thus, should be regarded as important as the novel aspect of the research itself. The contribution of this work is a framework that is able to reproduce consistent results and provides a means of easily creating, training, and evaluating natural language processing (NLP) deep learning (DL) models.</p>
<p>Introduction</p>
<p>Consistently reproducing results is a fundamental criteria of the scientific method, without which, a hypothesis may be weakened or even invalidated. This is becoming even more necessary, because a growing number of publications are inflated by false positives, to the point that they are labeled with the pejorative term "p-hacking", the intentional or unintentional act to bias results in favor of publication for peer acceptance (Head et al., 2015); efforts in this direction include introducing new statistical methods to detect false findings (Ulrich and Miller, 2015).</p>
<p>The inability to reproduce results has been referred to as the "replication crisis" (Hutson, 2018). The problem of reproducibility in results is becoming more acknowledged as a serious issue in the ML community with efforts to understand and overcome the challenge (Olorisade et al., 2017). Not only has the community addressed the issue in the literature, it has endeavored to assess if experiments are reproducible and provide recommendations to remedy the problem where reproducibility is lacking. An example of this effort includes reporting on experimental methodology, implementation, analysis and conclusions in the Reproducibility Challenge 1 .</p>
<p>To address these issues, we present DeepZensols, a DL framework for NLP research by and for the academic research community. Not only does the framework address issues of reproducibility, it also is designed to easily and quickly test with varying model configurations such as extending contextual (and non-contextual) word embeddings (Devlin et al., 2019;Mikolov et al., 2013;Pennington et al., 2014) with linguistic token level features (Huang et al., 2015), and join layer document level features (Deerwester et al., 1990;Sparck Jones, 1972) using easy to write configuration with little to no code.</p>
<p>What sets DeepZensols apart from other frameworks is its capability of reproducing results, efficient mini-batch creation for feature swapping for model comparisons, and an emphasis on vectorization of natural language text providing zero coding neural network (NN) construction. The framework was written with NLP researchers, science related outcomers, and students in mind.</p>
<p>The framework's source code and installable libraries are released under the MIT License 2 , which is available both on GitHub and as Python pip packages along with extensive and in depth documentation, tutorials and Jupyter notebook 3 examples. The advanced programming interface (API) documentation is fully hyperlinked, includes overview docu-mentation, class diagrams, and tutorials. The framework is validated with 236 unit tests and six integration tests, most of which are automated using continuous integration testing for both functionality and reproducibility.</p>
<p>Previous Work</p>
<p>Popular DL frameworks such as TensorFlow 4 have a dashboard that provides metrics, such as training and validation loss. However, these general purpose frameworks offer basic performance metrics and do not provide a means of producing higher abstraction level NLP specific models. More specifically, frameworks such as Keras, supply a very coarse API allowing solely for cookie-cutter models. They lack the ability to easily create and evaluate models past this surface interface.</p>
<p>Frameworks such as PyTorch 5 , which are more common in academia, provide a more straightforward simple API that is similar to the core TensorFlow 6 libraries, and thus have the same shortcomings as a tool to bridge the gap between pure research and reproducibility.</p>
<p>AllenNLP 7 (Gardner et al., 2018) is a flexible configuration driven framework that provides ease of construction of NLP NN architectures, and thus, is the closest framework to ours. However, it does not have fast feature swapping (see Section 3.5) and batch creation capability, and lacks most of the components necessary to consistently reproduce results 8 . Popular packages providing support for transformer architectures such as BERT (Devlin et al., 2019) include HuggingFace 9 . However, this framework only provides transformer models for contextual word embeddings.</p>
<p>Design</p>
<p>Like the DeepDIVA (Alberti et al., 2018), DeepZensols is written in Python and utilizes, but does not replace, PyTorch. The goal of our framework is:</p>
<p> Reproducibility of results (see Section 3.1),</p>
<p> Efficiently create and load mini-batches (see Section 3.5),</p>
<p> Decouple the process of vectorizing data for reuse in NN architectures (see Section 3.4),</p>
<p> Provide language specific vectorization (see Section 3.6) and DL layers (see Section 3.7).</p>
<p>Reproducibility</p>
<p>All random state, including utility libraries, scientific libraries, the PyTorch library, and GPU state, is consistent across each run of a Python interpreter execution of the model's training, evaluation and testing. Results consistency is retained by saving this random state when saving the model, then retrieving and resetting it after loading the model. The order of mini-batches, and their constituent data can affect the model performance as an aspect of training or the results of validation and testing. This performance inconsistency is addressed by recording the order of all data 10 and tracking the training, validation and test data splits. Not only are mini-batches given in the same order, the ordering in each mini-batch is also preserved. These dataset partitions and their order is saved to the file system so the community has the option of distributing it along with the source code for later experiment duplication.</p>
<p>In addition, the framework also saves the configuration used to recreate the same in memory state along with the model. This duplicates the model structure, parameters, hyper-parameters and all other train-time memory during testing.</p>
<p>Technology Stack</p>
<p>Each "layer" of the stack builds on more general libraries to reduce the installation footprint based on the needs of each use case. Each library contains the requirements for dependent third-party and lower tier packages. The framework consists of the following libraries (see Figure 1):</p>
<p> zensols.util 11 : Utility library command line parsing, persistence and a Java  zensols.nlparse 13 : Parses natural language text using spaCy 14 , generates and vectorizes features.</p>
<p> zensols.deeplearn 15 : General purpose DL API, much like DeepDIVA, providing mini-batching, vectorization, and training, validation and testing of a model.</p>
<p> zensols.deepnlp 16 : Contains language vectorization, such as word embeddings (see Section 3.7), part of speech tags, named entity recognition, and head dependencies (McDonald et al., 2005).</p>
<p>Execution</p>
<p>The framework provides both a command line and a Jupyter notebook interface to train, test and predict. A "glue" API is used to make a Python dataclass 17 class a dynamically generated command line with help usage message documentation. A set of default application classes are available with the framework, but they can be extended to include project specific actions. The default application set provides interactive early stopping or epoch resetting during training.</p>
<p>12 https://spring.io 13 https://github.com/plandes/nlparse 14 https://spacy.io 15 https://github.com/plandes/deeplearn 16 https://github.com/plandes/deepnlp 17 https://docs.python.org/3/library/dataclasses.html</p>
<p>The command line and Jupyter notebook both use a common facade interface to the model itself, which is conducive as an entry point to both larger projects or simple run scripts. However, the Jupyter notebook interface provides evaluation training and validation loss plots (see Figure 2). Both interfaces provide a debugging mode that outputs a step of the model training with batch composition, layer names, dimension calculations, using the Python logging system, which is filterable by module or component.</p>
<p>Vectorization</p>
<p>The DeepZensols framework provides easily configurable components to digitally vectorize data, which in our framework, is encapsulated in a vectorizer, which takes a particular input data and outputs a tensor.</p>
<p>The zensols.deeplearn library is general purpose with respect to any kind of data, such as: text, images, audio. Examples of data it can vectorize include Pandas 18 data frames, enumerated nominal values (typically used for labels), and hot encoded vectors.</p>
<p>The zensols.deepnlp library provides a higher abstraction that parses natural language text, sentence chunks, and vectorizes linguistic features. These vectorizers fall into one of the following categories:</p>
<p>token: Features taken from each token, shape congruent with the number of tokens, typically concatenated with the embedding layer include spaCy features such as part of speech (POS) tags, named entity recognizer (NER) tags, dependency tree tags and the depth of a token in its head dependency tree.  For example, suppose the following sentences are to be vectorized: "The boy hit the ball. He did it well.". First the zensols.nlparse library is used to parse, chunk and POS tag the sentence (see Figure 3), then POS tags are converted to one-hot encoded vectors by the spaCy feature vectorizer (see Figure 4).   </p>
<p>Batching and Persistence</p>
<p>Most NNs expect and perform well using minibatches (Ioffe and Szegedy, 2015) as input accept or require batched input. A nave approach to generating these mini-batches would be to re-parse and re-vectorize the data for each mini-batch over each epoch, which is inefficient. Many projects address this inefficiency by pre-processing the data before training. However, this leads to a brittle and difficult to reproduce dataset generated set of adhoc text processing scripts that are challenging re-execute, and thus, reproduce performance metrics.</p>
<p>A cleaner and more efficient method is to wrap this process in the framework and create a file system scheme with the intermediate files in a configured location so as to not clutter the project workspace, which is supported by DeepZensols.</p>
<p>Another desirable feature of any framework is to easily swap in and out feature sets and compare performance metrics, which usually takes the form of the following steps: a) decide which features to use at train time, b) train and evaluate, c) test, d) evaluate performance, e) choose a different feature set, f) go to step a. This incremental process highlights the need to efficiently create mini-batches.</p>
<p>A key observation is that each mini-batch is independent 19 . The zensols.deeplearn leverages the fact that mini-batches are independent and fit nicely as independent units of work by segmenting datasets into smaller chunks, vectorizing each chunk in parallel sub processes, and creating one or more batches independently across each sub processes. This process by which data is written to the file system in a format that is fast to reassemble is called batch encoding, and accomplished by:</p>
<ol>
<li>
<p>Collecting data needed to vectorize, 2. Chunking data in to equal size parts, 3. Forking processes using the python multiprocessing api, 4. Vectorizing each chunk in each subprocess by: (a) Recreating parent memory by using configuration factory in the zensols.util library, (b) Vectorize each data chunk as separate feature sets, (c) Groups the vectorized in to bundles as mini-batches, but in separate files, (d) Vectorized data is almost always ready-to-go tensors. Batch decoding is the process by which data is grouped for training as mini-batches and is accomplished by:</p>
</li>
<li>
<p>Choosing a feature set for a training run, 2. Reassembling features by mini-batch, then feature as a two level directory structure (see Figure 5), 3. Decode each mini-batch in to a tensor, if not unserialized from the file system as a tensor (see Figure 6), 4. Copy tensors to the GPU if available, 5. Cache tensors in CPU or GPU memory 20 . Reassembling mini-batches by feature greatly reduces load time and memory space, which speeds up model training and allows for more complex models. This leverage is most apparent when comparing pre-generated frozen large BERT model embeddings for frozen transformers compared to a trainable model. In the case of the former, large data files with output tensors are read back in compared to word piece embeddings (Wu et al., 2016) for a trainable model.</p>
</li>
</ol>
<p>After mini-batch encoding is complete, several feature combinations can be created in configuration, then trained, validated and tested offline. Utility methods exist to aggregate results in tabular form for reporting. 20 Cached resources are tracked so GPU memory is maintained.     </p>
<p>Natural Language Features</p>
<p>What sets DeepZensols apart from other frameworks is not only efficient mini-batch creation and feature swapping (Section 3.5), but the tight coupling of natural language features with a deep learning API. Specifically, vectorization of natural language features is at the heart of the utility of the DeepZensols framework, and addresses a need that is otherwise lacking in other APIs. One such powerful capability is the concatenation of any vectorized data to word embeddings, which is available for both contextual embeddings such as BERT (Devlin et al., 2019) and non-contextual embeddings such as GLoVE (Pennington et al., 2014) (see Section 3.7) for supported word embedding types.</p>
<p>In addition to concatenation of word embeddings, document level features can be added to a join layer (see Figure 7).</p>
<p>Layers</p>
<p>The framework provides many layer implementations, which extend from the PyTorch Module class, thus any PyTorch module can be  Figure 7: Embedding Concatenation used in the framework. To this end, it uses layers such as the pytorch-crf 21 conditional random field implementation to create an end-toend model for sequence classification. Layers are configured in memory to offload the construction details to the framework. Other layers provided include, but are not limited to:</p>
<p> BiLSTM CRF for applications such as sequence tagging (Huang et al., 2015) as an end-to-end model, which requires no coding with the exception of mapping data input to vectorizers.</p>
<p> BERT transformer models for sentence and token classification.</p>
<p> 1D convolution NN that provides calculation for an arbitrarily deep network with input and output dimensionality calculation, pooling, mini-batch (Ioffe and Szegedy, 2015) centering and activation.</p>
<p> Expanding or contracting DL feed forward linear networks with repeats with input and output feature calculation.</p>
<p> Word embedding layer capable of concatenating linguistic features at both the token and document level (see Section 3.4). Supported embeddings include Bert (Devlin et al., 2019), word2vec (Mikolov et al., 2013), GLoVE (Pennington et al., 2014) and FastText (Bojanowski et al., 2017) (see Section 3.6).</p>
<p> Document level latent semantic analysis (LSA) (Deerwester et al., 1990), and term frequency with inverse document frequency weighting (Sparck Jones, 1972) are also available out of the box with no coding required 21 https://github.com/kmkurn/pytorch-crf HuggingFace transformer features are available as an embeddings vectorizer and document, sentence and token classification are available as layers. In addition a vectorizer is provided to map linguistic features created by spaCy to word piece embeddings (Wu et al., 2016) for concatenation with the last hidden state of the transformer.</p>
<p>Limitations and Future Work</p>
<p>While the framework is thoroughly tested in the areas it was designed for, some work remains to enable more variations in DL architecture for state-of-the-art (SOTA) experimentation.</p>
<p>Any of the HuggingFace pretrained models 22 are available, but only BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019) and DistilBERT (Sanh et al., 2020) have been tested and next sentence and masking prediction is not yet implemented.</p>
<p>A planned future work is to integrate the framework with TensorFlow's TensorBoard 23 , which provides real-time graphing of metrics such as training and validation loss.</p>
<p>Conclusion</p>
<p>The DeepZensols framework has been presented as a viable solution to easily create NLP specific models with APIs and analysis tools to produce consistent results. Such frameworks are not only necessary, but vital in order to ensure the legitimacy of the area of DL in NLP by providing the means necessary to produce reliable reproducible results.</p>
<p>Figure 1 :
1The Python Library Stack Spring 12 like inversion of control(Mattsson, 1996) configuration system.</p>
<p>Figure 2 :
2Validation and Training Loss Plot from the NER Token Classification Application</p>
<p>Figure 3 :
3Parse Sentence Chunk and POS Tagged</p>
<p>.</p>
<p>Figure 4 :
4Vectorize Language</p>
<p>Figure 5 :
5Batch Reassembly Process</p>
<p>.</p>
<p>Figure 6 :
6Batch Decode</p>
<p>document :
documentFeatures taken from the document level, typically added to a join layer such as count sums of spaCy parsed features.multi-document: Aggregating and shared fea-
tures between more than one document, 
such as overlapping POS or NER tags. </p>
<p>embedding: Vectorizes text into word embed-
dings, such as sentence or document text. </p>
<p>See Section 3.6 for more information on 
NLP specific feature generation. </p>
<p>document </p>
<p>sentence </p>
<p>token </p>
<p>The boy hit the ball. 
He did it well. </p>
<p>The boy hit the ball. 
He did it well. </p>
<p>The 
boy 
hit 
the 
ball 
He 
well </p>
<p>DET 
NN 
VBD 
DET 
NN 
PRP 
RB 
POS tag </p>
<p>https://www.tensorflow.org 5 https://pytorch.org 6 https://www.tensorflow.org 7 https://allennlp.org 8 https://github.com/allenai/allennlp/issues/3100 9 https://huggingface.co
Regardless of any user given data pre-processing or shuffling.
https://pandas.pydata.org
There are exceptions for some algorithms that need to index and fit the corpus before vectorization.
https://huggingface.co/models 23 https://www.tensorflow.org/tensorboard</p>
<p>DeepDIVA: A Highly-Functional Python Framework for Reproducible Experiments. Michele Alberti, Vinaychandran Pondenkandath, Marcel Wrsch, Rolf Ingold, Marcus Liwicki, 10.1109/ICFHR-2018.2018.0008016th International Conference on Frontiers in Handwriting Recognition (ICFHR). Michele Alberti, Vinaychandran Pondenkandath, Marcel Wrsch, Rolf Ingold, and Marcus Li- wicki. 2018. DeepDIVA: A Highly-Functional Python Framework for Reproducible Experi- ments. In 2018 16th International Confer- ence on Frontiers in Handwriting Recognition (ICFHR), pages 423-428.</p>
<p>Enriching Word Vectors with Subword Information. Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov, Transactions of the Association for Computational Linguistics. 5Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching Word Vec- tors with Subword Information. Transactions of the Association for Computational Linguistics, 5:135-146.</p>
<p>Indexing by Latent Semantic Analysis. Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, Richard Harshman, Journal of the American Society for Information Science. 416Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard Harshman. 1990. Indexing by Latent Seman- tic Analysis. Journal of the American Soci- ety for Information Science; New York, N.Y., 41(6):391-407.</p>
<p>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-train- ing of Deep Bidirectional Transformers for Lan- guage Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguis- tics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186.</p>
<p>AllenNLP: A Deep Semantic Natural Language Processing Platform. Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F Liu, Matthew E Peters, Michael Schmitz, Luke Zettlemoyer, Proceedings of Workshop for NLP Open Source Software (NLP-OSS). Workshop for NLP Open Source Software (NLP-OSS)Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew E. Peters, Michael Schmitz, and Luke Zettlemoyer. 2018. AllenNLP: A Deep Seman- tic Natural Language Processing Platform. In Proceedings of Workshop for NLP Open Source Software (NLP-OSS), pages 1-6.</p>
<p>The Extent and Consequences of P-Hacking in Science. Megan L Head, Luke Holman, Rob Lanfear, Andrew T Kahn, Michael D Jennions, PLoS Biology. 313Megan L. Head, Luke Holman, Rob Lanfear, An- drew T. Kahn, and Michael D. Jennions. 2015. The Extent and Consequences of P-Hacking in Science. PLoS Biology, 13(3).</p>
<p>Zhiheng Huang, Wei Xu, Kai Yu, arXiv:1508.01991Bidirectional LSTM-CRF Models for Sequence Tagging. Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi- rectional LSTM-CRF Models for Sequence Tag- ging. arXiv: 1508.01991.</p>
<p>Artificial intelligence faces reproducibility crisis. Matthew Hutson, Science. 3596377Matthew Hutson. 2018. Artificial intelligence faces reproducibility crisis. Science, 359(6377):725- 726.</p>
<p>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. Sergey Ioffe, Christian Szegedy, Proceedings of the 32nd International Conference on International Conference on Machine Learning. the 32nd International Conference on International Conference on Machine LearningJMLR.org37ICML'15Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In Proceedings of the 32nd International Con- ference on International Conference on Machine Learning -Volume 37, ICML'15, pages 448-456. JMLR.org.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692RoBERTa: A Robustly Optimized BERT Pretraining Approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv: 1907.11692.</p>
<p>Object-Oriented Frameworks. masters. Michael Mattsson, Ronneby, SwedenLund UniversityMichael Mattsson. 1996. Object-Oriented Frame- works. masters, Lund University, Ronneby, Swe- den.</p>
<p>Online Large-margin Training of Dependency Parsers. Ryan Mcdonald, Koby Crammer, Fernando Pereira, Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL '05. the 43rd Annual Meeting on Association for Computational Linguistics, ACL '05Association for Computational LinguisticsRyan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online Large-margin Training of Dependency Parsers. In Proceedings of the 43rd Annual Meeting on Association for Computa- tional Linguistics, ACL '05, pages 91-98. Asso- ciation for Computational Linguistics.</p>
<p>Distributed Representations of Words and Phrases and their Compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, Advances in Neural Information Processing Systems. C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. WeinbergerCurran Associates, Inc26Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed Rep- resentations of Words and Phrases and their Compositionality. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Wein- berger, editors, Advances in Neural Information Processing Systems 26, pages 3111-3119. Curran Associates, Inc.</p>
<p>Reproducibility in Machine Learning-Based Studies: An Example of Text Mining. K Babatunde, Pearl Olorisade, Peter Brereton, Andras, Babatunde K. Olorisade, Pearl Brereton, and Pe- ter Andras. 2017. Reproducibility in Machine Learning-Based Studies: An Example of Text Mining.</p>
<p>Glove: Global Vectors for Word Representation. Jeffrey Pennington, Richard Socher, Christopher Manning, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsJeffrey Pennington, Richard Socher, and Christo- pher Manning. 2014. Glove: Global Vectors for Word Representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532-1543. Association for Computational Lin- guistics.</p>
<p>Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf, arXiv:1910.01108DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2020. DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. arXiv: 1910.01108.</p>
<p>A statistical interpretation of term specificity and its application in retrieval. Karen Sparck, Jones , Journal of documentation. 281Karen Sparck Jones. 1972. A statistical interpre- tation of term specificity and its application in retrieval. Journal of documentation, 28(1):11- 21.</p>
<p>P-hacking by post hoc selection with multiple opportunities: Detectability by skewness test. Rolf Ulrich, Jeff Miller, http:/dx.doi.org.proxy.cc.uic.edu/10.1037/xge0000086Comment on Simonsohn. Nelson, and Simmons144Rolf Ulrich and Jeff Miller. 2015. P-hacking by post hoc selection with multiple opportuni- ties: Detectability by skewness test?: Comment on Simonsohn, Nelson, and Simmons (2014). Journal of Experimental Psychology: General, 144(6):1137-1145.</p>
<p>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, arXiv:1609.08144Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. Greg Corrado, Macduff Hughes, and Jeffrey DeanCliff Young, Jason Smith, Jason Riesa, Alex RudnickYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Ja- son Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. Google's Neural Machine Translation System: Bridging the Gap be- tween Human and Machine Translation. arXiv: 1609.08144.</p>            </div>
        </div>

    </div>
</body>
</html>