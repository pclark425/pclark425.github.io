<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3413 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3413</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3413</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-78.html">extraction-schema-78</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-247187518</p>
                <p><strong>Paper Title:</strong> <a href="https://www.aclanthology.org/2022.findings-acl.276.pdf" target="_blank">MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning</a></p>
                <p><strong>Paper Abstract:</strong> Logical reasoning is of vital importance to natural language understanding. Previous studies either employ graph-based models to incorporate prior knowledge about logical relations, or introduce symbolic logic into neural models through data augmentation. These methods, however, heavily depend on annotated training data, and thus suffer from over-fitting and poor generalization problems due to the dataset sparsity. To address these two problems, in this paper, we propose MERIt, a MEta-path guided contrastive learning method for logical ReasonIng of text, to perform self-supervised pre-training on abundant unlabeled text data. Two novel strategies serve as indispensable components of our method. In particular, a strategy based on meta-path is devised to discover the logical structure in natural texts, followed by a counterfactual data augmentation strategy to eliminate the information shortcut induced by pre-training. The experimental results on two challenging logical reasoning benchmarks, i.e., ReClor and LogiQA, demonstrate that our method outperforms the SOTA baselines with significant improvements.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3413.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3413.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MERIt+RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MERIt (meta-path guided contrastive pre-training) applied to RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper applies MERIt — meta-path guided contrastive pre-training with counterfactual data augmentation — to RoBERTa to improve multiple-choice logical reasoning (MCQA) on benchmarks by continuing pre-training on automatically constructed context-option contrastive pairs from Wikipedia.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (large backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RoBERTa is a Transformer-based masked-language-model pre-trained encoder (robustly optimized BERT variant). In this work RoBERTa-large is used as the backbone and further pre-trained with MERIt on Wikipedia contrastive data before fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor and LogiQA (multiple-choice logical reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Document-level multiple-choice reading-comprehension benchmarks requiring extraction of logical relations and multi-sentence reasoning (ReClor splits: Test-Easy and Test-Hard; LogiQA includes various logical reasoning types such as categorical and conditional reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>MERIt: meta-path guided contrastive learning (option-oriented and context-oriented contrastive losses) + counterfactual data augmentation + MLM during pre-training; prompt-tuning or simple fine-tuning on downstream MCQA.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ReClor test accuracy improved from 55.6% (RoBERTa baseline) to 59.6% (MERIt). ReClor dev improved from 62.6% to 66.8%. On LogiQA dev/test RoBERTa improved from 35.0%/35.3% to 40.0%/38.9% with MERIt.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Vanilla RoBERTa (directly fine-tuned): ReClor dev 62.6%, test 55.6%; LogiQA dev 35.0%, test 35.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Absolute gains of +4.0 percentage points on ReClor test and +4.2 on dev; +3.9 on LogiQA dev and +3.6 on LogiQA test compared to vanilla RoBERTa.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper notes potential trivial solutions where model exploits world-knowledge/factuality rather than logical consistency; MERIt addresses this via counterfactual augmentation. Option-oriented contrastive learning can bias models toward options and harm generalization. No claims of perfect logical deduction; improvements are empirical and dataset-limited.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Ablations show removing counterfactual data augmentation (-DA) causes severe performance degradation; removing meta-path guidance (-Meta-Path) also reduces performance substantially. Both option-oriented and context-oriented contrastive objectives help, with context-oriented CL being more effective. Best pre-training found at ~500 steps; even 100 steps gave competitive gains.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3413.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MERIt+ALBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MERIt (meta-path guided contrastive pre-training) applied to ALBERT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper applies MERIt to ALBERT (treated as ALBERT-xxlarge in experiments) showing larger absolute accuracy gains on logical reasoning benchmarks compared to ALBERT baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ALBERT (xxlarge backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>ALBERT is a parameter-reduced variant of BERT using factorized embedding parameterization and cross-layer parameter sharing; the paper refers to ALBERT-xxlarge as its ALBERT backbone and further pre-trains it with MERIt on Wikipedia-constructed contrastive data.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor and LogiQA (multiple-choice logical reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same MCQA benchmarks; ReClor includes a hard split (Test-H) intended to reduce dataset shortcuts; LogiQA tests diverse formal logical reasoning types.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>MERIt pre-training (meta-path guided contrastive learning + counterfactual augmentation + MLM) followed by prompt-tuning or fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ALBERT baseline: ReClor test 66.5% (dev 69.1%). MERIt (ALBERT): ReClor test 70.1% (dev 74.2%). MERIt (ALBERT) + Prompt: test 70.5%, dev 74.7%. On LogiQA MERIt(ALBERT) test 42.5% vs ALBERT baseline 37.6%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Vanilla ALBERT: ReClor test 66.5%, dev 69.1%; LogiQA test 37.6%, dev 38.9%.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Absolute gains of +3.6 percentage points on ReClor test (MERIt vs ALBERT) and +4.9 on LogiQA test; prompt-tuning gave modest further gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Same world-knowledge shortcut risk noted; without counterfactual augmentation performance degrades. The paper does not claim full logical generalization and observes diminishing returns for some prior augmentation methods when large fine-tuning data is available.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Ablation results mirror RoBERTa: counterfactual augmentation and meta-path guidance are essential; context-oriented CL is particularly beneficial. MERIt shows stronger gains under low-resource fine-tuning compared to baselines.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3413.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MERIt+DeBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MERIt applied to DeBERTa-v2-xlarge/xxlarge</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Authors report scaling MERIt to stronger pre-trained encoders (DeBERTa-v2-xlarge and xxlarge) and observe significant improvements on ReClor, validating scalability of the pre-training approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeBERTa-v2-xlarge / DeBERTa-v2-xxlarge</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>DeBERTa-v2 is a family of Transformer-based encoders with disentangled attention and enhanced mask decoders; the paper reports applying MERIt to large DeBERTa variants to evaluate scalability.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor (multiple-choice logical reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>ReClor requires multi-sentence logical reasoning; Test-H subset is designed to be harder and less susceptible to dataset shortcuts.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>MERIt pre-training (meta-path guided contrastive learning + counterfactual augmentation) applied to DeBERTa backbones.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Paper states Table 4 shows significant improvements for DeBERTa-v2-xlarge and xxlarge on ReClor when using MERIt, but numeric values are not reproduced in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Baseline DeBERTa results not explicitly detailed in the main text; paper reports that MERIt provides significant gains relative to the evaluated DeBERTa baselines in Table 4.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Reported as significant in the paper; exact numeric deltas are provided in Table 4 (not verbatim in the body text).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No model-specific failure modes described for DeBERTa beyond the general limitations discussed for MERIt (world-knowledge shortcuts, dependence on quality of meta-paths).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Paper indicates MERIt concept scales to stronger backbones; ablations described for RoBERTa/ALBERT (importance of counterfactual augmentation, meta-path, and CL objectives) are presented as general findings.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3413.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vanilla RoBERTa (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa: A robustly optimized BERT pretraining approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RoBERTa is used in the paper as a standard pre-trained encoder baseline fine-tuned directly on logical reasoning MCQA datasets (ReClor, LogiQA).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Roberta: A robustly optimized BERT pretraining approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer encoder with masked-language-model pretraining (improved BERT recipe); used as baseline by directly fine-tuning on downstream tasks without MERIt pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor and LogiQA</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>MCQA logical reasoning benchmarks requiring inference of logical relations across sentences.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>No special intervention; vanilla fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ReClor dev 62.6%, test 55.6% (Test-E 75.5%, Test-H 40.0%). LogiQA dev 35.0%, test 35.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Per paper, RoBERTa is more affected by dataset shortcuts and achieves poor performance on the harder ReClor Test-H split (40.0%); overfitting/poor generalization on sparse logical datasets is noted.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Used as baseline for comparison; analysis shows MERIt reduces sensitivity to statistical shortcuts and improves low-resource generalization versus vanilla RoBERTa.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3413.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vanilla ALBERT (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ALBERT: A lite BERT for self-supervised learning of language representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ALBERT (xxlarge) is used as a stronger baseline encoder; fine-tuned directly on logical reasoning benchmarks for comparison with MERIt-pretrained variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ALBERT: A lite BERT for self-supervised learning of language representations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ALBERT (xxlarge)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>ALBERT is a parameter-efficient Transformer encoder employing cross-layer parameter sharing and factorized embeddings; serves as a high-performing baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor and LogiQA</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Document-level MCQA logical reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>No MERIt pre-training (vanilla fine-tuning baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ReClor dev 69.1%, test 66.5% (Test-E 76.7%, Test-H 58.4%). LogiQA dev 38.9%, test 37.6%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Although stronger than RoBERTa, ALBERT also benefits from MERIt pre-training; the paper notes that pretrained language models still overfit and generalize poorly on sparse logical reasoning datasets without targeted pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>MERIt applied to ALBERT yields substantial gains, indicating that focused pre-training on logical structures complements strong base encoders.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3413.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LReasoner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic-driven context extension and data augmentation for logical reasoning of text (LReasoner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LReasoner is a prior method that extracts logical expressions to perform context extension and data augmentation for logical reasoning tasks; used as a state-of-the-art baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logic-driven context extension and data augmentation for logical reasoning of text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LReasoner</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A framework combining extracted logical expressions with context extension and task-specific data augmentation to improve MCQA logical reasoning; previously achieved SOTA on ReClor.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor (and LogiQA comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>MCQA requiring logical inference; LReasoner augments training data via logical expression extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Symbolic logic extraction + context extension + data augmentation (task-specific), compared against MERIt which uses self-supervised pretraining instead of augmenting original training data.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>LReasoner (RoBERTa reproduced) reported Dev 64.7%, Test 58.3% on ReClor in the paper's table; MERIt variants outperform LReasoner in the reported comparisons (depending on backbone and setup).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>MERIt (RoBERTa + Prompt) achieved higher test/dev numbers than LReasoner (RoBERTa) in reported comparisons; exact deltas vary by setup.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>LReasoner is task-specific and relies on extraction/augmentation from labeled task data; MERIt authors argue this leads to overfitting and limited generalization compared to self-supervised pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Paper argues MERIt already encodes many logical rules via pretraining, so combining MERIt with LReasoner gives limited extra benefit; ablation shows MERIt alone gives strong gains without original-data augmentation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3413.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Focal Reasoner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fact-driven logical reasoning (Focal Reasoner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Focal Reasoner is a fact-driven logical reasoning model that builds supergraphs over fact units for document-level logical reasoning; included as a strong baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fact-driven logical reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Focal Reasoner</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A neural model that constructs fact-centric graph structures (supergraphs) to capture global and local connections between facts for logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ReClor and LogiQA</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>MCQA benchmarks requiring reasoning over facts and their relations across a passage.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Graph-based architecture over fact units (task-specific modeling of relations), compared as a baseline to MERIt's pretraining approach.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported in paper table: Dev 66.8%, Test 58.9% on ReClor; LogiQA dev 41.0%, test 40.3%. MERIt variants outperform or match these results depending on backbone and tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>MERIt (RoBERTa) and MERIt (ALBERT) show higher accuracy on several reported splits compared to Focal Reasoner in the paper's comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Graph-based, task-specific architectures can be effective but rely on annotated or parsed logical structures; MERIt aims to reduce that reliance via self-supervised pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Compared empirically; MERIt emphasizes data-driven pretraining advantages (better low-resource generalization) over task-specific graph models.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3413.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3413.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformers / GPT-2 (mentions)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformers as soft reasoners; pre-trained GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites prior work showing that Transformers or pre-trained GPT-2 can perform complex reasoning on synthetic datasets, motivating efforts to introduce symbolic logic into neural models for natural-language logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transformers as soft reasoners over language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer / GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>General Transformer architectures and pre-trained autoregressive models (e.g., GPT-2) previously shown to solve synthetic reasoning tasks, but real-world logical reasoning remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Synthetic complex reasoning datasets (prior work) / general logical reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Synthetic tasks designed to probe multi-step or formal reasoning; differ from natural-language MCQA logical reasoning benchmarks like ReClor/LogiQA.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Prior work used synthetic data to test model reasoning; cited as motivation rather than directly used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Prior cited works claim Transformers/GPT-2 can perform complex reasoning on synthetic datasets (exact numbers belong to referenced papers, not reproduced here).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Authors note that success on synthetic datasets does not directly translate to real-world natural-language logical reasoning due to dataset sparsity and distributional shortcuts.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>MERIt is motivated in part by those findings and attempts to bridge gap by building contrastive pretraining tasks grounded in meta-path logical structures from raw text.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Logic-driven context extension and data augmentation for logical reasoning of text <em>(Rating: 2)</em></li>
                <li>Fact-driven logical reasoning <em>(Rating: 2)</em></li>
                <li>DAGN: discourse-aware graph network for logical reasoning <em>(Rating: 2)</em></li>
                <li>Transformers as soft reasoners over language <em>(Rating: 2)</em></li>
                <li>Critical thinking for language models <em>(Rating: 2)</em></li>
                <li>ReasonBERT: Pre-trained to reason with distant supervision <em>(Rating: 1)</em></li>
                <li>ERICA: improving entity and relation understanding for pre-trained language models via contrastive learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3413",
    "paper_id": "paper-247187518",
    "extraction_schema_id": "extraction-schema-78",
    "extracted_data": [
        {
            "name_short": "MERIt+RoBERTa",
            "name_full": "MERIt (meta-path guided contrastive pre-training) applied to RoBERTa",
            "brief_description": "This paper applies MERIt — meta-path guided contrastive pre-training with counterfactual data augmentation — to RoBERTa to improve multiple-choice logical reasoning (MCQA) on benchmarks by continuing pre-training on automatically constructed context-option contrastive pairs from Wikipedia.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "RoBERTa (large backbone)",
            "model_description": "RoBERTa is a Transformer-based masked-language-model pre-trained encoder (robustly optimized BERT variant). In this work RoBERTa-large is used as the backbone and further pre-trained with MERIt on Wikipedia contrastive data before fine-tuning.",
            "model_size": null,
            "reasoning_task_name": "ReClor and LogiQA (multiple-choice logical reasoning)",
            "reasoning_task_description": "Document-level multiple-choice reading-comprehension benchmarks requiring extraction of logical relations and multi-sentence reasoning (ReClor splits: Test-Easy and Test-Hard; LogiQA includes various logical reasoning types such as categorical and conditional reasoning).",
            "method_or_intervention": "MERIt: meta-path guided contrastive learning (option-oriented and context-oriented contrastive losses) + counterfactual data augmentation + MLM during pre-training; prompt-tuning or simple fine-tuning on downstream MCQA.",
            "performance": "ReClor test accuracy improved from 55.6% (RoBERTa baseline) to 59.6% (MERIt). ReClor dev improved from 62.6% to 66.8%. On LogiQA dev/test RoBERTa improved from 35.0%/35.3% to 40.0%/38.9% with MERIt.",
            "baseline_performance": "Vanilla RoBERTa (directly fine-tuned): ReClor dev 62.6%, test 55.6%; LogiQA dev 35.0%, test 35.3%.",
            "improvement_over_baseline": "Absolute gains of +4.0 percentage points on ReClor test and +4.2 on dev; +3.9 on LogiQA dev and +3.6 on LogiQA test compared to vanilla RoBERTa.",
            "limitations_or_failures": "Paper notes potential trivial solutions where model exploits world-knowledge/factuality rather than logical consistency; MERIt addresses this via counterfactual augmentation. Option-oriented contrastive learning can bias models toward options and harm generalization. No claims of perfect logical deduction; improvements are empirical and dataset-limited.",
            "ablation_or_analysis": "Ablations show removing counterfactual data augmentation (-DA) causes severe performance degradation; removing meta-path guidance (-Meta-Path) also reduces performance substantially. Both option-oriented and context-oriented contrastive objectives help, with context-oriented CL being more effective. Best pre-training found at ~500 steps; even 100 steps gave competitive gains.",
            "uuid": "e3413.0"
        },
        {
            "name_short": "MERIt+ALBERT",
            "name_full": "MERIt (meta-path guided contrastive pre-training) applied to ALBERT",
            "brief_description": "The paper applies MERIt to ALBERT (treated as ALBERT-xxlarge in experiments) showing larger absolute accuracy gains on logical reasoning benchmarks compared to ALBERT baseline.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ALBERT (xxlarge backbone)",
            "model_description": "ALBERT is a parameter-reduced variant of BERT using factorized embedding parameterization and cross-layer parameter sharing; the paper refers to ALBERT-xxlarge as its ALBERT backbone and further pre-trains it with MERIt on Wikipedia-constructed contrastive data.",
            "model_size": null,
            "reasoning_task_name": "ReClor and LogiQA (multiple-choice logical reasoning)",
            "reasoning_task_description": "Same MCQA benchmarks; ReClor includes a hard split (Test-H) intended to reduce dataset shortcuts; LogiQA tests diverse formal logical reasoning types.",
            "method_or_intervention": "MERIt pre-training (meta-path guided contrastive learning + counterfactual augmentation + MLM) followed by prompt-tuning or fine-tuning.",
            "performance": "ALBERT baseline: ReClor test 66.5% (dev 69.1%). MERIt (ALBERT): ReClor test 70.1% (dev 74.2%). MERIt (ALBERT) + Prompt: test 70.5%, dev 74.7%. On LogiQA MERIt(ALBERT) test 42.5% vs ALBERT baseline 37.6%.",
            "baseline_performance": "Vanilla ALBERT: ReClor test 66.5%, dev 69.1%; LogiQA test 37.6%, dev 38.9%.",
            "improvement_over_baseline": "Absolute gains of +3.6 percentage points on ReClor test (MERIt vs ALBERT) and +4.9 on LogiQA test; prompt-tuning gave modest further gains.",
            "limitations_or_failures": "Same world-knowledge shortcut risk noted; without counterfactual augmentation performance degrades. The paper does not claim full logical generalization and observes diminishing returns for some prior augmentation methods when large fine-tuning data is available.",
            "ablation_or_analysis": "Ablation results mirror RoBERTa: counterfactual augmentation and meta-path guidance are essential; context-oriented CL is particularly beneficial. MERIt shows stronger gains under low-resource fine-tuning compared to baselines.",
            "uuid": "e3413.1"
        },
        {
            "name_short": "MERIt+DeBERTa",
            "name_full": "MERIt applied to DeBERTa-v2-xlarge/xxlarge",
            "brief_description": "Authors report scaling MERIt to stronger pre-trained encoders (DeBERTa-v2-xlarge and xxlarge) and observe significant improvements on ReClor, validating scalability of the pre-training approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "DeBERTa-v2-xlarge / DeBERTa-v2-xxlarge",
            "model_description": "DeBERTa-v2 is a family of Transformer-based encoders with disentangled attention and enhanced mask decoders; the paper reports applying MERIt to large DeBERTa variants to evaluate scalability.",
            "model_size": null,
            "reasoning_task_name": "ReClor (multiple-choice logical reasoning)",
            "reasoning_task_description": "ReClor requires multi-sentence logical reasoning; Test-H subset is designed to be harder and less susceptible to dataset shortcuts.",
            "method_or_intervention": "MERIt pre-training (meta-path guided contrastive learning + counterfactual augmentation) applied to DeBERTa backbones.",
            "performance": "Paper states Table 4 shows significant improvements for DeBERTa-v2-xlarge and xxlarge on ReClor when using MERIt, but numeric values are not reproduced in the main text.",
            "baseline_performance": "Baseline DeBERTa results not explicitly detailed in the main text; paper reports that MERIt provides significant gains relative to the evaluated DeBERTa baselines in Table 4.",
            "improvement_over_baseline": "Reported as significant in the paper; exact numeric deltas are provided in Table 4 (not verbatim in the body text).",
            "limitations_or_failures": "No model-specific failure modes described for DeBERTa beyond the general limitations discussed for MERIt (world-knowledge shortcuts, dependence on quality of meta-paths).",
            "ablation_or_analysis": "Paper indicates MERIt concept scales to stronger backbones; ablations described for RoBERTa/ALBERT (importance of counterfactual augmentation, meta-path, and CL objectives) are presented as general findings.",
            "uuid": "e3413.2"
        },
        {
            "name_short": "Vanilla RoBERTa (baseline)",
            "name_full": "RoBERTa: A robustly optimized BERT pretraining approach",
            "brief_description": "RoBERTa is used in the paper as a standard pre-trained encoder baseline fine-tuned directly on logical reasoning MCQA datasets (ReClor, LogiQA).",
            "citation_title": "Roberta: A robustly optimized BERT pretraining approach",
            "mention_or_use": "use",
            "model_name": "RoBERTa",
            "model_description": "Transformer encoder with masked-language-model pretraining (improved BERT recipe); used as baseline by directly fine-tuning on downstream tasks without MERIt pretraining.",
            "model_size": null,
            "reasoning_task_name": "ReClor and LogiQA",
            "reasoning_task_description": "MCQA logical reasoning benchmarks requiring inference of logical relations across sentences.",
            "method_or_intervention": "No special intervention; vanilla fine-tuning.",
            "performance": "ReClor dev 62.6%, test 55.6% (Test-E 75.5%, Test-H 40.0%). LogiQA dev 35.0%, test 35.3%.",
            "baseline_performance": null,
            "improvement_over_baseline": null,
            "limitations_or_failures": "Per paper, RoBERTa is more affected by dataset shortcuts and achieves poor performance on the harder ReClor Test-H split (40.0%); overfitting/poor generalization on sparse logical datasets is noted.",
            "ablation_or_analysis": "Used as baseline for comparison; analysis shows MERIt reduces sensitivity to statistical shortcuts and improves low-resource generalization versus vanilla RoBERTa.",
            "uuid": "e3413.3"
        },
        {
            "name_short": "Vanilla ALBERT (baseline)",
            "name_full": "ALBERT: A lite BERT for self-supervised learning of language representations",
            "brief_description": "ALBERT (xxlarge) is used as a stronger baseline encoder; fine-tuned directly on logical reasoning benchmarks for comparison with MERIt-pretrained variants.",
            "citation_title": "ALBERT: A lite BERT for self-supervised learning of language representations",
            "mention_or_use": "use",
            "model_name": "ALBERT (xxlarge)",
            "model_description": "ALBERT is a parameter-efficient Transformer encoder employing cross-layer parameter sharing and factorized embeddings; serves as a high-performing baseline.",
            "model_size": null,
            "reasoning_task_name": "ReClor and LogiQA",
            "reasoning_task_description": "Document-level MCQA logical reasoning tasks.",
            "method_or_intervention": "No MERIt pre-training (vanilla fine-tuning baseline).",
            "performance": "ReClor dev 69.1%, test 66.5% (Test-E 76.7%, Test-H 58.4%). LogiQA dev 38.9%, test 37.6%.",
            "baseline_performance": null,
            "improvement_over_baseline": null,
            "limitations_or_failures": "Although stronger than RoBERTa, ALBERT also benefits from MERIt pre-training; the paper notes that pretrained language models still overfit and generalize poorly on sparse logical reasoning datasets without targeted pretraining.",
            "ablation_or_analysis": "MERIt applied to ALBERT yields substantial gains, indicating that focused pre-training on logical structures complements strong base encoders.",
            "uuid": "e3413.4"
        },
        {
            "name_short": "LReasoner",
            "name_full": "Logic-driven context extension and data augmentation for logical reasoning of text (LReasoner)",
            "brief_description": "LReasoner is a prior method that extracts logical expressions to perform context extension and data augmentation for logical reasoning tasks; used as a state-of-the-art baseline in comparisons.",
            "citation_title": "Logic-driven context extension and data augmentation for logical reasoning of text",
            "mention_or_use": "mention",
            "model_name": "LReasoner",
            "model_description": "A framework combining extracted logical expressions with context extension and task-specific data augmentation to improve MCQA logical reasoning; previously achieved SOTA on ReClor.",
            "model_size": null,
            "reasoning_task_name": "ReClor (and LogiQA comparisons)",
            "reasoning_task_description": "MCQA requiring logical inference; LReasoner augments training data via logical expression extraction.",
            "method_or_intervention": "Symbolic logic extraction + context extension + data augmentation (task-specific), compared against MERIt which uses self-supervised pretraining instead of augmenting original training data.",
            "performance": "LReasoner (RoBERTa reproduced) reported Dev 64.7%, Test 58.3% on ReClor in the paper's table; MERIt variants outperform LReasoner in the reported comparisons (depending on backbone and setup).",
            "baseline_performance": null,
            "improvement_over_baseline": "MERIt (RoBERTa + Prompt) achieved higher test/dev numbers than LReasoner (RoBERTa) in reported comparisons; exact deltas vary by setup.",
            "limitations_or_failures": "LReasoner is task-specific and relies on extraction/augmentation from labeled task data; MERIt authors argue this leads to overfitting and limited generalization compared to self-supervised pretraining.",
            "ablation_or_analysis": "Paper argues MERIt already encodes many logical rules via pretraining, so combining MERIt with LReasoner gives limited extra benefit; ablation shows MERIt alone gives strong gains without original-data augmentation.",
            "uuid": "e3413.5"
        },
        {
            "name_short": "Focal Reasoner",
            "name_full": "Fact-driven logical reasoning (Focal Reasoner)",
            "brief_description": "Focal Reasoner is a fact-driven logical reasoning model that builds supergraphs over fact units for document-level logical reasoning; included as a strong baseline in comparisons.",
            "citation_title": "Fact-driven logical reasoning",
            "mention_or_use": "mention",
            "model_name": "Focal Reasoner",
            "model_description": "A neural model that constructs fact-centric graph structures (supergraphs) to capture global and local connections between facts for logical reasoning.",
            "model_size": null,
            "reasoning_task_name": "ReClor and LogiQA",
            "reasoning_task_description": "MCQA benchmarks requiring reasoning over facts and their relations across a passage.",
            "method_or_intervention": "Graph-based architecture over fact units (task-specific modeling of relations), compared as a baseline to MERIt's pretraining approach.",
            "performance": "Reported in paper table: Dev 66.8%, Test 58.9% on ReClor; LogiQA dev 41.0%, test 40.3%. MERIt variants outperform or match these results depending on backbone and tuning.",
            "baseline_performance": null,
            "improvement_over_baseline": "MERIt (RoBERTa) and MERIt (ALBERT) show higher accuracy on several reported splits compared to Focal Reasoner in the paper's comparisons.",
            "limitations_or_failures": "Graph-based, task-specific architectures can be effective but rely on annotated or parsed logical structures; MERIt aims to reduce that reliance via self-supervised pretraining.",
            "ablation_or_analysis": "Compared empirically; MERIt emphasizes data-driven pretraining advantages (better low-resource generalization) over task-specific graph models.",
            "uuid": "e3413.6"
        },
        {
            "name_short": "Transformers / GPT-2 (mentions)",
            "name_full": "Transformers as soft reasoners; pre-trained GPT-2",
            "brief_description": "The paper cites prior work showing that Transformers or pre-trained GPT-2 can perform complex reasoning on synthetic datasets, motivating efforts to introduce symbolic logic into neural models for natural-language logical reasoning.",
            "citation_title": "Transformers as soft reasoners over language",
            "mention_or_use": "mention",
            "model_name": "Transformer / GPT-2",
            "model_description": "General Transformer architectures and pre-trained autoregressive models (e.g., GPT-2) previously shown to solve synthetic reasoning tasks, but real-world logical reasoning remains challenging.",
            "model_size": null,
            "reasoning_task_name": "Synthetic complex reasoning datasets (prior work) / general logical reasoning",
            "reasoning_task_description": "Synthetic tasks designed to probe multi-step or formal reasoning; differ from natural-language MCQA logical reasoning benchmarks like ReClor/LogiQA.",
            "method_or_intervention": "Prior work used synthetic data to test model reasoning; cited as motivation rather than directly used in experiments.",
            "performance": "Prior cited works claim Transformers/GPT-2 can perform complex reasoning on synthetic datasets (exact numbers belong to referenced papers, not reproduced here).",
            "baseline_performance": null,
            "improvement_over_baseline": null,
            "limitations_or_failures": "Authors note that success on synthetic datasets does not directly translate to real-world natural-language logical reasoning due to dataset sparsity and distributional shortcuts.",
            "ablation_or_analysis": "MERIt is motivated in part by those findings and attempts to bridge gap by building contrastive pretraining tasks grounded in meta-path logical structures from raw text.",
            "uuid": "e3413.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Logic-driven context extension and data augmentation for logical reasoning of text",
            "rating": 2,
            "sanitized_title": "logicdriven_context_extension_and_data_augmentation_for_logical_reasoning_of_text"
        },
        {
            "paper_title": "Fact-driven logical reasoning",
            "rating": 2,
            "sanitized_title": "factdriven_logical_reasoning"
        },
        {
            "paper_title": "DAGN: discourse-aware graph network for logical reasoning",
            "rating": 2,
            "sanitized_title": "dagn_discourseaware_graph_network_for_logical_reasoning"
        },
        {
            "paper_title": "Transformers as soft reasoners over language",
            "rating": 2,
            "sanitized_title": "transformers_as_soft_reasoners_over_language"
        },
        {
            "paper_title": "Critical thinking for language models",
            "rating": 2,
            "sanitized_title": "critical_thinking_for_language_models"
        },
        {
            "paper_title": "ReasonBERT: Pre-trained to reason with distant supervision",
            "rating": 1,
            "sanitized_title": "reasonbert_pretrained_to_reason_with_distant_supervision"
        },
        {
            "paper_title": "ERICA: improving entity and relation understanding for pre-trained language models via contrastive learning",
            "rating": 1,
            "sanitized_title": "erica_improving_entity_and_relation_understanding_for_pretrained_language_models_via_contrastive_learning"
        }
    ],
    "cost": 0.0161235,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning
Association for Computational LinguisticsCopyright Association for Computational LinguisticsMay 22-27, 2022 c 2022</p>
<p>Fangkai Jiao jiaofangkai@hotmail.com 
School of Computer Science and Technology
Shandong University
QingdaoChina</p>
<p>Yangyang Guo 
School of Computing
National University of Singapore</p>
<p>Xuemeng Song 
School of Computer Science and Technology
Shandong University
QingdaoChina</p>
<p>Liqiang Nie nieliqiang@gmail.com 
School of Computer Science and Technology
Shandong University
QingdaoChina</p>
<p>MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning</p>
<p>Association for Computational Linguistics: ACL 2022
Association for Computational LinguisticsMay 22-27, 2022 c 2022
Logical reasoning is of vital importance to natural language understanding. Previous studies either employ graph-based models to incorporate prior knowledge about logical relations, or introduce symbolic logic into neural models through data augmentation. These methods, however, heavily depend on annotated training data, and thus suffer from overfitting and poor generalization problems due to the dataset sparsity. To address these two problems, in this paper, we propose MERIt, a MEta-path guided contrastive learning method for logical ReasonIng of text, to perform selfsupervised pre-training on abundant unlabeled text data. Two novel strategies serve as indispensable components of our method. In particular, a strategy based on meta-path is devised to discover the logical structure in natural texts, followed by a counterfactual data augmentation strategy to eliminate the information shortcut induced by pre-training. The experimental results on two challenging logical reasoning benchmarks, i.e., ReClor and LogiQA, demonstrate that our method outperforms the SOTA baselines with significant improvements. 1 * Corresponding author: Yangyang Guo and Liqiang Nie. 1 Our code and pre-trained models are available at https: //github.com/SparkJiao/MERIt. 2  We refer the term logical reasoning to the task itself in the remaining of this paper.</p>
<p>Introduction</p>
<p>Logical reasoning has long been recognized as one key critical thinking ability of human being. Until very recently, some pioneer researchers have crystallized this for the NLP community, and built several public challenging benchmarks, such as ReColor (Yu et al., 2020) and LogiQA (Liu et al., 2020). Logical reasoning 2 requires to correctly infer the semantic relations with respect to the constituents among different sentences. A typical formulation of logical reasoning is illustrated Figure 1: An instance of logical reasoning from the Re-Clor dataset. To infer the right answer, we should uncover the underlying logical structure, as shown in the bottom. (x) represents the logical variable (e.g., entity or phrase) and r j denotes the relation (e.g., predicate) between two logical variables.r j is the passive relation of r j .</p>
<p>in Figure 1, namely, a real-world examination instance from ReClor. As can be seen, to find the correct answer for the given question, one needs to extract the logical structures residing in a pair of each option and the whole context, and justify its reasonableness.</p>
<p>As a matter of fact, logical reasoning is still at its initial stage, thence, existing studies are somewhat rare in literature. Some efforts have been devoted to designing specific model architectures or integrating symbolic logic as the hints attached to the potential logical structure. For instance,  and Ouyang et al. (2021) first constructed a graph of different constituents and then performed implicit reasoning with graph neural networks (GNNs). Wang et al. (2022) proposed LReasoner, a unified context extension and data augmentation framework based on the parsed logical expressions.</p>
<p>These approaches have achieved some progress on benchmark datasets. However, though equipped with pre-trained language models, they still suffer from problems like overfitting and poor generalization. We attribute these drawbacks to the difficulty of building a model aware of the logical relations beneath natural language, which is revealed from two sides: 1) the high sparsity of the existing datasets, and 2) the goal of general pre-training, i.e., masked language modeling (Devlin et al., 2019), which however, deviates largely from that of the logical reasoning. To tackle this issue, we aim to build a bridge between logical reasoning and self-supervised pre-training, and accordingly inherit the strong generalization power from pre-trained language models.</p>
<p>Our proposed method is inspired by the recent progress of contrastive learning based pre-training. It mainly consists of two novel components: metapath guided data construction and counterfactual data augmentation. Both components are leveraged to perform automatic instance composition from unlabeled corpus (e.g., Wikipedia) for contrastive learning. Regarding the first component, we propose to employ the meta-path to define a symbolic form of logical structure. The intuition behind this is that the logical structure can be expressed as a reasoning path composed of a series of relation triplets, and a meta-path inherently offers such a means of consistency (Liu et al., 2021). Specifically, given an arbitrary document and a pair of entities in it, we try to find a positive instance pair in the document according to the logical structure. And the negative ones can thus be generated by modifying the relations involved in the structure, which explicitly break the logical consistency. Nevertheless, the contrastive learning often fails when models easily locate trivial solutions (Lai et al., 2021). In this context, the pre-trained language model may exclude the negative options through their conflicts with the world knowledge. To eliminate this information shortcut, in our second novel component, we devise a strong counterfactual data augmentation (Zeng et al., 2020b) strategy. By mixing counterfactual data during pre-training, of which the positive instance pair is also against the world knowledge, this component shows more ad-vantage in reasoning over logical relations.</p>
<p>We integrate this method with both AL-BERT (Lan et al., 2020) and RoBERTa  3 for further pre-training, and then fine-tune them on two downstream logical reasoning benchmarks, i.e., ReClor and LogiQA. The experimental results demonstrate that our method can outperform all the existing strong baselines, yet without any augmentation from the original training data. Besides, the ablation studies also show the effectiveness of the two essential strategies in our method. The contribution of this paper is summarized as follows:</p>
<ol>
<li>
<p>We propose MERIt, a MEta-path guided contrastive learning method for logical Reason-Ing of text, to reduce the heavy reliance on annotated data. To the best of our knowledge, we are the first to explore self-supervised pretraining for logical reasoning.</p>
</li>
<li>
<p>We successfully employ the meta-path strategy to mine the potential logical structure in raw text. It is able to automatically generate negative candidates for contrastive learning via logical relation editing.</p>
</li>
<li>
<p>We propose a simple yet effective counterfactual data augmentation method to eliminate the information shortcut during pre-training.</p>
</li>
<li>
<p>We evaluate our method on two logical reasoning tasks, LogiQA and ReClor. The experimental results show that our method achieves the new state-of-the-art performance on two benchmark datasets.</p>
</li>
</ol>
<p>2 Related Work 2.1 Self-Supervised Pre-training</p>
<p>With the success of language modeling based pretraining (Devlin et al., 2019;Brown et al., 2020), designing self-supervised pretext tasks to facilitate specific downstream ones has been extensively studied thus far. For example, Guu et al. (2020) proposed to train the retriever jointly with the encoder via retrieval enhanced masked language modeling for open-domain question answering. Jiao et al.</p>
<p>(2021) devised a retrieval-based pre-training approach to bridge the gap between language modeling and machine reading comprehension by enhancing the evidence extraction ability. Deng et al. (2021) proposed ReasonBERT to facilitate complex reasoning over multiple and hybrid contexts. The model is pre-trained on automatically constructed query-evidence pairs, which involve different types of corpora and long-range relations. In addition, contrastive learning (Hadsell et al., 2006) contributes to a strong toolkit to implement self-supervised pre-training. The key to contrastive learning is to build efficacious positive and negative counterparts. For example, Gao et al. (2021) leveraged Dropout (Srivastava et al., 2014) to build positive pairs from the same sentence while keeping the semantics untouched. Other sentences in the same mini-batch serve as negative candidates to obtain better sentence embeddings. ERICA (Qin et al., 2021) is a knowledge enhanced language model pre-trained through entity and relation discrimination, where the negative candidates are sampled from the pre-defined dictionaries. Nevertheless, directly employing these contrastive learning approaches to logical reasoning is arduous. One possible reason to this is the absence of distant labels or strong assumptions to group the naturally occurring text by its logical structure.</p>
<p>Logical Reasoning</p>
<p>Logical reasoning has attracted increasing research attention recently. Devising specific model architectures and integrating symbolic logic have been proved to be two effective solutions. For example,  and Ouyang et al. (2021) proposed to extract the basic units for logical reasoning, e.g., the elementary discourse or fact units, and then employed GNNs to model possible relationships. The graph structure of constituents can be viewed as a form of prior knowledge pertaining to logical relations. Differently, Betz et al. (2021) and Clark et al. (2020) used synthetically generated datasets to prove that the Transformer (Vaswani et al., 2017) or pre-trained GPT-2 is able to perform complex reasoning, motivating following researchers to introduce symbolic rules into neural models. For example, Wang et al. (2022) developed a context extension and data augmentation framework, which is based on the extracted logical expressions. Superior performance over its contenders can be observed on the ReClor dataset.</p>
<p>In this paper, we propose a self-supervised contrastive learning approach to enhance the logical reasoning ability of neural models. Orthogonal to existing methods, our approach is endowed with two intriguing merits: 1) it shows strong advan-tage in utilizing the unlabeled text data, and 2) the symbolic logic is seamlessly introduced into neural models via the guidance of meta-path for automatic data construction.</p>
<p>Preliminary</p>
<p>Contrastive Learning</p>
<p>Contrastive Learning (CL) aims to learn recognizable representations by pulling the semantically similar examples close and pushing apart the dissimilar ones (Hadsell et al., 2006). Given an instance x, a semantically similar example x + , and a set of dissimilar examples X − to x, the objective of CL can be formulated as:
L CL = L(x, x + , X − ) = − log exp f (x, x + ) x ∈X − ∪{x + } exp f (x, x )(1)
where f is the model to be optimized.</p>
<p>Symbolic Logical Reasoning</p>
<p>As shown in Figure 1, given a context containing a series of logical variables {v 1 , v 2 , · · · , v n }, and the relations between them, the logical reasoning objective is to judge whether a triplet v i , r i,j , v j in language, where r i,j is the relation between v i and v j , can be inferred from the context through a reasoning path:
v i , r i,j , v j ← (v i r i,i+1 −→ v i+1 · · · r j−1,j −→ v j ). (2)
The equation is also referred to symbolic logic rules (Clark et al., 2020;Liu et al., 2021).</p>
<p>Meta-Path</p>
<p>Given an entity-level knowledge graph, where the nodes refer to entities and edges are the relations among them, the meta-path connecting two target entities e i , e j can be given as,
e i r i,i+1 −→ e i+1 r i+1,i+2 −→ · · · e j−1 r j−1,j −→ e j ,(3)
where r i,j denotes the relation between entities e i and e j . The meta-path in the entity-level knowledge graph are often employed as a particular data structure expressing the relation between two indirectly connected entities (Zeng et al., 2020a;Xu et al., 2021).  Positive Data Pair = 1 , 5 ↔ 3</p>
<p>(a) Graph Construction (b) Meta-Path Guided Positive Instance Construction (c) Negative Candidate Generation (d) Counterfactual Data Augmentation</p>
<p>Context-oriented</p>
<p>(e) Objectives of Contrastive Learning</p>
<p>Option-oriented Figure 2: The overall framework of our proposed method. (a) A document D from Wikipedia and the corresponding entity-level graph construction. The sentences in black will be extracted as the context input for (b). (b) Given two target entities e 1 , e 5 , the possible answers A + and the meta-path are firstly extracted. The context sentences S connecting the entities in the meta-path, and the answers in A, are leveraged to yield positive instance pairs. (c) Given a sentence z with alternative relations, the relation modification for negative context sentence and option construction is implemented through entity replacement. The top operation is performed for negative options while the bottom one is to facilitate negative contexts. (d) The counterfactual sentences are generated by entity replacement to eliminate the information shortcut during pre-training. (e) The generated positive and negative samples are used for contrastive learning.</p>
<p>Method</p>
<p>In this paper, we study the problem of logical reasoning on the task of multiple choice question answering (MCQA). Specifically, given a passage P , a question Q and a set of K options O = {O 1 , · · · , O K }, the goal is to select the correct option O y , where y ∈ [1, K]. Notably, to tackle this task, we devise a novel pre-training method equipped with contrastive learning, where the abundant knowledge contained in the largescale Wikipedia documents is explored. We then transfer the learned knowledge to the downstream logical reasoning task.</p>
<p>From Logical Reasoning to Meta-Path</p>
<p>In a sense, in MCQA for logical reasoning, both the given context (i.e., passage and question) and options express certain relations between different logical variables (Figure 1). Go a step further, following Equation 2, the relation triplet contained in the correct option should be deduced from the given context through a reasoning path, while that in the wrong options should not. In other words, the context is logically consistent with the correct option only.</p>
<p>In light of this, the training instances for our contrastive learning based pre-training should be in the form of a context-option pair, where the context consists of multiple sentences and expresses the relations between the included constituents, while the option should illustrate the potential relations between parts of the constituents. Nevertheless, it is non-trivial to derive such instance pairs from large-scale unlabeled corpus like Wikipedia due to the redundant constituents, e.g., nouns and predicates. In order to address it, we propose to take the entities contained in unlabeled text as logical variables, and Equation 2 can be transformed as:
e i , r i,j , e j ← (e i r i,i+1 −→ e i+1 · · · r j−1,j −→ e j ). (4)
As can be seen, the right part above is indeed a meta-path connecting e i , e j as formulated in Equation 3, indicating an indirect relation between e i , e j through intermediary entities and relations. In order to aid the logical consistency conditioned on entities to be established, we posit an assumption that under the same context (in the same passage), the definite relation between a pair of en-tities can be inferred from the contextual indirect one, or at least not logically contradict to it. Taking the passage in Figure 2 as an example, it can be concluded from the sentences s 1 and s 5 that, the director McKean has cooperated with Stephanie Leonidas. Therefore, the logic is consistent between {s 1 , s 5 } and s 3 . This can be viewed as a weaker constraint than the original one in Equation 2 for logical consistency, yet it can be further enhanced by constructing negative candidates violating logics.</p>
<p>Motivated by this, given an arbitrary document D = {s 1 , · · · , s m }, where s i is the i-th sentence, we can first build an entity-level graph, denoted as G = (V, E), where V is the set of entities contained in D and E denotes the set of relations between entities. Notably, to comprehensively capture the relations among entities, we take into account both the external relation from the knowledge graph and the intra-sentence relation. As illustrated in Figure 2 (a), there will be an intra-sentence relation between two entities if they are mentioned in a common sentence. Thereafter, we can derive the pre-training instance pairs according to the meta-paths extracted from the graph, which will be detailed in the following subsections.</p>
<p>Meta-Path Guided Positive Instance Construction</p>
<p>As defined in Equation 4, in the positive instances, the answer should contain a relation triplet that is logically consistent with the given context. Since we take the intra-sentence relationship into consideration, given a pair of entities contained in the document, we first collect the sentences mentioning both of them as the set of answer candidates. Accordingly, we then try to find a meta-path connecting the entity pair and hence derive the corresponding logically consistent context. In particular, as shown in Figure 2 (b), given an entity pair e i , e j , we denote the collected answer candidates as A + , and then we use Depth-First Search (Tarjan, 1972) to find a meta-path linking them on G, following Equation 3. Thereafter, the context sentences S corresponding to the answer candidates in A + are derived by retrieving those sentences undertaking the intra-sentence relations during the search algorithm. Finally, for each answer candidate a ∈ A + , the pair (S, a) is treated as a positive context-answer pair to facilitate our contrastive learning. The details of positive instance generation algorithm are described in Appendix A.</p>
<p>Negative Instance Generation</p>
<p>In order to obtain the negative instances (i.e., negative context-option pairs) where the option is not logically consistent with the context, the most straightforward way is to randomly sample the sentences from different documents. However, this approach could lead to trivial solutions by simply checking whether the entities involved in each option are the same as those in the given context. In the light of this, we resort to directly breaking the logical consistency of the positive instance pair by modifying the relation rather than the entities in the context or the option, to derive the negative instance pair.</p>
<p>In particular, given a positive instance pair (S, a), we devise two negative instance generation methods: the context-oriented and the optionoriented method, focusing on generating negative pairs by modifying the relations involved in the context S and answer a of the positive pair, respectively. Considering that the relation is difficult to be extracted, especially the intra-sentence relation, we propose to implement this reversely via the entity replacement. In particular, for the optionoriented method, suppose that e i , e j is the target entity pair for retrieving the answer a, we first randomly sample a sentence z that contains at least one different entity pair e a , e b from e i , e j as the relation provider. We then obtain the negative option by replacing the entities e a and e b in z with e i and e j , respectively. The operation is equivalent to replacing the relation contained in a with that in z. Formally, we denote the operation as
a − = Relation_Replace(z → a).
Pertaining to the context-oriented negative instance generation method, we first randomly sample a sentence s i ∈ S, and then conduct the modification process as follows,
s − i = Relation_Replace(z → s i ),
where the entity pair to be replaced in s i should be contained in the meta-path corresponding to the target entity pair e i , e j . Accordingly, the negative context can be written as Figure 2 (c) illustrates the above operations on both the answer and context sentence.
S − = S \ {s i } ∪ {s − i }.</p>
<p>Counterfactual Data Augmentation</p>
<p>According to Ko et al. (2020); Guo et al. (2019); Lai et al. (2021); Guo et al. (2022), the neural models are adept at finding a trivial solution through the illusory statistical information in datasets to make correct predictions, which often leads to inferior generalization. In fact, this issue can also occur in our scenario. In particular, since the correct answer is from a natural sentence and describes a real world fact, while the negative option is synthesized by entity replacement, which may conflict with the commonsense knowledge. As a result, the pretrained language model tends to identify the correct option directly by judging its factuality rather than the logical consistency with the given context. For example, as shown in Figure 2 (d) (left), the language model deems a as correct, simply due to that the other synthetic option a − conflicts with the world knowledge.</p>
<p>To overcome this problem, we develop a simple yet effective counterfactual data augmentation method to further improve the capability of logical reasoning (Zeng et al., 2020b). Specifically, given the entities P that are involved in the metapath, we randomly select some entities from P and replace their occurrences in the context and the answer of the positive instance pair (S, a) with the entities extracted from other documents. In this manner, the positive instance also contradicts to the world knowledge. Notably, considering that the positive and negative instance pairs should keep the same set of entities, we also conduct the same replacement for a − or S − , if they mention the selected entities. As illustrated in Figure 2 </p>
<p>Contrastive Learning based Pre-training</p>
<p>As discussed in previous subsection, there are two contrastive learning schemes: option-oriented CL and context-oriented CL. Let A − be the set of all constructed negative options with respect to the correct option a. The option-oriented CL can be formulated as:
L OCL = L(S, a, A − ).(5)
In addition, given C − as the set of all generated negative contexts corresponding to S, the objective of context-oriented CL can be written as:
L CCL = L(a, S, C − ).(6)
To avoid the catastrophic forgetting problem, we also add the MLM objective during pre-training and the final loss is:
L = L OCL + L CCL + L MLM .(7)</p>
<p>Fine-tuning</p>
<p>During the fine-tuning stage, to approach the task of MCQA, we adopt the following loss function:
L QA = − log exp f (P, Q, O y ) i exp f (P, Q, O i ) ,(8)
where O y is the ground-truth option for the question Q, given the passage P . Figure 3 shows the overall training scheme of our method. f is the model to be optimized, θ, ω 0 , ω 1 and φ are parameters of different modules. During pre-training, we use a 2-layer MLP as the output layer. The parameters of the output layer are denoted as ω 0 , and θ represents the pre-trained Transformer parameters. As for the fine-tuning stage, we employ two schemes. For simple fine-tuning, we follow Devlin et al. (2019) to add another 2layer MLP with randomly initialized parameters ω 1 on the top of the pre-trained Transformer. In addition, to fully take advantage the knowledge acquired during pre-training stage, we choose to directly fine-tune the pre-trained output layer with optimizing both θ and ω 0 . In order to address the discrepancy that the question is absent during pretraining, the prompt-tuning technique (Lester et al., 2021) is employed. Specifically, some learnable embeddings with randomly initialized parameters φ are appended to the input to transform the question in downstream tasks into declarative constraint. </p>
<p>Model / Dataset</p>
<p>Experiment</p>
<p>Dataset and Baseline</p>
<p>We evaluated our method on two challenging logical reasoning benchmarks, i.e., LogiQA and Re-Clor, with several strong baselines, including the pre-trained language models, DAGN , Focal Reasoner (Ouyang et al., 2021) and LReasoner (Wang et al., 2022). For more details, please refer to Appendix B.</p>
<p>Implementation Detail</p>
<p>We further pre-trained RoBERTa and ALBERT on Wikipedia for another 500 and 100 steps, respectively, and the batch size for pre-training is set to 4,096. All experiments conducted on downstream tasks are repeated for 5 times with different random seeds. The knowledge graph we used for constructing training data is provided by Qin et al. (2021). More implementation details can be found in Appendix C.</p>
<p>6 Result and Analysis</p>
<p>Overall Results</p>
<p>The overall results on ReClor and LogiQA are shown in Table 1. It can be observed that 1) MERIt outperforms all the strong baselines using the same backbone with significant improvements. Besides, our method achieves the new state-of-theart performance on both datasets. 2) Our method leads to drastic contribution to the original models without further pre-training, i.e., RoBERTa and ALBERT, and the prompt-tuning further enhances our model with a significant performance margin, which both demonstrate the potential of our pretraining method. 3) MERIt achieves better performance on the more difficult split of ReClor (Test-H), indicating that our pre-training method is less affected by the statistical shortcut (Yu et al., 2020). 4) MERIt + Prompt does not benefit from the framework of LReasoner significantly. This is probably because the basic knowledge about logic rules has been covered in our method. 5) We also report the best result on the test set on LogiQA and ReClor for fair comparison with the published results of LReasoner. It can be observed that in terms of the best accuracy on the test set, our model still outperforms LReasoner consistently based on both RoBERTa and ALBERT. Table 2 shows the results of our ablation studies. To observe the impacts brought by the meta-path strategy, we built a baseline model without the metapath strategy by randomly selecting the sentences in a passage to form the context-answer pairs. From this table we can conclude that: 1) the model without counterfactual data augmentation (-DA) has a severe performance degradation. It suggests that the counterfactual data is essential for MERIt to conduct logical reasoning. As for the  Table 2: Performance comparisons on ReClor between different variants of MERIt. DA means data augmentation and DA N refers to 1:N ratio of the original data to the augmented data. P. is short for Prompt Tuning. ratio of original data to the counterfactual one, on test set, we found that 1:3 (+ DA 3 ) leads to better performance using prompt tuning while 1:2 (+ DA 2 ) obtains the best performance using simple fine-tuning. 2) The model without the guidance of meta-path (-Meta-Path) demonstrates a much worse performance than MERIt, indicating that the meta-path strategy plays an important role by discovering the potential logic structure. 3) Considering the results of models without the objectives of option-oriented CL and context-oriented CL, it can be seen that both contrastive learning schemes are beneficial for logical reasoning. In addition, the context-oriented CL is more effective than optionoriented CL. One possible reason to this is that the context-oriented CL is more diverse in format since each sentence can be disturbed while the optionoriented CL will make the model pay more attention to the option, leading to a worse generalization during fine-tuning. Figure 4 shows the accuracy on the test set and test-H set of ReClor with respect to different amount of training data. We reported the average results of MERIt + Prompt, LReasoenr and RoBERTa. It can be observed that: 1) With the scale of training data becoming larger, the performance of all models Pre-training Steps Figure 5: The prompt-tuning results on ReClor using the models pre-trained with different steps.</p>
<p>Ablation Study</p>
<p>Performance with Limited Training Data</p>
<p>Model</p>
<p>Dev Test RoBERTa 84.9 84.2 + MERIt 85.9 85.5 In addition, on test-H, our method outperforms RoBERTa and LReasoner trained on full dataset using only 20% and 40% training data, respectively, evidently demonstrating the generalization capability of our method. 3) Further improvements to LReasoner become insignificant when consuming more training data. This suggests that the basic logic rules can be easily fitted.</p>
<p>Effect of Pre-training Steps</p>
<p>In order to explore the effects of pre-training steps, we fine-tuned the models pre-trained for different steps on ReClor and the results are shown in Figure 5. From the histogram we can find that our method achieves the best performance on dev set at 500 steps. Besides, the model pre-trained with 100 steps (using only around 410k samples) has achieved comparable performance with the best one, indicating that our method is very competitive with few training iterations.</p>
<p>Performance on DREAM</p>
<p>We also evaluated our method on another benchmark requiring complex reasoning abilities, DREAM (Sun et al., 2019), to verify its generalization ability to different tasks. As shown in Table 3, our method can also make significant improvements compared with RoBERTa, demonstrating the generalization ability of our method.  6.6 Results of DeBERTa Table 4 shows the results of DeBERTa-v2-xlarge and DeBERTa-v2-xxlarge on ReClor, which validate that our method can be scaled to stronger pre-trained language models with significant improvements.</p>
<p>Conclusion and Future Work</p>
<p>In this paper, we present MERIt, a meta-path guided contrastive learning method to facilitate logical reasoning via self-supervised pre-training. MERIt is built upon the meta-path strategy for automatic data construction and the counterfactual data augmentation to eliminate the information shortcut during pre-training. With the evaluation on two logical reasoning benchmarks, our method has obtained significant improvements over strong baselines relying on task-specific model architecture or augmentation of original dataset. Pertaining to the further work, we plan to strengthen our method from both data construction and model architecture design angles. More challenging instances are expected to be constructed if multiple meta-paths can be considered at the same time. Besides, leveraging GNNs may bring better interpretability and generalization since the graph structure can be integrated into both pre-training and fine-tuning stages.</p>
<p>A DFS-based Algorithm for Meta-Path Extraction</p>
<p>Algorithm 1 The DFS algorithm to obtain the meta-paths.</p>
<p>Input: The graph G = (E, V); The sentences of the document D = {s 1 , · · · , s m }; The entity set of the i-th sentence V i ; Output: P, S, and A + ; 1: for each (e i , e j ) ∈ V × V and i = j do 2: ReClor (Yu et al., 2020) is extracted from logical reasoning questions of standardized graduate admission examinations. The held-out test set is further divided into EASY and HARD subsets, denoted as test-E and test-H, respectively. The instances in test-E are biased and can be solved even without knowing contexts and questions by neu-ral models. A leaderboard 4 is also host for public evaluation.
A + = {s k |e i ∈ V k , e j ∈ V
LogiQA (Liu et al., 2020) consists of 8,678 multiple-choice questions collected from National Civil Servants Examinations of China and are manually translated into English by experts. The dataset is randomly split into train/dev/test sets with 7,376/651/651 samples, respectively. LogiQA contains various logical reasoning types, e.g., categorical reasoning and sufficient conditional reasoning.</p>
<p>B.2 Baseline</p>
<p>DAGN ) is a discourse-aware graph network that reasons on the discourse structure of texts. It is based on elementary discourse units and discourse relations. DAGN (Aug) is a variant that augments the graph features. Focal Reasoner (Ouyang et al., 2021) is a factdriven logical reasoning model, which builds supergraphs on the top of fact units as the basis for logical reasoning. It captures both global connections between facts and the local concepts or actions inside the fact. LReasoner (Wang et al., 2022) includes a context extension framework and a data augmentation algorithm, which are all conducted based on the extracted logical expressions. This method has achieved new state-of-the-art performance on Re-Clor recently.</p>
<p>Besides, we also compare the performance with the directly fine-tuned large pre-trained language models, including RoBERTa and ALBERT.</p>
<p>C Implementation Detail</p>
<p>C.1 Data Construction</p>
<p>During the data construction process, we have employed two tricks to improve the complexity of the pretext task:</p>
<ol>
<li>
<p>For the sentence z as the relation provider for negative instance construction, the sentences from the document are primarily to be considered because they share the same entities with the context or describe the same topic. This can also be viewed as a trick to avoid trivial solution by checking whether the samples come from the same domain. Another problem is that if z comes from the same document, taking the option-oriented method as  example, the replacement may not work if e i = e a and e j = e b . To address it, we will change the order of the entities to be replaced, i.e., swapping the mentions of e i and e j .</p>
</li>
<li>
<p>Similarly, for counterfactual data augmentation, supposing the extracted meth-path of a training instance connects an entity pair e i , e j , e i and e j are always considered to be replaced for generating counterfactual data. And thus the sets of answer candidates A + constructed from other documents, where the corresponding meta-paths also link e i , e j , can be employed as negative candidates directly. The motivation of the trick is to avoid modifications on the original texts as many as possible.</p>
</li>
</ol>
<p>C.2 Pre-training Setting</p>
<p>We employed the model implementation of Transformer from Huggingface (Wolf et al., 2020) and pytorch 5 framework. The corpus for pre-training is generated from the dataset provided by Qin et al. (2021) 6 , which includes the pre-processed passages from Wikipedia and the recognized entities with their distantly annotated relations. The generated corpus contains one million samples and each sample has 3 negative options.</p>
<p>During pre-training, we adopted the LAMB (You et al., 2020) optimizer, warming up the learning rate to the peak and then linearly decaying it. It takes 32 hours on 4 RTX 2080Ti GPUs for RoBERTa pre-training and 3 days on 2 TeslaT4 GPUs for ALBERT pre-training. Other hyperparameters for pre-training are reported in Table 5.  </p>
<p>C.3 Hyper-parameters for Fine-tuning</p>
<p>The random seeds we utilized for repeated experiments are 42, 43, 44, 45 and 4321. The hyperparameters for fine-tuning are shown in Table 7.  Table 6 shows the results of linear probing on Re-Clor, where we used a single linear layer as the output layer and only fine-tuned its parameters. As shown in the table, MERIt (100 steps) and MERIt (ALBERT) outperform RoBERTa and AL-BERT on both dev and test set, respectively.</p>
<p>D Case Study for Generated Examples</p>
<p>E Results for Linear Probing</p>
<p>F A Different View from Contrastive Graph Representation Learning</p>
<p>To understand why the pre-training approach can promote logical reasoning, we provide a different view from the contrastive learning for graphs. Following Qiu et al. (2020), x and x + in Equation 1 are different sub-graphs extracted from the same graph through random walk with restart (Tong et al., 2006) while x − is sub-graph sampled from a different graph. To avoid the trivial solution by simply checking whether the node indices of two subgraphs match, they also developed an anonymization operation by relabeling the nodes of each subgraph. In fact, our proposed method can be taken as a special case of graph contrastive learning. Firstly, the context and answer based on the meta-path can be viewed as sub-graphs of G. In particular, the answer is the sub-graph with only two nodes (the two entities connected by the meta-path). Secondly, the entity replacement for negative candi-dates construction and counterfactual data generation play similar roles with the anonymization operation. Both of them aim at guiding the model focus on the logical/graph structure. The only assumption our approach built upon is that inferring the consistency defined in Equation 4 is in demand of logical reasoning, which has already been explored in many studies for document-level relation extraction (Zeng et al., 2021(Zeng et al., , 2020a.   </p>
<p>ALBERT</p>
<p>−
( ) "Mirror Mask ( 1 )", McKean ( 2 )'s first feature film as director, premiered at … in January 2005. ( ) The screenplay was written by Neil Gaiman ( 3 ), from a story by Gaiman and McKean. ( 3 ) A children's fantasy …, "Mirror Mask" was produced by Jim Henson Studios ( 4 ) and stars a British cast Stephanie Leonidas ( 5 ), … and Gina McKee ( 6 ). ( 4 ) Before "Mirror Mask", McKean directed a number of …. ( 5 ) McKean has directed "The Gospel of Us ( 7 )", …. A new feature film, "Luna", written and directed by McKean and starring Stephanie Leonidas, ..., debuted at ….</p>
<p>(d) (right), a counterfactual instance can be generated by replacing Mirror Mask and Stephanie Leonidas in a and a − with [ENT A] and [ENT B], where [ENT A] and [ENT B] are arbitrary entities. Ultimately, the key to infer the correct answer lies in the accurate inference of the logical relation between entities [ENT A] and [ENT B] implied in each context-option pair. We provide more cases of the constructed data and their corresponding counterfactual samples in Appendix D.</p>
<p>Figure 3 :
3The overall training scheme of our method.</p>
<p>Figure 4 :
4Results on the test set (left) and the test-H set (right) of ReClor.</p>
<p>(e i , {e i }, ∅, e j , G, D ); 5: if cond is TRUE and A + is not ∅ then function DFS(e i , P , S , e d , G = (E, V)each (e j , s k ) ∈ V × D and (e i , e j ) ∈ E, e j ∈ V k do 16: G = (E, V \ {e j }); DFS(e j , P , S , e d , G ,</p>
<p>Figure 6
6shows the constructed examples for contrastive learning as well as the corresponding counterfactual examples.</p>
<p>Figure 6 :
6Two cases of the generated and the counterfactual examples. The target entities used for extracting meta-path are colored in red.</p>
<p>Table 1: The overall results on ReClor and LogiQA. We adopt the accuracy as the evaluation metric and all the baselines are based on RoBERTa except specific statement. For each model we repeated training for 5 times using different random seeds and reported the average results. ‡ : The results are reproduced by ourselves. max: The results of the model achieving the best accuracy on the test set.ReClor 
LogiQA 
Dev 
Test 
Test-E 
Test-H 
Dev 
Test 
RoBERTa 
62.6 
55.6 
75.5 
40.0 
35.0 
35.3 
DAGN 
65.2 
58.2 
76.1 
44.1 
35.5 
38.7 
DAGN (Aug) 
65.8 
58.3 
75.9 
44.5 
36.9 
39.3 
LReasoner (RoBERTa)  ‡ 
64.7 
58.3 
77.6 
43.1 
-
-
Focal Reasoner 
66.8 
58.9 
77.1 
44.6 
41.0 
40.3 
MERIt 
66.8 
59.6 
78.1 
45.2 
40.0 
38.9 
MERIt + LReasoner 
67.4 
60.4 
78.5 
46.2 
-
-
MERIt + Prompt 
69.4 
61.6 
79.3 
47.8 
39.9 
40.7 
MERIt + Prompt + LReasoner 
67.3 
61.4 
79.8 
46.9 
-
-
ALBERT 
69.1 
66.5 
76.7 
58.4 
38.9 
37.6 
MERIt (ALBERT) 
74.2 
70.1 
81.6 
61.0 
43.7 
42.5 
MERIt (ALBERT) + Prompt 
74.7 
70.5 
82.5 
61.1 
46.1 
41.7 
max 
LReasoner (RoBERTa) 
66.2 
62.4 
81.4 
47.5 
38.1 
40.6 
MERIt 
67.8 
60.7 
79.6 
45.9 
42.4 
41.5 
MERIt + Prompt 
70.2 
62.6 
80.5 
48.5 
39.5 
42.4 
LReasoner (ALBERT) 
73.2 
70.7 
81.1 
62.5 
41.6 
41.2 
MERIt (ALBERT) 
73.2 
71.1 
83.6 
61.3 
43.9 
45.3 
MERIt (ALBERT) + Prompt 
75.0 
72.2 
82.5 
64.1 
45.8 
43.8 </p>
<p>Table 3 :
3The accuracy of different models on DREAM 
dataset. </p>
<p>achieves improvements. 2) MERIt + Prompt shows 
better performance under low resource, especially 
on test-H. Our method trained on 40% data has 
achieved comparable performance with RoBERTa. </p>
<p>Table 4 :
4Results on ReClor with DeBERTa as the backbone.</p>
<p>Table 5 :
5Hyper-parameters for ALBERT and RoBERTa during pre-training, respectively.</p>
<p>Table 6 :
6Results of Linear Probing on ReClor.</p>
<p>Table 7 :
7Hyper-parameters for fine-tuning on ReClor and LogiQA. ♣: Fine-Tuning. ♠: Prompt Tuning.
In this paper, we refer ALBERT-xxlarge and RoBERTalarge to ALBERT and RoBERTa for simplicity, respectively.
https://eval.ai/web/challenges/ challenge-page/503/leaderboard/1347.
https://pytorch.org. 6 https://github.com/thunlp/ERICA.
AcknowledgementsWe sincerely appreciate the valuable comments from all the reviewers to help us make the paper polished. We also greatly thank to Liqiang Jing and Harry Cheng for their kind suggestions. This work is supported by the National Natural Science Foundation of China, No.:U1936203; the Shandong Provincial Natural Science Foundation, No.:ZR2019JQ23; and Young creative team in universities of Shandong Province, No.:2020KJN012.
Critical thinking for language models. Gregor Betz, Christian Voigt, Kyle Richardson, IWCS. ACLGregor Betz, Christian Voigt, and Kyle Richardson. 2021. Critical thinking for language models. In IWCS, pages 63-75. ACL.</p>
<p>Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, NeurIPS. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mc-Candlish, Alec Radford, Ilya Sutskeverand Dario Amodei. 2020. Language models are few-shot learnersTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mc- Candlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learn- ers. In NeurIPS.</p>
<p>Transformers as soft reasoners over language. Peter Clark, Oyvind Tafjord, Kyle Richardson, 10.24963/ijcai.2020/537IJCAI. Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over language. In IJCAI, pages 3882-3890.</p>
<p>ReasonBERT: Pre-trained to reason with distant supervision. Xiang Deng, Yu Su, Alyssa Lees, You Wu, Cong Yu, Huan Sun, EMNLP. ACLXiang Deng, Yu Su, Alyssa Lees, You Wu, Cong Yu, and Huan Sun. 2021. ReasonBERT: Pre-trained to reason with distant supervision. In EMNLP. ACL.</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/n19-1423NAACL-HLT. ACLJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language under- standing. In NAACL-HLT, pages 4171-4186. ACL.</p>
<p>SimCSE: Simple contrastive learning of sentence embeddings. Tianyu Gao, Xingcheng Yao, Danqi Chen, EMNLP. ACLTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. SimCSE: Simple contrastive learning of sentence embeddings. In EMNLP. ACL.</p>
<p>Quantifying and alleviating the language prior problem in visual question answering. Yangyang Guo, Zhiyong Cheng, Liqiang Nie, Yibing Liu, Yinglong Wang, Mohan S Kankanhalli, SIGIR. ACMYangyang Guo, Zhiyong Cheng, Liqiang Nie, Yibing Liu, Yinglong Wang, and Mohan S. Kankanhalli. 2019. Quantifying and alleviating the language prior problem in visual question answering. In SIGIR, pages 75-84. ACM.</p>
<p>Loss re-scaling VQA: revisiting the language prior problem from a classimbalance view. Yangyang Guo, Liqiang Nie, Zhiyong Cheng, Qi Tian, Min Zhang, TIP. 31Yangyang Guo, Liqiang Nie, Zhiyong Cheng, Qi Tian, and Min Zhang. 2022. Loss re-scaling VQA: re- visiting the language prior problem from a class- imbalance view. TIP, 31:227-238.</p>
<p>Retrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang, PMLRICML. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pa- supat, and Ming-Wei Chang. 2020. Retrieval aug- mented language model pre-training. In ICML, pages 3929-3938. PMLR.</p>
<p>Dimensionality reduction by learning an invariant mapping. Raia Hadsell, Sumit Chopra, Yann Lecun, 10.1109/CVPR.2006.100CVPR. IEEERaia Hadsell, Sumit Chopra, and Yann LeCun. 2006. Dimensionality reduction by learning an invariant mapping. In CVPR, pages 1735-1742. IEEE.</p>
<p>DAGN: discourse-aware graph network for logical reasoning. Yinya Huang, Meng Fang, Yu Cao, Liwei Wang, Xiaodan Liang, 10.18653/v1/2021.naacl-main.467NAACL-HLT. ACLYinya Huang, Meng Fang, Yu Cao, Liwei Wang, and Xiaodan Liang. 2021. DAGN: discourse-aware graph network for logical reasoning. In NAACL- HLT, pages 5848-5855. ACL.</p>
<p>Rept: Bridging language models and machine reading comprehension via retrieval-based pre-training. Fangkai Jiao, Yangyang Guo, Yilin Niu, Feng Ji, Feng-Lin Li, Liqiang Nie, Findings of ACL-IJCNLP. ACLFangkai Jiao, Yangyang Guo, Yilin Niu, Feng Ji, Feng- Lin Li, and Liqiang Nie. 2021. Rept: Bridging lan- guage models and machine reading comprehension via retrieval-based pre-training. In Findings of ACL- IJCNLP, pages 150-163. ACL.</p>
<p>Look at the first sentence: Position bias in question answering. Miyoung Ko, Jinhyuk Lee, Hyunjae Kim, Gangwoo Kim, Jaewoo Kang, 10.18653/v1/2020.emnlp-main.84EMNLP. ACLMiyoung Ko, Jinhyuk Lee, Hyunjae Kim, Gangwoo Kim, and Jaewoo Kang. 2020. Look at the first sentence: Position bias in question answering. In EMNLP, pages 1109-1121. ACL.</p>
<p>Why machine reading comprehension models learn shortcuts. Yuxuan Lai, Chen Zhang, Yansong Feng, Quzhe Huang, Dongyan Zhao, 10.18653/v1/2021.findings-acl.85Findings of ACL/IJCNLP. ACLYuxuan Lai, Chen Zhang, Yansong Feng, Quzhe Huang, and Dongyan Zhao. 2021. Why machine reading comprehension models learn shortcuts? In Findings of ACL/IJCNLP, pages 989-1002. ACL.</p>
<p>ALBERT: A lite BERT for self-supervised learning of language representations. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut, ICLR. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020. ALBERT: A lite BERT for self-supervised learning of language representations. In ICLR.</p>
<p>The power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, EMNLP. ACLBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In EMNLP. ACL.</p>
<p>LogiQA: A challenge dataset for machine reading comprehension with logical reasoning. Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, Yue Zhang, 10.24963/ijcai.2020/501IJCAI. Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2020. LogiQA: A chal- lenge dataset for machine reading comprehension with logical reasoning. In IJCAI, pages 3622-3628.</p>
<p>Roberta: A robustly optimized BERT pretraining approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, abs/1907.11692CoRRYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized BERT pretraining ap- proach. CoRR, abs/1907.11692.</p>
<p>Martin Ringsquandl, Rime Raissouni, and Volker Tresp. 2021. Neural multi-hop reasoning with logical rules on biomedical knowledge graphs. Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, ESWC. Springer12731Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, Mar- tin Ringsquandl, Rime Raissouni, and Volker Tresp. 2021. Neural multi-hop reasoning with logical rules on biomedical knowledge graphs. In ESWC, volume 12731, pages 375-391. Springer.</p>
<p>Fact-driven logical reasoning. Siru Ouyang, Zhuosheng Zhang, Hai Zhao, abs/2105.10334CoRRSiru Ouyang, Zhuosheng Zhang, and Hai Zhao. 2021. Fact-driven logical reasoning. CoRR, abs/2105.10334.</p>
<p>ERICA: improving entity and relation understanding for pre-trained language models via contrastive learning. Yujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu, Peng Li, Heng Ji, Minlie Huang, Maosong Sun, Jie Zhou, 10.18653/v1/2021.acl-long.260ACL/IJCNLP. ACLYujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu, Peng Li, Heng Ji, Minlie Huang, Maosong Sun, and Jie Zhou. 2021. ERICA: improving entity and re- lation understanding for pre-trained language mod- els via contrastive learning. In ACL/IJCNLP, pages 3350-3363. ACL.</p>
<p>GCC: graph contrastive coding for graph neural network pre-training. Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, Jie Tang, 10.1145/3394486.3403168KDD. ACMJiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, and Jie Tang. 2020. GCC: graph contrastive coding for graph neural network pre-training. In KDD, pages 1150-1160. ACM.</p>
<p>Dropout: a simple way to prevent neural networks from overfitting. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov, Journal of Machine Learning Research. 151Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- nov. 2014. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929-1958.</p>
<p>DREAM: A challenge dataset and models for dialogue-based reading comprehension. Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, Claire Cardie, TACL. 7Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, and Claire Cardie. 2019. DREAM: A challenge dataset and models for dialogue-based reading com- prehension. TACL, 7:217-231.</p>
<p>Depth-first search and linear graph algorithms. Robert Endre Tarjan, 10.1137/0201010SIAM Journal on Computing. 12Robert Endre Tarjan. 1972. Depth-first search and lin- ear graph algorithms. SIAM Journal on Computing, 1(2):146-160.</p>
<p>Fast random walk with restart and its applications. Hanghang Tong, Christos Faloutsos, Jia-Yu Pan, 10.1109/ICDM.2006.70ICDM. IEEEHanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its appli- cations. In ICDM, pages 613-622. IEEE.</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, NeurIPS. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS, pages 5998-6008.</p>
<p>Logic-driven context extension and data augmentation for logical reasoning of text. Siyuan Wang, Wanjun Zhong, Duyu Tang, Zhongyu Wei, Zhihao Fan, Daxin Jiang, Ming Zhou, Nan Duan, Findings of ACL. ACL. Siyuan Wang, Wanjun Zhong, Duyu Tang, Zhongyu Wei, Zhihao Fan, Daxin Jiang, Ming Zhou, and Nan Duan. 2022. Logic-driven context extension and data augmentation for logical reasoning of text. In Findings of ACL. ACL.</p>
<p>Transformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Le Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander M Lhoest, Rush, EMNLP: System Demonstrations. ACLThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, Rémi Louf, Morgan Funtow- icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers: State-of-the-art natural language pro- cessing. In EMNLP: System Demonstrations, pages 38-45. ACL.</p>
<p>Discriminative reasoning for document-level relation extraction. Wang Xu, Kehai Chen, Tiejun Zhao, 10.18653/v1/2021.findings-acl.144Findings of ACL/IJCNLP. ACLWang Xu, Kehai Chen, and Tiejun Zhao. 2021. Dis- criminative reasoning for document-level relation extraction. In Findings of ACL/IJCNLP, pages 1653-1663. ACL.</p>
<p>Large batch optimization for deep learning: Training BERT in 76 minutes. Yang You, Jing Li, J Sashank, Jonathan Reddi, Sanjiv Hseu, Srinadh Kumar, Xiaodan Bhojanapalli, James Song, Kurt Demmel, Cho-Jui Keutzer, Hsieh, ICLR. Yang You, Jing Li, Sashank J. Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh. 2020. Large batch optimization for deep learning: Training BERT in 76 minutes. In ICLR.</p>
<p>Reclor: A reading comprehension dataset requiring logical reasoning. Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng, ICLR. Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. Reclor: A reading comprehension dataset requiring logical reasoning. In ICLR.</p>
<p>SIRE: separate intra-and inter-sentential reasoning for document-level relation extraction. Shuang Zeng, Yuting Wu, Baobao Chang, 10.18653/v1/2021.findings-acl.47Findings of ACL/IJCNLP. ACLShuang Zeng, Yuting Wu, and Baobao Chang. 2021. SIRE: separate intra-and inter-sentential reasoning for document-level relation extraction. In Findings of ACL/IJCNLP, pages 524-534. ACL.</p>
<p>Double graph based reasoning for documentlevel relation extraction. Shuang Zeng, Runxin Xu, Baobao Chang, Lei Li, 10.18653/v1/2020.emnlp-main.127EMNLP. ACLShuang Zeng, Runxin Xu, Baobao Chang, and Lei Li. 2020a. Double graph based reasoning for document- level relation extraction. In EMNLP, pages 1630- 1640. ACL.</p>
<p>Counterfactual generator: A weaklysupervised method for named entity recognition. Xiangji Zeng, Yunliang Li, Yuchen Zhai, Yin Zhang, 10.18653/v1/2020.emnlp-main.590EMNLP. ACLXiangji Zeng, Yunliang Li, Yuchen Zhai, and Yin Zhang. 2020b. Counterfactual generator: A weakly- supervised method for named entity recognition. In EMNLP, pages 7270-7280. ACL.</p>            </div>
        </div>

    </div>
</body>
</html>