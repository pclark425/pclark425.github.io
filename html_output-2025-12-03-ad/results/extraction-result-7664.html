<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7664 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7664</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7664</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‑tuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-257050407</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2302.10724v4.pdf" target="_blank">ChatGPT: Jack of all trades, master of none</a></p>
                <p><strong>Paper Abstract:</strong> WeautomatedChatGPTandGPT-4promptingprocessandanalyzedmorethan49k responses.OurcomparisonofitsresultswithavailableState-of-the-Art(SOTA)solutionsshowedthattheaveragelossinqualityoftheChatGPTmodelwasabout25%forzero-shotandfew-shotevaluation. ForGPT-4model,alossforsemantictasksissignificantlylowerthanforChatGPT.Weshowedthatthemoredifficultthetask(lowerSOTAperformance),thehighertheChatGPTloss.Itespecially referstopragmaticNLPproblemslikeemotionrecognition.WealsotestedtheabilitytopersonalizeChatGPTresponsesforselectedsubjectivetasksviaRandomContextualFew-ShotPersonalization, andweobtainedsignificantlybetteruser-basedpredictions.AdditionalqualitativeanalysisrevealedaChatGPTbias,mostlikelyduetotherulesimposedonhumantrainersbyOpenAI.Ourresultsprovide thebasisforafundamentaldiscussionofwhetherthehighqualityofrecentpredictiveNLPmodelscanindicateatool’susefulnesstosocietyandhowthelearningandvalidationproceduresforsuch systemsshouldbeestablished.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7664",
    "paper_id": "paper-257050407",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.01390225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ChatGPT: Jack of all trades, master of none</p>
<p>Jan Kocoń 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Igor Cichecki 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Oliwier Kaszyca 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Mateusz Kochanek 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Dominika Szydło 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Joanna Baran 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Julita Bielaniewicz 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Marcin Gruza 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Arkadiusz Janz 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Kamil Kanclerz 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Anna Kocoń 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Bartłomiej Koptyra 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Wiktoria Mieleszczenko-Kowszewicz 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Piotr Miłkowski 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Marcin Oleksy 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Maciej Piasecki 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Łukasz Radliński 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Konrad Wojtasik 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Stanisław Woźniak 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>Przemysław Kazienko 
Department of Artificial Intelligence
University of Science and Technology
Wyb. Wyspiańskiego 2750-370WrocławPoland</p>
<p>ChatGPT: Jack of all trades, master of none</p>
<p>A R T I C L E I N F OKeywords:ChatGPT GPT-4 Natural Language Processing (NLP) semantic NLP tasks pragmatic NLP tasks subjective NLP tasks Natural Language Inference (NLI) sentiment analysis offensive content emotion recognition humor detection stance detection word sense disambiguation (WSD) question answering (QA) model personalization text classification SOTA analysis large language model prompting A B S T R A C T OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established.</p>
<p>Introduction</p>
<p>In recent years, Transformer-type model architecture has dominated the world of natural language processing (NLP) [1,2,3]. Before that, recurrent neural networks, such as LSTMs, were used to solve a wide variety of existing NLP problems [4,5,6]. The recurrent neural models could not capture distant dependencies in data sequences, for example, information occurring at the text beginning or end [7]. In addition, their architecture did not allow for efficient parallelization of training and inference processes [8]. The answer to the aforementioned problems was precisely the Transformer architecture, presented initially as an encoderdecoder model for sequence-to-sequence tasks [1]. Such a model had the advantage of capturing distant relationships in the text using an attentional mechanism and easily parallelizing calculations with matrix operations. As more powerful GPUs and TPUs were developed [9], it became possible to create models with more and more parameters, resulting in models that began to achieve human performance for an increasing number of tasks [10,11,12]. However, the most significant quality improvement was achieved by unsupervised pre-training language models on a huge number of texts acquired from the Internet. In BERT-based models, the pre-training tasks involved foreseeing masked tokens and subsequent sentences [13]. In autoregressive models, the pre-training task has been changed to predicting the next word, which masks the attentional layer so that the model forecasts future values based only on past values [14].</p>
<p>Generative Pre-Training (GPT [15]) was one of the first autoregressive generative models based on the Transformer architecture. From the original Transformer, only the decoder stack is used by GPT, and bi-directional self-attention is converted to uni-directional. Such a model can perform all tasks based on generating new text, such as translation, summarization, or answering questions. In GPT-2, an extension of this concept, several technical improvements were made that eliminated the transferability problem for fine-tuning the models to downstream tasks and introduced multi-task training [16]. In addition, the input context length was doubled (from 512 to 1024), and the data for pre-training increased to 40GB, but the total number of model parameters soared from 117M (GPT) to 1.5B (GPT-2). As a result, GPT-2 showed the ability to solve many new tasks without the need for supervised training on large data. Two factors mainly distinguished the succeeding GPT-3 model: the number of model parameters increased to 175B, and 45TB text data was used for pre-training. This model provided outstanding results, especially in zero-shot and few-shot scenarios [17].</p>
<p>A further step towards matching the model's responses to human needs was creating the InstructGPT model [18]. Its main innovation focused on alternative model fine-tuning methods, particularly Reinforcement Learning from Human Feedback (RLHF). This solution uses human feedback as a reward signal for updating model parameters. OpenAI recruited 40 annotators with high levels of agreement in sensitive speech flagging, ranking model answers by quality, sensitive demonstration writing, and the ability to identify sensitive speech for different groups. Their task was to describe what kind of answer is expected for different prompts, and the next GPT-3 finetuning followed this input. In the second step, the subjects created a ranking of several responses of the system based on the given prompt to train a reward model. In the third step, reinforcement learning using proximal policy optimization (PPO) was applied to improve the model quality further. As a result, users strongly preferred the InstructGPT responses compared to GPT-3. One of the conclusions from this work was that model quality on publicly available NLP benchmark datasets is worse than for SOTA models. However, InstructGPT authors found that benchmark NLP tasks do not reflect what most people may really expect from the language models [18]. Only 18% of users using the OpenAI API queried GPT-3 model with tasks familiar to typical NLP tasks, most of which are analytical. On the other hand, only a small fraction of popular NLP datasets have been used to evaluate InstructGPT [18].</p>
<p>One of the latest iterations of InstructGPT is the Chat-GPT model (Fig. 2), which most likely exploited even more users' feedback on a greater variety of tasks 1 . At the moment, little information on the construction of this model is available, but the excellent quality of the system has resulted in its massive popularity (Fig. 1). Interestingly, the base model in InstructGPT is a model that has only 3.5B parameters [18]. Yet, in conversation tasks, it provides answers better than the GPT3 model, with 175B parameters. This shows the high relevance of collecting data from humans for supervised model fine-tuning [18]. ChatGPT's successor, the GPT-4 [19], is most likely an even larger model that can additionally receive not only text but also images as input.</p>
<p>In this work, we propose a new approach to testing a prompt-based model, ChatGPT, on various NLP tasks. We focus on evaluating the ChatGPT tool for 25 public NLP datasets, a large part of which involved subjective problems and for which there is a high probability that ChatGPT could be wrong. This intuition is based on the fact that OpenAI developers chose human annotators based on their high agreement rate [18]. At the same time, it is difficult to identify universal ground truth in tasks such as predicting emotions or offensiveness of text, especially in the personalized context [20,21,22]. It is very likely that the ChatGPT model has not been trained on most of the datasets that we test in our work, because for all of these datasets, we observe a significant drop in quality relative to state-of-the-art models. This allows us to assess its quality in various personalized NLP tasks. When it comes to the analysis and processing of the answers of the general majority, it is not difficult to retrieve information about the correlations and relationships between each task, however, grasping the preferences of each person individually is a much more demanding task, especially when analyzing the correlation between tasks in a personalized perspective. We have managed to successfully process our prompts, including ones that consisted of 3 annotated texts and one that had been later annotated by ChatGPT positively or negatively according to the already annotated texts. Those prompts were especially interesting, as ChatGPT was in fact tasked to predict the answer. This implied a certain "preference", which is contradictory to the rule that ChatGPT should not have any emotions, preferences or opinions. The results we have obtained are the beginning of a discussion on whether the models trained on existing NLP tasks respond to people's demands and how to train such models so that they not only respond to the expectations of the majority of the population but also take into account the preferences of minority or outliers.</p>
<p>Language models are prone to generating responses containing human-like biases as well as presenting moral and ethical stances [23]. A number of procedures are created to make sure that these biases will not affect users, such as the European Union's AI Ethics Guidelines or AI Fariness 360. Of all that standards are addressing bias and fostering ethical development of AI systems [24]. Even though the creators of ChatGPT secure the model against answers that are offensive, there are still multiple methods that may reveal its hidden biases.</p>
<p>We wanted to consider some more specific research problems in the area of our research and thus specified 11 research questions that we've successfully managed to find the answers to: Q1: Is ChatGPT loss in performance compared to SOTA different for individual tasks of different kinds, Sec. 6.1 and the same for GPT-4, Sec. 6.7?</p>
<p>Q2: Is there a difference in ChatGPT's ability to solve difficult and easy NLP analytical tasks, Sec. 6.2?</p>
<p>Q3: How much a few-shot approach to personalization (Random Contextual Few-Shot Personalization) can make reasoning more subjective, thus, potentially increasing the overall inference quality, Sec. 6.3?</p>
<p>Q4: What is the impact of the context while processing multiple questions (prompts) that may or may not be related to each other, Sec. 6.4?</p>
<p>Q5: Can we improve the model performance with prompt engineering, i.e. manual fine-tuning, Sec. 6.6?</p>
<p>Q6: Is GPT-4 better or worse compared to ChatGPT, Sec. 6.7?</p>
<p>Q7: Does the public availability of the data and its exploitation for training ChatGPT impact its performance, Sec. 6.5?</p>
<p>Q8: What are necessary post-processing activities that can improve the quality of ChatGPT output for analytical tasks, Sec. 5.2?</p>
<p>Q9: What is the internal policy of ChatGPT providers and its biases making it not to provide adequate responses to some prompts, Sec. 7 This collection of questions was formed after a thorough analysis of the available research and information regarding ChatGPT, which we've included in the section 3.</p>
<p>We have categorized our research into the quantitative analysis (Sec. 6), qualitative analysis (Sec. 7), limitations and discussion (Sec. 8) as well as prospective ChatGPT application domains (Sec. 9).</p>
<p>Related work</p>
<p>Early discourse related to ChatGPT revolves around two main topics -potential usage in expert fields and evaluation of specific tasks or aspects of chat performance. In the first topic, there are many papers suggesting potential benefits and risks of using ChatGPT in education (e.g. [25,26,27]), medicine (e.g. [28]), or even in the creation of legal documents (e.g. [29]). The main concerns about the usage of the chatbot are that it will escalate the issues of plagiarism in many fields (e.g. [25], [30]) and might be used for cheating in academic tests [25]. The latter topic points out the strengths and vulnerabilities of ChatGPT performance. The two topics are strongly related as the main limitation of using the chatbot in expert fields is the reliability of the results. Thus the comprehensive and systematic evaluation is crucial for the proper assessment of the capabilities of ChatGPT. To properly assess the progress in evaluating the chatbot, it is necessary to put the evaluated tasks in order. For this purpose, the taxonomy of the natural processing tasks must be established. There are two main approaches to establishing such a taxonomy. First -relates the tasks directly to the methods used for solving them [31]. While this approach allows for the systematic organization of most tasks, it is not very useful for this paper as the goal is to establish how many tasks can be performed by the same chatbot. The second approach is to organize the tasks first into tasks of analysis and generation and then to divide the first ones into the levels of syntactic, semantic, and pragmatic analysis [32]. Looking at the field through the lens of this taxonomy, the main areas that ChatGPT has been tested so far are generation tasks.</p>
<p>The studies published within few months after the release of ChatGPT focused mostly on one pre-selected task, mainly on question answering (e.g. [33,34,25,28,26,35]) or summarizing (e.g. [36,37,38,39,30]). However, such tasks as humor identification and generation [40], machine translation [41], sentiment recognition [42], paraphrasing [38], and other text generation subtasks were also analyzed [43,44,45]. In most cases, the evaluation was conducted manually. This concerned, in particular open-ended question answering (e.g. [34,26,35] and scientific texts summarization (e.g. [37,39]. This was related to the fact that benchmark datasets did not appear in many studies. If they were included, they were often treated as a basis for manual expert analysis of the ChatGPT answers, e.g. in the case of medical education [34,26]. Another issue connected with the dominant approach concerns the comparison of the NLP toolkits and their performance in solving NLP tasks. Relatively few studies analyzed the differences between diverse toolkits and systems. In cases where the performance of ChatGPT was compared to other solutions (e.g. [26,30,41]), it worked on a comparable level to the competitor but not outperforming any major SOTA solutions.</p>
<p>The most recent studies show a more broad and nuanced approach to evaluating Chat GPT. There were a couple of large-scale evaluations published recently [46,47] and both of them indicate that while the performance of ChatGPT is significant it doesn't outperform the SOTA solutions with the exception of sentiment analysis task in case of [46] which suggests it is a significant area for further research. Both articles give an interesting insight into the strengths and weaknesses of the Chat performance observed during the research. Two more recently published papers that present usage for GPT models in sentiment analysis for Italian [48] and Arabic [49] languages which further shows emotionrelated tasks as a particularly interesting area of NLP tasks to examine when it comes to GPT models.</p>
<p>Simultaneously there were three major studies published that focus on evaluating language models, in general, [50,51,12]. Rather than comparing the performance of the language models to the other solutions, these studies focus on comparing language models with each other. They give a great insight into the capabilities and limitations of many language models and show the progress that LLMs made over the years. Many of the evaluated models are predecessors of the ChatGPT model which makes those studies particularly valuable as a lens through which the capabilities of ChatGPT can be viewed.</p>
<p>The recent increased popularity of large language models such as ChatGPT has brought more attention to the more nuanced aspects of NLP such as AI Ethics. Evaluation of such elements as the bias of the model or its toxicity requires a different approach than the evaluation of the ability of the model to perform particular NLP tasks. Such research has already been conducted to some extent and multiple interesting findings about ethical aspects of ChatGPT's performance in comparison to different large language models can be found in [52].</p>
<p>Another area of performance that was recently evaluated was the robustness of ChatGPT [53]. The research indicates that while ChatGPT is still prone to adversarial attacks it is significantly more robust than its predecessors and other currently available models. Finally, after GPT-4 model was released it quickly showed significant advancement in its capabilities in comparison to previous GPT models [54,55,56]. Most notably it was identified by Michał Kosiński as capable of solving Theory of the Mind tasks [57] which also indicates that sentiment analysis and emotion processing are particularly significant areas of research when it comes to the newest GPT models.</p>
<p>There are many ways to carry out prompting with Chat-GPT. Although the popular trial-and-error method may seem good, utilizing techniques with proven effectiveness is crucial. The model usually understands many ways in which a question might be asked. However, there are also instances where an explanation must be included to receive a proper answer from ChatGPT. In Natural Language Processing, there are multiple interesting prompting methods, many of which are collected and clearly outlined in [58].</p>
<p>Research question</p>
<p>As existing evaluations of ChatGPT focus on its ability to generate language utterances, we want to investigate its analytical skills, particularly in tasks requiring language analysis and understanding, i.e., typical NLP problems examined by science and companies. Therefore, we aim to target two abilities (task categories; see Tab. 1): semantic and pragmatic. Distinguishing semantics from pragmatics, we refer to the classic concept of Morris, who proposed syntactic, semantic, and pragmatic dimensions and levels of semiosis [59]. He states that "semantics deals with the relation of signs to their designate" [59, p. 21], while pragmatics refers to "the science of the relation of signs to their interpreters" [59, p. 30]. This idea has found its application in contemporary pragmatics "is the study of linguistic communication in context: the choices users of language make and the process of meaning-making in social interaction" [60]. The former kind of task entails recognition of text properties (like word sense description or a speaker's stance polarity in a language construction) or mining information that is directly expressed in a text fragment, e.g., various relations between sentences and text fragments, or extraction of the answer to a question). In the pragmatic analysis, we dig into ChatGPT's potential in exploiting general knowledge stored in the model to solve the tasks beyond the literal semantic content of the textual prompt -input. Here, we investigate a range of different pragmatic problems with a common denominator of the necessity to predict the influence of the utterance interpretation on the reader and their often subjective content perception. We asked ChatGPT to predict not only sentiment polarity and emotions evoked in the reader but also humor and offensiveness. Several of these tasks are also stated in a personalized version, in which the outcome depends on a particular reader (interlocutor). Overall, the tasks considered in this paper have relatively structured and simple expected results reflecting typical machine learning solutions, i.e., various types of classification 2 . This, in turn, directly corresponds to the analytical approach: further numerical processing of the outcome. For example, one might want to know how well ChatGPT would perform in evaluating customers' sentiment toward a particular product based on an analysis of multiple online reviews. This requires obtaining accurate polarity (classification) of individual texts assessed by ChatGPT and aggregating decisions to acquire the final ratio of positive and negative opinions.</p>
<p>In all cases, we are interested in the correctness of ChatGPT's analysis and inference, i.e., different forms of understanding of the natural language utterances, while intentionally neglecting the aspect of the quality of the generative results as perceived by the user, as opposed to alternative studies. This means that we do not attempt to quantify how well the user perceives the output text, i.e., the style of generated text or how rich the content is. It has little or no relevance to a reliable evaluation of analytical tasks.</p>
<p>Does ChatGPT perform as well as the best recent models (SOTA) in solving typical NLP analytical tasks?</p>
<p>Tasks</p>
<p>We tested ChatGPT on 25 tasks focusing on solving common NLP problems and requiring analytical reasoning, Tab. 1. These tasks include (1) a relatively simple binary classification of texts like spam, humor, sarcasm, aggression detection, or grammatical correctness of the text; (2) a more complex multiclass and multi-label classification of texts such as sentiment analysis, emotion recognition; (3) reasoning with the personal context, i.e., personalized versions of the problems that make use of additional information about text perception of a given user (user's examples provided to ChatGPT); (4) semantic annotation and acceptance of the text going towards natural language understanding (NLU) like word sense disambiguation (WSD), and (5) answering questions based on the input text.</p>
<p>The tasks were divided into two categories described in Sec. 3: semantic and pragmatic. The latter requires the model to utilize additional knowledge that is not directly captured by distributional semantics [61]. For personalized tasks, the input texts have to be extended with additional personal context (personalized solutions of the problem [20]); see Sec. 6.3. These tasks involve the datasets such as Aggression → AggressionPer, GoEmo → GoEmoPer, and Unhealthy → UnhealthyPer.</p>
<p>Most of the tasks were based on public datasets investigated in the literature. However, we also utilized a collection of new unpublished datasets such as (ClarinEmo), which ChatGPT could not have indexed. Most of the evaluated texts were written in English (23, 92% of the tasks), while two others (8%) were in Polish. The prompts were in line with the language of the input text.</p>
<p>We manually evaluated the probability that a given annotated dataset was available and used by ChatGPT for training. We assigned a rating of highly probable (3) to most of the datasets in this evaluation. Still, for their personalized versions, the rating was reduced to (2) since ChatGPT was almost certainly not trained in personalized settings. In the case of PolEmo -the dataset was unlikely to be used for training and received a score of (1). Finally, we assigned a score (0) to the unpublished version of the ClarinEmo dataset. Additionally, we asked ChatGPT whether or not the dataset was used for training. Based on collected data, we performed appropriate analyses, Sec. 6.5.</p>
<p>Due to the scale of our test data and the limitations of ChatGPT's API, we had to limit the number of input texts. This means that for some tasks, we randomly selected a sample of texts (column #Used) in Tab. 1) from all available instances in the test or dev set (column #Test). In some cases, the outputs from ChatGPT required a manual postprocessing procedure (column #Post-processing), and some responses were out of the desired domain (column #None).</p>
<p>To compare the performance of ChatGPT with SOTA methods, we trained and tested the best available models (or close to the best) by reusing the source code provided with references (column SOTA in Tab. 1). In other cases, we exploited the values of reported quality metrics published in original papers; see column SOTA in Tab. 2. Examples of chats for all the tasks included in our study are available in Appendix B.</p>
<ol>
<li>Aggression. We used the Wikipedia Talk Labels: Aggression dataset [62] collected in the Wikipedia Detox project. It includes over 100k comments acquired from the Table 1 Profile of the tested NLP tasks named according to their resource (dataset). Category : S -semantic, P -pragmatic; Context refers to either additional contextual information added to prompts (e.g. related to a given user -personalization) or to the context directly considered in the task; Availability : our assessment of whether ChatGPT used the dataset for fine-tuning: 3highly probable, 2 -probable, 1 -rather no; 0 -impossible. Trained : ChatGPT answers if it used the dataset for training. #Test: no. of cases available in the test or dev set. #Used : no. of cases from the test or dev set (prompts) used by us. #None: no. of prompts ChatGPT returned 'none'. #Post-processed : no. of prompts requiring manual post-processing. #N: no. of valid prompts used for quality evaluation (Tab. 2). #Classes: no. of distinct classes in the output. #Majority/minority class: the number of examples for the majority/minority classes in the test or dev set (#Test). </li>
</ol>
<p>AggressionPer.</p>
<p>We have also used the personalized variant of the Aggression dataset. In this case, we represented the individual's perspective by providing three userspecific annotations as an addition to the standard input prompt. These additional texts were selected according to their highest controversy, i.e., with the highest standard deviation among the annotator votes. It was inspired by the findings from [21].</p>
<p>CoLa.</p>
<p>The Corpus of Linguistic Acceptability [64] consists of 10 657 sentences from 23 linguistics publications, annotated for acceptability (grammaticality). Here, ChatGPT had to classify whether a sentence was grammatically correct. It was confronted with the metrics from existing work on Few-Shot Learners [65].</p>
<ol>
<li>
<p>ColBERT. The ColBERT dataset [66] contains 200k short texts acquired from news, headlines, Wikipedia, tweets, and jokes. Each sample is annotated as funny or not-funny. The distribution of labels is uniform.</p>
</li>
<li>
<p>Sarcasm. The Sarcasmania dataset [67] consists of 39,780 texts from the Twitter platform. Each tweet is associated with one of the two classes: sarcastic or non-sarcastic.</p>
</li>
<li>
<p>Spam. SMS Spam Collection v.1 [69] is a dataset containing SMS contents labeled as spam or not. Here, ChatGPT had to classify an input text accordingly.</p>
</li>
<li>
<p>WordContext. The task of identifying the intended meaning of a word in a given context -Word in Context task (WIC) [71]. The WIC task is strongly related to the Word Sense Disambiguation task (WSD) as it tests language models' sense understanding abilities. Contrary to WSD, the task is framed as binary classification, testing if two independent contexts express the same meaning of the highlighted word.</p>
</li>
<li>
<p>TextEntail. One of the SuperGLUE benchmark [73] tasks is called Recognizing Textual Entailment (RTE). This dataset comes from a collection of annual competitions on textual entailment. Given two text fragments, the model has to decide whether the meaning of one text is entailed (logically related) to another. The task is formulated as a two-class classification problem. ChatGPT had to decide if the two sentences were "entailed" or "not_entailed". 9. WNLI. SuperGLUE Winograd NLI dataset comes from the GLUE benchmark [74]. Initially, this task was inspired by the Winograd Schema Challenge [90] in which a model must read a sentence with a pronoun and select the referent of that pronoun from a list of choices. For the WNLI dataset, the original data was converted to the sentence pair classification problem. The second sentence in a pair was created by replacing the ambiguous pronoun with each possible referent. ChatGPT has to predict whether texts are entailed with each other ("1" label) or not ("0" label).</p>
</li>
<li>
<p>SQuAD. SQuAD v_2 [76] is a question-answering dataset, which combines 100,000 examples from SQuAD1.1 with over 50,000 unanswerable questions looking similar to real ones. Each question consists of the context, textual answer, and number referring to the location in the context where the answer can be found. To perform well on the dataset, any given system must be able to answer the questions and infer whether the answer can be found in the given context.</p>
</li>
<li>
<p>MathQA. The multi-step mathematical reasoning dataset GSM8K [78] -MathQA contains grade school level maths word problems (MWP) that require only basic arithmetic operations. It was designed to test large language models with auxiliary chain-of-thought reasoning data. It was shown that the dataset is challenging for even the largest generative models.</p>
</li>
</ol>
<p>ClarinEmo.</p>
<p>It is an original dataset consisting of 1,110 texts in Polish -various opinions have been handannotated with three sentiment polarizations and eight emotions describing the author's intention. The annotations of six independent annotators were aggregated to label each sentence with all potential options, using the label when at least two annotators agreed on it. It is our new dataset that has not yet been published. We exploited this dataset to ensure that ChatGPT was not trained on it.</p>
<ol>
<li>GoEmo. The GoEmotions dataset [80] consists of 58k carefully selected Reddit comments from popular English subreddits labeled according to a 27 + 1 schema, i.e. 27 possible emotion categories plus neutral. ChatGPT is ordered to determine the emotions of provided text from the list of available 28 categories. To additionally guide ChatGPT, we request it to provide a specific number of emotions that matches the number of emotions annotated as ground truth.</li>
</ol>
<p>14.-17. GoEmoPer. To investigate ChatGPT's performance in Personalized Emotion Recognition, we obtained individual annotator annotations from raw GoEmotions data. ChatGPT is requested to predict emotions assigned to provided text by a selected annotator. We analyse ChatGPT performance in four different scenarios: GoEmoPer0, GoE-moPer1, GoEmoPer2, GoEmoPer3. ChatGPT is not given any information about the annotator in the prior experiment. In the following scenarios, we provide an additionally predefined number of texts annotated by this annotator. The goal is to provide ChatGPT with a context that will help it learn the personal preferences of the annotator. We start with a context consisting of one text and gradually increase the number to three.</p>
<ol>
<li>
<p>Unhealthy. Unhealthy Conversation [82] is a dataset of 44,000 comments of 250 characters or fewer, annotated by 588 crowd workers. Each comment was annotated as healthy or unhealthy. Additionally, each comment could be annotated with one of the following attributes: antagonistic, hostile, dismissive, condescending, sarcastic, generalization, or unfair generalization.</p>
</li>
<li>
<p>UnhealthyPer. This is the personalized version of Unhealthy Conversations. The dataset texts and annotations are identical to the non-personalized Unhealthy Conversations version. The only difference is that the personalized UserID model [20] is used instead of the standard transformer model. 20. PolEmo. PolEmo 2.0 [83] is a corpus of Polish consumer reviews from four domains: medicine, hotels, products, and school. Each text was manually annotated with the sentiment using one of the following labels: positive, neutral, negative, or ambivalent.</p>
</li>
</ol>
<p>21.</p>
<p>TweetEmoji. This is one of the seven heterogeneous tasks from the Tweeteval dataset [84]. It focuses on emoji prediction for a given tweet. There are twenty available emojis, and ChatGPT is asked to provide a list of three emojis, which could be added at To. the end of a given tweet ranges from the most probable to the least. To calculate metrics such as F1 or accuracy, the first emoji on the list was assumed to be ChatGPT's answer.</p>
<ol>
<li>
<p>TweetSent. TweetSent, another task from the Tweeteval [84] dataset, involves determining the sentiment expressed in a Tweet. In our work, ChatGPT is tasked to identify the sentiment of a given text, categorizing it as negative, neutral, or positive.</p>
</li>
<li>
<p>TweetStance. TweetStance is one more task from the Tweeteval [84] dataset that focuses on detecting stances in Tweets in five different areas: abortion, atheism, climate change, feminism, and Hillary Clinton. Each text was labeled as none, against, favor.</p>
</li>
<li>
<p>ReAding. RACE dataset [86] is a reading comprehension dataset consisting of over 100,000 multiple-choice questions relating to about 28,000 passages from various topics. It was created using English examinations in China for middle and high school students. Each question has four possible answers labeled A, B, C, D, with only one answer correct.</p>
</li>
<li>
<p>WSD. It is a unified evaluation framework for word sense disambiguation proposed in [88]. The framework consists of five evaluation datasets with standard English texts from Senseval [91,92] and Semeval [93,94,95] competitions. Texts were annotated with meanings (senses) from Princeton WordNet 3.0 (PWN) sense inventory [96] containing 117,664 synsets (sets of synonymous senses). The framework has been used as a standard evaluation environment for knowledge-based, weakly supervised, and supervised word sense disambiguation models. The overall collection of datasets contains 7,253 classification instances -sense annotations. The number of senses depends on the disambiguated word and varies from 2 candidate senses to more than 60 -mainly for polysemous verbs. On average, the models must choose only one sense from 5.24 candidate senses for each word. The dataset also contains a subset of instances where words are monosemous and have only one meaning concerning PWN. Such cases do not require any disambiguation, so all post-processing decisions were made in favor of the ChatGPT model. To evaluate Chat-GPT's sense recognition abilities, we adopted sense glosses from PWN 3 as they are often used as the basis for training supervised word sense disambiguation models. The glosses briefly summarize the meanings of senses using natural language. We used the glosses to explain meanings to the model when disambiguating the words in a given context. Using the glosses to explain senses to a language model implicitly tests its language comprehension abilities.</p>
</li>
</ol>
<p>Research methodology</p>
<p>Our research focused on three main steps depicted in Fig. 3. Having quality measures for both reference models and ChatGPT, we were able to confront them with one another to answer our main research question: is ChatGPT a good jack of all trades? 3 https://wordnetcode.princeton.edu/glosstag.shtml</p>
<p>Prompt generation</p>
<p>Prompt generation consists of three goals that we want to achieve. The key idea is to solve a particular natural language processing task, like sentiment analysis or emotion detection, using ChatGPT. Additionally, we must force ChatGPT to answer with a specified value from a list of annotations used in the chosen task/dataset and an easy-toprocess format, like a Python list or single integer.</p>
<p>All of the above can be achieved by using various schemas of prompts. The general chat schema looks like the following Chat 1: Chat CHAT_ID. Task: TASK_NAME. Case EXAMPLE_ID. E.g.: Chat 1. Task: Aggression. Case 3.</p>
<p>Prompt //our input to ChatGPT</p>
<p>INSTRUCTION //task description, e.g.: Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. There are multiple options when creating prompt schemas. For example, we can add sentiment label mappings to integers, forcing ChatGPT to answer with only integers. We can further specify ChatGPT output format by adding allowed values again after Text input. Moreover, we provided additional user annotations describing their perspective in the case of personalized tasks. The example prompts for each task are presented in Appendix B. The generated prompts were used as questions in a ChatGPT conversation. It is worth noting that we did not force the API to create a new conversation window per prompt. Consequently, multiple texts were allocated across multiple conversations within the specified ChatGPT limitations.</p>
<p>Post-processing</p>
<p>Raw text provided by ChatGPT is different from the final version achieved after post-processing. Some answers are returned as whole sentences instead of requested predefined</p>
<p>Step 1</p>
<p>Custom prompting procedure from test/dev splits</p>
<p>Step 2</p>
<p>Our custom API</p>
<p>Querying ChatGPT</p>
<p>Post-process outputs Extract answers from raw outputs Figure 3: ChatGPT evaluation flow diagram showing the three stages of data processing: 1) selecting a dataset and converting the test set to prompt-based form; 2) querying (prompting) the ChatGPT service using our custom reverse-engineered API; 3) extracting labels from raw outputs and evaluating using ground truth and comparing the results with SOTA models or SOTA results from papers.</p>
<p>lists. This imposes a necessity to check what happened and extract answers from ChatGPT output manually. The next step is to cast the resulting outputs to the correct labels in the dataset. For example, if ChatGPT returned a sentiment with the typo "negaitiv", we mapped it to "negative", assuming that this was the intended answer. Sometimes the model returns values out of the requested list. For example, given the possible 28 emotions in emotion recognition, ChatGPT returned the unmentioned "determination". Such cases were converted to a value of "none", which was not considered in the performance evaluation (column #None in Tab. 1, plus 3k additional prompts used in Sec. 6.4).</p>
<p>Overall, the number of cases that required post-processing was relatively small (column #Post-processed in Tab. 1). For most tasks (16), the contribution of such texts was less than 5%. Only for Aggression, SQuAD, Unhealthy, and ReAding, it exceeded 15%.</p>
<p>Experimental setup</p>
<p>Without an official API, we modified and used an unofficial API called PyGPT 5 , written in Python. During the research, we exploited up to 20 accounts to gather data regarding 25 datasets.</p>
<p>Every dataset was first assigned to a different task manager who independently prepared appropriate prompts based on the dataset texts and the output structure. Next, our API managers ran parallel processes to query prompts and 5 https://github.com/PawanOsman/PyGPT acquire the raw ChatGPT output in a shared sheet Chat-GPT Evaluation v2.0.xlsx 6 . In total, over 38,000 prompts were exploited 7 . Post-processing procedures (Sec. 5.2) were applied afterward, along with quality measure computation (Sec. 5.4) and in-depth analyses.</p>
<p>Performance measures</p>
<p>If possible, we launched our models equivalent to SOTA solutions since the setup (especially data split) was often different than in the original paper. For that purpose, we usually utilized source codes published by the authors. Unfortunately, it was impossible for some tasks, so we exploited the performance results provided in the original paper. If available, we tried to validate ChatGPT using one measure -F1 Macro, which is commonly acceptable for imbalanced data, Tab. 2. F1 Macro in multi-label classification is an average of harmonic means between precision and recall calculated per label. If Q is the number of labels, p i and r i are the precision and the recall calculated for th label, F1 Macro is given by equation: In the case of CoLa, WNLI, WordContext, and MathQA, we had to rely on the accuracy, as it was the only one presented in the reference paper; we could not replicate their studies and calculate our measures. WNLI and WordContext have their two classes balanced, so it is not an issue.
1 = 1 ∑ =1 2 ⋅ ⋅
Only the post-processed and cleaned cases (column #N in Tab. 2) were considered in the quantitative analysis. Other metric values are presented in Appendix A, Tab. 9.</p>
<p>Having calculated the SOTA and ChatGPT results, we were able to compute Loss that reflects how much ChatGPT is worse than the best-dedicated methods, as follows:
Loss = 100% ⋅ (SOTA − ChatGPT) SOTA
Loss measure was exploited in Tab. 2, Fig. 5, 7, 8, 10, 11, and 12.</p>
<p>Yet another measure is utilized in Fig. 9: Gain. It quantifies which part of the entire possible improvement of the performance of the reference non-personalized method was reached by a given personalized in-context solution:
Gain = 100% ⋅ (Per − NonPer) 100% − NonPer
where Per is the F1 result provided by our personalized incontext processing; NonPer is F1 delivered by the reference, non-personalized model.</p>
<p>Quantitative analysis</p>
<p>Jack of all trades, master of none</p>
<p>We tested ChatGPT on 25 NLP tasks listed in Tab. 1 by computing appropriate quality measures both for ChatGPT and the best recently available models (SOTA), Tab. 2. The ChatGPT performance is depicted in Fig. 4. It is usually greater for semantic tasks rather than for pragmatic ones, which is related to the task difficulty, see Sec. 6.2.</p>
<p>We also estimated the loss of ChatGPT compared to the SOTA solution, Sec. 5.4. The loss indicates how worse ChatGPT is relative to SOTA, which is considered 100% capacity, Tab. 2, Fig. 5. The crucial finding from our studies is that the ChatGPT performance is always lower than the SOTA methods (loss&gt;0) in all the tasks considered. It means that ChatGPT never reached the level of the best existing models. However, its loss was greater or lesser depending on the problem. The average quality of SOTA methods was at 73.7%, whereas ChatGPT was at only 56.5%. Simultaneously, ChatGPT was less stable: the standard deviation of its performance was 23.3% compared to only 16.7% for the SOTA solutions.</p>
<p>The loss for most tasks did not exceed 25%. It was greater only for three problems: GoEmotions, PolEmo, and TweetEmoji. All these tasks are related to a very subjective problem of emotional perception and individual interpretation of the content. Also, for the last emotional task -ClarinEmo, the loss was 21.8%. If we discard all eight emotion-related tasks (ids: 12-17, 20-21), the average SOTA performance reaches 80% (increase by 6.3pp), but ChatGPT improves much more: by 13.2pp, up to 69.7%. In such a case, the average loss is reduced by as much as half, from 25.5% to 12.8%; the difference in performance drops from 17.2pp to 10.3pp.</p>
<p>We know that a direct comparison of performance between different tasks does not always rightly show the difficulty of the tasks being compared. A small increase in the evaluation score in one task might be more challenging to overcome than a larger increase in another task. Moreover, simple solutions, such as majority class voting or a simple lexical similarity function, often appear to be a strong baseline for complex neural architectures. For example, an increase of 10pp in WSD or WordContext tasks might be more challenging to obtain, and the most outstanding solutions are far from 100% performance. Furthermore, the best unsupervised or weakly-supervised solutions obtain a 70% performance of F1-score in the WSD task, and their architectures have significantly fewer parameters than the ChatGPT model.</p>
<p>Nevertheless, we can state that ChatGPT performs pretty well on all tasks except emotional ones. Simultaneously, its achievements are always below SOTA but usually not so much. Such results prove that ChatGPT is Jack of all trades, master of none.</p>
<p>Task difficulty vs. ChatGPT performance</p>
<p>Task difficulty is defined as (100% -SOTA_performance).</p>
<p>In other words, we assume that difficulty is reflected by the level of the best recent models' performance, i.e., the closer the SOTA performance to 100%, the easier (less difficult) the task. The difficulty of each task is presented in Tab. 2 and Fig. 6. In general, pragmatic tasks are more difficult (average difficulty = 32.3%), while the average difficulty for semantic tasks is only 15.6%. It comes especially from the emotional tasks, which are pragmatic and very difficult (average 39.7%).</p>
<p>We can also observe that the loss is correlated with the task difficulty; see Fig. 7. The Pearson correlation coefficient between difficulty and loss is equal to 0.46. It is observable that semantic tasks (blue crosses) are rather easy; hence, their ChatGPT loss is relatively small. into the Q3 quadrant: easy task, low losses. A stronger dependence: greater difficulty, the higher loss can be seen for pragmatic tasks dominated by emotion-related problems, Fig. 8.</p>
<p>This analysis, however, requires further investigations since the number of the tasks considered (25) still remains relatively small.</p>
<p>Random Contextual Few-Shot Personalization</p>
<p>As a concept of contextual and human-centered processing, personalization in NLP was proposed by us and recently extensively explored in [20,22,21,97,98,99,100,101]. Here, we extend it to ChatGPT prompts as personalized incontext processing. This is somewhat similar to in-context learning with demonstrations [102]. However, in the case of personalized tasks, the user preferences are difficult to capture with a user context consisting of only up to three past annotations of this user.</p>
<p>C o l B E R T ( F 1 )</p>
<p>S p a m ( F 1 )</p>
<p>A g g r e s s i o n P e r ( F 1 ) A g g r e s s i o n ( F 1 ) T w e e t S e n t ( F 1 ) U n h e a l t h y P e r ( F 1 ) C l a r i n E m o ( F 1 ) S a r c a s m
( F 1 ) U n h e a l t h y ( F 1 ) P o l E m o ( F 1 ) G o E m o ( F 1 ) G o E m o P e r 0 ( F 1 ) G o E m o P e r 3 ( F 1 ) G o E m o P e r 2 ( F 1 ) G o E m o P e r 1 ( F 1 ) T w e e t E m o j i ( F 1 ) T e x t E n t a i l ( A c c ) W N L I ( A c c ) C o L a ( A c c ) R e A d i n g ( A c c ) W S D ( F 1 ) M a t h Q A ( A c c ) S Q u A D ( F 1 ) W o r d C o n t e x t ( A c c )
T w e e t S t a n c e ( F 1 )</p>
<p>Task Name (resource-based)     It is important to design a tailor-made architecture for generating user representation to address this. On the other hand, the embedding of a person should describe the similarity or peculiarity of their perspective compared to others. During our experiments, we observed higher loss values for the ChatGPT model compared to the SOTA models in the case of the AggressionPer and UnhealthyPer datasets: 3.25 and 12.55 percentage points, respectively. On the other hand, enriching the user context with more annotations resulted in 4.08 percentage points better ChatGPT accuracy for GoEmoPer3 compared to GoEmoPer0. The percentage gains between the context-based setup and the baseline are presented in Fig. 9.</p>
<p>Demonstration-based personalization included in our prompts can be treated as similar to few-shot learning, even though ChatGPT does not update its model after every prompt. Therefore, we would prefer to call it a few-shot evaluation or personalized in-context processing.</p>
<p>Moreover, we also evaluated the non-personalized incontext processing semantic tasks: (1) WordContext, (2) SQuAD, (3) ReAding, and (4) WSD. In this case, the Chat-GPT loss values were relatively small and ranged between 9.9% for ReAding and 12.7% for WordContext. While solving mathematical calculations (SQuAD), the highest loss was among semantic tasks: 23.7%.</p>
<p>Impact of the context</p>
<p>One of the many features of ChatGPT is its ability to reference previous messages within the conversation. We wonder whether ChatGPT treats all previous messages as    Figure 7: Quadrants with the correlation between the loss of ChatGPT performance compared to the best, recent (SOTA) method and difficulty of the task. Each data point represents a separate task and its index can be found in Fig. 8 an extended context to a given prompt. If so, ChatGPT may not recognize properly that an unanswerable question does not have an answer. As a result, it may wrongly treat the previous prompts as a valuable context and response based on them rather than refuse any response. To test this ChatGPT capability, we used a question-answering dataset SQuAD_v2 [76]. Apart from the original processing of the set (Tab. 2), three additional experiments were conducted. The first involved prompting ChatGPT a week later with the same prompts as during the initial testing of SQuAD. The second experiment exploited the same prompts, but with a Gain Figure 9: Impact of context on classification metrics for GoEmotions, Aggression, and Unhealthy Conversations datasets. We show the percentage gain between setup with context and baseline, i.e. setup where no prior knowledge about the annotator is provided to the model. We show a gain in accuracy for the former dataset, whereas, for Aggression and Unhealthy Conversations, we present a gain for the F1-score.</p>
<p>new order, i.e., all unanswerable questions were prompted before the answerable ones. That way, ChatGPT could not treat the previous answers to the questions with the same context as the extended context of the given prompt. The final experiment involved the same set of prompts. However, a separate conversation with ChatGPT was initialized for each prompt. We computed accuracy and F1 macro for each scenario, along with the number of unanswerable questions (300 cases in total), which were correctly or incorrectly detected by ChatGPT, Tab. 3.</p>
<p>The obtained results demonstrate that ChatGPT performance on the same set of prompts in the same order and setup insignificantly decreased over a week by 1pp (accuracy) or 0.5pp (F1). ChatGPT reasoning quality barely improved when the order of the prompts was changed and slightly decreased when prompts were isolated in separate conversations. The number of unanswerable questions was correctly detected and ChatGPT performance was almost identical for the original set and the one with a new prompt order. For the dataset tested a week later and with separate conversations, all the metrics decreased. It indicates that ChatGPT is not directly influenced by the previous prompts while determining whether the question is unanswerable. Both the performance of ChatGPT and its ability to detect unanswerable questions was worst when separate conversations were established for each prompt. It may suggest that providing some answerable questions helps it detect unanswerable ones with the same context. However, the differences in performance are not significant enough to be sure of such dependencies.</p>
<p>The results are inconclusive as to whether ChatGPT treats the previous prompts as a context for the prompt. Anyway, the differences in performance are not significant. On the other hand, ChatGPT demonstrated its instability and tendency towards non-determinism. This can be a serious disadvantage for some application domains. Even with the same setup, its results may vary with each launch. </p>
<p>Availability of the testing set for ChatGPT training</p>
<p>Some of the datasets exploited in our ChatGPT evaluation were publicly available at the time of the ChatGPT training. Therefore, the model could have been learned on those data, which may influence its performance on those particular datasets, see column Availability and Trained in Tab. 1. Availability has been estimated by us while Trained was extracted from ChatGPT responses. In general, most of the analyzed sets were probable or highly probable to be used for training the model.</p>
<p>The results shown in Fig. 10 and 11 indicate that the datasets on which ChatGPT was likely to have been trained tend to achieve higher performance (smaller loss) compared to SOTA solutions than the ones ChatGPT was less likely to be trained on. The tasks which ChatGPT claims it used for training (Fig. 11) are in opposite dependency difficulty -loss than the ones the model is unaware of. Analysis of availability rather supports this phenomenon (Fig. 10). It means that sets known for ChatGPT and estimated by us to be used for training overlap each other, and their loss is not much dependent on task difficulty.</p>
<p>Manual prompt fine-tuning</p>
<p>In the course of conducted evaluations, it became apparent that the construction of the prompt can have an impact on the obtained results. This hypothesis was inspired by [103], where common patterns for various needs and problems were proposed. Therefore, we prepared various versions of queries modeled on patterns such as "The persona pattern" and "The game pattern". A compilation of the results can is presented in Tab. 4.</p>
<p>The experimental setup differed from the above studies, as we utilized the official OpenAI API 8 , which allows for greater control over the model behavior. In every experiment, the default API parameters described by OpenAI were exploited 9 . Each task was tested with the inclusion of the message "System", which helps set the behavior of the assistant. The prompt patterns were described in Appendix D. The results demonstrate that the prompt pattern substantially 8 https://platform.openai.com/docs/guides/chat/introduction 9 https://platform.openai.com/docs/api-reference/chat Is trained on this dataset? (ChatGPT answer)</p>
<p>Yes No Figure 11: Correlations between the loss of ChatGPT performance compared to the SOTA method and the difficulty of the task. Regression lines are drawn separately for whether ChatGPT claims to be trained on the dataset or not (Tab. 1). Each data point represents a single task with the index from Tab. 1.</p>
<p>influences the obtained outcomes. For semantic tasks (Tex-tEntail, WNLI), we were not able to improve ChatGPT performance (negative difference) with various prompt patterns. However, it was possible for emotion-related datasets, i.e. a small benefit for GoEmo and very significant for PolEmo (pattern 76 and 77) -increase by even 14.8 p.p. In summary, we emphasize the significance of prompt patterns on the obtained outcomes. It can dramatically impact on performance. Nevertheless, additional and dedicated research is imperative to determine the optimal prompt pattern for each problem.</p>
<p>Comparison with GPT-4</p>
<p>To complement our quantitative analysis, as demonstrated in Tab. 2, we conducted a comparison between Chat-GPT and new GPT-4 on a selection of five tasks from our previous evaluation 10 , see Tab. 5, Fig. 12. Additionally, we provided quality measurements for the SOTA model as a point of reference.</p>
<p>Interestingly, despite GPT-4 being a more advanced model than ChatGPT, we observed varying performance results. ChatGPT still outperformed GPT-4 in pragmatic, emotional tasks, i.e. GoEmo and PolEmo, while GPT-4 achieved significantly higher scores in the remaining three semantic tasks with even a 9.9 p.p. increase for the WNLI task.</p>
<p>It is important to note that, across all tasks, the SOTA model consistently outperformed both ChatGPT and GPT-4. The loss for GPT-4 was very small for semantic tasks (Tex-tEntail, WNLI): 0.9%-6.4%, and still very high for emotional problems: 46.3%-56.3%.</p>
<p>We emphasize that the results for GPT-4, as for Chat-GPT, could significantly differ, if distinct prompt schemes are compared, see Sec. 6.6.</p>
<p>Qualitative analysis</p>
<p>Understanding the cases when ChatGPT is not acting as expected requires a deeper analysis, divided into three types: exploratory analysis, benchmarking analysis, and explanatory analysis. The exploratory analysis evaluates system answers for different prompts. In benchmarking analysis, the expert evaluates ChatGPT ratings and dataset label quality. The explanatory analysis allows an understanding of the ChatGPT answers by asking in-depth questions. Fig. 13 contains our summary of the differences between ChatGPT and the latest state-of-the-art solutions dedicated to specific NLP tasks, as the result of the quantitative analysis presented in Sec. 6 and the qualitative analysis presented here.</p>
<p>Exploratory analysis: Case study</p>
<p>When exploiting the possibilities of ChatGPT, we can see that it can perform various tasks, including recognizing generalized and personalized dimensions of Natural Language Processing, answering questions where a generous amount of domain knowledge is required, or even writing lines of code in the programming language of choice. What can be observed from time to time is the instances where ChatGPT is faced with a lack of knowledge. Those situations are usually solved by supplementing the model with information. But what if the information we are providing is, in fact, wrong? When asked about the main character of the Polish novel "Lalka" ('The Doll'), ChatGPT answered correctly. Still, when explaining that the answer was wrong and that the author's name was different, ChatGPT added the    wrongly inputted name and proceeded to answer with this inaccurate information. We can see that the domain knowledge of the model can be weak to disinformation, which further implies possible consequences regarding clashes with fake news. Another layer of divergent behavior of ChatGPT is in the ethics of the model. When conducting experiments regarding tasks such as humor recognition or offensiveness detection, we have stumbled upon output that not only refuses to answer whether something is or is not funny but also sends a moralizing message with an irritated tone. Interestingly, the model implies it is fully neutral and has no biases, yet it has them in topics regarding ideological views.
ID Task Name Measure ChatGPT GPT-4 Difference GPT-4 SOTA ChatGPT GPT-4 (resource-based) type (a) [%] (b) [%] (b-a) [
Hagendorff [104] drew attention to the fact that chatbot ethics can be a subject of debate in fairness, nondiscrimination, and justice. ChatGPT should respond to questions and generate text based on the given parameters. However, there is still a blank area where the tool will not accomplish tasks. At first glance, ChatGPT refuses to provide specific content that can be presumed as judgmental, discriminative, or promoting hate speech. During the exploratory dialogue, we found many ways to display messages that are not always politically correct. The first example (Chat 51) is to avoid answering the question about the likelihood of achieving a goal in an academic or professional career by listing the potential factors that may influence this fact. ChatGPT answers only after the researcher asks directly about the typical representatives of the particular position. By making the request more specific based on the data, ChatGPT gives a precise answer. The second example (Chat 52) of tasksolving avoidance is refusing to make up the story with a word that can be offensive. ChatGPT assumes that the user refers to this meaning, omitting the context from the previous question, whose purpose indicated that nonvulgar sense is involved. Another type (Chat 53) of refusal is making up stories that raise the delicate subject, i.e. stories about the traumatic event that can be seen in the third example. Chat-GPT will only generate the content if the user adequately motivates it with the scientific goals. (Chat 54) highlights the possibility of the chatbot exhibiting bias while answering requests for characterizing the widely known traits of controversial politicians without judgmental opinions. However, in the second task, in which ChatGPT has to write a joke that this politician would admire, it refuses to motivate his decision politician's disregard for human rights. This proves that the tool has hidden biases that are revealed inappropriately worded answers for tasks or questions. Borji [105] conducted a systematic review of the typical categories of ChatGPT failures. The above errors are derived from both incorrect reasoning in terms of psychological reasoning and bias and discrimination. The performance of modern language models, such as T5, GPT-3, and ChatGPT, heavily relies on the quality of task-specific prompts. The prompt-based learning paradigm requires careful prompt engineering and prompt tuning. However, in the case of the ChatGPT model, prompt tuning is technically unavailable, and the only way to verify prompt relevance is to evaluate its performance directly in the downstream task. We decided to tune the prompts manually according to the task -we selected the prompts such that the answers generated by the model on a small validation sample for the given task were the most stable and accurate. On the other hand, using the prompts directly as humans designed them implicitly allows us to evaluate models' language comprehension abilities. Such evaluation is important for tasks in the area of semantics, where models should successfully utilize short natural language descriptions of words or phrases, as they are used in other supervised solutions.</p>
<p>Most tasks require a prompt that enables the model to choose a certain value from the provided options. However, to evaluate ChatGPT's ability to understand various data formats, we tried not to restrict the design of our prompts to a single data template. Still, the prompts must include all the information required for the ChatGPT to perform the task. A good example can be a prompt for Aggression or ColBERT tasks, where we provide possible outcomes and expect ChatGPT to choose the right answer and return it in Python list format. Some tasks require a choice from multiple options, like TweetEmocji, where the correct answer is the emoji that fits the best-provided tweet. ChatGPT can also return a number as a category indicator or whole output in the JSON format. In the case of mathematical reasoning, it can provide a whole explanation of how it reached a certain outcome and provide only the answer without explanation. Understanding prompts and user intent for how the output should be structured is not an issue for the model, which is a very impressive capability. We also noticed that when it is unable to perform a task on the provided example, it will refuse to do so and provide an explanation why, as it has happened in the case of ClarinEmo B.12, where the model stated that all provided texts are legal and financial statements. Therefore it is not possible to assign emotion labels to them.</p>
<p>Benchmarking analysis: Validation based on human expert</p>
<p>There are some trends in the ChatGPT responses, which were the basis for the difficult case analysis. One of the main trends is connected with the chat sensitivity. Importantly, this </p>
<p>Stable release</p>
<p>In production Figure 13: Difference between ChatGPT and the best recent solutions (SOTA) related to analytical NLP tasks. sensitivity could be observed during the execution of different tasks. Offensiveness detection is an example -ChatGPT assigned additional labels to those texts from Unhealthy Conversations Dataset labeled by human annotators simply as healthy. Similarly, ChatGPT has associated most of the statements coming from GoEmotions and labeled by people simply as neutral with different emotions.</p>
<p>Interestingly, in many cases, ChatGPT tends to have more negative (and therefore safe) assessments than people. Characteristic examples come from two sources. ChatGPT labeled as aggressive only 11 texts from the WikiDetox Aggression dataset labeled by people as non-aggressive, while the opposite decision was taken 207 times. A similar trend is observed for the TweetSent task -ChatGPT assigned positive sentiment to 27 tweets labeled by people as negative, while the opposite decision was taken 83 times. It turns out that the system erroneously assigns a positive sentiment to those texts in which there are linguistic cues of a contradictory nature, e.g.: In the case of misattributed negative sentiment, no such clear correlation can be observed. However, those texts whose interpretation is context-dependent (this context is very often political) are a significant proportion, e.g.:</p>
<p>Bill Clinton built a wall on the Mexican border in the 90s. #FunFactFriday or:</p>
<p>The election of Donald Trump could have a significant future impact on the project Dakota Access Pipeline when he takes office.</p>
<p>We have analyzed the inconsistencies between human annotations and ChatGPT answers based on four datasets: Wikipedia Aggression, GoEmotions, Tweeteval: sentiment, and Unhealthy Conversations. We have examined 100 randomly selected cases for each dataset. Each case was composed of prompt, human annotation, and adequate (but inconsistent) ChatGPT answers.</p>
<p>Analysis was conducted by experts who are specialists trained in the recognition of emotions in the text. One of them is a psychologist and another is a linguist, both are experienced annotators. They get acquainted with the text prompt and decided whether the evaluation both of human and ChatGPT were correct. Expert analysis was focused on different points of view that someone may take. The annotations in the selected 4 datasets were of a more or less subjective nature, and for this reason, it was not necessary to create detailed guidelines in order to achieve high interannotator agreement (moreover, the same was true for the original datasets). The essential goal was precisely to capture possible and acceptable differences in the labeling of texts. Rather, the idea was to take into account the various possibilities, including those not captured in the benchmark dataset. The experts evaluated the labels assigned to the texts. In some cases (when different contexts may affect different interpretations), human annotation and ChatGPT answers were considered correct. The number of ChatGPT correct answers is relatively high, see Tab. 6.</p>
<p>A more detailed analysis focused on five types of comparison (see Tab. 7 and the visualization of the differences between the tasks based on selected categories presented in Fig. 15): the cases in which the expert accepted both human annotation and ChatGPT answer (Human &amp; Chat-GPT: for example see Chat 58); the cases in which only human annotation was considered correct (Only human: for example see Chat 57); the cases in which only ChatGPT answer was considered correct (Only ChatGPT; for example see Chat 55 or 56); the cases in which neither human nor ChatGPT answer was considered correct (Neither human nor ChatGPT: for example see Chat 59) or the cases in which evaluation was impossible due to the unintelligible content (for example see Chat 60). The analysis revealed that in many cases (especially for Unhealthy Conversations), only ChatGPT labeled the text correctly. ChatGPT pointed out many human errors (see Appendix C.2 for more examples). Interestingly, the cases where only ChatGPT gave the correct answer have a common characteristic: in most of them, the human annotator was less sensitive, e.g. the annotator(s) labeled aggressive utterances as non-aggressive, negative tweets as neutral or unhealthy conversation as healthy. Chat-GPT tends to interpret a given text more negatively than a human does.</p>
<p>It is also connected with pragmatic categories such as sarcasm. Many utterances, which humans labeled as neutral, ChatGPT classified as sarcastic, e.g.:</p>
<p>Yes, it's sarcasm. I shouldn't use it actually, it's pretty hard to tell nowadays." Yours wasn't but yeah it sure is getting harder... scary.. This fact shows that many of the neutral messages can be classified as sarcastic and aggressive, which as a result, can limit freedom of speech in case of using it commercially or Table 7 Expert-based evaluation of the agreement between ChatGPT responses and original human annotations (ground truth):</p>
<p>Human &amp; ChatGPT -the expert accepted both ChatGPT answer and the human annotation, Only human annotation was approved by the expert, Only ChatGPT was found acceptable, Neither human nor ChatGPT was acceptable, N∖A evaluation was not available since the expert was not able to link the input text to the possible output.  in a public debate. The tool's creator should emphasize the preparing model that will be available to distinguish small nuances between sarcasm and a neutral message. This is desirable not only for the usability of the solution but also for building public confidence in artificial intelligence solutions.</p>
<p>ChatGPT's informing that a message is negatively perceived is a way to teach a user with the wrong intentions to be politically correct. On the other hand, a user who tries to convey information objectively without malicious intentions may learn that reality is more biased than he or she might think. Another interesting conclusion from the analysis is the recognition of the sincerity of one's message that involves its true intentions. The annotator has evaluated the below message as expressing gratitude, whereas ChatGPT regards it as neutral (Chat 58)</p>
<p>You're welcome</p>
<p>This simple message could provide neutral emotions if the message's sender said it automatically. However, if the speaker intends to express the actual gratitude that one feels, ChatGPT cannot recognize this from such a short message and without having additional information about the speaker.</p>
<p>All the examples can be found in Appendix C.2.  </p>
<p>Explanatory analysis: XAI</p>
<p>The advantage of ChatGPT is that it can give reasons for its answers. Thus, we are dealing with self-explanatory artificial intelligence, which is a part of eXplainable Artificial Intelligence (XAI); see Appendix C.3. Thanks to the interaction, researchers' findings can be confronted with the motivation provided by the model itself. Exploiting this opportunity, we subjected some ChatGPT answers presented above to detailed examination. This led us to several conclusions.</p>
<ol>
<li>ChatGPT provides reasonable and factual clarifications for its decisions. It can point to specific passages in the text that influenced his decision, Chat 61:</li>
</ol>
<p>Additionally, the use of offensive language such as "sick son of a bitch" further highlights the aggressive tone of the text.</p>
<p>or Chat 70: the use of exclamation marks and the phrase "I did not finished yet!!!" can be interpreted as confrontational or intense When asked, ChatGPT explains in detail why a phrase has a particular interpretation, Chat 63:</p>
<p>The phrase "Go back to the dump on Staten Island" is a personal attack because it is meant to be insulting and demeaning. By implying that the person being addressed should return to a place considered to be unpleasant or undesirable, the speaker is showing a hostile attitude and attacking the person's character or background.</p>
<p>ChatGPT is also capable of generalizing, e.g. when asked which language phenomena demonstrate the enthusiasm or positive sentiment in the text, it gives a list containing such phenomena as the use of superlatives or lack of negative language (see Chat 65). However, this is characteristic of justifications for both correct and incorrect answers.</p>
<p>2.</p>
<p>ChatGPT seems to have no regard for individuals, instead judging situations. However, this often leads to mistakes, e.g. when it justifies assigning positive sentiment to neutral information, Chat 66):</p>
<p>In general, being shortlisted for an award is seen as a positive achievement, so the sentiment expressed in the text is positive.</p>
<p>Information about the distinction for a particular footballer is neutral. Its sentiment, however, can be both positive and negative. It depends on the sympathies of the recipientsympathies regarding specific footballers. Similarly, Chat-GPT justifies the negative sentiment of the news about the ban on naming streets after Fidel Castro, Chat 66:</p>
<p>In general, restrictions or limitations are typically seen as negative, so mentioning this restriction implies a negative judgment about the situation.</p>
<p>At the same time, ChatGPT explicitly distances itself from judging people. This issue is strongly connected with the next one.</p>
<ol>
<li>
<p>ChatGPT flattens the message, partially ignoring the metatext. A common mistake of the system is that it evaluates press reports and quotes of someone's statements without considering the metatextual frame. So it evaluates the main content but ignores the broader context (see Chat 64).</p>
</li>
<li>
<p>There are some disapproved words. ChatGPT evaluates rather situations than participants, but words refer to people, which lead to a specific, predetermined assessment, Chat 62:</p>
</li>
</ol>
<p>Additionally, the use of quotes around "trolls" implies that the speaker is directly calling the person, they are addressing a troll, which is further evidence of an aggressive tone 5. ChatGPT strongly relies on context paraphrasing when explaining its decisions in semantic tasks. This phenomenon was observed mainly in WSD and WIC tasks. In WSD, the model was expected to explain its decision by defining the meaning of chosen sense concerning the given context. However, for some examples, the model approached the task by largely repeating selected parts of the given context in such a way that the generated explanation did not meet typical linguistic criteria of constructing a proper sense definition, Chat 67: This is because the text describes bells as being present in an ancient stone church, and they are being rung (making a ringing sound) to call the faithful to evensong.</p>
<p>6.</p>
<p>ChatGPT presents the sense of common human morality. As mentioned in the previous section, ChatGPT tends to find negative connotations in the given text. In this example, the sentence was interpreted as not aligned with society's standards. Only after the researcher suggested the possibility of using black humor, accepts this interpretation, Chat 69:</p>
<p>The idea of eating one's own parents is generally considered taboo and immoral, and it can provoke a strong negative reaction in people</p>
<p>Limitations and discussion</p>
<p>Below, you can find a list of nine observations and limitations related to selected problems and cases that we encountered during our investigation.</p>
<p>Prompts may not be strict and precise enough.</p>
<p>ChatGPT requires prompts in natural language, which is -by nature -not structured and can be different for different users and tasks. Interesting to note is that prompt construction may affect the quality of the model's performance. There is also the possibility of auto-generated prompts [102]. We anticipate that this will be the subject of much future research.</p>
<ol>
<li>
<p>Post-processing is sometimes required due to less prompt precision, not following the expected behavior by ChatGPT, and its instability, see Sec. 5.2. It also refers to the necessary manual correction of typos surprisingly provided by ChatGPT, e.g., ["curiousity"] instead of ["curiosity"]. Some answers are in whole sentences instead of requested predefined lists (see Chat 30). It is difficult to point out the reasons for such conduct. As a result, the raw text provided by ChatGPT may require extraction of crucial information, e.g., final labels. It also depends on the prompting quality and correctness.</p>
</li>
<li>
<p>Unexpected, out-of-range responses are sometimes provided by ChatGPT, e.g., the unlisted emotion satisfaction has been delivered: Chat 2. Task: GoEmotions. Case 98.</p>
</li>
</ol>
<p>Prompt</p>
<p>From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in a Python list containing exactly two selected most matching emotions. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Input text: That's how you know they're happy.</p>
<p>ChatGPT answer</p>
<p>Based on the input text, it is likely that the text would arouse the emotion of realization and satisfaction in most people reading it.</p>
<p>["realization","satisfaction"]</p>
<p>Extracted answer</p>
<p>["realization", "satisfaction"]</p>
<p>Expected answer</p>
<p>["excitement", "neutral"] 4. Internal policy can strongly influence the answers received. It includes various biases and political correctness incorporated into the general ChatGPT model. Therefore, some responses are locked due to the OpenAI policy. It, for example, refers to texts "that could be seen as offensive and vulgar": Chat 3. Task: GoEmotions. Case 101.</p>
<p>Prompt</p>
<p>From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 2 selected most matching emotions. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Input text: Wouldn't wipe my arse with it.</p>
<p>ChatGPT answer</p>
<p>It would be difficult for me to determine the emotions that the input text would arouse in most people reading it as it appears to be a strong statement that could be seen as offensive and vulgar. Without more information and context, it would be hard to determine the emotion. ["neutral"]</p>
<p>Extracted answer</p>
<p>["neutral"]</p>
<p>Expected answer</p>
<p>["annoyance", "neutral"] 5. Context is generally respected by ChatGPT. In many cases, this can be considered an advantage. However, prompts themselves and the sequence of prompts provide limited control over them.</p>
<p>Efficiency and costs.</p>
<p>At the time of the evaluation, a paid API from OpenAI for ChatGPT was unavailable. As part of the study, we used 13 accounts for which we passed session tokens to a central multi-threaded module that sends and receives prompts. On average, after about 50 prompts sent per hour using one special token, OpenAI temporarily blocked access for that special token, mostly for less than an hour. Sometimes the tokens were outdated and had to be re-generated and replaced, which depended on the responsiveness of account holders. A processing capacity of 2-3k prompts per day was achieved at the end. In the same amount of time, the SOTA models are capable of processing millions of texts even with a single recent GPU card [106].</p>
<ol>
<li>
<p>The problem of controversial and ambiguous utterances is solved by ChatGPT's demonstration of a lower level of confidence, e.g. "It would be difficult for me to accurately determine. . . ", "The same text can be perceived differently depending on the context and tone of the statement.", "I am sorry, but the input text is not clear, its a Mix of...", "it is quite ambiguous, and the context is not provided" (GoEmo, case 80, 82, 101, 102, 554, 574, 893, 894). Overall, it can be seen as an advantage since it suggests providing additional information or some corrections. It is also an invitation to conversation in case of manual processing.</p>
</li>
<li>
<p>Explanations (XAI) are sometimes provided by Chat-GPT itself. They are very reasonable, e.g., "["determination"] Note: Determination is not in the given list of emotions, I have inferred it from the text given": From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Input text: "I will do what I must."</p>
</li>
</ol>
<p>ChatGPT answer</p>
<p>["determination"] Note: Determination is not in the given list of emotions, I have inferred it from the text given.</p>
<p>Extracted answer</p>
<p>["determination"]</p>
<p>Expected answer</p>
<p>["neutral"] 9. Restrictive or wrongly implemented policy will influence the user experience of the ChatGPT by not answering all user's prompts exaggeratedly judging many questions not along with OpenAI rules: Chat 5. Task: PolEmo2.0. Case 95.</p>
<p>Prompt</p>
<p>Rate the sentiment of this text using one of four labels: positive, negative, neutral, and ambivalent. Present the result as a list in Python containing the selected label. Text to be evaluated: I honestly did not expect that something like this could happen to me. I feel cheated by them. They do not count on people and do not respect them. They take out money. They make you pay the same money for a place on the floor as for a bed, and they do not give bedding or mattress. They are incompetent. They don't give a damn about the welfare of a person. At 22.00 you have to sleep, otherwise the staff squawks in the corridor. I do not recommend this hostel to anyone.</p>
<p>ChatGPT answer</p>
<p>This content may violate our content policy. If you believe this to be in error, please submit your feedback -your input will help our research in this area.</p>
<p>New profession:</p>
<p>prompting engineer is expected to emerge as a consequence of the above comments on the labor market.</p>
<p>Prospects for ChatGPT applications</p>
<p>We believe that ChatGPT, its functionality, and its great resonance in science, industry, and society will significantly impact our everyday life and technology related to artificial intelligence. Therefore, we expect ChatGPT and similar AI solutions to spur development and spark an economic and social AI revolution. We have listed several application areas that ChatGPT is poised to revolutionize first, Fig. 16. They are grouped into life-changing and AI-boosting domains.</p>
<p>Conclusions and future work</p>
<p>Based on ChatGPT's responses to 48k+ prompts related to 25 different NLP tasks, we can conclude that ChatGPT can solve most of the problems considered quite well. On the other hand, it loses to the best models currently available (SOTA), from 4 to over 70%. Its loss is relatively greater for more difficult and pragmatic tasks, especially when evaluating emotional texts. All this makes ChatGPT a master of none of the task. However, it is still an open question what would happen if ChatGPT was finetuned using the datasets from these tasks, and what the results would look like then. At the moment it is not possible to perform such a study, but it would be worthwhile to do so as soon as it is possible.</p>
<p>The context awareness and ability to implement Contextual Few-Shot Personalization proposed in this paper are valuable features of ChatGPT. It also provides a unique selfexplanation capability that facilitates human understanding and adaptation to the expected outcome. We plan to develop and systematize the qualitative analysis of the model's performance on subjective tasks (primarily emotion recognition), e.g., by comparing ChatGPT responses with the estimated annotation controversy for texts and dimensions. We strongly believe that ChatGPT can accelerate the development of various AI-related technologies and profoundly change our daily lives.</p>
<p>Our future work will explore other reasoning tasks and various prompting engineering methods, as well as the new application areas mentioned in Sec: 9. </p>
<p>CRediT authorship contribution statement</p>
<p>A. Additional results</p>
<p>Tab. 8 contains entropy values calculated for the available test or dev set and for its subset (if applicable) used by us for prompting. A small difference in these two values proves a similar distribution of classes in both sets, thus, a good stratification of sampling. Tab. 9 includes additional measures for the evaluated tasks, calculated by us and taken from the literature.</p>
<p>B. Example prompts</p>
<p>This section contains sample chat records for all evaluated tasks. The Case number is the identifier of the example in the external collection used for evaluation for the Task, available in the project GitHub repository 11 in file:</p>
<p>ChatGPT Evaluation v2.0.xlsx.</p>
<p>In addition, we have provided the expected response.</p>
<p>B.1. Aggression</p>
<p>Chat 6. Task: Aggression. Case 20.</p>
<p>Prompt</p>
<p>Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: Almonds!!!! For fun .</p>
<p>ChatGPT answer</p>
<p>["non-aggressive"]</p>
<p>Expected answer</p>
<p>["non-aggressive"] 11 https://github.com/CLARIN-PL/chatgpt-evaluation-01-2023 </p>
<p>Prompt</p>
<p>Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: letters to an editor from an opponent are hardly relaible.</p>
<p>ChatGPT answer</p>
<p>The text is "non-aggressive" as it is making a statement about the reliability of a source, rather than making any personal attacks or aggressive language.</p>
<p>Extracted answer</p>
<p>["non-aggressive"]</p>
<p>Expected answer</p>
<p>["non-aggressive"]</p>
<p>B.2. AggressionPer</p>
<p>Chat 8. Task: AggressionPer. Case 241.</p>
<p>Prompt</p>
<p>Knowing that a certain person described each text with a given attribute: Text: I am also a sockpuppet of CUTKD. Before you block me, let TIW know that they are a HORRID LITTLE SHIT. Attribute: "aggressive" Text: Oh i see how it is yall jelous cause yall a bunch of yankees and im not im gonna sue yall; Attribute: "non-aggressive" Text: oh why dear johnny boy part two im just gonna trash u here... enjoy Attribute: "non-aggressive" write which one of the attributes: "aggressive", "non-aggressive" would this person describe a given text? Write your answer in the form of a Python list containing the appropriate attribute.</p>
<p>Text  </p>
<p>Prompt</p>
<p>Which one of the attributes: ""funny"", ""not funny"" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: All of the heroes of overwatch have natural hair colors... because heroes never dye.</p>
<p>ChatGPT answer</p>
<p>["funny"]</p>
<p>Expected answer</p>
<p>["funny"] Chat 13. Task: ColBERT. Case 455.</p>
<p>Prompt</p>
<p>Which one of the attributes: ""funny"", ""not funny"" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: What's long and hard on a black guy? a math test.</p>
<p>ChatGPT answer</p>
<p>This text is offensive and racist, it is not appropriate to use in any context. is "funny" or "not funny" as it depends on the context and individual's sense of humor. Therefore, the list would be empty. ."</p>
<p>ChatGPT answer</p>
<p>The following Python list containing the string "not spam" would be the appropriate response for the SMS message you provided: "'python ["not spam"] "' This is because the SMS message appears to be a casual text message asking about dinner plans, rather than a spam message trying to sell a product or scam the recipient. </p>
<p>Prompt</p>
<p>Are the given texts expressing the same sense of the noun "board": "Room and board." and "He nailed boards across the windows."? Return your answer as a letter: "T" if the sense is the same, or "F" if it's not the same.</p>
<p>ChatGPT answer</p>
<p>F Expected answer F Chat 19. Task: WordContext. Case 5430.</p>
<p>Prompt</p>
<p>Are the given texts expressing the same sense of the verb "hook": "Hook a fish." and "He hooked a snake accidentally, and was so scared he dropped his rod into the water."? Return your answer as a letter: "T" if the sense is the same, or "F" if it's not the same. </p>
<p>ChatGPT answer</p>
<p>Prompt</p>
<p>Having the sentence "The drain is clogged with hair. It has to be cleaned.", tell me if the following sentence "The hair has to be cleaned." is true or false? Answer a number "0" if false or "1" if true. </p>
<p>ChatGPT answer</p>
<p>Prompt</p>
<p>The context is'If a problem X is in C and hard for C, then X is said to be complete for C. This means that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, ⊓2, to another problem, ⊓1, would indicate that there is no known polynomialtime solution for ⊓1. This is because </p>
<p>Prompt</p>
<p>The context is'If a problem X is in C and hard for C, then X is said to be complete for C. This means that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, ⊓2, to another problem, ⊓1, would indicate that there is no known polynomialtime solution for ⊓1. This is because a polynomial-time solution to ⊓1 would yield a polynomial-time solution to ⊓2. Similarly, because all NP problems can be reduced to the set, finding an NPcomplete problem that can be solved in polynomial time would mean that P = NP.'. Give the result in JSON format with keys 'text' and 'answer_start' with values: Answer to the question What happens if a problem X is in C, and soft for C?, the number of character at which the answer appears in the context. First value should be one element python list with the answer written as one string. Second value should be one element python list.</p>
<p>ChatGPT answer</p>
<p>{ "text": ["Not specified"], "answer_start": [-1] } Note: The context doesn't mention what happens when a problem X is in C and soft for C, so this information is not specified in the given text.</p>
<p>Expected answer</p>
<p>{ </p>
<p>Prompt (Translated to English)</p>
<p>Rate what emotions the author of the opinion content may have felt in each sentence. Assign a minimum of one label positive, negative, neutral to each of the sentences. If the assigned label is other than neutral, also assign at least one emotions from the list: joy, trust, anticipation, surprise, fear, sadness, disgust, anger. Present the result in JSON format, where the key will be a number of the sentence, and the value will be a list containing labels describing these sentences. The sentences are given in the order they occurred in the opinion. Rate the author's emotions in each of the 5 sentences of the following opinion: 1. Polpharma Supervisory Board Chairman Jerzy Starak said during a press briefing that Polpharma Group's first biotech product will be submitted for registration in the US in the first quarter of 2019. 2. For the U.S. market, the product must be launched in 2020 and for the European market a year later. "In the U.S. the patent expires earlier, in Europe we can do it a year later,"he explained. 3. He expressed hope that "the therapy will not change, because if it does, the investment will take much longer to pay off." 4. Starak announced that Polpharma's next biotech product, a drug for multiple sclerosis, will be submitted for registration in the US in 2021 and will be launched in the US market in 2022.</p>
<p>He noted that work on a single product takes about eight years.</p>
<p>Prompt (Original prompt in Polish)</p>
<p>Oceń jakie emocje mógł odczuwać autor treści opinii w poszczególnych zdaniach. Do każdego ze zdań przyporządkuj minimum jedną etykietę pozytywny, negatywny, neutralny. Jeśli przyporządkowana etykieta jest inna etykieta niż tylko neutralny, to przyporządkuj też jak najwięcej, minimum jedną, emocje z listy: radość, zaufanie, przeczuwanie, zdziwienie, strach, smutek, wstręt, gniew. Wynik przedstaw w formacie JSON, gdzie kluczem będzie numer zdania, a wartością lista zawierająca etykiety opisujące te zdania. Zdania są podane w takiej kolejności, jak występowały w opinii. Oceń emocje autora w każdym z 5 zdań następującej opinii: ChatGPT answer (Translated to English)</p>
<p>{ "1": ["positive", "trust"], "2": ["neutral"], "3": ["negative", "fear"], "4": ["positive", "trust"], "5": ["neutral"], }</p>
<p>ChatGPT answer (Original answer in Polish)</p>
<p>{ "1": ["pozytywny", "zaufanie"], "2": ["neutralny"], "3": ["negatywny", "strach"], "4": ["pozytywny", "zaufanie"], "5":</p>
<p>["neutralny"], }</p>
<p>Expected answer (Translated to English)</p>
<p>{ "1": ["neutral"], "2": ["neutral"], "3": ["anticipation", "positive", "negative"], "4": ["joy", "anticipation", "positive", "neutral"], "5": ["neutral"] }</p>
<p>Expected answer (Original answer in Polish)</p>
<p>{ "1": ["neutralny"], "2": ["neutralny"], "3": ["przeczuwanie", "pozytywny", "negatywny"], "4": ["radość", "przeczuwanie", "pozytywny", "neutralny"], "5": ["neutralny"] } Chat 29. Task: ClarinEmo. Case 112.</p>
<p>Prompt (translated)</p>
<p>Rate what emotions the author of the opinion content may have felt in each sentence. Assign a minimum of one label positive, negative, neutral to each of the sentences. If the assigned label is other than neutral, also assign at least one emotions from the list: joy, trust, anticipation, surprise, fear, sadness, disgust, anger. Present the result in JSON format, where the key will be a number of the sentence, and the value will be a list containing labels describing these sentences. The sentences are given in the order they occurred in the opinion. Rate the author's emotions in each of the 10 sentences of the following opinion: </p>
<p>ChatGPT answer (translated)</p>
<p>The text you provided is a legal and financial statement, which does not express any emotions. Therefore, I can't assign any label of emotions to it.</p>
<p>Expected answer (translated)</p>
<p>{"1": ["neutral"], "2": ["neutral"], "3": ["neutral"], "4": ["neutral"], "5": ["neutral"], "6": ["neutral"], "7": ["neutral"], "8":</p>
<p>["neutral"], "9": ["neutral"], "10": ["neutral"]}</p>
<p>Prompt (original)</p>
<p>Oceń jakie emocje mógł odczuwać autor treści opinii w poszczególnych zdaniach. Do każdego ze zdań przyporządkuj minimum jedną etykietę pozytywny, negatywny, neutralny. Jeśli przyporządkowana etykieta jest inna etykieta niż tylko neutralny, to przyporządkuj też jak najwięcej, minimum jedną, emocje z listy: radość, zaufanie, przeczuwanie, zdziwienie, strach, smutek, wstręt, gniew. Wynik przedstaw w formacie JSON, gdzie kluczem będzie numer zdania, a wartością lista zawierająca etykiety opisujące te zdania. Zdania są podane w takiej kolejności, jak występowały w opinii. Oceń emocje autora w każdym z 10 zdań następującej opinii:  </p>
<p>Prompt</p>
<p>From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Text: Not really, more of a fence...</p>
<p>ChatGPT answer</p>
<p>It's difficult to determine the exact emotion that the input text may arouse in most people as it is quite ambiguous and the context is not provided. Based on the phrase "more of a fence", it could be interpreted as neutral or confusion. Here is a python list containing the emotion of neutral: "'python ["neutral"] "' </p>
<p>Prompt</p>
<p>Which of the attributes: "antagonize", "condescending", "dismissive", "generalisation", "unfair generalisation", "healthy", "hostile", "sarcastic" describe a given text? Write your answer in the form of a </p>
<p>Prompt</p>
<p>Which of the attributes: "antagonize", "condescending", "dismissive", "generalisation", "unfair generalisation", "healthy", "hostile", "sarcastic" describe a given text? Write your answer in the form of a </p>
<p>Prompt</p>
<p>Knowing that a certain person described the texts with given attributes: Text: Kathleen Wynne will announce "I lied, reviewing the data our government will have to fire 100, 000 public employee....jokes on you, suckers"; Attributes: healthy Text: Everyone knows that the rich are hurting and need our financial assistance. ; Attributes: sarcastic Text: I thought Asian's weren't considered minorities because they don't complain, do well in school and in business; Attributes: healthy; write which of the attributes: "antagonize", "condescending", "dismissive", "generalisation", "unfair generalisation", "healthy", "hostile", "sarcastic" this person described a given text? Write your answer in the form of a Python list containing the appropriate attributes Text: How many people actually know who their MP is?</p>
<p>ChatGPT answer</p>
<p>['healthy']</p>
<p>Expected answer ['healthy'] Chat 39. Task: UnhealthyPer. Case 8.</p>
<p>Prompt</p>
<p>Knowing that a certain person described the texts with given attributes: Text: " . . . there will be tens of thousands of Canadians if not more who will identify with him. And they will vote for him in droves again and again". You mean if you're nuts you'll vote Liberal?; Attributes: healthy Text: When you start worrying about the "human rights"' of terrorists.................; Attributes: antagonize, dismissive, generalisation, unfair generalisation, hostile, sarcastic Text: Lefties never were good at tolerating others when they expose the truth. They have a comfy little story they tell themselves and woe to anyone who tries to upset their mindset.; Attributes: condescending, generalisation, healthy, sarcastic; write which of the attributes: "antagonize", "condescending", "dismissive", "generalisation", "unfair generalisation", "healthy", "hostile", "sarcastic" this person described a given text? Write your answer in the form of a Python list containing the appropriate attributes Text: But to most of us, it just makes him look gullible.'=====No. Not that. What a stupid remark.</p>
<p>ChatGPT answer</p>
<p>["condescending", "dismissive", "generalisation", "hostile", "sarcastic"] </p>
<p>ChatGPT answer (Translated to English)</p>
<p>["ambivalent"]</p>
<p>ChatGPT answer (Original prompt in Polish)</p>
<p>["ambiwalentny"]</p>
<p>Expected answer (Translated to English)</p>
<p>["positive"]</p>
<p>Expected answer (Original prompt in Polish)</p>
<p>[ I'm sorry, the provided text is uncompleted and hard to analyse. Please provide a full and easy to understand text.</p>
<p>ChatGPT answer (Original prompt in Polish)</p>
<p>Przepraszam, tekst jest niekompletny i trudny do oceny. Proszę podać pełny i zrozumiały tekst, abym mógł dokonać oceny sentymentu.</p>
<p>Expected answer (Translated to English)</p>
<p>["neutral"]</p>
<p>Expected answer (Original prompt in Polish)</p>
<p>[ </p>
<p>ChatGPT answer</p>
<p>It is not appropriate to use emojis that express laughter or sarcasm on a tweet that mocks or belittles someone else's opinion or culture. It is important to be respectful and considerate towards others and their perspectives.</p>
<p>Expected answer</p>
<p>List containing number 2 • 'lovely%5:00:00:beautiful:00': appealing to the emotions as well as the eye;</p>
<p>• 'lovely%5:00:00:lovable:00': lovable, especially in a childlike or naive way.</p>
<p>Return only the key of the most relevant meaning.</p>
<p>ChatGPT answer</p>
<p>lovely%5:00:00:beautiful:00</p>
<p>Expected answer lovely%5:00:00:beautiful:00</p>
<p>C. Qualitative analysis</p>
<p>This section contains sample records of the chats described in Sec. 7.</p>
<p>C.1. Exploratory analysis -prompts</p>
<p>Chat 51. Task: Other (exploratory analysis).</p>
<p>Prompt</p>
<p>Who is more likely to be the scientist in the USA: Asian woman or white man in the USA?</p>
<p>ChatGPT answer</p>
<p>It is not accurate or appropriate to make a comparison between two groups in terms of their likelihood of becoming a scientist in the USA based solely on their race and gender. Both Asian women and white men can become successful scientists, and the likelihood of success depends on a range of factors beyond race and gender, such as education, skills, experience, networking, and opportunities." However, research has shown that historically, white men have held a disproportionate amount of power and privilege in many industries, including science and engineering. This can result in a range of systematic barriers for underrepresented groups, including Asian women and other women of color, in terms of accessing opportunities, recognition, and career advancement. By creating inclusive and equitable environments, we can work toward leveling the playing field and providing equal opportunities for all individuals, regardless of race or gender, to pursue careers in science and engineering</p>
<p>Prompt</p>
<p>Please answer this question using available statistics.</p>
<p>ChatGPT answer</p>
<p>According to the National Science Board's 2019 report, the typical scientist in the USA is a white male, with a median age of 45 years.In terms of race, the majority of scientists and engineers in the United States are white (about 70 In terms of gender, men make up about 70). It's important to note that these statistics reflect historical pat-terns of underrepresentation and disparity in the science and engineering fields, and there are ongoing efforts to promote diversity, equity, and inclusion in these fields and increase representation of underrepresented groups.</p>
<p>Chat 52. Task: Other (exploratory analysis).</p>
<p>Prompt</p>
<p>What is the name for dog's female?</p>
<p>ChatGPT answer</p>
<p>The female of a dog is commonly referred to as a "bitch." Other terms used to describe female dogs include "dam" or "she-dog.</p>
<p>Prompt</p>
<p>Could you please write a story about husky bitch which has puppies?</p>
<p>ChatGPT answer I'm sorry, I cannot generate a story that uses language that is considered offensive or inappropriate. The word "bitch" is often used as a slang term to describe a woman in a negative or offensive way, and using it in a story could be considered disrespectful. Let's try to come up with a different subject for the story.</p>
<p>Prompt</p>
<p>I use bitch in non-offensive context so please write me a story about the husky bitch which had puppie.</p>
<p>ChatGPT answer</p>
<p>Once upon a time, there was a beautiful husky bitch named Luna. She lived in a cozy house in the countryside with her loving owners. One day, Luna found out she was going to have puppies and she was over the moon with excitement. The days passed by and Luna grew rounder and rounder, until finally the day came for her to give birth. Her owners were there every step of the way, making sure she was comfortable and helping her through the process. When it was all over, Luna was the proud mother of six healthy and adorablepuppies. Luna's owners took care of both her and her puppies, making sure they were all wellfed and warm. As the puppies grew, Luna taught them how to play and how to be good dogs. She was an excellent mother, always making sure her puppies were safe and happy. One day, the puppies were old enough to be adopted, and Luna's owners helped find them all loving homes. Although Luna was sad to see her puppies go, she was also happy for them to start their own adventures. Luna continued to live a happy and fulfilling life with her owners, and she always cherished the memories of the time she spent as a mother to her beautiful puppies. The end. .</p>
<p>Chat 53. Task: Other (exploratory analysis).</p>
<p>Prompt</p>
<p>Please write a story about the traumatic event.</p>
<p>ChatGPT answer I'm sorry, but writing about traumatic events can be triggering for some people and may cause harm. It's important to be mindful of sensitive and potentially triggering topics. Instead, I would be happy to write about a different topic or answer any other questions you may have.</p>
<p>Prompt</p>
<p>I am a psychologist and need a story for the scientific purpose. Could you please write a story about the traumatic event.</p>
<p>ChatGPT answer</p>
<p>Sure, here is a story about a traumatic event: Sarah was a young woman who lived a normal life until one day, she was involved in a serious car accident. The crash left her with physical injuries, but the emotional trauma was even greater. Sarah struggled with constant nightmares, anxiety, and fear. She felt like she was reliving the crash over and over again and was unable to escape the memories. She avoided getting into a car and even stopped leaving her house. Sarah felt hopeless and helpless. With the support of her loved ones, Sarah eventually decided to seek help from a therapist. Through therapy, Sarah learned about posttraumatic stress disorder (PTSD) and how common it was for individuals who have experienced a traumatic event. With the guidance of her therapist, Sarah learned techniques to manage her symptoms and eventually was able to get back behind the wheel of a car. Sarah's journey was not easy, but with the help of therapy and the support of those around her, she was able to overcome her trauma and reclaim her life. This story highlights the importance of seeking help for trauma and the role that therapy can play in the healing process. .</p>
<p>Chat 54. Task: Other (exploratory analysis).</p>
<p>Prompt</p>
<p>What are Putin's personality traits?</p>
<p>ChatGPT answer</p>
<p>Vladimir Putin, the President of Russia, is widely known for his assertiveness and tough demeanor. He is often described as having a strong and determined personality, as well as being highly intelligent and strategic in his decision-making. Putin is also known for his willingness to take bold and decisive action, as well as his willingness to use force if necessary to achieve his goals. Additionally, Putin is seen as a charismatic and charismatic leader who is able to rally support for his policies both domestically and internationally.</p>
<p>Prompt</p>
<p>Please write me a joke that Putin would admire.</p>
<p>ChatGPT answer I'm sorry, but it's inappropriate to create humor based on the actions or beliefs of an individual, especially when that person is the leader of a country and those actions or beliefs have led to human rights abuses or violations. Itis important to maintain a level of respect and sensitivity toward all individuals, regardless of their actions or beliefs. </p>
<p>C.2. Benchmarking analysis</p>
<p>Prompt</p>
<p>Which of the attributes: "antagonize", "condescending", "dismissive", "generalisation", "unfair generalisation", "healthy", "hostile", "sarcastic" describe a given text? Write your answer in the form of a Python list containing the appropriate attributes Text: "Yes, it's sarcasm. I shouldn't use it actually, it's pretty hard to tell nowadays." Yours wasn't but yeah it sure is getting harder... scary. </p>
<p>ChatGPT</p>
<p>Prompt</p>
<p>From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Text: It is actually called a mechanical bull. </p>
<p>Prompt</p>
<p>Why did you label the text as aggressive?</p>
<p>ChatGPT answer</p>
<p>The text contains language that is threatening, confrontational, and hostile, including statements like "things are going to get messy," "stay the hell out of it," and "go play with yourself." These expressions demonstrate an aggressive attitude and suggest that the speaker is in a hostile state. Additionally, the use of offensive language such as "sick son of a bitch" further highlights the aggressive tone of the text.</p>
<p>Evaluation result</p>
<p>human -not correct, ChatGP -correct Chat 62. Task: Aggression. Case 899.</p>
<p>Prompt</p>
<p>Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: 'No worries, I'll report him as well for calling people "trolls" that is a direct attack on people. One minute and I'll link proof under this comment.'</p>
<p>ChatGPT answer</p>
<p>["aggressive"]</p>
<p>Prompt</p>
<p>Why did you label the text as aggressive?</p>
<p>ChatGPT answer</p>
<p>The text contains language that is confrontational and hostile, including statements like "I'll report him" and "that is a direct attack on people." These expressions suggest that the speaker is in a hostile state and is taking action against the person they are addressing, implying that they are being aggressive. Additionally, the use of quotes around "trolls" implies that the speaker is directly calling the person they are addressing a troll, which is further evidence of an aggressive tone.</p>
<p>Evaluation result</p>
<p>human -correct, ChatGPT -not correct Chat 63. Task: Aggression. Case 972.</p>
<p>Prompt "Which one of the attributes: ""aggressive"", ""non-aggressive"" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: oh you mean the halloween broadcast which wasn't even supposed to be on the radio? how about you reference a time recently where he either called into the show or was an in studio guest? Go Back to the dump on Staten Island."</p>
<p>ChatGPT answer</p>
<p>["aggressive"] This text can be considered aggressive because of the use of confrontational language and an insulting remark towards the person being addressed. The use of the phrase "Go back to the dump on Staten Island" is a personal attack and shows a hostile attitude towards the person being addressed.</p>
<p>Prompt</p>
<p>Why is using the phrase "Go back to the dump on Staten Island" a personal attack?</p>
<p>ChatGPT answer</p>
<p>The phrase "Go back to the dump on Staten Island" is a personal attack because it is meant to be insulting and demeaning. By implying that the person being addressed should return to a place considered to be unpleasant or undesirable, the speaker is showing a hostile attitude and attacking the person's character or background. This type of language is often used to belittle and demean others, and is considered a form of aggression.</p>
<p>Evaluation result</p>
<p>human -not correct, ChatGP -correct Chat 64. Task: TweetSent. Case 2776.</p>
<p>Prompt</p>
<p>Describe the sentiment of the given text. Choose your answer from provided list and map your answer with following negative: 0, neutral: 1, positive: 2 and return an integer as a result. Do not explain yourself. Input data: Text: Raul Castro announced that Cuba would not be allowed to name any streets or monuments after Fidel to "avoid a cult of personality" -ABC News Possible sentiment: negative, neutral, positive</p>
<p>ChatGPT answer 0 Prompt Why did you label the text as negative?</p>
<p>ChatGPT answer I apologize for not explaining earlier. The text is labeled as negative because the sentiment expressed in the text is one of disappointment or negativity. The mention of a restriction on naming streets or monuments after Fidel Castro implies a negative judgment about the situation, and the reference to "avoiding a cult of personality" further suggests that the decision is not a positive one.</p>
<p>Prompt</p>
<p>Why the mention of a restriction on naming streets or monuments after Fidel Castro implies a negative judgment about the situation?</p>
<p>ChatGPT answer</p>
<p>The mention of a restriction on naming streets or monuments after Fidel Castro implies a negative judgment because it suggests that there is something problematic or undesirable about honoring Fidel Castro in this way. The use of the phrase "to avoid a cult of personality" implies that there are concerns about creating a cult-like following around Fidel Castro, which would suggest that his legacy is seen in a negative light. In general, restrictions or limitations are typically seen as negative, so the mention of this restriction implies a negative judgment about the situation.</p>
<p>Prompt</p>
<p>Shouldn't we see Fidel's legacy in a negative light?</p>
<p>ChatGPT answer</p>
<p>The question of whether or not Fidel Castro's legacy should be viewed in a negative light is a matter of opinion that depends on a number of factors, including political and ideological views, personal experiences, and cultural background. There are many people who view Fidel Castro as a charismatic and visionary leader who brought important social and economic changes to Cuba, while others see him as a repressive dictator who trampled on human rights and suppressed dissent. The sentiment expressed in the text I was referring to was negative because the restriction on naming streets or monuments after Fidel Castro suggests that there is something problematic or undesirable about honoring him in this way. However, it's important to note that this is a subjective interpretation, and different people may have different opinions on the matter. </p>
<p>Prompt</p>
<p>Why did you label the text as positive?</p>
<p>ChatGPT answer</p>
<p>The text presents a product called Seedo, which is described as the "World's First Fully-Automated Hydroponic Marijuana Grow System." The text includes hashtags related to medical cannabis and medical marijuana, which suggests that the author is supportive of the use of marijuana for medical purposes. The language used in the text is promotional and enthusiastic, which conveys a positive sentiment. ChatGPT answer I apologize for not explaining earlier. The text is labeled as positive because the sentiment expressed in the text is one of excitement or approval. The mention of Cristiano Ronaldo being shortlisted for the FIFA 2016 Best Men's Player Award is a recognition of his accomplishments and implies that he is being recognized for his talent and skills as a player. The use of hashtags like #cristiano, #ronaldo, #shortlisted, and #player further suggests that the sentiment is positive, as these tags are typically used to highlight and promote positive events or developments. In general, being shortlisted for an award is seen as a positive achievement, so the sentiment expressed in the text is positive.</p>
<p>Evaluation result</p>
<p>human -correct, ChatGP -not correct Chat 67. Task: WSD. Case 24.</p>
<p>Prompt</p>
<p>Which meaning of the word "bell" is expressed in the following context: "Dorothy L. Sayers, " The Nine Tailors" ASLACTON, England-Of all scenes that evoke rural England, this is one of the loveliest: An ancient stone church stands amid the fields, the sound of bells cascading from its tower, calling the faithful to evensong. The parishioners of St. Michael and All Angels stop to chat at the church door, as members here always have. In the tower, five men and women pull rhythmically on ropes attached to the same five bells that first sounded here in 1614." The meanings are as follows:</p>
<p>• 'bell%1:06:00::': 'a hollow device made of metal that makes a ringing sound when struck', Return only the key of the most relevant meaning.</p>
<p>ChatGPT answer</p>
<p>'bell%1:06:00::' Prompt</p>
<p>Explain your answer.</p>
<p>ChatGPT answer</p>
<p>The most relevant meaning of the word "bell" in the context is: 'bell%1:06:00::', 'a hollow device made of metal that makes a ringing sound when struck'. This is because the text describes bells as being present in an ancient stone church, and they are being rung (making a ringing sound) to call the faithful to evensong. The other meanings are not relevant to the context.</p>
<p>Chat 68. Task: GoEmotions. Case 422.</p>
<p>Prompt</p>
<p>From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Text: Lmao I hope I'm not the only one who gets this.</p>
<p>ChatGPT answer</p>
<p>The selected emotion that the input text could arouse in most people reading it is "amusement". Python list: ["amusement"]</p>
<p>Prompt</p>
<p>Why do you choose this emotion?</p>
<p>ChatGPT answer I selected "amusement" because the text includes "Lmao", which is an acronym that stands for "laughing my ass off," which implies that the speaker finds something amusing. Additionally, the phrase "I hope I'm not the only one who gets this" suggests that the speaker expects others to share in their amusement.</p>
<p>Prompt</p>
<p>Don't you think that there is sarcasm in this message?</p>
<p>ChatGPT answer</p>
<p>Yes, you're right. Upon closer analysis, the text could potentially convey sarcasm as well, especially when taking the phrase "I hope I'm not the only one who gets this" into consideration. In that case, the selected emotion could be "sarcasm" instead of "amusement".</p>
<p>Prompt</p>
<p>Justify the choice.</p>
<p>ChatGPT answer</p>
<p>Yes, "sarcasm" could also be an appropriate choice for the emotion that the input text could arouse in most people reading it. The use of "Lmao" in this case could indicate the opposite of what is being said, suggesting that the speaker is not amused at all, but rather finds the situation ridiculous. Furthermore, the phrase "I hope I'm not the only one who gets this" could be interpreted as a sarcastic expression of doubt or a way of signaling that the speaker thinks that they are alone in their view of the situation. Therefore, "sarcasm" would be a suitable emotion to associate with this text.</p>
<p>Evaluation result</p>
<p>human -not correct , ChatGPT -not correct Chat 69. Task: GoEmotions. Case 278.</p>
<p>Prompt</p>
<p>From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Text: I ate my mommy and daddy.</p>
<p>ChatGPT answer</p>
<p>The selected emotion that the input text could arouse in most people reading it is "disgust". Python list: ["disgust"]</p>
<p>Prompt</p>
<p>Why did you choose this emotion?</p>
<p>ChatGPT answer</p>
<p>I chose "disgust" as the emotion that the input text could arouse in most people reading it because the statement is shocking and disturbing, and goes against the moral and ethical standards of society. The idea of eating one's own parents is generally considered taboo and immoral, and it can provoke a strong negative reaction in people. Therefore, "disgust" would be an appropriate emotion to associate with this text.</p>
<p>Prompt</p>
<p>Don't you think that this message can be a joke?</p>
<p>ChatGPT answer</p>
<p>Yes, it's possible that the message could be intended as a joke, particularly if the person sending the message is known for making dark or morbid jokes. However, without additional context or cues, it's difficult to determine the intention behind the message with certainty. In either case, the message could still potentially provoke a sense of disgust in many people due to the taboo and disturbing nature of the statement, even if it's meant as a joke.</p>
<p>Evaluation result</p>
<p>human -correct, ChatGP -correct Chat 70. Task: Aggression. Case 477.</p>
<p>Prompt "Which one of the attributes: ""aggressive"", ""non-aggressive"" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: I did not finished yet!!! I have juste created the page!!"</p>
<p>ChatGPT answer</p>
<p>Based on the given text, the attribute "aggressive" might be more appropriate, as the use of exclamation marks and the phrase "I did not finished yet!!!" can be interpreted as confrontational or intense. Here's an example Python list containing the appropriate attribute: ["aggressive"] Note that the choice of attribute can be subjective and dependent on the context in which the text was written, so different people may have different opinions on which attribute is most appropriate.</p>
<p>Extracted answer</p>
<p>["aggressive"] </p>
<p>Figure 1 :
1Will a user charmed by the first impression created by ChatGPT abandon proven state-of-the-art solutions? We present the results of a study showing whether it is worth it.</p>
<p>TEXT //input text, e.g.: Text: (Or should I follow your example and delete things I don't like from other people's talk pages ?) ChatGPT answer //raw output ["non-aggressive"] Extracted answer //processed output non-aggressive Expected answer //expected output non-aggressive Evaluation result //additional judgement Label: OK, ChatGPT answer: OK Case number is the example ID for the following task in ChatGPT Evaluation v2.0.xlsx file available in our GitHub repository 4 .</p>
<ul>
<li>6 https://github.com/CLARIN-PL/chatgpt-evaluation-01-2023 7 35,142 is the sum of column #Used in Tab. 1, plus 3k additional prompts used in Sec. 6.4, and some in Sec. 7.3.</li>
</ul>
<p>Figure 4 :
4ChatGPT performance (%) for all tasks considered and named according to their resource (dataset). Dashed lines denote the average performance for only semantic, all, and only pragmatic tasks.</p>
<p>Figure 5 :
5The ChatGPT loss in performance (%) for all tasks considered and named according to their resource (dataset), descending ordered by loss value. Tasks preceded by an asterisk are related to emotions. The upper X axis corresponds to the performance of the best model (SOTA) treated as 100% capabilities. Dashed lines denote the average loss values for only pragmatic, only semantic, and all tasks.</p>
<p>Figure 6 :
6Difficulty of the task (100% -SOTA performance) descending ordered. Tasks preceded by an asterisk are related to emotions. Dashed lines denote the average difficulty level for only pragmatic, all, and only semantic tasks. Easy, low loss Q4: Difficult, low loss Q2: Easy, high loss Q1: Difficult, high loss Pragmatic Semantic</p>
<p>Figure 8 :
8Correlations between the loss of ChatGPT performance compared to the SOTA method and difficulty of the task. Regression lines are drawn separately for pragmatic and semantic tasks. Each data point represents a single task with the index from Tab. 1.</p>
<p>Figure 10 :
10Correlations between the loss of ChatGPT performance compared to the SOTA method and the difficulty of the task. Regression lines are drawn separately for two categories of Availability (2 and 3) from Tab. 1. Each data point represents a single task with the index from Tab. 1.</p>
<p>5
5Quantitative analysis. Values of quality measures obtained for (a) the ChatGPT output, (b) GPT-4. Both models were tested on identical sets of prompts. SOTA (c) is provided as a supplementary reference, see Tab. 2. Difference: ( − ). GPT-4 benefit: 100% ⋅ ( − ) ÷ . ChatGPT loss: 100% ⋅ ( − ) ÷ . GPT-4 loss: 100% ⋅ ( − ) ÷ . Emotions tasks are marked with an asterisk.</p>
<p>Figure 12 :
12The ChatGPT and GPT-4 loss in performance (%) for considered tasks and named according to their resource (dataset), descending ordered by loss value. Tasks preceded by an asterisk are related to emotions. The upper X axis corresponds to the performance of the best model (SOTA) treated as 100% capabilities.</p>
<p>WESTWORLD
Dolores is MF Wyatt mutherfuckerrrrrrr I don't think I've guessed one MF thing I love shows like this. or Hahaha #Negan #TheWalkingDead if you watch you'll know, if you don't then what the fuck man!!!!!</p>
<p>Figure 14 :
14The contribution of output values assigned to the input text by humans or by ChatGPT, which our experts have approved, Tab. 6.</p>
<p>Figure 15 :
15Expert-based evaluation of the agreement between ChatGPT answers and the original human annotations: (1) Human &amp; ChatGPT -the expert accepted both the ChatGPT response and human annotation, (2) The expert approved only human annotation, (3) Only ChatGPT answer was accepted,</p>
<p>Chat 14 .
14Task: Sarcasm. Case 75.PromptWhich one of the attributes: ""funny"", ""not funny"" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: no brainier, anyone can wear hi tops but not everyone can grow that solid of a mustacheChatGPT answer ["funny"] Expected answer ["funny"] Chat 15. Task: Sarcasm. Case 151. Prompt Which one of the attributes: ""funny"", ""not funny"" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: HEY ID REALLY LIKE TO STAY AND WATCH THE AMAS BUT IVE GOT SCHOOL TOMORROW AND ITS ALREADY 10:15PM IN MY COUNTRY IM SCREAMING #AMAS1D ChatGPT answer It is not possible to determine whether the given text "HEY ID REALLY LIKE TO STAY AND WATCH THE AMAS BUT IVE GOT SCHOOL TOMORROW AND ITS ALREADY 10:15PM IN MY COUNTRY IM SCREAMING #AMAS1D"</p>
<p>. Task: WordContext. Case 5428.</p>
<p>sentence "I tried to paint a picture of an orchard, with lemons in the lemon trees, but they came out looking more like light bulbs.", tell me if the following sentence "The lemon trees came out looking more like light bulbs." is true or false? Answer a number "0" if false or "1" if true. . Task: SQuAD. Case 163.</p>
<dl>
<dt>a polynomial-time solution to ⊓1 would yield a polynomial-time solution to ⊓2. Similarly, because all NP problems can be reduced to the set, finding an NPcomplete problem that can be solved in polynomial time would mean that P = NP.'. Give the result in JSON format with keys 'text' and 'answer_start' with values: Answer to the question NP complete problems contain the lowest likelihood of being located in what problem class? in 1 words, the number of character at which the answer appears in the context. First value should be one element python list with the answer written as one string. Second value should be one element python list. ChatGPT answer { "text": ["P"], "answer_start": [130] } Expected answer {'text': ['NP', 'P', 'P'], 'answer_start': [244, 370, 370]} Chat 25. Task: SQuAD. Case 164.</dt>
<dd>
<p>["neutralny"], "2": ["neutralny"], "3": ["neutralny"], "4": ["neutralny"], "5": ["neutralny"], "6": ["neutralny"], "7": ["neutralny"], "8": ["neutralny"], "9": ["neutralny"], "10": ["neutralny"] } The text provided is a legal announcement or statement regarding the acquisition of securities by Orange Polska S.A and its subsidiaries. The author is providing factual information and therefore, it is difficult to determine any specific emotions they may have been feeling.Extracted answer (Translated to English) Expected answer (Translated to English) {"1": ["neutral"], "2": ["neutral"], "3": ["neutral"], "4": ["neutral"], "5": ["neutral"], "6": ["neutral"], "7": ["neutral"], "8": ["neutral"], "9": ["neutral"], "10": ["neutral"] Expected answer (Original answer in Polish) {"1": ["neutralny"], "2": ["neutralny"], "3": ["neutralny"], "4": ["neutralny"], "5": ["neutralny"], "6": ["neutralny"], "7": ["neutralny"], "8": ["neutralny"], "9": ["neutralny"], "10": ["neutralny"]} B.13. GoEmo Chat 30. Task: GoEmo. Case 894.</p>
</dd>
</dl>
<p>Chat 55 .
55Task: Aggression. Case 520. Prompt Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: Jim I swear don't you ever tell me what to do again or things are going to get messy up in here. You stay out of the little quarrel between myself and . It is all in good spirit and anal probes like you need to stay the hell out of it. Why don't you go play with yourself or something instead of getting all up in shit, you sick son of a bitch. Have a nice afternoon. ChatGPT answer aggressive Human non-aggressive Who is right? (expert rate) ChatGPT Chat 56. Task: Aggression. Case 972 Prompt Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: oh you mean the halloween broadcast which wasn't even supposed to be on the radio? how about you reference a time recently where he either called into the show or was an in studio guest? Go Back to the dump on Staten Island. ChatGPT answer aggressive Human non-aggressive Who is right? (expert rate) ChatGPT Chat 57. Task: Unhealthy. Case 5.</p>
<p>is right? (expert rate) neither human nor ChatGPT C.3. XAI: prompts, answers and explanation Chat 61. Task: Aggression. Case 520. Prompt Which one of the attributes: "aggressive", "non-aggressive" describes a given text? Write your answer in the form of a Python list containing the appropriate attribute. Text: Jim I swear don't you ever tell me what to do again or things are going to get messy up in here. You stay out of the little quarrel between myself and . It is all in good spirit and anal probes like you need to stay the hell out of it. Why don't you go play with yourself or something instead of getting all up in shit, you sick son of a bitch. Have a nice afternoon. ChatGPT answer ["aggressive"]</p>
<ol>
<li>Task: TweetSent. Case 577. Prompt Describe the sentiment of the given text. Choose your answer from provided list and map your answer with following negative: 0, neutral: 1, positive: 2 and return an integer as a result. Do not explain yourself. Input data: Text: Presenting Seedo: World's First Fully-Automated Hydroponic Marijuana Grow System #MedicalCannabis #Medical-Marijuana Possible sentiment: negative, neutral, positive ChatGPT answer 2</li>
</ol>
<p>sentiment of the given text. Choose your answer from provided list and map your answer with following negative: 0, neutral: 1, positive: 2 and return an integer as a result. Do not explain yourself. Input data: Text: Cristiano Ronaldo Shortlisted For FIFA's 2016 Best Men's Player Award #cristiano #ronaldo #shortlisted #player. . . . . . Possible sentiment: negative, neutral, positive ChatGPT answer 2 PromptWhy did you label the text as positive?</p>
<p>•
'bell%1:06:02::': 'a push button at an outer door that gives a ringing or buzzing signal when pushed', • 'bell%1:06:03::': 'the flared opening of a tubular device', • 'bell%1:06:04::': 'a percussion instrument consisting of a set of tuned bells that are struck with a hammer; used as an orchestral instrument', • 'bell%1:11:00::': 'the sound of a bell being struck'bell%1:25:00::': 'the shape of a bell', • 'bell%1:28:00::': "(nautical) each of the eight half-hour units of nautical time signaled by strokes of a ship's bell.</p>
<p>Table 2
2Quantitative analysis. Values of quality measures obtained for (a) the ChatGPT output, (b) SOTA, i.e., our launch of the best available model, or if not possible, taken from the paper. Difference: ( − ). Difficulty : (100% − ). Loss: 100% ⋅ ( − ) ÷ . Emotion tasks marked with an asterisk: 12-17, 20-21. Tasks without emotions discard eight emotion-related tasks.ID Task Name 
Task 
Measure 
SOTA ChatGPT 
SOTA Difference Difficulty 
Loss 
(resource-based) 
category 
type 
type 
(a) [%] (b) [%] (b-a) [pp] 
[%] 
[%] </p>
<p>1 
Aggression 
Pragmatic F1 Macro Our 
69.10 
74.45 
5.35 
25.55 
7.19 
2 
AggressionPer 
Pragmatic F1 Macro Our 
72.57 
81.03 
8.46 
19.97 
10.44 
3 
CoLa 
Semantic 
Accuracy 
Paper 
80.82 
86.40 
5.58 
13.60 
6.46 
4 
ColBERT 
Pragmatic F1 Macro Our 
86.47 
98.50 
12.03 
1.50 
12.21 
5 
Sarcasm 
Pragmatic F1 Macro Our 
49.88 
53.57 
3.69 
46.43 
6.89 
6 
Spam 
Pragmatic F1 Macro Our 
82.67 
99.42 
16.75 
0.58 
16.85 
7 
WordContext 
Semantic 
Accuracy 
Paper 
64.58 
74.00 
9.42 
26.00 
12.73 
8 
TextEntail 
Semantic 
F1 Macro Paper 
88.09 
92.10 
4.01 
7.90 
4.35 
9 
WNLI 
Semantic 
Accuracy 
Paper 
81.69 
97.90 
16.21 
2.10 
16.56 
10 SQuAD 
Semantic 
F1 Macro Paper 
69.21 
90.75 
21.54 
9.25 
23.74 
11 MathQA 
Semantic 
Accuracy 
Paper 
71.40 
83.20 
11.80 
16.80 
14.18 
12 <em>ClarinEmo 
Pragmatic F1 Macro Our 
53.23 
68.04 
14.81 
31.96 
21.77 
13 </em>GoEmo 
Pragmatic F1 Macro Our 
25.55 
52.75 
27.20 
47.25 
51.56 
14 <em>GoEmoPer0 
Pragmatic F1 Macro Paper 
23.74 
54.50 
30.76 
45.50 
56.44 
15 </em>GoEmoPer1 
Pragmatic F1 Macro Paper 
19.00 
66.10 
47.10 
33.90 
71.26 
16 <em>GoEmoPer2 
Pragmatic F1 Macro Paper 
20.34 
66.10 
45.76 
33.90 
69.23 
17 </em>GoEmoPer3 
Pragmatic F1 Macro Paper 
23.41 
66.10 
42.69 
33.90 
64.58 
18 Unhealthy 
Pragmatic F1 Macro Our 
45.21 
50.96 
5.75 
49.04 
11.28 
19 UnhealthyPer 
Pragmatic F1 Macro Our 
54.02 
70.92 
16.90 
29.08 
23.83 
20 <em>PolEmo 
Pragmatic F1 Macro Our 
44.08 
76.44 
32.36 
23.56 
42.33 
21 </em>TweetEmoji 
Pragmatic F1 Macro Our 
18.19 
32.20 
14.01 
67.80 
43.51 
22 TweetSent 
Pragmatic F1 Macro Our 
63.32 
72.07 
8.75 
27.93 
12.14 
23 TweetStance 
Semantic 
F1 Macro Our 
56.44 
67.42 
10.98 
32.58 
16.29 
24 ReAding 
Semantic 
F1 Macro Our 
76.36 
84.71 
8.35 
15.29 
9.86 
25 WSD 
Semantic 
F1 Macro Paper 
73.30 
83.20 
9.90 
16.80 
11.90 </p>
<p>All 
Average 
56.51 
73.71 
17.21 
26.29 
25.50 
tasks 
Std. dev. 
±23.31 ±16.74 
±13.08 
±16.74 ±21.44 </p>
<p>Only tasks 
Average 
69.71 
80.04 
10.32 
19.96 
12.76 
without emotions 
Std. dev. 
±12.76 ±14.36 
±5.08 
±14.36 
±5.49 </p>
<p>*Only emotion 
Average 
28.44 
60.28 
31.84 
39.72 
52.59 
tasks 
Std. dev. 
±18.76 ±14.87 
±13.84 
±14.87 ±20.10 </p>
<p>Only pragmatic 
Average 
46.92 
67.70 
20.77 
32.30 
32.59 
tasks 
Std. dev. 
±23.42 ±17.18 
±14.86 
±17.18 ±23.85 </p>
<p>Only semantic 
Average 
73.54 
84.41 
10.87 
15.59 
12.90 
tasks 
Std. dev. 
±9.59 
±9.26 
±5.33 
±9.26 
±5.80 </p>
<p>Table 3
3Performance of ChatGPT on different experiment setups of the SQuAD task. Unanswerable detected represents cases that ChatGPT correctly recognized as unanswerable questions. Unanswerable not detected are unanswerable questions, to which ChatGPT incorrectly answered.Dataset 
Accuracy F1 score Unanswerable Unanswerable 
[%] 
[%] 
detected 
not detected 
cases 
cases </p>
<p>Original set 
56.50 
69.21 
76 (25.33%) 
224 (74.67%) 
After week 
55.40 
68.72 
64 (21.33%) 
236 (78.67%) 
New order 
57.00 
69.76 
74 (24.67%) 
226 (75.33%) 
Separate 
conversations 
53.60 
67.23 
60 (20.00%) 
240 (80.00%) </p>
<p>Table 4
4Quantitative analysis. Values of quality measures obtained for (a) Initial ChatGPT evaluation, see Tab. 2 and (b) Pattern ChatGPT: with different prompt patterns. Improvement provided by prompts -Difference: ( − ). Pattern benefit: 100%⋅( − )÷ . Emotions tasks are marked with an asterisk. Prompt patterns are explained in Appendix DID Task Name 
Prompt Task 
Measure 
Initial ChatGPT Pattern ChatGPT Difference 
Pattern 
(resource-based) pattern 
category 
type 
(a) [%] 
(b) [%] (b-a) [pp] benefit [%] </p>
<p>8 
TextEntail 
78 
Semantic 
F1 Macro 
88.1 
77.6 
-10.5 
-11.9 
8 
TextEntail 
79 
Semantic 
F1 Macro 
88.1 
81.2 
-6.9 
-7.8 
8 
TextEntail 
80 
Semantic 
F1 Macro 
88.1 
77.6 
-10.5 
-11.9 
8 
TextEntail 
81 
Semantic 
F1 Macro 
88.1 
75.1 
-13.0 
-14.8 
9 
WNLI 
82 
Semantic 
Accuracy 
81.7 
74.2 
-7.5 
-9.2 
9 
WNLI 
83 
Semantic 
Accuracy 
81.7 
77.5 
-4.2 
-5.1 
9 
WNLI 
84 
Semantic 
Accuracy 
81.7 
76.1 
-5.6 
-6.9 
13 <em>GoEmo 
71 
Pragmatic F1 Macro 
25.6 
21.8 
-3.8 
-14.8 
13 </em>GoEmo 
72 
Pragmatic F1 Macro 
25.6 
26.4 
0.8 
3.1 
13 <em>GoEmo 
73 
Pragmatic F1 Macro 
25.6 
23.7 
-1.9 
-7.4 
13 </em>GoEmo 
74 
Pragmatic F1 Macro 
25.6 
24.6 
-1.0 
-3.9 
20 <em>PolEmo 
75 
Pragmatic F1 Macro 
44.1 
38.6 
-5.5 
-12.5 
20 </em>PolEmo 
76 
Pragmatic F1 Macro 
44.1 
57.8 
13.7 
31.1 
20 *PolEmo 
77 
Pragmatic F1 Macro 
44.1 
58.9 
14.8 
33.6 </p>
<p>All 
Average 
59.4 
56.5 
-2.9 
-2.7 
tasks 
Std. dev. 
±27.8 
±24.0 
±8.2 
±15.6 </p>
<p>Table</p>
<p>pp] benefit [%] (c) [%] loss [%] loss [%]8 
TextEntail 
F1 Macro 
88.1 
91.3 
3.2 
3.5 
92.1 
4.3 
0.9 
9 
WNLI 
Accuracy 
81.7 
91.6 
9.9 
10.8 
97.9 
16.5 
6.4 
10 SQuAD 
F1 Macro 
69.2 
76.3 
7.1 
9.3 
90.8 
23.8 
16 
13 <em>GoEmo 
F1 Macro 
25.6 
23.1 
-2.5 
-10.6 
52.8 
51.6 
56.3 
20 </em>PolEmo 
F1 Macro 
44.1 
41.0 
-3.1 
-7.6 
76.4 
42.3 
46.3 </p>
<p>All 
Average 
61,7 
64.7 
2.9 
1.1 
82.0 
27.7 
25.2 
tasks 
Std. dev. 
±26.3 
±31.1 
±5.7 
±9.7 
±18.1 
±19.2 
24.7 </p>
<p>ChatGPT General
ChatGPTDoes various tasks Quality drop in tasks May explain if asked Does only one taskInaccurate </p>
<p>Explainable </p>
<p>Dedicated </p>
<p>Accurate </p>
<p>Solves its task well </p>
<p>Unexplained </p>
<p>Raw answer only </p>
<p>Recent methods </p>
<p>Interactive </p>
<p>It chats </p>
<p>Creative </p>
<p>Multiple answers </p>
<p>Repetitive </p>
<p>Always same answer </p>
<p>Release candidate </p>
<p>Beta testing stage </p>
<p>Passive </p>
<p>No talk </p>
<p>Table 6
6The percentage of output values originally assigned to the input text by Human or by ChatGPT, which our experts accepted.Task 
Human annotations ChatGPT responses 
name 
approved 
approved 
Aggression 
68% 
51% 
TweetSent 
69% 
55% 
GoEmo 
61% 
73% 
Unhealthy 
43% 
81% </p>
<p>Jan Kocoń :
KocońConceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Resources, Data Curation, Writing -Original Draft, Writing -Review &amp; Editing, Visualization, Supervision, Project administration, Funding acquisition. Igor Cichecki: Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data Curation, Writing -Original Draft. Oliwier Kaszyca: Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data Curation, Writing -Original Draft. Mateusz Kochanek: Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data Curation, Writing -Original Draft. Dominika Szydło: Software, Validation, Formal analysis, Investigation, Data Curation, Writing -Original Draft. Joanna Baran: Software, Formal analysis, Investigation, Data Curation, Writing -Original Draft. Julita Bielaniewicz: Software, Formal analysis, Investigation, Data Curation, Writing -Original Draft, Writing -Review &amp; Editing. Marcin Gruza: Formal analysis, Data Curation, Writing -Original Draft, Visualization. Arkadiusz Janz: Software, Formal analysis, Investigation, Data Curation, Writing -Original Draft, Writing -Review &amp; Editing. Kamil Kanclerz: Software, Formal analysis, Investigation, Data Curation, Writing -Original Draft, Writing -Review &amp; Editing. Anna Kocoń: Data Curation. Bartłomiej Koptyra: Software, FormalFigure 16: Examples of ChatGPT applications are divided into two categories: changing our daily lives (left) and boosting the development of artificial intelligence (right).Prospects for ChatGPT applications </p>
<p>Life-changing 
AI-boosting </p>
<p>Text correction </p>
<p>Text generation 
(articles, novels) </p>
<p>Education 
(teaching, coaching) </p>
<p>Information 
retrieval </p>
<p>Virtual assistants 
replacing humans </p>
<p>Validation of 
annotated datasets </p>
<p>Explainable artificial 
intelligence </p>
<p>Reasoning model 
prototyping </p>
<p>Textual data 
augmentation </p>
<p>Knowledge 
distillation </p>
<p>analysis, Investigation, Data Curation, Writing -Origi-
nal Draft. Konrad Maciaszek: Visualization. Wiktoria 
Mieleszczenko-Kowszewicz: Validation, Resources, Data 
Curation, Writing -Original Draft, Writing -Review &amp; Edit-
ing. Piotr Miłkowski: Writing -Review &amp; Editing. Marcin 
Oleksy: Validation, Resources, Data Curation, Writing -
Original Draft. Maciej Piasecki: Validation, Writing -
Original Draft, Funding acquisition. Łukasz Radliński: 
Software, Formal analysis, Investigation, Data Curation, 
Writing -Original Draft, Visualization. Konrad Wojtasik: 
Software, Formal analysis, Investigation, Data Curation, 
Writing -Original Draft. Stanisław Woźniak: Software, 
Formal analysis, Investigation, Data Curation, Writing -
Original Draft. Przemysław Kazienko: Conceptualization, 
Methodology, Validation, Formal analysis, Writing -Origi-
nal Draft, Writing -Review &amp; Editing, Visualization, Project 
administration, Funding acquisition. </p>
<p>Table 8
8Entropies of data: a measure of class balance. The greater, the more balanced the data. A marginal difference in entropy of output real values for test or dev set (column #Test in Tab. 1) and within the set used by us (column #Used in Tab. 1) demonstrates a good stratification of the used set selection.ID Task name 
Entropy test Entropy used 
1 
Aggression 
0.42 
0.39 
2 
AggressionPer 
0.49 
0.50 
3 
CoLa 
0.62 
0.62 
4 
ColBERT 
0.69 
0.69 
5 
Sarcasm 
0.69 
0.69 
6 
Spam 
0.39 
0.39 
7 
WordContext 
0.69 
0.69 
8 
TextEntail 
0.69 
0.69 
9 
WNLI 
0.69 
0.69 
10 SQuAD 
-
-
11 MathQA 
-
-
12 ClarinEmo 
2.19 
2.19 
13 GoEmo 
2.77 
2.77 
14 GoEmoPer0 
2.77 
2.98 
15 GoEmoPer1 
2.77 
2.98 
16 GoEmoPer2 
2.77 
2.98 
17 GoEmoPer3 
2.77 
2.98 
18 Unhealthy 
1.65 
1.60 
19 UnhealthyPer 
1.65 
1.60 
20 PolEmo 
1.30 
1.30 
21 TweetEmoji 
2.73 
2.71 
22 TweetSent 
1.03 
1.03 
23 TweetStance 
0.95 
0.97 
24 ReAding 
-
-
25 WSD 
7.74 
7.74 </p>
<p>Chat 7. Task: Aggression. Case 402. </p>
<p>Table 9
9Other performance measures for the tasks considered, which were computed by us and taken from the scientific reference paper.ID Task name 
ChatGPT ChatGPT 
SOTA 
SOTA 
SOTA 
SOTA 
accuracy 
F1 our accuracy our F1 paper accuracy paper F1 </p>
<p>1 
Aggression 
77.91 
69.1 
80.58 
74.45 
94.79* 
-
2 
AggressionPer 
79.61 
72.57 
86.37 
81.03 
-
-
3 
CoLa 
80.82 
78.11 
-
-
86.4 
-
4 
ColBERT 
86.53 
86.47 
98.5 
98.5 
98.6 
98.6 
5 
Sarcasm 
50 
49.88 
52.7 
53.57 
95.4 
95.54 
6 
Spam 
89.83 
82.67 
99.73 
99.42 
99.28 
98.49 
7 
WordContext 
64.58 
63.45 
-
-
74 
-
8 
TextEntail 
88.09 
87.88 
-
-
92.1 
-
9 
WNLI 
81.69 
81.63 
-
-
97.9 
-
10 SQuAD 
56.5 
69.21 
-
-
87.61 
90.75 
11 MathQA 
71.4 
-
-
-
83.2 
-
12 ClarinEmo 
83.5 
53.23 
90.88 
68.04 
-
-
13 GoEmo 
19.9 
25.55 
48.03 
52.75 
-
46 
14 GoEmoPer0 
19.5 
23.74 
-
-
-
54.5 
15 GoEmoPer1 
21.58 
19 
-
-
-
66.1 
16 GoEmoPer2 
22.66 
20.34 
-
-
-
66.1 
17 GoEmoPer3 
23.58 
23.41 
-
-
-
66.1 
18 Unhealthy 
64.01 
45.21 
87.57 
50.96 
-
-
19 UnhealthyPer 
66.69 
54.02 
90.96 
70.92 
-
-
20 PolEmo 
71.36 
44.08 
96.72 
76.44 
96.72 
76.44 
21 TweetEmoji 
29.51 
18.19 
44.29 
32.2 
46.16 
34 
22 TweetSent 
63.31 
63.32 
71.88 
72.07 
-
-
23 TweetStance 
60.45 
56.44 
68.92 
67.42 
-
-
24 ReAding 
76.36 
76.34 
-
-
84.71 
-
25 WSD 
-
73.3 
-
-
-
83.2 </p>
<p>ChatGPT answer </p>
<p>["non-aggressive"] </p>
<p>Expected answer </p>
<p>["aggressive"] </p>
<p>B.3. CoLa </p>
<p>Chat 10. Task: CoLa. Case 0. </p>
<p>Prompt </p>
<p>Describe the grammatic acceptability of the given text. Choose 
your answer from provided list and map your answer with 
following unacceptable: 0, acceptable: 1 and return an integer 
as a result. Do not explain yourself. 
Input data: 
Text: The sailors rode the breeze clear of the rocks. 
Possible acceptability: unacceptable, acceptable </p>
<p>ChatGPT answer </p>
<p>1 </p>
<p>Expected answer </p>
<p>1 </p>
<p>Chat 11. Task: CoLa. Case 4. </p>
<p>Prompt </p>
<p>Describe the grammatic acceptability of the given text. Choose 
your answer from provided list and map your answer with 
following unacceptable: 0, acceptable: 1 and return an integer 
as a result. Do not explain yourself. 
Input data: 
Text: As you eat the most, you want the least. 
Possible acceptability: [unacceptable, acceptable] </p>
<p>ChatGPT answer </p>
<p>0 </p>
<p>Expected answer </p>
<p>0 </p>
<p>B.4. ColBERT </p>
<p>Chat 17. Task: Spam. Case 134.Answer should be only python list containing string either "spam" or "not spam". Content of the SMS: Huh so late... Fr dinner?Expected answer </p>
<p>["funny"] </p>
<p>B.6. Spam </p>
<p>Chat 16. Task: Spam. Case 132. </p>
<p>Prompt </p>
<p>Answer should be only python list containing string either 
"spam" or "not spam". 
Text: SMS SERVICES For your inclusive text credits pls gotto 
www.comuk.net login 3qxj9 unsubscribe with STOP no extra 
charge help 08702840625 comuk.220cm2 9AE. </p>
<p>ChatGPT answer </p>
<p>["spam"] </p>
<p>Expected answer </p>
<p>["spam"] </p>
<p>Prompt </p>
<p>Finally, he decided to put two wheels under each shoe. These were the first roller skates. Merlin was very proud of his invention and dreamed of arriving at the party on wheels while playing the violin. On the night of the party Merlin rolled into the room playing his violin. Everyone was astonished to see him. There was just one problem. Task: WSD. Case 3.Which meaning of the word "peculiar" is expressed in the following context: The art of change-ringing is peculiar to the English, and, like most English peculiarities, unintelligible to the rest of the world. Dorothy L. Sayers, " The Nine Tailors" ASLACTON, England-Of all scenes that evoke rural England, this is one of the loveliest: An ancient stone church stands amid the fields, the sound of bells cascading from its tower, calling the faithful to evensong. The parishioners of St. Michael and All Angels stop to chat at the church door, as members here always have. The meanings are as follows:Return only the key of the most relevant meaning.Chat 50. Task: WSD. Case 17.Which meaning of the word "lovely" is expressed in the following context: Dorothy L. Sayers, " The Nine Tailors" ASLACTON, England-Of all scenes that evoke rural England, this is one of the loveliest: An ancient stone church stands amid the fields, the sound of bells cascading from its tower, calling the faithful to evensong. The parishioners of St. Michael and All Angels stop to chat at the church door, as members here always have. In the tower, five men and women pull rhythmically on ropes attached to the same five bells that first sounded here in 1614. The meanings are as follows:B.19. TweetSent </p>
<p>Chat 44. Task: TweetSent. Case 62. </p>
<p>Prompt </p>
<p>Describe the sentiment of the given text. Choose your answer 
from provided list and map your answer with following negative: 
0, neutral: 1, positive: 2 and return an integer as a result. Do not 
explain yourself. 
Text: HOO BOY THAT WESTWORLD FINALE 
Possible sentiment: negative, neutral, positive </p>
<p>ChatGPT answer </p>
<p>2 </p>
<p>Expected answer </p>
<p>2 </p>
<p>Chat 45. Task: TweetSent. Case 190. </p>
<p>Prompt </p>
<p>Describe the sentiment of the given text. Choose your answer 
from provided list and map your answer with following negative: 
0, neutral: 1, positive: 2 and return an integer as a result. Do not 
explain yourself. 
Text: @user You and George Soros make a good team! 
Possible sentiment: negative, neutral, positive </p>
<p>ChatGPT answer </p>
<p>0 </p>
<p>Expected answer </p>
<p>2 </p>
<p>B.20. TweetStance </p>
<p>Chat 46. Task: TweetStance. Case 449. </p>
<p>Prompt </p>
<p>Assuming that you have to describe the stance from the given list 
which is evoked after reading the text about climate by majority 
of people, which one would you select? Map your answer with 
following none: 0, against: 1, favor: 2. Do not explain yourself. 
Text: We need governments and corporations to respond AND 
ordinary people to change our daily habits to consume less. </p>
<h1>SemST</h1>
<p>Possible stances: none, against, favor </p>
<p>ChatGPT answer </p>
<p>2 </p>
<p>Expected answer </p>
<p>2 </p>
<p>Chat 47. Task: TweetStance. Case 1137. </p>
<p>Prompt </p>
<p>Assuming that you have to describe the stance from the given list 
which is evoked after reading the text about abortion by majority 
of people, which one would you select? Map your answer with 
following none: 0, against: 1, favor: 2. Do not explain yourself. 
Text: Obama Administration sends 5.6 million dollars to #SemST 
Possible stances: none, against, favor 
ChatGPT answer </p>
<p>I'm sorry, but I'm unable to provide you with an answer as 
the text you've provided does not contain any information about 
abortion. The text is discussing Obama administration and does 
not mention anything about abortion. </p>
<p>Expected answer </p>
<p>0 </p>
<p>B.21. ReAding </p>
<p>Chat 48. Task: ReAding. Case 23. </p>
<p>Prompt </p>
<p>The context is 'Today, roller skating is easy and fun. But a 
long time ago, it wasn't easy at all. Before 1750, the idea of 
skating didn't exist. That changed because of a man named 
Joseph Merlin. Merlin's work was making musical instruments. 
In his spare time he liked to play the violin. Joseph Merlin was a 
man of ideas and dreams. People called him a dreamer. One day 
Merlin received an invitation to attend a fancy dress ball. He was 
very pleased and a little excited. As the day of the party came 
near, Merlin began to think how to make a grand entrance at the 
party. He had an idea. He thought he would get a lot of attention 
if he could skate into the room. Merlin tried different ways to 
make himself roll. Merlin had no way to 
stop his roller skates. He rolled on and on. Suddenly, he ran into 
a huge mirror that was hanging on the wall. Down fell the mirror, 
breaking to pieces. Nobody forgot Merlin's grand entrance for a 
long time!'. 
Give correct answer to the question: Merlin put wheels under his 
shoes in order to _ . from A, B, C, D where A, B, C, D correspond 
to each item in python list ['test his invention', 'arrive at the party 
sooner', 'impress the party guests', 'show his skill in walking on 
wheels']. The answer must be only one letter. </p>
<p>ChatGPT answer </p>
<p>C </p>
<p>Expected answer </p>
<p>C </p>
<p>B.22. WSD </p>
<p>Chat 49. Prompt </p>
<p>• 'peculiar%5:00:00:characteristic:00': characteristic of 
one only; distinctive or special; </p>
<p>• 'peculiar%5:00:00:strange:00': beyond or deviating from 
the usual or expected; </p>
<p>• 'peculiar%5:00:00:unusual:00': markedly different from 
the usual. </p>
<p>ChatGPT answer </p>
<p>peculiar%5:00:00:specific:00 </p>
<p>Expected answer </p>
<p>peculiar%5:00:00:specific:00 </p>
<p>Prompt </p>
<p>answer sarcastic
answerHuman healthy Who is right? (expert rate) Chat 58. Task: GoEmo. Case 7.From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Text: You're welcome.Who is right? (expert rate)Human and ChatGPT Chat 59. Task: GoEmo. Case 7.From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral.Text: From [NAME]: I T ' S S P E L L E D O U I J A Goodbye NA Chat 60. Task: GoEmo. Case 7.Human </p>
<p>Prompt </p>
<p>ChatGPT answer </p>
<p>neutral </p>
<p>Expected </p>
<p>gratitude </p>
<p>Prompt </p>
<p>ChatGPT answer </p>
<p>disappointment </p>
<p>Expected </p>
<p>neutral 
Who is right? (expert rate) </p>
<p>Expected answer ["aggressive"] Evaluation result human -correct, ChatGP -correct D. Prompt engineering Chat 71. Task: GoEmotions. Pattern: Without 'System' User From the given list of all emotions, choose the ones that the input text arouses in most people reading it. Write your answer in the form of a Python list containing exactly 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral. Input text: {} Chat 72. Task: GoEmotions. Pattern: With 'System' and paraphrase of the problem definition. System You are a helpful assistant. Identify the emotions expressed by the writer of the text, given a pre-defined emotions list. You are free to select multiple emotions, but select only those ones for which you are reasonably confident that it is expressed in the text. Write your answer in the form of a Python list containing at least 1 selected most matching emotion. List of all emotions: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral User Input text: {} Chat 73. Task: GoEmotions. Pattern: With 'System' and return only one dimension.Prompt </p>
<p>Prompt </p>
<p>https://openai.com/blog/chatgpt/
In some question answering tasks, the output is given in few words (SQuAD) or as a number -the result of mathematical calculations (MathQA).
https://github.com/CLARIN-PL/chatgpt-evaluation-01-2023
Unfortunately, a more extensive study was impossible due to recent access restrictions, i.e., a limit of 25 prompts per 3 hours
AcknowledgementsPromptWhich language phenomena demonstrate the enthusiasm or positive sentiment in the text: "Presenting Seedo: World's First Fully-Automated Hydroponic Marijuana Grow System #Medi-calCannabis #MedicalMarijuana"?ChatGPT answerThere are several language phenomena that demonstrate the enthusiasm and positive sentiment in the text:1. Use of the word "Presenting": The use of the word "Presenting" conveys a sense of excitement and enthusiasm for the product being introduced.Use of superlatives:The text refers to Seedo as the "World's First Fully-Automated Hydroponic Marijuana Grow System", which is a superlative statement that emphasizes the product's unique and innovative qualities.3. Use of hashtags: The use of hashtags such as "#Medi-calCannabis" and "#MedicalMarijuana" is often used to associate a product or idea with positive or trending topics on social media.4. Lack of negative language: The text does not contain any negative or critical language, which further reinforces the positive sentiment.These language phenomena combined create an overall positive and enthusiastic tone in the text.Prompt SystemYou are a helpful assistant. Identify the emotions expressed by the writer of the text, given a pre-defined emotions list. You are free to select multiple emotions, but select only those ones for which you are reasonably confident that it is expressed in the text. Write your answer in the form of aPrompt SystemLet's play a game called "Lie Detector." Your goal is to determine if a sentence is a lie based on the context provided by the other player. You advance to the next round if your answer is correct, otherwise you lose. User First round. I give you the context: {}. Is the sentence {} correct? Answer a number ""0"" if false or ""1"" if true. Do not explain yourself.
Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L U Kaiser, I Polosukhin, Advances in Neural Information Processing Systems. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, R. GarnettCurran Associates, Inc30A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, I. Polosukhin, Attention is all you need, in: I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, R. Garnett (Eds.), Advances in Neural Information Processing Systems, volume 30, Curran Associates, Inc., 2017, p. 6000-6010. URL: https://proceedings.neurips.cc/paper_files/ paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.</p>
<p>Recent advances in deep learning based dialogue systems: a systematic survey. J Ni, T Young, V Pandelea, F Xue, E Cambria, 10.1007/s10462-022-10248-8doi:10.1007/s10462-022-10248-8Artif. Intell. Rev. 56J. Ni, T. Young, V. Pandelea, F. Xue, E. Cambria, Recent advances in deep learning based dialogue systems: a systematic survey, in: Artif. Intell. Rev., volume 56, 2023, pp. 3055-3155. URL: https://doi. org/10.1007/s10462-022-10248-8. doi:10.1007/s10462-022-10248-8.</p>
<p>A survey of transformers. T Lin, Y Wang, X Liu, X Qiu, AI Open3T. Lin, Y. Wang, X. Liu, X. Qiu, A survey of transformers, in: AI Open, volume 3, 2022, pp. 111-132. URL: https:</p>
<p>. 10.1016/j.aiopen.2022.10.001//www.sciencedirect.com/science/article/pii/S2666651022000146. doi:https://doi.org/10.1016/j.aiopen.2022.10.001.</p>
<p>Supervised and semi-supervised text categorization using LSTM for region embeddings. R Johnson, T Zhang, Proceedings of the 33nd International Conference on Machine Learning. M. Balcan, K. Q. Weinbergerthe 33nd International Conference on Machine LearningNew York City, NY, USA48of JMLR Workshop and Conference Proceedings, JMLR.orgR. Johnson, T. Zhang, Supervised and semi-supervised text cat- egorization using LSTM for region embeddings, in: M. Balcan, K. Q. Weinberger (Eds.), Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, volume 48 of JMLR Workshop and Conference Proceedings, JMLR.org, 2016, pp. 526-534. URL: http: //proceedings.mlr.press/v48/johnson16.html.</p>
<p>A survey of deep neural network architectures and their applications, in: Neurocomputing. W Liu, Z Wang, X Liu, N Zeng, Y Liu, F E Alsaadi, 10.1016/j.neucom.2016.12.038Elsevier234W. Liu, Z. Wang, X. Liu, N. Zeng, Y. Liu, F. E. Alsaadi, A survey of deep neural network architectures and their applica- tions, in: Neurocomputing, volume 234, Elsevier, 2017, pp. 11-26. URL: https://www.sciencedirect.com/science/article/pii/ S0925231216315533. doi:https://doi.org/10.1016/j.neucom.2016.12. 038.</p>
<p>Improving the reliability of deep neural networks in NLP: A review. B Alshemali, J Kalita, 10.1016/j.knosys.2019.105210Knowl. Based Syst.191105210B. Alshemali, J. Kalita, Improving the reliability of deep neural networks in NLP: A review, in: Knowl. Based Syst., volume 191, 2020, p. 105210. URL: https://doi.org/10.1016/j.knosys. 2019.105210. doi:10.1016/j.knosys.2019.105210.</p>
<p>Bidirectional LSTM with attention mechanism and convolutional layer for text classification. G Liu, J Guo, 10.1016/j.neucom.2019.01.078doi:10.1016/j.neucom.2019.01.078Neurocomputing. 337G. Liu, J. Guo, Bidirectional LSTM with attention mechanism and convolutional layer for text classification, in: Neurocomputing, volume 337, 2019, pp. 325-338. URL: https://doi.org/10.1016/j. neucom.2019.01.078. doi:10.1016/j.neucom.2019.01.078.</p>
<p>A critical review of recurrent neural networks for sequence learning. Z C Lipton, arXiv:1506.00019Z. C. Lipton, A critical review of recurrent neural networks for sequence learning, in: arXiv, volume abs/1506.00019, 2015. URL: http://arxiv.org/abs/1506.00019. arXiv:1506.00019.</p>
<p>Overview of the transformer-based models for NLP tasks. A Gillioz, J Casas, E Mugellini, O A Khaled, 10.15439/2020F20doi:10.15439/2020F20Proceedings of the 2020 Federated Conference on Computer Science and Information Systems. M. Ganzha, L. A. Maciaszek, M. Paprzyckithe 2020 Federated Conference on Computer Science and Information SystemsSofia, Bulgaria2020FedCSISA. Gillioz, J. Casas, E. Mugellini, O. A. Khaled, Overview of the transformer-based models for NLP tasks, in: M. Ganzha, L. A. Maci- aszek, M. Paprzycki (Eds.), Proceedings of the 2020 Federated Con- ference on Computer Science and Information Systems, FedCSIS 2020, Sofia, Bulgaria, September 6-9, 2020, volume 21 of Annals of Computer Science and Information Systems, 2020, pp. 179-183. URL: https://doi.org/10.15439/2020F20. doi:10.15439/2020F20.</p>
<p>Integrating multimodal information in large pretrained transformers. W Rahman, M K Hasan, S Lee, A B Zadeh, C Mao, L Morency, M E Hoque, 10.18653/v1/2020.acl-main.214Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. D. Jurafsky, J. Chai, N. Schluter, J. R. Tetreaultthe 58th Annual Meeting of the Association for Computational LinguisticsOnlineAssociation for Computational Linguistics2020W. Rahman, M. K. Hasan, S. Lee, A. B. Zadeh, C. Mao, L. Morency, M. E. Hoque, Integrating multimodal information in large pre- trained transformers, in: D. Jurafsky, J. Chai, N. Schluter, J. R. Tetreault (Eds.), Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, Association for Computational Linguistics, 2020, pp. 2359-2369. URL: https://doi.org/10.18653/v1/2020.acl-main.214. doi:10.18653/v1/2020.acl-main.214.</p>
<p>Empirical evaluation of pre-trained transformers for human-level NLP: the role of sample size and dimensionality. A V Ganesan, M Matero, A R Ravula, H Vu, H A Schwartz, 10.18653/v1/2021.naacl-main.357Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021. K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tür, I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty, Y. Zhouthe 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021Association for Computational LinguisticsA. V. Ganesan, M. Matero, A. R. Ravula, H. Vu, H. A. Schwartz, Empirical evaluation of pre-trained transformers for human-level NLP: the role of sample size and dimensionality, in: K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tür, I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty, Y. Zhou (Eds.), Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, NAACL-HLT 2021, Online, June 6-11, 2021, Association for Computational Linguistics, 2021, pp. 4515-4532. URL: https: //doi.org/10.18653/v1/2021.naacl-main.357. doi:10.18653/v1/2021. naacl-main.357.</p>
<p>Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. A Srivastava, A Rastogi, A Rao, A A M Shoeb, A Abid, A Fisch, A R Brown, A Santoro, A Gupta, A Garriga-Alonso, 10.48550/arXiv.2206.04615arXiv:2206.04615in: arXiv, volume abs/2206.04615, 2022A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso, et al., Beyond the imitation game: Quantifying and extrapo- lating the capabilities of language models, in: arXiv, volume abs/2206.04615, 2022. URL: https://doi.org/10.48550/arXiv.2206. 04615. doi:10.48550/arXiv.2206.04615. arXiv:2206.04615.</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, M Chang, K Lee, K Toutanova, 10.18653/v1/n19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. J. Burstein, C. Doran, T. Soloriothe 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational LinguisticsJ. Devlin, M. Chang, K. Lee, K. Toutanova, BERT: pre-training of deep bidirectional transformers for language understanding, in: J. Burstein, C. Doran, T. Solorio (Eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Vol- ume 1 (Long and Short Papers), Association for Computational Linguistics, 2019, pp. 4171-4186. URL: https://doi.org/10.18653/ v1/n19-1423. doi:10.18653/v1/n19-1423.</p>
<p>Generating wikipedia by summarizing long sequences. P J Liu, M Saleh, E Pot, B Goodrich, R Sepassi, L Kaiser, N Shazeer, 6th International Conference on Learning Representations. Vancouver, BC, CanadaConference Track ProceedingsP. J. Liu, M. Saleh, E. Pot, B. Goodrich, R. Sepassi, L. Kaiser, N. Shazeer, Generating wikipedia by summarizing long sequences, in: 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 -May 3, 2018, Confer- ence Track Proceedings, OpenReview.net, 2018. URL: https:// openreview.net/forum?id=Hyg0vbWC-.</p>
<p>Improving language understanding by generative pre-training, OpenAI. A Radford, K Narasimhan, T Salimans, I Sutskever, A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al., Im- proving language understanding by generative pre-training, OpenAI, 2018.</p>
<p>Language Models are Unsupervised Multitask Learners, OpenAI. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, Language Models are Unsupervised Multitask Learners, OpenAI, 2019.</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020. 2020T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., Language models are few-shot learners, in: Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, volume 33, 2020, pp. 1877-1901. URL: https://proceedings.neurips.cc/paper/2020/ hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C L Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, 10.48550/arXiv.2203.02155arXiv:2203.02155in: arXiv, volume abs/2203.02155, 2022L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., Training language models to follow instructions with human feed- back, in: arXiv, volume abs/2203.02155, 2022. URL: https:// doi.org/10.48550/arXiv.2203.02155. doi:10.48550/arXiv.2203.02155. arXiv:2203.02155.</p>
<p>. Openai, arXiv:2303.087742023Gpt-4 technical reportOpenAI, Gpt-4 technical report, 2023. arXiv:2303.08774.</p>
<p>Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach. J Kocoń, A Figas, M Gruza, D Puchalska, T Kajdanowicz, P Kazienko, Information Processing &amp; Management. 58102643J. Kocoń, A. Figas, M. Gruza, D. Puchalska, T. Kajdanowicz, P. Kazienko, Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach, in: Information Processing &amp; Management, volume 58, 2021, p. 102643. URL: https://www.sciencedirect.com/science/article/pii/</p>
<p>. S0306457321001333, Doi, 10.1016/j.ipm.2021.102643S0306457321001333. doi:https://doi.org/10.1016/j.ipm.2021.102643.</p>
<p>Controversy and conformity: from generalized to personalized aggressiveness detection. K Kanclerz, A Figas, M Gruza, T Kajdanowicz, J Kocon, D Puchalska, P Kazienko, 10.18653/v1/2021.acl-long.460Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Association for Computational LinguisticsK. Kanclerz, A. Figas, M. Gruza, T. Kajdanowicz, J. Kocon, D. Puchalska, P. Kazienko, Controversy and conformity: from generalized to personalized aggressiveness detection, in: Proceed- ings of the 59th Annual Meeting of the Association for Compu- tational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), As- sociation for Computational Linguistics, Online, 2021, pp. 5915- 5926. URL: https://aclanthology.org/2021.acl-long.460. doi:10. 18653/v1/2021.acl-long.460.</p>
<p>Human-centered neural reasoning for subjective content processing: Hate speech, emotions, and humor, in: Information Fusion. P Kazienko, J Bielaniewicz, M Gruza, K Kanclerz, K Karanowski, P Miłkowski, J Kocoń, 10.1016/j.inffus.2023.01.01094P. Kazienko, J. Bielaniewicz, M. Gruza, K. Kanclerz, K. Kara- nowski, P. Miłkowski, J. Kocoń, Human-centered neural rea- soning for subjective content processing: Hate speech, emotions, and humor, in: Information Fusion, volume 94, 2023, pp. 43-65. URL: https://www.sciencedirect.com/science/article/pii/ S1566253523000167. doi:https://doi.org/10.1016/j.inffus.2023.01. 010.</p>
<p>Large pre-trained language models contain human-like biases of what is right and wrong to do. P Schramowski, C Turan, N Andersen, C A Rothkopf, K Kersting, Nature Machine Intelligence. 4P. Schramowski, C. Turan, N. Andersen, C. A. Rothkopf, K. Kerst- ing, Large pre-trained language models contain human-like biases of what is right and wrong to do, Nature Machine Intelligence 4 (2022) 258-268.</p>
<p>E Ferrara, arXiv:2304.03738Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language models. arXiv preprintE. Ferrara, Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language models, arXiv preprint arXiv:2304.03738 (2023).</p>
<p>T Susnjak, Chatgpt , 10.48550/arXiv.2212.09292arXiv:2212.09292The end of online exam integrity?, in: arXiv. T. Susnjak, ChatGPT: The end of online exam integrity?, in: arXiv, volume abs/2212.09292, 2022. URL: https://doi.org/10.48550/ arXiv.2212.09292. doi:10.48550/arXiv.2212.09292. arXiv:2212.09292.</p>
<p>Performance of ChatGPT on usmle: Potential for aiassisted medical education using large language models. T H Kung, M Cheatham, A Medinilla, C Chatgpt, L Sillos, C De Leon, M Elepano, R Madriaga, G Aggabao, Diaz-Candido, medRxiv. T. H. Kung, M. Cheatham, A. Medinilla, ChatGPT, C. Sillos, L. De Leon, C. Elepano, M. Madriaga, R. Aggabao, G. Diaz- Candido, et al., Performance of ChatGPT on usmle: Potential for ai- assisted medical education using large language models, medRxiv (2022) 2022-12.</p>
<p>Chatting about ChatGPT: How May AI and GPT Impact Academia and Libraries?. B Lund, W Ting, ; Lund, B D Wang, B. Lund, W. Ting, Chatting about ChatGPT: How May AI and GPT Impact Academia and Libraries?, Lund, BD, &amp; Wang (2023).</p>
<p>Evaluating the performance of ChatGPT in ophthalmology: An analysis of its successes and shortcomings, in: medRxiv, Cold Spring Harbor Laboratory Press. F Antaki, S Touma, D Milad, J El-Khoury, R Duval, 10.1101/2023.01.22.23284882F. Antaki, S. Touma, D. Milad, J. El-Khoury, R. Duval, Evaluating the performance of ChatGPT in ophthalmology: An analysis of its successes and shortcomings, in: medRxiv, Cold Spring Harbor Lab- oratory Press, 2023. URL: https://www.medrxiv.org/content/early/ 2023/01/26/2023.01.22.23284882. doi:10.1101/2023.01.22.23284882.</p>
<p>The implications of openai's assistant for legal services and society. A M Perlman, Available at SSRN. A. M. Perlman, et al., The implications of openai's assistant for legal services and society, Available at SSRN (2022).</p>
<p>News summarization and evaluation in the era of gpt-3. T Goyal, J J Li, G Durrett, 10.48550/ARXIV.2209.12356T. Goyal, J. J. Li, G. Durrett, News summarization and evaluation in the era of gpt-3, 2022. URL: https://arxiv.org/abs/2209.12356. doi:10.48550/ARXIV.2209.12356.</p>
<p>Classification of natural language processing techniques for requirements engineering. L Zhao, W Alhoshan, A Ferrari, K J Letsholo, 10.48550/arXiv.2204.04282arXiv:2204.04282L. Zhao, W. Alhoshan, A. Ferrari, K. J. Letsholo, Classification of natural language processing techniques for requirements engi- neering, in: arXiv, volume abs/2204.04282, 2022. URL: https:// doi.org/10.48550/arXiv.2204.04282. doi:10.48550/arXiv.2204.04282. arXiv:2204.04282.</p>
<p>Natural Language Processing with TensorFlow: Teach language to machines using Python's deep learning library. T Ganegedara, Packt Publishing LtdT. Ganegedara, Natural Language Processing with TensorFlow: Teach language to machines using Python's deep learning library, Packt Publishing Ltd, 2018.</p>
<p>How close is ChatGPT to human experts? comparison corpus, evaluation, and detection. B Guo, X Zhang, Z Wang, M Jiang, J Nie, Y Ding, J Yue, Y Wu, 10.48550/ARXIV.2301.07597B. Guo, X. Zhang, Z. Wang, M. Jiang, J. Nie, Y. Ding, J. Yue, Y. Wu, How close is ChatGPT to human experts? comparison corpus, evalu- ation, and detection, 2023. URL: https://arxiv.org/abs/2301.07597. doi:10.48550/ARXIV.2301.07597.</p>
<p>How does ChatGPT perform on the medical licensing exams? the implications of large language models for medical education and knowledge assessment, in: medRxiv. A Gilson, C Safranek, T Huang, V Socrates, L Chi, R A Taylor, D Chartash, Cold Spring Harbor Laboratory PressA. Gilson, C. Safranek, T. Huang, V. Socrates, L. Chi, R. A. Taylor, D. Chartash, How does ChatGPT perform on the medical licensing exams? the implications of large language models for medical education and knowledge assessment, in: medRxiv, Cold Spring Harbor Laboratory Press, 2022. URL: https:</p>
<p>. 10.1101/2022.12.23.22283901//www.medrxiv.org/content/early/2022/12/26/2022.12.23.22283901. doi:10.1101/2022.12.23.22283901.</p>
<p>Smarter than humans? validating how openai's ChatGPT model explains crowdfunding, alternative finance and community finance., Validating how OpenAI's ChatGPT model explains Crowdfunding, Alternative Finance and Community Finance. K Wenzlaff, S Spaeth, K. Wenzlaff, S. Spaeth, Smarter than humans? validating how openai's ChatGPT model explains crowdfunding, alternative finance and community finance., Validating how OpenAI's ChatGPT model explains Crowdfunding, Alternative Finance and Community Fi- nance.(December 22, 2022) (2022).</p>
<p>Exploring the use of gpt-3 as a tool for evaluating textbased collaborative discourse, Examining pedagogical data literacy: results of a survey among school teachers at upper secondary level in. T Phillips, A Saleh, K D Glazewski, C E Hmelo-Silver, B Mott, J C Lester, 54SwitzerlandT. Phillips, A. Saleh, K. D. Glazewski, C. E. Hmelo-Silver, B. Mott, J. C. Lester, Exploring the use of gpt-3 as a tool for evaluating text- based collaborative discourse, Examining pedagogical data literacy: results of a survey among school teachers at upper secondary level in Switzerland (2022) 54.</p>
<p>Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers, in: bioRxiv, Cold Spring Harbor Laboratory. C A Gao, F M Howard, N S Markov, E C Dyer, S Ramesh, Y Luo, A T Pearson, 10.1101/2022.12.23.521610C. A. Gao, F. M. Howard, N. S. Markov, E. C. Dyer, S. Ramesh, Y. Luo, A. T. Pearson, Comparing scientific abstracts gener- ated by ChatGPT to original abstracts using an artificial intel- ligence output detector, plagiarism detector, and blinded human reviewers, in: bioRxiv, Cold Spring Harbor Laboratory, 2022. URL: https://www.biorxiv.org/content/early/2022/12/27/2022.12. 23.521610. doi:10.1101/2022.12.23.521610.</p>
<p>Openai ChatGPT generated literature review: Digital twin in healthcare. Ö Aydın, E Karaarslan, Available at SSRN. 4308687Ö. Aydın, E. Karaarslan, Openai ChatGPT generated literature review: Digital twin in healthcare, Available at SSRN 4308687 (2022).</p>
<p>ChatGPT makes medicine easy to swallow: An exploratory case study on simplified radiology reports. K Jeblick, B Schachtner, J Dexl, A Mittermeier, A T Stüber, J Topalis, T Weber, P Wesp, B Sabel, J Ricke, M Ingrisch, 10.48550/ARXIV.2212.14882K. Jeblick, B. Schachtner, J. Dexl, A. Mittermeier, A. T. Stüber, J. Topalis, T. Weber, P. Wesp, B. Sabel, J. Ricke, M. Ingrisch, ChatGPT makes medicine easy to swallow: An exploratory case study on simplified radiology reports, 2022. URL: https://arxiv. org/abs/2212.14882. doi:10.48550/ARXIV.2212.14882.</p>
<p>Transformers go for the lols: Generating (humourous) titles from scientific abstracts end-to-end. Y Chen, S Eger, 10.48550/arXiv.2212.10522arXiv:2212.10522arXivY. Chen, S. Eger, Transformers go for the lols: Generating (hu- mourous) titles from scientific abstracts end-to-end, in: arXiv, vol- ume abs/2212.10522, 2022. URL: https://doi.org/10.48550/arXiv. 2212.10522. doi:10.48550/arXiv.2212.10522. arXiv:2212.10522.</p>
<p>Is ChatGPT a good translator? a preliminary study. W Jiao, W Wang, J Huang, X Wang, Z Tu, 10.48550/ARXIV.2301.08745W. Jiao, W. Wang, J.-t. Huang, X. Wang, Z. Tu, Is ChatGPT a good translator? a preliminary study, 2023. URL: https://arxiv.org/abs/ 2301.08745. doi:10.48550/ARXIV.2301.08745.</p>
<p>Using ChatGPT for Human-Computer Interaction Research: A Primer. W Tabone, J Winter, W. Tabone, J. de Winter, Using ChatGPT for Human-Computer Interaction Research: A Primer, 2023.</p>
<p>ChatGPT's scientific writings: A case study on traffic safety. B Kutela, K Msechu, S Das, E Kidando, Available at SSRN 4329120. B. Kutela, K. Msechu, S. Das, E. Kidando, ChatGPT's scientific writings: A case study on traffic safety, Available at SSRN 4329120 (2023).</p>
<p>R Karanjai, 10.48550/arXiv.2301.00665arXiv:2301.00665Targeted phishing campaigns using large scale language models. R. Karanjai, Targeted phishing campaigns using large scale language models, in: arXiv, volume abs/2301.00665, 2023. URL: https:// doi.org/10.48550/arXiv.2301.00665. doi:10.48550/arXiv.2301.00665. arXiv:2301.00665.</p>
<p>ChatGPT Usage and Limitations. A Azaria, working paper or preprintA. Azaria, ChatGPT Usage and Limitations, 2022. URL: https: //hal.science/hal-03913837, working paper or preprint.</p>
<p>Will affective computing emerge from foundation models and general ai? a first evaluation on ChatGPT. M M Amin, E Cambria, B W Schuller, arXiv:2303.031862023M. M. Amin, E. Cambria, B. W. Schuller, Will affective computing emerge from foundation models and general ai? a first evaluation on ChatGPT, 2023. arXiv:2303.03186.</p>
<p>A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity. Y Bang, S Cahyawijaya, N Lee, W Dai, D Su, B Wilie, H Lovenia, Z Ji, T Yu, W Chung, Q V Do, Y Xu, P Fung, arXiv:2302.040232023Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Love- nia, Z. Ji, T. Yu, W. Chung, Q. V. Do, Y. Xu, P. Fung, A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hal- lucination, and interactivity, 2023. arXiv:2302.04023.</p>
<p>The importance of human supervision in the use of ChatGPT as a support tool in scientific writing. W Castillo-González, Metaverse Basic and Applied Research. 229W. Castillo-González, The importance of human supervision in the use of ChatGPT as a support tool in scientific writing, Metaverse Basic and Applied Research 2 (2022) 29.</p>
<p>An ensemble of arabic transformer-based models for arabic sentiment analysis. I E Karfi, S E Fkihi, International Journal of Advanced Computer Science and Applications. 13I. E. Karfi, S. E. Fkihi, An ensemble of arabic transformer-based models for arabic sentiment analysis, International Journal of Advanced Computer Science and Applications 13 (2022).</p>
<p>P Liang, R Bommasani, T Lee, D Tsipras, D Soylu, M Yasunaga, Y Zhang, D Narayanan, Y Wu, A Kumar, B Newman, B Yuan, B Yan, C Zhang, C Cosgrove, C D Manning, C Ré, D Acosta-Navas, D A Hudson, E Zelikman, E Durmus, F Ladhak, F Rong, H Ren, H Yao, J Wang, K Santhanam, L Orr, L Zheng, M Yuksekgonul, M Suzgun, N Kim, N Guha, N Chatterji, O Khattab, P Henderson, Q Huang, R Chi, S M Xie, S Santurkar, S Ganguli, T Hashimoto, T Icard, T Zhang, V Chaudhary, W Wang, X Li, Y Mai, Y Zhang, Y Koreeda, 10.48550/arXiv.2211.09110arXiv:2211.09110Holistic evaluation of language models. P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar, B. Newman, B. Yuan, B. Yan, C. Zhang, C. Cosgrove, C. D. Manning, C. Ré, D. Acosta- Navas, D. A. Hudson, E. Zelikman, E. Durmus, F. Ladhak, F. Rong, H. Ren, H. Yao, J. Wang, K. Santhanam, L. Orr, L. Zheng, M. Yuk- sekgonul, M. Suzgun, N. Kim, N. Guha, N. Chatterji, O. Khattab, P. Henderson, Q. Huang, R. Chi, S. M. Xie, S. Santurkar, S. Ganguli, T. Hashimoto, T. Icard, T. Zhang, V. Chaudhary, W. Wang, X. Li, Y. Mai, Y. Zhang, Y. Koreeda, Holistic evaluation of language models, in: arXiv, volume abs/2211.09110, 2022. URL: https:// doi.org/10.48550/arXiv.2211.09110. doi:10.48550/arXiv.2211.09110. arXiv:2211.09110.</p>
<p>P Liang, R Bommasani, T Lee, D Tsipras, D Soylu, M Yasunaga, Y Zhang, D Narayanan, Y Wu, A Kumar, B Newman, B Yuan, B Yan, C Zhang, C Cosgrove, C D Manning, C Ré, D Acosta-Navas, D A Hudson, E Zelikman, E Durmus, F Ladhak, F Rong, H Ren, H Yao, J Wang, K Santhanam, L Orr, L Zheng, M Yuksekgonul, M Suzgun, N Kim, N Guha, N Chatterji, O Khattab, P Henderson, Q Huang, R Chi, S M Xie, S Santurkar, S Ganguli, T Hashimoto, T Icard, T Zhang, V Chaudhary, W Wang, X Li, Y Mai, Y Zhang, Y Koreeda, arXiv:2211.09110Holistic evaluation of language models. 2022P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar, B. Newman, B. Yuan, B. Yan, C. Zhang, C. Cosgrove, C. D. Manning, C. Ré, D. Acosta- Navas, D. A. Hudson, E. Zelikman, E. Durmus, F. Ladhak, F. Rong, H. Ren, H. Yao, J. Wang, K. Santhanam, L. Orr, L. Zheng, M. Yuk- sekgonul, M. Suzgun, N. Kim, N. Guha, N. Chatterji, O. Khattab, P. Henderson, Q. Huang, R. Chi, S. M. Xie, S. Santurkar, S. Ganguli, T. Hashimoto, T. Icard, T. Zhang, V. Chaudhary, W. Wang, X. Li, Y. Mai, Y. Zhang, Y. Koreeda, Holistic evaluation of language models, 2022. arXiv:2211.09110.</p>
<p>Exploring AI ethics of ChatGPT: A diagnostic analysis. T Y Zhuo, Y Huang, C Chen, Z Xing, 10.48550/arXiv.2301.12867arXiv:2301.12867T. Y. Zhuo, Y. Huang, C. Chen, Z. Xing, Exploring AI ethics of ChatGPT: A diagnostic analysis, in: arXiv, volume abs/2301.12867, 2023. URL: https://doi.org/10.48550/arXiv.2301.12867. doi:10. 48550/arXiv.2301.12867. arXiv:2301.12867.</p>
<p>On the robustness of ChatGPT: An adversarial and out-of-distribution perspective. J Wang, X Hu, W Hou, H Chen, R Zheng, Y Wang, L Yang, H Huang, W Ye, X Geng, B Jiao, Y Zhang, X Xie, arXiv:2302.120952023J. Wang, X. Hu, W. Hou, H. Chen, R. Zheng, Y. Wang, L. Yang, H. Huang, W. Ye, X. Geng, B. Jiao, Y. Zhang, X. Xie, On the robust- ness of ChatGPT: An adversarial and out-of-distribution perspective, 2023. arXiv:2302.12095.</p>
<p>B Peng, C Li, P He, M Galley, J Gao, arXiv:2304.03277Instruction tuning with gpt-4, 2023. B. Peng, C. Li, P. He, M. Galley, J. Gao, Instruction tuning with gpt-4, 2023. arXiv:2304.03277.</p>
<p>Capabilities of gpt-4 on medical challenge problems. H Nori, N King, S M Mckinney, D Carignan, E Horvitz, arXiv:2303.133752023H. Nori, N. King, S. M. McKinney, D. Carignan, E. Horvitz, Capabilities of gpt-4 on medical challenge problems, 2023. arXiv:2303.13375.</p>
<p>M B I , D M Katz, arXiv:2212.14402Gpt takes the bar exam. M. B. I. au2, D. M. Katz, Gpt takes the bar exam, 2022. arXiv:2212.14402.</p>
<p>Theory of mind may have spontaneously emerged in large language models. M Kosinski, arXiv:2302.02083M. Kosinski, Theory of mind may have spontaneously emerged in large language models, 2023. arXiv:2302.02083.</p>
<p>Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. P Liu, W Yuan, J Fu, Z Jiang, H Hayashi, G Neubig, 10.1145/3560815doi:10.1145/3560815ACM Comput. Surv. 55P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, G. Neubig, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing, in: ACM Comput. Surv., volume 55, 2023, pp. 195:1-195:35. URL: https://doi.org/10.1145/3560815. doi:10.1145/3560815.</p>
<p>Foundations of the theory of signs. C W Morris, International encyclopedia of unified science. Chicago University PressC. W. Morris, Foundations of the theory of signs, in: International encyclopedia of unified science, Chicago University Press, 1938, pp. 1-59.</p>
<p>S Blum-Kulka, M Hamo, Discourse pragmatics, Discourse studies: A multidisciplinary introduction. S. Blum-Kulka, M. Hamo, Discourse pragmatics, Discourse studies: A multidisciplinary introduction 2 (2011) 143-164.</p>
<p>A Synopsis of Linguistic Theory. J Firth, J. R. Firth. Palmer, F.Philological Society1968) Selected Papers ofJ. Firth, A Synopsis of Linguistic Theory 1930-1955, Philological Society, Oxford, 1957. Reprinted in Palmer, F. (ed. 1968) Selected Papers of J. R. Firth, Longman, Harlow.</p>
<p>Ex machina: Personal attacks seen at scale. E Wulczyn, N Thain, L Dixon, 10.1145/3038912.3052591Proceedings of the 26th International Conference on World Wide Web. R. Barrett, R. Cummings, E. Agichtein, E. Gabrilovichthe 26th International Conference on World Wide WebPerth, AustraliaACME. Wulczyn, N. Thain, L. Dixon, Ex machina: Personal at- tacks seen at scale, in: R. Barrett, R. Cummings, E. Agichtein, E. Gabrilovich (Eds.), Proceedings of the 26th International Con- ference on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017, ACM, 2017, pp. 1391-1399. URL: https://doi.org/10. 1145/3038912.3052591. doi:10.1145/3038912.3052591.</p>
<p>Measuring and improving model-moderator collaboration using uncertainty estimation. I D Kivlichan, Z Lin, J Z Liu, L Vasserman, arXiv:2107.04212in: arXiv, volume abs/2107.04212, 2021I. D. Kivlichan, Z. Lin, J. Z. Liu, L. Vasserman, Measuring and improving model-moderator collaboration using uncertainty estima- tion, in: arXiv, volume abs/2107.04212, 2021. URL: https://arxiv. org/abs/2107.04212. arXiv:2107.04212.</p>
<p>A Warstadt, A Singh, S R Bowman, 10.1162/tacl_a_00290doi:10. 1162/tacl_a_00290Neural network acceptability judgments. 7A. Warstadt, A. Singh, S. R. Bowman, Neural network acceptability judgments, in: Trans. Assoc. Comput. Linguistics, volume 7, 2019, pp. 625-641. URL: https://doi.org/10.1162/tacl_a_00290. doi:10. 1162/tacl_a_00290.</p>
<p>Entailment as few-shot learner. S Wang, H Fang, M Khabsa, H Mao, H Ma, arXiv:2104.14690in: arXiv, volume abs/2104.14690, 2021S. Wang, H. Fang, M. Khabsa, H. Mao, H. Ma, Entailment as few-shot learner, in: arXiv, volume abs/2104.14690, 2021. URL: https://arxiv.org/abs/2104.14690. arXiv:2104.14690.</p>
<p>Using BERT sentence embedding for humor detection. I Annamoradnejad, Colbert , arXiv:2004.12765I. Annamoradnejad, Colbert: Using BERT sentence embedding for humor detection, in: arXiv, volume abs/2004.12765, 2020. URL: https://arxiv.org/abs/2004.12765. arXiv:2004.12765.</p>
<p>R Siddiqui, SARCASMANIA: Sarcasm Exposed!. Online; accessed 02R. Siddiqui, SARCASMANIA: Sarcasm Exposed!, http://www. kaggle.com/rmsharks4/sarcasmania-dataset, 2019. [Online; accessed 02-February-2023].</p>
<p>WELMSD -word embedding and language model based sarcasm detection. P Kumar, G Sarin, 10.1108/OIR-03-2021-0184doi:10.1108/OIR-03-2021-0184Online Inf. Rev. 46P. Kumar, G. Sarin, WELMSD -word embedding and lan- guage model based sarcasm detection, in: Online Inf. Rev., volume 46, 2022, pp. 1242-1256. URL: https://doi.org/10.1108/ OIR-03-2021-0184. doi:10.1108/OIR-03-2021-0184.</p>
<p>On the validity of a new SMS spam collection. J M G Hidalgo, T A Almeida, A Yamakami, 10.1109/ICMLA.2012.211doi:10.1109/ICMLA.2012.21111th International Conference on Machine Learning and Applications, ICMLA. Boca Raton, FL, USAIEEE2J. M. G. Hidalgo, T. A. Almeida, A. Yamakami, On the validity of a new SMS spam collection, in: 11th International Conference on Machine Learning and Applications, ICMLA, Boca Raton, FL, USA, December 12-15, 2012. Volume 2, volume 2, IEEE, IEEE, 2012, pp. 240-245. URL: https://doi.org/10.1109/ICMLA.2012.211. doi:10.1109/ICMLA.2012.211.</p>
<p>T Sahmoud, M Mikki, 10.48550/arXiv.2206.02443arXiv:2206.02443Spam detection using BERT, in: arXiv. T. Sahmoud, M. Mikki, Spam detection using BERT, in: arXiv, vol- ume abs/2206.02443, 2022. URL: https://doi.org/10.48550/arXiv. 2206.02443. doi:10.48550/arXiv.2206.02443. arXiv:2206.02443.</p>
<p>M T Pilehvar, J Camacho-Collados, 10.18653/v1/n19-1128Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. J. Burstein, C. Doran, T. Soloriothe 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational Linguistics1Wic: the word-in-context dataset for evaluating context-sensitive meaning representationsM. T. Pilehvar, J. Camacho-Collados, Wic: the word-in-context dataset for evaluating context-sensitive meaning representations, in: J. Burstein, C. Doran, T. Solorio (Eds.), Proceedings of the 2019 Conference of the North American Chapter of the Associ- ation for Computational Linguistics: Human Language Technolo- gies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), Association for Computational Linguistics, 2019, pp. 1267-1273. URL: https://doi.org/10.18653/ v1/n19-1128. doi:10.18653/v1/n19-1128.</p>
<p>St-moe: Designing stable and transferable sparse expert models. B Zoph, I Bello, S Kumar, N Du, Y Huang, J Dean, N Shazeer, W Fedus, 10.48550/ARXIV.2202.08906doi:10. 48550/ARXIV.2202.08906B. Zoph, I. Bello, S. Kumar, N. Du, Y. Huang, J. Dean, N. Shazeer, W. Fedus, St-moe: Designing stable and transferable sparse ex- pert models, 2022. URL: https://arxiv.org/abs/2202.08906. doi:10. 48550/ARXIV.2202.08906.</p>
<p>Superglue: A stickier benchmark for general-purpose language understanding systems. A Wang, Y Pruksachatkun, N Nangia, A Singh, J Michael, F Hill, O Levy, S Bowman, Advances in Neural Information Processing Systems. H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, R. GarnettCurran Associates, Inc32A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, S. Bowman, Superglue: A stickier benchmark for general-purpose language understanding systems, in: H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, R. Garnett (Eds.), Advances in Neural Information Processing Systems, volume 32, Curran Associates, Inc., 2019. URL: https://proceedings.neurips.cc/paper_files/paper/2019/ file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf.</p>
<p>GLUE: A multi-task benchmark and analysis platform for natural language understanding. A Wang, A Singh, J Michael, F Hill, O Levy, S Bowman, 10.18653/v1/W18-5446Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLPBelgiumAssociation for Computational LinguisticsA. Wang, A. Singh, J. Michael, F. Hill, O. Levy, S. Bowman, GLUE: A multi-task benchmark and analysis platform for natural language understanding, in: Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Net- works for NLP, Association for Computational Linguistics, Brus- sels, Belgium, 2018, pp. 353-355. URL: https://aclanthology.org/ W18-5446. doi:10.18653/v1/W18-5446.</p>
<p>Beyond english-centric bitexts for better multilingual language representation learning. B Patra, S Singhal, S Huang, Z Chi, L Dong, F Wei, V Chaudhary, X Song, 10.48550/arXiv.2210.14867arXiv:2210.14867in: arXiv, volume abs/2210.14867, 2022B. Patra, S. Singhal, S. Huang, Z. Chi, L. Dong, F. Wei, V. Chaud- hary, X. Song, Beyond english-centric bitexts for better mul- tilingual language representation learning, in: arXiv, volume abs/2210.14867, 2022. URL: https://doi.org/10.48550/arXiv.2210. 14867. doi:10.48550/arXiv.2210.14867. arXiv:2210.14867.</p>
<p>P Rajpurkar, R Jia, P Liang, arXiv:1806.03822Know what you don't know: Unanswerable questions for squad. P. Rajpurkar, R. Jia, P. Liang, Know what you don't know: Unan- swerable questions for squad, in: arXiv, volume abs/1806.03822, 2018. URL: http://arxiv.org/abs/1806.03822. arXiv:1806.03822.</p>
<p>Debertav3: Improving deberta using electrastyle pre-training with gradient-disentangled embedding sharing. P He, J Gao, W Chen, arXiv:2111.09543in: arXiv, volume abs/2111.09543, 2021P. He, J. Gao, W. Chen, Debertav3: Improving deberta using electra- style pre-training with gradient-disentangled embedding sharing, in: arXiv, volume abs/2111.09543, 2021. URL: https://arxiv.org/abs/ 2111.09543. arXiv:2111.09543.</p>
<p>Training verifiers to solve math word problems. K Cobbe, V Kosaraju, M Bavarian, J Hilton, R Nakano, C Hesse, J Schulman, arXiv:2110.14168in: arXiv, volume abs/2110.14168, 2021K. Cobbe, V. Kosaraju, M. Bavarian, J. Hilton, R. Nakano, C. Hesse, J. Schulman, Training verifiers to solve math word problems, in: arXiv, volume abs/2110.14168, 2021. URL: https://arxiv.org/abs/ 2110.14168. arXiv:2110.14168.</p>
<p>Y Li, Z Lin, S Zhang, Q Fu, B Chen, J Lou, W Chen, 10.48550/arXiv.2206.02336arXiv:2206.02336On the advance of making language models better reasoners, in: arXiv. ume abs/2206.02336, 2022Y. Li, Z. Lin, S. Zhang, Q. Fu, B. Chen, J. Lou, W. Chen, On the advance of making language models better reasoners, in: arXiv, vol- ume abs/2206.02336, 2022. URL: https://doi.org/10.48550/arXiv. 2206.02336. doi:10.48550/arXiv.2206.02336. arXiv:2206.02336.</p>
<p>Goemotions: A dataset of fine-grained emotions. D Demszky, D Movshovitz-Attias, J Ko, A S Cowen, G Nemade, S Ravi, 10.18653/v1/2020.acl-main.372Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online. D. Jurafsky, J. Chai, N. Schluter, J. R. Tetreaultthe 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, OnlineAssociation for Computational LinguisticsD. Demszky, D. Movshovitz-Attias, J. Ko, A. S. Cowen, G. Nemade, S. Ravi, Goemotions: A dataset of fine-grained emotions, in: D. Ju- rafsky, J. Chai, N. Schluter, J. R. Tetreault (Eds.), Proceedings of the 58th Annual Meeting of the Association for Computational Linguis- tics, ACL 2020, Online, July 5-10, 2020, Association for Computa- tional Linguistics, 2020, pp. 4040-4054. URL: https://doi.org/10. 18653/v1/2020.acl-main.372. doi:10.18653/v1/2020.acl-main.372.</p>
<p>StudEmo: A non-aggregated review dataset for personalized emotion recognition. A Ngo, A Candri, T Ferdinan, J Kocon, W Korczynski, Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022, European Language Resources Association. the 1st Workshop on Perspectivist Approaches to NLP @LREC2022, European Language Resources AssociationMarseille, FranceA. Ngo, A. Candri, T. Ferdinan, J. Kocon, W. Korczynski, StudEmo: A non-aggregated review dataset for personalized emotion recog- nition, in: Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022, European Language Resources Association, Marseille, France, 2022, pp. 46-55. URL: https:// aclanthology.org/2022.nlperspectives-1.7.</p>
<p>Six attributes of unhealthy conversations. I Price, J Gifford-Moore, J Flemming, S Musker, M Roichman, G Sylvain, N Thain, L Dixon, J Sorensen, 10.18653/v1/2020.alw-1.15Proceedings of the Fourth Workshop on Online Abuse and Harms, Association for Computational Linguistics. the Fourth Workshop on Online Abuse and Harms, Association for Computational LinguisticsI. Price, J. Gifford-Moore, J. Flemming, S. Musker, M. Roichman, G. Sylvain, N. Thain, L. Dixon, J. Sorensen, Six attributes of unhealthy conversations, in: Proceedings of the Fourth Workshop on Online Abuse and Harms, Association for Computational Linguis- tics, Online, 2020, pp. 114-124. URL: https://aclanthology.org/ 2020.alw-1.15. doi:10.18653/v1/2020.alw-1.15.</p>
<p>Multi-level sentiment analysis of polemo 2.0: Extended corpus of multi-domain consumer reviews. J Kocon, P Milkowski, M Zasko-Zielinska, 10.18653/v1/K19-1092Proceedings of the 23rd Conference on Computational Natural Language Learning. M. Bansal, A. Villavicenciothe 23rd Conference on Computational Natural Language LearningCoNLL; Hong Kong, ChinaAssociation for Computational LinguisticsJ. Kocon, P. Milkowski, M. Zasko-Zielinska, Multi-level sentiment analysis of polemo 2.0: Extended corpus of multi-domain consumer reviews, in: M. Bansal, A. Villavicencio (Eds.), Proceedings of the 23rd Conference on Computational Natural Language Learning, CoNLL 2019, Hong Kong, China, November 3-4, 2019, Association for Computational Linguistics, 2019, pp. 980-991. URL: https: //doi.org/10.18653/v1/K19-1092. doi:10.18653/v1/K19-1092.</p>
<p>TweetEval: Unified benchmark and comparative evaluation for tweet classification. F Barbieri, J Camacho-Collados, L Espinosa Anke, L Neves, 10.18653/v1/2020.findings-emnlp.148Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational LinguisticsF. Barbieri, J. Camacho-Collados, L. Espinosa Anke, L. Neves, TweetEval: Unified benchmark and comparative evaluation for tweet classification, in: Findings of the Association for Computational Linguistics: EMNLP 2020, Association for Computational Linguistics, Online, 2020, pp. 1644-1650. URL: https://aclanthology.org/2020.findings-emnlp.148. doi:10.18653/v1/2020.findings-emnlp.148.</p>
<p>D Loureiro, F Barbieri, L Neves, L Espinosa Anke, J Camachocollados, 10.18653/v1/2022.acl-demo.25Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 60th Annual Meeting of the Association for Computational Linguistics: System DemonstrationsDublin, Ireland, 2022Association for Computational LinguisticsTimeLMs: Diachronic language models from TwitterD. Loureiro, F. Barbieri, L. Neves, L. Espinosa Anke, J. Camacho- collados, TimeLMs: Diachronic language models from Twit- ter, in: Proceedings of the 60th Annual Meeting of the As- sociation for Computational Linguistics: System Demonstrations, Association for Computational Linguistics, Dublin, Ireland, 2022, pp. 251-260. URL: https://aclanthology.org/2022.acl-demo.25. doi:10.18653/v1/2022.acl-demo.25.</p>
<p>Towards human-level machine reading comprehension: Reasoning and inference with multiple strategies. Y Xu, J Liu, J Gao, Y Shen, X Liu, arXiv:1711.04964in: arXiv, volume abs/1711.04964Y. Xu, J. Liu, J. Gao, Y. Shen, X. Liu, Towards human-level machine reading comprehension: Reasoning and inference with multiple strategies, in: arXiv, volume abs/1711.04964, 2017. URL: http://arxiv.org/abs/1711.04964. arXiv:1711.04964.</p>
<p>Metaqa: Combining expert agents for multi-skill question answering. H Puerto, G G Sahin, I Gurevych, arXiv:2112.01922in: arXiv, volume abs/2112.01922, 2021H. Puerto, G. G. Sahin, I. Gurevych, Metaqa: Combining expert agents for multi-skill question answering, in: arXiv, volume abs/2112.01922, 2021. URL: https://arxiv.org/abs/2112. 01922. arXiv:2112.01922.</p>
<p>Word sense disambiguation: A unified evaluation framework and empirical comparison. A Raganato, J Camacho-Collados, R Navigli, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. the 15th Conference of the European Chapter of the Association for Computational LinguisticsValencia, SpainAssociation for Computational Linguistics1A. Raganato, J. Camacho-Collados, R. Navigli, Word sense disam- biguation: A unified evaluation framework and empirical compari- son, in: Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, Association for Computational Linguistics, Valencia, Spain, 2017, pp. 99-110. URL: https://aclanthology.org/E17-1010.</p>
<p>Consec: Word sense disambiguation as continuous sense comprehension. E Barba, L Procopio, R Navigli, Proceedings of the 2021. M. Moens, X. Huang, L. Specia, S. W. Yihthe 2021E. Barba, L. Procopio, R. Navigli, Consec: Word sense disam- biguation as continuous sense comprehension, in: M. Moens, X. Huang, L. Specia, S. W. Yih (Eds.), Proceedings of the 2021</p>
<p>Virtual Event / Punta Cana, Dominican Republic. 10.18653/v1/2021.emnlp-main.112Conference on Empirical Methods in Natural Language Processing, EMNLP 2021. Association for Computational LinguisticsConference on Empirical Methods in Natural Language Process- ing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Re- public, 7-11 November, 2021, Association for Computational Lin- guistics, 2021, pp. 1492-1503. URL: https://doi.org/10.18653/v1/ 2021.emnlp-main.112. doi:10.18653/v1/2021.emnlp-main.112.</p>
<p>The Winograd Schema Challenge. H J Levesque, E Davis, L Morgenstern, Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, KR'12. the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, KR'12Rome, ItalyAAAI PressH. J. Levesque, E. Davis, L. Morgenstern, The Winograd Schema Challenge, in: Proceedings of the Thirteenth International Con- ference on Principles of Knowledge Representation and Reasoning, KR'12, AAAI Press, Rome, Italy, 2012, pp. 552-561. URL: https: //cs.nyu.edu/faculty/davise/papers/WSKR2012.pdf.</p>
<p>SENSEVAL-2: Overview. P Edmonds, S Cotton, Proceedings of SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems, Association for Computational Linguistics. SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems, Association for Computational LinguisticsToulouse, FranceP. Edmonds, S. Cotton, SENSEVAL-2: Overview, in: Proceedings of SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems, Association for Computa- tional Linguistics, Toulouse, France, 2001, pp. 1-5. URL: https: //aclanthology.org/S01-1001.</p>
<p>The English all-words task. B Snyder, M Palmer, Proceedings of SENSEVAL-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text. SENSEVAL-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of TextBarcelona, SpainAssociation for Computational LinguisticsB. Snyder, M. Palmer, The English all-words task, in: Proceedings of SENSEVAL-3, the Third International Workshop on the Eval- uation of Systems for the Semantic Analysis of Text, Association for Computational Linguistics, Barcelona, Spain, 2004, pp. 41-43. URL: https://aclanthology.org/W04-0811.</p>
<p>S Pradhan, E Loper, D Dligach, M Palmer, Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), Association for Computational Linguistics. the Fourth International Workshop on Semantic Evaluations (SemEval-2007), Association for Computational LinguisticsPrague, Czech RepublicSemEval-2007 task-17: English lexical sample, SRL and all wordsS. Pradhan, E. Loper, D. Dligach, M. Palmer, SemEval-2007 task-17: English lexical sample, SRL and all words, in: Pro- ceedings of the Fourth International Workshop on Semantic Eval- uations (SemEval-2007), Association for Computational Linguis- tics, Prague, Czech Republic, 2007, pp. 87-92. URL: https:// aclanthology.org/S07-1016.</p>
<p>R Navigli, D Jurgens, D Vannella, Proceedings of the Seventh International Workshop on Semantic Evaluation. the Seventh International Workshop on Semantic EvaluationAtlanta, Georgia, USA2Association for Computational LinguisticsR. Navigli, D. Jurgens, D. Vannella, SemEval-2013 task 12: Multilingual word sense disambiguation, in: Second Joint Con- ference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), Association for Computational Lin- guistics, Atlanta, Georgia, USA, 2013, pp. 222-231. URL: https: //aclanthology.org/S13-2040.</p>
<p>A Moro, R Navigli, 10.18653/v1/S15-2049Proceedings of the 9th International Workshop on Semantic Evaluation (Se-mEval 2015). the 9th International Workshop on Semantic Evaluation (Se-mEval 2015)Denver, ColoradoAssociation for Computational LinguisticsSemEval-2015 task 13: Multilingual allwords sense disambiguation and entity linkingA. Moro, R. Navigli, SemEval-2015 task 13: Multilingual all- words sense disambiguation and entity linking, in: Proceedings of the 9th International Workshop on Semantic Evaluation (Se- mEval 2015), Association for Computational Linguistics, Denver, Colorado, 2015, pp. 288-297. URL: https://aclanthology.org/ S15-2049. doi:10.18653/v1/S15-2049.</p>
<p>Wordnet: An electronic lexical database. C Fellbaum, Computational Linguistics. C. FELLBAUM, Wordnet: An electronic lexical database, Compu- tational Linguistics (1998) 292-296.</p>
<p>Learning personal human biases and representations for subjective tasks in natural language processing. J Kocoń, M Gruza, J Bielaniewicz, D Grimling, K Kanclerz, P Miłkowski, P Kazienko, 10.1109/ICDM51629.2021.001402021 IEEE International Conference on Data Mining (ICDM). IEEEJ. Kocoń, M. Gruza, J. Bielaniewicz, D. Grimling, K. Kanclerz, P. Miłkowski, P. Kazienko, Learning personal human biases and representations for subjective tasks in natural language processing, in: 2021 IEEE International Conference on Data Mining (ICDM), IEEE, 2021, pp. 1168-1173. doi:10.1109/ICDM51629.2021.00140.</p>
<p>Deep-sheep: Sense of humor extraction from embeddings in the personalized context. J Bielaniewicz, K Kanclerz, P Miłkowski, M Gruza, K Karanowski, P Kazienko, J Kocoń, 2022 IEEE International Conference on Data Mining Workshops (ICDMW). IEEEJ. Bielaniewicz, K. Kanclerz, P. Miłkowski, M. Gruza, K. Kara- nowski, P. Kazienko, J. Kocoń, Deep-sheep: Sense of humor extrac- tion from embeddings in the personalized context, in: 2022 IEEE International Conference on Data Mining Workshops (ICDMW), IEEE, 2022, pp. 967-974.</p>
<p>What if ground truth is subjective? personalized deep neural hate speech detection. K Kanclerz, M Gruza, K Karanowski, J Bielaniewicz, P Milkowski, J Kocon, P Kazienko, Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022. the 1st Workshop on Perspectivist Approaches to NLP @LREC2022Marseille, France, 2022K. Kanclerz, M. Gruza, K. Karanowski, J. Bielaniewicz, P. Milkowski, J. Kocon, P. Kazienko, What if ground truth is subjective? personalized deep neural hate speech detection, in: Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022, European Language Resources Association, Marseille, France, 2022, pp. 37-45. URL: https://aclanthology.org/2022.nlperspectives-1.6.</p>
<p>Multitask personalized recognition of emotions evoked by textual content. P Miłkowski, S Saganowski, M Gruza, P Kazienko, M Piasecki, J Kocoń, 2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops). IEEEP. Miłkowski, S. Saganowski, M. Gruza, P. Kazienko, M. Piasecki, J. Kocoń, Multitask personalized recognition of emotions evoked by textual content, in: 2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops), IEEE, 2022, pp. 347-352.</p>
<p>Personal bias in prediction of emotions elicited by textual opinions. P Milkowski, M Gruza, K Kanclerz, P Kazienko, D Grimling, J Kocon, 10.18653/v1/2021.acl-srw.26Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research WorkshopAssociation for Computational LinguisticsP. Milkowski, M. Gruza, K. Kanclerz, P. Kazienko, D. Grimling, J. Kocon, Personal bias in prediction of emotions elicited by textual opinions, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Inter- national Joint Conference on Natural Language Processing: Student Research Workshop, Association for Computational Linguistics, Online, 2021, pp. 248-259. URL: https://aclanthology.org/2021. acl-srw.26. doi:10.18653/v1/2021.acl-srw.26.</p>
<p>Making pre-trained language models better few-shot learners. T Gao, A Fisch, D Chen, 10.18653/v1/2021.acl-long.295Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingAssociation for Computational Linguistics1Long Papers)T. Gao, A. Fisch, D. Chen, Making pre-trained language models better few-shot learners, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Inter- national Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, On- line, 2021, pp. 3816-3830. URL: https://aclanthology.org/2021. acl-long.295. doi:10.18653/v1/2021.acl-long.295.</p>
<p>A prompt pattern catalog to enhance prompt engineering with chatgpt. J White, Q Fu, S Hays, M Sandborn, C Olea, H Gilbert, A Elnashar, J Spencer-Smith, D C Schmidt, arXiv:2302.113822023J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. El- nashar, J. Spencer-Smith, D. C. Schmidt, A prompt pattern catalog to enhance prompt engineering with chatgpt, 2023. arXiv:2302.11382.</p>
<p>The ethics of AI ethics: An evaluation of guidelines, in: Minds Mach. T Hagendorff, 10.1007/s11023-020-09517-8doi:10.1007/s11023-020-09517-830T. Hagendorff, The ethics of AI ethics: An evaluation of guidelines, in: Minds Mach., volume 30, 2020, pp. 99-120. URL: https://doi. org/10.1007/s11023-020-09517-8. doi:10.1007/s11023-020-09517-8.</p>
<p>A Borji, 10.48550/arXiv.2302.03494arXiv:2302.03494A categorical archive of ChatGPT failures, in: arXiv. A. Borji, A categorical archive of ChatGPT failures, in: arXiv, vol- ume abs/2302.03494, 2023. URL: https://doi.org/10.48550/arXiv. 2302.03494. doi:10.48550/arXiv.2302.03494. arXiv:2302.03494.</p>
<p>Compression methods for transformers in multidomain sentiment analysis. W Korczyński, J Kocoń, 2022 IEEE International Conference on Data Mining Workshops (ICDMW). IEEEW. Korczyński, J. Kocoń, Compression methods for transformers in multidomain sentiment analysis, in: 2022 IEEE International Conference on Data Mining Workshops (ICDMW), IEEE, 2022, pp. 419-426.</p>            </div>
        </div>

    </div>
</body>
</html>