<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6783 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6783</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6783</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-130.html">extraction-schema-130</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <p><strong>Paper ID:</strong> paper-6a74efe6cf4526058d1a7dd2289e1b3d4fbb418e</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/6a74efe6cf4526058d1a7dd2289e1b3d4fbb418e" target="_blank">Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models.</p>
                <p><strong>Paper Abstract:</strong> Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6783.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6783.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as an example of a large pretrained language model that, despite many prompting attempts, was reported in this paper to be unable to solve multi‑step Sudoku puzzles.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder‑only transformer language model (mentioned in passing; no experiments in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>constraint satisfaction / combinatorial logic / spatial reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>various prompting strategies attempted (not detailed in this paper); described as ineffective</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>qualitative failure (no quantitative metric reported here)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Unable to solve Sudoku via prompting (no numeric success rate provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Paper states that 'despite the various ideas for prompting GPT-3, GPT-3 is not able to solve Sudoku' and uses this as evidence that off‑the‑shelf LLM prompting struggles on multi‑step logical / system‑2 tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Reported limitation (in this paper): prompting GPT‑3 did not yield successful Sudoku solutions; LLM prompting alone insufficient for this multi‑step constraint reasoning task.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6783.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6783.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Discussed qualitatively: Transformer‑based LLMs tend to perform poorly on multi‑step logical reasoning and system‑2 style tasks like Sudoku, according to cited analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large Language Models (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based language models (broad class; no experiments in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku / multi-step logical reasoning problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>constraint satisfaction / combinatorial logic</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>various prompting strategies (discussed externally; not evaluated here)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>not applicable (discussion only)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>qualitative claims from related work (no metrics in this paper for LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Described as performing poorly on multi-step logical reasoning tasks (no numeric results provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Cites prior analyses (e.g., Creswell et al., 2022; Nye et al., 2021) to note that LLMs are better at system‑1/intuitive tasks and tend to struggle on system‑2 logical multi‑step reasoning (such as Sudoku which often requires tens of reasoning steps).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>General limitation: LLMs struggle on multi‑step logical, constraint‑satisfaction tasks; prompting alone is insufficient as reported in the literature cited by this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6783.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6783.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Transformer (visual Sudoku)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Transformer (applied to visual Sudoku)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer encoder extended with recurrence (shared block parameters across steps) that is trained end‑to‑end (optionally with injected discrete constraint losses) to solve visual Sudoku where cells are MNIST images; jointly learns symbol grounding and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Recurrent Transformer (L1R32H4 and variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder‑only Transformer with L self‑attention blocks and R recurrences (same block parameters reused across recurrent steps), multi‑head attention, token+positional embeddings, and output softmax per variable; visual inputs are embedded via a CNN token embedder.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Example L1R32H4: ~702k parameters for visual model (211k parameters for textual variant; Table 4 gives 211,328 for textual L1R32H4 and 702k for visual L1R32H4).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku (visual, ungrounded SATNet‑V / RRN‑V)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>constraint satisfaction / spatial combinatorial logic</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SATNet‑V (ungrounded visual Sudoku), RRN‑V (ungrounded visual RRN dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>not applicable — model is trained end‑to‑end (supervised on solution boards or semi‑supervised using injected constraint losses); no natural‑language prompting</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>Iterative multi‑step reasoning via recurrence and multi‑head attention; optional injection of discrete cardinality constraints using binarization + straight‑through estimator (STE) to bias learning.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>Board represented as sequence of t=81 tokens (one per cell) with learned positional embeddings; visual cells tokenized via CNN to produce token embeddings; model maintains hidden embeddings H^(r,l) and attention matrices A^(r,l); outputs per‑cell probability distribution over digits (1..9).</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Whole‑board accuracy, solution board accuracy, per‑cell accuracy (givens / solution / whole board).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>SATNet‑V (9k/1k): L1R32H4‑V whole board accuracy 93.5%, solution board acc 93.7%, whole board cell acc 99.55%, givens cell acc 99.77%. On RRN‑V (9k/1k) L1R32H4‑V whole board 74.8%, solution 75.5%, solution cell acc 92.49%, givens 99.36%; larger L1R32H8‑V trained on 180k/18k achieved whole board 89.52% on RRN‑V (180k/18k).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Recurrent Transformer jointly learns symbol grounding and solving (classification of givens and solving improve together when trained ungrounded); attention heads specialize (separate row/column/box patterns for >=3 heads); additional recurrences at test time improve accuracy; attentions are interpretable and align with Sudoku structure; model avoids the symbol grounding failure modes that SATNet exhibits on ungrounded visual Sudoku.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td>Ablations show recurrence is essential (non‑recurrent L64R1 performs poorly); applying cross‑entropy loss at every block and recurrence improves convergence vs only final output; removing positional embeddings drops test accuracy from 100% to 0%; using >=3 attention heads separates row/column/box attentions and speeds convergence; increasing L, H, or dh improves accuracy at cost of size.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires learned positional embeddings (critical); performance depends on number of recurrences and blocks (more recurrences at inference help); model sizes larger for higher accuracy; although robust, very hard puzzles still see degraded accuracy (e.g., RRN‑hardest ~96.7% for textual).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6783.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6783.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Transformer (textual Sudoku)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Transformer (applied to textual Sudoku)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Same Recurrent Transformer architecture applied to symbolic/textual Sudoku (inputs are integer digits with zero for empty cells); trained end‑to‑end and outperforms prior neural baselines on textual Sudoku.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Recurrent Transformer (e.g., L1R32H4)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder Transformer with recurrence; token embedding for textual digits (linear layer), positional embeddings, multi‑head attention; output softmax per cell over digits.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Example L1R32H4 textual: ~211k parameters (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku (textual SATNet and RRN datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>constraint satisfaction / combinatorial logic</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SATNet (textual), RRN (textual), RRN‑hardest</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>not applicable — supervised training on puzzle/solution pairs (loss accumulated over outputs from all recurrent steps and blocks).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>Iterative multi‑step reasoning via recurrence and attention; optional constraint losses that encode cardinality constraints via binarization + STE.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>Sequence of 81 tokens representing cells; token embeddings + positional embeddings; outputs X^(r,l) ∈ [0,1]^(81 x 9); attention matrices A^(r,l) learned and interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Whole‑board accuracy (percentage of boards solved completely), per‑cell accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Textual SATNet dataset: L1R32H4 achieved 100% whole‑board accuracy; on RRN dataset L1R32H4 achieved 99.5% and on RRN‑hardest 96.7% (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>More total self‑attention steps (L * R) improve accuracy; recurrence is essential; applying losses at all blocks speeds convergence and improves stability; attention heads segregate semantics (row/column/box).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td>Removing positional embedding: accuracy 100% -> 0%; non‑recurrent 32‑block vanilla Transformer underperforms recurrent variants; applying loss to all blocks (vs only last) boosts performance and stability (see B.2 figures).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Performance decreases on hardest puzzles but remains high; requires design choices (recurrence, heads, positional embeddings) to be tuned; constraint injection required to improve sample efficiency on small labeled sets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6783.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6783.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Transformer (Nonograms)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Transformer (applied to Nonogram puzzles)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applied Recurrent Transformer to Nonogram (gridded binary image reconstruction) by encoding row/column constraints into token embeddings and predicting binary cell values; achieved high accuracy on small grids.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Recurrent Transformer (L1R16H4 used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder Transformer with recurrence; each grid cell represented as concatenated vectors of its row and column constraints; sequence length = N^2; output binary classification per cell.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Nonogram (7x7 and 15x15)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>constraint satisfaction / spatial pattern reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Custom Nonogram datasets (7x7 and 15x15, 9k/1k splits)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>not applicable — trained end‑to‑end supervised on puzzle/solution pairs</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>Iterative recurrence with attention across all cells to satisfy row/column run constraints</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>Each cell token is the concatenation of its row and column constraint vectors (padded to fixed length); positional encoding implicit in token order representing grid positions.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Test accuracy (percentage of boards/cells solved correctly)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>7x7: 97.5% test accuracy; 15x15: 78.3% test accuracy (L1R16H4).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Model can learn to satisfy run constraints and reconstruct images; performance degrades on larger grids (15x15) but remains substantial; same recurrent attention mechanism effectively captures nonogram constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Performance drops with increasing grid size and complexity; no further scaling or curriculum strategies tested in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6783.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6783.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Transformer (Shortest Path)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Transformer (applied to shortest path CSP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applied to shortest‑path formulated as CSP (nodes and edges as Boolean variables) and augmented with a path constraint loss via cardinality STE; improved constraint accuracy versus baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Recurrent Transformer (L1R32)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder Transformer with recurrence; input tokens represent nodes and edges with simple numeric encodings; output per‑edge TRUE/FALSE probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Shortest Path (grid graphs: SP4 4x4 and SP12 12x12)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>graph constraint satisfaction / combinatorial optimization</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SP4 (4x4 grid dataset from Xu et al., 2018) and SP12 (12x12 dataset generated by authors)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>not applicable — supervised training; optional semantic/constraint loss added</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>Iterative recurrence with optional injected path constraint loss encoding degree/cardinality constraints (via STE) to encourage valid paths and shortest path solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>Sequence of m+n tokens (m nodes + n edges); adjacency matrix M used to build constraint losses; outputs per‑edge probability vector v aggregated into path constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Constraint accuracy: percentage of predictions forming a valid path, avoiding removed edges, and being a shortest path.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On SP4 test: L1R32 baseline constraint accuracy: Path 84.5%, Shortest path 83.5%; with injected path constraint loss L_path: Path 91.9%, Shortest path 91.0%. On SP12: 72.3% (cross‑entropy only) vs 76.0% (with constraint loss).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Recurrent Transformer outperforms simple MLP baselines on path constraints; injection of domain constraints via cardinality STE significantly improves validity and optimality of predicted paths.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td>Adding explicit path constraint loss improved path validity from 84.5% -> 91.9% and shortest‑path accuracy 83.5% -> 91.0% (SP4).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Performance declines on larger graphs; requires appropriate design of constraint loss and weighting to avoid overwriting label signals if too much unlabeled data / high constraint weight used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6783.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6783.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Transformer (MNIST Mapping)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Transformer (applied to MNIST mapping / symbol grounding test)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applied to MNIST mapping problem (learning bijection from MNIST images to symbolic digits) as a test of symbol grounding; achieved high accuracy demonstrating robustness to symbol grounding issues.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Recurrent Transformer (L1R32, CNN token embedder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder Transformer with recurrence; single token sequence length 1 in MNIST mapping setting, CNN used to embed images.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>MNIST Mapping (symbol grounding task)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>symbol grounding / mapping / classification</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>MNIST Mapping dataset (as used in Chang et al., 2020 comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>not applicable — supervised end‑to‑end learning</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>Joint representation learning and iterative refinement through recurrence</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>Input is MNIST image embedded via CNN; model outputs probability distribution over 10 symbolic digits.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (correct bijection mapping rate)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Achieved 99% accuracy on MNIST Mapping task (reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Recurrent Transformer is robust to symbol grounding issues that plague SATNet when not grounded; classification and reasoning are learned jointly rather than as separate stages.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>No further scaling experiments reported; specific training details tuned to dataset; not a demonstration of few‑shot prompting but of supervised learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver <em>(Rating: 2)</em></li>
                <li>Recurrent Relational Networks <em>(Rating: 2)</em></li>
                <li>Assessing SATNet's ability to solve the symbol grounding problem <em>(Rating: 2)</em></li>
                <li>Techniques for symbol grounding with SATNet <em>(Rating: 2)</em></li>
                <li>Injecting logical constraints into neural networks via straight-through estimators <em>(Rating: 2)</em></li>
                <li>Selection-inference: Exploiting large language models for interpretable logical reasoning <em>(Rating: 1)</em></li>
                <li>Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6783",
    "paper_id": "paper-6a74efe6cf4526058d1a7dd2289e1b3d4fbb418e",
    "extraction_schema_id": "extraction-schema-130",
    "extracted_data": [
        {
            "name_short": "GPT-3",
            "name_full": "GPT-3",
            "brief_description": "Mentioned as an example of a large pretrained language model that, despite many prompting attempts, was reported in this paper to be unable to solve multi‑step Sudoku puzzles.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-3",
            "model_description": "Decoder‑only transformer language model (mentioned in passing; no experiments in this paper).",
            "model_size": null,
            "puzzle_name": "Sudoku",
            "puzzle_type": "constraint satisfaction / combinatorial logic / spatial reasoning",
            "dataset_name": null,
            "prompting_method": "various prompting strategies attempted (not detailed in this paper); described as ineffective",
            "reasoning_technique": null,
            "internal_representation": null,
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "qualitative failure (no quantitative metric reported here)",
            "performance": "Unable to solve Sudoku via prompting (no numeric success rate provided in this paper).",
            "analysis_findings": "Paper states that 'despite the various ideas for prompting GPT-3, GPT-3 is not able to solve Sudoku' and uses this as evidence that off‑the‑shelf LLM prompting struggles on multi‑step logical / system‑2 tasks.",
            "ablation_comparison": null,
            "limitations": "Reported limitation (in this paper): prompting GPT‑3 did not yield successful Sudoku solutions; LLM prompting alone insufficient for this multi‑step constraint reasoning task.",
            "uuid": "e6783.0",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "LLMs (general)",
            "name_full": "Large Language Models",
            "brief_description": "Discussed qualitatively: Transformer‑based LLMs tend to perform poorly on multi‑step logical reasoning and system‑2 style tasks like Sudoku, according to cited analyses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Large Language Models (unspecified)",
            "model_description": "Transformer-based language models (broad class; no experiments in this paper).",
            "model_size": null,
            "puzzle_name": "Sudoku / multi-step logical reasoning problems",
            "puzzle_type": "constraint satisfaction / combinatorial logic",
            "dataset_name": null,
            "prompting_method": "various prompting strategies (discussed externally; not evaluated here)",
            "reasoning_technique": "not applicable (discussion only)",
            "internal_representation": null,
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "qualitative claims from related work (no metrics in this paper for LLMs)",
            "performance": "Described as performing poorly on multi-step logical reasoning tasks (no numeric results provided in this paper).",
            "analysis_findings": "Cites prior analyses (e.g., Creswell et al., 2022; Nye et al., 2021) to note that LLMs are better at system‑1/intuitive tasks and tend to struggle on system‑2 logical multi‑step reasoning (such as Sudoku which often requires tens of reasoning steps).",
            "ablation_comparison": null,
            "limitations": "General limitation: LLMs struggle on multi‑step logical, constraint‑satisfaction tasks; prompting alone is insufficient as reported in the literature cited by this paper.",
            "uuid": "e6783.1",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Recurrent Transformer (visual Sudoku)",
            "name_full": "Recurrent Transformer (applied to visual Sudoku)",
            "brief_description": "A Transformer encoder extended with recurrence (shared block parameters across steps) that is trained end‑to‑end (optionally with injected discrete constraint losses) to solve visual Sudoku where cells are MNIST images; jointly learns symbol grounding and reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Recurrent Transformer (L1R32H4 and variants)",
            "model_description": "Encoder‑only Transformer with L self‑attention blocks and R recurrences (same block parameters reused across recurrent steps), multi‑head attention, token+positional embeddings, and output softmax per variable; visual inputs are embedded via a CNN token embedder.",
            "model_size": "Example L1R32H4: ~702k parameters for visual model (211k parameters for textual variant; Table 4 gives 211,328 for textual L1R32H4 and 702k for visual L1R32H4).",
            "puzzle_name": "Sudoku (visual, ungrounded SATNet‑V / RRN‑V)",
            "puzzle_type": "constraint satisfaction / spatial combinatorial logic",
            "dataset_name": "SATNet‑V (ungrounded visual Sudoku), RRN‑V (ungrounded visual RRN dataset)",
            "prompting_method": "not applicable — model is trained end‑to‑end (supervised on solution boards or semi‑supervised using injected constraint losses); no natural‑language prompting",
            "reasoning_technique": "Iterative multi‑step reasoning via recurrence and multi‑head attention; optional injection of discrete cardinality constraints using binarization + straight‑through estimator (STE) to bias learning.",
            "internal_representation": "Board represented as sequence of t=81 tokens (one per cell) with learned positional embeddings; visual cells tokenized via CNN to produce token embeddings; model maintains hidden embeddings H^(r,l) and attention matrices A^(r,l); outputs per‑cell probability distribution over digits (1..9).",
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "Whole‑board accuracy, solution board accuracy, per‑cell accuracy (givens / solution / whole board).",
            "performance": "SATNet‑V (9k/1k): L1R32H4‑V whole board accuracy 93.5%, solution board acc 93.7%, whole board cell acc 99.55%, givens cell acc 99.77%. On RRN‑V (9k/1k) L1R32H4‑V whole board 74.8%, solution 75.5%, solution cell acc 92.49%, givens 99.36%; larger L1R32H8‑V trained on 180k/18k achieved whole board 89.52% on RRN‑V (180k/18k).",
            "analysis_findings": "Recurrent Transformer jointly learns symbol grounding and solving (classification of givens and solving improve together when trained ungrounded); attention heads specialize (separate row/column/box patterns for &gt;=3 heads); additional recurrences at test time improve accuracy; attentions are interpretable and align with Sudoku structure; model avoids the symbol grounding failure modes that SATNet exhibits on ungrounded visual Sudoku.",
            "ablation_comparison": "Ablations show recurrence is essential (non‑recurrent L64R1 performs poorly); applying cross‑entropy loss at every block and recurrence improves convergence vs only final output; removing positional embeddings drops test accuracy from 100% to 0%; using &gt;=3 attention heads separates row/column/box attentions and speeds convergence; increasing L, H, or dh improves accuracy at cost of size.",
            "limitations": "Requires learned positional embeddings (critical); performance depends on number of recurrences and blocks (more recurrences at inference help); model sizes larger for higher accuracy; although robust, very hard puzzles still see degraded accuracy (e.g., RRN‑hardest ~96.7% for textual).",
            "uuid": "e6783.2",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Recurrent Transformer (textual Sudoku)",
            "name_full": "Recurrent Transformer (applied to textual Sudoku)",
            "brief_description": "Same Recurrent Transformer architecture applied to symbolic/textual Sudoku (inputs are integer digits with zero for empty cells); trained end‑to‑end and outperforms prior neural baselines on textual Sudoku.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Recurrent Transformer (e.g., L1R32H4)",
            "model_description": "Encoder Transformer with recurrence; token embedding for textual digits (linear layer), positional embeddings, multi‑head attention; output softmax per cell over digits.",
            "model_size": "Example L1R32H4 textual: ~211k parameters (Table 4).",
            "puzzle_name": "Sudoku (textual SATNet and RRN datasets)",
            "puzzle_type": "constraint satisfaction / combinatorial logic",
            "dataset_name": "SATNet (textual), RRN (textual), RRN‑hardest",
            "prompting_method": "not applicable — supervised training on puzzle/solution pairs (loss accumulated over outputs from all recurrent steps and blocks).",
            "reasoning_technique": "Iterative multi‑step reasoning via recurrence and attention; optional constraint losses that encode cardinality constraints via binarization + STE.",
            "internal_representation": "Sequence of 81 tokens representing cells; token embeddings + positional embeddings; outputs X^(r,l) ∈ [0,1]^(81 x 9); attention matrices A^(r,l) learned and interpretable.",
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "Whole‑board accuracy (percentage of boards solved completely), per‑cell accuracy.",
            "performance": "Textual SATNet dataset: L1R32H4 achieved 100% whole‑board accuracy; on RRN dataset L1R32H4 achieved 99.5% and on RRN‑hardest 96.7% (Table 1).",
            "analysis_findings": "More total self‑attention steps (L * R) improve accuracy; recurrence is essential; applying losses at all blocks speeds convergence and improves stability; attention heads segregate semantics (row/column/box).",
            "ablation_comparison": "Removing positional embedding: accuracy 100% -&gt; 0%; non‑recurrent 32‑block vanilla Transformer underperforms recurrent variants; applying loss to all blocks (vs only last) boosts performance and stability (see B.2 figures).",
            "limitations": "Performance decreases on hardest puzzles but remains high; requires design choices (recurrence, heads, positional embeddings) to be tuned; constraint injection required to improve sample efficiency on small labeled sets.",
            "uuid": "e6783.3",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Recurrent Transformer (Nonograms)",
            "name_full": "Recurrent Transformer (applied to Nonogram puzzles)",
            "brief_description": "Applied Recurrent Transformer to Nonogram (gridded binary image reconstruction) by encoding row/column constraints into token embeddings and predicting binary cell values; achieved high accuracy on small grids.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Recurrent Transformer (L1R16H4 used in experiments)",
            "model_description": "Encoder Transformer with recurrence; each grid cell represented as concatenated vectors of its row and column constraints; sequence length = N^2; output binary classification per cell.",
            "model_size": null,
            "puzzle_name": "Nonogram (7x7 and 15x15)",
            "puzzle_type": "constraint satisfaction / spatial pattern reconstruction",
            "dataset_name": "Custom Nonogram datasets (7x7 and 15x15, 9k/1k splits)",
            "prompting_method": "not applicable — trained end‑to‑end supervised on puzzle/solution pairs",
            "reasoning_technique": "Iterative recurrence with attention across all cells to satisfy row/column run constraints",
            "internal_representation": "Each cell token is the concatenation of its row and column constraint vectors (padded to fixed length); positional encoding implicit in token order representing grid positions.",
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "Test accuracy (percentage of boards/cells solved correctly)",
            "performance": "7x7: 97.5% test accuracy; 15x15: 78.3% test accuracy (L1R16H4).",
            "analysis_findings": "Model can learn to satisfy run constraints and reconstruct images; performance degrades on larger grids (15x15) but remains substantial; same recurrent attention mechanism effectively captures nonogram constraints.",
            "ablation_comparison": null,
            "limitations": "Performance drops with increasing grid size and complexity; no further scaling or curriculum strategies tested in this paper.",
            "uuid": "e6783.4",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Recurrent Transformer (Shortest Path)",
            "name_full": "Recurrent Transformer (applied to shortest path CSP)",
            "brief_description": "Applied to shortest‑path formulated as CSP (nodes and edges as Boolean variables) and augmented with a path constraint loss via cardinality STE; improved constraint accuracy versus baselines.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Recurrent Transformer (L1R32)",
            "model_description": "Encoder Transformer with recurrence; input tokens represent nodes and edges with simple numeric encodings; output per‑edge TRUE/FALSE probabilities.",
            "model_size": null,
            "puzzle_name": "Shortest Path (grid graphs: SP4 4x4 and SP12 12x12)",
            "puzzle_type": "graph constraint satisfaction / combinatorial optimization",
            "dataset_name": "SP4 (4x4 grid dataset from Xu et al., 2018) and SP12 (12x12 dataset generated by authors)",
            "prompting_method": "not applicable — supervised training; optional semantic/constraint loss added",
            "reasoning_technique": "Iterative recurrence with optional injected path constraint loss encoding degree/cardinality constraints (via STE) to encourage valid paths and shortest path solutions.",
            "internal_representation": "Sequence of m+n tokens (m nodes + n edges); adjacency matrix M used to build constraint losses; outputs per‑edge probability vector v aggregated into path constraints.",
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "Constraint accuracy: percentage of predictions forming a valid path, avoiding removed edges, and being a shortest path.",
            "performance": "On SP4 test: L1R32 baseline constraint accuracy: Path 84.5%, Shortest path 83.5%; with injected path constraint loss L_path: Path 91.9%, Shortest path 91.0%. On SP12: 72.3% (cross‑entropy only) vs 76.0% (with constraint loss).",
            "analysis_findings": "Recurrent Transformer outperforms simple MLP baselines on path constraints; injection of domain constraints via cardinality STE significantly improves validity and optimality of predicted paths.",
            "ablation_comparison": "Adding explicit path constraint loss improved path validity from 84.5% -&gt; 91.9% and shortest‑path accuracy 83.5% -&gt; 91.0% (SP4).",
            "limitations": "Performance declines on larger graphs; requires appropriate design of constraint loss and weighting to avoid overwriting label signals if too much unlabeled data / high constraint weight used.",
            "uuid": "e6783.5",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Recurrent Transformer (MNIST Mapping)",
            "name_full": "Recurrent Transformer (applied to MNIST mapping / symbol grounding test)",
            "brief_description": "Applied to MNIST mapping problem (learning bijection from MNIST images to symbolic digits) as a test of symbol grounding; achieved high accuracy demonstrating robustness to symbol grounding issues.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Recurrent Transformer (L1R32, CNN token embedder)",
            "model_description": "Encoder Transformer with recurrence; single token sequence length 1 in MNIST mapping setting, CNN used to embed images.",
            "model_size": null,
            "puzzle_name": "MNIST Mapping (symbol grounding task)",
            "puzzle_type": "symbol grounding / mapping / classification",
            "dataset_name": "MNIST Mapping dataset (as used in Chang et al., 2020 comparison)",
            "prompting_method": "not applicable — supervised end‑to‑end learning",
            "reasoning_technique": "Joint representation learning and iterative refinement through recurrence",
            "internal_representation": "Input is MNIST image embedded via CNN; model outputs probability distribution over 10 symbolic digits.",
            "use_of_external_tool": false,
            "external_tool_description": "",
            "evaluation_metric": "Accuracy (correct bijection mapping rate)",
            "performance": "Achieved 99% accuracy on MNIST Mapping task (reported in paper).",
            "analysis_findings": "Recurrent Transformer is robust to symbol grounding issues that plague SATNet when not grounded; classification and reasoning are learned jointly rather than as separate stages.",
            "ablation_comparison": null,
            "limitations": "No further scaling experiments reported; specific training details tuned to dataset; not a demonstration of few‑shot prompting but of supervised learning.",
            "uuid": "e6783.6",
            "source_info": {
                "paper_title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "rating": 2
        },
        {
            "paper_title": "Recurrent Relational Networks",
            "rating": 2
        },
        {
            "paper_title": "Assessing SATNet's ability to solve the symbol grounding problem",
            "rating": 2
        },
        {
            "paper_title": "Techniques for symbol grounding with SATNet",
            "rating": 2
        },
        {
            "paper_title": "Injecting logical constraints into neural networks via straight-through estimators",
            "rating": 2
        },
        {
            "paper_title": "Selection-inference: Exploiting large language models for interpretable logical reasoning",
            "rating": 1
        },
        {
            "paper_title": "Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning",
            "rating": 1
        }
    ],
    "cost": 0.019539749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer</h1>
<p>Zhun Yang ${ }^{1}$, Adam Ishay ${ }^{1}$ \&amp; Joohyung Lee ${ }^{1,2}$<br>${ }^{1}$ School of Computing and AI, Arizona State University, AZ, USA<br>${ }^{2}$ Global AI Center, Samsung Research, S. Korea<br>{zyang90,aishay, joolee}@asu.edu</p>
<h4>Abstract</h4>
<p>Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sampleefficient learning and semi-supervised learning for CSPs.</p>
<h2>1 INTRODUCTION</h2>
<p>Constraint Satisfaction Problems (CSPs) are about finding values of variables that satisfy given constraints. They have been widely studied in symbolic AI with an emphasis on designing efficient algorithms to deductively find solutions for explicitly stated constraints. In the recent deep learningbased approach, the focus is on inductively learning the constraints and solving them in an end-to-end manner. For example, the Recurrent Relational Network (RRN) (Palm et al., 2018) uses message passing over graph structures to learn logical constraints, achieving high accuracy in textual Sudoku. On the other hand, it uses hand-coded information about Sudoku constraints, namely, which variables are allowed to interact. Moreover, it is limited to textual input. SATNet (Wang et al., 2019) is a differentiable MAXSAT solver that can infer logical rules and can be integrated into DNNs. SATNet was shown to solve even visual Sudoku, where the input is a hand-written Sudoku board. The problem is harder because a model has to learn how to map visual inputs to symbolic digits without explicit supervision. However, Chang et al. (2020) observed a label leakage issue with the experiment; with proper evaluation, the performance of SATNet on visual Sudoku dropped to 0\%. Moreover, SATNet evaluation is limited to easy puzzles, and SATNet does not perform well on hard puzzles that RRN could solve.</p>
<p>On another aspect, although these models could learn complicated constraints purely from data, in many cases, (part of) constraints are already known, and exploiting such deductive knowledge in inductive learning could be helpful for sample-efficient and robust learning. The problem is challenging, especially if the knowledge is in the form of discrete constraints, whereas standard deep learning is mainly about optimizing the continuous and differentiable parameters.</p>
<p>This paper provides a viable solution to the limitations of the above models based on the Transformer architecture. Transformer-based models have not been shown to be effective for CSPs despite their widespread applications in language (Vaswani et al., 2017; Zhang et al., 2020; Helwe et al., 2021; Li et al., 2020) and vision (Dosovitskiy et al., 2020; Gabeur et al., 2020). Creswell et al. (2022) asserted that Transformer-based large language models (LLMs) tend to perform poorly on multi-step logical reasoning problems. In the case of Sudoku, typical solving requires about 20 to 60 steps of reasoning. Despite the various ideas for prompting GPT-3, GPT-3 is not able to solve Sudoku. Nye et al. (2021) note that LLMs work well for system 1 intuitive thinking but not for system 2 logical thinking. Given the superiority of other models on CSPs, one might conclude that Transformers are unsuitable for CSPs.</p>
<p>We find that Transformer can be successfully applied to CSPs by incorporating recurrence, which encourages the Transformer model to apply multi-step reasoning similar to RRNs. Interestingly, this simple change already yields better results than the other models above and gives several other advantages. The learning is more robust than SATNet’s. Looking at the learned attention matrices, we could interpret what the Transformer has learned. Intuitively, multi-head attention extracts distinct information about the problem structure. Adding more attention blocks and recurrences tends to make the model learn better. Analogously to the Vision Transformer (Dosovitskiy et al., 2020), our model can be easily extended to process visual input. Moreover, the model avoids the symbol grounding problem encountered by SATNet.</p>
<p>In addition, we present a way to inject discrete constraints into the Recurrent Transformer training, borrowing the idea from (Yang et al., 2022). That paper shows a way to encode logical constraints as a loss function and use Straight-Through Estimators (STE) (Courbariaux et al., 2015) to make discrete constraints meaningfully differentiable for gradient descent. We apply this idea to Recurrent Transformer with some modifications. We note that adding explicit constraint loss to all recurrent layers helps the Transformer learn more effectively. We also add a constraint loss to the attention matrix so that constraints can help learn better attentions. Including these constraint losses in training improves accuracy and lets the Transformer learn with fewer labeled data (semi-supervised learning).</p>
<p>In summary, the paper makes the following contributions.</p>
<p>Recurrent Transformer for Constraint Reasoning. We show that Recurrent Transformer is a viable approach to learning to solve CSPs, with clear advantages over state-of-the-art methods, such as RRN and SATNet.</p>
<p>Symbol Grounding with Recurrent Transformer. With the ability of Transformers to handle vision problems well, we demonstrate that our model can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. It achieves 93.5% test accuracy on the SATNet’s visual Sudoku test set, for which even the enhanced SATNet from (Topan et al., 2021) could achieve only 64.8% accuracy.</p>
<p>Injecting Logical Constraints into Transformers. We show how to inject discrete logical constraints into Recurrent Transformer training to achieve sample-efficient learning and semi-supervised learning for CSPs.</p>
<h2>2 BACKGROUND</h2>
<h3>2.1 CONSTRAINT SATISFACTION PROBLEMS</h3>
<p>A constraint satisfaction problem is defined as $\langle\mathbb{X}, \mathbb{D}, \mathbb{C}\rangle$ where $\mathbb{X}={\mathcal{X}<em t="t">{1}, \ldots, \mathcal{X}</em>}}$ is a set of $t$ logical variables; $\mathbb{D}={\mathbb{D<em t="t">{1}, \ldots, \mathbb{D}</em>}}$ and each $\mathbb{D<em i="i">{i}$ is a finite set of domain values for logical variable $\mathcal{X}</em>}$; and $\mathbb{C}$ is a set of constraints. An atom (i.e., value assignment) is of the form $\mathcal{X<em i="i">{i}=v$ where $v \in \mathbb{D}</em>}$. A constraint on a sequence $\langle\mathcal{X<em j="j">{i}, \ldots, \mathcal{X}</em>}\rangle$ of variables is a mapping: $\mathbb{D<em j="j">{i} \times \cdots \times \mathbb{D}</em>} \rightarrow {\text{TRUE, FALSE}}$ that specifies the set of atoms that can or cannot hold at the same time. A (complete) evaluation is a set of $t$ atoms ${\mathcal{X<em i="i">{i}=v \mid i \in {1, \ldots, t}, v \in \mathbb{D}</em>$, i.e., it makes all constraints TRUE.}}$. An evaluation is a solution if it does not violate any constraint in $\mathbb{C</p>
<p>One of the commonly used constraints is the cardinality constraint:</p>
<p>$$l \leq \left|\left{\mathcal{X}<em i="i">{i}=v</em>}, \ldots, \mathcal{X<em j="j">{j}=v</em>$$}\right}\right| \leq u \tag{1</p>
<p>where $l$ and $u$ are nonnegative integers denoting bounds, and for $k \in {i, \ldots, j}$, $\mathcal{X}<em k="k">{k} \in \mathbb{X}$ and $v</em>$. Cardinality constraint (1) is TRUE iff the number of atoms that are true in it is between $l$ and $u$. If $l = u$, constraint (1) can be simplified to} \in \mathbb{D}_{k</p>
<p>$$\left|\left{\mathcal{X}<em i="i">{i}=v</em>}, \ldots, \mathcal{X<em j="j">{j}=v</em>$$}\right}\right| = l \tag{2</p>
<p>which is TRUE iff the number of atoms in the given set is exactly $l$. If $i = j$ and $l = 1$, constraint (2) can be further simplified to $\mathcal{X}<em i="i">{i}=v</em>$.</p>
<p>Example 1 (CSP for Sudoku) A CSP for a Sudoku puzzle is such that $\mathbb{X} = {cell_{1}, \ldots, cell_{81}}$ denotes all 81 cells on a Sudoku board; $\mathbb{D} = {\mathbb{D}<em 81="81">{1}, \ldots, \mathbb{D}</em>_i = {1, \ldots, 9}$ (i = 1, ..., 81)}}$ and $\mathbb{D</p>
<p><sup>1</sup>The code is available at https://github.com/azreasoners/recurrent_transformer.</p>
<p>denotes all possible values in each cell; and $\mathbb{C}$ consists of constraints cell $_{i}=d$ for each given digit $d$ in cell $i$, and constraints</p>
<p>$$
\left|\left{\text { cell }<em j="j">{i}=d, \ldots, \text { cell }</em>=d\right}\right|=1
$$</p>
<p>for $d \in{1, \ldots, 9}$ and any set ${i, \ldots, j}$ of 9 cell indices that belong to the same row/column/box, saying that "each digit $d$ should appear exactly once in each row/column/box." The solution to the CSP corresponds to the solution to the Sudoku puzzle.</p>
<h1>2.2 Related MODELS</h1>
<p>Graph Neural Networks (GNNs). GNNs (Gori et al., 2005; Veličković et al., 2018; Kipf \&amp; Welling, 2017) are closely related to Transformers. They encode graph structures where adjacent nodes affect each other by recurrent message passing. The vanilla Transformer does not have an explicit encoding of the graph structure. In other words, it assumes fully connected graphs and does not exploit the sparsity of graphs. There have been many recent works to bring about the complementary nature of Transformers and GNNs, such as (Dehghani et al., 2018; Dai et al., 2019; Veličković et al., 2018; Yun et al., 2019; Rong et al., 2020; Cai \&amp; Lam, 2020; Hu et al., 2020; Ying et al., 2021; Dwivedi \&amp; Bresson, 2021).</p>
<p>SATNet. SATNet (Wang et al., 2019) explores semi-definite program relaxations as a tool for solving MAXSAT, which can be employed as a layer in deep neural networks to solve composite learning problems, such as visual Sudoku puzzles, that require both visual perception and logical reasoning. SATNet learns to solve visual Sudoku puzzles without any hand-coded knowledge, but its training relied on the "leakage" of labels, as discovered by Chang et al. (2020) and remedied by Topan et al. (2021). The following figure is from (Topan et al., 2021) to illustrate the symbol grounding problem in the context of a $3 \times 3$ portion of Sudoku. The task is to identify $a^{i n}$ given only $a_{\text {visual }}^{i n}$ and $a^{o u t}$ as the labels (called Ungrounded Dataset). However, the original SATNet training was performed on Grounded Dataset, where the labels also included $a^{i n}$ so that a digit classifier was trained with the labels in a supervised way. Obviously, learning from the Ungrounded Dataset is harder because learning cannot be broken into two stages, classifying and solving.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Neuro-Symbolic Models for Constraint Reasoning. CLR-DRNet (Bai et al., 2021) is a curriculum-learning-with-restarts model which leverages a Deep Reasoning Network (DRNet) (Chen et al., 2019) and is applied to visual Sudoku with a grounded dataset using rules given as a loss function but cannot be applied to Ungrounded Datasets. Neuro-symbolic models such as DeepProbLog (Manhaeve et al., 2018), NeurASP (Yang et al., 2020), and NeuroLog (Tsamoura et al., 2021) integrate neural networks with logic programming languages. They perform perception in neural networks and logical reasoning in hand-written logic programs. These models have shown that neural network training can benefit from constraints in logic programs.</p>
<h2>3 Recurrent Transformer for Constraint Satisfaction Problems</h2>
<h3>3.1 RECURRENT TRANSFORMERS</h3>
<p>Given a constraint satisfaction problem $\langle\mathbb{X}, \mathbb{D}, \mathbb{C}\rangle$ such that, for $i \in{1, \ldots, t}, 1 \leq\left|\mathbb{D}<em 1="1">{i}\right| \leq c$ for a constant $c$, Recurrent Transformer takes as input the sequence $\left\langle\mathcal{X}</em>}, \ldots, \mathcal{X<em i="i">{t}\right\rangle$ of logical variables and outputs the probability distribution over the values in the domain $\mathbb{D}</em>}$ of each $\mathcal{X<em i="i">{i}$. Let $c</em>}$ be the domain size of $\mathcal{X<em i="i">{i}$. Without loss of generality, we assume that the values in $\mathbb{D}</em>}$ are represented by their indices, i.e., $\mathbb{D<em i="i">{i}=\left{1, \ldots, c</em>}\right}$. The probability of $\mathcal{X<em i="i">{i}=j$ is given by the $j$-th value of the output for $\mathcal{X}</em>$.</p>
<p>A logical variable $\mathcal{X}<em h="h">{i}$ is treated as a token whose token embedding is a vector of length $d</em>}$ encoding the given information about this logical variable (e.g., some numbers, a textual description, an image, etc.). The positional embedding of $\mathcal{X<em h="h">{i}$ is a randomly initialized vector of length $d</em>}$ and is to be learned to record data-invariant information for logical variable $\mathcal{X<em k="k" o="o" t="t">{i}$. Let $\boldsymbol{E}</em>}, \boldsymbol{E<em h="h">{p o s} \in \mathbb{R}^{t \times d</em>$ denote the token and positional embeddings of $t$ logical variables. The $r$-th recurrent step in a Recurrent Transformer}</p>
<p>with $L$ self-attention blocks and $R$ recurrences can be formulated as follows $(r \in{1, \ldots, R})$ :</p>
<p>$$
\begin{aligned}
\boldsymbol{H}^{(r, 0)} &amp; =\boldsymbol{H}^{(r-1, L)} \
\boldsymbol{H}^{(r, l)} &amp; =\operatorname{block}<em _out="{out" _text="\text">{l}\left(\boldsymbol{H}^{(r, l-1)}\right) &amp; &amp; \forall l \in{1, \ldots, L} \
\boldsymbol{X}^{(r, l)} &amp; =\operatorname{softmax}\left(\operatorname{layer} _ \operatorname{norm}\left(\boldsymbol{H}^{(r, l)}\right) \cdot \boldsymbol{W}</em>\right) &amp; &amp; \forall l \in{1, \ldots, L}
\end{aligned}
$$}</p>
<p>where the initial hidden embedding $\boldsymbol{H}^{(0, L)}$ is $\boldsymbol{E}<em o="o" p="p" s="s">{t o k}+\boldsymbol{E}</em>}$ and + denotes element-wise addition; $\boldsymbol{H}^{(r, l)} \in \mathbb{R}^{t \times d_{h}}$ denotes the hidden embedding of $t$ logical variables after the $l$-th (self-attention) block in the $r$-th recurrent step; block $l_{l}$ denotes the $l$-th Transformer block in the model; layer_norm denotes layer normalization; $\cdot$ denotes matrix multiplication, $\boldsymbol{W<em h="h">{\text {out }} \in \mathbb{R}^{d</em>$ are given in Appendix A.} \times c}$ is the weight of the output layer; and $\boldsymbol{X}^{(r, l)} \in[0,1]^{t \times c}$ denotes the NN output with the hidden embedding $\boldsymbol{H}^{(r, l)}$. The figure of the model architecture and the formal definition of block $l_{l</p>
<p>For logical variable $\mathcal{X}<em i="i">{i}$ and its domain $\mathbb{D}</em>}=\left{1, \ldots, c_{i}\right}$ where $c_{i} \leq c$, the scalar $X_{i, j}^{(r, l)}$ (i.e., element $i, j$ of matrix $\boldsymbol{X}^{(r, l)}$ ) is interpreted as the probability of atom $\mathcal{X<em i="i">{i}=j$ for $j \in\left{1, \ldots, c</em>\right}$.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 1: Recurrent Transformer for visual Sudoku problem.
Example 2 (Recurrent Transformer for visual Sudoku) Figure 1 shows how Recurrent Transformer is used to solve the visual Sudoku problem from (Wang et al., 2019). Here, a Sudoku board is represented by $9 \times 9=81$ MNIST digit images where empty cells are represented by images of digit 0. The Recurrent Transformer takes as input the sequence $\left\langle\right.$ cell $\left.<em 81="81">{1}, \ldots$, cell $\left.</em>\right\rangle$ of logical variables, and outputs the probability distribution over atoms cell $<em i="i">{i}=v$ for $i \in{1, \ldots, 81}, v \in{1, \ldots, 9}$. The information given for each logical variable cell $</em>}$ is the MNIST digit image in the $i$-th cell. Within the Recurrent Transformer, the token, position, and hidden embeddings $\boldsymbol{E<em o="o" p="p" s="s">{t o k}, \boldsymbol{E}</em>$.}, \boldsymbol{H}^{(r, l)}$ are in $\mathbb{R}^{81 \times 128}$, and the output $\boldsymbol{X}^{(r, l)}$ is in $\mathbb{R}^{81 \times 9</p>
<p>Recurrence in Transformers. Adding recurrence to the standard Transformer is not a new idea, but its application to CSP is novel. Other implementations of recurrence in Transformers (Dehghani et al., 2018; Hao et al., 2019) apply causal attention to make the models predict the next token. In contrast, we use an encoder-only model with full attention and force the Transformer to update all unknown variables at every recurrence. Our Recurrent Transformer solves CSP problems incrementally, gradually predicting more unknown variables after it is confident in others. During the inference time, more recurrence steps can be used than those used in the training time, which can further boost performance. Furthermore, instead of computing a single loss on the final output as in Universal Transformer (Dehghani et al., 2018), we accumulate loss for each output from every attention block at every recurrent step, which yields better performance, as shown in Appendix B.2.</p>
<h1>3.2 Training Objective</h1>
<p>Consider a labeled data instance $\langle\boldsymbol{t}, \boldsymbol{l}\rangle$ where $\boldsymbol{t}$ is $t$ input tokens (which will be turned into the token and positional embeddings $\mathbf{E}<em o="o" p="p" s="s">{t o k}, \mathbf{E}</em>}$ ) and $\boldsymbol{l} \in{n a, 1, \ldots, c}^{t}$ is a label for $\boldsymbol{t}$, where $n a$ denotes an unknown label. Let $\boldsymbol{X}^{(r, l)} \in \mathbb{R}^{t \times c}$ be the NN output with input $\boldsymbol{t}$ at recurrent step $r \in{1, \ldots, R}$ and block $l \in{1, \ldots, L}$. The cross-entropy loss $\mathcal{L<em i="i">{\text {cross }}$ is defined as follows, where $l</em>$.}$ denotes element $i$ in $\boldsymbol{l</p>
<p>$$
\mathcal{L}<em _in_123_1_="\in{1," _ldots_="\ldots," c_125_="c}," i="i" j="j" l__i="l_{i" t_125_="t},">{\text {cross }}\left(\boldsymbol{X}^{(r, l)}, \boldsymbol{l}\right)=-\sum</em>\right)
$$}=j} \log \left(X_{i, j}^{(r, l)</p>
<p>For example, in ungrounded visual Sudoku, $\boldsymbol{t}$ is a list of $t=81$ MNIST images and $\boldsymbol{l} \in$ ${n a, 1, \ldots, 9}^{81}$ is the "ungrounded" solution for the Sudoku puzzle where the label for all given</p>
<p>digits is $n a$. The cross-entropy loss on NN output $\boldsymbol{X}^{(r, l)} \in \mathbb{R}^{81 \times 9}$ depends only on the predictions of empty cells. In other words, no supervision for given digits is provided during training.</p>
<p>The baseline loss $\mathcal{L}<em _cross="{cross" _text="\text">{\text {base }}$ is the sum of $\mathcal{L}</em>$ from all recurrent steps and blocks.}}$ over the NN output $\boldsymbol{X}^{(r, l)</p>
<p>$$
\mathcal{L}<em L_125_="L}" R_125_="R}," _in_123_1_="\in{1," _ldots_="\ldots," l="l" r="r">{\text {base }}=\sum</em>\right)
$$} \mathcal{L}_{\text {cross }}\left(\boldsymbol{X}^{(r, l)}, \boldsymbol{l</p>
<p>Note that we apply the cross-entropy loss to the NN outputs from all recurrent steps and all layers instead of from the very last one. We find that this makes the Recurrent Transformer converge faster.</p>
<h1>4 EXPERIMENTS WITH RECURRENT TRANSFORMER</h1>
<p>We use LxRyHz to denote our Recurrent Transformer with $L=x$ self-attention blocks, $R=y$ recurrent steps, and $z$ self-attention heads. If omitted, the number of heads $z$ is 4 and the embedding size $d_{h}$ is 128 .</p>
<h3>4.1 SUDOKU</h3>
<p>In this section, we apply Recurrent Transformer to solve Sudoku problem, where a board can be either textual or visual.</p>
<p>Dataset. For textual Sudoku, we use the SATNet dataset from (Wang et al., 2019) and the RRN dataset from (Palm et al., 2018). The difference is that the RRN dataset is much harder and bigger (with 17-34 given digits in each puzzle and 180k/18k training/test data) than the SATNet dataset (with 31-42 given digits and $9 \mathrm{k} / 1 \mathrm{k}$ training/test data). Each labeled data instance in textual Sudoku is $\langle\boldsymbol{t}, \boldsymbol{l}\rangle$ where $\boldsymbol{t} \in{0, \ldots, 9}^{81}$ denotes a Sudoku puzzle ( 0 represents an empty cell) and $\boldsymbol{l} \in{1, \ldots, 9}^{81}$ is the solution to the puzzle. For visual Sudoku, we use the ungrounded SATNet-V dataset from (Topan et al., 2021). SATNet-V was created based on the SATNet dataset where (i) each textual input in ${0, \ldots, 9}$ in the training (or testing resp.) split is replaced with a randomly selected MNIST image in the MNIST training (or testing resp.) dataset, and (ii) the label for each given digit is $n a$, i.e., unknown label that cannot be used to help training. In addition to SATNet-V, we created a new ungrounded dataset, RRN-V, following the same procedure based on the RRN data set. For faster evaluation of the RRN-V dataset, we randomly sampled $9 \mathrm{k} / 1 \mathrm{k}$ training/test data and denoted it by "RRN-V (9k/1k)".</p>
<p>Baselines and our Model. We take RRN and SATNet as the baselines for textual Sudoku, and take RRN, SATNet, and SATNet* (Topan et al., 2021) (which resolves the symbol grounding issue of SATNet by clustering the input images) as the baselines for visual Sudoku. As RRN was not designed for visual Sudoku, we applied the same convolutional neural network (CNN) from (Wang et al., 2019) to turn each MNIST image into the initial number embedding of that cell in RRN. For our method on both textual and visual Sudoku, we apply Recurrent Transformer as in Figure 1 where the only difference is that the token embedding layer is a linear embedding layer for textual Sudoku and is the same CNN for visual Sudoku. All evaluations of our model use 32 recurrence steps for training and 64 for evaluation, as is done in (Palm et al., 2018).</p>
<p>Table 1: Whole board accuracy on different Sudoku datasets. RRN-hardest consists of a copy of the RRN training set, while the testing set consists of only the hardest puzzles with 17 given digits in the RRN test set.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">textual Sudoku</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">visual Sudoku (Ungrounded)</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">dataset</td>
<td style="text-align: center;">SATNet</td>
<td style="text-align: center;">RRN</td>
<td style="text-align: center;">RRN-hardest</td>
<td style="text-align: center;">SATNet-V</td>
<td style="text-align: center;">RRN-V</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#given</td>
<td style="text-align: center;">31-42</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">31-42</td>
<td style="text-align: center;">17-34</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">(#train/#test)</td>
<td style="text-align: center;">(9k/1k)</td>
<td style="text-align: center;">(180k/18k)</td>
<td style="text-align: center;">(180k/1k)</td>
<td style="text-align: center;">(9k/1k)</td>
<td style="text-align: center;">(9k/1k)</td>
</tr>
<tr>
<td style="text-align: center;">Models</td>
<td style="text-align: center;">#Param (text/visual)</td>
<td style="text-align: center;">Accuracy on test data</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">RRN (Palm et al., 2018)</td>
<td style="text-align: center;">201k / 692k</td>
<td style="text-align: center;">100\%</td>
<td style="text-align: center;">98.9\%</td>
<td style="text-align: center;">96.6\%</td>
<td style="text-align: center;">0\%</td>
<td style="text-align: center;">0\%</td>
</tr>
<tr>
<td style="text-align: center;">SATNet (Wang et al., 2019)</td>
<td style="text-align: center;">618k / 1049k</td>
<td style="text-align: center;">98.3\%</td>
<td style="text-align: center;">6.1\%</td>
<td style="text-align: center;">0\%</td>
<td style="text-align: center;">0\%</td>
<td style="text-align: center;">0\%</td>
</tr>
<tr>
<td style="text-align: center;">SATNet* (Topan et al., 2021)</td>
<td style="text-align: center;">$-/ 1049 \mathrm{k}+13 \mathrm{M}($ InfoGAN)</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">64.8\%</td>
<td style="text-align: center;">0\%</td>
</tr>
<tr>
<td style="text-align: center;">L1R32H4 (ours)</td>
<td style="text-align: center;">211k / 702k</td>
<td style="text-align: center;">100\%</td>
<td style="text-align: center;">99.5\%</td>
<td style="text-align: center;">96.7\%</td>
<td style="text-align: center;">93.5\%</td>
<td style="text-align: center;">75.6\%</td>
</tr>
</tbody>
</table>
<p>Table 1 shows that our method outperforms the state-of-the-art neural network models for both textual and visual Sudoku in different difficulties. Note that among all methods, only RRN requires prior</p>
<p>knowledge about Sudoku rules (i.e., there is an edge in the graph between every 2 nodes if their related cells are in the same row/column/box). Both RRN and SATNet fail on the (ungrounded) SATNet-V dataset due to the symbol grounding issue. While SATNet^{∗} could learn to solve visual Sudoku with the ungrounded dataset, it requires training an InfoGAN with 13M parameters to cluster the inputs. Unlike SATNet^{∗}, our model works out-of-the-box on visual Sudoku without carefully adjusting the structure and outperforms SATNet^{∗} by a large margin.</p>
<p>Although the L1R32H4 model has already achieved the new state-of-the-art results, we can further improve the accuracy by increasing the number $L$ of attention blocks, the number $H$ of heads, or the hidden embedding size $d_{h}$, with a trade-off of larger model size. We will analyze the effects of these decision choices on smaller datasets in the following sections.</p>
<h3>4.1.1 Ablation Study on Model Design (LxRyHz) with Textual Sudoku</h3>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 2: (left) Running average of the test accuracy for every 10 epochs of a Recurrent Transformer with different $L$ and $R$ trained on the same 8k RRN data. (right) Test accuracy as a function of the number $T$ of recurrences when testing on different difficulty puzzles in the RRN dataset, using the same L1R32 model trained on 180k RRN data.</p>
<p>Effects of Blocks and Recurrences. To analyze the effects of blocks and recurrences, we trained six LxRy(H4) models with different numbers of self-attention blocks $L$ and recurrences $R$ on an 8k/2k (training/test) RRN dataset with $\mathcal{L}_{base}$. Figure 2 (left) compares the whole board accuracy of these models, showing that more self-attention steps (equal to $L \times R$) lead to higher accuracy. With the same number of self-attention steps, when $L$ is small (e.g., $L \leq 4$), more parameters introduced by a larger $L$ slightly increase accuracy. On the other hand, adding recurrences is essential, and the non-recurrent model L64R1 performs poorly compared to the Recurrent Transformers.</p>
<p>The number of recurrences $T$ during testing can be higher than $R$ during training. Indeed, Figure 2 (right) shows that when $T \leq 64$, the more recurrent steps $T$ are, the higher accuracy is achieved with the same L1R32 model trained with 32 steps, and the improvement is bigger for harder puzzles.</p>
<p>What Multi-Head Attentions Look at. Without prior knowledge of the Sudoku game, Recurrent Transformer learns purely from $\langle$ puzzle, solution $\rangle$ pairs that each cell should pay attention to all cells in the same row, column, and $3 \times 3$ box through the attention mechanism. We trained an L1R32 model with 1 to 4 self-attention heads on the SATNet dataset with $\mathcal{L}_{base}$. We found that the attentions on row, column, and box are clearly separated in different heads if the number of heads is greater or equal to 3 and would merge otherwise. Also, more attention heads help faster convergence, and accuracy may decrease if the number of attention heads is too small to capture different semantic meanings. More details and visualization of the attention matrices are given in Appendix B.1.</p>
<p>Effect of Positional Embedding. To evaluate the effect of positional embedding, we trained the L1R32 model without positional embedding on the SATNet dataset with $\mathcal{L}<em 1="1">{base}$, finding that removing positional embedding decreases the test accuracy from 100% to 0%. This is because positional embedding is essential for a CSP as it is the only source to differentiate logical variables (e.g., cell $</em>$ ) with the same given information (e.g., digit 2 in both cell 4 and cell 10 in Figure 1).}, \ldots$, cell $_{81</p>
<h3>4.1.2 Analyses on Symbol Grounding with Visual Sudoku</h3>
<p>In visual Sudoku, we observed similar effects of different model designs as in textual Sudoku. We refer the reader to Appendix B for more details. In this section, we analyze how the symbol grounding issue is resolved in Recurrent Transformer by applying the same L1R32 model on both the RRN-V dataset and its grounded version (i.e., the label for every given digit is provided instead of $n a$ ). For each of the two trained models, we evaluate their (i) whole board accuracy, (ii) solution accuracy where a board is counted correct if the prediction on all non-given cells is correct (even when the</p>
<p>given digits are incorrectly classified), and (iii) <em>givens cell</em> accuracy, i.e., the per-cell classification accuracy of the given cells.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: (left) The whole board accuracy and solution accuracy of the L1R32 model trained on the grounded or ungrounded RRN-V dataset (9k/1k). (right) The givens cell accuracy of the same models.</p>
<p>When trained on the grounded dataset, the L1R32 model quickly learns to classify the givens in 1 epoch, as shown in Figure 3 (right). On the other hand, with the ungrounded dataset, the L1R32 model starts to classify the givens correctly at around epoch 85. In Figure 3 (left) and (right), the solution accuracy and givens cell accuracy (with the ungrounded dataset) increase around the same time, indicating that digit classification is being jointly learned with solving. Interestingly, our model achieves 99.36% classification (givens cell) accuracy without explicitly training for it. Furthermore, the solution accuracy (75.5%) is consistently higher than the whole board accuracy (74.8%) as shown in Figure 3 (left), meaning that even when givens are not correctly classified, the solution can still be attained. We attribute this to the fact that reasoning is on the latent space instead of classifying and solving in two steps, as SATNet does.</p>
<h3>4.2 OTHER EXPERIMENTS</h3>
<p>Due to lack of space, we summarize other experiments with Recurrent Transformer below and refer the reader to Appendix D for the details.</p>
<p>16x16 Sudoku. We train our L1R32H8 model (d<sub>h</sub> = 256) on 16x16 textual Sudoku. We generate two 10k (9k/1k training/test split) datasets of difficulty "simple" with an average of 111 givens and "medium" with an average of 95 givens. With 64 recurrent steps during inference, we achieved 99.9% accuracy on both test sets, meaning that there is only one wrongly predicted board solution. Due to the absence of a 16x16 Sudoku generator that can produce fewer givens, we could not test on harder boards.</p>
<p>MNIST Mapping. The MNIST Mapping problem was proposed in (Chang et al., 2020) as a simple test for the symbol grounding problem. It requires learning a bijection that maps an image of an MNIST digit to one of the 10 symbolic digits. (Chang et al., 2020) shows that SATNet is sensitive to this task and often fails without delicate tuning. Our Recurrent Transformer achieves 99% accuracy.</p>
<p>Nonograms. Nonogram (https://en.wikipedia.org/wiki/Nonogram) is a game that consists of an initially empty N × N grid representing a binary image, where each cell must take on a value of 0 or 1. Each row and column have constraints that must be satisfied to complete the image successfully. A constraint for a row/column is a list of numbers, where each number corresponds to contiguous blocks of cells with value 1 for a row/column. The Recurrent Transformer L1R16H4 achieved 97.5% test accuracy on 7x7 grids and 78.3% on 15x15 grids.</p>
<h2>5 INJECTING LOGICAL CONSTRAINTS IN RECURRENT TRANSFORMER</h2>
<h3>5.1 INJECTING GENERAL CARDINALITY CONSTRAINTS VIA STE</h3>
<p>Although Recurrent Transformer can learn to solve CSPs purely from labeled data, we could inject the known constraints to help it learn with fewer labeled data. In this section, we follow the idea from CL-STE (Yang et al., 2022) and propose a lightweight constraint loss method for a special family of constraints in CSP, namely the cardinality constraint that restricts the number of atoms in a set that can hold at the same time.</p>
<p>The main idea of CL-STE is to use a binarization function B to turn continuous values $x$ in NN output $\boldsymbol{X}^{(r, l)}$ into discrete values $\mathrm{B}(x)$ where $\mathrm{B}(x)$ is 1 (denoting TRUE) if $x \geq 0.5$ and 0 (denoting FALSE) otherwise. A constraint loss is then defined on these Boolean values and a set of propositional formulas in the Conjunctive Normal Form (CNF). Since $\frac{\partial \mathrm{B}(x)}{\partial x}$ is zero almost everywhere, the idea of STE is to replace $\frac{\partial \mathrm{B}(x)}{\partial x}$ with a straight-through estimator $\frac{\partial s(x)}{\partial x}$ for some (sub)differentiable function $s(x)$ so that the constraint loss has a non-zero gradient on $\boldsymbol{X}^{(r, l)}$.
While CL-STE has successfully injected discrete constraints into NN training, representing cardinality constraints in CNF is tedious. On the other hand, we notice that the binarization function $\mathrm{B}(x)$ enables direct counting on discrete values. Under this observation, for the cardinality constraint</p>
<p>$$
l \leq\left|\left{\mathcal{X}<em 1="1">{i 1}=v</em>}, \ldots, \mathcal{X<em k="k">{i k}=v</em>\right}\right| \leq u
$$</p>
<p>we construct a vector $\boldsymbol{x} \in \mathbb{R}^{k}$ of probabilities of the atoms in the given set such that $x_{j}$ (i.e., element $j$ in $\boldsymbol{x}$ ) is the probability of $\mathcal{X}<em j="j">{i j}=v</em>$ for $j \in{1, \ldots, k}$, and design a constraint loss as follows:</p>
<p>$$
\mathcal{L}<em c_boldsymbol_x="c(\boldsymbol{x">{[l, u]}(\boldsymbol{x})=\mathbf{1}</em>
$$})<l} \times\left(c(\boldsymbol{x})-l\right)^{2}+\mathbf{1}_{c(\boldsymbol{x})>u} \times\left(c(\boldsymbol{x})-u\right)^{2</p>
<p>where scalar $c(\boldsymbol{x})=\sum \mathrm{B}(\boldsymbol{x})=\sum_{j} \mathrm{~B}\left(x_{j}\right)$, and $\mathbf{1}<em 1="1" i="i">{\text {condition }}$ is 1 if condition is true, 0 otherwise. Similarly, constraint $\left|\left{\mathcal{X}</em>}=v_{1}, \ldots, \mathcal{X<em k="k">{i k}=v</em>\right}\right|=n$ can be encoded in the following loss.</p>
<p>$$
\mathcal{L}_{[n]}(\boldsymbol{x})=(c(\boldsymbol{x})-n)^{2}
$$</p>
<p>In constraint losses (4) and (5), $c(\boldsymbol{x})$ is the number of 1 s in the binarized vector $\mathrm{B}(\boldsymbol{x})$, which corresponds to counting the number of true atoms in constraints (1) and (2). Note that the binarization function $\mathrm{B}(x)$ enables the counting, but its gradient $\frac{\partial \mathrm{B}(x)}{\partial x}$ is always 0 whenever differentiable, so minimizing (4) and (5) will not work in updating NN parameters.
As with CL-STE, we use the identity STE to replace the gradient $\frac{\partial \mathrm{B}(x)}{\partial x}$ with 1 so that the gradient of each constraint loss to $\mathrm{B}(x)$ becomes the "straight-though estimator" of the gradient to $x$. In this way, we can do counting on the NN output with meaningful gradients. Although CL-STE could also represent the constraint loss (5) for $n=1$ (uniqueness and existence of values), the size of the CNF representation could be huge.</p>
<p>Example 3 (Constraint Loss on Output) Cardinality constraint loss (5) can be used to define the constraints in Sudoku problem</p>
<p>$$
\mathcal{L}<em _in_123_r="\in{r" b="b" c="c" k="k" l_="l," o="o" w_="w," x_125_="x}">{\text {Sudoku }}\left(\boldsymbol{X}^{(r, l)}\right)=\sum</em>} \sum_{i \in{1, \ldots, 81}} \mathcal{L<em class="" i_="i,">{[1]}\left(\boldsymbol{X}</em>\right)
$$}^{k</p>
<p>where $\boldsymbol{X}^{(r, l)} \in \mathbb{R}^{81 \times 9}$ is the NN output; $\mathbf{X}^{r o w}, \boldsymbol{X}^{c o l}, \boldsymbol{X}^{b o x} \in \mathbb{R}^{81 \times 9}$ are reshaped copies of $\boldsymbol{X}^{(r, l)}$ such that each row in them contains the predictions in the same row/column/box; and $\boldsymbol{X}<em _Sudoku="{Sudoku" _text="\text">{i . .}^{k}$ denotes row $i$ of matrix $\boldsymbol{X}^{k}$. Intuitively, $\mathcal{L}</em>$.}}$ says that "exactly one digit in ${1, \ldots, 9}$ can be predicted in the same row/column/box". Note that, in CL-STE, the same Sudoku constraints are represented by a CNF with 729 atoms and 8991 clauses, which requires computation on a big matrix in ${-1,0,1}^{8991 \times 729</p>
<p>Furthermore, since the values in vector $\boldsymbol{x}$ are not limited to probabilities in NN outputs, we can apply these cardinality constraint losses to an attention matrix, representing additional constraints (not in the original CSP) that should be satisfied by the attention.</p>
<p>Example 4 (Constraint Loss on Attention) In Sudoku problem, an attention matrix $\boldsymbol{A}^{(r, l)} \in$ $\mathbb{R}^{81 \times 81}$ is computed in the l-th block at the $r$-th recurrence where $A_{i, j}^{(r, l)}$ is a normalized attention weight that can be interpreted as the percentage of attention from cell $i$ to cell $j$. The cardinality constraint loss (5) can also be used to define the following constraint loss</p>
<p>$$
\mathcal{L}<em _81_="[81]">{\text {attention }}\left(\boldsymbol{A}^{(r, l)}\right)=\mathcal{L}</em>)
$$}(\boldsymbol{x</p>
<p>where $\boldsymbol{x}=\sum_{j}\left(\boldsymbol{A}<em class="" j="j">{. . j}^{(r, l)} \odot \boldsymbol{M}</em>\right)$ makes all 81 cells pay attention to their adjacent cells.}\right) ; \boldsymbol{M}$ is the adjacency matrix in ${0,1}^{81 \times 81}$ such that $M_{i, j}$ is 1 iff cells $i$ and $j$ are in the same row, column, or box; $\odot$ denotes element-wise multiplication. Intuitively, the $i$-th element in $\boldsymbol{x} \in \mathbb{R}^{81}$ denotes the probability of the $i$-th cell paying attention to its adjacent cells. Minimizing $\mathcal{L}_{\text {attention }}\left(\boldsymbol{A}^{(r, l)</p>
<p>Similarly to the baseline loss $\mathcal{L}<em _cross="{cross" _text="\text">{\text {base }}$, which is the sum of $\mathcal{L}</em>}}$ over NN output $\boldsymbol{X}^{(r, l)}$ from all recurrent steps and blocks, the total constraint loss $\mathcal{L<em _text="\text" _total="{total">{\text {constraint }}$ is also accumulated over all NN outputs. The total loss with constraint loss is $\mathcal{L}</em>}}=\mathcal{L<em _constraint="{constraint" _text="\text">{\text {base }}+\mathcal{L}</em>$.}</p>
<p>The constraint loss for the Sudoku problem is</p>
<p>$$
\mathcal{L}<em L_125_="L}" R_125_="R}," _in_123_1_="\in{1," _ldots_="\ldots," l="l" r="r">{\text {constraint }}=\sum</em>}\left(\alpha \mathcal{L<em _attention="{attention" _text="\text">{\text {Sudoku }}\left(\boldsymbol{X}^{(r, l)}\right)+\beta \mathcal{L}</em>\right)\right)
$$}}\left(\boldsymbol{A}^{(r, l)</p>
<p>where $\alpha, \beta$ are reals in $[0,1]$ that are hyper-parameters specified in Appendix F.2.</p>
<h1>5.2 EXPERIMENTS ON INJECTING LOGICAL CONSTRAINTS IN RECURRENT TRANSFORMER TRAINING</h1>
<p>Table 2: Effect of adding constraint losses $\mathcal{L}<em _Sudoku="{Sudoku" _text="\text">{\text {attention }}$ (att) and $\mathcal{L}</em>$ when training the same L1R32 model on 9 k RRN or RRN -V training data.}}$ (sud) to the baseline loss $\mathcal{L}_{\text {base }</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">textual Sudoku</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">visual Sudoku</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">att</td>
<td style="text-align: center;">sud</td>
<td style="text-align: center;">$T=32$</td>
<td style="text-align: center;">$T=64$</td>
<td style="text-align: center;">$T=32$</td>
<td style="text-align: center;">$T=64$</td>
</tr>
<tr>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">80.3\%</td>
<td style="text-align: center;">81.9\%</td>
<td style="text-align: center;">72.0\%</td>
<td style="text-align: center;">75.6\%</td>
</tr>
<tr>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">80.1\%</td>
<td style="text-align: center;">84.4\%</td>
<td style="text-align: center;">74.4\%</td>
<td style="text-align: center;">79.3\%</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">83.8\%</td>
<td style="text-align: center;">86.3\%</td>
<td style="text-align: center;">76.4\%</td>
<td style="text-align: center;">79.1\%</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">83.3\%</td>
<td style="text-align: center;">87.0\%</td>
<td style="text-align: center;">79.9\%</td>
<td style="text-align: center;">83.6\%</td>
</tr>
</tbody>
</table>
<p>Table 3: Effect of adding constraint loss $\mathcal{L}_{\text {constraint }}$ and $x$ thousand Unlabeled data (denoted by $x \mathrm{kU}$ ) when training the same L1R32 model on 4 k Labeled RRN or RRN-V training data (denoted by 4 kL ).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Data</th>
<th style="text-align: center;">textual Sudoku</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">visual Sudoku</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$T=32$</td>
<td style="text-align: center;">$T=64$</td>
<td style="text-align: center;">$T=32$</td>
<td style="text-align: center;">$T=64$</td>
</tr>
<tr>
<td style="text-align: center;">4kL</td>
<td style="text-align: center;">58.0\%</td>
<td style="text-align: center;">62.0\%</td>
<td style="text-align: center;">40.9\%</td>
<td style="text-align: center;">44.0\%</td>
</tr>
<tr>
<td style="text-align: center;">4kL + $\mathcal{L}_{\text {constraint }}$</td>
<td style="text-align: center;">65.4\%</td>
<td style="text-align: center;">69.2\%</td>
<td style="text-align: center;">47.5\%</td>
<td style="text-align: center;">50.4\%</td>
</tr>
<tr>
<td style="text-align: center;">4kL + 4kU + $\mathcal{L}_{\text {constraint }}$</td>
<td style="text-align: center;">65.8\%</td>
<td style="text-align: center;">69.9\%</td>
<td style="text-align: center;">57.2\%</td>
<td style="text-align: center;">61.0\%</td>
</tr>
<tr>
<td style="text-align: center;">4kL + 8kU + $\mathcal{L}_{\text {constraint }}$</td>
<td style="text-align: center;">70.7\%</td>
<td style="text-align: center;">73.3\%</td>
<td style="text-align: center;">60.8\%</td>
<td style="text-align: center;">64.4\%</td>
</tr>
</tbody>
</table>
<p>To evaluate the effects of different logical constraint losses, we trained the L1R32 model on the 9k / 1 k (training / test) RRN dataset and the $9 \mathrm{k} / 1 \mathrm{k}$ RRN-V dataset for 300 epochs until convergence with and without constraint losses. Table 2 shows that the same Recurrent Transformer model can further be improved if, in the total loss, we include $\mathcal{L}<em _Sudoku="{Sudoku" _text="\text">{\text {attention }}$ and/or $\mathcal{L}</em>}}$ on each neural network output, where the accuracy is evaluated with 32 or 64 recurrent steps $T$ during testing. We also observe a better performance gain with $\mathcal{L<em _attention="{attention" _text="\text">{\text {Sudoku }}$ than with $\mathcal{L}</em>$ only) already learns the attention matrices well, as shown in Figure 5 in Appendix B.1. Besides, when we use 64 recurrences during testing (whereas trained with 32 recurrences), the same Recurrent Transformer model has bigger improvements in the test accuracy when it is also trained with constraint losses.}}$ because the baseline model (trained with $\mathcal{L}_{\text {base }</p>
<p>Since constraint loss $\mathcal{L}<em _Sudoku="{Sudoku" _text="\text">{\text {constraint }}$ (accumulated by $\mathcal{L}</em>}}$ and $\mathcal{L<em _constraint="{constraint" _text="\text">{\text {attention }}$ ) does not require labels, we could use it for semi-supervised learning tasks. Table 3 shows that, with only 4 k labeled data, adding $\mathcal{L}</em>$.}}$ increases the whole board accuracy of 1 k test data, which can further be improved by adding additional 4 k and 8 k unlabeled data along with $\mathcal{L}_{\text {constraint }</p>
<p>The shortest path problem is from (Xu et al., 2018) and is about finding the shortest path given a graph and the two endpoints. The example was used in (Xu et al., 2018; Yang et al., 2020) to demonstrate the effectiveness of semantic/constraint loss on neural network learning. Our experiment indicates that Recurrent Transformer achieves higher constraint accuracy, confirming the effects of the injected path constraints on Recurrent Transformer (Table 7 in Appendix D.1).</p>
<h2>6 CONCLUSION</h2>
<p>With the widespread success of Transformers on system 1 perception tasks, it is intriguing that they could also perform well on system 2 logical reasoning problems. Adding recurrences to the baseline model already outperforms the existing methods, especially on visual Sudoku puzzles with large margins ( $93.5 \%$ over enhanced SATNet's $64.8 \%$ ), successfully addressing the issue of symbol grounding. We further improve the results by injecting underlying constraints into Transformer training so that the model can learn with fewer data, converge faster, and even improve accuracy. Our experiments show that more recurrences during training tend to yield higher test accuracy and additional recurrences during testing could also help. The number of attention blocks affects the size and modeling power of Recurrent Transformer. More attention heads lead to faster convergence, and the accuracy may decrease if the heads are too few to capture different semantic meanings.</p>
<h1>ACKNOWLEDGEMENTS</h1>
<p>This work was partially supported by the National Science Foundation under Grant IIS-2006747.</p>
<h2>REFERENCES</h2>
<p>Yiwei Bai, Di Chen, and Carla P Gomes. CLR-DRNets: Curriculum learning with restarts to solve visual combinatorial games. In 27th International Conference on Principles and Practice of Constraint Programming (CP 2021). Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2021.</p>
<p>Deng Cai and Wai Lam. Graph transformer for graph-to-sequence learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 7464-7471, 2020.</p>
<p>Oscar Chang, Lampros Flokas, Hod Lipson, and Michael Spranger. Assessing SATNet's ability to solve the symbol grounding problem. Advances in Neural Information Processing Systems, 33: $1428-1439,2020$.</p>
<p>Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John M Gregoire, and Carla P Gomes. Deep reasoning networks: Thinking fast and slow. arXiv preprint arXiv:1906.00855, 2019.</p>
<p>Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: training deep neural networks with binary weights during propagations. In Proceedings of the 28th International Conference on Neural Information Processing Systems-Volume 2, pp. 3123-3131, 2015.</p>
<p>Antonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712, 2022.</p>
<p>Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V Le, and Ruslan Salakhutdinov. Transformer-XL: Attentive language models beyond a fixed-length context. arXiv preprint arXiv:1901.02860, 2019.</p>
<p>Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Łukasz Kaiser. Universal transformers. arXiv preprint arXiv:1807.03819, 2018.</p>
<p>Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16 x 16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.</p>
<p>Vijay Prakash Dwivedi and Xavier Bresson. A generalization of transformer networks to graphs. AAAI Workshop on Deep Learning on Graphs: Methods and Applications, 2021.</p>
<p>Valentin Gabeur, Chen Sun, Karteek Alahari, and Cordelia Schmid. Multi-modal transformer for video retrieval. In European Conference on Computer Vision, pp. 214-229. Springer, 2020.</p>
<p>M Gori, G Monfardini, and F Scarselli. A new model for learning in graph domains. In Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005., volume 2, pp. 729-734. IEEE, 2005.</p>
<p>Jie Hao, Xing Wang, Baosong Yang, Longyue Wang, Jinfeng Zhang, and Zhaopeng Tu. Modeling recurrence for transformer. arXiv preprint arXiv:1904.03092, 2019.</p>
<p>Chadi Helwe, Chloé Clavel, and Fabian M Suchanek. Reasoning with transformer-based models: Deep learning, but shallow reasoning. In 3rd Conference on Automated Knowledge Base Construction, 2021.</p>
<p>Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. Heterogeneous graph transformer. In Proceedings of The Web Conference 2020, pp. 2704-2710, 2020.</p>
<p>Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In Proceedings of the 5th International Conference on Learning Representations, ICLR 2017, 2017.</p>
<p>Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.</p>
<p>Wenda Li, Lei Yu, Yuhuai Wu, and Lawrence C Paulson. Isarstep: a benchmark for high-level mathematical reasoning. arXiv preprint arXiv:2006.09265, 2020.</p>
<p>Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deepproblog: Neural probabilistic logic programming. In Proceedings of Advances in Neural Information Processing Systems, pp. 3749-3759, 2018.</p>
<p>Maxwell Nye, Michael Tessler, Josh Tenenbaum, and Brenden M Lake. Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning. Advances in Neural Information Processing Systems, 34:25192-25204, 2021.</p>
<p>Rasmus Palm, Ulrich Paquet, and Ole Winther. Recurrent relational networks. In Proceedings of Advances in Neural Information Processing Systems, pp. 3368-3378, 2018.</p>
<p>Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang. Self-supervised graph transformer on large-scale molecular data. Advances in Neural Information Processing Systems, 33:12559-12571, 2020.</p>
<p>Sever Topan, David Rolnick, and Xujie Si. Techniques for symbol grounding with SATNet. Advances in Neural Information Processing Systems, 34, 2021.</p>
<p>Efthymia Tsamoura, Timothy Hospedales, and Loizos Michael. Neural-symbolic integration: A compositional perspective. In Proceedings of the AAAI Conference on Artificial Intelligence, pp. $5051-5060,2021$.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pp. 5998-6008, 2017.</p>
<p>Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. Graph Attention Networks. International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=rJXMpikCZ.</p>
<p>Po-Wei Wang, Priya L Donti, Bryan Wilder, and Zico Kolter. SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. In Proceedings of the 35th International Conference on Machine Learning (ICML), 2019.</p>
<p>Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van den Broeck. A semantic loss function for deep learning with symbolic knowledge. In Proceedings of the 35th International Conference on Machine Learning (ICML), July 2018. URL http://starai.cs.ucla.edu/papers/ XuICML18.pdf.</p>
<p>Zhun Yang, Adam Ishay, and Joohyung Lee. NeurASP: Embracing neural networks into answer set programming. In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI), pp. 1755-1762, 2020. doi: 10.24963/ijcai.2020/243.</p>
<p>Zhun Yang, Joohyung Lee, and Chiyoun Park. Injecting logical constraints into neural networks via straight-through estimators. In International Conference on Machine Learning, pp. 25096-25122. PMLR, 2022.</p>
<p>Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan Liu. Do transformers really perform badly for graph representation? Advances in Neural Information Processing Systems, 34, 2021.</p>
<p>Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim. Graph transformer networks. Advances in neural information processing systems, 32, 2019.</p>
<p>Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning, pp. 11328-11339. PMLR, 2020.</p>
<h1>A Recurrent Transformer Details</h1>
<p>Figure 4 shows a multi-layer Transformer encoder architecture (a) and the Recurrent Transformer architecture in our work (b), where every dotted box denotes a self-attention block. An output layer consists of a layer normalization, a linear layer, and a softmax activation function. In (b), all output layers share the same parameters, while every self-attention block has its own parameters.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4: (a) Transformer encoder. (b) Recurrent Transformer encoder.
The Recurrent Transformer with $L$ self-attention blocks and $R$ recurrences can be formulated as follows:</p>
<p>$$
\begin{aligned}
&amp; \boldsymbol{H}^{(r, 0)}=\boldsymbol{H}^{(r-1, L)} \
&amp; \forall r \in{1, \ldots, R} \
&amp; \boldsymbol{H}^{(r, l)}=\operatorname{block}<em _out="{out" _text="\text">{l}\left(\boldsymbol{H}^{(r, l-1)}\right) \
&amp; \forall r \in{1, \ldots, R}, \forall l \in{1, \ldots, L} \
&amp; \boldsymbol{X}^{(r, l)}=\operatorname{softmax}(\text { layer_norm }\left(\boldsymbol{H}^{(r, l)}\right) \cdot \boldsymbol{W}</em> \quad \forall r \in{1, \ldots, R}, \forall l \in{1, \ldots, L}
\end{aligned}
$$}</p>
<p>where $\boldsymbol{H}^{(r, l)} \in \mathbb{R}^{t \times d_{h}}$ denotes the hidden embeddings of $t$ input tokens after the $l$-th (self-attention) block in the $r$-th recurrent step, block $l$ denotes the $l$-th Transformer block in the model (i.e., the $l$-th dotted box in Figure 4 (b)), layer_norm denotes layer normalization, $\cdot$ denotes matrix multiplication, $\boldsymbol{W}<em h="h">{\text {out }} \in \mathbb{R}^{d</em>$.
Each block $} \times c}$ is the weight of the output layer for $c$ classes, and $\boldsymbol{X}^{(r, l)} \in[0,1]^{t \times c}$ denotes the NN output with the hidden embedding $\boldsymbol{H}^{(r, l)<em K="K">{l}$ is defined on weights $\boldsymbol{W}</em>}^{(l)}, \boldsymbol{W<em V="V">{Q}^{(l)}, \boldsymbol{W}</em>}^{(l)}, \boldsymbol{W<em h="h">{P}^{(l)} \in \mathbb{R}^{d</em>} \times d_{h}}$ (for simplicity, we describe a single-head case) and a multilayer perceptron $\mathrm{MLP<em h="h">{l}$ with output size $d</em>$.</p>
<p>$$
\begin{aligned}
&amp; \mathbf{K}^{(r, l)}=\text { layer_norm }\left(\boldsymbol{H}^{(r, l)}\right) \cdot \boldsymbol{W}<em Q="Q">{K}^{(l)} \quad \mathbf{Q}^{(r, l)}=\text { layer_norm }\left(\boldsymbol{H}^{(r, l)}\right) \cdot \boldsymbol{W}</em> \
&amp; \mathbf{V}^{(r, l)}=\text { layer_norm }\left(\boldsymbol{H}^{(r, l)}\right) \cdot \boldsymbol{W}}^{(l)<em h="h">{V}^{(l)} \quad \mathbf{A}^{(r, l)}=\operatorname{softmax}\left(\frac{\mathbf{Q}^{(r, l)}\left(\mathbf{K}^{(r, l)}\right)^{T}}{\sqrt{d</em>\right) \
&amp; \mathbf{V}^{}}<em>}=\left(\mathbf{A}^{(r, l)} \cdot \mathbf{V}^{(r, l)}\right) \cdot \boldsymbol{W}<em l="l">{P}^{(l)}+\boldsymbol{H}^{(r, l)} \
&amp; \operatorname{block}</em>^{}\left(\boldsymbol{H}^{(r, l)}\right)=\operatorname{MLP}_{l}(\text { layer_norm }\left(\mathbf{V</em>}\right))+\mathbf{V}^{*}
\end{aligned}
$$</p>
<p>Here, $\boldsymbol{H}^{(r, l)}, \mathbf{K}^{(r, l)}, \mathbf{Q}^{(r, l)}, \mathbf{V}^{(r, l)}, \mathbf{V}^{*} \in \mathbb{R}^{t \times d_{h}}$ and $\mathbf{A}^{(r, l)} \in[0,1]^{t \times t}$.
The parameters are in terms of input vocabulary size $(v)$, context size $(t)$, number of classes $(c)$, hidden embedding size $\left(d_{h}\right)$, and the hidden layer size $\left(d_{M L P}\right)$ of $\mathrm{MLP}<em h="h">{l}$, which is of shape $\left(d</em>\right)$.}\right.$, $\left.d_{M L P}, d_{h</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Operation</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Parameter Count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Parameter</td>
<td style="text-align: center;">Value</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$v$</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">Token Embedding</td>
<td style="text-align: center;">$v \times d_{h}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$t$</td>
<td style="text-align: center;">81</td>
<td style="text-align: center;">Positional Embedding</td>
<td style="text-align: center;">$t \times d_{h}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$c$</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">Multi-Head Self-Attention</td>
<td style="text-align: center;">$4\left(d_{h}^{2}+d_{h}\right)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$d_{h}$</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;">$\left(\boldsymbol{W}<em Q="Q">{K}^{(l)}, \boldsymbol{W}</em>}^{(l)}, \boldsymbol{W<em P="P">{V}^{(l)}, \boldsymbol{W}</em>\right)$}^{(l)</td>
<td style="text-align: center;">(the $d_{h}$ is for bias)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$d_{M L P}$</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">Layer normalization</td>
<td style="text-align: center;">$3 \times 2 d_{h}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">(a) Parameter Values</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{MLP}_{l}$</td>
<td style="text-align: center;">$d_{h} d_{M L P}+d_{M L P}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\left(d_{h}, d_{M L P}, d_{h}\right)$</td>
<td style="text-align: center;">$+d_{M L P} d_{h}+d_{h}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Output layer $\boldsymbol{W}_{\text {out }}$</td>
<td style="text-align: center;">$d_{h} c$</td>
</tr>
</tbody>
</table>
<p>(b) Parameter Counts</p>
<p>Table 4: Parameter values and counts for L1R32H4 model for symbolic Sudoku.</p>
<p>As shown in Table 4, the parameters and their counts are shown. There are a total of 211,328 parameters. For SATNet(Wang et al., 2019), the number of parameters for Sudoku is 618,000 in total. This is $(n+1+a u x) \times m$, where $n$ is the number of input variables, $a u x$ is the number of auxiliary variables, and $m$ is the rank of the clause matrix. The (Palm et al., 2018) work has a total of 201,194 trainable parameters, which come from the row, column, and number embeddings, and the three MLPs used for node updates, message passing, and producing output probabilities.</p>
<h1>B More Ablation Studies on Sudoku Experiments</h1>
<h2>B. 1 Effects and Visualization of Multi-Head Attention</h2>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 5: (left) Heatmaps of the learned 81x81 attention matrices in the L1R32 Recurrent Transformer with varying numbers of heads. (right) Test accuracy vs. epochs for these models.</p>
<p>Without prior knowledge of the Sudoku game, Recurrent Transformer learns purely from $\langle$ puzzle, solution $\rangle$ pairs so that each cell should pay attention to all cells in the same row, column, and $3 \times 3$ box through the attention mechanism. We trained an L1R32 model with 1 to 4 self-attention heads on the SATNet dataset with $\mathcal{L}_{\text {base }}$. Figure 5 (left) visualizes the learned attention matrices - they correctly pay attention to each row, column, and box, respectively. For example, the first row of the top-left attention matrix in Figure 5 (left) learns purely from data about the 9 atoms to</p>
<p>pay attention in constraint (3) where ${i, \ldots, j}={1, \ldots, 9}$ and $d=1$. These attentions are clearly separated into different heads if the number of heads is greater than or equal to 3 and would otherwise merge. Figure 5 (right) compares the whole board accuracy of these models, showing that more attention heads help accelerate convergence. The accuracy may decrease if the number of attention heads is too small to capture different semantic meanings.</p>
<h1>B. 2 RECURRENT TRANSFORMER VS. VANILLA TRANSFORMER</h1>
<p>There are two main decision choices in Recurrent Transformer: adding recurrence and applying losses to all blocks at all recurrent steps. To justify our decision choices, we compared 3 Transformer designs on the textual Sudoku problem under 3 settings. Figures 6, 7, and 8 show the experimental results on textual Sudoku on SATNet ( $9 \mathrm{k} / 1 \mathrm{k}$ for training/testing), Palm ( $9 \mathrm{k} / 1 \mathrm{k}$ ), and Palm ( $3 \mathrm{k} / 1 \mathrm{k}$ ) datasets where</p>
<ul>
<li>the black line denotes the vanilla Transformer L32R1 with 32 blocks and with the crossentropy loss applied to the final output;</li>
<li>the yellow line denotes the Recurrent Transformer L1R32 with a single block, 32 recurrences, and with the cross-entropy loss applied to the last output;</li>
<li>the red line denotes the Recurrent Transformer L1R32 with a single block, 32 recurrences, and with the cross-entropy loss applied to 32 outputs.
<img alt="img-6.jpeg" src="img-6.jpeg" /></li>
</ul>
<p>Figure 6: Whole-board test accuracy on SATNet $(9 \mathrm{k} / 1 \mathrm{k})$
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 7: Whole-board test accuracy on Palm $(9 \mathrm{k} / 1 \mathrm{k})$
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 8: Cell test accuracy on Palm $(3 \mathrm{k} / 1 \mathrm{k})$</p>
<p>We can see that</p>
<ul>
<li>(comparing black and yellow lines) adding recurrences allows the model to achieve higher accuracy (especially for harder problems in the Palm dataset) with much fewer parameters in the model ( 1 block vs. 32 blocks);</li>
<li>(comparing yellow and red lines) applying losses to all blocks makes the Recurrent Transformer model more stable and achieves higher accuracy than the Recurrent Transformer with a single loss;</li>
<li>(comparing Figure 8 with the other 2 figures) the benefit of recurrence and losses on all blocks is greater when the number of data is smaller. Figure 8 compares the cell accuracy under the above 3 settings when trained on only 3 k Palm data. In this figure, using recurrent blocks increases the converged cell accuracy from $17.7 \%$ to $46.3 \%$, and applying losses to all blocks further improves the cell accuracy to $76.5 \%$, and it has not converged.</li>
</ul>
<h2>B. 3 SEMI-SUPERVISED LEARNING WITH CONSTRAINT LOSS</h2>
<p>In Table 3, we showed how constraint loss helps in a semi-supervised setting for textual and visual Sudoku. To analyze the effect of constraint loss on more unlabeled data instances, we continued the experiments for both textual and visual Sudoku and recorded the running average of the test accuracy for every 10 epochs in Figures 9 and 10.
We set the batch size to around 64 in the experiments in Figure 9 and to around 128 in the experiments in Figure 10. The batch sizes are slightly adjusted to have integer number split on labeled and</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 9: Effect of adding constraint loss $\mathcal{L}_{\text {constraint }}$ and $x$ thousand Unlabeled data (denoted by $x \mathrm{kU}$ ) when training the same L1R32 model on 4 k Labeled RRN training data (denoted by 4 kL ).
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 10: Effect of adding constraint loss $\mathcal{L}<em _sudoku="{sudoku" _text="\text">{\text {constraint }}$ and $x$ thousand Unlabeled data (denoted by $x \mathrm{kU}$ ) when training the same L1R32 model on 4 k Labeled RRN-V training data (denoted by 4 kL ).
unlabeled data in each batch. To reduce the effect of hyper-parameter tuning on the weights of constraint losses, in all experiments, the weights $\langle\alpha, \beta\rangle$ of the constraint losses $\mathcal{L}</em>}}$ and $\mathcal{L<em _sudoku="{sudoku" _text="\text">{\text {uttention }}$ are set to $\langle 1,0\rangle$, i.e., only the constraint loss $\mathcal{L}</em>$ is used with fixed weight 1 . We can see that}</p>
<ul>
<li>adding constraint loss improves the baseline accuracy by a large margin when trained with limited labeled data;</li>
<li>with the help of constraint loss, adding more unlabeled data improves the accuracy in the beginning but the improvement is getting smaller;</li>
<li>if we don't lower the weight for the constraint loss and keep increasing the number of unlabeled data, adding unlabeled data may lower the accuracy at some point as the signals (i.e., gradients) from constraint loss may overwrite the signals from the labels.</li>
</ul>
<h1>B. 4 Cardinality Constraint Loss vs. CL-STE Loss</h1>
<p>The proposed cardinality constraint loss is different from the constraint loss in CL-STE Yang et al. (2022). We tried the original design of constraint loss in CL-STE but it computes too slowly due to the exponential size of CNF used to represent a cardinality constraint.</p>
<p>In Table 5, we applied the cross-entropy loss, the CL-STE loss, and the cardinality constraint loss to train the same RRN Palm et al. (2018) on the SATNet textual Sudoku dataset Wang et al. (2019). The cross-entropy loss serves as the baseline loss and is used in all four rows in Table 5 during training. Here, $R$ is the number of recurrent steps and is 32 in the RRN model; NumAtom is the number of Boolean atoms in Sudoku and is $81 \times 9=729$; and NumClause is 8991 which is the number of clauses in the CNF for Sudoku. As we can see, the proposed cardinality constraint loss has the same computation size as the cross-entropy loss, thus almost does not affect the training time. On</p>
<p>Table 5: Computation Size of Different Losses $(R=32$, NumAtom $=729$, NumClause $=8991$ )</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Loss</th>
<th style="text-align: center;">Applied To</th>
<th style="text-align: center;">Computation Size</th>
<th style="text-align: center;">Time/Epoch</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Cross Entropy</td>
<td style="text-align: center;">all recurrent steps</td>
<td style="text-align: center;">$O(R \times$ NumAtom $)$</td>
<td style="text-align: center;">120 s</td>
</tr>
<tr>
<td style="text-align: left;">CL-STE</td>
<td style="text-align: center;">first recurrent step</td>
<td style="text-align: center;">$O(1 \times$ NumAtom $\times$ NumClause $)$</td>
<td style="text-align: center;">211 s</td>
</tr>
<tr>
<td style="text-align: left;">CL-STE</td>
<td style="text-align: center;">all recurrent steps</td>
<td style="text-align: center;">$O(R \times$ NumAtom $\times$ NumClause $)$</td>
<td style="text-align: center;">3796 s</td>
</tr>
<tr>
<td style="text-align: left;">Cardinality (ours)</td>
<td style="text-align: center;">all recurrent steps</td>
<td style="text-align: center;">$O(R \times$ NumAtom $)$</td>
<td style="text-align: center;">122 s</td>
</tr>
</tbody>
</table>
<p>the other hand, the constraint loss in CL-STE computes much slower since the computation size is propositional to the number of clauses in a CNF, whose size is exponential to represent a cardinality constraint. In addition to the cross-entropy loss that is applied to the output from all recurrent steps, if we only apply the CL-STE loss to the output from the first recurrent step as done in the CL-STE paper, the training time per epoch is 211 s . Note that batch size is not included in the computation size for simplicity. All experiments use a batch size of 16 except for the third row (applying CL-STE loss to the outputs from all recurrent steps). If we apply the CL-STE loss to all recurrent steps, we have to decrease the batch size by 8 times to fit the GPU memory and the training time per epoch is increased to 3796 s.</p>
<h1>C Detailed Comparison with SOTA Models for visual Sudoku</h1>
<p>Topan et al. (2021) and Chang et al. (2020) showed that the original SATNet implementation failed on symbol grounding, which was not apparent due to a data leakage issue where labels for the input symbols were exposed during training time. Introduced in (Topan et al., 2021), the ungrounded visual Sudoku dataset does not include the symbolic label for the given numbers, while the grounded one does.</p>
<p>SATNet fails on ungrounded visual Sudoku (SATNet-V), achieving 0\% accuracy. To address this, (Topan et al., 2021) alters SATNet by using InfoGAN to cluster the inputs and then jointly trains on MAXSAT to ground the symbols and solve Sudoku. They also slightly boost performance by using an additional linear "proofreading" layer, with a final ungrounded performance of $64.8 \% \pm$ $3.0 \%$. We train improved SATNet from (Topan et al., 2021) using the harder visual Sudoku dataset RRN-V ( $9 \mathrm{k} / 1 \mathrm{k}$ ), and it performs poorly, getting $0 \%$ whole board accuracy. Unlike the SATNet improved in (Topan et al., 2021), our model works out of the box on visual Sudoku without carefully adjusting the structure. Yet, it achieves $93.5 \%$ on the same dataset, as shown in Table 6. We also extended (Palm et al., 2018) to include an image embedding layer for visual Sudoku, denoted as RRN*. Although it performs well on textual Sudoku, it fails at symbol grounding for the same boards as images, achieving no better than random performance.</p>
<p>As described in (Topan et al., 2021), the SATNet paper (Wang et al., 2019) erroneously argued a performance bound of $74.8 \%\left(0.992^{36.2}\right)$ whole board accuracy based on the input classification accuracy of LeNet ( $99.2 \%$ ) and the average number of givens (36.2). Our experiments confirm that this is wrong. We use the same CNN architecture that (Wang et al., 2019) uses, except that we change the output size to be the same as our embedding. Note that we achieved higher given cell accuracy with the same CNN ( $99.77 \%$ over $99.2 \%$ ). Also, to the best of our knowledge, no simple CNN such as this achieves $99.77 \%$ accuracy on MNIST if trained for each image separately. Following the argument above, $92.0 \%$ ( $=0.9977^{36.2}$ ) would have been the theoretical maximum. However, our model achieves $93.5 \%$ whole board accuracy on the SATNet's visual Sudoku dataset, which indicates that digit classification learning considers the relational information of Sudoku.</p>
<p>Interestingly, our model's solution board accuracies are consistently higher than whole board accuracies, meaning that even when the givens are misclassified, the empty cells are filled with the right values. This is because our model does not wait to solve after the classification of givens is completed; rather, the classification and solving are jointly done, which also explains why the accuracy of the givens is on par with more advanced vision models, which use additional techniques like data augmentation, ensembling, etc.</p>
<p>Figure 3 compares our models trained with the grounded and the ungrounded versions of the RRN-V dataset. With the grounded dataset, the input labels are quickly learned, with the model achieving $99.46 \%$ givens cell accuracy just after the first epoch, while the ungrounded version takes significantly</p>
<p>Table 6: Results on visual Sudoku (ungrounded)</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Dataset (#train/#test)</th>
<th style="text-align: center;">#givens</th>
<th style="text-align: center;">whole <br> board acc.</th>
<th style="text-align: center;">solution <br> board acc.</th>
<th style="text-align: center;">whole board <br> cell acc.</th>
<th style="text-align: center;">solution <br> cell acc.</th>
<th style="text-align: center;">givens <br> cell acc.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">SATNet (Wang et al., 2019)</td>
<td style="text-align: center;">SATNet-V (9k/1k)</td>
<td style="text-align: center;">31-42</td>
<td style="text-align: center;">0\%</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$11.2 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$11.6 \%$</td>
</tr>
<tr>
<td style="text-align: center;">SATNet* (Topan et al., 2021)</td>
<td style="text-align: center;">SATNet-V (9k/1k)</td>
<td style="text-align: center;">31-42</td>
<td style="text-align: center;">$64.8 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$98.4 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$98.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">RRN* (Palm et al., 2018)</td>
<td style="text-align: center;">SATNet-V (9k/1k)</td>
<td style="text-align: center;">31-42</td>
<td style="text-align: center;">$0 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$11.56 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">L1R32H4-V (ours)</td>
<td style="text-align: center;">SATNet-V (9k/1k)</td>
<td style="text-align: center;">31-42</td>
<td style="text-align: center;">$93.5 \%$</td>
<td style="text-align: center;">$93.7 \%$</td>
<td style="text-align: center;">$99.55 \%$</td>
<td style="text-align: center;">$99.37 \%$</td>
<td style="text-align: center;">$99.77 \%$</td>
</tr>
<tr>
<td style="text-align: center;">SATNet (Wang et al., 2019)</td>
<td style="text-align: center;">RRN-V (9k/1k)</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">$0 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$11.63 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$12.70 \%$</td>
</tr>
<tr>
<td style="text-align: center;">SATNet* (Topan et al., 2021)</td>
<td style="text-align: center;">RRN-V (9k/1k)</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">$0 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$31.08 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$74.03 \%$</td>
</tr>
<tr>
<td style="text-align: center;">RRN* (Palm et al., 2018)</td>
<td style="text-align: center;">RRN-V (9k/1k)</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">$0 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$11.69 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">L1R32H4-V (ours)</td>
<td style="text-align: center;">RRN-V (9k/1k)</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">$74.8 \%$</td>
<td style="text-align: center;">$75.5 \%$</td>
<td style="text-align: center;">$94.66 \%$</td>
<td style="text-align: center;">$92.49 \%$</td>
<td style="text-align: center;">$99.36 \%$</td>
</tr>
<tr>
<td style="text-align: center;">L1R32H8-V (ours)</td>
<td style="text-align: center;">RRN-V (180k/18k)</td>
<td style="text-align: center;">17-34</td>
<td style="text-align: center;">$89.52 \%$</td>
<td style="text-align: center;">89.56</td>
<td style="text-align: center;">$97.50 \%$</td>
<td style="text-align: center;">$96.64 \%$</td>
<td style="text-align: center;">$99.36 \%$</td>
</tr>
</tbody>
</table>
<p>SATNet<em> indicates the altered SATNet from (Topan et al., 2021) and RRN</em> indicates RRN with an image embedding layer for visual Sudoku compatibility. Givens cell accuracy refers to the per-cell classification accuracy of the given digits. solution cell accuracy refers to the per-cell accuracy of solution cells (initially empty). For solution board accuracy, a board is counted as correct when all solution cells are correct. Whole board cell accuracy refers to the combined per-cell accuracy of both given and solution cells. For whole board accuracy, a board is counted as correct when all givens and empty cells are correct.
longer, achieving $99.36 \%$ after 143 epochs. The grounded dataset appears to help improve the whole board accuracy at first but converges at a lower solution board accuracy and whole board accuracy than the model trained with the ungrounded dataset. With the ungrounded dataset, the model starts to learn the givens and solutions at the same time, at around 85 epochs. This indicates that digit classification is being jointly learned during the solving process. However, as shown in Figure 3 (left), the model has a higher solution board accuracy than the whole board accuracy. This behavior is not surprising since it is enough to solve the non-given cells by just having a sufficient embedding of the given cells without classifying them. What is more interesting is that even though the model trained on the ungrounded dataset has no access to classification labels, it still learns to classify over $99 \%$ of the givens. The large oscillations of whole board accuracy for the model trained on the unground dataset is due to classification errors, mostly due to a single given digit being misrecognized. The graph also shows that for the ungrounded version, the solution board accuracy is consistently higher than the whole board accuracy, meaning that the unground version could still solve correctly even when the classification of input digits is wrong. On the other hand, for the model learned with the grounded dataset, the solution board accuracy overlaps with the whole board accuracy, implying a dependency between the solution board accuracy and givens/classification cell accuracy. The difference in the final whole-board accuracy between grounded and ungrounded is because the grounded version must optimize the classification of the input symbols while the ungrounded version does not.</p>
<h1>D MORE DETAILS ABOUT OTHER EXPERIMENTS</h1>
<h2>D. 1 SHORTEST PATH</h2>
<p>Shortest Path in CSP. A shortest path problem can be viewed as a CSP where $\mathbb{X}=$ $\left{\right.$ node $\left.<em m="m">{1}, \ldots\right.$, node $\left.</em>\right.$, edge $\left.<em n="n">{1}, \ldots\right.$, edge $\left.</em>}\right}$ denotes all $m$ nodes and $n$ edges in a graph; $\mathbb{D}=$ $\left{\mathbb{D<em m_n="m+n">{1}, \ldots, \mathbb{D}</em>}\right}$ and $\mathbb{D<em i="i">{i}={$ FALSE, TRUE $}$; and $\mathbb{C}$ is the set of constraints specifying the two end nodes in the graph and that "the selected edges form a path between the end nodes with a minimum length". The goal is to find a solution of this CSP, which represents the solution of the shortest path problem. Here, node $</em>=$ TRUE (or edge $<em 1="1">{i}=$ TRUE resp.) represents that node $i$ (or edge $i$ resp.) is in the shortest path. Let $n</em>$ contains constraints node $}, n_{2} \in{1, \ldots, m}$ denote the indices of the 2 end nodes. $\mathbb{C<em 1="1">{n</em>=$ TRUE and node $}<em 2="2">{n</em>\right}$,}}=$ TRUE , the following constraint for the end nodes $i \in\left{n_{1}, n_{2</p>
<p>$$
\left|\left{\text { edge }<em i="i" k="k">{i 1}=\text { TRUE }, \ldots, \text { edge }</em>\right}\right|=1
$$}=\text { TRUE </p>
<p>and the following constraint for non-end nodes $i \in{1, \ldots, m} \backslash\left{n_{1}, n_{2}\right}$ in the shortest path (given from the label),</p>
<p>$$
\left|\left{\text { edge }<em i="i" k="k">{i 1}=\text { TRUE }, \ldots, \text { edge }</em>\right}\right|=2
$$}=\text { TRUE </p>
<p>where $\left{e d g e_{i 1}, \ldots\right.$, edge $\left._{i k}\right}$ are the edges connected to node $i$ in the graph. The first constraint says that "each end node should connect to exactly 1 edge in the path" and the second constraint says that "each non-end node in the path should connect to exactly 2 edges in the path".
Dataset. We use the shortest path dataset SP4 from (Xu et al., 2018) to illustrate our method where each graph is a $4 \times 4$ grid with $m=16$ nodes and $n=24$ edges. SP4 has 1610 data instances and,</p>
<p>as in (Xu et al., 2018), we split the dataset into 60%/20%/20% training/test/validation examples. In addition, we created a more challenging dataset SP12 where each graph is a $12 \times 12$ grid with $m=144$ nodes and $n=264$ edges. SP12 has 22k data instances, split into 20k/1k/1k training/test/validation examples. In each problem, two end nodes are randomly picked up, and $\frac{n}{2}$ edges are randomly removed to increase difficulty. A labeled data instance is $\langle\boldsymbol{t}, \boldsymbol{l}\rangle$ where $\boldsymbol{t} \in{0,1}^{m+n}$ such that $t_{i}=1$ denotes "node $i$ is a terminal node" when $i \leq m$, and denotes "edge $i-m$ ' is not removed" when $i&gt;m$; and $\boldsymbol{l} \in{0,1}^{n}$ such that $l_{i}=1$ denotes "edge $i$ is in the shortest path."
<img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 11: The representation used for the shortest path.
Figure 11 shows how Recurrent Transformer is used to solve the shortest path problem in a $4 \times 4$ grid with $m=16$ nodes and $n=24$ edges. The information given for each logical variable node $e_{i}$ $(i \in{1, \ldots, 16})$ is a single digit 1 or 0 denoting that node $i$ is an end node or not. The given information for edge $e_{i}(i \in{1, \ldots, 24})$ is a single digit 2 or 3 denoting that the edge $i$ is removed or not. Given a NN output $\boldsymbol{X}^{(r, l)} \in \mathbb{R}^{40 \times 2}$ for 40 logical variables, we construct the vector $\boldsymbol{v} \in \mathbb{R}^{24}$ such that $v_{i}=X_{i+16,2}^{(r, l)}$, denoting the probabilities of edge $e_{i}=$ TRUE for $i \in{1, \ldots, 24}$. Let $\boldsymbol{l} \in{0,1}^{24}$ denote the label, i.e., $l_{i}=1$ iff edge $i$ is in the shortest path. The cross-entropy loss is defined on $\boldsymbol{v}$ and $\boldsymbol{l}$.
For the optional constraint loss, let $\boldsymbol{M}$ be the matrix in ${0,1}^{16 \times 24}$ such that $M_{i, j}=1$ iff node $i$ is connected with edge $j$ in the graph. Let $\boldsymbol{c} \in{0,1,2,3,4}^{16}$ be $\boldsymbol{M} \cdot \boldsymbol{l}$. Intuitively, $c_{i}$ denotes the number of edges in the shortest path containing node $i$, and $c_{i}&gt;0$ means that node $i$ is in the shortest path. Then, constraints (6) and (7) can be encoded as follows:</p>
<p>$$
\begin{aligned}
\mathcal{L}<em _in_left_123_n__1="\in\left{n_{1" i="i">{\text {path }}\left(\boldsymbol{X}^{(r, l)}\right)= &amp; \sum</em>}, n_{2}\right}}\left(\mathcal{L<em i_:="i,:">{[1]}\left(\boldsymbol{M}</em>\right)\right)+ \
&amp; \sum_{i \in{1, \ldots, 16} \backslash\left{n_{1}, n_{2}\right}}\left(\mathbf{1}} \odot \boldsymbol{v<em i="i">{c</em>}&gt;0} \times \mathcal{L<em i_:="i,:">{[2]}\left(\boldsymbol{M}</em>\right)\right)
\end{aligned}
$$} \odot \boldsymbol{v</p>
<p>where the non-zero values in $\boldsymbol{M}<em j="j">{i,:} \odot \boldsymbol{v} \in \mathbb{R}^{24}$ are the probabilities of edge $e</em>=$ TRUE for all edge $j$ that contains node $i$.</p>
<p>Table 7: Constraint accuracy on SP4 test data for the shortest path problem</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Constraint accuracy</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Path</td>
<td style="text-align: center;">No removed edges</td>
<td style="text-align: center;">Shortest path</td>
</tr>
<tr>
<td style="text-align: left;">MLP</td>
<td style="text-align: center;">$28.3 \%$</td>
<td style="text-align: center;">$32.9 \%$</td>
<td style="text-align: center;">$23.0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">MLP + Semantic Loss (Xu et al., 2018)</td>
<td style="text-align: center;">$69.9 \%$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">MLP + NeurASP (Yang et al., 2020)</td>
<td style="text-align: center;">$96.6 \%$</td>
<td style="text-align: center;">$36.3 \%$</td>
<td style="text-align: center;">$33.2 \%$</td>
</tr>
<tr>
<td style="text-align: left;">L1R32 (ours)</td>
<td style="text-align: center;">$84.5 \%$</td>
<td style="text-align: center;">$100 \%$</td>
<td style="text-align: center;">$83.5 \%$</td>
</tr>
<tr>
<td style="text-align: left;">L1R32 + $\mathcal{L}_{\text {path }}$ (ours)</td>
<td style="text-align: center;">$91.9 \%$</td>
<td style="text-align: center;">$100 \%$</td>
<td style="text-align: center;">$91.0 \%$</td>
</tr>
</tbody>
</table>
<p>Table 7 compares the constraint accuracy achieved by (i) the baseline Multi-Layer Perceptron (MLP) introduced in (Xu et al., 2018) for the shortest path problem, (ii) the NeurASP method that encodes a path constraint to help train the MLP, (iii) our Recurrent Transformer (L1R32), and (iv) the same Recurrent Transformer enhanced by the constraint loss $\mathcal{L}_{\text {path }}$. The constraint accuracy are the percentage of the predictions that (i) form a valid path between end nodes, or (ii) do not include</p>
<p>removed edges, or (iii) form a shortest path between end nodes. Table 7 shows that Recurrent Transformer significantly outperforms the baseline MLP. Besides, the constraint loss $\mathcal{L}<em _path="{path" _text="\text">{\text {path }}$ further improves the accuracy of the same Recurrent Transformer for predicting a valid path (or a shortest path resp.) from $84.5 \%$ (or $83.5 \%$ ) to $91.9 \%$ (or $91.0 \%$ ).
Furthermore, we applied the same L1R32 model to the more challenging SP12 dataset. After 2,000 epochs of training, we achieved $72.3 \%$ accuracy when trained with cross-entropy loss only and $76.0 \%$ when trained with both cross-entropy loss and constraint loss $\mathcal{L}</em>$.}</p>
<h1>D. 2 NONOGRAMS</h1>
<p>Nonogram (https://en.wikipedia.org/wiki/Nonogram) is a game consisting of an initially empty $N \times N$ grid representing a binary image, where each cell must have a value of 0 or 1. Each row and column have constraints that must be satisfied to complete the image successfully. A constraint for a row/column is a list of numbers, where each number corresponds to contiguous blocks of cells for a row/column. We created two datasets for $7 \times 7$ and $15 \times 15$ grids, each having a $9 \mathrm{k} / 1 \mathrm{k}$ training/test split. We use the same Recurrent Transformer model as in previous experiments. A sample $N \times N$ grid is input as a $N^{2}$ long sequence, where each element is a concatenated representation of the row and column constraints associated with the element. For example, for $15 \times 15$ grids, a given cell with column constraint $[1,7,4]$ and row constraint $[2,2,4,1]$ would have a corresponding sequence element of the concatenation of the two constraint vectors $[0,0,1,7,4]$ and $[0,2,2,4,1]$ (assuming the maximum constraint length is 5 ). With this simple input encoding only, our Recurrent Transformer L1R16H4 achieved $97.5 \%$ test accuracy on $7 \times 7$ grids and $78.3 \%$ test accuracy on $15 \times 15$ grids.</p>
<h2>E Code \&amp; Datasets</h2>
<p>Our Recurrent Transformer implementation is based on Andrej Karpathy's minGPT repository (https://github.com/karpathy/minGPT) under MIT license. We extend minGPT (a smaller version of GPT-3) to allow full attention, add recurrences, apply additional losses, and alter embeddings.</p>
<h2>E. 1 DATASET CREATED BY OTHERS</h2>
<p>SATNet and SATNet-V Datasets. The SATNet and SATNet-V datasets are from SATNet (Wang et al., 2019) repository (https://github.com/locuslab/SATNet) under MIT license.
RRN Dataset. The RRN dataset is from Recurrent Relational Networks (Palm et al., 2018) repository (https://github.com/rasmusbergpalm/recurrent-relational-networks) where no license information is provided.</p>
<p>MNIST. We use MNIST images (LeCun et al., 1998) (http://yann.lecun.com/exdb/ mnist ), which are available under the Creative Commons Attribution-Share Alike 3.0 license.</p>
<p>SP4. We use $4 \times 4$ shortest path grids from (Xu et al., 2018) (https://github.com/ UCLA-StarAI/Semantic-Loss), where no license information is provided.</p>
<h2>E. 2 Datasets CREATED by Us</h2>
<p>RRN-V. The RRN-V dataset is created using the RRN dataset and MNIST images, similar to the way how SATNet-V dataset was created in SATNet repository. We construct the visual versions of RRN training/test datasets in which each board cell is represented by a randomly selected MNIST image.</p>
<p>16x16 Sudoku. We generate 16x16 Sudoku boards using the generator here: httdp://sudoku. smike.ru/hexsudoku.htm, where no license is found. Though "medium" boards are actually labeled "hard" in their program, we label them "medium" since baseline performance is very high, and the percentage of givens is not low relative to the hardest $9 \times 9$ Sudoku hardest problems (17-givens, $21 \%$ of board).</p>
<p>Nonograms. For Nonograms dataset, we generate grids using the program "pattern.exe", available under the MIT license available here: https://www.chiark.greenend.org.uk/ sgtatham/puzzles/.
SP12. We generate $12 \times 12$ shortest path grids using the answer set solver CLINGO. ${ }^{2}$</p>
<h1>F EXPERIMENTAL DETAILS</h1>
<h2>F. 1 COMPUTING</h2>
<p>All of our experiments were done on Ubuntu 18.04.2 LTS with two 10-cores CPU Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz and four GP104 [GeForce GTX 1080].</p>
<h2>F. 2 TRAINING DETAILS</h2>
<p>We used a fixed random seed 0 for all experiments. The values of the weights $\alpha$ and $\beta$ of the constraint losses $\mathcal{L}<em _attention="{attention" _text="\text">{\text {sudoku }}$ and $\mathcal{L}</em>$ are selected from ${0,0.1,0.5,1}$ to achieve the highest training accuracy.
Textual Sudoku. For the weights $\langle\alpha, \beta\rangle$ of the constraint losses $\mathcal{L}}<em _attention="{attention" _text="\text">{\text {sudoku }}$ and $\mathcal{L}</em>$, we used $\langle 0,0\rangle,\langle 0,1\rangle,\langle 1,0\rangle$, and $\langle 0.5,0.5\rangle$ in the 4 textual Sudoku experiments in Table 2. The model structure and hyperparameters are shown in Table 8.}</p>
<p>Table 8: Model Structure and Hyperparameters for Textual Sudoku Experiments</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">SATNET,RRN (9k/1k)</th>
<th style="text-align: left;">RRN (180k/(10k/1k))</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Model Structure</td>
<td style="text-align: left;">Value</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Number of attention heads</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">8</td>
</tr>
<tr>
<td style="text-align: left;">Number of layers</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">Number of recurrences (training/inference)</td>
<td style="text-align: left;">$32 / 64$</td>
<td style="text-align: left;">$32 / 64$</td>
</tr>
<tr>
<td style="text-align: left;">Embedding dimension</td>
<td style="text-align: left;">128</td>
<td style="text-align: left;">256</td>
</tr>
<tr>
<td style="text-align: left;">Token Embedder</td>
<td style="text-align: left;">Linear</td>
<td style="text-align: left;">Linear</td>
</tr>
<tr>
<td style="text-align: left;">Sequence length</td>
<td style="text-align: left;">81</td>
<td style="text-align: left;">81</td>
</tr>
<tr>
<td style="text-align: left;">Hyperparameter</td>
<td style="text-align: left;">Value</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">16</td>
</tr>
<tr>
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">$6 \mathrm{e}-4$</td>
<td style="text-align: left;">$6 \mathrm{e}-5$</td>
</tr>
<tr>
<td style="text-align: left;">Dropout</td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.1</td>
</tr>
</tbody>
</table>
<p>visual Sudoku. For the weights $\langle\alpha, \beta\rangle$ of the constraint losses $\mathcal{L}<em _attention="{attention" _text="\text">{\text {sudoku }}$ and $\mathcal{L}</em>$, we used $\langle 0,0\rangle,\langle 0,0.1\rangle,\langle 1,0\rangle$, and $\langle 1,0.1\rangle$ in the 4 visual Sudoku experiments in Table 2. The model structure and hyperparameters are shown in Table 9.}</p>
<p>16x16 Sudoku. The model structure and hyperparameters used for 16x16 Sudoku experiments are shown in Table 10.
Shortest Path. The model structure and hyperparameters used for shortest path experiments are shown in Table 11.</p>
<p>MNIST Mapping. The model structure and hyperparameters used for MNIST Mapping experiments are shown in Table 12.</p>
<p>Nonograms. A sample 7x7 Nonogram grid and solution is shown in Figure 12.
The model structure and hyperparameters used for Nonograms experiments are shown in Table 13.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 9: Model Structure and Hyperparameters for visual Sudoku Experiments</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model Structure</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Number of attention heads</td>
<td style="text-align: left;">4</td>
</tr>
<tr>
<td style="text-align: left;">Number of layers</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">Number of recurrences (training/inference)</td>
<td style="text-align: left;">$32 / 64$</td>
</tr>
<tr>
<td style="text-align: left;">Embedding dimension</td>
<td style="text-align: left;">128</td>
</tr>
<tr>
<td style="text-align: left;">Token Embedder</td>
<td style="text-align: left;">CNN</td>
</tr>
<tr>
<td style="text-align: left;">Sequence length</td>
<td style="text-align: left;">81</td>
</tr>
<tr>
<td style="text-align: left;">Hyperparameter</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: left;">16</td>
</tr>
<tr>
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">$6 \mathrm{e}-4$</td>
</tr>
<tr>
<td style="text-align: left;">Dropout</td>
<td style="text-align: left;">0.1</td>
</tr>
</tbody>
</table>
<p>Table 10: Model Structure and Hyperparameters for 16x16 Sudoku Experiments</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model Structure</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Number of attention heads</td>
<td style="text-align: left;">8</td>
</tr>
<tr>
<td style="text-align: left;">Number of layers</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">Number of recurrences (training/inference)</td>
<td style="text-align: left;">$32 / 64$</td>
</tr>
<tr>
<td style="text-align: left;">Embedding dimension</td>
<td style="text-align: left;">256</td>
</tr>
<tr>
<td style="text-align: left;">Token Embedder</td>
<td style="text-align: left;">Linear Embedding</td>
</tr>
<tr>
<td style="text-align: left;">Sequence length</td>
<td style="text-align: left;">256</td>
</tr>
<tr>
<td style="text-align: left;">Hyperparameter</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: left;">24</td>
</tr>
<tr>
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">$6 \mathrm{e}-4$</td>
</tr>
<tr>
<td style="text-align: left;">Dropout</td>
<td style="text-align: left;">0.1</td>
</tr>
</tbody>
</table>
<p>Table 11: Model Structure and Hyperparameters for Shortest Path Experiments</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">$4 \times 4(10 \mathrm{k} / 2 \mathrm{k})$</th>
<th style="text-align: left;">$12 \times 12(20 \mathrm{k} / 1 \mathrm{k})$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Model Structure</td>
<td style="text-align: left;">Value</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Number of attention heads</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
</tr>
<tr>
<td style="text-align: left;">Number of layers</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">Number of recurrences (training/inference)</td>
<td style="text-align: left;">$32 / 64$</td>
<td style="text-align: left;">$32 / 64$</td>
</tr>
<tr>
<td style="text-align: left;">Embedding dimension</td>
<td style="text-align: left;">128</td>
<td style="text-align: left;">128</td>
</tr>
<tr>
<td style="text-align: left;">Token Embedder</td>
<td style="text-align: left;">Linear</td>
<td style="text-align: left;">Linear</td>
</tr>
<tr>
<td style="text-align: left;">Sequence length</td>
<td style="text-align: left;">40</td>
<td style="text-align: left;">408</td>
</tr>
<tr>
<td style="text-align: left;">Hyperparameter</td>
<td style="text-align: left;">Value</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: left;">128</td>
<td style="text-align: left;">32</td>
</tr>
<tr>
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">$6 \mathrm{e}-4$</td>
<td style="text-align: left;">$6 \mathrm{e}-4$</td>
</tr>
<tr>
<td style="text-align: left;">Dropout</td>
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.1</td>
</tr>
</tbody>
</table>
<p>Table 12: Model Structure and Hyperparameters for MNIST Mapping Experiments</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model Structure</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Number of attention heads</td>
<td style="text-align: left;">4</td>
</tr>
<tr>
<td style="text-align: left;">Number of layers</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">Number of recurrences (training/inference)</td>
<td style="text-align: left;">$32 / 32$</td>
</tr>
<tr>
<td style="text-align: left;">Embedding dimension</td>
<td style="text-align: left;">128</td>
</tr>
<tr>
<td style="text-align: left;">Token Embedder</td>
<td style="text-align: left;">CNN</td>
</tr>
<tr>
<td style="text-align: left;">Sequence length</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">Hyperparameter</td>
<td style="text-align: left;">Value</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: left;">256</td>
</tr>
<tr>
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">$6 \mathrm{e}-4$</td>
</tr>
<tr>
<td style="text-align: left;">Dropout</td>
<td style="text-align: left;">0.1</td>
</tr>
</tbody>
</table>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ https://github.com/potassco/guide/releases/tag/v2.2.0&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>