<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7166 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7166</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7166</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-134.html">extraction-schema-134</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-3fa1e1c67514b9eaf9ec8da562baef8974b4f3f9</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3fa1e1c67514b9eaf9ec8da562baef8974b4f3f9" target="_blank">When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs</a></p>
                <p><strong>Paper Venue:</strong> Transactions of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This work categorizes research questions in self-correction research and provides a checklist for designing appropriate experiments and shows that no prior work demonstrates successful self-correction with feedback from prompted LLMs, except for studies in tasks that are exceptionally suited for self-correction.</p>
                <p><strong>Paper Abstract:</strong> Abstract Self-correction is an approach to improving responses from large language models (LLMs) by refining the responses using LLMs during inference. Prior work has proposed various self-correction frameworks using different sources of feedback, including self-evaluation and external feedback. However, there is still no consensus on the question of when LLMs can correct their own mistakes, as recent studies also report negative results. In this work, we critically survey broad papers and discuss the conditions required for successful self-correction. We first find that prior studies often do not define their research questions in detail and involve impractical frameworks or unfair evaluations that over-evaluate self-correction. To tackle these issues, we categorize research questions in self-correction research and provide a checklist for designing appropriate experiments. Our critical survey based on the newly categorized research questions shows that (1) no prior work demonstrates successful self-correction with feedback from prompted LLMs, except for studies in tasks that are exceptionally suited for self-correction, (2) self-correction works well in tasks that can use reliable external feedback, and (3) large-scale fine-tuning enables self-correction.</p>
                <p><strong>Cost:</strong> 0.052</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7166.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7166.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Refine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Refine (iterative refinement with self-feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An intrinsic, in‑context iterative refinement method that prompts an LLM to generate feedback on its own initial response and then refine the response using that feedback; used across tasks such as math, coding, and dialogue in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-refine: Iterative refinement with self-feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (unspecified; in cited work authors apply general LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained transformer LLMs used in few‑shot or zero‑shot prompting settings; exact architectures and sizes vary by referenced experiments and are not specified in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Self-Refine (iterative self-feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Generate an initial response, prompt the same LLM to produce feedback (critique/identify errors) about that response, then prompt the LLM again to produce a refined response conditioned on the feedback; the process can be iterated.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (iterative refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Math reasoning, code generation, dialogue, constrained generation (as reported by Madaan et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where the model must produce solutions or text (grade-school math problems, code, conversational responses, constrained generation tasks such as including specified words).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Varies by task (accuracy/EM for reasoning, pass@k or execution-based metrics for code, task-specific metrics for dialogue); the survey notes these are task dependent and often not consistently reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey calls out Self-Refine for often being evaluated in unfair settings: initial-response prompts in some experiments are purposely weak or even incorrect while stronger prompts are used for feedback, which overestimates self-correction gains; also feedback generation quality is a bottleneck and many positive claims do not hold under fair (best-possible initial response) evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7166.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7166.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RCI Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RCI Prompting (Recognition–Correction–Iteration prompting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative prompting method where the LLM recognizes and corrects errors in its outputs, sometimes using ground-truth‑based stop conditions in the referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models can solve computer tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (unspecified in survey; referenced studies use LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained transformer LLMs used with in‑context prompts; specific model variants/sizes not specified in the survey summary.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>RCI Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Iteratively prompt an LLM to (1) recognize mistakes in its generated solution, (2) optionally use a stop/update condition, and (3) correct or refine the solution; may include checks against ground-truth to determine whether to continue updating.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (iterative detection + correction)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Computer tasks / arithmetic & planning tasks cited in the RCI paper</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Algorithmic/computational tasks and reasoning tasks where generated solutions can be evaluated for correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Task-dependent correctness/accuracy or environment success; not uniformly reported by the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>The survey highlights that RCI Prompting (as reported in the cited work) can use oracle/ground-truth information as a stop condition (i.e., uses knowledge not available in realistic settings), which unfairly removes cases where the method would incorrectly update already-correct answers; thus evaluation may overstate the method's practical self-correction ability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7166.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7166.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for LLM agents that uses verbalized feedback and environment/tool interaction (e.g., game environments, code execution) to iteratively improve behavior via reinforcement-like loops.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM agents (unspecified in the survey summary)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LLM-based agents interacting with external environments/tools (game simulators, code interpreters) and generating self-reflective feedback; specific backbone models vary across referenced experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Reflexion (verbal RL / tool-interactive self-reflection)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Run the agent in an environment, collect failures/successes, generate textual reflections/feedback about failures, and use those reflections (and possibly tool results) to update future behavior or generate refined outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>environment-interactive iterative reflection (generate-run-reflect-update)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Games and coding (as reported in the referenced Reflexion experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Interactive tasks where agent actions can be executed and scored (game play, code execution leading to pass/fail signal).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Environment success measures, task-specific pass/fail; survey does not list numeric metrics</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey notes Reflexion uses feedback mechanisms that in some evaluations rely on exact matches to ground-truth or external signals that are unrealistic for pure intrinsic self-correction; such oracle-style feedback prevents using Reflexion results to answer whether LLMs can self-correct based purely on their inherent capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7166.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7166.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CRITIC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CRITIC: Tool-interactive critiquing for self-correction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-correction approach that augments LLM self-feedback with external tools (e.g., Python/code interpreter, web search) to produce higher-quality feedback and corrections for reasoning and QA tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CRITIC: Large language models can self-correct with tool-interactive critiquing</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (unspecified in survey; applied to problems like GSM8k, SVAMP, HotpotQA in the referenced paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained LLMs prompted to generate and use tool-augmented feedback (code execution, web retrieval) to critique and refine answers; exact model/backbone varies by referenced experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Tool-interactive critiquing (CRITIC)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Generate an initial solution, execute or call external tools (e.g., Python interpreter, web search) to check or validate parts of the solution, synthesize tool results into feedback, and refine the solution accordingly.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate + external-tool-augmented reflection (possibly iterative)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8k, SVAMP, HotpotQA (as cited in survey's Table 5 for CRITIC)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Arithmetic reasoning benchmarks (GSM8k, SVAMP) and multi-hop QA (HotpotQA).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (for math reasoning) and QA metrics (e.g., exact match/accuracy for HotpotQA); the survey does not report numeric values.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey emphasizes that CRITIC illustrates the general point that self-correction succeeds when reliable external tools are available; however, such tool‑augmented methods do not answer whether LLMs can self-correct using only intrinsic capabilities. Also, the paper warns about unfair evaluations that use external info for feedback but not for initial response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7166.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7166.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RARR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RARR (Researching and Revising what language models say, using language models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that uses retrieval (web search) to detect mistakes in LLM outputs and then revises outputs using retrieved external information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RARR: Researching and revising what language models say, using language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs with retrieval augmentation (unspecified in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LLMs that produce initial answers, use retrieval to gather evidence for verification, and then apply retrieved evidence to produce corrected/refined answers.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Retrieval‑augmented reflection (RARR)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Generate initial response, form queries from the response, retrieve external documents via web search, use retrieved evidence to detect and correct mistakes in the initial response.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate → retrieve → reflect/ refine (usually post-hoc correction; may be iterative)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Open‑domain QA benchmarks (e.g., Natural Questions, SQuAD variants) as cited in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Knowledge/fact‑based question answering where external evidence can validate correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>QA accuracy/EM or dataset-specific metrics; not enumerated in the survey summary.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey warns that many works (including RARR) use retrieval only during self-correction and do not allow retrieval during initial generation, creating an 'unfair' setting for evaluating whether self-correction improves the best-possible initial responses; such setups are appropriate for comparing final-system performance [RQ3] but not for answering whether self-correction can improve best-possible initial outputs [RQ2].</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7166.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7166.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-RAG: Learning to retrieve, generate, and critique through self-reflection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented self-reflection framework (as cited) that integrates retrieval, generation, and critique cycles so the model can retrieve supporting evidence and critique its own outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-RAG: Learning to retrieve, generate, and critique through self-reflection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Retrieval‑augmented LLMs (unspecified by survey)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Models that combine retrieval modules with generation and self-evaluation/critique steps; specifics depend on the referenced ICLR 2024 work.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Self-RAG (retrieve + critique + refine)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Use retrieved documents to inform generation, produce critiques of the generated output, and then refine the output conditioned on critiques and retrieval results.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>retrieve-then-reflect (feedback uses retrieved evidence) possibly iterative</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Not specified in survey summary (general retrieval-augmented generation / QA tasks implied)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks benefiting from external knowledge retrieval to verify or improve generated content (e.g., open-domain QA, long-form generation).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Task-dependent (QA accuracy, factuality metrics); survey does not report numbers for Self-RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey groups Self-RAG with methods that use external information to improve feedback quality; such methods can be effective but must be evaluated fairly depending on whether retrieval is available for initial-response generation as well as for feedback — otherwise conclusions about improving best-possible initial responses are not supported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7166.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7166.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fine-tuned self-correction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fine-tuning for self-correction (supervised SFT / RL fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approaches that train models (same or smaller auxiliary models) specifically to generate feedback or refine outputs, using supervised data or reinforcement learning to improve self-correction capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Fine-tuned LLMs (same-model or smaller fine-tuned verifiers/feedback models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained transformer LLMs further fine-tuned on supervised feedback datasets (human annotations or model-generated feedback) or trained with RL to produce feedback/refinements; often requires large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Fine-tuned feedback/refinement models (SFT / RL)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Train a feedback model to generate reference feedback and/or train a refinement model to produce corrected outputs given initial answers and feedback (can be same model fine-tuned for all stages or smaller models used cross‑model).</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>trained correction (single or iterative at inference, depending on design)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Various (code repair, proof generation, QA, summarization) depending on study</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where labeled feedback or execution-based verification is available to create supervised training signals.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Task-dependent (execution/pass@k for code, accuracy/EM for QA); survey highlights many SFT methods rely on large (>100k) training instances.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey notes SFT methods often require very large feedback datasets (>100k examples), may rely on feedback generated by stronger models (simulated human annotation), and can be unfair when feedback/refinement models are stronger than initial-response models; also unexplored territory for small-data fine-tuning and tasks lacking reliable reward functions for RL.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Self-refine: Iterative refinement with self-feedback <em>(Rating: 2)</em></li>
                <li>RCI Prompting (as in Language models can solve computer tasks / RCI) <em>(Rating: 2)</em></li>
                <li>Reflexion: Language agents with verbal reinforcement learning <em>(Rating: 2)</em></li>
                <li>CRITIC: Large language models can self-correct with tool-interactive critiquing <em>(Rating: 2)</em></li>
                <li>RARR: Researching and revising what language models say, using language models <em>(Rating: 2)</em></li>
                <li>Self-RAG: Learning to retrieve, generate, and critique through self-reflection <em>(Rating: 2)</em></li>
                <li>Large language models cannot self-correct reasoning yet <em>(Rating: 2)</em></li>
                <li>Self-critiquing models for assisting human evaluators <em>(Rating: 1)</em></li>
                <li>Teaching large language models to self-debug <em>(Rating: 1)</em></li>
                <li>Check your facts and try again: Improving large language models with external knowledge and automated feedback <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7166",
    "paper_id": "paper-3fa1e1c67514b9eaf9ec8da562baef8974b4f3f9",
    "extraction_schema_id": "extraction-schema-134",
    "extracted_data": [
        {
            "name_short": "Self-Refine",
            "name_full": "Self-Refine (iterative refinement with self-feedback)",
            "brief_description": "An intrinsic, in‑context iterative refinement method that prompts an LLM to generate feedback on its own initial response and then refine the response using that feedback; used across tasks such as math, coding, and dialogue in the cited work.",
            "citation_title": "Self-refine: Iterative refinement with self-feedback",
            "mention_or_use": "mention",
            "model_name": "Large language models (unspecified; in cited work authors apply general LLMs)",
            "model_description": "Pretrained transformer LLMs used in few‑shot or zero‑shot prompting settings; exact architectures and sizes vary by referenced experiments and are not specified in this survey.",
            "model_size": null,
            "reflection_method_name": "Self-Refine (iterative self-feedback)",
            "reflection_method_description": "Generate an initial response, prompt the same LLM to produce feedback (critique/identify errors) about that response, then prompt the LLM again to produce a refined response conditioned on the feedback; the process can be iterated.",
            "iteration_type": "generate-then-reflect (iterative refinement)",
            "num_iterations": null,
            "task_name": "Math reasoning, code generation, dialogue, constrained generation (as reported by Madaan et al., 2023)",
            "task_description": "Tasks where the model must produce solutions or text (grade-school math problems, code, conversational responses, constrained generation tasks such as including specified words).",
            "evaluation_metric": "Varies by task (accuracy/EM for reasoning, pass@k or execution-based metrics for code, task-specific metrics for dialogue); the survey notes these are task dependent and often not consistently reported.",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Survey calls out Self-Refine for often being evaluated in unfair settings: initial-response prompts in some experiments are purposely weak or even incorrect while stronger prompts are used for feedback, which overestimates self-correction gains; also feedback generation quality is a bottleneck and many positive claims do not hold under fair (best-possible initial response) evaluations.",
            "uuid": "e7166.0",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "RCI Prompting",
            "name_full": "RCI Prompting (Recognition–Correction–Iteration prompting)",
            "brief_description": "An iterative prompting method where the LLM recognizes and corrects errors in its outputs, sometimes using ground-truth‑based stop conditions in the referenced work.",
            "citation_title": "Language models can solve computer tasks",
            "mention_or_use": "mention",
            "model_name": "Large language models (unspecified in survey; referenced studies use LLMs)",
            "model_description": "Pretrained transformer LLMs used with in‑context prompts; specific model variants/sizes not specified in the survey summary.",
            "model_size": null,
            "reflection_method_name": "RCI Prompting",
            "reflection_method_description": "Iteratively prompt an LLM to (1) recognize mistakes in its generated solution, (2) optionally use a stop/update condition, and (3) correct or refine the solution; may include checks against ground-truth to determine whether to continue updating.",
            "iteration_type": "generate-then-reflect (iterative detection + correction)",
            "num_iterations": null,
            "task_name": "Computer tasks / arithmetic & planning tasks cited in the RCI paper",
            "task_description": "Algorithmic/computational tasks and reasoning tasks where generated solutions can be evaluated for correctness.",
            "evaluation_metric": "Task-dependent correctness/accuracy or environment success; not uniformly reported by the survey.",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "The survey highlights that RCI Prompting (as reported in the cited work) can use oracle/ground-truth information as a stop condition (i.e., uses knowledge not available in realistic settings), which unfairly removes cases where the method would incorrectly update already-correct answers; thus evaluation may overstate the method's practical self-correction ability.",
            "uuid": "e7166.1",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Reflexion",
            "name_full": "Reflexion: Language agents with verbal reinforcement learning",
            "brief_description": "A framework for LLM agents that uses verbalized feedback and environment/tool interaction (e.g., game environments, code execution) to iteratively improve behavior via reinforcement-like loops.",
            "citation_title": "Reflexion: Language agents with verbal reinforcement learning",
            "mention_or_use": "mention",
            "model_name": "LLM agents (unspecified in the survey summary)",
            "model_description": "LLM-based agents interacting with external environments/tools (game simulators, code interpreters) and generating self-reflective feedback; specific backbone models vary across referenced experiments.",
            "model_size": null,
            "reflection_method_name": "Reflexion (verbal RL / tool-interactive self-reflection)",
            "reflection_method_description": "Run the agent in an environment, collect failures/successes, generate textual reflections/feedback about failures, and use those reflections (and possibly tool results) to update future behavior or generate refined outputs.",
            "iteration_type": "environment-interactive iterative reflection (generate-run-reflect-update)",
            "num_iterations": null,
            "task_name": "Games and coding (as reported in the referenced Reflexion experiments)",
            "task_description": "Interactive tasks where agent actions can be executed and scored (game play, code execution leading to pass/fail signal).",
            "evaluation_metric": "Environment success measures, task-specific pass/fail; survey does not list numeric metrics",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Survey notes Reflexion uses feedback mechanisms that in some evaluations rely on exact matches to ground-truth or external signals that are unrealistic for pure intrinsic self-correction; such oracle-style feedback prevents using Reflexion results to answer whether LLMs can self-correct based purely on their inherent capabilities.",
            "uuid": "e7166.2",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "CRITIC",
            "name_full": "CRITIC: Tool-interactive critiquing for self-correction",
            "brief_description": "A self-correction approach that augments LLM self-feedback with external tools (e.g., Python/code interpreter, web search) to produce higher-quality feedback and corrections for reasoning and QA tasks.",
            "citation_title": "CRITIC: Large language models can self-correct with tool-interactive critiquing",
            "mention_or_use": "mention",
            "model_name": "Large language models (unspecified in survey; applied to problems like GSM8k, SVAMP, HotpotQA in the referenced paper)",
            "model_description": "Pretrained LLMs prompted to generate and use tool-augmented feedback (code execution, web retrieval) to critique and refine answers; exact model/backbone varies by referenced experiments.",
            "model_size": null,
            "reflection_method_name": "Tool-interactive critiquing (CRITIC)",
            "reflection_method_description": "Generate an initial solution, execute or call external tools (e.g., Python interpreter, web search) to check or validate parts of the solution, synthesize tool results into feedback, and refine the solution accordingly.",
            "iteration_type": "generate + external-tool-augmented reflection (possibly iterative)",
            "num_iterations": null,
            "task_name": "GSM8k, SVAMP, HotpotQA (as cited in survey's Table 5 for CRITIC)",
            "task_description": "Arithmetic reasoning benchmarks (GSM8k, SVAMP) and multi-hop QA (HotpotQA).",
            "evaluation_metric": "Accuracy (for math reasoning) and QA metrics (e.g., exact match/accuracy for HotpotQA); the survey does not report numeric values.",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Survey emphasizes that CRITIC illustrates the general point that self-correction succeeds when reliable external tools are available; however, such tool‑augmented methods do not answer whether LLMs can self-correct using only intrinsic capabilities. Also, the paper warns about unfair evaluations that use external info for feedback but not for initial response generation.",
            "uuid": "e7166.3",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "RARR",
            "name_full": "RARR (Researching and Revising what language models say, using language models)",
            "brief_description": "A framework that uses retrieval (web search) to detect mistakes in LLM outputs and then revises outputs using retrieved external information.",
            "citation_title": "RARR: Researching and revising what language models say, using language models",
            "mention_or_use": "mention",
            "model_name": "LLMs with retrieval augmentation (unspecified in survey)",
            "model_description": "LLMs that produce initial answers, use retrieval to gather evidence for verification, and then apply retrieved evidence to produce corrected/refined answers.",
            "model_size": null,
            "reflection_method_name": "Retrieval‑augmented reflection (RARR)",
            "reflection_method_description": "Generate initial response, form queries from the response, retrieve external documents via web search, use retrieved evidence to detect and correct mistakes in the initial response.",
            "iteration_type": "generate → retrieve → reflect/ refine (usually post-hoc correction; may be iterative)",
            "num_iterations": null,
            "task_name": "Open‑domain QA benchmarks (e.g., Natural Questions, SQuAD variants) as cited in the survey",
            "task_description": "Knowledge/fact‑based question answering where external evidence can validate correctness.",
            "evaluation_metric": "QA accuracy/EM or dataset-specific metrics; not enumerated in the survey summary.",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Survey warns that many works (including RARR) use retrieval only during self-correction and do not allow retrieval during initial generation, creating an 'unfair' setting for evaluating whether self-correction improves the best-possible initial responses; such setups are appropriate for comparing final-system performance [RQ3] but not for answering whether self-correction can improve best-possible initial outputs [RQ2].",
            "uuid": "e7166.4",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Self-RAG",
            "name_full": "Self-RAG: Learning to retrieve, generate, and critique through self-reflection",
            "brief_description": "A retrieval-augmented self-reflection framework (as cited) that integrates retrieval, generation, and critique cycles so the model can retrieve supporting evidence and critique its own outputs.",
            "citation_title": "Self-RAG: Learning to retrieve, generate, and critique through self-reflection",
            "mention_or_use": "mention",
            "model_name": "Retrieval‑augmented LLMs (unspecified by survey)",
            "model_description": "Models that combine retrieval modules with generation and self-evaluation/critique steps; specifics depend on the referenced ICLR 2024 work.",
            "model_size": null,
            "reflection_method_name": "Self-RAG (retrieve + critique + refine)",
            "reflection_method_description": "Use retrieved documents to inform generation, produce critiques of the generated output, and then refine the output conditioned on critiques and retrieval results.",
            "iteration_type": "retrieve-then-reflect (feedback uses retrieved evidence) possibly iterative",
            "num_iterations": null,
            "task_name": "Not specified in survey summary (general retrieval-augmented generation / QA tasks implied)",
            "task_description": "Tasks benefiting from external knowledge retrieval to verify or improve generated content (e.g., open-domain QA, long-form generation).",
            "evaluation_metric": "Task-dependent (QA accuracy, factuality metrics); survey does not report numbers for Self-RAG.",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Survey groups Self-RAG with methods that use external information to improve feedback quality; such methods can be effective but must be evaluated fairly depending on whether retrieval is available for initial-response generation as well as for feedback — otherwise conclusions about improving best-possible initial responses are not supported.",
            "uuid": "e7166.5",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Fine-tuned self-correction",
            "name_full": "Fine-tuning for self-correction (supervised SFT / RL fine-tuning)",
            "brief_description": "Approaches that train models (same or smaller auxiliary models) specifically to generate feedback or refine outputs, using supervised data or reinforcement learning to improve self-correction capabilities.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "model_name": "Fine-tuned LLMs (same-model or smaller fine-tuned verifiers/feedback models)",
            "model_description": "Pretrained transformer LLMs further fine-tuned on supervised feedback datasets (human annotations or model-generated feedback) or trained with RL to produce feedback/refinements; often requires large datasets.",
            "model_size": null,
            "reflection_method_name": "Fine-tuned feedback/refinement models (SFT / RL)",
            "reflection_method_description": "Train a feedback model to generate reference feedback and/or train a refinement model to produce corrected outputs given initial answers and feedback (can be same model fine-tuned for all stages or smaller models used cross‑model).",
            "iteration_type": "trained correction (single or iterative at inference, depending on design)",
            "num_iterations": null,
            "task_name": "Various (code repair, proof generation, QA, summarization) depending on study",
            "task_description": "Tasks where labeled feedback or execution-based verification is available to create supervised training signals.",
            "evaluation_metric": "Task-dependent (execution/pass@k for code, accuracy/EM for QA); survey highlights many SFT methods rely on large (&gt;100k) training instances.",
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Survey notes SFT methods often require very large feedback datasets (&gt;100k examples), may rely on feedback generated by stronger models (simulated human annotation), and can be unfair when feedback/refinement models are stronger than initial-response models; also unexplored territory for small-data fine-tuning and tasks lacking reliable reward functions for RL.",
            "uuid": "e7166.6",
            "source_info": {
                "paper_title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Self-refine: Iterative refinement with self-feedback",
            "rating": 2
        },
        {
            "paper_title": "RCI Prompting (as in Language models can solve computer tasks / RCI)",
            "rating": 2
        },
        {
            "paper_title": "Reflexion: Language agents with verbal reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "CRITIC: Large language models can self-correct with tool-interactive critiquing",
            "rating": 2
        },
        {
            "paper_title": "RARR: Researching and revising what language models say, using language models",
            "rating": 2
        },
        {
            "paper_title": "Self-RAG: Learning to retrieve, generate, and critique through self-reflection",
            "rating": 2
        },
        {
            "paper_title": "Large language models cannot self-correct reasoning yet",
            "rating": 2
        },
        {
            "paper_title": "Self-critiquing models for assisting human evaluators",
            "rating": 1
        },
        {
            "paper_title": "Teaching large language models to self-debug",
            "rating": 1
        },
        {
            "paper_title": "Check your facts and try again: Improving large language models with external knowledge and automated feedback",
            "rating": 1
        }
    ],
    "cost": 0.051702,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><!DOCTYPE html>

<html lang="en" class="no-js">

<head>
    <!-- charset must appear in the first 1024 bytes of the document -->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <title>When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs | Transactions of the Association for Computational Linguistics | MIT Press</title>




    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js" type="text/javascript"></script>
<script>window.jQuery || document.write('<script src="//mitp.silverchair-cdn.com/Themes/Silver/app/js/jquery.3.4.1.min.js" type="text/javascript">\x3C/script>')</script>
<script src="//mitp.silverchair-cdn.com/Themes/Silver/app/vendor/v-638969378558603438/jquery-migrate-3.1.0.min.js" type="text/javascript"></script>

    <script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=643701de45aa460012e1032e&amp;product=sop' async='async' ></script>


    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=10" />


    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <!-- Turn off telephone number detection. -->
    <meta name="format-detection" content="telephone=no" />

<!-- Bookmark Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377051987773/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377052037765/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377052037765/favicon-16x16.png" sizes="16x16">
  <link rel="mask-icon" href="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377052087788/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="icon" href="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377052087788/favicon.ico">
  <link rel="manifest" href="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377052087788/manifest.json">
  <meta name="msapplication-config" content="//mitp.silverchair-cdn.com/Themes/Client/app/img/favicons/v-638969377051987773/browserconfig.xml">
  <meta name="theme-color" content="#002f65">





  <link rel="stylesheet" type="text/css" href="//mitp.silverchair-cdn.com/Themes/Client/app/css/v-638984277034521966/site.min.css" />
  <link rel="stylesheet" type="text/css" href="//mitp.silverchair-cdn.com/Themes/Client/app/css/icons/v-638969377051937806/style.css" />
  <link rel="stylesheet" type="text/css" href="//mitp.silverchair-cdn.com/Themes/Client/app/css/v-638969377051637796/bg_img.css" />

<link href="/Themes/Client/app/css/SiteFonts/SiteFonts.css" rel="stylesheet" />


            <link href="//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/CSS/tacl/v-638760972547904737/site.css" rel="stylesheet" type="text/css" />

            <script>
                (function (w, d, s, l, i) {
                    w[l] = w[l] || []; w[l].push({
                        'gtm.start':
                            new Date().getTime(), event: 'gtm.js'
                    }); var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : '';
                        j.async = true; j.src =
                        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
                })(window, document, 'script', 'dataLayer', 'GTM-5P3FLZ8');
            </script>



        <script type="text/javascript">
            var App = App || {};
            App.LoginUserInfo = {
                isInstLoggedIn: 0,
                isIndividualLoggedIn: 0
            };

            App.CurrentSubdomain = 'tacl';
            App.SiteURL = 'direct.mit.edu/tacl';
        </script>



    <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/chartist.js/latest/chartist.min.css">

    <meta name="citation_author" content="Kamoi, Ryo" /><meta name="citation_author_email" content="ryokamoi@psu.edu" /><meta name="citation_author_institution" content="Penn State University, USA. " /><meta name="citation_author" content="Zhang, Yusen" /><meta name="citation_author_institution" content="Penn State University, USA" /><meta name="citation_author" content="Zhang, Nan" /><meta name="citation_author_institution" content="Penn State University, USA" /><meta name="citation_author" content="Han, Jiawei" /><meta name="citation_author_institution" content="University of Illinois Urbana-Champaign, USA" /><meta name="citation_author" content="Zhang, Rui" /><meta name="citation_author_email" content="rmz5227@psu.edu" /><meta name="citation_author_institution" content="Penn State University, USA. " /><meta name="citation_title" content="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs" /><meta name="citation_firstpage" content="1417" /><meta name="citation_lastpage" content="1440" /><meta name="citation_doi" content="10.1162/tacl_a_00713" /><meta name="citation_journal_title" content="Transactions of the Association for Computational Linguistics" /><meta name="citation_journal_abbrev" content="Transactions of the Association for Computational Linguistics" /><meta name="citation_volume" content="12" /><meta name="citation_publication_date" content="2024/12/23" /><meta name="citation_publisher" content="MIT Press" /><meta name="citation_reference" content="citation_title=RL4F: Generating natural language feedback with reinforcement learning for repairing model outputs; citation_author=Akyurek  Afra Feyza; citation_author=Akyurek  Ekin; citation_author=Kalyan  Ashwin; citation_author=Clark  Peter; citation_author=Wijaya  Derry Tanti; citation_author=Tandon  Niket; citation_publisher=Association for Computational Linguistics, Toronto, Canada;  citation_title=Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2023;  citation_pages=7716-7733; " /><meta name="citation_reference" content="citation_title=Self-RAG: Learning to retrieve, generate, and critique through self-reflection; citation_author=Asai  Akari; citation_author=Zeqiu  Wu; citation_author=Wang  Yizhong; citation_author=Sil  Avirup; citation_author=Hajishirzi  Hannaneh;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Getafix: Learning to fix bugs automatically; citation_author=Bader  Johannes; citation_author=Scott  Andrew; citation_author=Pradel  Michael; citation_author=Chandra  Satish;  citation_journal_title=Proceedings of the ACM on Programming Languages;  citation_year=2019;  citation_volume=3;  citation_issue=OOPSLA; " /><meta name="citation_reference" content="citation_title=Constitutional AI: Harmlessness from AI feedback; citation_author=Bai  Yuntao; citation_author=Kadavath  Saurav; citation_author=Kundu  Sandipan; citation_author=Askell  Amanda; citation_author=Kernion  Jackson; citation_author=Jones  Andy; citation_author=Chen  Anna; citation_author=Goldie  Anna; citation_author=Mirhoseini  Azalia; citation_author=McKinnon  Cameron; citation_author=Chen  Carol; citation_author=Olsson  Catherine; citation_author=Olah  Christopher; citation_author=Hernandez  Danny; citation_author=Drain  Dawn; citation_author=Ganguli  Deep; citation_author=Li  Dustin; citation_author=Tran-Johnson  Eli; citation_author=Perez  Ethan; citation_author=Kerr  Jamie; citation_author=Mueller  Jared; citation_author=Ladish  Jeffrey; citation_author=Landau  Joshua; citation_author=Ndousse  Kamal; citation_author=Lukosuite  Kamile; citation_author=Lovitt  Liane; citation_author=Sellitto  Michael; citation_author=Elhage  Nelson; citation_author=Schiefer  Nicholas; citation_author=Mercado  Noemi; citation_author=DasSarma  Nova; citation_author=Lasenby  Robert; citation_author=Larson  Robin; citation_author=Ringer  Sam; citation_author=Johnston  Scott; citation_author=Kravec  Shauna; citation_author=Showk  Sheer El; citation_author=Fort  Stanislav; citation_author=Lanham  Tamera; citation_author=Telleen-Lawton  Timothy; citation_author=Conerly  Tom; citation_author=Henighan  Tom; citation_author=Hume  Tristan; citation_author=Bowman  Samuel R.; citation_author=Hatfield-Dodds  Zac; citation_author=Mann  Ben; citation_author=Amodei  Dario; citation_author=Joseph  Nicholas; citation_author=McCandlish  Sam; citation_author=Brown  Tom; citation_author=Kaplan  Jared;  citation_journal_title=arXiv preprint arXiv:2212.08073;  citation_year=2022; " /><meta name="citation_reference" content="citation_title=Language (technology) is power: A critical survey of “bias” in NLP; citation_author=Lin Blodgett  Su; citation_author=Barocas  Solon; citation_author=Daumé  Hal; citation_author=Wallach  Hanna; citation_publisher=Association for Computational Linguistics, ;  citation_title=Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics;  citation_year=2020;  citation_pages=5454-5476; " /><meta name="citation_reference" content="citation_title=Factual error correction for abstractive summarization models; citation_author=Cao  Meng; citation_author=Dong  Yue; citation_author=Jiapeng  Wu; citation_author=Cheung  Jackie Chi Kit; citation_publisher=Association for Computational Linguistics, ;  citation_title=Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP);  citation_year=2020;  citation_pages=6251-6258; " /><meta name="citation_reference" content="citation_title=Chateval: Towards better LLM-based evaluators through multi-agent debate; citation_author=Chan  Chi-Min; citation_author=Chen  Weize; citation_author=Yusheng  Su; citation_author=Jianxuan  Yu; citation_author=Xue  Wei; citation_author=Zhang  Shanghang; citation_author=Jie  Fu; citation_author=Liu  Zhiyuan;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=A new era in software security: Towards self-healing software via large language models and formal verification; citation_author=Charalambous  Yiannis; citation_author=Tihanyi  Norbert; citation_author=Jain  Ridhi; citation_author=Sun  Youcheng; citation_author=Ferrag  Mohamed Amine; citation_author=Cordeiro  Lucas C.;  citation_journal_title=arXiv preprint arXiv:2305.14752;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Learning from natural language feedback; citation_author=Chen  Angelica; citation_author=Scheurer  Jérémy; citation_author=Campos  Jon Ander; citation_author=Korbak  Tomasz; citation_author=Chan  Jun Shern; citation_author=Bowman  Samuel R.; citation_author=Cho  Kyunghyun; citation_author=Perez  Ethan;  citation_journal_title=Transactions on Machine Learning Research;  citation_year=2024a; " /><meta name="citation_reference" content="citation_title=Codet: Code generation with generated tests; citation_author=Chen  Bei; citation_author=Zhang  Fengji; citation_author=Nguyen  Anh; citation_author=Zan  Daoguang; citation_author=Lin  Zeqi; citation_author=Lou  Jian-Guang; citation_author=Chen  Weizhu;  citation_journal_title=The Eleventh International Conference on Learning Representations;  citation_year=2023a; " /><meta name="citation_reference" content="citation_title=Can LLM-generated misinformation be detected?; citation_author=Chen  Canyu; citation_author=Shu  Kai;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Reconcile: Round-table conference improves reasoning via consensus among diverse LLMs; citation_author=Chen  Justin Chih-Yao; citation_author=Saha  Swarnadeep; citation_author=Bansal  Mohit;  citation_journal_title=arXiv preprint arXiv: 2309.13007;  citation_year=2024b; " /><meta name="citation_reference" content="citation_title=Iterative translation refinement with large language models; citation_author=Chen  Pinzhen; citation_author=Guo  Zhicheng; citation_author=Haddow  Barry; citation_author=Heafield  Kenneth;  citation_journal_title=arXiv preprint arXiv:2306.03856;  citation_year=2023b; " /><meta name="citation_reference" content="citation_title=Universal self-consistency for large language models; citation_author=Chen  Xinyun; citation_author=Aksitov  Renat; citation_author=Alon  Uri; citation_author=Ren  Jie; citation_author=Xiao  Kefan; citation_author=Yin  Pengcheng; citation_author=Prakash  Sushant; citation_author=Sutton  Charles; citation_author=Wang  Xuezhi; citation_author=Zhou  Denny;  citation_journal_title=ICML 2024 Workshop on In-Context Learning;  citation_year=2024c; " /><meta name="citation_reference" content="citation_title=Teaching large language models to self-debug; citation_author=Chen  Xinyun; citation_author=Lin  Maxwell; citation_author=Schärli  Nathanael; citation_author=Zhou  Denny;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024d; " /><meta name="citation_reference" content="citation_title=Sequencer: Sequence-to-sequence learning for end-to-end program repair; citation_author=Chen  Zimin; citation_author=Kommrusch  Steve; citation_author=Tufano  Michele; citation_author=Pouchet  Louis-Noël; citation_author=Poshyvanyk  Denys; citation_author=Monperrus  Martin;  citation_journal_title=IEEE Transactions on Software Engineering;  citation_year=2021;  citation_volume=47;  citation_issue=9;  citation_pages=1943-1959; " /><meta name="citation_reference" content="citation_title=Factool: Factuality detection in generative AI – a tool augmented framework for multi-task and multi-domain scenarios; citation_author=Chern  I-Chun; citation_author=Chern  Steffi; citation_author=Chen  Shiqi; citation_author=Yuan  Weizhe; citation_author=Feng  Kehua; citation_author=Zhou  Chunting; citation_author=He  Junxian; citation_author=Neubig  Graham; citation_author=Liu  Pengfei;  citation_journal_title=arXiv preprint arXiv:2307.13528;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Can large language models be an alternative to human evaluations?; citation_author=Chiang  Cheng-Han; citation_author=Lee  Hung-yi; citation_publisher=Association for Computational Linguistics, Toronto, Canada;  citation_title=Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2023;  citation_pages=15607-15631; " /><meta name="citation_reference" content="citation_title=Training verifiers to solve math word problems; citation_author=Cobbe  Karl; citation_author=Kosaraju  Vineet; citation_author=Bavarian  Mohammad; citation_author=Chen  Mark; citation_author=Jun  Heewoo; citation_author=Kaiser  Lukasz; citation_author=Plappert  Matthias; citation_author=Tworek  Jerry; citation_author=Hilton  Jacob; citation_author=Nakano  Reiichiro; citation_author=Hesse  Christopher; citation_author=Schulman  John;  citation_journal_title=arXiv preprint arXiv:2110.14168;  citation_year=2021; " /><meta name="citation_reference" content="citation_title=LM vs LM: Detecting factual errors via cross examination; citation_author=Cohen  Roi; citation_author=Hamri  May; citation_author=Geva  Mor; citation_author=Globerson  Amir; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=12621-12640; " /><meta name="citation_reference" content="citation_title=Faithful reasoning using large language models; citation_author=Creswell  Antonia; citation_author=Shanahan  Murray;  citation_journal_title=arXiv preprint arXiv:2208.14271;  citation_year=2022; " /><meta name="citation_reference" content="citation_title=Chain-of-verification reduces hallucination in large language models; citation_author=Dhuliawala  Shehzaad; citation_author=Komeili  Mojtaba; citation_author=Jing  Xu; citation_author=Raileanu  Roberta; citation_author=Li  Xian; citation_author=Celikyilmaz  Asli; citation_author=Weston  Jason;  citation_journal_title=arXiv preprint arXiv:2309.11495;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Improving factuality and reasoning in language models through multiagent debate; citation_author=Yilun  Du; citation_author=Li  Shuang; citation_author=Torralba  Antonio; citation_author=Tenenbaum  Joshua B.; citation_author=Mordatch  Igor;  citation_journal_title=arXiv preprint arXiv:2305.14325;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=FEQA: A question answering evaluation framework for faithfulness assessment in abstractive summarization; citation_author=Durmus  Esin; citation_author=He  He; citation_author=Diab  Mona; citation_publisher=Association for Computational Linguistics, ;  citation_title=Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics;  citation_year=2020;  citation_pages=5055-5070; " /><meta name="citation_reference" content="citation_title=Halo: Estimation and reduction of hallucinations in open-source weak large language models; citation_author=Elaraby  Mohamed; citation_author=Mengyin  Lu; citation_author=Dunn  Jacob; citation_author=Zhang  Xueying; citation_author=Wang  Yu; citation_author=Liu  Shizhu; citation_author=Tian  Pingchuan; citation_author=Wang  Yuping; citation_author=Wang  Yuxuan;  citation_journal_title=arXiv preprint arXiv:2308 .11764;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair NLP models; citation_author=Feng  Shangbin; citation_author=Park  Chan Young; citation_author=Liu  Yuhan; citation_author=Tsvetkov  Yulia; citation_publisher=Association for Computational Linguistics, Toronto, Canada;  citation_title=Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2023;  citation_pages=11737-11762; " /><meta name="citation_reference" content="citation_title=Baldur: Whole-proof generation and repair with large language models; citation_author=First  Emily; citation_author=Rabe  Markus; citation_author=Ringer  Talia; citation_author=Brun  Yuriy; citation_publisher=Association for Computing Machinery, New York, NY, USA;  citation_title=Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering;  citation_year=2023;  citation_pages=1229-1241; " /><meta name="citation_reference" content="citation_title=GPTScore: Evaluate as you desire; citation_author=Jinlan  Fu; citation_author=Ng  See-Kiong; citation_author=Jiang  Zhengbao; citation_author=Liu  Pengfei; citation_publisher=Association for Computational Linguistics, Mexico City, Mexico;  citation_title=Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers);  citation_year=2024;  citation_pages=6556-6576; " /><meta name="citation_reference" content="citation_title=RARR: Researching and revising what language models say, using language models; citation_author=Gao  Luyu; citation_author=Dai  Zhuyun; citation_author=Pasupat  Panupong; citation_author=Chen  Anthony; citation_author=Chaganty  Arun Tejasvi; citation_author=Fan  Yicheng; citation_author=Zhao  Vincent; citation_author=Ni  Lao; citation_author=Lee  Hongrae; citation_author=Juan  Da-Cheng; citation_author=Guu  Kelvin; citation_publisher=Association for Computational Linguistics, Toronto, Canada;  citation_title=Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2023;  citation_pages=16477-16508; " /><meta name="citation_reference" content="citation_title=From wrong to right: A recursive approach towards vision-language explanation; citation_author=Ge  Jiaxin; citation_author=Subramanian  Sanjay; citation_author=Darrell  Trevor; citation_author=Li  Boyi; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=1173-1185; " /><meta name="citation_reference" content="citation_title=Self-verification improves few-shot clinical information extraction; citation_author=Gero  Zelalem; citation_author=Singh  Chandan; citation_author=Cheng  Hao; citation_author=Naumann  Tristan; citation_author=Galley  Michel; citation_author=Gao  Jianfeng; citation_author=Poon  Hoifung;  citation_journal_title=ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH);  citation_year=2023; " /><meta name="citation_reference" content="citation_title=CRITIC: Large language models can self-correct with tool-interactive critiquing; citation_author=Gou  Zhibin; citation_author=Shao  Zhihong; citation_author=Gong  Yeyun; citation_author=shen  yelong; citation_author=Yang  Yujiu; citation_author=Duan  Nan; citation_author=Chen  Weizhu;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Reinforced self-training (rest) for language modeling; citation_author=Gulcehre  Caglar; citation_author=Paine  Tom Le; citation_author=Srinivasan  Srivatsan; citation_author=Konyushkova  Ksenia; citation_author=Weerts  Lotte; citation_author=Sharma  Abhishek; citation_author=Siddhant  Aditya; citation_author=Ahern  Alex; citation_author=Wang  Miaosen; citation_author=Chenjie  Gu; citation_author=Macherey  Wolfgang; citation_author=Doucet  Arnaud; citation_author=Firat  Orhan; citation_author=de Freitas  Nando;  citation_journal_title=arXiv preprint arXiv:2308.08998;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Deepfix: Fixing common c language errors by deep learning; citation_author=Gupta  Rahul; citation_author=Pal  Soham; citation_author=Kanade  Aditya; citation_author=Shevade  Shirish;  citation_journal_title=Proceedings of the AAAI Conference on Artificial Intelligence;  citation_year=2017;  citation_volume=31;  citation_issue=1; " /><meta name="citation_reference" content="citation_title=Small language model can self-correct; citation_author=Han  Haixia; citation_author=Liang  Jiaqing; citation_author=Shi  Jie; citation_author=He  Qianyu; citation_author=Xiao  Yanghua;  citation_journal_title=Proceedings of the AAAI Conference on Artificial Intelligence;  citation_year=2024;  citation_volume=38;  citation_issue=16;  citation_pages=18162-18170; " /><meta name="citation_reference" content="citation_title=Reasoning with language model is planning with world model; citation_author=Hao  Shibo; citation_author=Yi  Gu; citation_author=Ma  Haodi; citation_author=Hong  Joshua; citation_author=Wang  Zhen; citation_author=Wang  Daisy; citation_author=Zhiting  Hu; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=8154-8173; " /><meta name="citation_reference" content="citation_title=A closer look at the self-verification abilities of large language models in logical reasoning; citation_author=Hong  Ruixin; citation_author=Zhang  Hongming; citation_author=Pang  Xinyu; citation_author=Dong  Yu; citation_author=Zhang  Changshui; citation_publisher=Association for Computational Linguistics, Mexico City, Mexico;  citation_title=Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers);  citation_year=2024;  citation_pages=900-925; " /><meta name="citation_reference" content="citation_title=Large language models can self-improve; citation_author=Huang  Jiaxin; citation_author=Shixiang  Gu; citation_author=Le  Hou; citation_author=Yuexin  Wu; citation_author=Wang  Xuezhi; citation_author=Hongkun  Yu; citation_author=Han  Jiawei; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=1051-1068; " /><meta name="citation_reference" content="citation_title=Large language models cannot self-correct reasoning yet; citation_author=Huang  Jie; citation_author=Chen  Xinyun; citation_author=Mishra  Swaroop; citation_author=Zheng  Huaixiu Steven; citation_author=Adams Wei  Yu; citation_author=Song  Xinying; citation_author=Zhou  Denny;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024a; " /><meta name="citation_reference" content="citation_title=Do LVLMs understand charts? Analyzing and correcting factual errors in chart captioning; citation_author=Huang  Kung-Hsiang; citation_author=Zhou  Mingyang; citation_author=Chan  Hou Pong; citation_author=Yi  Fung; citation_author=Wang  Zhenhailong; citation_author=Zhang  Lingyu; citation_author=Chang  Shih-Fu; citation_author=Ji  Heng; citation_publisher=Association for Computational Linguistics, Bangkok, Thailand and virtual meeting;  citation_title=Findings of the Association for Computational Linguistics ACL 2024;  citation_year=2024b;  citation_pages=730-749; " /><meta name="citation_reference" content="citation_title=FRUIT: Faithfully reflecting updated information in text; citation_author=Iv  Robert; citation_author=Passos  Alexandre; citation_author=Singh  Sameer; citation_author=Chang  Ming-Wei; citation_publisher=Association for Computational Linguistics, Seattle, United States;  citation_title=Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies;  citation_year=2022;  citation_pages=3670-3686; " /><meta name="citation_reference" content="citation_title=Self-[in]correct: Llms struggle with refining self-generated responses; citation_author=Jiang  Dongwei; citation_author=Zhang  Jingyu; citation_author=Weller  Orion; citation_author=Weir  Nathaniel; citation_author=Van Durme  Benjamin; citation_author=Khashabi  Daniel;  citation_journal_title=arXiv preprint arXiv:2404.04298;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Selfevolve: A code evolution framework via large language models; citation_author=Jiang  Shuyang; citation_author=Wang  Yuhao; citation_author=Wang  Yu;  citation_journal_title=arXiv preprint arXiv:2306.02907;  citation_year=2023a; " /><meta name="citation_reference" content="citation_title=Active retrieval augmented generation; citation_author=Jiang  Zhengbao; citation_author=Frank  Xu; citation_author=Gao  Luyu; citation_author=Sun  Zhiqing; citation_author=Liu  Qian; citation_author=Dwivedi-Yu  Jane; citation_author=Yang  Yiming; citation_author=Callan  Jamie; citation_author=Neubig  Graham; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023b;  citation_pages=7969-7992; " /><meta name="citation_reference" content="citation_title=Maieutic prompting: Logically consistent reasoning with recursive explanations; citation_author=Jung  Jaehun; citation_author=Qin  Lianhui; citation_author=Welleck  Sean; citation_author=Brahman  Faeze; citation_author=Bhagavatula  Chandra; citation_author=Bras  Ronan Le; citation_author=Choi  Yejin; citation_publisher=Association for Computational Linguistics, Abu Dhabi, United Arab Emirates;  citation_title=Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing;  citation_year=2022;  citation_pages=1266-1279; " /><meta name="citation_reference" content="citation_title=Evaluating LLMs at detecting errors in LLM responses; citation_author=Kamoi  Ryo; citation_author=Das  Sarkar Snigdha Sarathi; citation_author=Lou  Renze; citation_author=Ahn  Jihyun Janice; citation_author=Zhao  Yilun; citation_author=Xiaoxin  Lu; citation_author=Zhang  Nan; citation_author=Zhang  Yusen; citation_author=Zhang  Ranran Haoran; citation_author=Vummanthala  Sujeeth Reddy; citation_author=Dave  Salika; citation_author=Qin  Shaobo; citation_author=Cohan  Arman; citation_author=Yin  Wenpeng; citation_author=Zhang  Rui;  citation_journal_title=arXiv preprint arXiv:2404.03602;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Guiding large language models to post-edit machine translation with error annotations; citation_author=Ki  Dayeon; citation_author=Carpuat  Marine; citation_publisher=Association for Computational Linguistics, Mexico City, Mexico;  citation_title=Findings of the Association for Computational Linguistics: NAACL 2024;  citation_year=2024;  citation_pages=4253-4273; " /><meta name="citation_reference" content="citation_title=Language models can solve computer tasks; citation_author=Kim  Geunwoo; citation_author=Baldi  Pierre; citation_author=McAleer  Stephen; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2023;  citation_volume=36;  citation_pages=39648-39677; " /><meta name="citation_reference" content="citation_title=Coderl: Mastering code generation through pretrained models and deep reinforcement learning; citation_author=Le  Hung; citation_author=Wang  Yue; citation_author=Gotmare  Akhilesh Deepak; citation_author=Savarese  Silvio; citation_author=Hoi  Steven Chu Hong; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2022;  citation_volume=35;  citation_pages=21314-21328; " /><meta name="citation_reference" content="citation_title=Volcano: Mitigating multimodal hallucination through self-feedback guided revision; citation_author=Lee  Seongyun; citation_author=Park  Sue; citation_author=Jo  Yongrae; citation_author=Seo  Minjoon; citation_publisher=Association for Computational Linguistics, Mexico City, Mexico;  citation_title=Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers);  citation_year=2024;  citation_pages=391-404; " /><meta name="citation_reference" content="citation_title=Confidence matters: Revisiting intrinsic self-correction capabilities of large language models; citation_author=Li  Loka; citation_author=Chen  Zhenhao; citation_author=Chen  Guangyi; citation_author=Zhang  Yixuan; citation_author=Yusheng  Su; citation_author=Xing  Eric; citation_author=Zhang  Kun;  citation_journal_title=arXiv preprint arXiv:2402 .12563;  citation_year=2024a; " /><meta name="citation_reference" content="citation_title=Prd: Peer rank and discussion improve large language model based evaluations; citation_author=Li  Ruosen; citation_author=Patel  Teerth; citation_author=Xinya  Du;  citation_journal_title=arXiv preprint arXiv:2307.02762;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=When hindsight is not 20/20: Testing limits on reflective thinking in large language models; citation_author=Li  Yanhong; citation_author=Yang  Chenghao; citation_author=Ettinger  Allyson; citation_publisher=Association for Computational Linguistics, Mexico City, Mexico;  citation_title=Findings of the Association for Computational Linguistics: NAACL 2024;  citation_year=2024b;  citation_pages=3741-3753; " /><meta name="citation_reference" content="citation_title=Encouraging divergent thinking in large language models through multi-agent debate; citation_author=Liang  Tian; citation_author=He  Zhiwei; citation_author=Jiao  Wenxiang; citation_author=Wang  Xing; citation_author=Wang  Yan; citation_author=Wang  Rui; citation_author=Yang  Yujiu; citation_author=Zhaopeng  Tu; citation_author=Shi  Shuming;  citation_journal_title=arXiv preprint arXiv:2305.19118;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Corpora generation for grammatical error correction; citation_author=Lichtarge  Jared; citation_author=Alberti  Chris; citation_author=Kumar  Shankar; citation_author=Shazeer  Noam; citation_author=Parmar  Niki; citation_author=Tong  Simon; citation_publisher=Association for Computational Linguistics, Minneapolis, Minnesota;  citation_title=Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers);  citation_year=2019;  citation_pages=3291-3301; " /><meta name="citation_reference" content="citation_title=Let’s verify step by step; citation_author=Lightman  Hunter; citation_author=Kosaraju  Vineet; citation_author=Burda  Yuri; citation_author=Edwards  Harrison; citation_author=Baker  Bowen; citation_author=Lee  Teddy; citation_author=Leike  Jan; citation_author=Schulman  John; citation_author=Sutskever  Ilya; citation_author=Cobbe  Karl;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=On the intrinsic self-correction capability of LLMs: Uncertainty and latent concept; citation_author=Liu  Guangliang; citation_author=Mao  Haitao; citation_author=Cao  Bochuan; citation_author=Xue  Zhiyu; citation_author=Johnson  Kristen; citation_author=Tang  Jiliang; citation_author=Wang  Rongrong;  citation_journal_title=arXiv preprint arXiv:2406.02378;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=G-eval: NLG evaluation using gpt-4 with better human alignment; citation_author=Liu  Yang; citation_author=Iter  Dan; citation_author=Yichong  Xu; citation_author=Wang  Shuohang; citation_author=Ruochen  Xu; citation_author=Zhu  Chenguang; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=2511-2522; " /><meta name="citation_reference" content="citation_title=Self-refine: Iterative refinement with self-feedback; citation_author=Madaan  Aman; citation_author=Tandon  Niket; citation_author=Gupta  Prakhar; citation_author=Hallinan  Skyler; citation_author=Gao  Luyu; citation_author=Wiegreffe  Sarah; citation_author=Alon  Uri; citation_author=Dziri  Nouha; citation_author=Prabhumoye  Shrimai; citation_author=Yang  Yiming; citation_author=Gupta  Shashank; citation_author=Majumder  Bodhisattwa Prasad; citation_author=Hermann  Katherine; citation_author=Welleck  Sean; citation_author=Yazdanbakhsh  Amir; citation_author=Clark  Peter; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2023;  citation_volume=36;  citation_pages=46534-46594; " /><meta name="citation_reference" content="citation_title=SelfCheckGPT: Zero-resource black-box hallucination detection for generative large language models; citation_author=Manakul  Potsawee; citation_author=Liusie  Adian; citation_author=Gales  Mark; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=9004-9017; " /><meta name="citation_reference" content="citation_title=Flirt: Feedback loop in-context red teaming; citation_author=Mehrabi  Ninareh; citation_author=Goyal  Palash; citation_author=Dupuy  Christophe; citation_author=Qian  Hu; citation_author=Ghosh  Shalini; citation_author=Zemel  Richard; citation_author=Chang  Kai-Wei; citation_author=Galstyan  Aram; citation_author=Gupta  Rahul;  citation_journal_title=arXiv preprint arXiv: 2308.04265;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Generating training data with language models: Towards zero-shot language understanding; citation_author=Meng  Yu; citation_author=Huang  Jiaxin; citation_author=Zhang  Yu; citation_author=Han  Jiawei; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2022;  citation_volume=35;  citation_pages=462-477; " /><meta name="citation_reference" content="citation_title=Deepdelta: Learning to repair compilation errors; citation_author=Mesbah  Ali; citation_author=Rice  Andrew; citation_author=Johnston  Emily; citation_author=Glorioso  Nick; citation_author=Aftandilian  Edward; citation_publisher=Association for Computing Machinery, New York, NY, USA;  citation_title=Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;  citation_year=2019;  citation_issue=ESEC/ FSE 2019;  citation_pages=925-936; " /><meta name="citation_reference" content="citation_title=Selfcheck: Using LLMs to zero-shot check their own step-by-step reasoning; citation_author=Miao  Ning; citation_author=Teh  Yee Whye; citation_author=Rainforth  Tom;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=FActScore: Fine-grained atomic evaluation of factual precision in long form text generation; citation_author=Min  Sewon; citation_author=Krishna  Kalpesh; citation_author=Lyu  Xinxi; citation_author=Lewis  Mike; citation_author=Yih  Wen-tau; citation_author=Koh  Pang; citation_author=Iyyer  Mohit; citation_author=Zettlemoyer  Luke; citation_author=Hajishirzi  Hannaneh; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=12076-12100; " /><meta name="citation_reference" content="citation_title=Fine-grained hallucination detection and editing for language models; citation_author=Mishra  Abhika; citation_author=Asai  Akari; citation_author=Balachandran  Vidhisha; citation_author=Wang  Yizhong; citation_author=Neubig  Graham; citation_author=Tsvetkov  Yulia; citation_author=Hajishirzi  Hannaneh;  citation_journal_title=arXiv preprint arXiv:2401.06855;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=MAF: Multi-aspect feedback for improving reasoning in large language models; citation_author=Nathani  Deepak; citation_author=Wang  David; citation_author=Pan  Liangming; citation_author=Wang  William; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=6591-6616; " /><meta name="citation_reference" content="citation_title=The CoNLL-2014 shared task on grammatical error correction; citation_author=Ng  Hwee Tou; citation_author=Siew Mei  Wu; citation_author=Briscoe  Ted; citation_author=Hadiwinoto  Christian; citation_author=Susanto  Raymond Hendy; citation_author=Bryant  Christopher; citation_publisher=Association for Computational Linguistics, Baltimore, Maryland;  citation_title=Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task;  citation_year=2014;  citation_pages=1-14; " /><meta name="citation_reference" content="citation_title=LEVER: Learning to verify language-to-code generation with execution; citation_author=Ni  Ansong; citation_author=Iyer  Srini; citation_author=Radev  Dragomir; citation_author=Stoyanov  Veselin; citation_author=Yih  Wen-Tau; citation_author=Wang  Sida; citation_author=Xi  Victoria Lin; citation_publisher=PMLR, ;  citation_title=Proceedings of the 40th International Conference on Machine Learning;  citation_year=2023;  citation_volume=202 of Proceedings of Machine Learning Research;  citation_pages=26106-26128; " /><meta name="citation_reference" content="citation_title=Is self-repair a silver bullet for code generation?; citation_author=Olausson  Theo X.; citation_author=Inala  Jeevana Priya; citation_author=Wang  Chenglong; citation_author=Gao  Jianfeng; citation_author=Solar-Lezama  Armando;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning; citation_author=Pan  Liangming; citation_author=Albalak  Alon; citation_author=Wang  Xinyi; citation_author=Wang  William; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Findings of the Association for Computational Linguistics: EMNLP 2023;  citation_year=2023;  citation_pages=3806-3824; " /><meta name="citation_reference" content="citation_title=Automatically correcting large language models: Surveying the landscape of diverse automated correction strategies; citation_author=Pan  Liangming; citation_author=Saxon  Michael; citation_author=Wenda  Xu; citation_author=Nathani  Deepak; citation_author=Wang  Xinyi; citation_author=Wang  William Yang;  citation_journal_title=Transactions of the Association for Computational Linguistics;  citation_year=2024;  citation_volume=12;  citation_pages=484-506; " /><meta name="citation_reference" content="citation_title=Language model self-improvement by reinforcement learning contemplation; citation_author=Pang  Jing-Cheng; citation_author=Wang  Pengyuan; citation_author=Li  Kaiyuan; citation_author=Chen  Xiong-Hui; citation_author=Jiacheng  Xu; citation_author=Zhang  Zongzhang; citation_author=Yang  Yu;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=REFINER: Reasoning feedback on intermediate representations; citation_author=Paul  Debjit; citation_author=Ismayilzada  Mete; citation_author=Peyrard  Maxime; citation_author=Borges  Beatriz; citation_author=Bosselut  Antoine; citation_author=West  Robert; citation_author=Faltings  Boi; citation_publisher=Association for Computational Linguistics, St. Julian’s, Malta;  citation_title=Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2024;  citation_pages=1100-1126; " /><meta name="citation_reference" content="citation_title=Check your facts and try again: Improving large language models with external knowledge and automated feedback; citation_author=Peng  Baolin; citation_author=Galley  Michel; citation_author=He  Pengcheng; citation_author=Cheng  Hao; citation_author=Xie  Yujia; citation_author=Yu  Hu; citation_author=Huang  Qiuyuan; citation_author=Liden  Lars; citation_author=Zhou  Yu; citation_author=Chen  Weizhu; citation_author=Gao  Jianfeng;  citation_journal_title=arXiv preprint arXiv:2302.12813;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Llm self defense: By self examination, llms know they are being tricked; citation_author=Phute  Mansi; citation_author=Helbling  Alec; citation_author=Hull  Matthew; citation_author=Peng  ShengYun; citation_author=Szyller  Sebastian; citation_author=Cornelius  Cory; citation_author=Chau  Duen Horng;  citation_journal_title=arXiv preprint arXiv:2308.07308;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Automatic prompt optimization with “gradient descent” and beam search; citation_author=Pryzant  Reid; citation_author=Iter  Dan; citation_author=Li  Jerry; citation_author=Lee  Yin; citation_author=Zhu  Chenguang; citation_author=Zeng  Michael; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023;  citation_pages=7957-7968; " /><meta name="citation_reference" content="citation_title=Characteristics of harmful text: Towards rigorous benchmarking of language models; citation_author=Rauh  Maribeth; citation_author=Mellor  John F. J.; citation_author=Uesato  Jonathan; citation_author=Huang  Po-Sen; citation_author=Welbl  Johannes; citation_author=Weidinger  Laura; citation_author=Dathathri  Sumanth; citation_author=Glaese  Amelia; citation_author=Irving  Geoffrey; citation_author=Gabriel  Iason; citation_author=Isaac  William; citation_author=Hendricks  Lisa Anne;  citation_journal_title=Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track;  citation_year=2022; " /><meta name="citation_reference" content="citation_title=Leveraging GPT-4 for automatic translation post-editing; citation_author=Raunak  Vikas; citation_author=Sharaf  Amr; citation_author=Wang  Yiren; citation_author=Awadalla  Hany; citation_author=Menezes  Arul; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Findings of the Association for Computational Linguistics: EMNLP 2023;  citation_year=2023;  citation_pages=12009-12024; " /><meta name="citation_reference" content="citation_title=Branch-solve-merge improves large language model evaluation and generation; citation_author=Saha  Swarnadeep; citation_author=Levy  Omer; citation_author=Celikyilmaz  Asli; citation_author=Bansal  Mohit; citation_author=Weston  Jason; citation_author=Li  Xian; citation_publisher=Association for Computational Linguistics, Mexico City, Mexico;  citation_title=Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers);  citation_year=2024;  citation_pages=8352-8370; " /><meta name="citation_reference" content="citation_title=Self-critiquing models for assisting human evaluators; citation_author=Saunders  William; citation_author=Yeh  Catherine; citation_author=Jeff  Wu; citation_author=Bills  Steven; citation_author=Ouyang  Long; citation_author=Ward  Jonathan; citation_author=Leike  Jan;  citation_journal_title=arXiv preprint arXiv:2206.05802;  citation_year=2022; " /><meta name="citation_reference" content="citation_title=Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in NLP; citation_author=Schick  Timo; citation_author=Udupa  Sahana; citation_author=Schütze  Hinrich;  citation_journal_title=Transactions of the Association for Computational Linguistics;  citation_year=2021;  citation_volume=9;  citation_pages=1408-1424; " /><meta name="citation_reference" content="citation_title=PEER: A collaborative language model; citation_author=Schick  Timo; citation_author=Jane  A. Yu; citation_author=Jiang  Zhengbao; citation_author=Petroni  Fabio; citation_author=Lewis  Patrick; citation_author=Izacard  Gautier; citation_author=You  Qingfei; citation_author=Nalmpantis  Christoforos; citation_author=Grave  Edouard; citation_author=Riedel  Sebastian;  citation_journal_title=The Eleventh International Conference on Learning Representations;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=QuestEval: Summarization asks for fact-based evaluation; citation_author=Scialom  Thomas; citation_author=Dray  Paul-Alexis; citation_author=Lamprier  Sylvain; citation_author=Piwowarski  Benjamin; citation_author=Staiano  Jacopo; citation_author=Wang  Alex; citation_author=Gallinari  Patrick; citation_publisher=Association for Computational Linguistics, Online and Punta Cana, Dominican Republic;  citation_title=Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing;  citation_year=2021;  citation_pages=6594-6604; " /><meta name="citation_reference" content="citation_title=Automatic fact-guided sentence modification; citation_author=Shah  Darsh; citation_author=Schuster  Tal; citation_author=Barzilay  Regina;  citation_journal_title=Proceedings of the AAAI Conference on Artificial Intelligence;  citation_year=2020;  citation_volume=34;  citation_issue=05;  citation_pages=8791-8798; " /><meta name="citation_reference" content="citation_title=Generate &amp; rank: A multi-task framework for math word problems; citation_author=Shen  Jianhao; citation_author=Yin  Yichun; citation_author=Li  Lin; citation_author=Shang  Lifeng; citation_author=Jiang  Xin; citation_author=Zhang  Ming; citation_author=Liu  Qun; citation_publisher=Association for Computational Linguistics, Punta Cana, Dominican Republic;  citation_title=Findings of the Association for Computational Linguistics: EMNLP 2021;  citation_year=2021;  citation_pages=2269-2279; " /><meta name="citation_reference" content="citation_title=Natural language to code translation with execution; citation_author=Shi  Freda; citation_author=Fried  Daniel; citation_author=Ghazvininejad  Marjan; citation_author=Zettlemoyer  Luke; citation_author=Wang  Sida I.; citation_publisher=Association for Computational Linguistics, Abu Dhabi, United Arab Emirates;  citation_title=Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing;  citation_year=2022;  citation_pages=3533-3546; " /><meta name="citation_reference" content="citation_title=Reflexion: Language agents with verbal reinforcement learning; citation_author=Shinn  Noah; citation_author=Cassano  Federico; citation_author=Gopinath  Ashwin; citation_author=Narasimhan  Karthik; citation_author=Yao  Shunyu; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2023;  citation_volume=36;  citation_pages=8634-8652; " /><meta name="citation_reference" content="citation_title=GPT-4 doesn’t know it’s wrong: An analysis of iterative prompting for reasoning problems; citation_author=Stechly  Kaya; citation_author=Marquez  Matthew; citation_author=Kambhampati  Subbarao;  citation_journal_title=NeurIPS 2023 Foundation Models for Decision Making Workshop;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Regal: Refactoring programs to discover generalizable abstractions; citation_author=Stengel-Eskin  Elias; citation_author=Prasad  Archiki; citation_author=Bansal  Mohit;  citation_journal_title=arXiv preprint arXiv:2401.16467;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Entailer: Answering questions with faithful and truthful chains of reasoning; citation_author=Tafjord  Oyvind; citation_author=Mishra  Bhavana Dalvi; citation_author=Clark  Peter; citation_publisher=Association for Computational Linguistics, Abu Dhabi, United Arab Emirates;  citation_journal_title=Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing;  citation_year=2022;  citation_pages=2078-2093; " /><meta name="citation_reference" content="citation_title=Evidence-based factual error correction; citation_author=Thorne  James; citation_author=Vlachos  Andreas; citation_publisher=Association for Computational Linguistics, ;  citation_title=Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers);  citation_year=2021;  citation_pages=3298-3309; " /><meta name="citation_reference" content="citation_title=LLMs cannot find reasoning errors, but can correct them given the error location; citation_author=Tyen  Gladys; citation_author=Mansoor  Hassan; citation_author=Carbune  Victor; citation_author=Chen  Peter; citation_author=Mak  Tony; citation_publisher=Association for Computational Linguistics, Bangkok, Thailand and virtual meeting;  citation_title=Findings of the Association for Computational Linguistics ACL 2024;  citation_year=2024;  citation_pages=13894-13908; " /><meta name="citation_reference" content="citation_title=Solving math word problems with process- and outcome-based feedback; citation_author=Uesato  Jonathan; citation_author=Kushman  Nate; citation_author=Kumar  Ramana; citation_author=Song  Francis; citation_author=Siegel  Noah; citation_author=Wang  Lisa; citation_author=Creswell  Antonia; citation_author=Irving  Geoffrey; citation_author=Higgins  Irina;  citation_journal_title=arXiv preprint arXiv:2211.14275;  citation_year=2022; " /><meta name="citation_reference" content="citation_title=Investigating the effectiveness of self-critiquing in LLMs solving planning tasks; citation_author=Valmeekam  Karthik; citation_author=Marquez  Matthew; citation_author=Kambhampati  Subbarao;  citation_journal_title=NeurIPS 2023 Foundation Models for Decision Making Workshop;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=A stitch in time saves nine: Detecting and mitigating hallucinations of LLMs by validating low-confidence generation; citation_author=Varshney  Neeraj; citation_author=Yao  Wenlin; citation_author=Zhang  Hongming; citation_author=Chen  Jianshu; citation_author=Dong  Yu;  citation_journal_title=arXiv preprint arXiv: 2307.03987;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Asking and answering questions to evaluate the factual consistency of summaries; citation_author=Wang  Alex; citation_author=Cho  Kyunghyun; citation_author=Lewis  Mike; citation_publisher=Association for Computational Linguistics, ;  citation_title=Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics;  citation_year=2020;  citation_pages=5008-5020; " /><meta name="citation_reference" content="citation_title=Rethinking the bounds of LLM reasoning: Are multi-agent discussions the key?; citation_author=Wang  Qineng; citation_author=Wang  Zihao; citation_author=Ying  Su; citation_author=Tong  Hanghang; citation_author=Song  Yangqiu; citation_publisher=Association for Computational Linguistics, Bangkok, Thailand;  citation_title=Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2024a;  citation_pages=6106-6131; " /><meta name="citation_reference" content="citation_title=Self-consistency improves chain of thought reasoning in language models; citation_author=Wang  Xuezhi; citation_author=Wei  Jason; citation_author=Schuurmans  Dale; citation_author=Le  Quoc V.; citation_author=Ed  H. Chi; citation_author=Narang  Sharan; citation_author=Chowdhery  Aakanksha; citation_author=Zhou  Denny;  citation_journal_title=The Eleventh International Conference on Learning Representations;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=A theoretical understanding of self-correction through in-context alignment; citation_author=Wang  Yifei; citation_author=Yuyang  Wu; citation_author=Wei  Zeming; citation_author=Jegelka  Stefanie; citation_author=Wang  Yisen;  citation_journal_title=ICML 2024 Workshop on In-Context Learning;  citation_year=2024b; " /><meta name="citation_reference" content="citation_title=Generating sequences by learning to self-correct; citation_author=Welleck  Sean; citation_author=Ximing  Lu; citation_author=West  Peter; citation_author=Brahman  Faeze; citation_author=Shen  Tianxiao; citation_author=Khashabi  Daniel; citation_author=Choi  Yejin;  citation_journal_title=The Eleventh International Conference on Learning Representations;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Large language models are better reasoners with self-verification; citation_author=Weng  Yixuan; citation_author=Zhu  Minjun; citation_author=Xia  Fei; citation_author=Li  Bin; citation_author=He  Shizhu; citation_author=Liu  Shengping; citation_author=Sun  Bin; citation_author=Liu  Kang; citation_author=Zhao  Jun; citation_publisher=Association for Computational Linguistics, Singapore;  citation_title=Findings of the Association for Computational Linguistics: EMNLP 2023;  citation_year=2023;  citation_pages=2550-2575; " /><meta name="citation_reference" content="citation_title=Large language models can self-correct with minimal effort; citation_author=Zhenyu  Wu; citation_author=Zeng  Qingkai; citation_author=Zhang  Zhihan; citation_author=Tan  Zhaoxuan; citation_author=Shen  Chao; citation_author=Jiang  Meng;  citation_journal_title=arXiv preprint arXiv: 2405.14092;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Self-evaluation guided beam search for reasoning; citation_author=Xie  Yuxi; citation_author=Kawaguchi  Kenji; citation_author=Zhao  Yiran; citation_author=Zhao  Xu; citation_author=Kan  Min-Yen; citation_author=He  Junxian; citation_author=Xie  Qizhe;  citation_journal_title=Thirty-seventh Conference on Neural Information Processing Systems;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=INSTRUCTSCORE: Towards explainable text generation evaluation with automatic feedback; citation_author=Wenda  Xu; citation_author=Wang  Danqing; citation_author=Pan  Liangming; citation_author=Song  Zhenqiao; citation_author=Freitag  Markus; citation_author=Wang  William Yang; citation_author=Li  Lei;  citation_journal_title=The 2023 Conference on Empirical Methods in Natural Language Processing;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Large language models as optimizers; citation_author=Yang  Chengrun; citation_author=Wang  Xuezhi; citation_author=Yifeng  Lu; citation_author=Liu  Hanxiao; citation_author=Le  Quoc V.; citation_author=Zhou  Denny; citation_author=Chen  Xinyun;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_reference" content="citation_title=Generating natural language proofs with verifier-guided search; citation_author=Yang  Kaiyu; citation_author=Deng  Jia; citation_author=Chen  Danqi; citation_publisher=Association for Computational Linguistics, Abu Dhabi, United Arab Emirates;  citation_title=Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing;  citation_year=2022a;  citation_pages=89-105; " /><meta name="citation_reference" content="citation_title=Re3: Generating longer stories with recursive reprompting and revision; citation_author=Yang  Kevin; citation_author=Tian  Yuandong; citation_author=Peng  Nanyun; citation_author=Klein  Dan; citation_publisher=Association for Computational Linguistics, Abu Dhabi, United Arab Emirates;  citation_title=Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing;  citation_year=2022b;  citation_pages=4393-4479; " /><meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models; citation_author=Yao  Shunyu; citation_author=Dian  Yu; citation_author=Zhao  Jeffrey; citation_author=Shafran  Izhak; citation_author=Griffiths  Tom; citation_author=Cao  Yuan; citation_author=Narasimhan  Karthik; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2023;  citation_volume=36;  citation_pages=11809-11822; " /><meta name="citation_reference" content="citation_title=Graph-based, self-supervised program repair from diagnostic feedback; citation_author=Yasunaga  Michihiro; citation_author=Liang  Percy; citation_publisher=PMLR, ;  citation_title=Proceedings of the 37th International Conference on Machine Learning;  citation_year=2020;  citation_volume=119 of Proceedings of Machine Learning Research;  citation_pages=10799-10808; " /><meta name="citation_reference" content="citation_title=Break-it-fix-it: Unsupervised learning for program repair; citation_author=Yasunaga  Michihiro; citation_author=Liang  Percy; citation_publisher=PMLR, ;  citation_title=Proceedings of the 38th International Conference on Machine Learning;  citation_year=2021;  citation_volume=139;  citation_pages=11941-11952; " /><meta name="citation_reference" content="citation_title=Selfee: Iterative self-revising LLM empowered by self-feedback generation; citation_author=Ye  Seonghyeon; citation_author=Jo  Yongrae; citation_author=Kim  Doyoung; citation_author=Kim  Sungdong; citation_author=Hwang  Hyeonbin; citation_author=Seo  Minjoon;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Woodpecker: Hallucination correction for multimodal large language models; citation_author=Yin  Shukang; citation_author=Chaoyou  Fu; citation_author=Zhao  Sirui; citation_author=Tong  Xu; citation_author=Wang  Hao; citation_author=Sui  Dianbo; citation_author=Shen  Yunhang; citation_author=Ke  Li; citation_author=Sun  Xing; citation_author=Chen  Enhong;  citation_journal_title=arXiv preprint arXiv:2310.16045;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Improving language models via plug-and-play retrieval feedback; citation_author=Wenhao  Yu; citation_author=Zhang  Zhihan; citation_author=Liang  Zhenwen; citation_author=Jiang  Meng; citation_author=Sabharwal  Ashish;  citation_journal_title=arXiv preprint arXiv: 2305.14002;  citation_year=2023; " /><meta name="citation_reference" content="citation_title=Star: Bootstrapping reasoning with reasoning; citation_author=Zelikman  Eric; citation_author=Yuhuai  Wu; citation_author=Jesse  Mu; citation_author=Goodman  Noah; citation_publisher=Curran Associates, Inc., ;  citation_title=Advances in Neural Information Processing Systems;  citation_year=2022;  citation_volume=35;  citation_pages=15476-15488; " /><meta name="citation_reference" content="citation_title=Exploring collaboration mechanisms for llm agents: A social psychology view; citation_author=Zhang  Jintian; citation_author=Xin  Xu; citation_author=Deng  Shumin;  citation_journal_title=arXiv preprint arXiv:2310.02124;  citation_year=2023a; " /><meta name="citation_reference" content="citation_title=Self-edit: Fault-aware code editor for code generation; citation_author=Zhang  Kechi; citation_author=Li  Zhuo; citation_author=Li  Jia; citation_author=Ge  Li; citation_author=Jin  Zhi; citation_publisher=Association for Computational Linguistics, Toronto, Canada;  citation_title=Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2023b;  citation_pages=769-787; " /><meta name="citation_reference" content="citation_title=How language model hallucinations can snowball; citation_author=Zhang  Muru; citation_author=Press  Ofir; citation_author=Merrill  William; citation_author=Liu  Alisa; citation_author=Smith  Noah A.;  citation_journal_title=arXiv preprint arXiv:2305.13534;  citation_year=2023c; " /><meta name="citation_reference" content="citation_title=Coder reviewer reranking for code generation; citation_author=Zhang  Tianyi; citation_author=Tao  Yu; citation_author=Hashimoto  Tatsunori; citation_author=Lewis  Mike; citation_author=Yih  Wen-Tau; citation_author=Fried  Daniel; citation_author=Wang  Sida; citation_publisher=PMLR, ;  citation_title=Proceedings of the 40th International Conference on Machine Learning;  citation_year=2023d;  citation_volume=202 of Proceedings of Machine Learning Research;  citation_pages=41832-41846; " /><meta name="citation_reference" content="citation_title=Small language models need strong verifiers to self-correct reasoning; citation_author=Zhang  Yunxiang; citation_author=Khalifa  Muhammad; citation_author=Logeswaran  Lajanugen; citation_author=Kim  Jaekyeom; citation_author=Lee  Moontae; citation_author=Lee  Honglak; citation_author=Wang  Lu; citation_publisher=Association for Computational Linguistics, Bangkok, Thailand and virtual meeting;  citation_title=Findings of the Association for Computational Linguistics ACL 2024;  citation_year=2024;  citation_pages=15637-15653; " /><meta name="citation_reference" content="citation_title=Verify-and-edit: A knowledge-enhanced chain-of-thought framework; citation_author=Zhao  Ruochen; citation_author=Li  Xingxuan; citation_author=Joty  Shafiq; citation_author=Qin  Chengwei; citation_author=Bing  Lidong; citation_publisher=Association for Computational Linguistics, Toronto, Canada;  citation_title=Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers);  citation_year=2023;  citation_pages=5823-5840; " /><meta name="citation_reference" content="citation_title=Analyzing and mitigating object hallucination in large vision-language models; citation_author=Zhou  Yiyang; citation_author=Cui  Chenhang; citation_author=Yoon  Jaehong; citation_author=Zhang  Linjun; citation_author=Deng  Zhun; citation_author=Finn  Chelsea; citation_author=Bansal  Mohit; citation_author=Yao  Huaxiu;  citation_journal_title=The Twelfth International Conference on Learning Representations;  citation_year=2024; " /><meta name="citation_fulltext_world_readable" content="" /><meta name="citation_pdf_url" content="https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00713/2478635/tacl_a_00713.pdf" /><meta name="dc.identifier" content="10.1162/tacl_a_00713" />

<meta name="citation_xml_url" content="https://direct.mit.edu/tacl/article-xml/doi/10.1162/tacl_a_00713/125177" />
    <meta name="description" content="Abstract. Self-correction is an approach to improving responses from large language models (LLMs) by refining the responses using LLMs during inference.">


    <link rel="canonical" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes" />






    <meta name="publish_date" content="2024-11-04" />

    <meta name="publish_image" content="//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_title-606805150.svg" />



    <meta name="product_code" content="COMPMARC" />
    <meta name="product_code" content="Journals_Complete_Collection_Trial" />
    <meta name="product_code" content="OPEN_ACCESS" />
    <meta name="product_code" content="COMP" />
    <meta name="product_code" content="ALL_CONTENT" />
    <meta name="product_code" content="J_125177" />
    <meta name="product_code" content="I_3495" />

    <script type="application/ld+json">
        {"@context":"https://schema.org","@type":"ScholarlyArticle","@id":"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes","name":"When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs","datePublished":"2024-11-04","isPartOf":{"@id":"https://direct.mit.edu/tacl/issue/volume/12","@type":"PublicationIssue","datePublished":"2024-12-23","isPartOf":{"@id":"https://direct.mit.edu/tacl","@type":"Periodical","name":"Transactions of the Association for Computational Linguistics","issn":["2307-387X"]}},"url":"https://dx.doi.org/10.1162/tacl_a_00713","inLanguage":"en","copyrightHolder":"","copyrightYear":"2025","publisher":"","author":[{"name":"Kamoi, Ryo","affiliation":"Penn State University, USA.  ryokamoi@psu.edu","@type":"Person"},{"name":"Zhang, Yusen","affiliation":"Penn State University, USA","@type":"Person"},{"name":"Zhang, Nan","affiliation":"Penn State University, USA","@type":"Person"},{"name":"Han, Jiawei","affiliation":"University of Illinois Urbana-Champaign, USA","@type":"Person"},{"name":"Zhang, Rui","affiliation":"Penn State University, USA.  rmz5227@psu.edu","@type":"Person"}],"description":"Abstract. Self-correction is an approach to improving responses from large language models (LLMs) by refining the responses using LLMs during inference. Prior work has proposed various self-correction frameworks using different sources of feedback, including self-evaluation and external feedback. However, there is still no consensus on the question of when LLMs can correct their own mistakes, as recent studies also report negative results. In this work, we critically survey broad papers and discuss the conditions required for successful self-correction. We first find that prior studies often do not define their research questions in detail and involve impractical frameworks or unfair evaluations that over-evaluate self-correction. To tackle these issues, we categorize research questions in self-correction research and provide a checklist for designing appropriate experiments. Our critical survey based on the newly categorized research questions shows that (1) no prior work demonstrates successful self-correction with feedback from prompted LLMs, except for studies in tasks that are exceptionally suited for self-correction, (2) self-correction works well in tasks that can use reliable external feedback, and (3) large-scale fine-tuning enables self-correction.","pageStart":"1417","pageEnd":"1440","siteName":"MIT Press","thumbnailURL":"//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_cover-1343168140.png","headline":"When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs","image":"//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_cover-1343168140.png","image:alt":""}
    </script>
<meta property="og:site_name" content="MIT Press" />
<meta property="og:title" content="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs" />
<meta property="og:description" content="Abstract. Self-correction is an approach to improving responses from large language models (LLMs) by refining the responses using LLMs during inference. Prior work has proposed various self-correction frameworks using different sources of feedback, including self-evaluation and external feedback. However, there is still no consensus on the question of when LLMs can correct their own mistakes, as recent studies also report negative results. In this work, we critically survey broad papers and discuss the conditions required for successful self-correction. We first find that prior studies often do not define their research questions in detail and involve impractical frameworks or unfair evaluations that over-evaluate self-correction. To tackle these issues, we categorize research questions in self-correction research and provide a checklist for designing appropriate experiments. Our critical survey based on the newly categorized research questions shows that (1) no prior work demonstrates successful self-correction with feedback from prompted LLMs, except for studies in tasks that are exceptionally suited for self-correction, (2) self-correction works well in tasks that can use reliable external feedback, and (3) large-scale fine-tuning enables self-correction." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dx.doi.org/10.1162/tacl_a_00713" />
<meta property="og:updated_time" content="" />
<meta property="og:image" content="https://mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_cover-1343168140.png" />
<meta property="og:image:url" content="https://mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_cover-1343168140.png" />
<meta property="og:image:secure_url" content="https://mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_cover-1343168140.png" />
<meta property="og:image:alt" content="" />








<script type="text/javascript" async="async" src="https://securepubads.g.doubleclick.net/tag/js/gpt.js" ></script>

    <script>
        var SCM = SCM || {};
        SCM.pubGradeAdsEnabled = false;
    </script>

<script>
    var googletag = googletag || {};
    googletag.cmd = googletag.cmd || [];

    googletag.cmd.push(function () {
    googletag.pubads().disableInitialLoad();



    });
</script>




<script src="https://servedbyadbutler.com/app.js" type="text/javascript"></script>
<script>

</script>







    <script src="https://scholar.google.com/scholar_js/casa.js" async></script>
</head>

<body data-sitename="transactionsoftheassociationforcomputationallinguistics" class="off-canvas pg_Article pg_article   " theme-tacl data-sitestyletemplate="Journal" >
            <noscript>
                <iframe  src="https://www.googletagmanager.com/ns.html?id=GTM-5P3FLZ8"
                        height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <a href="#skipNav" class="skipnav">Skip to Main Content</a>
<input id="hdnSiteID" name="hdnSiteID" type="hidden" value="1000067" /><input id="hdnAdDelaySeconds" name="hdnAdDelaySeconds" type="hidden" value="3000" /><input id="hdnAdConfigurationTop" name="hdnAdConfigurationTop" type="hidden" value="basic" /><input id="hdnAdConfigurationRightRail" name="hdnAdConfigurationRightRail" type="hidden" value="basic" />





<section class="master-header row vt-site-header">

    <div class="ad-banner js-ad-banner">
    <div class="widget-AdBlock widget-instance-HeaderAd" 
         data-widget-name="AdBlock" 
         data-widget-instance="HeaderAd">
            <input type="hidden"
           class="hfAdBlockInfo"
           data-divid="placement_451583_adBlockHeader"
           data-slotname="451583"
           data-targetname="179758"
           data-sizes="[[728, 90]]"
           data-enabled-on-mobile="True"
           data-adprovider-typeid="2"
           data-accountid=""
           data-outofpagead="False"
           data-sticky-time="5"
           data-lazyloaded="False"
           data-position-keyword=""
           data-skip-size-mapping="False"
           data-wps-adsize-number="0"
           data-wps-network-id="0"
           data-wps-site-id="0"
           data-wps-zone-ids=""
           data-wps-brandlock-keyword=""
           data-tapnative-aid=""
           data-tapnative-div-id=""/>
    <div class="adblock-wrap js-adblock-wrap " style="width:728px;">
                    <p class="adblock-advertisement-text js-adblock-advertisement-text hide">Advertisement</p>

<div id="placement_451583_adBlockHeader" adslot="451583" class="adblock-slot-placeholder js-adblock" style="width:728px; height:90px;"></div>


    </div>


    </div>

    </div>

    <div class="widget-SitePageHeader widget-instance-SitePageHeader" 
         data-widget-name="SitePageHeader" 
         data-widget-instance="SitePageHeader">
            <div class="site-theme-header">
        <div class="site-theme-header_contents global-nav-base">


<div class="global-nav">
            <a class="js-dropdown-trigger global-nav-trigger" href="javascript:;">
            <picture>
                <source media="(min-width: 601px)" srcset="//mitp.silverchair-cdn.com/UI/app/svg/umbrella/logo.svg">
                <img class="logo-TransactionsoftheAssociationforComputationalLinguistics site-theme-header-image" src="//mitp.silverchair-cdn.com/UI/app/svg/umbrella/logo.svg" alt="MIT Press Direct, home" />
            </picture>
                <i class="icon-general_arrow-down arrow-icon"><span class="screenreader-text">Open Menu</span></i>
        </a>
        <nav class="navbar-menu global-nav-dropdown js-dropdown">
            <div class="site-theme-header-logo">
                <a href="/" class="site-theme-header-image-wrap">
                        <picture>
                            <source media="(min-width: 601px)" srcset="//mitp.silverchair-cdn.com/UI/app/svg/umbrella/logo.svg">
                            <img class="logo-TransactionsoftheAssociationforComputationalLinguistics site-theme-header-image" src="//mitp.silverchair-cdn.com/UI/app/svg/umbrella/logo.svg" alt="MIT Press Direct, home" />
                        </picture>
                </a>
                <a href="javascript:;" class="icon-general-close menu-close js-menu-close"><span class="screenreader-text">Close</span></a>
            </div>
                    <ul class="site-menu site-menu-lvl-0 js-theme-dropdown">
                <li class="site-menu-item site-menu-lvl-0 site-menu-item-Books " id="site-menu-item-14014">
                        <a href="javascript:;" class="nav-link js-theme-dropdown-trigger" aria-expanded="false">Books <i class="icon-general_arrow-down arrow-icon"><span class="screenreader-text">Open Menu</span></i></a>

                            <ul class="site-menu site-menu-lvl-1 js-theme-dropdown">
                <li class="site-menu-item site-menu-lvl-1 site-menu-item-Books-Home " id="site-menu-item-14016">
                        <a href="/books" class="nav-link" >Books Home                      </a>


                </li>
                <li class="site-menu-item site-menu-lvl-1 site-menu-item-Browse-Books " id="site-menu-item-14017">
                        <a href="/books/search-results?fl_SiteID=5&amp;page=1&amp;f_ContentType=Book" class="nav-link" >Browse Books                      </a>


                </li>
        </ul>

                </li>
                <li class="site-menu-item site-menu-lvl-0 site-menu-item-Journals " id="site-menu-item-14015">
                        <a href="javascript:;" class="nav-link js-theme-dropdown-trigger" aria-expanded="false">Journals <i class="icon-general_arrow-down arrow-icon"><span class="screenreader-text">Open Menu</span></i></a>

                            <ul class="site-menu site-menu-lvl-1 js-theme-dropdown">
                <li class="site-menu-item site-menu-lvl-1 site-menu-item-Journals-Home " id="site-menu-item-14018">
                        <a href="/journals" class="nav-link" >Journals Home                      </a>


                </li>
                <li class="site-menu-item site-menu-lvl-1 site-menu-item-Browse-Journals " id="site-menu-item-14019">
                        <a href="/journals/pages/browse_by_title" class="nav-link" >Browse Journals                      </a>


                </li>
        </ul>

                </li>
                <li class="site-menu-item site-menu-lvl-0 site-menu-item-CogNet " id="site-menu-item-14020">
                        <a href="/pages/cognet" class="nav-link" >CogNet                      </a>


                </li>
                <li class="site-menu-item site-menu-lvl-0 site-menu-item-About-MIT-Press-Direct " id="site-menu-item-14021">
                        <a href="/pages/about" class="nav-link" >About MIT Press Direct                      </a>


                </li>
                <li class="site-menu-item site-menu-lvl-0 site-menu-item-Customer-Support " id="site-menu-item-14022">
                        <a href="/pages/customer_support" class="nav-link" >Customer Support                      </a>


                </li>
                <li class="site-menu-item site-menu-lvl-0 site-menu-item-Librarians " id="site-menu-item-14023">
                        <a href="/pages/librarians" class="nav-link" >Librarians                      </a>


                </li>
        </ul>

        </nav>

</div>



    <input type="hidden" class="hfEnableEnhancedAutoSuggest" value="false" name="searchScope" aria-hidden="true" />
        <div class="mobile-menu-trigger_wrap mobile-search_wrap">
            <a href="javascript:;"
               class="mobile-search_toggle at-search-toggle"
               role="button"
               aria-expanded="false"
               data-theme-dropdown-trigger="search-dropdown"><i class="icon-menu_search"><span class="screenreader-text">Search Dropdown Menu</span></i></a>
        </div>
    <div class="navbar-search-container mobile-dropdown search-dropdown" data-theme-dropdown="search-dropdown">
        <div class="navbar-search">
            <form class="microsite-search js-MicrositeSearch">
                <fieldset class="searchbar-fieldset">
                    <legend><span class="screenreader-text">header search</span></legend>
                    <div class="navbar-search-input_wrap">
                        <label for="MicrositeSearchTerm-SitePageHeader"><span class="screenreader-text">search input</span></label>

                        <input class="navbar-search-input microsite-search-term at-microsite-search-term search-term-autosuggest"
                               data-autosuggest-hint="micrositeSearchTermInputHint-SitePageHeader"
                               data-autosuggest-results="micrositeAutoCompleteResults-SitePageHeader"
                               data-autosuggest-id="MicrositeSearchTerm-SitePageHeader"
                               data-searchfilter="search-filter-SitePageHeader"
                               placeholder="Search..."
                               type="text" maxlength="255"
                                                              id="MicrositeSearchTerm-SitePageHeader"
                               title="search input">

                        <input type="hidden" name="hfAutoCompleteMaxResults" class="hfAutoCompleteMaxResults" value="6" aria-hidden="true" />
                        <input type="hidden" name="hfSolrAutoSuggestMinimumCharactersLength" class="hfSolrAutoSuggestMinimumCharactersLength" value="2" aria-hidden="true" />
                        <input type="hidden" name="hfSolrJournalName" class="hfSolrJournalName" value="" aria-hidden="true" />
                        <input type="hidden" name="hfSolrJournalID" class="hfSolrJournalID" value="" aria-hidden="true" />
                        <label for="micrositeSearchTermInputHint-SitePageHeader">
                            <span class="screenreader-text">Search input auto suggest</span>
                        </label>
                        <input type="text"
                               id="micrositeSearchTermInputHint-SitePageHeader"
                               data-autosuggest-id="micrositeSearchTermInputHint-SitePageHeader"
                               class="microsite-search-term-input-hint"
                               autocomplete="off" />
                        <ul data-autosuggest-id="micrositeAutoCompleteResults-SitePageHeader" class="term-list hidden"></ul>
                    </div>
                        <div class="navbar-search-filter_wrap">
                            <label for="navbar-search-filter-site-SitePageHeader">
                                <span class="screenreader-text">filter your search</span>
                            </label>
                            <select class="navbar-search-filter navbar-search-filter-site at-navbar-search-filter" id="navbar-search-filter-site-SitePageHeader" data-autosuggest-id="search-filter-SitePageHeader">
<option class="header-search-bar-filters-item" value="/search-results?page=1&q={searchQuery}" data-siteid="0" >All Content</option><option class="header-search-bar-filters-item" value="/journals/search-results?page=1&q={searchQuery}&fl_SiteID=1000001&allJournals=1" data-siteid="1000001" >All Journals</option><option class="header-search-bar-filters-item selected" value="/tacl/search-results?page=1&q={searchQuery}&fl_SiteID=1000067" data-siteid="1000067" selected>Transactions of the Association for Computational Linguistics</option>                            </select>
                        </div>
                    <div class="navbar-search-submit_wrap">
                        <a href="javascript:;" class="microsite-search-icon navbar-search-submit icon-menu_search"><span class="screenreader-text">Search</span></a>
                    </div>
                </fieldset>
            </form><!-- /#MicrositeSearch -->
        </div><!-- /.navbar-search -->
<div class="navbar-search-advanced">
    <a href="/advanced-search" class="advanced-search">Advanced Search</a>
</div>    </div><!-- /.navbar-search-container -->

<input type="hidden" name="parentSiteName" class="hfParentSiteName" value="Journals Gateway" aria-hidden="true" />
<input type="hidden" class="hfSolrMaxAllowSearchChar" value="100" aria-hidden="true" />
<input type="hidden" class="hfJournalShortName" value="" aria-hidden="true" />
<input type="hidden" class="hfSearchPlaceholder" value="" aria-hidden="true" />
<input type="hidden" name="hfGlobalSearchSiteURL" class="hfGlobalSearchSiteURL" value="" aria-hidden="true" />
<input type="hidden" name="hfSearchSiteURL" id="hfSiteURL" value="direct.mit.edu/tacl" aria-hidden="true" />
<input type="hidden" class="hfQuickSearchUrl" value="/tacl/search-results?page=1&amp;q={searchQuery}&amp;fl_SiteID=1000067" aria-hidden="true" />
<script type="text/javascript">
    (function () {
        var hfSiteUrl = document.getElementById('hfSiteURL');
        var siteUrl = hfSiteUrl.value;
        var subdomainIndex = siteUrl.indexOf('/');

        hfSiteUrl.value = location.host + (subdomainIndex >= 0 ? siteUrl.substring(subdomainIndex) : '');
    })();
</script>

    <div class="tablet-menu-trigger_wrap">
        <!-- MOBILE SHOPPING CART ICON -->
        <a href="javascript:;"
           class="tablet-sign-in"
           data-theme-dropdown-trigger="tablet-user-dropdown"
           aria-controls="tablet-user-dropdown"
           aria-expanded="false"><i class="icon-menu_account"><span class="screenreader-text">User Tools Dropdown</span></i></a>
    </div>
<div class="site-theme-header-menu-item_wrap tablet-menu" id="tablet-user-dropdown" data-theme-dropdown="tablet-user-dropdown">
    <!-- DESKTOP SHOPPING CART ICON -->

    <!-- DESKTOP REGISTRATION -->
        <div class="site-theme-header-menu-item"><a href="/my-account/register?siteId=1000067&amp;returnUrl=%2ftacl%2farticle%2fdoi%2f10.1162%2ftacl_a_00713%2f125177%2fWhen-Can-LLMs-Actually-Correct-Their-Own-Mistakes" class="register at-register js-register-user-modals">Register</a></div>

    <!-- DESKTOP INSTITUTIONS -->

        <!-- DESKTOP SIGN IN -->
        <div class="site-theme-header-menu-item not-authenicated">
            <a href="javascript:;"
                class="dropdown-toggle signin at-signin-dropdown at-signin-username"
                id="header-account-info-user-fullname"
                data-login-location="/SignIn/LoginForm/LoginFormPopup?returnUrl="
                data-theme-dropdown-trigger="sign-in-dropdown"
                aria-controls="sign-in-dropdown"
                aria-expanded="false"
                rel=nofollow>

Sign In                <i class="icon-general_arrow-down arrow-icon"><span class="screenreader-text">Open Menu</span></i>
            </a>
            <div class="dropdown-panel dropdown-panel-signin dropdown-panel-form at-signin-dropdown-panel" id="sign-in-dropdown" data-theme-dropdown="sign-in-dropdown">
                <div class="spinner"></div>
            </div><!-- /.dropdown-panel -->
        </div>

</div>
        </div><!-- /.site-theme-header_content -->
    </div><!-- /.site-theme-header- -->


    <div class="journal-header journal-bg">
        <div class="journal-header_content ">

    <div class="journal-logo_wrap">
        <a href="//direct.mit.edu/tacl" class="journal-logo-link">
            <picture>
                <source media="(min-width: 601px)" srcset="//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_title-606805150.svg">
                <img class="logo-TransactionsoftheAssociationforComputationalLinguistics journal-logo" src="//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_title-606805150.svg" alt="Transactions of the Association for Computational Linguistics" />
            </picture>
        </a>
    </div>




<div class="navbar-menu_wrap">
            <a class="mobile-site-menu-toggle" data-theme-dropdown-trigger="microsite-nav-menu" aria-controls="microsite-nav-menu" aria-expanded="false" href="javascript:;"><i class="icon-menu_hamburger"><span class="screenreader-text">Toggle Menu</span></i><span class="tablet-menu-label">Menu</span></a>
            <nav class="navbar-menu" id="microsite-nav-menu" data-theme-dropdown="microsite-nav-menu">
                    <ul class="site-menu site-menu-lvl-0 js-theme-dropdown">
<li class="site-menu-item site-menu-lvl-0 " id="site-menu-item-14881">
        <a href="/tacl/issue" class="nav-link" >Issues</a>
    </li> <li class="site-menu-item site-menu-lvl-0 " id="site-menu-item-14879">
        <a href="javascript:;" class="nav-link js-theme-dropdown-trigger" aria-expanded="false">About<i class="nav-arrow icon-general_arrow-down arrow-icon"><span class="screenreader-text">Open Menu</span></i></a>
        <ul class="site-menu site-menu-lvl-1 js-theme-dropdown">
<li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14882">
        <a href="/tacl/pages/editorial-info" class="nav-link" >Editorial Info</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14883">
        <a href="/tacl/pages/abstracting-indexing" class="nav-link" >Abstracting and Indexing</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14884">
        <a href="/tacl/../journals/pages/release-schedule" class="nav-link" >Release Schedule</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14885">
        <a href="/tacl/../journals/pages/rights-permissions" class="nav-link" >Rights and Permissions</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14886">
        <a href="/tacl/../journals/pages/authors" class="nav-link" >Author Resources</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14887">
        <a href="/tacl/../journals/pages/advertising-info" class="nav-link" >Advertising Info</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14888">
        <a href="/tacl/../journals/pages/publication-ethics" class="nav-link" >Publication Ethics</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14889">
        <a href="https://transacl.org/ojs/index.php/tacl/index" class="nav-link" target=&quot;_blank&quot;>TACL&#39;s website<span class="screenreader-text">Open External Link</span></a>
    </li>     </ul>
 </li> <li class="site-menu-item site-menu-lvl-0 " id="site-menu-item-14880">
        <a href="javascript:;" class="nav-link js-theme-dropdown-trigger" aria-expanded="false">Submit<i class="nav-arrow icon-general_arrow-down arrow-icon"><span class="screenreader-text">Open Menu</span></i></a>
        <ul class="site-menu site-menu-lvl-1 js-theme-dropdown">
<li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14890">
        <a href="/tacl/pages/submission-guidelines" class="nav-link" >Submission Guidelines</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14891">
        <a href="/tacl/../DocumentLibrary/PubAgreements/TACL_pub_agreement.pdf" class="nav-link" >Publication Agreement</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14892">
        <a href="/tacl/../journals/pages/open-access#diamond" class="nav-link" >Open Access</a>
    </li> <li class="site-menu-item site-menu-lvl-1 " id="site-menu-item-14893">
        <a href="/tacl/../journals/pages/publication-ethics" class="nav-link" >Publication Ethics</a>
    </li>     </ul>
 </li>     </ul>

            </nav>
</div><!-- /.navbar -->

        </div><!-- /.center-inner-row -->

    </div><!-- /.journal-header -->


<input id="routename" name="RouteName" type="hidden" value="tacl" />


    </div>

</section>

<div id="main" class="content-main js-main ui-base">
    <section class="master-main row">
        <div class="content-main_content">
            <a href="#" id="skipNav" class="screenreader-text" tabindex="-1">Skip Nav Destination</a>






<div class="page-column-wrap article-browse_content ">
<div id="InfoColumn" class="page-column page-column--left">

    <div class="info-inner-wrap can-stick empty">

        <button type="button" class="btn-as-icon toggle-left-col__close icon-general-close">
            <span class="screenreader-text">Close navigation menu</span>
        </button>
        <div class="responsive-nav-title">Article navigation</div>

        <div class="info-widget-wrap">
    <div class="widget-IssueInfo widget-instance-IssueInfo_Article" 
         data-widget-name="IssueInfo" 
         data-widget-instance="IssueInfo_Article">


<div id="issueInfo-IssueInfo_Article" class="article-info-wrap clearfix">
    <div class="article-issue-info">
        <div class="volume-issue__wrap">
                    <a href="/tacl/issue/volume/12">

                <span class="volume issue">Volume 12</span>

                </a>
        </div>

        <div class="ii-pub-date">
Volume 12 2024        </div>






    </div>

    <div class="article-issue-img">
                <a href="/tacl/issue/volume/12">
            <img id="issueFallbackImage" class="fb-featured-image at-coverimage" src="//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_cover-1343168140.png" alt="Issue Cover" />
                </a>
    </div>


</div> 
    </div>
                <div class="widget-ArticleNavLinks widget-instance-ArticleNavLinks_Article" 
         data-widget-name="ArticleNavLinks" 
         data-widget-instance="ArticleNavLinks_Article">
        <ul class="inline-list">
        <li class="prev arrow">
            <a href="/tacl/article/125175/Self-supervised-Topic-Taxonomy-Discovery-in-the"><i class="icon-general_arrow-left"></i>Previous <span>Article</span></a>
        </li>
            <li class="next arrow">
            <a href="/tacl/article/125276/Interactive-Machine-Teaching-by-Labeling-Rules-and">Next <span>Article</span><i class="icon-general_arrow-right"></i></a>
        </li>
</ul>

    </div>


    <div class="widget-ArticleJumpLinks widget-instance-ArticleJumpLinks_Widget" 
         data-widget-name="ArticleJumpLinks" 
         data-widget-instance="ArticleJumpLinks_Widget">
        <div class="content-nav">
        <div class="jumplink-title">Article Contents</div>
    <ul class="jumplink-list">
            <li class="section-jump-link head-1 abstract-section-jumplink" link-destination="5111371">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111371">Abstract</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111372">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111372">1 Introduction</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111381">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111381">2 Self-Correction of LLMs</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111406">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111406">3 Research Questions</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111425">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111425">4 Self-Correction with Prompting</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111435">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111435">5 Self-Correction with External Information</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111452">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111452">6 Strong Baselines</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111459">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111459">7 Summary of Our Analysis</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111464">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111464">8 Checklist for Self-Correction Research</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111468">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111468">9 Differences from Other Survey</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111470">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111470">10 Related Work of Self-Correction</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111477">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111477">11 Future Directions</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111486">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111486">12 Conclusion</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111488">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111488">Acknowledgments</a>
                </div>
            </li>
            <li class="section-jump-link head-1 section-section-jumplink" link-destination="5111490">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111490">Notes</a>
                </div>
            </li>
            <li class="section-jump-link head-1 backReferenceLink backreferences-section-jumplink" link-destination="5111493">
                <div class="section-jump-link__link-wrap">

                    <a class="jumplink scrollTo" href="#5111493">References</a>
                </div>
            </li>
    </ul>
</div>

    </div>



        </div>
    </div>
</div> 


    <div id="ContentColumn" class="page-column page-column--center center-content can-stick">
        <div class="article-browse_content-wrap js-content-standard">
                <div class="widget-ArticleMainView widget-instance-ArticleMainView_Article" 
         data-widget-name="ArticleMainView" 
         data-widget-instance="ArticleMainView_Article">

<div class="article-browse-top article-browse-mobile-nav empty">
    <div class="article-browse-mobile-nav-inner">
        <button type="button" class="btn toggle-left-col toggle-left-col__article">Article Navigation</button>
    </div>
</div>    <div class="content-inner-wrap">

    <div class="widget-ArticleTopInfo widget-instance-ArticleTopInfo" 
         data-widget-name="ArticleTopInfo" 
         data-widget-instance="ArticleTopInfo">
        <div class="module-widget article-top-widget content-metadata_wrap">


<div class="article-groups left-flag">
        <span class="article-date">November 04 2024</span>

</div>


    <div class="widget-items">
                <h1 class="wi-article-title article-title-main">
                    When Can LLMs <em>Actually</em> Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs
<i class='icon-availability_open' title='Open Access'><span class='screenreader-text'>Open Access</span></i>                </h1>
<div class="wi-authors">
    <div class="al-authors-list">
                <div class="al-author-name">

                            <!-- Keep these element on the same line, to prevent browsers from inserting a space between elements -->
            <a rel="nofollow" class="linked-name js-linked-name stats-author-info-trigger" href="javascript:;">Ryo Kamoi</a><span class="al-author-delim">, </span>


                    <div class="al-author-info-wrap arrow-up stats-author-info-panel">
<div class="info-card-author authorInfo_ArticleTopInfo">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Ryo Kamoi
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff">Penn State University, USA. <a href="/cdn-cgi/l/email-protection#d0a2a9bfbbb1bdbfb990a0a3a5feb5b4a5" target="_blank"><span class="__cf_email__" data-cfemail="44363d2b2f25292b2d043437316a212031">[email&#160;protected]</span></a></div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/tacl/search-results?f_Authors=Ryo+Kamoi" rel="nofollow">This Site</a>
</div>

    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:&quot;Ryo Kamoi&quot;">Google Scholar</a>
    </div>
</div>                    </div>
                </div>
                <div class="al-author-name">

                            <!-- Keep these element on the same line, to prevent browsers from inserting a space between elements -->
            <a rel="nofollow" class="linked-name js-linked-name stats-author-info-trigger" href="javascript:;">Yusen Zhang</a><span class="al-author-delim">, </span>


                    <div class="al-author-info-wrap arrow-up stats-author-info-panel">
<div class="info-card-author authorInfo_ArticleTopInfo">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Yusen Zhang
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff">Penn State University, USA</div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/tacl/search-results?f_Authors=Yusen+Zhang" rel="nofollow">This Site</a>
</div>

    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:&quot;Yusen Zhang&quot;">Google Scholar</a>
    </div>
</div>                    </div>
                </div>
                <div class="al-author-name">

                            <!-- Keep these element on the same line, to prevent browsers from inserting a space between elements -->
            <a rel="nofollow" class="linked-name js-linked-name stats-author-info-trigger" href="javascript:;">Nan Zhang</a><span class="al-author-delim">, </span>


                    <div class="al-author-info-wrap arrow-up stats-author-info-panel">
<div class="info-card-author authorInfo_ArticleTopInfo">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Nan Zhang
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff">Penn State University, USA</div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/tacl/search-results?f_Authors=Nan+Zhang" rel="nofollow">This Site</a>
</div>

    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:&quot;Nan Zhang&quot;">Google Scholar</a>
    </div>
</div>                    </div>
                </div>
                <div class="al-author-name">

                            <!-- Keep these element on the same line, to prevent browsers from inserting a space between elements -->
            <a rel="nofollow" class="linked-name js-linked-name stats-author-info-trigger" href="javascript:;">Jiawei Han</a><span class="al-author-delim">, </span>


                    <div class="al-author-info-wrap arrow-up stats-author-info-panel">
<div class="info-card-author authorInfo_ArticleTopInfo">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Jiawei Han
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff">University of Illinois Urbana-Champaign, USA</div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/tacl/search-results?f_Authors=Jiawei+Han" rel="nofollow">This Site</a>
</div>

    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:&quot;Jiawei Han&quot;">Google Scholar</a>
    </div>
</div>                    </div>
                </div>
                <div class="al-author-name">

                                <a rel="nofollow" class="linked-name js-linked-name stats-author-info-trigger" href="javascript:;">Rui Zhang</a>

                    <div class="al-author-info-wrap arrow-up stats-author-info-panel">
<div class="info-card-author authorInfo_ArticleTopInfo">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Rui Zhang
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff">Penn State University, USA. <a href="/cdn-cgi/l/email-protection#71031c0b44434346310102045f141504" target="_blank"><span class="__cf_email__" data-cfemail="56243b2c636464611626252378333223">[email&#160;protected]</span></a></div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/tacl/search-results?f_Authors=Rui+Zhang" rel="nofollow">This Site</a>
</div>

    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:&quot;Rui Zhang&quot;">Google Scholar</a>
    </div>
</div>                    </div>
                </div>
    </div>
</div>




<div class="wi-crossmark-button">
    <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="https://crossmark-cdn.crossref.org/widget/v2.0/widget.js"></script>
    <a href="javascript:;" class="stats-crossmark-updates" data-target="crossmark">
        <img src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg" width="150" alt="Crossmark: Check for Updates" />
    </a>
</div>


    <div class="js-author-expand-collapse-metadata-wrap author-expand-collapse-metadata-wrap stats-article-metadata-trigger-wrap">
        <a href="javascript:;" class="js-expand-collapse-metadata author-expand-collapse-metadata stats-article-metadata-trigger">
            <i class="js-metadata-toggle-icon icon-general-add"></i>Author and Article Information
        </a>
    </div>
<div class="js-metadata-wrap metadata">



<div id="authorInfoFullList" class="author-info-full-list">
            <div class="author-info-wrap">


<span class="author-full-name">
    Ryo Kamoi

</span>



                    <div class="author-affiliation">
                        <div class="aff">Penn State University, USA. <a href="/cdn-cgi/l/email-protection#493b3026222824262009393a3c672c2d3c" target="_blank"><span class="__cf_email__" data-cfemail="05777c6a6e64686a6c457576702b606170">[email&#160;protected]</span></a></div>
                    </div>
            </div>
            <div class="author-info-wrap">


<span class="author-full-name">
    Yusen Zhang

</span>



                    <div class="author-affiliation">
                        <div class="aff">Penn State University, USA</div>
                    </div>
            </div>
            <div class="author-info-wrap">


<span class="author-full-name">
    Nan Zhang

</span>



                    <div class="author-affiliation">
                        <div class="aff">Penn State University, USA</div>
                    </div>
            </div>
            <div class="author-info-wrap">


<span class="author-full-name">
    Jiawei Han

</span>



                    <div class="author-affiliation">
                        <div class="aff">University of Illinois Urbana-Champaign, USA</div>
                    </div>
            </div>
            <div class="author-info-wrap">


<span class="author-full-name">
    Rui Zhang

</span>



                    <div class="author-affiliation">
                        <div class="aff">Penn State University, USA. <a href="/cdn-cgi/l/email-protection#66140b1c535454512616151348030213" target="_blank"><span class="__cf_email__" data-cfemail="ddafb0a7e8efefea9dadaea8f3b8b9a8">[email&#160;protected]</span></a></div>
                    </div>
            </div>
</div>
            <div class="wi-footnotes">
                    <div>
                        <div class="article-footnote">
                            <div class="fn" content-id=""><p>Action Editor: Grzegorz Chrupała</p></div>
                        </div>
                    </div>
            </div>
            <div class="metadata-pubhistory">
                    <div class="pubhistory-entry">
                        <span class="pubhistory-state">Received:</span>
                        <span class="pubhistory-date">May 01 2024</span>
                    </div>
                    <div class="pubhistory-entry">
                        <span class="pubhistory-state">Revision Received:</span>
                        <span class="pubhistory-date">August 01 2024</span>
                    </div>

            </div>
            <div class="metadata-copyright">
                <div class="copyright copyright-statement">© 2024 Association for Computational Linguistics</div><div class="copyright copyright-year">2024</div><div class="copyright copyright-holder">Association for Computational Linguistics</div><div class="license "><div class="license-p">This is an open-access article distributed under the terms of the <a class="link link-uri" href="https://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. For a full description of the license, please visit <a class="link link-uri" href="https://creativecommons.org/licenses/by/4.0/legalcode" target="_blank">https://creativecommons.org/licenses/by/4.0/legalcode</a>.</div></div>
            </div>

</div>


<div class="pub-history-wrap clearfix">

            <div class="pub-history-row clearfix">
            <div class="ww-citation-primary"><em>Transactions of the Association for Computational Linguistics</em> (2024) 12: 1417–1440.</div>
        </div>
        <div class="pub-history-row citation-wrap-row clearfix">
                <div class="ww-citation-wrap-doi">
                    <div class="citation-doi">
                        <a href="https://doi.org/10.1162/tacl_a_00713">https://doi.org/10.1162/tacl_a_00713</a>
                    </div>
                </div>

                <div class="ww-citation-history-wrap js-history-dropdown-wrap">
                    <a href="javascript:;" class="history-label js-history-dropdown-trigger">
                        <span>Article history</span><i class="icon-history-small"></i>
                    </a>

                    <div class="ww-history js-history-entries-wrap">
                            <div class="history-entry">
                                <div class="wi-state">Received:</div>
                                <div class="wi-date">May 01 2024</div>
                            </div>
                            <div class="history-entry">
                                <div class="wi-state">Revision Received:</div>
                                <div class="wi-date">August 01 2024</div>
                            </div>
                    </div>
                </div>
        </div>

</div>



    </div>
</div>

<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>
    $(document).ready(function () {
        $('.article-top-widget').on('click', '.ati-toggle-trigger', function () {
            $(this).find('.icon-general-add, .icon-minus').toggleClass('icon-minus icon-general-add');
            $(this).siblings('.ati-toggle-content').toggleClass('hide');
        });

        // In Chrome, an anchor tag with target="_blank" and a "mailto:" href opens a new tab/window as well as the email client
        // I suspect this behavior will be corrected in the future
        // Remove the target="_blank"
        $('ul.wi-affiliationList').find('a[href^="mailto:"]').each(function () {
            $(this).removeAttr('target');
        });
    });
</script>


    </div>
    <div class="widget-ArticleLinks widget-instance-ArticleLinks" 
         data-widget-name="ArticleLinks" 
         data-widget-instance="ArticleLinks">

    </div>
<div class="toolbar-wrap vt-toolbar-wrap" role="navigation">
    <div class="toolbar-inner-wrap">
<div class="toolbar-inner-wrap ">
    <ul id="Toolbar" class="debug js-toolbar toolbar">

    <li class="toolbar-item item-cite js-item-cite">
<div class="getCitationDiv at-CiteButton">
    <a href="javascript:;" class="stats-get-citation" data-modal-source-id="toolbox-get-citation" rel=nofollow>
        <i class="icon-cite">
            <span class="screenreader-text">Cite Icon</span>
        </i>
        <span class="toolbar-text normalize">Cite</span>
    </a>
</div>
    </li>

    <li class="toolbar-item item-with-dropdown item-pdf">
    <a id="aria125177pdf"
       class="al-link pdf openInAnotherWindow stats-item-pdf-download js-download-file-gtm-datalayer-event  article-pdfLink"
       data-resourceId="125177"
       data-resourceTypeId="Article"
       data-doi="10.1162/tacl_a_00713"
       data-doctype="contentPdf"
       data-article-Id="125177" 
       href="/tacl/article-pdf/doi/10.1162/tacl_a_00713/2478635/tacl_a_00713.pdf"
       aria-labelledby="aria125177 aria125177pdf"
       target="_blank"
       rel=nofollow>
        <span class="screenreader-text">Open the </span>
        <i class="icon-menu_pdf-small">
        </i><span>PDF <span class="screenreader-text">for  in another window</span></span>
    </a>



    </li>

<li class="toolbar-item item-tools">
    <div class="widget-ToolboxPermissions widget-instance-ToolboxPermissions" 
         data-widget-name="ToolboxPermissions" 
         data-widget-instance="ToolboxPermissions">
            <div class="module-widget">
          <a id="PermissionsLink" href="/journals/pages/rights-permissions" class="" onclick="window.open(this.href); return false;" rel=nofollow>Permissions</a>
    </div>

    </div>

</li>
    <li class="toolbar-item item-with-dropdown item-share">
        <a href="javascript:;" class="drop-trigger js-toolbar-dropdown at-ShareButton" data-dropdown="ShareDrop">
            <i class="icon-menu_share"><span class="screenreader-text">Share Icon</span></i>
            <span class="toolbar-label">
                <span class="toolbar-text">Share</span>
                <i class="arrow-icon icon-general_arrow-down js-toolbar-arrow-icon"></i>
            </span>
        </a>
        <ul id="ShareDrop" class="addthis_toolbox addthis_default_style addthis_20x20_style f-dropdown js-dropdown-content" data-dropdown-content>

    <li>
        <a class="st-custom-button addthis_button_facebook js-share-link"
           data-network="facebook"
           data-title="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           data-url="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes"
           data-email-subject="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           href="javascript:;"
           rel=nofollow><span>Facebook</span></a>
    </li>
    <li>
        <a class="st-custom-button addthis_button_twitter js-share-link"
           data-network="twitter"
           data-title="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           data-url="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes"
           data-email-subject="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           href="javascript:;"
           rel=nofollow><span>X</span></a>
    </li>
    <li>
        <a class="st-custom-button addthis_button_linkedin js-share-link"
           data-network="linkedin"
           data-title="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           data-url="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes"
           data-email-subject="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           href="javascript:;"
           rel=nofollow><span>LinkedIn</span></a>
    </li>
    <li>
        <a class="st-custom-button addthis_button_email js-share-link"
           data-network="email"
           data-title="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           data-url="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes"
           data-email-subject="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           href="javascript:;"
           rel=nofollow><span>Email</span></a>
    </li>
    <li>
        <a class="st-custom-button addthis_button_bluesky js-share-link"
           data-network="bluesky"
           data-title="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           data-url=" https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00713/125177/When-Can-LLMs-Actually-Correct-Their-Own-Mistakes"
           data-email-subject="When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"
           href="javascript:;"
           rel=nofollow><span>Bluesky</span></a>
    </li>



        </ul>
    </li>
<li class="toolbar-item item-with-dropdown item-views js-item-views">
  <a href="javascript:;" class="js-toolbar-dropdown" data-dropdown="FilterDrop">
    <i class="icon-menu_views"><span class="screenreader-text">Views Icon</span></i>
    <span class="toolbar-label">
      <span class="toolbar-text">Views</span>
      <i class="icon-general_arrow-down arrow-icon js-toolbar-arrow-icon"><span class="screenreader-text">Open Menu</span></i>
    </span>
  </a>
  <ul id="ViewsDrop" class="f-dropdown js-dropdown-content" data-dropdown-content>
      <li class="article-content-filter js-content-filter" data-content-filter="article-content"><a href="javascript:;" rel=nofollow><span>Article contents</span></a></li>
      <li class="article-content-filter js-content-filter" data-content-filter="figures-tables"><a href="javascript:;" rel=nofollow><span>Figures &amp; tables</span></a></li>
      <li class="article-content-filter js-content-filter" data-content-filter="video"><a href="javascript:;" rel=nofollow><span>Video</span></a></li>
      <li class="article-content-filter js-content-filter" data-content-filter="audio"><a href="javascript:;" rel=nofollow><span>Audio</span></a></li>
      <li class="article-content-filter js-content-filter" data-content-filter="supplementary-data"><a href="javascript:;" rel=nofollow><span>Supplementary Material</span></a></li>
      <li class="article-content-filter js-content-filter" data-content-filter="peer-review"><a href="javascript:;" rel=nofollow><span>Peer Review</span></a></li>
  </ul>
</li>

<li class="search-dropdown-trigger_wrap toolbar-item">
    <a href="javascript:;" data-theme-dropdown-trigger="toolbar-search-dropdown" aria-controls="toolbar-search-dropdown" aria-expanded="false">
        <i class="icon-menu_search"></i>
        <span class="site-search-text">Search Site</span>
    </a>
</li>

    </ul>
</div>

<div id="getCitation" data-content-id="toolbox-get-citation" class="modal-only-content vt-citation-modal">
  <div class="modal-title">Citation</div>
  <p>Ryo Kamoi<span class='al-author-delim'>, </span>Yusen Zhang<span class='al-author-delim'>, </span>Nan Zhang<span class='al-author-delim'>, </span>Jiawei Han<span class='al-author-delim'>, </span>Rui Zhang; When Can LLMs <em>Actually</em> Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs. <em><em>Transactions of the Association for Computational Linguistics</em></em> 2024; 12 1417–1440. doi: <a href="https://doi.org/10.1162/tacl_a_00713">https://doi.org/10.1162/tacl_a_00713</a></p>
  <p class="citation-label">Download citation file:</p>
  <ul>
      <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=0" rel="nofollow">Ris (Zotero)</a></li>
          <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=0" rel="nofollow">Reference Manager</a></li>
          <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=0" rel="nofollow">EasyBib</a></li>
          <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=0" rel="nofollow">Bookends</a></li>

      <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=0" rel="nofollow">Mendeley</a></li>

      <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=0" rel="nofollow">Papers</a></li>

      <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=1" rel="nofollow">EndNote</a></li>
          <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=3" rel="nofollow">RefWorks</a></li>
          <li><a href="/Citation/Download?resourceId=125177&amp;resourceType=3&amp;citationFormat=2" rel="nofollow">BibTex</a></li>
          </ul>
</div>


        <div class="toolbar-search" id="toolbar-search-dropdown" data-theme-dropdown="toolbar-search-dropdown">
            <fieldset>
                <legend class="screenreader-text">toolbar search</legend>

    <div class="widget-SitePageHeader widget-instance-SiteSearch_ArticleMainView" 
         data-widget-name="SitePageHeader" 
         data-widget-instance="SiteSearch_ArticleMainView">


    <input type="hidden" class="hfEnableEnhancedAutoSuggest" value="false" name="searchScope" aria-hidden="true" />
        <div class="mobile-menu-trigger_wrap mobile-search_wrap">
            <a href="javascript:;"
               class="mobile-search_toggle at-search-toggle"
               role="button"
               aria-expanded="false"
               data-theme-dropdown-trigger="search-dropdown"><i class="icon-menu_search"><span class="screenreader-text">Search Dropdown Menu</span></i></a>
        </div>
    <div class="navbar-search-container mobile-dropdown search-dropdown" data-theme-dropdown="search-dropdown">
        <div class="navbar-search">
            <form class="microsite-search js-MicrositeSearch">
                <fieldset class="searchbar-fieldset">
                    <legend><span class="screenreader-text">toolbar search</span></legend>
                    <div class="navbar-search-input_wrap">
                        <label for="MicrositeSearchTerm-SiteSearch_ArticleMainView"><span class="screenreader-text">search input</span></label>

                        <input class="navbar-search-input microsite-search-term at-microsite-search-term search-term-autosuggest"
                               data-autosuggest-hint="micrositeSearchTermInputHint-SiteSearch_ArticleMainView"
                               data-autosuggest-results="micrositeAutoCompleteResults-SiteSearch_ArticleMainView"
                               data-autosuggest-id="MicrositeSearchTerm-SiteSearch_ArticleMainView"
                               data-searchfilter="search-filter-SiteSearch_ArticleMainView"
                               placeholder="Search..."
                               type="text" maxlength="255"
                                                              id="MicrositeSearchTerm-SiteSearch_ArticleMainView"
                               title="search input">

                        <input type="hidden" name="hfAutoCompleteMaxResults" class="hfAutoCompleteMaxResults" value="6" aria-hidden="true" />
                        <input type="hidden" name="hfSolrAutoSuggestMinimumCharactersLength" class="hfSolrAutoSuggestMinimumCharactersLength" value="2" aria-hidden="true" />
                        <input type="hidden" name="hfSolrJournalName" class="hfSolrJournalName" value="" aria-hidden="true" />
                        <input type="hidden" name="hfSolrJournalID" class="hfSolrJournalID" value="" aria-hidden="true" />
                        <label for="micrositeSearchTermInputHint-SiteSearch_ArticleMainView">
                            <span class="screenreader-text">Search input auto suggest</span>
                        </label>
                        <input type="text"
                               id="micrositeSearchTermInputHint-SiteSearch_ArticleMainView"
                               data-autosuggest-id="micrositeSearchTermInputHint-SiteSearch_ArticleMainView"
                               class="microsite-search-term-input-hint"
                               autocomplete="off" />
                        <ul data-autosuggest-id="micrositeAutoCompleteResults-SiteSearch_ArticleMainView" class="term-list hidden"></ul>
                    </div>
                        <div class="navbar-search-filter_wrap">
                            <label for="navbar-search-filter-site-SiteSearch_ArticleMainView">
                                <span class="screenreader-text">filter your search</span>
                            </label>
                            <select class="navbar-search-filter navbar-search-filter-site at-navbar-search-filter" id="navbar-search-filter-site-SiteSearch_ArticleMainView" data-autosuggest-id="search-filter-SiteSearch_ArticleMainView">
<option class="header-search-bar-filters-item" value="/search-results?page=1&q={searchQuery}" data-siteid="0" >All Content</option><option class="header-search-bar-filters-item" value="/journals/search-results?page=1&q={searchQuery}&fl_SiteID=1000001&allJournals=1" data-siteid="1000001" >All Journals</option><option class="header-search-bar-filters-item selected" value="/tacl/search-results?page=1&q={searchQuery}&fl_SiteID=1000067" data-siteid="1000067" selected>Transactions of the Association for Computational Linguistics</option>                            </select>
                        </div>
                    <div class="navbar-search-submit_wrap">
                        <a href="javascript:;" class="microsite-search-icon navbar-search-submit icon-menu_search"><span class="screenreader-text">Search</span></a>
                    </div>
                </fieldset>
            </form><!-- /#MicrositeSearch -->
        </div><!-- /.navbar-search -->
<div class="navbar-search-advanced">
    <a href="/advanced-search" class="advanced-search">Advanced Search</a>
</div>    </div><!-- /.navbar-search-container -->


    </div>

            </fieldset>
        </div>
    </div><!-- /.toolbar-inner-wrap -->
</div><!-- /.toolbar-wrap -->

<div class="article-body">
    <div id="articleMainView-articleId" class="js-articleMainView-articleId" data-articleid="125177" style="display: none;"></div>
    <div id="ContentTab" class="content active">
    <div class="widget-ArticleFulltext widget-instance-ArticleFulltext" 
         data-widget-name="ArticleFulltext" 
         data-widget-instance="ArticleFulltext">
        <input type="hidden" name="js-hfArticleLinksReferencesDoiRegex" id="js-hfArticleLinksReferencesDoiRegex" value="" />

<div class="module-widget">
    <div class="widget-items" data-widgetname="ArticleFulltext">
            <div class="article-metadata-standalone-panel clearfix"></div>





                <h2 scrollto-destination="5111371"  id="5111371" data-section-title="Abstract" class="abstract-title jumplink-heading">Abstract</h2>
            <div  class="">
                <div id="5111371-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="0">

                    <section class="abstract"><p>Self-correction is an approach to improving responses from large language models (LLMs) by refining the responses using LLMs during inference. Prior work has proposed various self-correction frameworks using different sources of feedback, including self-evaluation and external feedback. However, there is still no consensus on the question of <em>when LLMs can correct their own mistakes</em>, as recent studies also report negative results. In this work, we critically survey broad papers and discuss the conditions required for successful self-correction. We first find that prior studies often do not define their research questions in detail and involve impractical frameworks or unfair evaluations that over-evaluate self-correction. To tackle these issues, we categorize research questions in self-correction research and provide a checklist for designing appropriate experiments. Our critical survey based on the newly categorized research questions shows that (1) no prior work demonstrates successful self-correction with feedback from prompted LLMs, except for studies in tasks that are exceptionally suited for self-correction, (2) self-correction works well in tasks that can use reliable external feedback, and (3) large-scale fine-tuning enables self-correction.</p></section>
                </div>
                    <div class="article-metadata-panel clearfix rs_skip">
    <div class="widget-SolrResourceMetadata widget-instance-ContentMetadata_ArticleFulltext_Article" 
         data-widget-name="SolrResourceMetadata" 
         data-widget-instance="ContentMetadata_ArticleFulltext_Article">




    </div>

                    </div>
                </div>
                <h2 scrollto-destination="5111372"  id="5111372" data-section-title="1 Introduction" class="section-title jumplink-heading">1 Introduction</h2>
            <div  class="">
                <div id="5111373-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>Self-correction is a popular approach to improve responses from large language models (LLMs) by refining them using LLMs during inference (Bai et al., <a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>; Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>). Extensive studies on self-correction have been conducted in various tasks, including arithmetic reasoning, code generation, and question answering (Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>). The simplest approach of self-correction prompts LLMs to provide feedback on their own responses and refine the responses using the feedback (Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>), under the hypothesis that <em>recognizing errors is easier than avoiding them</em> (Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>). As in <a href="javascript:;" reveal-id="F1" data-open="F1" class="link link-reveal link-table xref-fig">Figure 1</a>, self-correction has also been studied using additional information for improving feedback, including external tools such as code interpreters (Chen et al., <a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>), external knowledge retrieved via web search (Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>), or fine-tuning (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>; Ye et al., <a href="javascript:;" data-modal-source-id="bib112" class="link link-ref xref-bibr">2023</a>). However, recent studies also report negative results indicating that LLMs cannot self-correct (Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Li et al., <a href="javascript:;" data-modal-source-id="bib53" class="link link-ref xref-bibr">2024b</a>) or even self-detect (Chen and Shu, <a href="javascript:;" data-modal-source-id="bib11" class="link link-ref xref-bibr">2024</a>; Tyen et al., <a href="javascript:;" data-modal-source-id="bib93" class="link link-ref xref-bibr">2024</a>; Hong et al., <a href="javascript:;" data-modal-source-id="bib37" class="link link-ref xref-bibr">2024</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib42" class="link link-ref xref-bibr">2024</a>; Kamoi et al., <a href="javascript:;" data-modal-source-id="bib46" class="link link-ref xref-bibr">2024</a>) their own mistakes at least in certain conditions. These conflicting observations indicate that further analysis of self-correction is needed.</p>
                </div>
                <div id="5111374-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <a id = "5111374" scrollto-destination="5111374"></a><div data-id="F1" class="fig fig-section" reveal-group-id=""><span class="hidden" id="viewTranscriptId_"></span><div class="graphic-wrap"><a class="fig-link" href="/view-large/figure/5111374/tacl_a_00713_f001.tif" target="_blank" rel="nofollow"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f001.png?Expires=1766635869&amp;Signature=k-EuiDLEJfMy8JdPE7-VS1Zx92lyETlp-K6A1TY8gJOswzmQ~ShpDKHKEDt2GV0StqDmbg0BpiwNF9ggunEhZpruCtoBPAuxJ1nMXHp7Mfmg56DVkypv-v8gcvXsgG6KDEqVWDEnBGDiArBhjIRVINfKFsA3bnoF3i46DjrWBrbweIpRcrUFi8hK1tZ3ZjF2lLbABNfpXFtiGUIQj6dcwmUQf2jRZct70vbhY-DYEh7gam1YbS8zej3XpdKOXWGf~qUQQGLIf5nkPbDRSV~dYJzC9QHn-j0FcP9LU4n8Eaeo8l8MWkzubfNME5VfgJNYFaEMf0JtooZh17J5AkTLOg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f001.png?Expires=1766635869&amp;Signature=k-EuiDLEJfMy8JdPE7-VS1Zx92lyETlp-K6A1TY8gJOswzmQ~ShpDKHKEDt2GV0StqDmbg0BpiwNF9ggunEhZpruCtoBPAuxJ1nMXHp7Mfmg56DVkypv-v8gcvXsgG6KDEqVWDEnBGDiArBhjIRVINfKFsA3bnoF3i46DjrWBrbweIpRcrUFi8hK1tZ3ZjF2lLbABNfpXFtiGUIQj6dcwmUQf2jRZct70vbhY-DYEh7gam1YbS8zej3XpdKOXWGf~qUQQGLIf5nkPbDRSV~dYJzC9QHn-j0FcP9LU4n8Eaeo8l8MWkzubfNME5VfgJNYFaEMf0JtooZh17J5AkTLOg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Self-correction in three stages: initial response generation, feedback, and refinement." path-from-xml="tacl_a_00713_f001.tif" /></a><div class="fig-orig original-slide"><a section="5111374" class="fig-view-orig at-figureViewLarge" href="/view-large/figure/5111374/tacl_a_00713_f001.tif" path-from-xml="tacl_a_00713_f001.tif" target="_blank" rel="nofollow" aria-label="View large Figure 1: ">View large</a><a section="5111374" href="//mitp.silverchair-cdn.com/DownloadFile/DownloadImage.aspx?image=https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/tacl_a_00713_f001.png?Expires=1766635869&Signature=t861rhnURfmbldLaa4DRxJVr-ePL3MDSQz1CIXIPBW3FeNxQbYBVs4fXkgq~NMdL-A6jRnQ-xZ4-P6jx-rgovPl3RwJOJvxlUAGFj0s5Xksth6QJ29EzsTQIEUS7mGjfHDXjcCQ0CC03jucZ6~wvGLqzVQV4V-AlwymeSq1Sxm-hylp5bVQw3ZygXIC6-i2HIS7ui-MGCvuOJjSg8b2raVOq0n5Bq4HOPv8CVMDoR58WbRFNpNCFI4eY07dSlsKbka0QD6tKOiTrEXhmKbVzvg10aE-okoYiP5aWcPbQC85CU4u6LNoGzU4gI7FMS4TlQDocSDjXhvUDfWrXXO3B6A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=5111374&ar=125177&xsltPath=~/UI/app/XSLT&imagename=&siteId=1000067" class="download-slide stats-download-slide js-download-file-gtm-datalayer-event" data-filetype="ppt" path-from-xml="tacl_a_00713_f001.tif" target="_blank" rel="nofollow" aria-label="Download slide for Figure 1: ">Download slide</a></div></div><div class="graphic-bottom"><div class="label fig-label">Figure 1: </div><div class="caption fig-caption"><p>Self-correction in three stages: initial response generation, feedback, and refinement.</p></div></div></div><div id="F1" content-id="F1" class="fig fig-modal reveal-modal" data-reveal="data-reveal"><div class="graphic-wrap"><a class="fig-link" href="/view-large/figure/5111374/tacl_a_00713_f001.tif" target="_blank" rel="nofollow"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f001.png?Expires=1766635869&amp;Signature=k-EuiDLEJfMy8JdPE7-VS1Zx92lyETlp-K6A1TY8gJOswzmQ~ShpDKHKEDt2GV0StqDmbg0BpiwNF9ggunEhZpruCtoBPAuxJ1nMXHp7Mfmg56DVkypv-v8gcvXsgG6KDEqVWDEnBGDiArBhjIRVINfKFsA3bnoF3i46DjrWBrbweIpRcrUFi8hK1tZ3ZjF2lLbABNfpXFtiGUIQj6dcwmUQf2jRZct70vbhY-DYEh7gam1YbS8zej3XpdKOXWGf~qUQQGLIf5nkPbDRSV~dYJzC9QHn-j0FcP9LU4n8Eaeo8l8MWkzubfNME5VfgJNYFaEMf0JtooZh17J5AkTLOg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f001.png?Expires=1766635869&amp;Signature=k-EuiDLEJfMy8JdPE7-VS1Zx92lyETlp-K6A1TY8gJOswzmQ~ShpDKHKEDt2GV0StqDmbg0BpiwNF9ggunEhZpruCtoBPAuxJ1nMXHp7Mfmg56DVkypv-v8gcvXsgG6KDEqVWDEnBGDiArBhjIRVINfKFsA3bnoF3i46DjrWBrbweIpRcrUFi8hK1tZ3ZjF2lLbABNfpXFtiGUIQj6dcwmUQf2jRZct70vbhY-DYEh7gam1YbS8zej3XpdKOXWGf~qUQQGLIf5nkPbDRSV~dYJzC9QHn-j0FcP9LU4n8Eaeo8l8MWkzubfNME5VfgJNYFaEMf0JtooZh17J5AkTLOg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Self-correction in three stages: initial response generation, feedback, and refinement." path-from-xml="tacl_a_00713_f001.tif" /></a><div class="fig-orig original-slide"><a section="5111374" class="fig-view-orig at-figureViewLarge" href="/view-large/figure/5111374/tacl_a_00713_f001.tif" path-from-xml="tacl_a_00713_f001.tif" target="_blank" rel="nofollow" aria-label="View large Figure 1: ">View large</a><a section="5111374" href="//mitp.silverchair-cdn.com/DownloadFile/DownloadImage.aspx?image=https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/tacl_a_00713_f001.png?Expires=1766635869&Signature=t861rhnURfmbldLaa4DRxJVr-ePL3MDSQz1CIXIPBW3FeNxQbYBVs4fXkgq~NMdL-A6jRnQ-xZ4-P6jx-rgovPl3RwJOJvxlUAGFj0s5Xksth6QJ29EzsTQIEUS7mGjfHDXjcCQ0CC03jucZ6~wvGLqzVQV4V-AlwymeSq1Sxm-hylp5bVQw3ZygXIC6-i2HIS7ui-MGCvuOJjSg8b2raVOq0n5Bq4HOPv8CVMDoR58WbRFNpNCFI4eY07dSlsKbka0QD6tKOiTrEXhmKbVzvg10aE-okoYiP5aWcPbQC85CU4u6LNoGzU4gI7FMS4TlQDocSDjXhvUDfWrXXO3B6A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=5111374&ar=125177&xsltPath=~/UI/app/XSLT&imagename=&siteId=1000067" class="download-slide stats-download-slide js-download-file-gtm-datalayer-event" data-filetype="ppt" path-from-xml="tacl_a_00713_f001.tif" target="_blank" rel="nofollow" aria-label="Download slide for Figure 1: ">Download slide</a></div></div><div class="graphic-bottom"><div class="label fig-label">Figure 1: </div><div class="caption fig-caption"><p>Self-correction in three stages: initial response generation, feedback, and refinement.</p></div></div><a class="close-reveal-modal" href="javascript:;" aria-label="Close modal"><i class="icon-general-close"> </i><span class="screenreader-text">Close modal</span></a></div>
                </div>
                <div id="5111375-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>In this work, we provide a critical survey to investigate the conditions required for successful self-correction. First, our analysis finds that prior studies often do not define their research questions in detail. As a result, many papers fail to provide appropriate experiments to evaluate the research questions they implicitly target. To address this issue, we categorize research questions in self-correction research (§<a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">3.1</a>) and discuss frameworks that should be used for verifying each research question (§<a href="#sec4" data-scrollto="sec4" class="sectionLink xref-sec js-sec-jumplink">3.2</a>). Finally, we provide a checklist for designing appropriate experiments (§<a href="#sec11" data-scrollto="sec11" class="sectionLink xref-sec js-sec-jumplink">8</a>).</p>
                </div>
                <div id="5111376-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>Next, we analyze prior work to identify when LLMs can self-correct their mistakes, using the new definitions of the research questions. Our analysis highlights that the bottleneck is in the feedback generation (§<a href="#sec10" data-scrollto="sec10" class="sectionLink xref-sec js-sec-jumplink">7</a>). Specifically, (1) no prior work shows successful self-correction with feedback from prompted LLMs in general tasks (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>), (2) self-correction works well in tasks where reliable external feedback is available (§<a href="#sec7" data-scrollto="sec7" class="sectionLink xref-sec js-sec-jumplink">5.1</a>), (3) large-scale fine-tuning enables self-correction (§<a href="#sec8" data-scrollto="sec8" class="sectionLink xref-sec js-sec-jumplink">5.2</a>), and (4) some tasks have properties exceptionally suitable for self-correction (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>). In summary, our analysis identifies the properties required for successful self-correction as follows:</p>
                </div>
                <div id="5111377-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>[RQ1] When can LLMs self-correct <em>based solely on the inherent capabilities of LLMs?</em><ul class="bullet"><li><p>In general tasks, no prior work shows reliable evidence of successful self-correction with in-context learning. (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>)</p></li><li><p>In tasks with specific properties that are exceptionally favorable for self-correction (e.g., responses are decomposable), self-correction is effective even with in-context learning. (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>)</p></li></ul></p>
                </div>
                <div id="5111378-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>[RQ2] When can LLMs self-correct the best-possible initial responses <em>with external information?</em><ul class="bullet"><li><p>Self-correction is effective in tasks where reliable external feedback is available. (§<a href="#sec7" data-scrollto="sec7" class="sectionLink xref-sec js-sec-jumplink">5.1</a>)</p></li><li><p>Fine-tuning enables self-correction when large training data is available but is unexplored for small training data. (§<a href="#sec8" data-scrollto="sec8" class="sectionLink xref-sec js-sec-jumplink">5.2</a>)</p></li></ul></p>
                </div>
                <div id="5111379-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>[RQ3] When are the final outputs of self-correction <em>better than other approaches</em>? <ul class="bullet"><li><p>Self-correction is often not compared with sufficiently strong baselines, and it is still unclear whether it is better than other approaches. (§<a href="#sec9" data-scrollto="sec9" class="sectionLink xref-sec js-sec-jumplink">6</a>)</p></li></ul></p>
                </div>
                <div id="5111380-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111372">

                    <p>This survey is organized as follows. <a href="#sec1" data-scrollto="sec1" class="sectionLink xref-sec js-sec-jumplink">Section 2</a> provides an overview of self-correction. <a href="#sec2" data-scrollto="sec2" class="sectionLink xref-sec js-sec-jumplink">Section 3</a> introduces a new approach to classify research questions and frameworks in self-correction research. Sections <a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a> and <a href="#sec6" data-scrollto="sec6" class="sectionLink xref-sec js-sec-jumplink">5</a> analyze prior work in self-correction with in-context learning and external information (external tools, external knowledge, fine-tuning), respectively. <a href="#sec9" data-scrollto="sec9" class="sectionLink xref-sec js-sec-jumplink">Section 6</a> explains related approaches that should be compared with self-correction as baselines. <a href="#sec10" data-scrollto="sec10" class="sectionLink xref-sec js-sec-jumplink">Section 7</a> summarizes our findings from the analysis. <a href="#sec11" data-scrollto="sec11" class="sectionLink xref-sec js-sec-jumplink">Section 8</a> provides a checklist for self-correction research. <a href="#sec12" data-scrollto="sec12" class="sectionLink xref-sec js-sec-jumplink">Section 9</a> explains differences from other surveys. <a href="#sec13" data-scrollto="sec13" class="sectionLink xref-sec js-sec-jumplink">Section 10</a> provides studies related to self-correction. <a href="#sec14" data-scrollto="sec14" class="sectionLink xref-sec js-sec-jumplink">Section 11</a> provides future directions.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111381" data-legacyid="sec1" id="5111381" data-section-title="2 Self-Correction of LLMs" class="section-title jumplink-heading">2 Self-Correction of LLMs</h2>
            <div  class="">
                <div id="5111382-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111381">

                    <p>The term “self-correction” is used in a wide range of scenarios, from a strict definition in which LLMs refine their own responses by themselves (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>) to broader concepts that also involve feedback from external tools or knowledge (Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>). In this work, we define self-correction as a framework that <em>refines</em> responses from LLMs using LLMs <em>during inference</em>, possibly with external tools or knowledge. As in <a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a>, <a href="javascript:;" reveal-id="F2" data-open="F2" class="link link-reveal link-table xref-fig">Figure 2</a>, and <a href="javascript:;" reveal-id="F3" data-open="F3" class="link link-reveal link-table xref-fig">Figure 3</a>, self-correction has been studied in various frameworks with different sources of feedback.</p>
                </div>
                <div id="5111383-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111381">

                    <a id = "5111383" scrollto-destination="5111383"></a><div content-id="T1 sec1" class="table-wrap table-wide"><div id="T1" data-id="T1" class="table-wrap-title "><span class="label title-label" id="label-50447">Table 1: </span><div class="caption caption-id-" id="caption-50447"><p>Representative studies in self-correction of LLMs. <img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i002.png?Expires=1766635869&amp;Signature=g2XMqEtOhJEhMUI7g2tiVlw8eJIWFDwob3MqHgAFRDjIMc6uekAVt0ydeLjxDO206C8LvbmeY0WkjEJfaSPBrcDBCAMm73Loa9FLS8g4Y4v112KE08I941UlT9IHmtuWhbB0DowAeUhdUTdCeQTRXN5~mNg6Dv~HltUx~MCyNtQClszykfHp3WQjy3~eAj7o4Xhm9X0C-REf0D7E9jRohaKTV4azoMIT8N2GbjZrZoXG-Na58YKF50iIyk3M2u3Su1JuQSqgcSg4n9xBfWIpnokaxwRA7QKdAqppRr4-OZxrCYTIhHbGIn0OjKEVD7rfA6jvKP5OVEFdvBnA8Psr5Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i002.png?Expires=1766635869&amp;Signature=g2XMqEtOhJEhMUI7g2tiVlw8eJIWFDwob3MqHgAFRDjIMc6uekAVt0ydeLjxDO206C8LvbmeY0WkjEJfaSPBrcDBCAMm73Loa9FLS8g4Y4v112KE08I941UlT9IHmtuWhbB0DowAeUhdUTdCeQTRXN5~mNg6Dv~HltUx~MCyNtQClszykfHp3WQjy3~eAj7o4Xhm9X0C-REf0D7E9jRohaKTV4azoMIT8N2GbjZrZoXG-Na58YKF50iIyk3M2u3Su1JuQSqgcSg4n9xBfWIpnokaxwRA7QKdAqppRr4-OZxrCYTIhHbGIn0OjKEVD7rfA6jvKP5OVEFdvBnA8Psr5Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="" path-from-xml="tacl_a_00713_i002.tif" />Gray color represents unrealistic settings. <sup>♠</sup>: Weak prompts for generating initial responses. FB: Feedback models for cross-model correction.</p></div></div><div class="fig-graphic"><a class="jumplink-placeholder" data-sectionId="5111383" id="tacl_a_00713_i001.tif"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i001.png?Expires=1766635869&amp;Signature=JcVm8vU5OYJX5Nl6hfW93zJxkM2~iyA1FJZG0E51a44G6hs-o-1hzKtUlb76TwSZMOjzOXF742CAc00MVYmhlevpZ5QCuds7VITkK-UqkltbRMVroJ2TuUtFpjcvDhIWknNN1GSKjnjVS5ac8LnaUGvlbn2upBdqQ0nPfpt8VoAkYcEeorFuCH8KHcYZ9k9MqqquAoJwcXqtHC083H-~JvWRDFzYsihAR5zkKeUf0vCl1-qDECrmzOu6jjTVF~nEsnp3kORYeP5g-cRwPcrshO3twLPkCRe9FkKOCF2Qg1fK4p0n6QQaznfPPdSMsc0zeYS9pZVZGxxIr0PbPORexA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i001.png?Expires=1766635869&amp;Signature=JcVm8vU5OYJX5Nl6hfW93zJxkM2~iyA1FJZG0E51a44G6hs-o-1hzKtUlb76TwSZMOjzOXF742CAc00MVYmhlevpZ5QCuds7VITkK-UqkltbRMVroJ2TuUtFpjcvDhIWknNN1GSKjnjVS5ac8LnaUGvlbn2upBdqQ0nPfpt8VoAkYcEeorFuCH8KHcYZ9k9MqqquAoJwcXqtHC083H-~JvWRDFzYsihAR5zkKeUf0vCl1-qDECrmzOu6jjTVF~nEsnp3kORYeP5g-cRwPcrshO3twLPkCRe9FkKOCF2Qg1fK4p0n6QQaznfPPdSMsc0zeYS9pZVZGxxIr0PbPORexA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Representative studies in self-correction of LLMs. Gray color represents unrealistic settings. ♠: Weak prompts for generating initial responses. FB: Feedback models for cross-model correction." path-from-xml="tacl_a_00713_i001.tif" /></a></div><div class="fig-orig original-slide"><a section="5111383" class="fig-view-orig" href="/view-large/figure/5111383/tacl_a_00713_i001.tif" path-from-xml="tacl_a_00713_i001.tif" target="_blank">View large</a></div><div content-id="T1" class="table-modal"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i001.png?Expires=1766635869&amp;Signature=JcVm8vU5OYJX5Nl6hfW93zJxkM2~iyA1FJZG0E51a44G6hs-o-1hzKtUlb76TwSZMOjzOXF742CAc00MVYmhlevpZ5QCuds7VITkK-UqkltbRMVroJ2TuUtFpjcvDhIWknNN1GSKjnjVS5ac8LnaUGvlbn2upBdqQ0nPfpt8VoAkYcEeorFuCH8KHcYZ9k9MqqquAoJwcXqtHC083H-~JvWRDFzYsihAR5zkKeUf0vCl1-qDECrmzOu6jjTVF~nEsnp3kORYeP5g-cRwPcrshO3twLPkCRe9FkKOCF2Qg1fK4p0n6QQaznfPPdSMsc0zeYS9pZVZGxxIr0PbPORexA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i001.png?Expires=1766635869&amp;Signature=JcVm8vU5OYJX5Nl6hfW93zJxkM2~iyA1FJZG0E51a44G6hs-o-1hzKtUlb76TwSZMOjzOXF742CAc00MVYmhlevpZ5QCuds7VITkK-UqkltbRMVroJ2TuUtFpjcvDhIWknNN1GSKjnjVS5ac8LnaUGvlbn2upBdqQ0nPfpt8VoAkYcEeorFuCH8KHcYZ9k9MqqquAoJwcXqtHC083H-~JvWRDFzYsihAR5zkKeUf0vCl1-qDECrmzOu6jjTVF~nEsnp3kORYeP5g-cRwPcrshO3twLPkCRe9FkKOCF2Qg1fK4p0n6QQaznfPPdSMsc0zeYS9pZVZGxxIr0PbPORexA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Representative studies in self-correction of LLMs. Gray color represents unrealistic settings. ♠: Weak prompts for generating initial responses. FB: Feedback models for cross-model correction." path-from-xml="tacl_a_00713_i001.tif" /></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111383" target="_blank" rel="nofollow" aria-label="View large Table 1: ">
                  View Large</a></div></div>
                </div>
                <div id="5111384-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111381">

                    <a id = "5111384" scrollto-destination="5111384"></a><div data-id="F2" class="fig fig-section" reveal-group-id="sec1"><span class="hidden" id="viewTranscriptId_"></span><div class="graphic-wrap"><a class="fig-link" href="/view-large/figure/5111384/tacl_a_00713_f002.tif" target="_blank" rel="nofollow"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f002.png?Expires=1766635869&amp;Signature=VQulgiLKDw4b8MT2tzpSif1ZhaHh6G-ug6O53WTmHxCHuqxRBJklZ9n7ToBlAxzAN3RPnfrB42kU07Kq2erXpE-eshOUoB40nwpA52eBw8qWSgJpRBkbDzogav8x6RpntBEmE4fGOSfODRMk2CHjW~0cWaZwfW8mceJZsfIaCTKUZzzpxSqRzd-jritulOsM3hUfnrynW6wUmc8kWbnZbT05OgcyIf8-q4A~YsSsIFEyRDIKjnP8QsJHtejVr~ZVr-xr2reMxfFfREy~uiDPB5m3~2MxU9~3vRnl3133L9uO1wEr7qciWO~klXoiVfHNWi~vAbrLrabodj-uwlqdew__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f002.png?Expires=1766635869&amp;Signature=VQulgiLKDw4b8MT2tzpSif1ZhaHh6G-ug6O53WTmHxCHuqxRBJklZ9n7ToBlAxzAN3RPnfrB42kU07Kq2erXpE-eshOUoB40nwpA52eBw8qWSgJpRBkbDzogav8x6RpntBEmE4fGOSfODRMk2CHjW~0cWaZwfW8mceJZsfIaCTKUZzzpxSqRzd-jritulOsM3hUfnrynW6wUmc8kWbnZbT05OgcyIf8-q4A~YsSsIFEyRDIKjnP8QsJHtejVr~ZVr-xr2reMxfFfREy~uiDPB5m3~2MxU9~3vRnl3133L9uO1wEr7qciWO~klXoiVfHNWi~vAbrLrabodj-uwlqdew__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="LLM self-correction frameworks, categorized by information used for generating feedback and whether they use best-possible initial responses (§3.2). This figure illustrates representative architectures." path-from-xml="tacl_a_00713_f002.tif" /></a><div class="fig-orig original-slide"><a section="5111384" class="fig-view-orig at-figureViewLarge" href="/view-large/figure/5111384/tacl_a_00713_f002.tif" path-from-xml="tacl_a_00713_f002.tif" target="_blank" rel="nofollow" aria-label="View large Figure 2: ">View large</a><a section="5111384" href="//mitp.silverchair-cdn.com/DownloadFile/DownloadImage.aspx?image=https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/tacl_a_00713_f002.png?Expires=1766635869&Signature=4U5-jq3VK-dYMsKlzfSYYS1tVt6pxT7r0RRf~eozQEOxXjVnLZfmZZjxUwt2aS8an0lAizT2ehOpV3KlIQcyqRoK4p268zxshstjNpXsrJPLesVLLnOxuIpa5wL1GkIkkfc54B6~2vMQCHQRML~ZGajLzEoTvdzWlCZY7LAyYVhZxrn5mj0KaUsvZOPNq1AgmgZhOx8WSZ8aAWDLvU2qV8H05yD4lSPyXuRbY3C~ALWScISORMs865LFCnTXhLjz8xp-i9fyb35Jvnt0U3EDxbTiz76rqRM8kTfvCUHVirlBOxv2wyaymgoKQ7Jlj~T0aV-~3CDAWK4nZJwkyAYH5A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=5111384&ar=125177&xsltPath=~/UI/app/XSLT&imagename=&siteId=1000067" class="download-slide stats-download-slide js-download-file-gtm-datalayer-event" data-filetype="ppt" path-from-xml="tacl_a_00713_f002.tif" target="_blank" rel="nofollow" aria-label="Download slide for Figure 2: ">Download slide</a></div></div><div class="graphic-bottom"><div class="label fig-label">Figure 2: </div><div class="caption fig-caption"><p>LLM self-correction frameworks, categorized by information used for generating feedback and whether they use best-possible initial responses (§<a href="#sec4" data-scrollto="sec4" class="sectionLink xref-sec js-sec-jumplink">3.2</a>). This figure illustrates representative architectures.</p></div></div></div><div id="F2" content-id="F2" class="fig fig-modal reveal-modal" data-reveal="data-reveal"><div class="graphic-wrap"><a class="fig-link" href="/view-large/figure/5111384/tacl_a_00713_f002.tif" target="_blank" rel="nofollow"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f002.png?Expires=1766635869&amp;Signature=VQulgiLKDw4b8MT2tzpSif1ZhaHh6G-ug6O53WTmHxCHuqxRBJklZ9n7ToBlAxzAN3RPnfrB42kU07Kq2erXpE-eshOUoB40nwpA52eBw8qWSgJpRBkbDzogav8x6RpntBEmE4fGOSfODRMk2CHjW~0cWaZwfW8mceJZsfIaCTKUZzzpxSqRzd-jritulOsM3hUfnrynW6wUmc8kWbnZbT05OgcyIf8-q4A~YsSsIFEyRDIKjnP8QsJHtejVr~ZVr-xr2reMxfFfREy~uiDPB5m3~2MxU9~3vRnl3133L9uO1wEr7qciWO~klXoiVfHNWi~vAbrLrabodj-uwlqdew__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f002.png?Expires=1766635869&amp;Signature=VQulgiLKDw4b8MT2tzpSif1ZhaHh6G-ug6O53WTmHxCHuqxRBJklZ9n7ToBlAxzAN3RPnfrB42kU07Kq2erXpE-eshOUoB40nwpA52eBw8qWSgJpRBkbDzogav8x6RpntBEmE4fGOSfODRMk2CHjW~0cWaZwfW8mceJZsfIaCTKUZzzpxSqRzd-jritulOsM3hUfnrynW6wUmc8kWbnZbT05OgcyIf8-q4A~YsSsIFEyRDIKjnP8QsJHtejVr~ZVr-xr2reMxfFfREy~uiDPB5m3~2MxU9~3vRnl3133L9uO1wEr7qciWO~klXoiVfHNWi~vAbrLrabodj-uwlqdew__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="LLM self-correction frameworks, categorized by information used for generating feedback and whether they use best-possible initial responses (§3.2). This figure illustrates representative architectures." path-from-xml="tacl_a_00713_f002.tif" /></a><div class="fig-orig original-slide"><a section="5111384" class="fig-view-orig at-figureViewLarge" href="/view-large/figure/5111384/tacl_a_00713_f002.tif" path-from-xml="tacl_a_00713_f002.tif" target="_blank" rel="nofollow" aria-label="View large Figure 2: ">View large</a><a section="5111384" href="//mitp.silverchair-cdn.com/DownloadFile/DownloadImage.aspx?image=https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/tacl_a_00713_f002.png?Expires=1766635869&Signature=4U5-jq3VK-dYMsKlzfSYYS1tVt6pxT7r0RRf~eozQEOxXjVnLZfmZZjxUwt2aS8an0lAizT2ehOpV3KlIQcyqRoK4p268zxshstjNpXsrJPLesVLLnOxuIpa5wL1GkIkkfc54B6~2vMQCHQRML~ZGajLzEoTvdzWlCZY7LAyYVhZxrn5mj0KaUsvZOPNq1AgmgZhOx8WSZ8aAWDLvU2qV8H05yD4lSPyXuRbY3C~ALWScISORMs865LFCnTXhLjz8xp-i9fyb35Jvnt0U3EDxbTiz76rqRM8kTfvCUHVirlBOxv2wyaymgoKQ7Jlj~T0aV-~3CDAWK4nZJwkyAYH5A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=5111384&ar=125177&xsltPath=~/UI/app/XSLT&imagename=&siteId=1000067" class="download-slide stats-download-slide js-download-file-gtm-datalayer-event" data-filetype="ppt" path-from-xml="tacl_a_00713_f002.tif" target="_blank" rel="nofollow" aria-label="Download slide for Figure 2: ">Download slide</a></div></div><div class="graphic-bottom"><div class="label fig-label">Figure 2: </div><div class="caption fig-caption"><p>LLM self-correction frameworks, categorized by information used for generating feedback and whether they use best-possible initial responses (§<a href="#sec4" data-scrollto="sec4" class="sectionLink xref-sec js-sec-jumplink">3.2</a>). This figure illustrates representative architectures.</p></div></div><a class="close-reveal-modal" href="javascript:;" aria-label="Close modal"><i class="icon-general-close"> </i><span class="screenreader-text">Close modal</span></a></div>
                </div>
                <div id="5111385-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111381">

                    <a id = "5111385" scrollto-destination="5111385"></a><div data-id="F3" class="fig fig-section" reveal-group-id="sec1"><span class="hidden" id="viewTranscriptId_"></span><div class="graphic-wrap"><a class="fig-link" href="/view-large/figure/5111385/tacl_a_00713_f003.tif" target="_blank" rel="nofollow"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f003.png?Expires=1766635869&amp;Signature=icXlsv0z~BtL-KVxS2H-BRn~2WxkLTrkeqJCZRMBj7o6WJHZQ48wNQuPwCyMDXfsoULNSmgFCok38Z75hOLtkByT55xwCxt-r6MstGenxIw8NhkUs83UUvn822eQVF8x1cr3REljI-5wj7Ub~iyVjM6Z0-T0nU1~5q3HVz5ubsn8lc2OXrg4PONYAZM4ti5Xdn87RyDQxHZSTukbjPCEzjbxjAU280EHx~hnPcHEav~j9zjOlpbfs1t1lywIHo6nO1qpQL84l1AMJUWJJP5bzQtaKmhK~Zlpe8flAkyLzOn37d4ubY~DE3TrIZaFORVofWlhWBJHguS9XatFEESDLQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f003.png?Expires=1766635869&amp;Signature=icXlsv0z~BtL-KVxS2H-BRn~2WxkLTrkeqJCZRMBj7o6WJHZQ48wNQuPwCyMDXfsoULNSmgFCok38Z75hOLtkByT55xwCxt-r6MstGenxIw8NhkUs83UUvn822eQVF8x1cr3REljI-5wj7Ub~iyVjM6Z0-T0nU1~5q3HVz5ubsn8lc2OXrg4PONYAZM4ti5Xdn87RyDQxHZSTukbjPCEzjbxjAU280EHx~hnPcHEav~j9zjOlpbfs1t1lywIHo6nO1qpQL84l1AMJUWJJP5bzQtaKmhK~Zlpe8flAkyLzOn37d4ubY~DE3TrIZaFORVofWlhWBJHguS9XatFEESDLQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Taxonomy of LLM self-correction, categorized by information used for generating feedback and whether they use best-possible initial responses (fair or unfair). Refer to Section 3.2 for the definitions." path-from-xml="tacl_a_00713_f003.tif" /></a><div class="fig-orig original-slide"><a section="5111385" class="fig-view-orig at-figureViewLarge" href="/view-large/figure/5111385/tacl_a_00713_f003.tif" path-from-xml="tacl_a_00713_f003.tif" target="_blank" rel="nofollow" aria-label="View large Figure 3: ">View large</a><a section="5111385" href="//mitp.silverchair-cdn.com/DownloadFile/DownloadImage.aspx?image=https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/tacl_a_00713_f003.png?Expires=1766635869&Signature=hPyG5EkHIVUaZuEzfdD3jpjfKSTkF9KckJwTLwVtSgOnsLeQcT-nAGFegn7PVgLJ49tH6VP4rrCKFjamHP5IjP3SAeeW4hIO~rSg~TwH4KAvtyRHCOU~8K0phBeR9cIk2GqX5u3TlrjKN2x0QSpnHGjSIQHWXRIlDBPS1REeGRW7euu1iZfcK07RbGv9dKWm5EKz5rIWsp31ahTpTJh7nioYdOMzFw45jjw34~gUFdXP-wyBY7poKVMwWhhRtGNl2pjuOEa9FdJrLYNpvID6FJ2mDGIH1Hr2hde4ah3uwE5LdeVmP5QIyMS5oAhLp7lsYErnAKs6cWI4WbywjPgF8A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=5111385&ar=125177&xsltPath=~/UI/app/XSLT&imagename=&siteId=1000067" class="download-slide stats-download-slide js-download-file-gtm-datalayer-event" data-filetype="ppt" path-from-xml="tacl_a_00713_f003.tif" target="_blank" rel="nofollow" aria-label="Download slide for Figure 3: ">Download slide</a></div></div><div class="graphic-bottom"><div class="label fig-label">Figure 3: </div><div class="caption fig-caption"><p>Taxonomy of LLM self-correction, categorized by information used for generating feedback and whether they use best-possible initial responses (fair or unfair). Refer to <a href="#sec4" data-scrollto="sec4" class="sectionLink xref-sec js-sec-jumplink">Section 3.2</a> for the definitions.</p></div></div></div><div id="F3" content-id="F3" class="fig fig-modal reveal-modal" data-reveal="data-reveal"><div class="graphic-wrap"><a class="fig-link" href="/view-large/figure/5111385/tacl_a_00713_f003.tif" target="_blank" rel="nofollow"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f003.png?Expires=1766635869&amp;Signature=icXlsv0z~BtL-KVxS2H-BRn~2WxkLTrkeqJCZRMBj7o6WJHZQ48wNQuPwCyMDXfsoULNSmgFCok38Z75hOLtkByT55xwCxt-r6MstGenxIw8NhkUs83UUvn822eQVF8x1cr3REljI-5wj7Ub~iyVjM6Z0-T0nU1~5q3HVz5ubsn8lc2OXrg4PONYAZM4ti5Xdn87RyDQxHZSTukbjPCEzjbxjAU280EHx~hnPcHEav~j9zjOlpbfs1t1lywIHo6nO1qpQL84l1AMJUWJJP5bzQtaKmhK~Zlpe8flAkyLzOn37d4ubY~DE3TrIZaFORVofWlhWBJHguS9XatFEESDLQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_f003.png?Expires=1766635869&amp;Signature=icXlsv0z~BtL-KVxS2H-BRn~2WxkLTrkeqJCZRMBj7o6WJHZQ48wNQuPwCyMDXfsoULNSmgFCok38Z75hOLtkByT55xwCxt-r6MstGenxIw8NhkUs83UUvn822eQVF8x1cr3REljI-5wj7Ub~iyVjM6Z0-T0nU1~5q3HVz5ubsn8lc2OXrg4PONYAZM4ti5Xdn87RyDQxHZSTukbjPCEzjbxjAU280EHx~hnPcHEav~j9zjOlpbfs1t1lywIHo6nO1qpQL84l1AMJUWJJP5bzQtaKmhK~Zlpe8flAkyLzOn37d4ubY~DE3TrIZaFORVofWlhWBJHguS9XatFEESDLQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Taxonomy of LLM self-correction, categorized by information used for generating feedback and whether they use best-possible initial responses (fair or unfair). Refer to Section 3.2 for the definitions." path-from-xml="tacl_a_00713_f003.tif" /></a><div class="fig-orig original-slide"><a section="5111385" class="fig-view-orig at-figureViewLarge" href="/view-large/figure/5111385/tacl_a_00713_f003.tif" path-from-xml="tacl_a_00713_f003.tif" target="_blank" rel="nofollow" aria-label="View large Figure 3: ">View large</a><a section="5111385" href="//mitp.silverchair-cdn.com/DownloadFile/DownloadImage.aspx?image=https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/tacl_a_00713_f003.png?Expires=1766635869&Signature=hPyG5EkHIVUaZuEzfdD3jpjfKSTkF9KckJwTLwVtSgOnsLeQcT-nAGFegn7PVgLJ49tH6VP4rrCKFjamHP5IjP3SAeeW4hIO~rSg~TwH4KAvtyRHCOU~8K0phBeR9cIk2GqX5u3TlrjKN2x0QSpnHGjSIQHWXRIlDBPS1REeGRW7euu1iZfcK07RbGv9dKWm5EKz5rIWsp31ahTpTJh7nioYdOMzFw45jjw34~gUFdXP-wyBY7poKVMwWhhRtGNl2pjuOEa9FdJrLYNpvID6FJ2mDGIH1Hr2hde4ah3uwE5LdeVmP5QIyMS5oAhLp7lsYErnAKs6cWI4WbywjPgF8A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=5111385&ar=125177&xsltPath=~/UI/app/XSLT&imagename=&siteId=1000067" class="download-slide stats-download-slide js-download-file-gtm-datalayer-event" data-filetype="ppt" path-from-xml="tacl_a_00713_f003.tif" target="_blank" rel="nofollow" aria-label="Download slide for Figure 3: ">Download slide</a></div></div><div class="graphic-bottom"><div class="label fig-label">Figure 3: </div><div class="caption fig-caption"><p>Taxonomy of LLM self-correction, categorized by information used for generating feedback and whether they use best-possible initial responses (fair or unfair). Refer to <a href="#sec4" data-scrollto="sec4" class="sectionLink xref-sec js-sec-jumplink">Section 3.2</a> for the definitions.</p></div></div><a class="close-reveal-modal" href="javascript:;" aria-label="Close modal"><i class="icon-general-close"> </i><span class="screenreader-text">Close modal</span></a></div>
                </div>
                </div>
                <h3 scrollto-destination="5111386"  id="5111386" data-section-title="2.1 Frameworks" class="section-title ">2.1 Frameworks</h3>
            <div  class="">
                <div id="5111387-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111386">

                    <p>Prior studies propose self-correction frameworks with various different architectures.</p>
                </div>
                </div>
                <h4 scrollto-destination="5111388"  id="5111388" data-section-title="Explicit Feedback vs. Direct Refinement." class="section-title ">Explicit Feedback vs. Direct Refinement.</h4>
            <div  class="">
                <div id="5111389-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111388">

                    <p>Self-correction often consists of three stages including <em>feedback generation</em> (Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>; Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>): <ul class="bullet"><li><p><strong>Initial Response Generation</strong> is a stage of generating initial responses from an LLM.</p></li><li><p><strong>Feedback</strong> model generates feedback given the original input and initial response. This stage may use external tools or knowledge.</p></li><li><p><strong>Refinement</strong> model generates a refined response, given the input, initial response, and feedback.</p></li></ul></p>
                </div>
                <div id="5111390-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111388">

                    <p><em>Direct refinement</em> is another approach that refines responses without generating feedback explicitly (Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>; Bai et al., <a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>; Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>; Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>).</p>
                </div>
                </div>
                <h4 scrollto-destination="5111391"  id="5111391" data-section-title="Post-hoc vs. Generation-time." class="section-title ">Post-hoc vs. Generation-time.</h4>
            <div  class="">
                <div id="5111392-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111391">

                    <p><em>Post-hoc correction</em> refines responses after they are generated (Pan et al., <a href="javascript:;" data-modal-source-id="bib72" class="link link-ref xref-bibr">2024</a>). <em>Generation-time correction</em> or step-level correction (Paul et al., <a href="javascript:;" data-modal-source-id="bib74" class="link link-ref xref-bibr">2024</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>) improves step-by-step reasoning by providing feedback on intermediate reasoning steps. Post-hoc correction is more flexible and applicable to broader tasks, although generation-time correction is popular for reasoning tasks (Pan et al., <a href="javascript:;" data-modal-source-id="bib72" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h4 scrollto-destination="5111393"  id="5111393" data-section-title="Same-model vs. Cross-model." class="section-title ">Same-model vs. Cross-model.</h4>
            <div  class="">
                <div id="5111394-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111393">

                    <p><em>Cross-model correction</em> generates feedback or refines the responses using models different from the model that generates initial responses. Cross-model correction has been mostly studied in the settings of correcting mistakes of large proprietary LLMs using small fine-tuned models (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>; Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>; Paul et al., <a href="javascript:;" data-modal-source-id="bib74" class="link link-ref xref-bibr">2024</a>) or multi-agent debate of multiple models with similar capabilities (Liang et al., <a href="javascript:;" data-modal-source-id="bib54" class="link link-ref xref-bibr">2023</a>; Li et al., <a href="javascript:;" data-modal-source-id="bib52" class="link link-ref xref-bibr">2023</a>; Cohen et al., <a href="javascript:;" data-modal-source-id="bib20" class="link link-ref xref-bibr">2023</a>; Du et al., <a href="javascript:;" data-modal-source-id="bib23" class="link link-ref xref-bibr">2023</a>; Zhang et al., <a href="javascript:;" data-modal-source-id="bib116" class="link link-ref xref-bibr">2023a</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib12" class="link link-ref xref-bibr">2024b</a>; Chan et al., <a href="javascript:;" data-modal-source-id="bib7" class="link link-ref xref-bibr">2024</a>; Wang et al., <a href="javascript:;" data-modal-source-id="bib98" class="link link-ref xref-bibr">2024a</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111395"  id="5111395" data-section-title="2.2 Sources of Feedback" class="section-title ">2.2 Sources of Feedback</h3>
            <div  class="">
                </div>
                <h4 scrollto-destination="5111396"  id="5111396" data-section-title="Intrinsic (&#167;4)." class="section-title ">Intrinsic (§4).</h4>
            <div  class="">
                <div id="5111397-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111396">

                    <p>Intrinsic self-correction prompts LLMs to generate feedback on their own responses. Prompting strategies include simple zero-shot or few-shot prompts (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>), decomposing the responses (Dhuliawala et al., <a href="javascript:;" data-modal-source-id="bib22" class="link link-ref xref-bibr">2023</a>), and evaluating confidence (Varshney et al., <a href="javascript:;" data-modal-source-id="bib96" class="link link-ref xref-bibr">2023</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>; Wu et al., <a href="javascript:;" data-modal-source-id="bib103" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h4 scrollto-destination="5111398"  id="5111398" data-section-title="External Information (&#167;5.1)." class="section-title ">External Information (§5.1).</h4>
            <div  class="">
                <div id="5111399-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111398">

                    <p>Self-correction often relies on external information, including <strong>external tools</strong> such as code executors (Jiang et al., <a href="javascript:;" data-modal-source-id="bib43" class="link link-ref xref-bibr">2023a</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>; Stengel-Eskin et al., <a href="javascript:;" data-modal-source-id="bib90" class="link link-ref xref-bibr">2024</a>), symbolic reasoners (Pan et al., <a href="javascript:;" data-modal-source-id="bib71" class="link link-ref xref-bibr">2023</a>), proof assistant (First et al., <a href="javascript:;" data-modal-source-id="bib27" class="link link-ref xref-bibr">2023</a>), or task-specific metrics (Xu et al., <a href="javascript:;" data-modal-source-id="bib105" class="link link-ref xref-bibr">2023</a>), <strong>external knowledge</strong> from search engines (Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>; Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Zhao et al., <a href="javascript:;" data-modal-source-id="bib121" class="link link-ref xref-bibr">2023</a>), Wikipedia (Yu et al., <a href="javascript:;" data-modal-source-id="bib114" class="link link-ref xref-bibr">2023</a>; Zhao et al., <a href="javascript:;" data-modal-source-id="bib121" class="link link-ref xref-bibr">2023</a>), or other corpora (Peng et al., <a href="javascript:;" data-modal-source-id="bib75" class="link link-ref xref-bibr">2023</a>; Zhao et al., <a href="javascript:;" data-modal-source-id="bib121" class="link link-ref xref-bibr">2023</a>), <strong>oracle information</strong> such as ground-truth answers (Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>; Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>), human feedback (Chen et al., <a href="javascript:;" data-modal-source-id="bib9" class="link link-ref xref-bibr">2024a</a>), or stronger models (Zhang et al., <a href="javascript:;" data-modal-source-id="bib120" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h4 scrollto-destination="5111400"  id="5111400" data-section-title="Fine-tuning (&#167;5.2)." class="section-title ">Fine-tuning (§5.2).</h4>
            <div  class="">
                <div id="5111401-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111400">

                    <p>Models fine-tuned for self-correction are another source of feedback, which are trained via supervised fine-tuning (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>; Ye et al., <a href="javascript:;" data-modal-source-id="bib112" class="link link-ref xref-bibr">2023</a>; First et al., <a href="javascript:;" data-modal-source-id="bib27" class="link link-ref xref-bibr">2023</a>; Paul et al., <a href="javascript:;" data-modal-source-id="bib74" class="link link-ref xref-bibr">2024</a>; Han et al., <a href="javascript:;" data-modal-source-id="bib35" class="link link-ref xref-bibr">2024</a>) or reinforcement learning (Le et al., <a href="javascript:;" data-modal-source-id="bib49" class="link link-ref xref-bibr">2022</a>; Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111402"  id="5111402" data-section-title="2.3 Tasks" class="section-title ">2.3 Tasks</h3>
            <div  class="">
                <div id="5111403-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111402">

                    <p>Self-correction has been studied in various tasks, including <strong>Reasoning:</strong> arithmetic reasoning (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Nathani et al., <a href="javascript:;" data-modal-source-id="bib67" class="link link-ref xref-bibr">2023</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>), code generation (Jiang et al., <a href="javascript:;" data-modal-source-id="bib43" class="link link-ref xref-bibr">2023a</a>; Charalambous et al., <a href="javascript:;" data-modal-source-id="bib8" class="link link-ref xref-bibr">2023</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>; Olausson et al., <a href="javascript:;" data-modal-source-id="bib70" class="link link-ref xref-bibr">2024</a>), proof generation (First et al., <a href="javascript:;" data-modal-source-id="bib27" class="link link-ref xref-bibr">2023</a>), logical reasoning (Pan et al., <a href="javascript:;" data-modal-source-id="bib71" class="link link-ref xref-bibr">2023</a>); <strong>Knowledge:</strong> closed-book QA (Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>; Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>); <strong>Context-based Generation:</strong> dialogue generation (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Peng et al., <a href="javascript:;" data-modal-source-id="bib75" class="link link-ref xref-bibr">2023</a>), text summarization (Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>); <strong>Open-ended Generation:</strong> conditional text generation (Ye et al., <a href="javascript:;" data-modal-source-id="bib112" class="link link-ref xref-bibr">2023</a>; Schick et al., <a href="javascript:;" data-modal-source-id="bib83" class="link link-ref xref-bibr">2023</a>), story generation (Yang et al., <a href="javascript:;" data-modal-source-id="bib108" class="link link-ref xref-bibr">2022b</a>), detoxification (Schick et al., <a href="javascript:;" data-modal-source-id="bib82" class="link link-ref xref-bibr">2021</a>; Bai et al., <a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Phute et al., <a href="javascript:;" data-modal-source-id="bib76" class="link link-ref xref-bibr">2024</a>); <strong>Others:</strong> machine translation (Chen et al., <a href="javascript:;" data-modal-source-id="bib13" class="link link-ref xref-bibr">2023b</a>; Raunak et al., <a href="javascript:;" data-modal-source-id="bib79" class="link link-ref xref-bibr">2023</a>; Ki and Carpuat, <a href="javascript:;" data-modal-source-id="bib47" class="link link-ref xref-bibr">2024</a>), information retrieval (Gero et al., <a href="javascript:;" data-modal-source-id="bib31" class="link link-ref xref-bibr">2023</a>), vision language tasks (Yin et al., <a href="javascript:;" data-modal-source-id="bib113" class="link link-ref xref-bibr">2023</a>; Ge et al., <a href="javascript:;" data-modal-source-id="bib30" class="link link-ref xref-bibr">2023</a>; Zhou et al., <a href="javascript:;" data-modal-source-id="bib122" class="link link-ref xref-bibr">2024</a>; Lee et al., <a href="javascript:;" data-modal-source-id="bib50" class="link link-ref xref-bibr">2024</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib40" class="link link-ref xref-bibr">2024b</a>; Liu et al., <a href="javascript:;" data-modal-source-id="bib57" class="link link-ref xref-bibr">2024</a>), and prompt optimization (Pryzant et al., <a href="javascript:;" data-modal-source-id="bib77" class="link link-ref xref-bibr">2023</a>; Mehrabi et al., <a href="javascript:;" data-modal-source-id="bib61" class="link link-ref xref-bibr">2023</a>; Yang et al., <a href="javascript:;" data-modal-source-id="bib106" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111404"  id="5111404" data-section-title="2.4 Differences from Related Approaches" class="section-title ">2.4 Differences from Related Approaches</h3>
            <div  class="">
                <div id="5111405-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111404">

                    <p>In this work, we define self-consistency (Wang et al., <a href="javascript:;" data-modal-source-id="bib99" class="link link-ref xref-bibr">2023</a>) or generate-and-rank (Shen et al., <a href="javascript:;" data-modal-source-id="bib86" class="link link-ref xref-bibr">2021</a>; Weng et al., <a href="javascript:;" data-modal-source-id="bib102" class="link link-ref xref-bibr">2023</a>) to be different from self-correction because these approaches do not refine responses and assume that LLMs generate correct answers with a reasonable probability. We discuss these methods in <a href="#sec9" data-scrollto="sec9" class="sectionLink xref-sec js-sec-jumplink">Section 6</a> as strong baselines that should be compared with self-correction.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111406" data-legacyid="sec2" id="5111406" data-section-title="3 Research Questions" class="section-title jumplink-heading">3 Research Questions</h2>
            <div  class="">
                <div id="5111407-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111406">

                    <p>We find that prior studies often do not define their research questions in detail and fail to use appropriate self-correction frameworks in their experiments. We propose a new approach to classify research questions and frameworks in self-correction.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111408" data-legacyid="sec3" id="5111408" data-section-title="3.1 RQs in Self-Correction Research" class="section-title ">3.1 RQs in Self-Correction Research</h3>
            <div  class="">
                <div id="5111409-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111408">

                    <p>Prior studies often simply state their research questions as <em>whether LLMs can self-correct their mistakes</em> (e.g., Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>; Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>). However, we claim that <span class="underline">research questions in self-correction research should be defined in more detail</span>. We identify the following research questions implicitly targeted in prior studies, as in <a href="javascript:;" reveal-id="T2" data-open="T2" class="link link-reveal link-table xref-fig">Table 2</a>. <ul class="bullet"><li><p>[RQ1] Can LLMs self-correct their best-possible initial responses <em>based solely on the inherent capabilities?</em> (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>)</p></li><li><p>[RQ2] Can LLMs self-correct their best-possible initial responses <em>assisted by external information?</em> (§<a href="#sec6" data-scrollto="sec6" class="sectionLink xref-sec js-sec-jumplink">5</a>)</p></li><li><p>[RQ3] Are the final outputs from self-correction <em>better than other methods?</em> (§<a href="#sec9" data-scrollto="sec9" class="sectionLink xref-sec js-sec-jumplink">6</a>)</p></li></ul></p>
                </div>
                <div id="5111410-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111408">

                    <a id = "5111410" scrollto-destination="5111410"></a><div content-id="T2 sec3" class="table-wrap table-wide"><div id="T2" data-id="T2" class="table-wrap-title "><span class="label title-label" id="label-69965">Table 2: </span><div class="caption caption-id-" id="caption-69965"><p>Research questions that prior studies implicitly target by claiming they are ✓ verified or ✗ refuted.</p></div> </div><div class="table-overflow"><table role="table" aria-labelledby="&#xA;                        label-69965" aria-describedby="&#xA;                        caption-69965"><thead name="thead" align=""><tr><th rowspan="2">RQ<span aria-hidden="true" style="display: none;">
            . </span></th><th>Self-Refine<span aria-hidden="true" style="display: none;">
            . </span></th><th>Huang et al.<span aria-hidden="true" style="display: none;">
            . </span></th><th>RCI<span aria-hidden="true" style="display: none;">
            . </span></th><th>RCI<span aria-hidden="true" style="display: none;">
            . </span></th><th>CRITIC<span aria-hidden="true" style="display: none;">
            . </span></th><th>CRITIC<span aria-hidden="true" style="display: none;">
            . </span></th><th>RARR<span aria-hidden="true" style="display: none;">
            . </span></th></tr><tr><th>(2023)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2024a)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2023, §3.1)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2023, §3.2)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2024, §4.2)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2024, §4.3)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2023)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>RQ1 </td><td>✓ </td><td>✗ (§3,5) </td><td>✓ </td><td>– </td><td>✗ </td><td>✗ </td><td>– </td></tr><tr><td>RQ2 </td><td>– </td><td>– </td><td>– </td><td>✓ </td><td>✓ </td><td>✓ </td><td>– </td></tr><tr><td>RQ3 </td><td>– </td><td>✗ (§4) </td><td>– </td><td>✓ </td><td>– </td><td>✓ </td><td>✓ </td></tr></tbody></table></div><div class="table-modal"><table><thead name="thead" align=""><tr><th rowspan="2">RQ<span aria-hidden="true" style="display: none;">
            . </span></th><th>Self-Refine<span aria-hidden="true" style="display: none;">
            . </span></th><th>Huang et al.<span aria-hidden="true" style="display: none;">
            . </span></th><th>RCI<span aria-hidden="true" style="display: none;">
            . </span></th><th>RCI<span aria-hidden="true" style="display: none;">
            . </span></th><th>CRITIC<span aria-hidden="true" style="display: none;">
            . </span></th><th>CRITIC<span aria-hidden="true" style="display: none;">
            . </span></th><th>RARR<span aria-hidden="true" style="display: none;">
            . </span></th></tr><tr><th>(2023)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2024a)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2023, §3.1)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2023, §3.2)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2024, §4.2)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2024, §4.3)<span aria-hidden="true" style="display: none;">
            . </span></th><th>(2023)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>RQ1 </td><td>✓ </td><td>✗ (§3,5) </td><td>✓ </td><td>– </td><td>✗ </td><td>✗ </td><td>– </td></tr><tr><td>RQ2 </td><td>– </td><td>– </td><td>– </td><td>✓ </td><td>✓ </td><td>✓ </td><td>– </td></tr><tr><td>RQ3 </td><td>– </td><td>✗ (§4) </td><td>– </td><td>✓ </td><td>– </td><td>✓ </td><td>✓ </td></tr></tbody></table></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111410" target="_blank" rel="nofollow" aria-label="View large Table 2: ">
                  View Large</a></div></div>
                </div>
                <div id="5111411-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111408">

                    <p>We define the <em>best-possible initial responses</em> as <span class="underline">initial responses generated with best effort, using</span><span class="underline">information that self-correction modules can access</span>, such as external tools, knowledge, or fine-tuning.</p>
                </div>
                </div>
                <h4 scrollto-destination="5111412"  id="5111412" data-section-title="Requirements for Verifying RQs." class="section-title ">Requirements for Verifying RQs.</h4>
            <div  class="">
                <div id="5111413-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111412">

                    <p>Experiments for verifying these research questions need to satisfy different requirements, as shown in <a href="javascript:;" reveal-id="T3" data-open="T3" class="link link-reveal link-table xref-fig">Table 3</a>. <strong>External Information:</strong> RQ1 needs to be evaluated on frameworks that refine responses using the same model without additional information. RQ2 and RQ3 can be evaluated on frameworks that use external information. <strong>Initial Responses:</strong> RQ1 and RQ2 need to be evaluated on frameworks that use the <em>best-possible initial responses</em>. RQ3 is about the final performance, so it is not necessary to start from strong initial responses. <strong>Evaluation:</strong> RQ1 and RQ2 only require to show that self-correction improves performance from the initial responses. RQ3 requires comparison with strong baselines (§<a href="#sec9" data-scrollto="sec9" class="sectionLink xref-sec js-sec-jumplink">6</a>).</p>
                </div>
                <div id="5111414-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111412">

                    <a id = "5111414" scrollto-destination="5111414"></a><div content-id="T3 " class="table-wrap table-wide"><div id="T3" data-id="T3" class="table-wrap-title "><span class="label title-label" id="label-69965">Table 3: </span><div class="caption caption-id-" id="caption-69965"><p>Requirements for experiments to verify each research question in <a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">Section 3.1</a>.</p></div> </div><div class="table-overflow"><table role="table" aria-labelledby="&#xA;                        label-69965" aria-describedby="&#xA;                        caption-69965"><thead name="thead" align=""><tr><th rowspan="2">RQ<span aria-hidden="true" style="display: none;">
            . </span></th><th colspan="3">Requirements for Frameworks<span aria-hidden="true" style="display: none;">
            . </span></th><th colspan="2">Required Experiments<span aria-hidden="true" style="display: none;">
            . </span></th></tr><tr><th>Information Symmetricity<span aria-hidden="true" style="display: none;">
            . </span></th><th>Best-possible Initial Responses<span aria-hidden="true" style="display: none;">
            . </span></th><th>Realistic<span aria-hidden="true" style="display: none;">
            . </span></th><th>Comparison to Initial Responses<span aria-hidden="true" style="display: none;">
            . </span></th><th>Comparison to Strong Baselines<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>RQ1 </td><td>✓ </td><td>✓ </td><td>✓ </td><td>✓ </td><td>– </td></tr><tr><td>RQ2 </td><td>– </td><td>✓ </td><td>✓ </td><td>✓ </td><td>– </td></tr><tr><td>RQ3 </td><td>– </td><td>– </td><td>✓ </td><td>– </td><td>✓ </td></tr></tbody></table></div><div class="table-modal"><table><thead name="thead" align=""><tr><th rowspan="2">RQ<span aria-hidden="true" style="display: none;">
            . </span></th><th colspan="3">Requirements for Frameworks<span aria-hidden="true" style="display: none;">
            . </span></th><th colspan="2">Required Experiments<span aria-hidden="true" style="display: none;">
            . </span></th></tr><tr><th>Information Symmetricity<span aria-hidden="true" style="display: none;">
            . </span></th><th>Best-possible Initial Responses<span aria-hidden="true" style="display: none;">
            . </span></th><th>Realistic<span aria-hidden="true" style="display: none;">
            . </span></th><th>Comparison to Initial Responses<span aria-hidden="true" style="display: none;">
            . </span></th><th>Comparison to Strong Baselines<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>RQ1 </td><td>✓ </td><td>✓ </td><td>✓ </td><td>✓ </td><td>– </td></tr><tr><td>RQ2 </td><td>– </td><td>✓ </td><td>✓ </td><td>✓ </td><td>– </td></tr><tr><td>RQ3 </td><td>– </td><td>– </td><td>✓ </td><td>– </td><td>✓ </td></tr></tbody></table></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111414" target="_blank" rel="nofollow" aria-label="View large Table 3: ">
                  View Large</a></div></div>
                </div>
                </div>
                <h4 scrollto-destination="5111415"  id="5111415" data-section-title="Confusion in Prior Work." class="section-title ">Confusion in Prior Work.</h4>
            <div  class="">
                <div id="5111416-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111415">

                    <p>Some prior studies implicitly target different research questions in a single work without clearly distinguishing them. As in <a href="javascript:;" reveal-id="T2" data-open="T2" class="link link-reveal link-table xref-fig">Table 2</a>, Kim et al. (<a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>) target RQ1 for arithmetic reasoning by comparing self-corrected responses only with initial responses, but they target RQ3 for MiniWoB++ by comparing self-correction with baseline methods. Similarly, Gou et al. (<a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) target RQ2 for arithmetic reasoning but target RQ3 for detoxification.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111417" data-legacyid="sec4" id="5111417" data-section-title="3.2 Frameworks for Verifying RQs" class="section-title ">3.2 Frameworks for Verifying RQs</h3>
            <div  class="">
                <div id="5111418-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111417">

                    <p>Prior work often categorizes self-correction frameworks based on approaches for generating feedback (§<a href="#sec1" data-scrollto="sec1" class="sectionLink xref-sec js-sec-jumplink">2</a>). However, we point out that we also need to categorize them by <span class="underline">the quality of initial responses</span> because the frameworks we need to use for verifying different research questions vary by whether they use the best-possible initial responses (§<a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">3.1</a>).</p>
                </div>
                <div id="5111419-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111417">

                    <p>We propose categories of (same-model) self-correction that correspond to different research questions (§<a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">3.1</a>), as shown in <a href="javascript:;" reveal-id="F2" data-open="F2" class="link link-reveal link-table xref-fig">Figure 2</a>. Specifically, we propose to categorize the self-correction frameworks as follows. <ul class="bullet"><li><p>Realistic: Can be used in real-world applications.</p><p><ul class="list-simple"><li><span class="label title-label">–</span><p>Fair: Using best-possible initial responses</p></li><li><span class="label title-label">–</span><p>Unfair: Using sub-optimal initial responses</p></li></ul></p></li><li><p>Unrealistic: Using information that is not accessible in real-world applications.</p></li></ul></p>
                </div>
                <div id="5111420-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111417">

                    <p>In this work, we focus on categorizing self-correction frameworks that do not involve multiple language models with different architectures. Cross-model correction uses different models for initial response generation and self-correction, so it is unsuitable for evaluating whether LLMs can improve their own initial responses [RQ1, RQ2]. However, it can be used to evaluate [RQ3] whether the final responses from self-correction are better than other methods.</p>
                </div>
                </div>
                <h4 scrollto-destination="5111421"  id="5111421" data-section-title="Realistic vs. Unrealistic." class="section-title ">Realistic vs. Unrealistic.</h4>
            <div  class="">
                <div id="5111422-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111421">

                    <p>Some prior studies propose unrealistic self-correction, which cannot be implemented in real-world applications, by using oracle information such as ground-truth answers (Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>; Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>). These methods cannot be used to verify any research questions.</p>
                </div>
                </div>
                <h4 scrollto-destination="5111423"  id="5111423" data-section-title="Fair vs. Unfair." class="section-title ">Fair vs. Unfair.</h4>
            <div  class="">
                <div id="5111424-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111423">

                    <p>Realistic frameworks can be categorized by whether they use the best-possible initial responses. <strong>Fair self-correction</strong> represents frameworks that refine the best-possible initial responses. (1) <em>Intrinsic self-correction</em> (Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>) uses the same model and information for initial response generation and self-correction. Intrinsic self-correction can be used to assess [RQ1] whether LLMs can self-correct based solely on their inherent capabilities. (2) <em>Fair-asymmetric self-correction</em> uses additional information for self-correction, but also uses information to improve initial response generation as much as possible. For example, self-correction with code interpreters (Chen et al., <a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) is not intrinsic but fair because we cannot easily use code interpreters to directly improve the initial response generation. Fair-asymmetric self-correction can be used to evaluate [RQ2] whether LLMs can self-correct the best-possible initial responses using external information. <strong>Unfair self-correction</strong> (or <em>unfair-asymmetric self-correction</em>) represents frameworks that are practical but do not use the best-possible initial responses. For example, methods that use search engines only for self-correction (Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Yu et al., <a href="javascript:;" data-modal-source-id="bib114" class="link link-ref xref-bibr">2023</a>) are unfair because they can use search engines to directly improve the initial response generation. Unfair self-correction can evaluate [RQ3] whether the final responses from self-correction outperform other methods but cannot evaluate [RQ2] whether self-correction can improve the best-possible initial responses.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111425" data-legacyid="sec5" id="5111425" data-section-title="4 Self-Correction with Prompting" class="section-title jumplink-heading">4 Self-Correction with Prompting</h2>
            <div  class="">
                <div id="5111426-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111425">

                    <div class="blockquote-wrap" id=""><blockquote><p>[RQ1] Can LLMs self-correct their best-possible initial responses <em>based solely on the inherent capabilities?</em></p></blockquote></div>
                </div>
                <div id="5111427-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111425">

                    <p>Several studies propose <em>intrinsic self-correction</em> methods, which self-correct responses from LLMs by prompting themselves to generate feedback and refine the responses. Bai et al. (<a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>) propose self-correcting harmful responses from LLMs by prompting themselves. Self-Refine (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) and RCI Prompting (Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>) iteratively prompt LLMs to self-correct their own responses in tasks such as arithmetic reasoning.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111428"  id="5111428" data-section-title="Negative Results." class="section-title ">Negative Results.</h3>
            <div  class="">
                <div id="5111429-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111428">

                    <p>However, recent studies report that intrinsic self-correction does not improve or even degrade the performance in tasks such as arithmetic reasoning, closed-book QA (Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>), code generation (Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Olausson et al., <a href="javascript:;" data-modal-source-id="bib70" class="link link-ref xref-bibr">2024</a>), plan generation (Valmeekam et al., <a href="javascript:;" data-modal-source-id="bib95" class="link link-ref xref-bibr">2023</a>), and graph coloring (Stechly et al., <a href="javascript:;" data-modal-source-id="bib89" class="link link-ref xref-bibr">2023</a>). Several studies claim that a bottleneck is in the feedback generation, and it is difficult to generate reliable feedback on their responses only by prompting themselves (Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>; Olausson et al., <a href="javascript:;" data-modal-source-id="bib70" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111430"  id="5111430" data-section-title="Unrealistic or Unfair Settings." class="section-title ">Unrealistic or Unfair Settings.</h3>
            <div  class="">
                <div id="5111431-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111430">

                    <p>The conflicting positive and negative results motivate us to analyze when LLMs can self-correct <em>only by prompting themselves</em>. Specifically, we assess whether prior studies satisfy the requirements to verify that [RQ1] LLMs can self-correct their responses based solely on their inherent capabilities. As in <a href="javascript:;" reveal-id="T4" data-open="T4" class="link link-reveal link-table xref-fig">Table 4</a>, we find that many studies use either oracle information in the self-correction processes (unrealistic frameworks) or weak prompts that can be easily improved for generating initial responses (unfair settings), which over-evaluate self-correction. Consequently, we conclude that <span class="underline">no major work shows successful self-correction of responses from LLMs using feedback generated by prompting themselves under fair settings in general tasks</span>. <strong>Oracle Information:</strong> RCI Prompting (Kim et al., <a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>) uses ground-truth answers and does not apply self-correction when the initial responses are correct, which unfairly ignores mistakes caused by updating correct responses incorrectly. Reflexion (Shinn et al., <a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>) generates feedback by using an exact match between the generated and ground-truth answers, which cannot be accessed in real-world applications. <strong>Weak Initial Responses:</strong> Detoxifying harmful responses is a popular task in self-correction research, but prior studies often study in situations where initial response generation is not instructed to generate harmless responses (Bai et al., <a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>; Wang et al., <a href="javascript:;" data-modal-source-id="bib100" class="link link-ref xref-bibr">2024b</a>). Although detecting harmful contents using LLMs is a reasonable research topic, this setting is not the self-correction from best-possible initial responses, since we can improve the initial response generation process by instructing not to generate harmful responses. As more obvious weak prompts, Self-Refine (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) uses instructions or few-shot examples that do not correctly correspond to the target task only for initial response generation (e.g., providing wrong target labels in few-shot examples), while using appropriate instructions for self-correction, as shown in <a href="javascript:;" reveal-id="T9" data-open="T9" class="link link-reveal link-table xref-fig">Tables 9</a> and <a href="javascript:;" reveal-id="T10" data-open="T10" class="link link-reveal link-table xref-fig">10</a>. These settings evaluate improvement from weak initial responses, which over-evaluate the improvement by self-correction.</p>
                </div>
                <div id="5111432-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111430">

                    <a id = "5111432" scrollto-destination="5111432"></a><div content-id="T4 " class="table-wrap table-wide"><div id="T4" data-id="T4" class="table-wrap-title "><span class="label title-label" id="label-69965">Table 4: </span><div class="caption caption-id-" id="caption-69965"><p>Unfair settings in prior studies of self-correction with prompting, over-evaluating self-correction.</p></div> </div><div class="table-overflow"><table role="table" aria-labelledby="&#xA;                        label-69965" aria-describedby="&#xA;                        caption-69965"><thead name="thead" align=""><tr><th>Paper<span aria-hidden="true" style="display: none;">
            . </span></th><th>Task<span aria-hidden="true" style="display: none;">
            . </span></th><th>Using Oracle Info for Feedback<span aria-hidden="true" style="display: none;">
            . </span></th><th>Weak Prompt for Initial Responses<span aria-hidden="true" style="display: none;">
            . </span></th><th>Comments<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>RCI (<a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>, §3.1) </td><td>Computer Tasks </td><td>✓ stop condition </td><td>– </td><td>Using ground-truth answers and do not update correct responses, which unfairly ignores false-positive correction </td></tr><tr><td>Reflexion (<a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>, §4.2) </td><td>HotpotQA (Context) </td><td>✓ feedback </td><td>– </td><td>Feedback is the exact match between the responses and ground-truth answers </td></tr><tr><td>CAI Revisions (<a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>) </td><td>Detoxification </td><td>– </td><td>✓ </td><td>Initial generation is not prompted to remove harmful outputs </td></tr><tr><td>Self-Refine (<a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) </td><td>Math, Coding, Dialogue </td><td>– </td><td>✓ </td><td>Unfairly weak or wrong instructions or few-shot demonstrations for initial response generation </td></tr></tbody></table></div><div class="table-modal"><table><thead name="thead" align=""><tr><th>Paper<span aria-hidden="true" style="display: none;">
            . </span></th><th>Task<span aria-hidden="true" style="display: none;">
            . </span></th><th>Using Oracle Info for Feedback<span aria-hidden="true" style="display: none;">
            . </span></th><th>Weak Prompt for Initial Responses<span aria-hidden="true" style="display: none;">
            . </span></th><th>Comments<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>RCI (<a href="javascript:;" data-modal-source-id="bib48" class="link link-ref xref-bibr">2023</a>, §3.1) </td><td>Computer Tasks </td><td>✓ stop condition </td><td>– </td><td>Using ground-truth answers and do not update correct responses, which unfairly ignores false-positive correction </td></tr><tr><td>Reflexion (<a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>, §4.2) </td><td>HotpotQA (Context) </td><td>✓ feedback </td><td>– </td><td>Feedback is the exact match between the responses and ground-truth answers </td></tr><tr><td>CAI Revisions (<a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>) </td><td>Detoxification </td><td>– </td><td>✓ </td><td>Initial generation is not prompted to remove harmful outputs </td></tr><tr><td>Self-Refine (<a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) </td><td>Math, Coding, Dialogue </td><td>– </td><td>✓ </td><td>Unfairly weak or wrong instructions or few-shot demonstrations for initial response generation </td></tr></tbody></table></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111432" target="_blank" rel="nofollow" aria-label="View large Table 4: ">
                  View Large</a></div></div>
                </div>
                </div>
                <h3 scrollto-destination="5111433"  id="5111433" data-section-title="Tasks in which Self-Correction is Exceptionally Effective." class="section-title ">Tasks in which Self-Correction is Exceptionally Effective.</h3>
            <div  class="">
                <div id="5111434-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111433">

                    <p>Although our analysis of prior studies shows that intrinsic self-correction is difficult in general, some tasks have properties that make feedback generation easy and enable intrinsic self-correction. For example, CoVe (Dhuliawala et al., <a href="javascript:;" data-modal-source-id="bib22" class="link link-ref xref-bibr">2023</a>) is an intrinsic self-correction method for tasks of generating multiple answers, such as <em>Name some politicians who were born in NY, New York.</em> Generated responses include multiple answers, but the feedback generation can be decomposed into easier sub-tasks of verifying each answer. Tasks with <strong>decomposable responses</strong> are one of the few groups of tasks for which verification is clearly easier than generation, which enables intrinsic self-correction. However, many real-world tasks do not satisfy this property.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111435" data-legacyid="sec6" id="5111435" data-section-title="5 Self-Correction with External Information" class="section-title jumplink-heading">5 Self-Correction with External Information</h2>
            <div  class="">
                <div id="5111436-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111435">

                    <div class="blockquote-wrap" id=""><blockquote><p>[RQ2] Can LLMs self-correct their best-possible initial responses <em>assisted by external information?</em></p></blockquote></div>
                </div>
                <div id="5111437-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111435">

                    <p>This section analyzes self-correction frameworks that make use of external tools, external knowledge, and fine-tuning.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111438" data-legacyid="sec7" id="5111438" data-section-title="5.1 Self-Correction with External Tools or Knowledge" class="section-title ">5.1 Self-Correction with External Tools or Knowledge</h3>
            <div  class="">
                <div id="5111439-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111438">

                    <p>Given the observation that feedback generation is a bottleneck of self-correction (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>), improving feedback using external tools or knowledge is a promising direction. External tools used for self-correction include code interpreters for code generation tasks (Chen et al., <a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) and symbolic reasoners for logical reasoning tasks (Pan et al., <a href="javascript:;" data-modal-source-id="bib71" class="link link-ref xref-bibr">2023</a>). A popular source of knowledge is search engines, which are often used with queries generated from initial responses to retrieve information for validating their correctness (Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>). These prior studies widely agree that self-correction can improve LLM responses when reliable external tools or knowledge suitable for improving feedback are available.</p>
                </div>
                </div>
                <h4 scrollto-destination="5111440"  id="5111440" data-section-title="Unfair Self-correction with External Information." class="section-title ">Unfair Self-correction with External Information.</h4>
            <div  class="">
                <div id="5111441-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111440">

                    <p>Although using external tools or knowledge is known to be effective in self-correction, we raise caution that the way of using external tools or knowledge influences the research questions we can verify (§<a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">3.1</a>). As shown in <a href="javascript:;" reveal-id="T5" data-open="T5" class="link link-reveal link-table xref-fig">Table 5</a>, some prior studies (Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>; Yu et al., <a href="javascript:;" data-modal-source-id="bib114" class="link link-ref xref-bibr">2023</a>; Zhao et al., <a href="javascript:;" data-modal-source-id="bib121" class="link link-ref xref-bibr">2023</a>) use external knowledge only for self-correction, while they can also directly use external knowledge to improve the initial response generation process. For example, RARR (Gao et al., <a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>) uses external knowledge to detect mistakes in initial responses, while it does not use any external knowledge when generating initial responses. <span class="underline">These methods are reasonable when only focusing</span><span class="underline">on [RQ3] the performance of final responses, but</span><span class="underline">it is not fair to use them for evaluating [RQ2] whether</span><span class="underline">self-correction can improve from the best-possible</span><span class="underline">initial responses</span>. In contrast, using code interpreters for self-correction (Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>) can be regarded as using best-possible initial responses because there is no easy way to improve the initial response generation directly.</p>
                </div>
                <div id="5111442-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111440">

                    <a id = "5111442" scrollto-destination="5111442"></a><div content-id="T5 " class="table-wrap table-wide"><div id="T5" data-id="T5" class="table-wrap-title "><span class="label title-label" id="label-69965">Table 5: </span><div class="caption caption-id-" id="caption-69965"><p>Self-correction with external tools or knowledge (with in-context learning).</p></div> </div><div class="table-overflow"><table role="table" aria-labelledby="&#xA;                        label-69965" aria-describedby="&#xA;                        caption-69965"><thead name="thead" align=""><tr><th rowspan="2">Paper<span aria-hidden="true" style="display: none;">
            . </span></th><th rowspan="2">Main Task<span aria-hidden="true" style="display: none;">
            . </span></th><th colspan="2">External Tools or Knowledge<span aria-hidden="true" style="display: none;">
            . </span></th></tr><tr><th>For Initial Response Generation<span aria-hidden="true" style="display: none;">
            . </span></th><th>For Feedback Generation<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>Reflexion (<a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>, §4.1, 4.3) </td><td>Games, Coding </td><td>– </td><td>Game Envs, Code Interpreter </td></tr><tr><td>CRITIC (<a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) </td><td>GSM8k, SVAMP </td><td>– </td><td>Python interpreter </td></tr><tr><td>Self-Debug (<a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>) </td><td>Text-to-Code </td><td>– </td><td>Code Interpreter </td></tr><tr><td colspan="4"> </td></tr><tr><td>CRITIC (<a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) </td><td>HotpotQA </td><td>Web Search </td><td>Web Search </td></tr><tr><td>FLARE (<a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>) </td><td>2WikiMultihopQA, StrategyQA, ASQA </td><td>Web Search </td><td>Web Search </td></tr><tr><td colspan="4"> </td></tr><tr><td>RARR (<a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>) </td><td>NQ, SQA, QReCC </td><td>– </td><td>Web Search </td></tr><tr><td>ReFeed (<a href="javascript:;" data-modal-source-id="bib114" class="link link-ref xref-bibr">2023</a>) </td><td>NQ, TriviaQA, HotpotQA </td><td>– </td><td>Wikipedia </td></tr></tbody></table></div><div class="table-modal"><table><thead name="thead" align=""><tr><th rowspan="2">Paper<span aria-hidden="true" style="display: none;">
            . </span></th><th rowspan="2">Main Task<span aria-hidden="true" style="display: none;">
            . </span></th><th colspan="2">External Tools or Knowledge<span aria-hidden="true" style="display: none;">
            . </span></th></tr><tr><th>For Initial Response Generation<span aria-hidden="true" style="display: none;">
            . </span></th><th>For Feedback Generation<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td>Reflexion (<a href="javascript:;" data-modal-source-id="bib88" class="link link-ref xref-bibr">2023</a>, §4.1, 4.3) </td><td>Games, Coding </td><td>– </td><td>Game Envs, Code Interpreter </td></tr><tr><td>CRITIC (<a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) </td><td>GSM8k, SVAMP </td><td>– </td><td>Python interpreter </td></tr><tr><td>Self-Debug (<a href="javascript:;" data-modal-source-id="bib15" class="link link-ref xref-bibr">2024d</a>) </td><td>Text-to-Code </td><td>– </td><td>Code Interpreter </td></tr><tr><td colspan="4"> </td></tr><tr><td>CRITIC (<a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>) </td><td>HotpotQA </td><td>Web Search </td><td>Web Search </td></tr><tr><td>FLARE (<a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>) </td><td>2WikiMultihopQA, StrategyQA, ASQA </td><td>Web Search </td><td>Web Search </td></tr><tr><td colspan="4"> </td></tr><tr><td>RARR (<a href="javascript:;" data-modal-source-id="bib29" class="link link-ref xref-bibr">2023</a>) </td><td>NQ, SQA, QReCC </td><td>– </td><td>Web Search </td></tr><tr><td>ReFeed (<a href="javascript:;" data-modal-source-id="bib114" class="link link-ref xref-bibr">2023</a>) </td><td>NQ, TriviaQA, HotpotQA </td><td>– </td><td>Wikipedia </td></tr></tbody></table></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111442" target="_blank" rel="nofollow" aria-label="View large Table 5: ">
                  View Large</a></div></div>
                </div>
                </div>
                <h4 scrollto-destination="5111443"  id="5111443" data-section-title="Verifiable Tasks." class="section-title ">Verifiable Tasks.</h4>
            <div  class="">
                <div id="5111444-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111443">

                    <p>Some tasks have a property that allows the correctness of the responses to be verified easily, even without external information. For example, the constrained generation task evaluated in Self-Refine (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) is a task to generate a sentence that includes five specified words. We can easily evaluate the correctness by checking whether the five words are included in the generated sentence. Tree-of-thought (Yao et al., <a href="javascript:;" data-modal-source-id="bib109" class="link link-ref xref-bibr">2023</a>) is a generate-and-rank method for verifiable tasks,<sup><a href="javascript:;" reveal-id="fn1" data-open="fn1" class="link link-ref link-reveal xref-fn js-xref-fn split-view-modal"><sup>1</sup></a></sup> such as Game of 24, the task to obtain 24 using basic arithmetic operations (+,−,×,÷) and provided four integers. For Game of 24, we can easily verify the answer by checking whether the generated answer is 24. We consider self-correction to work well in these tasks because they are in the same situations as using strong external tools or the oracle information to generate feedback.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111445" data-legacyid="sec8" id="5111445" data-section-title="5.2 Self-Correction with Fine-tuning" class="section-title ">5.2 Self-Correction with Fine-tuning</h3>
            <div  class="">
                <div id="5111446-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111445">

                    <p>Prior work shows that fine-tuning LLMs for generating feedback or refining responses improves the self-correction capability. A common approach fine-tunes feedback models to generate reference feedback given initial responses and fine-tunes refinement models to generate reference answers given the initial responses and reference feedback (Ye et al., <a href="javascript:;" data-modal-source-id="bib112" class="link link-ref xref-bibr">2023</a>; Lee et al., <a href="javascript:;" data-modal-source-id="bib50" class="link link-ref xref-bibr">2024</a>; Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>). <strong>Frameworks:</strong> The first approach fine-tunes <em>the same model</em> to correct its own responses. In this approach, most methods fine-tune models for all stages: initial responses, feedback, and refinement (Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>; Ye et al., <a href="javascript:;" data-modal-source-id="bib112" class="link link-ref xref-bibr">2023</a>; Lee et al., <a href="javascript:;" data-modal-source-id="bib50" class="link link-ref xref-bibr">2024</a>). Another approach corrects responses from larger models using <em>smaller fine-tuned models</em>. This cross-model correction approach often instructs the larger models to refine their own responses using feedback from the smaller fine-tuned models (Yang et al., <a href="javascript:;" data-modal-source-id="bib108" class="link link-ref xref-bibr">2022b</a>; Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>; Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>; Paul et al., <a href="javascript:;" data-modal-source-id="bib74" class="link link-ref xref-bibr">2024</a>), which can be viewed as using the small fine-tuned models as external tools. <strong>Training Strategies:</strong> A popular approach is supervised fine-tuning, which fine-tunes self-correction modules on human-annotated feedback (Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>), feedback from stronger models (Ye et al., <a href="javascript:;" data-modal-source-id="bib112" class="link link-ref xref-bibr">2023</a>), or synthetic negative responses (Paul et al., <a href="javascript:;" data-modal-source-id="bib74" class="link link-ref xref-bibr">2024</a>). As other approaches, to avoid the cost of collecting human feedback, self-corrective learning (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>) selects model-generated feedback that successfully refines responses as training data, and RL4L (Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>) uses reinforcement-learning. <strong>External Tools:</strong> Some works fine-tune models to refine responses given feedback from external tools. Self-Edit (Zhang et al., <a href="javascript:;" data-modal-source-id="bib117" class="link link-ref xref-bibr">2023b</a>) uses the results on test cases evaluated by code executors for code generation, and Baldur (First et al., <a href="javascript:;" data-modal-source-id="bib27" class="link link-ref xref-bibr">2023</a>) uses proof assistants for improving proof generation.</p>
                </div>
                </div>
                <h4 scrollto-destination="5111447"  id="5111447" data-section-title="Large Training Data for SFT of Feedback." class="section-title ">Large Training Data for SFT of Feedback.</h4>
            <div  class="">
                <div id="5111448-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111447">

                    <p>As shown in <a href="javascript:;" reveal-id="T6" data-open="T6" class="link link-reveal link-table xref-fig">Table 6</a>, many methods with supervised fine-tuning for feedback generation rely on training data with more than 100K instances. These studies often use feedback generated by stronger models to simulate human annotation, but this approach requires large-scale human annotations to be implemented on state-of-the-art models. We expect future research to explore approaches that do not require large-scale human annotations (§<a href="#sec14" data-scrollto="sec14" class="sectionLink xref-sec js-sec-jumplink">11</a>).</p>
                </div>
                <div id="5111449-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111447">

                    <a id = "5111449" scrollto-destination="5111449"></a><div content-id="T6 " class="table-wrap table-wide"><div id="T6" data-id="T6" class="table-wrap-title "><span class="label title-label" id="label-69965">Table 6: </span><div class="caption caption-id-" id="caption-69965"><p>Self-correction with supervised fine-tuning. Most methods require large training datasets. “–” represents no fine-tuning.</p></div> </div><div class="fig-graphic"><a class="jumplink-placeholder" data-sectionId="5111449" id="tacl_a_00713_i003.tif"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i003.png?Expires=1766635869&amp;Signature=lQs9ZpIJGBJiXBcV8p6seajZ3BNqbY38gaTh80Ik4YAHzMl446ftmJY652TWn0KkQ3uiWzoo-LFrBE2ANMAlNE67V6el9qRyuD-~Y1N0z--9GJaFFslEhEE-H9GTOYwqRg-FvOgnHgv4jar3oK61LAK2u0B9qP5yVSbxKZG75VzQyq9cJm0HezXj~hBfUwBxB1xDoSB~yXR75tTRU2lO73xXPS~~qXz2TcSuKpmA5vW6~kKyonef~4KsAuq5S-qWzH3VPpXoPIYyPqvlJcl48XW~ylc0MJsBDQ2N7CfU6VTj53o57QgAwWhd2ULBbuB3~YHOJhTADwav5UGOnHaawg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i003.png?Expires=1766635869&amp;Signature=lQs9ZpIJGBJiXBcV8p6seajZ3BNqbY38gaTh80Ik4YAHzMl446ftmJY652TWn0KkQ3uiWzoo-LFrBE2ANMAlNE67V6el9qRyuD-~Y1N0z--9GJaFFslEhEE-H9GTOYwqRg-FvOgnHgv4jar3oK61LAK2u0B9qP5yVSbxKZG75VzQyq9cJm0HezXj~hBfUwBxB1xDoSB~yXR75tTRU2lO73xXPS~~qXz2TcSuKpmA5vW6~kKyonef~4KsAuq5S-qWzH3VPpXoPIYyPqvlJcl48XW~ylc0MJsBDQ2N7CfU6VTj53o57QgAwWhd2ULBbuB3~YHOJhTADwav5UGOnHaawg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Self-correction with supervised fine-tuning. Most methods require large training datasets. “–” represents no fine-tuning." path-from-xml="tacl_a_00713_i003.tif" /></a></div><div class="fig-orig original-slide"><a section="5111449" class="fig-view-orig" href="/view-large/figure/5111449/tacl_a_00713_i003.tif" path-from-xml="tacl_a_00713_i003.tif" target="_blank">View large</a></div><div content-id="T6" class="table-modal"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i003.png?Expires=1766635869&amp;Signature=lQs9ZpIJGBJiXBcV8p6seajZ3BNqbY38gaTh80Ik4YAHzMl446ftmJY652TWn0KkQ3uiWzoo-LFrBE2ANMAlNE67V6el9qRyuD-~Y1N0z--9GJaFFslEhEE-H9GTOYwqRg-FvOgnHgv4jar3oK61LAK2u0B9qP5yVSbxKZG75VzQyq9cJm0HezXj~hBfUwBxB1xDoSB~yXR75tTRU2lO73xXPS~~qXz2TcSuKpmA5vW6~kKyonef~4KsAuq5S-qWzH3VPpXoPIYyPqvlJcl48XW~ylc0MJsBDQ2N7CfU6VTj53o57QgAwWhd2ULBbuB3~YHOJhTADwav5UGOnHaawg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i003.png?Expires=1766635869&amp;Signature=lQs9ZpIJGBJiXBcV8p6seajZ3BNqbY38gaTh80Ik4YAHzMl446ftmJY652TWn0KkQ3uiWzoo-LFrBE2ANMAlNE67V6el9qRyuD-~Y1N0z--9GJaFFslEhEE-H9GTOYwqRg-FvOgnHgv4jar3oK61LAK2u0B9qP5yVSbxKZG75VzQyq9cJm0HezXj~hBfUwBxB1xDoSB~yXR75tTRU2lO73xXPS~~qXz2TcSuKpmA5vW6~kKyonef~4KsAuq5S-qWzH3VPpXoPIYyPqvlJcl48XW~ylc0MJsBDQ2N7CfU6VTj53o57QgAwWhd2ULBbuB3~YHOJhTADwav5UGOnHaawg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Self-correction with supervised fine-tuning. Most methods require large training datasets. “–” represents no fine-tuning." path-from-xml="tacl_a_00713_i003.tif" /></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111449" target="_blank" rel="nofollow" aria-label="View large Table 6: ">
                  View Large</a></div></div>
                </div>
                </div>
                <h4 scrollto-destination="5111450"  id="5111450" data-section-title="Unfair Fine-tuning." class="section-title ">Unfair Fine-tuning.</h4>
            <div  class="">
                <div id="5111451-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111450">

                    <p>Some studies (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>) apply stronger fine-tuning for self-correction models than initial response generation models, which do not use best-possible initial responses in the available resources (§<a href="#sec4" data-scrollto="sec4" class="sectionLink xref-sec js-sec-jumplink">3.2</a>). This approach can be used to evaluate [RQ3] the performance of the final responses to compare with other methods but cannot be used to evaluate [RQ2] the improvement from best-possible initial responses.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111452" data-legacyid="sec9" id="5111452" data-section-title="6 Strong Baselines" class="section-title jumplink-heading">6 Strong Baselines</h2>
            <div  class="">
                <div id="5111453-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111452">

                    <div class="blockquote-wrap" id=""><blockquote><p>[RQ3] Are the final outputs from self-correction <em>better than other methods?</em></p></blockquote></div>
                </div>
                <div id="5111454-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111452">

                    <p>Self-correction involves multiple LLM calls for generating feedback and refinement. Therefore, to claim that [RQ3] the performance of the final outputs from self-correction frameworks is better than other approaches, it should be compared with sufficiently strong baselines, possibly relying on additional LLM calls or computational cost. Many self-correction studies do not compare their methods with strong baselines, although some studies pointed out this issue and compare self-correction with self-consistency (Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>) or pass@k in code generation (Zhang et al., <a href="javascript:;" data-modal-source-id="bib117" class="link link-ref xref-bibr">2023b</a>; Olausson et al., <a href="javascript:;" data-modal-source-id="bib70" class="link link-ref xref-bibr">2024</a>). We encourage future research to compare self-correction with strong baselines, including self-consistency and generate-and-rank, to further explore RQ3.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111455"  id="5111455" data-section-title="Self-Consistency." class="section-title ">Self-Consistency.</h3>
            <div  class="">
                <div id="5111456-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111455">

                    <p>(Wang et al., <a href="javascript:;" data-modal-source-id="bib99" class="link link-ref xref-bibr">2023</a>) is an approach that generates multiple responses for the same input and takes the majority vote of the final answers in reasoning tasks. The idea of selecting good responses using the consistency between multiple responses from the same model has also been extended to other tasks such as text generation (Manakul et al., <a href="javascript:;" data-modal-source-id="bib60" class="link link-ref xref-bibr">2023</a>; Elaraby et al., <a href="javascript:;" data-modal-source-id="bib25" class="link link-ref xref-bibr">2023</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib14" class="link link-ref xref-bibr">2024c</a>) and code generation (Shi et al., <a href="javascript:;" data-modal-source-id="bib87" class="link link-ref xref-bibr">2022</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111457"  id="5111457" data-section-title="Generate-and-Rank." class="section-title ">Generate-and-Rank.</h3>
            <div  class="">
                <div id="5111458-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111457">

                    <p>is an approach that generates multiple responses and selects the best response using verifiers. <strong>Post-hoc</strong> approach ranks responses using self-evaluation (Weng et al., <a href="javascript:;" data-modal-source-id="bib102" class="link link-ref xref-bibr">2023</a>; Zhang et al., <a href="javascript:;" data-modal-source-id="bib119" class="link link-ref xref-bibr">2023d</a>), confidence (Manakul et al., <a href="javascript:;" data-modal-source-id="bib60" class="link link-ref xref-bibr">2023</a>), fine-tuned verifiers (Cobbe et al., <a href="javascript:;" data-modal-source-id="bib19" class="link link-ref xref-bibr">2021</a>; Shen et al., <a href="javascript:;" data-modal-source-id="bib86" class="link link-ref xref-bibr">2021</a>; Lightman et al., <a href="javascript:;" data-modal-source-id="bib56" class="link link-ref xref-bibr">2024</a>), or verifiers with external tools (Shi et al., <a href="javascript:;" data-modal-source-id="bib87" class="link link-ref xref-bibr">2022</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib10" class="link link-ref xref-bibr">2023a</a>; Ni et al., <a href="javascript:;" data-modal-source-id="bib69" class="link link-ref xref-bibr">2023</a>). <strong>Feedback-guided decoding</strong> generates multiple responses and selects the best response for each reasoning step using generation probability (Hao et al., <a href="javascript:;" data-modal-source-id="bib36" class="link link-ref xref-bibr">2023</a>; Tyen et al., <a href="javascript:;" data-modal-source-id="bib93" class="link link-ref xref-bibr">2024</a>), prompted self-evaluation (Jung et al., <a href="javascript:;" data-modal-source-id="bib45" class="link link-ref xref-bibr">2022</a>; Creswell and Shanahan, <a href="javascript:;" data-modal-source-id="bib21" class="link link-ref xref-bibr">2022</a>; Xie et al., <a href="javascript:;" data-modal-source-id="bib104" class="link link-ref xref-bibr">2023</a>; Yao et al., <a href="javascript:;" data-modal-source-id="bib109" class="link link-ref xref-bibr">2023</a>; Miao et al., <a href="javascript:;" data-modal-source-id="bib64" class="link link-ref xref-bibr">2024</a>), or fine-tuned verifiers (Uesato et al., <a href="javascript:;" data-modal-source-id="bib94" class="link link-ref xref-bibr">2022</a>; Tafjord et al., <a href="javascript:;" data-modal-source-id="bib91" class="link link-ref xref-bibr">2022</a>; Yang et al., <a href="javascript:;" data-modal-source-id="bib107" class="link link-ref xref-bibr">2022a</a>; Asai et al., <a href="javascript:;" data-modal-source-id="bib2" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h2 scrollto-destination="5111459" data-legacyid="sec10" id="5111459" data-section-title="7 Summary of Our Analysis" class="section-title jumplink-heading">7 Summary of Our Analysis</h2>
            <div  class="">
                </div>
                <h3 scrollto-destination="5111460"  id="5111460" data-section-title="Bottleneck is in Feedback Generation." class="section-title ">Bottleneck is in Feedback Generation.</h3>
            <div  class="">
                <div id="5111461-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111460">

                    <p>Prior studies widely agree that LLMs can <em>refine</em> their responses given reliable feedback (§<a href="#sec6" data-scrollto="sec6" class="sectionLink xref-sec js-sec-jumplink">5</a>). However, generating reliable <em>feedback</em> on their own responses is still observed to be challenging for LLMs without using additional information (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>). In other words, for the current LLMs, the hypothesis that <em>recognizing errors is easier than avoiding them</em> (Saunders et al., <a href="javascript:;" data-modal-source-id="bib81" class="link link-ref xref-bibr">2022</a>) is only true for certain tasks whose verification is exceptionally easy, according to our analysis of the experiments in prior studies. We recommend that self-correction research analyze the quality of generated feedback in more detail, not only evaluate the downstream performance of the refined responses.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111462"  id="5111462" data-section-title="Tasks Suitable for Self-Correction." class="section-title ">Tasks Suitable for Self-Correction.</h3>
            <div  class="">
                <div id="5111463-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111462">

                    <p>Our analysis identifies the properties of tasks that are suitable for self-correction under different conditions. <ul class="bullet"><li><p>Intrinsic Self-Correction (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>) <ul class="list-simple"><li><span class="label title-label">–</span><p>Tasks whose verification tasks are much easier than the original tasks (e.g., tasks whose responses are decomposable)</p></li></ul></p></li><li><p>Self-Correction with External Information (§<a href="#sec7" data-scrollto="sec7" class="sectionLink xref-sec js-sec-jumplink">5.1</a>) <ul class="list-simple"><li><span class="label title-label">–</span><p>Tasks for which external tools that provide reliable feedback exist (e.g., code generation)</p></li><li><span class="label title-label">–</span><p>Tasks for which responses can be utilized to obtain useful information that is difficult to obtain before generating initial responses (e.g., generate queries from responses to retrieve documents for verifying information)</p></li></ul></p></li><li><p>Self-Correction with Fine-tuning (§<a href="#sec8" data-scrollto="sec8" class="sectionLink xref-sec js-sec-jumplink">5.2</a>) <ul class="list-simple"><li><span class="label title-label">–</span><p>Self-correction works in many tasks when large training data for feedback generation is available</p></li><li><span class="label title-label">–</span><p>Tasks that can use reinforcement learning or self-corrective learning (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>), i.e., tasks whose responses can be easily evaluated given ground-truth answers</p></li></ul></p></li></ul></p>
                </div>
                </div>
                <h2 scrollto-destination="5111464" data-legacyid="sec11" id="5111464" data-section-title="8 Checklist for Self-Correction Research" class="section-title jumplink-heading">8 Checklist for Self-Correction Research</h2>
            <div  class="">
                <div id="5111465-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111464">

                    <p>Our analysis shows that many studies do not clearly define their research questions and fail to conduct appropriate experiments (§<a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">3.1</a>, <a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>). To tackle these issues, we provide a checklist for self-correction research that provides requirements for designing appropriate experiments for verifying target RQs and recommended experiments for comprehensive analysis. <a href="javascript:;" reveal-id="T7" data-open="T7" class="link link-reveal link-table xref-fig">Table 7</a> provides a checklist for verifying different RQs identified in <a href="#sec3" data-scrollto="sec3" class="sectionLink xref-sec js-sec-jumplink">Section 3.1</a>. <a href="javascript:;" reveal-id="T8" data-open="T8" class="link link-reveal link-table xref-fig">Table 8</a> provides a checklist for reporting negative results.</p>
                </div>
                <div id="5111466-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111464">

                    <a id = "5111466" scrollto-destination="5111466"></a><div content-id="T7 sec11" class="table-wrap table-wide"><div id="T7" data-id="T7" class="table-wrap-title "><span class="label title-label" id="label-69965">Table 7: </span><div class="caption caption-id-" id="caption-69965"><p>Checklist for self-correction research for different target research questions.</p></div> </div><div class="fig-graphic"><a class="jumplink-placeholder" data-sectionId="5111466" id="tacl_a_00713_i004.tif"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i004.png?Expires=1766635869&amp;Signature=397g2gw4XTOObBUiFdyx-71U7sqfTH1yJXYB5Gt8jVr4cbpzUUHXHWyK5KJmEPml2TNbTe6MAzbXXZ7eBYkhqHzYVDgICCBK1~IbFGdxGvgqARjgTto793h4KWFaJnS8jh1vmo-Sp68~zZ7caNC96rhmF3yC2e7YnNhxyn9VD1LTyJHN6p-AAiciH4pP7ETaBn35Wpuzmq8-VpBnNgunBK8vpz9tvhXNCSwBiRfHDufT5iiK36tzgieSp4PC9nF36Wa1RqJXbwqQ64v1I52eIwsbjMEj4JC-0He1-Rr684iTVmfXs3edR4lUzSIuciLTPsmEdYPIsbnpa~VObRWQ7Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i004.png?Expires=1766635869&amp;Signature=397g2gw4XTOObBUiFdyx-71U7sqfTH1yJXYB5Gt8jVr4cbpzUUHXHWyK5KJmEPml2TNbTe6MAzbXXZ7eBYkhqHzYVDgICCBK1~IbFGdxGvgqARjgTto793h4KWFaJnS8jh1vmo-Sp68~zZ7caNC96rhmF3yC2e7YnNhxyn9VD1LTyJHN6p-AAiciH4pP7ETaBn35Wpuzmq8-VpBnNgunBK8vpz9tvhXNCSwBiRfHDufT5iiK36tzgieSp4PC9nF36Wa1RqJXbwqQ64v1I52eIwsbjMEj4JC-0He1-Rr684iTVmfXs3edR4lUzSIuciLTPsmEdYPIsbnpa~VObRWQ7Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Checklist for self-correction research for different target research questions." path-from-xml="tacl_a_00713_i004.tif" /></a></div><div class="fig-orig original-slide"><a section="5111466" class="fig-view-orig" href="/view-large/figure/5111466/tacl_a_00713_i004.tif" path-from-xml="tacl_a_00713_i004.tif" target="_blank">View large</a></div><div content-id="T7" class="table-modal"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i004.png?Expires=1766635869&amp;Signature=397g2gw4XTOObBUiFdyx-71U7sqfTH1yJXYB5Gt8jVr4cbpzUUHXHWyK5KJmEPml2TNbTe6MAzbXXZ7eBYkhqHzYVDgICCBK1~IbFGdxGvgqARjgTto793h4KWFaJnS8jh1vmo-Sp68~zZ7caNC96rhmF3yC2e7YnNhxyn9VD1LTyJHN6p-AAiciH4pP7ETaBn35Wpuzmq8-VpBnNgunBK8vpz9tvhXNCSwBiRfHDufT5iiK36tzgieSp4PC9nF36Wa1RqJXbwqQ64v1I52eIwsbjMEj4JC-0He1-Rr684iTVmfXs3edR4lUzSIuciLTPsmEdYPIsbnpa~VObRWQ7Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i004.png?Expires=1766635869&amp;Signature=397g2gw4XTOObBUiFdyx-71U7sqfTH1yJXYB5Gt8jVr4cbpzUUHXHWyK5KJmEPml2TNbTe6MAzbXXZ7eBYkhqHzYVDgICCBK1~IbFGdxGvgqARjgTto793h4KWFaJnS8jh1vmo-Sp68~zZ7caNC96rhmF3yC2e7YnNhxyn9VD1LTyJHN6p-AAiciH4pP7ETaBn35Wpuzmq8-VpBnNgunBK8vpz9tvhXNCSwBiRfHDufT5iiK36tzgieSp4PC9nF36Wa1RqJXbwqQ64v1I52eIwsbjMEj4JC-0He1-Rr684iTVmfXs3edR4lUzSIuciLTPsmEdYPIsbnpa~VObRWQ7Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Checklist for self-correction research for different target research questions." path-from-xml="tacl_a_00713_i004.tif" /></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111466" target="_blank" rel="nofollow" aria-label="View large Table 7: ">
                  View Large</a></div></div>
                </div>
                <div id="5111467-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111464">

                    <a id = "5111467" scrollto-destination="5111467"></a><div content-id="T8 sec11" class="table-wrap table-wide"><div id="T8" data-id="T8" class="table-wrap-title "><span class="label title-label" id="label-5846">Table 8: </span><div class="caption caption-id-" id="caption-5846"><p>Checklist for reporting negative results of self-correction.</p></div> </div><div class="fig-graphic"><a class="jumplink-placeholder" data-sectionId="5111467" id="tacl_a_00713_i005.tif"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i005.png?Expires=1766635869&amp;Signature=a8PdFv0y518GB-h53phXs9cV6iKrSyqaQUsDDawO2G5uuTi9sBhw3TW-A86doew~NTT43D~Gast4SAdSWykArj5jpiTZotkrYN2lGrbpNbyZoGKF4B4UNljGHnTaGb-cxxxPpnqHeroeWuAum~7qGQzpQBCiEKM0LX0lNfly0VE2b5bDO9STJKd~jXd6IJqDuc8sKv3MpdSqfQwCxDmm1PBprh1zy9P7bc5g7K77EYIhwhFpi0GM5sw5-LSoDknu18p8CgksE3DYVBve-jD-ZlkIbavGT54ZhWcMtcBUlI7HYLvLkucpF2e7nbX5UdmeIy3w0vQhlUxvOufehRYC1A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i005.png?Expires=1766635869&amp;Signature=a8PdFv0y518GB-h53phXs9cV6iKrSyqaQUsDDawO2G5uuTi9sBhw3TW-A86doew~NTT43D~Gast4SAdSWykArj5jpiTZotkrYN2lGrbpNbyZoGKF4B4UNljGHnTaGb-cxxxPpnqHeroeWuAum~7qGQzpQBCiEKM0LX0lNfly0VE2b5bDO9STJKd~jXd6IJqDuc8sKv3MpdSqfQwCxDmm1PBprh1zy9P7bc5g7K77EYIhwhFpi0GM5sw5-LSoDknu18p8CgksE3DYVBve-jD-ZlkIbavGT54ZhWcMtcBUlI7HYLvLkucpF2e7nbX5UdmeIy3w0vQhlUxvOufehRYC1A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Checklist for reporting negative results of self-correction." path-from-xml="tacl_a_00713_i005.tif" /></a></div><div class="fig-orig original-slide"><a section="5111467" class="fig-view-orig" href="/view-large/figure/5111467/tacl_a_00713_i005.tif" path-from-xml="tacl_a_00713_i005.tif" target="_blank">View large</a></div><div content-id="T8" class="table-modal"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i005.png?Expires=1766635869&amp;Signature=a8PdFv0y518GB-h53phXs9cV6iKrSyqaQUsDDawO2G5uuTi9sBhw3TW-A86doew~NTT43D~Gast4SAdSWykArj5jpiTZotkrYN2lGrbpNbyZoGKF4B4UNljGHnTaGb-cxxxPpnqHeroeWuAum~7qGQzpQBCiEKM0LX0lNfly0VE2b5bDO9STJKd~jXd6IJqDuc8sKv3MpdSqfQwCxDmm1PBprh1zy9P7bc5g7K77EYIhwhFpi0GM5sw5-LSoDknu18p8CgksE3DYVBve-jD-ZlkIbavGT54ZhWcMtcBUlI7HYLvLkucpF2e7nbX5UdmeIy3w0vQhlUxvOufehRYC1A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i005.png?Expires=1766635869&amp;Signature=a8PdFv0y518GB-h53phXs9cV6iKrSyqaQUsDDawO2G5uuTi9sBhw3TW-A86doew~NTT43D~Gast4SAdSWykArj5jpiTZotkrYN2lGrbpNbyZoGKF4B4UNljGHnTaGb-cxxxPpnqHeroeWuAum~7qGQzpQBCiEKM0LX0lNfly0VE2b5bDO9STJKd~jXd6IJqDuc8sKv3MpdSqfQwCxDmm1PBprh1zy9P7bc5g7K77EYIhwhFpi0GM5sw5-LSoDknu18p8CgksE3DYVBve-jD-ZlkIbavGT54ZhWcMtcBUlI7HYLvLkucpF2e7nbX5UdmeIy3w0vQhlUxvOufehRYC1A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Checklist for reporting negative results of self-correction." path-from-xml="tacl_a_00713_i005.tif" /></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111467" target="_blank" rel="nofollow" aria-label="View large Table 8: ">
                  View Large</a></div></div>
                </div>
                </div>
                <h2 scrollto-destination="5111468" data-legacyid="sec12" id="5111468" data-section-title="9 Differences from Other Survey" class="section-title jumplink-heading">9 Differences from Other Survey</h2>
            <div  class="">
                <div id="5111469-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111468">

                    <p>Pan et al. (<a href="javascript:;" data-modal-source-id="bib72" class="link link-ref xref-bibr">2024</a>) provide a comprehensive survey on broad topics related to self-correction, including training strategies. Our work specifically focuses on (inference-time) self-correction and provides a more detailed and critical analysis of prior work. Huang et al. (<a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>) provide an analysis of problems in the evaluation settings of self-correction research, which motivates our work. They focus on analyzing a few papers on intrinsic self-correction in reasoning tasks. We provide a more comprehensive analysis of self-correction with in-context learning, external tools, and fine-tuning.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111470" data-legacyid="sec13" id="5111470" data-section-title="10 Related Work of Self-Correction" class="section-title jumplink-heading">10 Related Work of Self-Correction</h2>
            <div  class="">
                </div>
                <h3 scrollto-destination="5111471"  id="5111471" data-section-title="Self-Detection." class="section-title ">Self-Detection.</h3>
            <div  class="">
                <div id="5111472-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111471">

                    <p>of mistakes in LLM responses using LLMs (possibly with external information) has been studied in various domains, including misinformation detection (Zhang et al., <a href="javascript:;" data-modal-source-id="bib118" class="link link-ref xref-bibr">2023c</a>; Chern et al., <a href="javascript:;" data-modal-source-id="bib17" class="link link-ref xref-bibr">2023</a>; Chen and Shu, <a href="javascript:;" data-modal-source-id="bib11" class="link link-ref xref-bibr">2024</a>; Mishra et al., <a href="javascript:;" data-modal-source-id="bib66" class="link link-ref xref-bibr">2024</a>), context-faithfulness (Wang et al., <a href="javascript:;" data-modal-source-id="bib97" class="link link-ref xref-bibr">2020</a>; Durmus et al., <a href="javascript:;" data-modal-source-id="bib24" class="link link-ref xref-bibr">2020</a>; Scialom et al., <a href="javascript:;" data-modal-source-id="bib84" class="link link-ref xref-bibr">2021</a>), harmful content detection (Rauh et al., <a href="javascript:;" data-modal-source-id="bib78" class="link link-ref xref-bibr">2022</a>), and bias detection (Blodgett et al., <a href="javascript:;" data-modal-source-id="bib5" class="link link-ref xref-bibr">2020</a>; Feng et al., <a href="javascript:;" data-modal-source-id="bib26" class="link link-ref xref-bibr">2023</a>). However, recent studies (Tyen et al., <a href="javascript:;" data-modal-source-id="bib93" class="link link-ref xref-bibr">2024</a>; Kamoi et al., <a href="javascript:;" data-modal-source-id="bib46" class="link link-ref xref-bibr">2024</a>) show that even strong LLMs often cannot detect their own mistakes in various tasks.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111473"  id="5111473" data-section-title="Editing Human-Written Text." class="section-title ">Editing Human-Written Text.</h3>
            <div  class="">
                <div id="5111474-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111473">

                    <p>by using language models has been studied in various domains, including information update (Shah et al., <a href="javascript:;" data-modal-source-id="bib85" class="link link-ref xref-bibr">2020</a>; Iv et al., <a href="javascript:;" data-modal-source-id="bib41" class="link link-ref xref-bibr">2022</a>; Schick et al., <a href="javascript:;" data-modal-source-id="bib83" class="link link-ref xref-bibr">2023</a>), grammatical error correction (Ng et al., <a href="javascript:;" data-modal-source-id="bib68" class="link link-ref xref-bibr">2014</a>; Lichtarge et al., <a href="javascript:;" data-modal-source-id="bib55" class="link link-ref xref-bibr">2019</a>), factual error correction (Cao et al., <a href="javascript:;" data-modal-source-id="bib6" class="link link-ref xref-bibr">2020</a>; Thorne and Vlachos, <a href="javascript:;" data-modal-source-id="bib92" class="link link-ref xref-bibr">2021</a>), and code repair (Gupta et al., <a href="javascript:;" data-modal-source-id="bib34" class="link link-ref xref-bibr">2017</a>; Mesbah et al., <a href="javascript:;" data-modal-source-id="bib63" class="link link-ref xref-bibr">2019</a>; Bader et al., <a href="javascript:;" data-modal-source-id="bib3" class="link link-ref xref-bibr">2019</a>; Chen et al., <a href="javascript:;" data-modal-source-id="bib16" class="link link-ref xref-bibr">2021</a>; Yasunaga and Liang, <a href="javascript:;" data-modal-source-id="bib110" class="link link-ref xref-bibr">2020</a>, <a href="javascript:;" data-modal-source-id="bib111" class="link link-ref xref-bibr">2021</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111475"  id="5111475" data-section-title="Self-Training." class="section-title ">Self-Training.</h3>
            <div  class="">
                <div id="5111476-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111475">

                    <p>or self-improvement is an approach to train models using their own responses. Some studies use self-evaluation or self-correction for creating training data (Bai et al., <a href="javascript:;" data-modal-source-id="bib4" class="link link-ref xref-bibr">2022</a>; Gulcehre et al., <a href="javascript:;" data-modal-source-id="bib33" class="link link-ref xref-bibr">2023</a>) or use self-evaluation as training signals (Pang et al., <a href="javascript:;" data-modal-source-id="bib73" class="link link-ref xref-bibr">2024</a>). Another approach improves the reasoning of LLMs using LLM-generated reasoning by selecting high-quality outputs using ground-truth final answers (Zelikman et al., <a href="javascript:;" data-modal-source-id="bib115" class="link link-ref xref-bibr">2022</a>) or self-consistency (Huang et al., <a href="javascript:;" data-modal-source-id="bib38" class="link link-ref xref-bibr">2023</a>). As another direction, Meng et al. (<a href="javascript:;" data-modal-source-id="bib62" class="link link-ref xref-bibr">2022</a>) use sentences generated by LLMs with high confidence for training classifiers.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111477" data-legacyid="sec14" id="5111477" data-section-title="11 Future Directions" class="section-title jumplink-heading">11 Future Directions</h2>
            <div  class="">
                </div>
                <h3 scrollto-destination="5111478"  id="5111478" data-section-title="Improving Feedback." class="section-title ">Improving Feedback.</h3>
            <div  class="">
                <div id="5111479-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111478">

                    <p>Prior studies indicate that it is difficult for LLMs to generate feedback on their own responses with in-context learning (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>, <a href="#sec10" data-scrollto="sec10" class="sectionLink xref-sec js-sec-jumplink">7</a>). However, most studies in intrinsic self-correction (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>) use simple prompts for generating feedback, and there is room for improvement. A possible direction to improve feedback is to apply (reference-free and point-wise) <strong>LLM-based evaluation metrics</strong>. Recent approaches for improving the model-based evaluation include using human-written evaluation criteria (Chiang and Lee, <a href="javascript:;" data-modal-source-id="bib18" class="link link-ref xref-bibr">2023</a>; Liu et al., <a href="javascript:;" data-modal-source-id="bib58" class="link link-ref xref-bibr">2023</a>) and decomposing responses (Saha et al., <a href="javascript:;" data-modal-source-id="bib80" class="link link-ref xref-bibr">2024</a>; Min et al., <a href="javascript:;" data-modal-source-id="bib65" class="link link-ref xref-bibr">2023</a>). As another direction, recent studies in self-correction propose frameworks using the <strong>confidence</strong> in their responses, estimated by generation probabilities (Varshney et al., <a href="javascript:;" data-modal-source-id="bib96" class="link link-ref xref-bibr">2023</a>; Jiang et al., <a href="javascript:;" data-modal-source-id="bib44" class="link link-ref xref-bibr">2023b</a>), prompting (Li et al., <a href="javascript:;" data-modal-source-id="bib51" class="link link-ref xref-bibr">2024a</a>), or generating new questions from their answers to evaluate logical consistency (Jung et al., <a href="javascript:;" data-modal-source-id="bib45" class="link link-ref xref-bibr">2022</a>; Tafjord et al., <a href="javascript:;" data-modal-source-id="bib91" class="link link-ref xref-bibr">2022</a>; Wu et al., <a href="javascript:;" data-modal-source-id="bib103" class="link link-ref xref-bibr">2024</a>).</p>
                </div>
                </div>
                <h3 scrollto-destination="5111480"  id="5111480" data-section-title="Unexplored Tasks." class="section-title ">Unexplored Tasks.</h3>
            <div  class="">
                <div id="5111481-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111480">

                    <p>The difficulty of self-evaluation differs from task to task (§<a href="#sec5" data-scrollto="sec5" class="sectionLink xref-sec js-sec-jumplink">4</a>), while many studies assume that verification is consistently easier than generation. We expect that there are unexplored tasks in which intrinsic self-correction works well, although self-correction research mostly focuses on reasoning tasks such as math reasoning and coding (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>; Gou et al., <a href="javascript:;" data-modal-source-id="bib32" class="link link-ref xref-bibr">2024</a>; Huang et al., <a href="javascript:;" data-modal-source-id="bib39" class="link link-ref xref-bibr">2024a</a>). For example, LLM-based evaluation is often studied in open-ended text generation, such as dialogue generation and text summarization (Fu et al., <a href="javascript:;" data-modal-source-id="bib28" class="link link-ref xref-bibr">2024</a>; Liu et al., <a href="javascript:;" data-modal-source-id="bib58" class="link link-ref xref-bibr">2023</a>), suggesting that reasonable model-based feedback is available for these tasks.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111482"  id="5111482" data-section-title="Fine-tuning on Small Training Data." class="section-title ">Fine-tuning on Small Training Data.</h3>
            <div  class="">
                <div id="5111483-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111482">

                    <p>Fine-tuning of feedback generation often relies on large training data, which requires large-scale human annotations (§<a href="#sec8" data-scrollto="sec8" class="sectionLink xref-sec js-sec-jumplink">5.2</a>). We expect future work to explore self-correction with smaller training data. Although reinforcement learning (Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>) or self-corrective learning (Welleck et al., <a href="javascript:;" data-modal-source-id="bib101" class="link link-ref xref-bibr">2023</a>) do not require human feedback, they require reasonable reward functions for evaluating LLM responses, which are not available in many tasks. For example, RL4F (Akyurek et al., <a href="javascript:;" data-modal-source-id="bib1" class="link link-ref xref-bibr">2023</a>) uses ROUGE as a reward function for text summarization and action planning, which is sub-optimal.</p>
                </div>
                </div>
                <h3 scrollto-destination="5111484"  id="5111484" data-section-title="Pre-training for Improving Self-Correction." class="section-title ">Pre-training for Improving Self-Correction.</h3>
            <div  class="">
                <div id="5111485-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111484">

                    <p>Prior studies show that large-scale fine-tuning on reference feedback improves the self-correction capability of LLMs (§<a href="#sec8" data-scrollto="sec8" class="sectionLink xref-sec js-sec-jumplink">5.2</a>). This observation suggests that the current approach or datasets for pre-training LLMs are insufficient to make LLMs acquire self-correction capability. We expect future work to explore pre-training strategies to improve the intrinsic self-correction capability of LLMs.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111486"  id="5111486" data-section-title="12 Conclusion" class="section-title jumplink-heading">12 Conclusion</h2>
            <div  class="">
                <div id="5111487-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111486">

                    <p>We provide a critical survey of self-correction to identify in which conditions LLMs can self-correct their mistakes. Our analysis reveals that many studies fail to define their research questions clearly or design experiments appropriately. To tackle these issues, we categorize research questions and frameworks in self-correction research and provide a checklist for conducting appropriate experiments.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111488"  id="5111488" data-section-title="Acknowledgments" class="section-title jumplink-heading">Acknowledgments</h2>
            <div  class="">
                <div id="5111489-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111488">

                    <p>This work was supported by a Cisco Research Grant. We appreciate valuable suggestions from the action editor and anonymous reviewers.</p>
                </div>
                </div>
                <h2 scrollto-destination="5111490"  id="5111490" data-section-title="Notes" class="section-title jumplink-heading">Notes</h2>
            <div  class="">
                <div id="5111492-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111491">

                    <div class="fn" content-id="fn1"><span class="label fn-label"><span rel="nofollow" data-fn-id="fn1" class="end-note-link">1 </span></span><p>Tree-of-thought is a generate-and-rank method and not a self-correction method in our definition.</p></div>
                </div>
                </div>
                <h2 scrollto-destination="5111493"  id="5111493" data-section-title="References" class="backreferences-title jumplink-heading">References</h2>
            <div  class="">
                <div id="5111493-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="0">

                    <div class="ref-list js-splitview-ref-list"><div data-content-id="bib1" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Afra Feyza</div> <div class="surname">Akyurek</div></span>, <span class="name string-name"><div class="given-names">Ekin</div> <div class="surname">Akyurek</div></span>, <span class="name string-name"><div class="given-names">Ashwin</div> <div class="surname">Kalyan</div></span>, <span class="name string-name"><div class="given-names">Peter</div> <div class="surname">Clark</div></span>, <span class="name string-name"><div class="given-names">Derry Tanti</div> <div class="surname">Wijaya</div></span>, and <span class="name string-name"><div class="given-names">Niket</div> <div class="surname">Tandon</div></span></span>. <div class="year">2023</div>. <div class="article-title">RL4F: Generating natural language feedback with reinforcement learning for repairing model outputs</div>. In <div class="source">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">7716</div>–<div class="lpage">7733</div>, <div class="publisher-loc">Toronto, Canada</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.acl-long.427" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.acl-long.427</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=RL4F%3A%20Generating%20natural%20language%20feedback%20with%20reinforcement%20learning%20for%20repairing%20model%20outputs&amp;author=Afra%20Feyza%20Akyurek&amp;author=Ekin%20Akyurek&amp;author=Ashwin%20Kalyan&amp;author=Peter%20Clark&amp;author=Derry%20Tanti%20Wijaya&amp;author=Niket%20Tandon&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2061st%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib2" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Akari</div> <div class="surname">Asai</div></span>, <span class="name string-name"><div class="surname">Zeqiu</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="given-names">Yizhong</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Avirup</div> <div class="surname">Sil</div></span>, and <span class="name string-name"><div class="given-names">Hannaneh</div> <div class="surname">Hajishirzi</div></span></span>. <div class="year">2024</div>. <div class="article-title">Self-RAG: Learning to retrieve, generate, and critique through self-reflection</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-RAG%3A%20Learning%20to%20retrieve%2C%20generate%2C%20and%20critique%20through%20self-reflection&amp;author=Akari%20Asai&amp;author=Wu%20Zeqiu&amp;author=Yizhong%20Wang&amp;author=Avirup%20Sil&amp;author=Hannaneh%20Hajishirzi&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib3" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Johannes</div> <div class="surname">Bader</div></span>, <span class="name string-name"><div class="given-names">Andrew</div> <div class="surname">Scott</div></span>, <span class="name string-name"><div class="given-names">Michael</div> <div class="surname">Pradel</div></span>, and <span class="name string-name"><div class="given-names">Satish</div> <div class="surname">Chandra</div></span></span>. <div class="year">2019</div>. <div class="article-title">Getafix: Learning to fix bugs automatically</div>. <div class="source">Proceedings of the ACM on Programming Languages</div>, <div class="volume">3</div>(<div class="issue">OOPSLA</div>). <div class="pub-id-doi"><a href="https://doi.org/10.1145/3360585" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1145/3360585</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Getafix%3A%20Learning%20to%20fix%20bugs%20automatically&amp;author=Johannes%20Bader&amp;author=Andrew%20Scott&amp;author=Michael%20Pradel&amp;author=Satish%20Chandra&amp;publication_year=2019&amp;journal=Proceedings%20of%20the%20ACM%20on%20Programming%20Languages&amp;volume=3&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib4" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yuntao</div> <div class="surname">Bai</div></span>, <span class="name string-name"><div class="given-names">Saurav</div> <div class="surname">Kadavath</div></span>, <span class="name string-name"><div class="given-names">Sandipan</div> <div class="surname">Kundu</div></span>, <span class="name string-name"><div class="given-names">Amanda</div> <div class="surname">Askell</div></span>, <span class="name string-name"><div class="given-names">Jackson</div> <div class="surname">Kernion</div></span>, <span class="name string-name"><div class="given-names">Andy</div> <div class="surname">Jones</div></span>, <span class="name string-name"><div class="given-names">Anna</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Anna</div> <div class="surname">Goldie</div></span>, <span class="name string-name"><div class="given-names">Azalia</div> <div class="surname">Mirhoseini</div></span>, <span class="name string-name"><div class="given-names">Cameron</div> <div class="surname">McKinnon</div></span>, <span class="name string-name"><div class="given-names">Carol</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Catherine</div> <div class="surname">Olsson</div></span>, <span class="name string-name"><div class="given-names">Christopher</div> <div class="surname">Olah</div></span>, <span class="name string-name"><div class="given-names">Danny</div> <div class="surname">Hernandez</div></span>, <span class="name string-name"><div class="given-names">Dawn</div> <div class="surname">Drain</div></span>, <span class="name string-name"><div class="given-names">Deep</div> <div class="surname">Ganguli</div></span>, <span class="name string-name"><div class="given-names">Dustin</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Eli</div> <div class="surname">Tran-Johnson</div></span>, <span class="name string-name"><div class="given-names">Ethan</div> <div class="surname">Perez</div></span>, <span class="name string-name"><div class="given-names">Jamie</div> <div class="surname">Kerr</div></span>, <span class="name string-name"><div class="given-names">Jared</div> <div class="surname">Mueller</div></span>, <span class="name string-name"><div class="given-names">Jeffrey</div> <div class="surname">Ladish</div></span>, <span class="name string-name"><div class="given-names">Joshua</div> <div class="surname">Landau</div></span>, <span class="name string-name"><div class="given-names">Kamal</div> <div class="surname">Ndousse</div></span>, <span class="name string-name"><div class="given-names">Kamile</div> <div class="surname">Lukosuite</div></span>, <span class="name string-name"><div class="given-names">Liane</div> <div class="surname">Lovitt</div></span>, <span class="name string-name"><div class="given-names">Michael</div> <div class="surname">Sellitto</div></span>, <span class="name string-name"><div class="given-names">Nelson</div> <div class="surname">Elhage</div></span>, <span class="name string-name"><div class="given-names">Nicholas</div> <div class="surname">Schiefer</div></span>, <span class="name string-name"><div class="given-names">Noemi</div> <div class="surname">Mercado</div></span>, <span class="name string-name"><div class="given-names">Nova</div> <div class="surname">DasSarma</div></span>, <span class="name string-name"><div class="given-names">Robert</div> <div class="surname">Lasenby</div></span>, <span class="name string-name"><div class="given-names">Robin</div> <div class="surname">Larson</div></span>, <span class="name string-name"><div class="given-names">Sam</div> <div class="surname">Ringer</div></span>, <span class="name string-name"><div class="given-names">Scott</div> <div class="surname">Johnston</div></span>, <span class="name string-name"><div class="given-names">Shauna</div> <div class="surname">Kravec</div></span>, <span class="name string-name"><div class="given-names">Sheer El</div> <div class="surname">Showk</div></span>, <span class="name string-name"><div class="given-names">Stanislav</div> <div class="surname">Fort</div></span>, <span class="name string-name"><div class="given-names">Tamera</div> <div class="surname">Lanham</div></span>, <span class="name string-name"><div class="given-names">Timothy</div> <div class="surname">Telleen-Lawton</div></span>, <span class="name string-name"><div class="given-names">Tom</div> <div class="surname">Conerly</div></span>, <span class="name string-name"><div class="given-names">Tom</div> <div class="surname">Henighan</div></span>, <span class="name string-name"><div class="given-names">Tristan</div> <div class="surname">Hume</div></span>, <span class="name string-name"><div class="given-names">Samuel R.</div> <div class="surname">Bowman</div></span>, <span class="name string-name"><div class="given-names">Zac</div> <div class="surname">Hatfield-Dodds</div></span>, <span class="name string-name"><div class="given-names">Ben</div> <div class="surname">Mann</div></span>, <span class="name string-name"><div class="given-names">Dario</div> <div class="surname">Amodei</div></span>, <span class="name string-name"><div class="given-names">Nicholas</div> <div class="surname">Joseph</div></span>, <span class="name string-name"><div class="given-names">Sam</div> <div class="surname">McCandlish</div></span>, <span class="name string-name"><div class="given-names">Tom</div> <div class="surname">Brown</div></span>, and <span class="name string-name"><div class="given-names">Jared</div> <div class="surname">Kaplan</div></span></span>. <div class="year">2022</div>. <div class="article-title">Constitutional AI: Harmlessness from AI feedback</div>. <div class="source">arXiv preprint arXiv:2212.08073</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Constitutional%20AI%3A%20Harmlessness%20from%20AI%20feedback&amp;author=Yuntao%20Bai&amp;author=Saurav%20Kadavath&amp;author=Sandipan%20Kundu&amp;author=Amanda%20Askell&amp;author=Jackson%20Kernion&amp;author=Andy%20Jones&amp;author=Anna%20Chen&amp;author=Anna%20Goldie&amp;author=Azalia%20Mirhoseini&amp;author=Cameron%20McKinnon&amp;author=Carol%20Chen&amp;author=Catherine%20Olsson&amp;author=Christopher%20Olah&amp;author=Danny%20Hernandez&amp;author=Dawn%20Drain&amp;author=Deep%20Ganguli&amp;author=Dustin%20Li&amp;author=Eli%20Tran-Johnson&amp;author=Ethan%20Perez&amp;author=Jamie%20Kerr&amp;author=Jared%20Mueller&amp;author=Jeffrey%20Ladish&amp;author=Joshua%20Landau&amp;author=Kamal%20Ndousse&amp;author=Kamile%20Lukosuite&amp;author=Liane%20Lovitt&amp;author=Michael%20Sellitto&amp;author=Nelson%20Elhage&amp;author=Nicholas%20Schiefer&amp;author=Noemi%20Mercado&amp;author=Nova%20DasSarma&amp;author=Robert%20Lasenby&amp;author=Robin%20Larson&amp;author=Sam%20Ringer&amp;author=Scott%20Johnston&amp;author=Shauna%20Kravec&amp;author=Sheer%20El%20Showk&amp;author=Stanislav%20Fort&amp;author=Tamera%20Lanham&amp;author=Timothy%20Telleen-Lawton&amp;author=Tom%20Conerly&amp;author=Tom%20Henighan&amp;author=Tristan%20Hume&amp;author=Samuel%20R.%20Bowman&amp;author=Zac%20Hatfield-Dodds&amp;author=Ben%20Mann&amp;author=Dario%20Amodei&amp;author=Nicholas%20Joseph&amp;author=Sam%20McCandlish&amp;author=Tom%20Brown&amp;author=Jared%20Kaplan&amp;publication_year=2022&amp;journal=arXiv%20preprint%20arXiv%3A2212.08073&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib5" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Su</div> <div class="surname">Lin Blodgett</div></span>, <span class="name string-name"><div class="given-names">Solon</div> <div class="surname">Barocas</div></span>, <span class="name string-name"><div class="given-names">Hal</div> <div class="surname">Daumé</div> III</span>, and <span class="name string-name"><div class="given-names">Hanna</div> <div class="surname">Wallach</div></span></span>. <div class="year">2020</div>. <div class="article-title">Language (technology) is power: A critical survey of “bias” in NLP</div>. In <div class="source">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</div>, pages <div class="fpage">5454</div>–<div class="lpage">5476</div>, <div class="comment">Online</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2020.acl-main.485" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2020.acl-main.485</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Language%20%28technology%29%20is%20power%3A%20A%20critical%20survey%20of%20%E2%80%9Cbias%E2%80%9D%20in%20NLP&amp;author=Su%20Lin%20Blodgett&amp;author=Solon%20Barocas&amp;author=Hal%20Daum%C3%A9&amp;author=Hanna%20Wallach&amp;publication_year=2020&amp;book=Proceedings%20of%20the%2058th%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib6" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Meng</div> <div class="surname">Cao</div></span>, <span class="name string-name"><div class="given-names">Yue</div> <div class="surname">Dong</div></span>, <span class="name string-name"><div class="surname">Jiapeng</div> <div class="given-names">Wu</div></span>, and <span class="name string-name"><div class="given-names">Jackie Chi Kit</div> <div class="surname">Cheung</div></span></span>. <div class="year">2020</div>. <div class="article-title">Factual error correction for abstractive summarization models</div>. In <div class="source">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</div>, pages <div class="fpage">6251</div>–<div class="lpage">6258</div>, <div class="comment">Online</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2020.emnlp-main.506" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2020.emnlp-main.506</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Factual%20error%20correction%20for%20abstractive%20summarization%20models&amp;author=Meng%20Cao&amp;author=Yue%20Dong&amp;author=Wu%20Jiapeng&amp;author=Jackie%20Chi%20Kit%20Cheung&amp;publication_year=2020&amp;book=Proceedings%20of%20the%202020%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing%20%28EMNLP%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib7" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Chi-Min</div> <div class="surname">Chan</div></span>, <span class="name string-name"><div class="given-names">Weize</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="surname">Yusheng</div> <div class="given-names">Su</div></span>, <span class="name string-name"><div class="surname">Jianxuan</div> <div class="given-names">Yu</div></span>, <span class="name string-name"><div class="given-names">Wei</div> <div class="surname">Xue</div></span>, <span class="name string-name"><div class="given-names">Shanghang</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="surname">Jie</div> <div class="given-names">Fu</div></span>, and <span class="name string-name"><div class="given-names">Zhiyuan</div> <div class="surname">Liu</div></span></span>. <div class="year">2024</div>. <div class="article-title">Chateval: Towards better LLM-based evaluators through multi-agent debate</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Chateval%3A%20Towards%20better%20LLM-based%20evaluators%20through%20multi-agent%20debate&amp;author=Chi-Min%20Chan&amp;author=Weize%20Chen&amp;author=Su%20Yusheng&amp;author=Yu%20Jianxuan&amp;author=Wei%20Xue&amp;author=Shanghang%20Zhang&amp;author=Fu%20Jie&amp;author=Zhiyuan%20Liu&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib8" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yiannis</div> <div class="surname">Charalambous</div></span>, <span class="name string-name"><div class="given-names">Norbert</div> <div class="surname">Tihanyi</div></span>, <span class="name string-name"><div class="given-names">Ridhi</div> <div class="surname">Jain</div></span>, <span class="name string-name"><div class="given-names">Youcheng</div> <div class="surname">Sun</div></span>, <span class="name string-name"><div class="given-names">Mohamed Amine</div> <div class="surname">Ferrag</div></span>, and <span class="name string-name"><div class="given-names">Lucas C.</div> <div class="surname">Cordeiro</div></span></span>. <div class="year">2023</div>. <div class="article-title">A new era in software security: Towards self-healing software via large language models and formal verification</div>. <div class="source">arXiv preprint arXiv:2305.14752</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=A%20new%20era%20in%20software%20security%3A%20Towards%20self-healing%20software%20via%20large%20language%20models%20and%20formal%20verification&amp;author=Yiannis%20Charalambous&amp;author=Norbert%20Tihanyi&amp;author=Ridhi%20Jain&amp;author=Youcheng%20Sun&amp;author=Mohamed%20Amine%20Ferrag&amp;author=Lucas%20C.%20Cordeiro&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2305.14752&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib9" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Angelica</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Jérémy</div> <div class="surname">Scheurer</div></span>, <span class="name string-name"><div class="given-names">Jon Ander</div> <div class="surname">Campos</div></span>, <span class="name string-name"><div class="given-names">Tomasz</div> <div class="surname">Korbak</div></span>, <span class="name string-name"><div class="given-names">Jun Shern</div> <div class="surname">Chan</div></span>, <span class="name string-name"><div class="given-names">Samuel R.</div> <div class="surname">Bowman</div></span>, <span class="name string-name"><div class="given-names">Kyunghyun</div> <div class="surname">Cho</div></span>, and <span class="name string-name"><div class="given-names">Ethan</div> <div class="surname">Perez</div></span></span>. <div class="year">2024a</div>. <div class="article-title">Learning from natural language feedback</div>. <div class="source">Transactions on Machine Learning Research</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Learning%20from%20natural%20language%20feedback&amp;author=Angelica%20Chen&amp;author=J%C3%A9r%C3%A9my%20Scheurer&amp;author=Jon%20Ander%20Campos&amp;author=Tomasz%20Korbak&amp;author=Jun%20Shern%20Chan&amp;author=Samuel%20R.%20Bowman&amp;author=Kyunghyun%20Cho&amp;author=Ethan%20Perez&amp;publication_year=2024a&amp;journal=Transactions%20on%20Machine%20Learning%20Research&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib10" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Bei</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Fengji</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Anh</div> <div class="surname">Nguyen</div></span>, <span class="name string-name"><div class="given-names">Daoguang</div> <div class="surname">Zan</div></span>, <span class="name string-name"><div class="given-names">Zeqi</div> <div class="surname">Lin</div></span>, <span class="name string-name"><div class="given-names">Jian-Guang</div> <div class="surname">Lou</div></span>, and <span class="name string-name"><div class="given-names">Weizhu</div> <div class="surname">Chen</div></span></span>. <div class="year">2023a</div>. <div class="article-title">Codet: Code generation with generated tests</div>. In <div class="source">The Eleventh International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Codet%3A%20Code%20generation%20with%20generated%20tests&amp;author=Bei%20Chen&amp;author=Fengji%20Zhang&amp;author=Anh%20Nguyen&amp;author=Daoguang%20Zan&amp;author=Zeqi%20Lin&amp;author=Jian-Guang%20Lou&amp;author=Weizhu%20Chen&amp;publication_year=2023a&amp;journal=The%20Eleventh%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib11" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Canyu</div> <div class="surname">Chen</div></span> and <span class="name string-name"><div class="given-names">Kai</div> <div class="surname">Shu</div></span></span>. <div class="year">2024</div>. <div class="article-title">Can LLM-generated misinformation be detected?</div> In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Can%20LLM-generated%20misinformation%20be%20detected%3F&amp;author=Canyu%20Chen&amp;author=Kai%20Shu&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib12" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Justin Chih-Yao</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Swarnadeep</div> <div class="surname">Saha</div></span>, and <span class="name string-name"><div class="given-names">Mohit</div> <div class="surname">Bansal</div></span></span>. <div class="year">2024b</div>. <div class="article-title">Reconcile: Round-table conference improves reasoning via consensus among diverse LLMs</div>. <div class="source">arXiv preprint arXiv: 2309.13007</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Reconcile%3A%20Round-table%20conference%20improves%20reasoning%20via%20consensus%20among%20diverse%20LLMs&amp;author=Justin%20Chih-Yao%20Chen&amp;author=Swarnadeep%20Saha&amp;author=Mohit%20Bansal&amp;publication_year=2024b&amp;journal=arXiv%20preprint%20arXiv%3A%202309.13007&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib13" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Pinzhen</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Zhicheng</div> <div class="surname">Guo</div></span>, <span class="name string-name"><div class="given-names">Barry</div> <div class="surname">Haddow</div></span>, and <span class="name string-name"><div class="given-names">Kenneth</div> <div class="surname">Heafield</div></span></span>. <div class="year">2023b</div>. <div class="article-title">Iterative translation refinement with large language models</div>. <div class="source">arXiv preprint arXiv:2306.03856</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Iterative%20translation%20refinement%20with%20large%20language%20models&amp;author=Pinzhen%20Chen&amp;author=Zhicheng%20Guo&amp;author=Barry%20Haddow&amp;author=Kenneth%20Heafield&amp;publication_year=2023b&amp;journal=arXiv%20preprint%20arXiv%3A2306.03856&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib14" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Xinyun</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Renat</div> <div class="surname">Aksitov</div></span>, <span class="name string-name"><div class="given-names">Uri</div> <div class="surname">Alon</div></span>, <span class="name string-name"><div class="given-names">Jie</div> <div class="surname">Ren</div></span>, <span class="name string-name"><div class="given-names">Kefan</div> <div class="surname">Xiao</div></span>, <span class="name string-name"><div class="given-names">Pengcheng</div> <div class="surname">Yin</div></span>, <span class="name string-name"><div class="given-names">Sushant</div> <div class="surname">Prakash</div></span>, <span class="name string-name"><div class="given-names">Charles</div> <div class="surname">Sutton</div></span>, <span class="name string-name"><div class="given-names">Xuezhi</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">Denny</div> <div class="surname">Zhou</div></span></span>. <div class="year">2024c</div>. <div class="article-title">Universal self-consistency for large language models</div>. In <div class="source">ICML 2024 Workshop on In-Context Learning</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Universal%20self-consistency%20for%20large%20language%20models&amp;author=Xinyun%20Chen&amp;author=Renat%20Aksitov&amp;author=Uri%20Alon&amp;author=Jie%20Ren&amp;author=Kefan%20Xiao&amp;author=Pengcheng%20Yin&amp;author=Sushant%20Prakash&amp;author=Charles%20Sutton&amp;author=Xuezhi%20Wang&amp;author=Denny%20Zhou&amp;publication_year=2024c&amp;journal=ICML%202024%20Workshop%20on%20In-Context%20Learning&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib15" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Xinyun</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Maxwell</div> <div class="surname">Lin</div></span>, <span class="name string-name"><div class="given-names">Nathanael</div> <div class="surname">Schärli</div></span>, and <span class="name string-name"><div class="given-names">Denny</div> <div class="surname">Zhou</div></span></span>. <div class="year">2024d</div>. <div class="article-title">Teaching large language models to self-debug</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Teaching%20large%20language%20models%20to%20self-debug&amp;author=Xinyun%20Chen&amp;author=Maxwell%20Lin&amp;author=Nathanael%20Sch%C3%A4rli&amp;author=Denny%20Zhou&amp;publication_year=2024d&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib16" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Zimin</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Steve</div> <div class="surname">Kommrusch</div></span>, <span class="name string-name"><div class="given-names">Michele</div> <div class="surname">Tufano</div></span>, <span class="name string-name"><div class="given-names">Louis-Noël</div> <div class="surname">Pouchet</div></span>, <span class="name string-name"><div class="given-names">Denys</div> <div class="surname">Poshyvanyk</div></span>, and <span class="name string-name"><div class="given-names">Martin</div> <div class="surname">Monperrus</div></span></span>. <div class="year">2021</div>. <div class="article-title">Sequencer: Sequence-to-sequence learning for end-to-end program repair</div>. <div class="source">IEEE Transactions on Software Engineering</div>, <div class="volume">47</div>(<div class="issue">9</div>):<div class="fpage">1943</div>–<div class="lpage">1959</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1109/TSE.2019.2940179" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1109/TSE.2019.2940179</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Sequencer%3A%20Sequence-to-sequence%20learning%20for%20end-to-end%20program%20repair&amp;author=Zimin%20Chen&amp;author=Steve%20Kommrusch&amp;author=Michele%20Tufano&amp;author=Louis-No%C3%ABl%20Pouchet&amp;author=Denys%20Poshyvanyk&amp;author=Martin%20Monperrus&amp;publication_year=2021&amp;journal=IEEE%20Transactions%20on%20Software%20Engineering&amp;volume=47&amp;pages=1943-1959" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib17" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">I-Chun</div> <div class="surname">Chern</div></span>, <span class="name string-name"><div class="given-names">Steffi</div> <div class="surname">Chern</div></span>, <span class="name string-name"><div class="given-names">Shiqi</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Weizhe</div> <div class="surname">Yuan</div></span>, <span class="name string-name"><div class="given-names">Kehua</div> <div class="surname">Feng</div></span>, <span class="name string-name"><div class="given-names">Chunting</div> <div class="surname">Zhou</div></span>, <span class="name string-name"><div class="given-names">Junxian</div> <div class="surname">He</div></span>, <span class="name string-name"><div class="given-names">Graham</div> <div class="surname">Neubig</div></span>, and <span class="name string-name"><div class="given-names">Pengfei</div> <div class="surname">Liu</div></span></span>. <div class="year">2023</div>. <div class="article-title">Factool: Factuality detection in generative AI – a tool augmented framework for multi-task and multi-domain scenarios</div>. <div class="source">arXiv preprint arXiv:2307.13528</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Factool%3A%20Factuality%20detection%20in%20generative%20AI%20%E2%80%93%20a%20tool%20augmented%20framework%20for%20multi-task%20and%20multi-domain%20scenarios&amp;author=I-Chun%20Chern&amp;author=Steffi%20Chern&amp;author=Shiqi%20Chen&amp;author=Weizhe%20Yuan&amp;author=Kehua%20Feng&amp;author=Chunting%20Zhou&amp;author=Junxian%20He&amp;author=Graham%20Neubig&amp;author=Pengfei%20Liu&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2307.13528&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib18" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Cheng-Han</div> <div class="surname">Chiang</div></span> and <span class="name string-name"><div class="given-names">Hung-yi</div> <div class="surname">Lee</div></span></span>. <div class="year">2023</div>. <div class="article-title">Can large language models be an alternative to human evaluations?</div> In <div class="source">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">15607</div>–<div class="lpage">15631</div>, <div class="publisher-loc">Toronto, Canada</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.acl-long.870" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.acl-long.870</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Can%20large%20language%20models%20be%20an%20alternative%20to%20human%20evaluations%3F&amp;author=Cheng-Han%20Chiang&amp;author=Hung-yi%20Lee&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2061st%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib19" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Karl</div> <div class="surname">Cobbe</div></span>, <span class="name string-name"><div class="given-names">Vineet</div> <div class="surname">Kosaraju</div></span>, <span class="name string-name"><div class="given-names">Mohammad</div> <div class="surname">Bavarian</div></span>, <span class="name string-name"><div class="given-names">Mark</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Heewoo</div> <div class="surname">Jun</div></span>, <span class="name string-name"><div class="given-names">Lukasz</div> <div class="surname">Kaiser</div></span>, <span class="name string-name"><div class="given-names">Matthias</div> <div class="surname">Plappert</div></span>, <span class="name string-name"><div class="given-names">Jerry</div> <div class="surname">Tworek</div></span>, <span class="name string-name"><div class="given-names">Jacob</div> <div class="surname">Hilton</div></span>, <span class="name string-name"><div class="given-names">Reiichiro</div> <div class="surname">Nakano</div></span>, <span class="name string-name"><div class="given-names">Christopher</div> <div class="surname">Hesse</div></span>, and <span class="name string-name"><div class="given-names">John</div> <div class="surname">Schulman</div></span></span>. <div class="year">2021</div>. <div class="article-title">Training verifiers to solve math word problems</div>. <div class="source">arXiv preprint arXiv:2110.14168</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Training%20verifiers%20to%20solve%20math%20word%20problems&amp;author=Karl%20Cobbe&amp;author=Vineet%20Kosaraju&amp;author=Mohammad%20Bavarian&amp;author=Mark%20Chen&amp;author=Heewoo%20Jun&amp;author=Lukasz%20Kaiser&amp;author=Matthias%20Plappert&amp;author=Jerry%20Tworek&amp;author=Jacob%20Hilton&amp;author=Reiichiro%20Nakano&amp;author=Christopher%20Hesse&amp;author=John%20Schulman&amp;publication_year=2021&amp;journal=arXiv%20preprint%20arXiv%3A2110.14168&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib20" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Roi</div> <div class="surname">Cohen</div></span>, <span class="name string-name"><div class="given-names">May</div> <div class="surname">Hamri</div></span>, <span class="name string-name"><div class="given-names">Mor</div> <div class="surname">Geva</div></span>, and <span class="name string-name"><div class="given-names">Amir</div> <div class="surname">Globerson</div></span></span>. <div class="year">2023</div>. <div class="article-title">LM vs LM: Detecting factual errors via cross examination</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">12621</div>–<div class="lpage">12640</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.778" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.778</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=LM%20vs%20LM%3A%20Detecting%20factual%20errors%20via%20cross%20examination&amp;author=Roi%20Cohen&amp;author=May%20Hamri&amp;author=Mor%20Geva&amp;author=Amir%20Globerson&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib21" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Antonia</div> <div class="surname">Creswell</div></span> and <span class="name string-name"><div class="given-names">Murray</div> <div class="surname">Shanahan</div></span></span>. <div class="year">2022</div>. <div class="article-title">Faithful reasoning using large language models</div>. <div class="source">arXiv preprint arXiv:2208.14271</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Faithful%20reasoning%20using%20large%20language%20models&amp;author=Antonia%20Creswell&amp;author=Murray%20Shanahan&amp;publication_year=2022&amp;journal=arXiv%20preprint%20arXiv%3A2208.14271&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib22" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Shehzaad</div> <div class="surname">Dhuliawala</div></span>, <span class="name string-name"><div class="given-names">Mojtaba</div> <div class="surname">Komeili</div></span>, <span class="name string-name"><div class="surname">Jing</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Roberta</div> <div class="surname">Raileanu</div></span>, <span class="name string-name"><div class="given-names">Xian</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Asli</div> <div class="surname">Celikyilmaz</div></span>, and <span class="name string-name"><div class="given-names">Jason</div> <div class="surname">Weston</div></span></span>. <div class="year">2023</div>. <div class="article-title">Chain-of-verification reduces hallucination in large language models</div>. <div class="source">arXiv preprint arXiv:2309.11495</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Chain-of-verification%20reduces%20hallucination%20in%20large%20language%20models&amp;author=Shehzaad%20Dhuliawala&amp;author=Mojtaba%20Komeili&amp;author=Xu%20Jing&amp;author=Roberta%20Raileanu&amp;author=Xian%20Li&amp;author=Asli%20Celikyilmaz&amp;author=Jason%20Weston&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2309.11495&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib23" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="surname">Yilun</div> <div class="given-names">Du</div></span>, <span class="name string-name"><div class="given-names">Shuang</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Antonio</div> <div class="surname">Torralba</div></span>, <span class="name string-name"><div class="given-names">Joshua B.</div> <div class="surname">Tenenbaum</div></span>, and <span class="name string-name"><div class="given-names">Igor</div> <div class="surname">Mordatch</div></span></span>. <div class="year">2023</div>. <div class="article-title">Improving factuality and reasoning in language models through multiagent debate</div>. <div class="source">arXiv preprint arXiv:2305.14325</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Improving%20factuality%20and%20reasoning%20in%20language%20models%20through%20multiagent%20debate&amp;author=Du%20Yilun&amp;author=Shuang%20Li&amp;author=Antonio%20Torralba&amp;author=Joshua%20B.%20Tenenbaum&amp;author=Igor%20Mordatch&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2305.14325&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib24" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Esin</div> <div class="surname">Durmus</div></span>, <span class="name string-name"><div class="surname">He</div> <div class="given-names">He</div></span>, and <span class="name string-name"><div class="given-names">Mona</div> <div class="surname">Diab</div></span></span>. <div class="year">2020</div>. <div class="article-title">FEQA: A question answering evaluation framework for faithfulness assessment in abstractive summarization</div>. In <div class="source">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</div>, pages <div class="fpage">5055</div>–<div class="lpage">5070</div>, <div class="comment">Online</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2020.acl-main.454" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2020.acl-main.454</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=FEQA%3A%20A%20question%20answering%20evaluation%20framework%20for%20faithfulness%20assessment%20in%20abstractive%20summarization&amp;author=Esin%20Durmus&amp;author=He%20He&amp;author=Mona%20Diab&amp;publication_year=2020&amp;book=Proceedings%20of%20the%2058th%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib25" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Mohamed</div> <div class="surname">Elaraby</div></span>, <span class="name string-name"><div class="surname">Mengyin</div> <div class="given-names">Lu</div></span>, <span class="name string-name"><div class="given-names">Jacob</div> <div class="surname">Dunn</div></span>, <span class="name string-name"><div class="given-names">Xueying</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Yu</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Shizhu</div> <div class="surname">Liu</div></span>, <span class="name string-name"><div class="given-names">Pingchuan</div> <div class="surname">Tian</div></span>, <span class="name string-name"><div class="given-names">Yuping</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">Yuxuan</div> <div class="surname">Wang</div></span></span>. <div class="year">2023</div>. <div class="article-title">Halo: Estimation and reduction of hallucinations in open-source weak large language models</div>. <div class="source">arXiv preprint arXiv:2308 .11764</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Halo%3A%20Estimation%20and%20reduction%20of%20hallucinations%20in%20open-source%20weak%20large%20language%20models&amp;author=Mohamed%20Elaraby&amp;author=Lu%20Mengyin&amp;author=Jacob%20Dunn&amp;author=Xueying%20Zhang&amp;author=Yu%20Wang&amp;author=Shizhu%20Liu&amp;author=Pingchuan%20Tian&amp;author=Yuping%20Wang&amp;author=Yuxuan%20Wang&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2308%20.11764&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib26" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Shangbin</div> <div class="surname">Feng</div></span>, <span class="name string-name"><div class="given-names">Chan Young</div> <div class="surname">Park</div></span>, <span class="name string-name"><div class="given-names">Yuhan</div> <div class="surname">Liu</div></span>, and <span class="name string-name"><div class="given-names">Yulia</div> <div class="surname">Tsvetkov</div></span></span>. <div class="year">2023</div>. <div class="article-title">From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair NLP models</div>. In <div class="source">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">11737</div>–<div class="lpage">11762</div>, <div class="publisher-loc">Toronto, Canada</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.acl-long.656" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.acl-long.656</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=From%20pretraining%20data%20to%20language%20models%20to%20downstream%20tasks%3A%20Tracking%20the%20trails%20of%20political%20biases%20leading%20to%20unfair%20NLP%20models&amp;author=Shangbin%20Feng&amp;author=Chan%20Young%20Park&amp;author=Yuhan%20Liu&amp;author=Yulia%20Tsvetkov&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2061st%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib27" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Emily</div> <div class="surname">First</div></span>, <span class="name string-name"><div class="given-names">Markus</div> <div class="surname">Rabe</div></span>, <span class="name string-name"><div class="given-names">Talia</div> <div class="surname">Ringer</div></span>, and <span class="name string-name"><div class="given-names">Yuriy</div> <div class="surname">Brun</div></span></span>. <div class="year">2023</div>. <div class="article-title">Baldur: Whole-proof generation and repair with large language models</div>. In <div class="source">Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering</div>, <div class="comment">ESEC/FSE 2023</div>, pages <div class="fpage">1229</div>–<div class="lpage">1241</div>, <div class="publisher-loc">New York, NY, USA</div>. <div class="publisher-name">Association for Computing Machinery</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1145/3611643.3616243" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1145/3611643.3616243</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Baldur%3A%20Whole-proof%20generation%20and%20repair%20with%20large%20language%20models&amp;author=Emily%20First&amp;author=Markus%20Rabe&amp;author=Talia%20Ringer&amp;author=Yuriy%20Brun&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2031st%20ACM%20Joint%20European%20Software%20Engineering%20Conference%20and%20Symposium%20on%20the%20Foundations%20of%20Software%20Engineering" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib28" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="surname">Jinlan</div> <div class="given-names">Fu</div></span>, <span class="name string-name"><div class="given-names">See-Kiong</div> <div class="surname">Ng</div></span>, <span class="name string-name"><div class="given-names">Zhengbao</div> <div class="surname">Jiang</div></span>, and <span class="name string-name"><div class="given-names">Pengfei</div> <div class="surname">Liu</div></span></span>. <div class="year">2024</div>. <div class="article-title">GPTScore: Evaluate as you desire</div>. In <div class="source">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</div>, pages <div class="fpage">6556</div>–<div class="lpage">6576</div>, <div class="publisher-loc">Mexico City, Mexico</div>. <div class="publisher-name">Association for Computational Linguistics</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=GPTScore%3A%20Evaluate%20as%20you%20desire&amp;author=Fu%20Jinlan&amp;author=See-Kiong%20Ng&amp;author=Zhengbao%20Jiang&amp;author=Pengfei%20Liu&amp;publication_year=2024&amp;book=Proceedings%20of%20the%202024%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib29" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Luyu</div> <div class="surname">Gao</div></span>, <span class="name string-name"><div class="given-names">Zhuyun</div> <div class="surname">Dai</div></span>, <span class="name string-name"><div class="given-names">Panupong</div> <div class="surname">Pasupat</div></span>, <span class="name string-name"><div class="given-names">Anthony</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Arun Tejasvi</div> <div class="surname">Chaganty</div></span>, <span class="name string-name"><div class="given-names">Yicheng</div> <div class="surname">Fan</div></span>, <span class="name string-name"><div class="given-names">Vincent</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="surname">Ni</div> <div class="given-names">Lao</div></span>, <span class="name string-name"><div class="given-names">Hongrae</div> <div class="surname">Lee</div></span>, <span class="name string-name"><div class="given-names">Da-Cheng</div> <div class="surname">Juan</div></span>, and <span class="name string-name"><div class="given-names">Kelvin</div> <div class="surname">Guu</div></span></span>. <div class="year">2023</div>. <div class="article-title">RARR: Researching and revising what language models say, using language models</div>. In <div class="source">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">16477</div>–<div class="lpage">16508</div>, <div class="publisher-loc">Toronto, Canada</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.acl-long.910" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.acl-long.910</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=RARR%3A%20Researching%20and%20revising%20what%20language%20models%20say%2C%20using%20language%20models&amp;author=Luyu%20Gao&amp;author=Zhuyun%20Dai&amp;author=Panupong%20Pasupat&amp;author=Anthony%20Chen&amp;author=Arun%20Tejasvi%20Chaganty&amp;author=Yicheng%20Fan&amp;author=Vincent%20Zhao&amp;author=Lao%20Ni&amp;author=Hongrae%20Lee&amp;author=Da-Cheng%20Juan&amp;author=Kelvin%20Guu&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2061st%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib30" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jiaxin</div> <div class="surname">Ge</div></span>, <span class="name string-name"><div class="given-names">Sanjay</div> <div class="surname">Subramanian</div></span>, <span class="name string-name"><div class="given-names">Trevor</div> <div class="surname">Darrell</div></span>, and <span class="name string-name"><div class="given-names">Boyi</div> <div class="surname">Li</div></span></span>. <div class="year">2023</div>. <div class="article-title">From wrong to right: A recursive approach towards vision-language explanation</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">1173</div>–<div class="lpage">1185</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.75" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.75</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=From%20wrong%20to%20right%3A%20A%20recursive%20approach%20towards%20vision-language%20explanation&amp;author=Jiaxin%20Ge&amp;author=Sanjay%20Subramanian&amp;author=Trevor%20Darrell&amp;author=Boyi%20Li&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib31" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Zelalem</div> <div class="surname">Gero</div></span>, <span class="name string-name"><div class="given-names">Chandan</div> <div class="surname">Singh</div></span>, <span class="name string-name"><div class="given-names">Hao</div> <div class="surname">Cheng</div></span>, <span class="name string-name"><div class="given-names">Tristan</div> <div class="surname">Naumann</div></span>, <span class="name string-name"><div class="given-names">Michel</div> <div class="surname">Galley</div></span>, <span class="name string-name"><div class="given-names">Jianfeng</div> <div class="surname">Gao</div></span>, and <span class="name string-name"><div class="given-names">Hoifung</div> <div class="surname">Poon</div></span></span>. <div class="year">2023</div>. <div class="article-title">Self-verification improves few-shot clinical information extraction</div>. In <div class="source">ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-verification%20improves%20few-shot%20clinical%20information%20extraction&amp;author=Zelalem%20Gero&amp;author=Chandan%20Singh&amp;author=Hao%20Cheng&amp;author=Tristan%20Naumann&amp;author=Michel%20Galley&amp;author=Jianfeng%20Gao&amp;author=Hoifung%20Poon&amp;publication_year=2023&amp;journal=ICML%203rd%20Workshop%20on%20Interpretable%20Machine%20Learning%20in%20Healthcare%20%28IMLH%29&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib32" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Zhibin</div> <div class="surname">Gou</div></span>, <span class="name string-name"><div class="given-names">Zhihong</div> <div class="surname">Shao</div></span>, <span class="name string-name"><div class="given-names">Yeyun</div> <div class="surname">Gong</div></span>, <span class="name string-name"><div class="given-names">yelong</div> <div class="surname">shen</div></span>, <span class="name string-name"><div class="given-names">Yujiu</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="given-names">Nan</div> <div class="surname">Duan</div></span>, and <span class="name string-name"><div class="given-names">Weizhu</div> <div class="surname">Chen</div></span></span>. <div class="year">2024</div>. <div class="article-title">CRITIC: Large language models can self-correct with tool-interactive critiquing</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=CRITIC%3A%20Large%20language%20models%20can%20self-correct%20with%20tool-interactive%20critiquing&amp;author=Zhibin%20Gou&amp;author=Zhihong%20Shao&amp;author=Yeyun%20Gong&amp;author=yelong%20shen&amp;author=Yujiu%20Yang&amp;author=Nan%20Duan&amp;author=Weizhu%20Chen&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib33" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Caglar</div> <div class="surname">Gulcehre</div></span>, <span class="name string-name"><div class="given-names">Tom Le</div> <div class="surname">Paine</div></span>, <span class="name string-name"><div class="given-names">Srivatsan</div> <div class="surname">Srinivasan</div></span>, <span class="name string-name"><div class="given-names">Ksenia</div> <div class="surname">Konyushkova</div></span>, <span class="name string-name"><div class="given-names">Lotte</div> <div class="surname">Weerts</div></span>, <span class="name string-name"><div class="given-names">Abhishek</div> <div class="surname">Sharma</div></span>, <span class="name string-name"><div class="given-names">Aditya</div> <div class="surname">Siddhant</div></span>, <span class="name string-name"><div class="given-names">Alex</div> <div class="surname">Ahern</div></span>, <span class="name string-name"><div class="given-names">Miaosen</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="surname">Chenjie</div> <div class="given-names">Gu</div></span>, <span class="name string-name"><div class="given-names">Wolfgang</div> <div class="surname">Macherey</div></span>, <span class="name string-name"><div class="given-names">Arnaud</div> <div class="surname">Doucet</div></span>, <span class="name string-name"><div class="given-names">Orhan</div> <div class="surname">Firat</div></span>, and <span class="name string-name"><div class="given-names">Nando</div> <div class="surname">de Freitas</div></span></span>. <div class="year">2023</div>. <div class="article-title">Reinforced self-training (rest) for language modeling</div>. <div class="source">arXiv preprint arXiv:2308.08998</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Reinforced%20self-training%20%28rest%29%20for%20language%20modeling&amp;author=Caglar%20Gulcehre&amp;author=Tom%20Le%20Paine&amp;author=Srivatsan%20Srinivasan&amp;author=Ksenia%20Konyushkova&amp;author=Lotte%20Weerts&amp;author=Abhishek%20Sharma&amp;author=Aditya%20Siddhant&amp;author=Alex%20Ahern&amp;author=Miaosen%20Wang&amp;author=Gu%20Chenjie&amp;author=Wolfgang%20Macherey&amp;author=Arnaud%20Doucet&amp;author=Orhan%20Firat&amp;author=Nando%20de%20Freitas&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2308.08998&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib34" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Rahul</div> <div class="surname">Gupta</div></span>, <span class="name string-name"><div class="given-names">Soham</div> <div class="surname">Pal</div></span>, <span class="name string-name"><div class="given-names">Aditya</div> <div class="surname">Kanade</div></span>, and <span class="name string-name"><div class="given-names">Shirish</div> <div class="surname">Shevade</div></span></span>. <div class="year">2017</div>. <div class="article-title">Deepfix: Fixing common c language errors by deep learning</div>. <div class="source">Proceedings of the AAAI Conference on Artificial Intelligence</div>, <div class="volume">31</div>(<div class="issue">1</div>). <div class="pub-id-doi"><a href="https://doi.org/10.1609/aaai.v31i1.10742" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1609/aaai.v31i1.10742</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Deepfix%3A%20Fixing%20common%20c%20language%20errors%20by%20deep%20learning&amp;author=Rahul%20Gupta&amp;author=Soham%20Pal&amp;author=Aditya%20Kanade&amp;author=Shirish%20Shevade&amp;publication_year=2017&amp;journal=Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence&amp;volume=31&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib35" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Haixia</div> <div class="surname">Han</div></span>, <span class="name string-name"><div class="given-names">Jiaqing</div> <div class="surname">Liang</div></span>, <span class="name string-name"><div class="given-names">Jie</div> <div class="surname">Shi</div></span>, <span class="name string-name"><div class="given-names">Qianyu</div> <div class="surname">He</div></span>, and <span class="name string-name"><div class="given-names">Yanghua</div> <div class="surname">Xiao</div></span></span>. <div class="year">2024</div>. <div class="article-title">Small language model can self-correct</div>. <div class="source">Proceedings of the AAAI Conference on Artificial Intelligence</div>, <div class="volume">38</div>(<div class="issue">16</div>):<div class="fpage">18162</div>–<div class="lpage">18170</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1609/aaai.v38i16.29774" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1609/aaai.v38i16.29774</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Small%20language%20model%20can%20self-correct&amp;author=Haixia%20Han&amp;author=Jiaqing%20Liang&amp;author=Jie%20Shi&amp;author=Qianyu%20He&amp;author=Yanghua%20Xiao&amp;publication_year=2024&amp;journal=Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence&amp;volume=38&amp;pages=18162-18170" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib36" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Shibo</div> <div class="surname">Hao</div></span>, <span class="name string-name"><div class="surname">Yi</div> <div class="given-names">Gu</div></span>, <span class="name string-name"><div class="given-names">Haodi</div> <div class="surname">Ma</div></span>, <span class="name string-name"><div class="given-names">Joshua</div> <div class="surname">Hong</div></span>, <span class="name string-name"><div class="given-names">Zhen</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Daisy</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="surname">Zhiting</div> <div class="given-names">Hu</div></span></span>. <div class="year">2023</div>. <div class="article-title">Reasoning with language model is planning with world model</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">8154</div>–<div class="lpage">8173</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.507" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.507</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Reasoning%20with%20language%20model%20is%20planning%20with%20world%20model&amp;author=Shibo%20Hao&amp;author=Gu%20Yi&amp;author=Haodi%20Ma&amp;author=Joshua%20Hong&amp;author=Zhen%20Wang&amp;author=Daisy%20Wang&amp;author=Hu%20Zhiting&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib37" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ruixin</div> <div class="surname">Hong</div></span>, <span class="name string-name"><div class="given-names">Hongming</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Xinyu</div> <div class="surname">Pang</div></span>, <span class="name string-name"><div class="surname">Dong</div> <div class="given-names">Yu</div></span>, and <span class="name string-name"><div class="given-names">Changshui</div> <div class="surname">Zhang</div></span></span>. <div class="year">2024</div>. <div class="article-title">A closer look at the self-verification abilities of large language models in logical reasoning</div>. In <div class="source">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</div>, pages <div class="fpage">900</div>–<div class="lpage">925</div>, <div class="publisher-loc">Mexico City, Mexico</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.naacl-long.52" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.naacl-long.52</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=A%20closer%20look%20at%20the%20self-verification%20abilities%20of%20large%20language%20models%20in%20logical%20reasoning&amp;author=Ruixin%20Hong&amp;author=Hongming%20Zhang&amp;author=Xinyu%20Pang&amp;author=Yu%20Dong&amp;author=Changshui%20Zhang&amp;publication_year=2024&amp;book=Proceedings%20of%20the%202024%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib38" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jiaxin</div> <div class="surname">Huang</div></span>, <span class="name string-name"><div class="surname">Shixiang</div> <div class="given-names">Gu</div></span>, <span class="name string-name"><div class="surname">Le</div> <div class="given-names">Hou</div></span>, <span class="name string-name"><div class="surname">Yuexin</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="given-names">Xuezhi</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="surname">Hongkun</div> <div class="given-names">Yu</div></span>, and <span class="name string-name"><div class="given-names">Jiawei</div> <div class="surname">Han</div></span></span>. <div class="year">2023</div>. <div class="article-title">Large language models can self-improve</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">1051</div>–<div class="lpage">1068</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.67" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.67</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Large%20language%20models%20can%20self-improve&amp;author=Jiaxin%20Huang&amp;author=Gu%20Shixiang&amp;author=Hou%20Le&amp;author=Wu%20Yuexin&amp;author=Xuezhi%20Wang&amp;author=Yu%20Hongkun&amp;author=Jiawei%20Han&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib39" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jie</div> <div class="surname">Huang</div></span>, <span class="name string-name"><div class="given-names">Xinyun</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Swaroop</div> <div class="surname">Mishra</div></span>, <span class="name string-name"><div class="given-names">Huaixiu Steven</div> <div class="surname">Zheng</div></span>, <span class="name string-name"><div class="surname">Adams Wei</div> <div class="given-names">Yu</div></span>, <span class="name string-name"><div class="given-names">Xinying</div> <div class="surname">Song</div></span>, and <span class="name string-name"><div class="given-names">Denny</div> <div class="surname">Zhou</div></span></span>. <div class="year">2024a</div>. <div class="article-title">Large language models cannot self-correct reasoning yet</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Large%20language%20models%20cannot%20self-correct%20reasoning%20yet&amp;author=Jie%20Huang&amp;author=Xinyun%20Chen&amp;author=Swaroop%20Mishra&amp;author=Huaixiu%20Steven%20Zheng&amp;author=Yu%20Adams%20Wei&amp;author=Xinying%20Song&amp;author=Denny%20Zhou&amp;publication_year=2024a&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib40" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Kung-Hsiang</div> <div class="surname">Huang</div></span>, <span class="name string-name"><div class="given-names">Mingyang</div> <div class="surname">Zhou</div></span>, <span class="name string-name"><div class="given-names">Hou Pong</div> <div class="surname">Chan</div></span>, <span class="name string-name"><div class="surname">Yi</div> <div class="given-names">Fung</div></span>, <span class="name string-name"><div class="given-names">Zhenhailong</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Lingyu</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Shih-Fu</div> <div class="surname">Chang</div></span>, and <span class="name string-name"><div class="given-names">Heng</div> <div class="surname">Ji</div></span></span>. <div class="year">2024b</div>. <div class="article-title">Do LVLMs understand charts? Analyzing and correcting factual errors in chart captioning</div>. In <div class="source">Findings of the Association for Computational Linguistics ACL 2024</div>, pages <div class="fpage">730</div>–<div class="lpage">749</div>, <div class="publisher-loc">Bangkok, Thailand and virtual meeting</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.findings-acl.41" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.findings-acl.41</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Do%20LVLMs%20understand%20charts%3F%20Analyzing%20and%20correcting%20factual%20errors%20in%20chart%20captioning&amp;author=Kung-Hsiang%20Huang&amp;author=Mingyang%20Zhou&amp;author=Hou%20Pong%20Chan&amp;author=Fung%20Yi&amp;author=Zhenhailong%20Wang&amp;author=Lingyu%20Zhang&amp;author=Shih-Fu%20Chang&amp;author=Heng%20Ji&amp;publication_year=2024b&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%20ACL%202024" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib41" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Robert</div> <div class="surname">Iv</div></span>, <span class="name string-name"><div class="given-names">Alexandre</div> <div class="surname">Passos</div></span>, <span class="name string-name"><div class="given-names">Sameer</div> <div class="surname">Singh</div></span>, and <span class="name string-name"><div class="given-names">Ming-Wei</div> <div class="surname">Chang</div></span></span>. <div class="year">2022</div>. <div class="article-title">FRUIT: Faithfully reflecting updated information in text</div>. In <div class="source">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</div>, pages <div class="fpage">3670</div>–<div class="lpage">3686</div>, <div class="publisher-loc">Seattle, United States</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2022.naacl-main.269" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2022.naacl-main.269</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=FRUIT%3A%20Faithfully%20reflecting%20updated%20information%20in%20text&amp;author=Robert%20Iv&amp;author=Alexandre%20Passos&amp;author=Sameer%20Singh&amp;author=Ming-Wei%20Chang&amp;publication_year=2022&amp;book=Proceedings%20of%20the%202022%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib42" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Dongwei</div> <div class="surname">Jiang</div></span>, <span class="name string-name"><div class="given-names">Jingyu</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Orion</div> <div class="surname">Weller</div></span>, <span class="name string-name"><div class="given-names">Nathaniel</div> <div class="surname">Weir</div></span>, <span class="name string-name"><div class="given-names">Benjamin</div> <div class="surname">Van Durme</div></span>, and <span class="name string-name"><div class="given-names">Daniel</div> <div class="surname">Khashabi</div></span></span>. <div class="year">2024</div>. <div class="article-title">Self-[in]correct: Llms struggle with refining self-generated responses</div>. <div class="source">arXiv preprint arXiv:2404.04298</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-%5Bin%5Dcorrect%3A%20Llms%20struggle%20with%20refining%20self-generated%20responses&amp;author=Dongwei%20Jiang&amp;author=Jingyu%20Zhang&amp;author=Orion%20Weller&amp;author=Nathaniel%20Weir&amp;author=Benjamin%20Van%20Durme&amp;author=Daniel%20Khashabi&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A2404.04298&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib43" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Shuyang</div> <div class="surname">Jiang</div></span>, <span class="name string-name"><div class="given-names">Yuhao</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">Yu</div> <div class="surname">Wang</div></span></span>. <div class="year">2023a</div>. <div class="article-title">Selfevolve: A code evolution framework via large language models</div>. <div class="source">arXiv preprint arXiv:2306.02907</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Selfevolve%3A%20A%20code%20evolution%20framework%20via%20large%20language%20models&amp;author=Shuyang%20Jiang&amp;author=Yuhao%20Wang&amp;author=Yu%20Wang&amp;publication_year=2023a&amp;journal=arXiv%20preprint%20arXiv%3A2306.02907&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib44" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Zhengbao</div> <div class="surname">Jiang</div></span>, <span class="name string-name"><div class="surname">Frank</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Luyu</div> <div class="surname">Gao</div></span>, <span class="name string-name"><div class="given-names">Zhiqing</div> <div class="surname">Sun</div></span>, <span class="name string-name"><div class="given-names">Qian</div> <div class="surname">Liu</div></span>, <span class="name string-name"><div class="given-names">Jane</div> <div class="surname">Dwivedi-Yu</div></span>, <span class="name string-name"><div class="given-names">Yiming</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="given-names">Jamie</div> <div class="surname">Callan</div></span>, and <span class="name string-name"><div class="given-names">Graham</div> <div class="surname">Neubig</div></span></span>. <div class="year">2023b</div>. <div class="article-title">Active retrieval augmented generation</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">7969</div>–<div class="lpage">7992</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.495" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.495</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Active%20retrieval%20augmented%20generation&amp;author=Zhengbao%20Jiang&amp;author=Xu%20Frank&amp;author=Luyu%20Gao&amp;author=Zhiqing%20Sun&amp;author=Qian%20Liu&amp;author=Jane%20Dwivedi-Yu&amp;author=Yiming%20Yang&amp;author=Jamie%20Callan&amp;author=Graham%20Neubig&amp;publication_year=2023b&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib45" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jaehun</div> <div class="surname">Jung</div></span>, <span class="name string-name"><div class="given-names">Lianhui</div> <div class="surname">Qin</div></span>, <span class="name string-name"><div class="given-names">Sean</div> <div class="surname">Welleck</div></span>, <span class="name string-name"><div class="given-names">Faeze</div> <div class="surname">Brahman</div></span>, <span class="name string-name"><div class="given-names">Chandra</div> <div class="surname">Bhagavatula</div></span>, <span class="name string-name"><div class="given-names">Ronan Le</div> <div class="surname">Bras</div></span>, and <span class="name string-name"><div class="given-names">Yejin</div> <div class="surname">Choi</div></span></span>. <div class="year">2022</div>. <div class="article-title">Maieutic prompting: Logically consistent reasoning with recursive explanations</div>. In <div class="source">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">1266</div>–<div class="lpage">1279</div>, <div class="publisher-loc">Abu Dhabi, United Arab Emirates</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2022.emnlp-main.82" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2022.emnlp-main.82</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Maieutic%20prompting%3A%20Logically%20consistent%20reasoning%20with%20recursive%20explanations&amp;author=Jaehun%20Jung&amp;author=Lianhui%20Qin&amp;author=Sean%20Welleck&amp;author=Faeze%20Brahman&amp;author=Chandra%20Bhagavatula&amp;author=Ronan%20Le%20Bras&amp;author=Yejin%20Choi&amp;publication_year=2022&amp;book=Proceedings%20of%20the%202022%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib46" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ryo</div> <div class="surname">Kamoi</div></span>, <span class="name string-name"><div class="given-names">Sarkar Snigdha Sarathi</div> <div class="surname">Das</div></span>, <span class="name string-name"><div class="given-names">Renze</div> <div class="surname">Lou</div></span>, <span class="name string-name"><div class="given-names">Jihyun Janice</div> <div class="surname">Ahn</div></span>, <span class="name string-name"><div class="given-names">Yilun</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="surname">Xiaoxin</div> <div class="given-names">Lu</div></span>, <span class="name string-name"><div class="given-names">Nan</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Yusen</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Ranran Haoran</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Sujeeth Reddy</div> <div class="surname">Vummanthala</div></span>, <span class="name string-name"><div class="given-names">Salika</div> <div class="surname">Dave</div></span>, <span class="name string-name"><div class="given-names">Shaobo</div> <div class="surname">Qin</div></span>, <span class="name string-name"><div class="given-names">Arman</div> <div class="surname">Cohan</div></span>, <span class="name string-name"><div class="given-names">Wenpeng</div> <div class="surname">Yin</div></span>, and <span class="name string-name"><div class="given-names">Rui</div> <div class="surname">Zhang</div></span></span>. <div class="year">2024</div>. <div class="article-title">Evaluating LLMs at detecting errors in LLM responses</div>. <div class="source">arXiv preprint arXiv:2404.03602</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Evaluating%20LLMs%20at%20detecting%20errors%20in%20LLM%20responses&amp;author=Ryo%20Kamoi&amp;author=Sarkar%20Snigdha%20Sarathi%20Das&amp;author=Renze%20Lou&amp;author=Jihyun%20Janice%20Ahn&amp;author=Yilun%20Zhao&amp;author=Lu%20Xiaoxin&amp;author=Nan%20Zhang&amp;author=Yusen%20Zhang&amp;author=Ranran%20Haoran%20Zhang&amp;author=Sujeeth%20Reddy%20Vummanthala&amp;author=Salika%20Dave&amp;author=Shaobo%20Qin&amp;author=Arman%20Cohan&amp;author=Wenpeng%20Yin&amp;author=Rui%20Zhang&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A2404.03602&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib47" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Dayeon</div> <div class="surname">Ki</div></span> and <span class="name string-name"><div class="given-names">Marine</div> <div class="surname">Carpuat</div></span></span>. <div class="year">2024</div>. <div class="article-title">Guiding large language models to post-edit machine translation with error annotations</div>. In <div class="source">Findings of the Association for Computational Linguistics: NAACL 2024</div>, pages <div class="fpage">4253</div>–<div class="lpage">4273</div>, <div class="publisher-loc">Mexico City, Mexico</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.findings-naacl.265" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.findings-naacl.265</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Guiding%20large%20language%20models%20to%20post-edit%20machine%20translation%20with%20error%20annotations&amp;author=Dayeon%20Ki&amp;author=Marine%20Carpuat&amp;publication_year=2024&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20NAACL%202024" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib48" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Geunwoo</div> <div class="surname">Kim</div></span>, <span class="name string-name"><div class="given-names">Pierre</div> <div class="surname">Baldi</div></span>, and <span class="name string-name"><div class="given-names">Stephen</div> <div class="surname">McAleer</div></span></span>. <div class="year">2023</div>. <div class="article-title">Language models can solve computer tasks</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">36</div>, pages <div class="fpage">39648</div>–<div class="lpage">39677</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Language%20models%20can%20solve%20computer%20tasks&amp;author=Geunwoo%20Kim&amp;author=Pierre%20Baldi&amp;author=Stephen%20McAleer&amp;publication_year=2023&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib49" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Hung</div> <div class="surname">Le</div></span>, <span class="name string-name"><div class="given-names">Yue</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Akhilesh Deepak</div> <div class="surname">Gotmare</div></span>, <span class="name string-name"><div class="given-names">Silvio</div> <div class="surname">Savarese</div></span>, and <span class="name string-name"><div class="given-names">Steven Chu Hong</div> <div class="surname">Hoi</div></span></span>. <div class="year">2022</div>. <div class="article-title">Coderl: Mastering code generation through pretrained models and deep reinforcement learning</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">35</div>, pages <div class="fpage">21314</div>–<div class="lpage">21328</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Coderl%3A%20Mastering%20code%20generation%20through%20pretrained%20models%20and%20deep%20reinforcement%20learning&amp;author=Hung%20Le&amp;author=Yue%20Wang&amp;author=Akhilesh%20Deepak%20Gotmare&amp;author=Silvio%20Savarese&amp;author=Steven%20Chu%20Hong%20Hoi&amp;publication_year=2022&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib50" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Seongyun</div> <div class="surname">Lee</div></span>, <span class="name string-name"><div class="given-names">Sue</div> <div class="surname">Park</div></span>, <span class="name string-name"><div class="given-names">Yongrae</div> <div class="surname">Jo</div></span>, and <span class="name string-name"><div class="given-names">Minjoon</div> <div class="surname">Seo</div></span></span>. <div class="year">2024</div>. <div class="article-title">Volcano: Mitigating multimodal hallucination through self-feedback guided revision</div>. In <div class="source">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</div>, pages <div class="fpage">391</div>–<div class="lpage">404</div>, <div class="publisher-loc">Mexico City, Mexico</div>. <div class="publisher-name">Association for Computational Linguistics</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Volcano%3A%20Mitigating%20multimodal%20hallucination%20through%20self-feedback%20guided%20revision&amp;author=Seongyun%20Lee&amp;author=Sue%20Park&amp;author=Yongrae%20Jo&amp;author=Minjoon%20Seo&amp;publication_year=2024&amp;book=Proceedings%20of%20the%202024%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib51" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Loka</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Zhenhao</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Guangyi</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="given-names">Yixuan</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="surname">Yusheng</div> <div class="given-names">Su</div></span>, <span class="name string-name"><div class="given-names">Eric</div> <div class="surname">Xing</div></span>, and <span class="name string-name"><div class="given-names">Kun</div> <div class="surname">Zhang</div></span></span>. <div class="year">2024a</div>. <div class="article-title">Confidence matters: Revisiting intrinsic self-correction capabilities of large language models</div>. <div class="source">arXiv preprint arXiv:2402 .12563</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Confidence%20matters%3A%20Revisiting%20intrinsic%20self-correction%20capabilities%20of%20large%20language%20models&amp;author=Loka%20Li&amp;author=Zhenhao%20Chen&amp;author=Guangyi%20Chen&amp;author=Yixuan%20Zhang&amp;author=Su%20Yusheng&amp;author=Eric%20Xing&amp;author=Kun%20Zhang&amp;publication_year=2024a&amp;journal=arXiv%20preprint%20arXiv%3A2402%20.12563&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib52" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ruosen</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Teerth</div> <div class="surname">Patel</div></span>, and <span class="name string-name"><div class="surname">Xinya</div> <div class="given-names">Du</div></span></span>. <div class="year">2023</div>. <div class="article-title">Prd: Peer rank and discussion improve large language model based evaluations</div>. <div class="source">arXiv preprint arXiv:2307.02762</div>. <div class="pub-id-doi"><a href="https://doi.org/10.48550/arXiv.2307.02762" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.48550/arXiv.2307.02762</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Prd%3A%20Peer%20rank%20and%20discussion%20improve%20large%20language%20model%20based%20evaluations&amp;author=Ruosen%20Li&amp;author=Teerth%20Patel&amp;author=Du%20Xinya&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2307.02762&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib53" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yanhong</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Chenghao</div> <div class="surname">Yang</div></span>, and <span class="name string-name"><div class="given-names">Allyson</div> <div class="surname">Ettinger</div></span></span>. <div class="year">2024b</div>. <div class="article-title">When hindsight is not 20/20: Testing limits on reflective thinking in large language models</div>. In <div class="source">Findings of the Association for Computational Linguistics: NAACL 2024</div>, pages <div class="fpage">3741</div>–<div class="lpage">3753</div>, <div class="publisher-loc">Mexico City, Mexico</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.findings-naacl.237" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.findings-naacl.237</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=When%20hindsight%20is%20not%2020%2F20%3A%20Testing%20limits%20on%20reflective%20thinking%20in%20large%20language%20models&amp;author=Yanhong%20Li&amp;author=Chenghao%20Yang&amp;author=Allyson%20Ettinger&amp;publication_year=2024b&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20NAACL%202024" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib54" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Tian</div> <div class="surname">Liang</div></span>, <span class="name string-name"><div class="given-names">Zhiwei</div> <div class="surname">He</div></span>, <span class="name string-name"><div class="given-names">Wenxiang</div> <div class="surname">Jiao</div></span>, <span class="name string-name"><div class="given-names">Xing</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Yan</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Rui</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Yujiu</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="surname">Zhaopeng</div> <div class="given-names">Tu</div></span>, and <span class="name string-name"><div class="given-names">Shuming</div> <div class="surname">Shi</div></span></span>. <div class="year">2023</div>. <div class="article-title">Encouraging divergent thinking in large language models through multi-agent debate</div>. <div class="source">arXiv preprint arXiv:2305.19118</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Encouraging%20divergent%20thinking%20in%20large%20language%20models%20through%20multi-agent%20debate&amp;author=Tian%20Liang&amp;author=Zhiwei%20He&amp;author=Wenxiang%20Jiao&amp;author=Xing%20Wang&amp;author=Yan%20Wang&amp;author=Rui%20Wang&amp;author=Yujiu%20Yang&amp;author=Tu%20Zhaopeng&amp;author=Shuming%20Shi&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2305.19118&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib55" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jared</div> <div class="surname">Lichtarge</div></span>, <span class="name string-name"><div class="given-names">Chris</div> <div class="surname">Alberti</div></span>, <span class="name string-name"><div class="given-names">Shankar</div> <div class="surname">Kumar</div></span>, <span class="name string-name"><div class="given-names">Noam</div> <div class="surname">Shazeer</div></span>, <span class="name string-name"><div class="given-names">Niki</div> <div class="surname">Parmar</div></span>, and <span class="name string-name"><div class="given-names">Simon</div> <div class="surname">Tong</div></span></span>. <div class="year">2019</div>. <div class="article-title">Corpora generation for grammatical error correction</div>. In <div class="source">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</div>, pages <div class="fpage">3291</div>–<div class="lpage">3301</div>, <div class="publisher-loc">Minneapolis, Minnesota</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/N19-1333" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/N19-1333</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Corpora%20generation%20for%20grammatical%20error%20correction&amp;author=Jared%20Lichtarge&amp;author=Chris%20Alberti&amp;author=Shankar%20Kumar&amp;author=Noam%20Shazeer&amp;author=Niki%20Parmar&amp;author=Simon%20Tong&amp;publication_year=2019&amp;book=Proceedings%20of%20the%202019%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%2C%20Volume%201%20%28Long%20and%20Short%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib56" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Hunter</div> <div class="surname">Lightman</div></span>, <span class="name string-name"><div class="given-names">Vineet</div> <div class="surname">Kosaraju</div></span>, <span class="name string-name"><div class="given-names">Yuri</div> <div class="surname">Burda</div></span>, <span class="name string-name"><div class="given-names">Harrison</div> <div class="surname">Edwards</div></span>, <span class="name string-name"><div class="given-names">Bowen</div> <div class="surname">Baker</div></span>, <span class="name string-name"><div class="given-names">Teddy</div> <div class="surname">Lee</div></span>, <span class="name string-name"><div class="given-names">Jan</div> <div class="surname">Leike</div></span>, <span class="name string-name"><div class="given-names">John</div> <div class="surname">Schulman</div></span>, <span class="name string-name"><div class="given-names">Ilya</div> <div class="surname">Sutskever</div></span>, and <span class="name string-name"><div class="given-names">Karl</div> <div class="surname">Cobbe</div></span></span>. <div class="year">2024</div>. <div class="article-title">Let’s verify step by step</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Let%E2%80%99s%20verify%20step%20by%20step&amp;author=Hunter%20Lightman&amp;author=Vineet%20Kosaraju&amp;author=Yuri%20Burda&amp;author=Harrison%20Edwards&amp;author=Bowen%20Baker&amp;author=Teddy%20Lee&amp;author=Jan%20Leike&amp;author=John%20Schulman&amp;author=Ilya%20Sutskever&amp;author=Karl%20Cobbe&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib57" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Guangliang</div> <div class="surname">Liu</div></span>, <span class="name string-name"><div class="given-names">Haitao</div> <div class="surname">Mao</div></span>, <span class="name string-name"><div class="given-names">Bochuan</div> <div class="surname">Cao</div></span>, <span class="name string-name"><div class="given-names">Zhiyu</div> <div class="surname">Xue</div></span>, <span class="name string-name"><div class="given-names">Kristen</div> <div class="surname">Johnson</div></span>, <span class="name string-name"><div class="given-names">Jiliang</div> <div class="surname">Tang</div></span>, and <span class="name string-name"><div class="given-names">Rongrong</div> <div class="surname">Wang</div></span></span>. <div class="year">2024</div>. <div class="article-title">On the intrinsic self-correction capability of LLMs: Uncertainty and latent concept</div>. <div class="source">arXiv preprint arXiv:2406.02378</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=On%20the%20intrinsic%20self-correction%20capability%20of%20LLMs%3A%20Uncertainty%20and%20latent%20concept&amp;author=Guangliang%20Liu&amp;author=Haitao%20Mao&amp;author=Bochuan%20Cao&amp;author=Zhiyu%20Xue&amp;author=Kristen%20Johnson&amp;author=Jiliang%20Tang&amp;author=Rongrong%20Wang&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A2406.02378&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib58" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yang</div> <div class="surname">Liu</div></span>, <span class="name string-name"><div class="given-names">Dan</div> <div class="surname">Iter</div></span>, <span class="name string-name"><div class="surname">Yichong</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Shuohang</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="surname">Ruochen</div> <div class="given-names">Xu</div></span>, and <span class="name string-name"><div class="given-names">Chenguang</div> <div class="surname">Zhu</div></span></span>. <div class="year">2023</div>. <div class="article-title">G-eval: NLG evaluation using gpt-4 with better human alignment</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">2511</div>–<div class="lpage">2522</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.153" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.153</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=G-eval%3A%20NLG%20evaluation%20using%20gpt-4%20with%20better%20human%20alignment&amp;author=Yang%20Liu&amp;author=Dan%20Iter&amp;author=Xu%20Yichong&amp;author=Shuohang%20Wang&amp;author=Xu%20Ruochen&amp;author=Chenguang%20Zhu&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib59" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Aman</div> <div class="surname">Madaan</div></span>, <span class="name string-name"><div class="given-names">Niket</div> <div class="surname">Tandon</div></span>, <span class="name string-name"><div class="given-names">Prakhar</div> <div class="surname">Gupta</div></span>, <span class="name string-name"><div class="given-names">Skyler</div> <div class="surname">Hallinan</div></span>, <span class="name string-name"><div class="given-names">Luyu</div> <div class="surname">Gao</div></span>, <span class="name string-name"><div class="given-names">Sarah</div> <div class="surname">Wiegreffe</div></span>, <span class="name string-name"><div class="given-names">Uri</div> <div class="surname">Alon</div></span>, <span class="name string-name"><div class="given-names">Nouha</div> <div class="surname">Dziri</div></span>, <span class="name string-name"><div class="given-names">Shrimai</div> <div class="surname">Prabhumoye</div></span>, <span class="name string-name"><div class="given-names">Yiming</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="given-names">Shashank</div> <div class="surname">Gupta</div></span>, <span class="name string-name"><div class="given-names">Bodhisattwa Prasad</div> <div class="surname">Majumder</div></span>, <span class="name string-name"><div class="given-names">Katherine</div> <div class="surname">Hermann</div></span>, <span class="name string-name"><div class="given-names">Sean</div> <div class="surname">Welleck</div></span>, <span class="name string-name"><div class="given-names">Amir</div> <div class="surname">Yazdanbakhsh</div></span>, and <span class="name string-name"><div class="given-names">Peter</div> <div class="surname">Clark</div></span></span>. <div class="year">2023</div>. <div class="article-title">Self-refine: Iterative refinement with self-feedback</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">36</div>, pages <div class="fpage">46534</div>–<div class="lpage">46594</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-refine%3A%20Iterative%20refinement%20with%20self-feedback&amp;author=Aman%20Madaan&amp;author=Niket%20Tandon&amp;author=Prakhar%20Gupta&amp;author=Skyler%20Hallinan&amp;author=Luyu%20Gao&amp;author=Sarah%20Wiegreffe&amp;author=Uri%20Alon&amp;author=Nouha%20Dziri&amp;author=Shrimai%20Prabhumoye&amp;author=Yiming%20Yang&amp;author=Shashank%20Gupta&amp;author=Bodhisattwa%20Prasad%20Majumder&amp;author=Katherine%20Hermann&amp;author=Sean%20Welleck&amp;author=Amir%20Yazdanbakhsh&amp;author=Peter%20Clark&amp;publication_year=2023&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib60" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Potsawee</div> <div class="surname">Manakul</div></span>, <span class="name string-name"><div class="given-names">Adian</div> <div class="surname">Liusie</div></span>, and <span class="name string-name"><div class="given-names">Mark</div> <div class="surname">Gales</div></span></span>. <div class="year">2023</div>. <div class="article-title">SelfCheckGPT: Zero-resource black-box hallucination detection for generative large language models</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">9004</div>–<div class="lpage">9017</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.557" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.557</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=SelfCheckGPT%3A%20Zero-resource%20black-box%20hallucination%20detection%20for%20generative%20large%20language%20models&amp;author=Potsawee%20Manakul&amp;author=Adian%20Liusie&amp;author=Mark%20Gales&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib61" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ninareh</div> <div class="surname">Mehrabi</div></span>, <span class="name string-name"><div class="given-names">Palash</div> <div class="surname">Goyal</div></span>, <span class="name string-name"><div class="given-names">Christophe</div> <div class="surname">Dupuy</div></span>, <span class="name string-name"><div class="surname">Qian</div> <div class="given-names">Hu</div></span>, <span class="name string-name"><div class="given-names">Shalini</div> <div class="surname">Ghosh</div></span>, <span class="name string-name"><div class="given-names">Richard</div> <div class="surname">Zemel</div></span>, <span class="name string-name"><div class="given-names">Kai-Wei</div> <div class="surname">Chang</div></span>, <span class="name string-name"><div class="given-names">Aram</div> <div class="surname">Galstyan</div></span>, and <span class="name string-name"><div class="given-names">Rahul</div> <div class="surname">Gupta</div></span></span>. <div class="year">2023</div>. <div class="article-title">Flirt: Feedback loop in-context red teaming</div>. <div class="source">arXiv preprint arXiv: 2308.04265</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Flirt%3A%20Feedback%20loop%20in-context%20red%20teaming&amp;author=Ninareh%20Mehrabi&amp;author=Palash%20Goyal&amp;author=Christophe%20Dupuy&amp;author=Hu%20Qian&amp;author=Shalini%20Ghosh&amp;author=Richard%20Zemel&amp;author=Kai-Wei%20Chang&amp;author=Aram%20Galstyan&amp;author=Rahul%20Gupta&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A%202308.04265&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib62" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yu</div> <div class="surname">Meng</div></span>, <span class="name string-name"><div class="given-names">Jiaxin</div> <div class="surname">Huang</div></span>, <span class="name string-name"><div class="given-names">Yu</div> <div class="surname">Zhang</div></span>, and <span class="name string-name"><div class="given-names">Jiawei</div> <div class="surname">Han</div></span></span>. <div class="year">2022</div>. <div class="article-title">Generating training data with language models: Towards zero-shot language understanding</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">35</div>, pages <div class="fpage">462</div>–<div class="lpage">477</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Generating%20training%20data%20with%20language%20models%3A%20Towards%20zero-shot%20language%20understanding&amp;author=Yu%20Meng&amp;author=Jiaxin%20Huang&amp;author=Yu%20Zhang&amp;author=Jiawei%20Han&amp;publication_year=2022&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib63" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ali</div> <div class="surname">Mesbah</div></span>, <span class="name string-name"><div class="given-names">Andrew</div> <div class="surname">Rice</div></span>, <span class="name string-name"><div class="given-names">Emily</div> <div class="surname">Johnston</div></span>, <span class="name string-name"><div class="given-names">Nick</div> <div class="surname">Glorioso</div></span>, and <span class="name string-name"><div class="given-names">Edward</div> <div class="surname">Aftandilian</div></span></span>. <div class="year">2019</div>. <div class="article-title">Deepdelta: Learning to repair compilation errors</div>. In <div class="source">Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</div>, <div class="issue">ESEC/ FSE 2019</div>, pages <div class="fpage">925</div>–<div class="lpage">936</div>, <div class="publisher-loc">New York, NY, USA</div>. <div class="publisher-name">Association for Computing Machinery</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1145/3338906.3340455" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1145/3338906.3340455</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Deepdelta%3A%20Learning%20to%20repair%20compilation%20errors&amp;author=Ali%20Mesbah&amp;author=Andrew%20Rice&amp;author=Emily%20Johnston&amp;author=Nick%20Glorioso&amp;author=Edward%20Aftandilian&amp;publication_year=2019&amp;book=Proceedings%20of%20the%202019%2027th%20ACM%20Joint%20Meeting%20on%20European%20Software%20Engineering%20Conference%20and%20Symposium%20on%20the%20Foundations%20of%20Software%20Engineering" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib64" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ning</div> <div class="surname">Miao</div></span>, <span class="name string-name"><div class="given-names">Yee Whye</div> <div class="surname">Teh</div></span>, and <span class="name string-name"><div class="given-names">Tom</div> <div class="surname">Rainforth</div></span></span>. <div class="year">2024</div>. <div class="article-title">Selfcheck: Using LLMs to zero-shot check their own step-by-step reasoning</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Selfcheck%3A%20Using%20LLMs%20to%20zero-shot%20check%20their%20own%20step-by-step%20reasoning&amp;author=Ning%20Miao&amp;author=Yee%20Whye%20Teh&amp;author=Tom%20Rainforth&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib65" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Sewon</div> <div class="surname">Min</div></span>, <span class="name string-name"><div class="given-names">Kalpesh</div> <div class="surname">Krishna</div></span>, <span class="name string-name"><div class="given-names">Xinxi</div> <div class="surname">Lyu</div></span>, <span class="name string-name"><div class="given-names">Mike</div> <div class="surname">Lewis</div></span>, <span class="name string-name"><div class="given-names">Wen-tau</div> <div class="surname">Yih</div></span>, <span class="name string-name"><div class="given-names">Pang</div> <div class="surname">Koh</div></span>, <span class="name string-name"><div class="given-names">Mohit</div> <div class="surname">Iyyer</div></span>, <span class="name string-name"><div class="given-names">Luke</div> <div class="surname">Zettlemoyer</div></span>, and <span class="name string-name"><div class="given-names">Hannaneh</div> <div class="surname">Hajishirzi</div></span></span>. <div class="year">2023</div>. <div class="article-title">FActScore: Fine-grained atomic evaluation of factual precision in long form text generation</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">12076</div>–<div class="lpage">12100</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.741" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.741</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=FActScore%3A%20Fine-grained%20atomic%20evaluation%20of%20factual%20precision%20in%20long%20form%20text%20generation&amp;author=Sewon%20Min&amp;author=Kalpesh%20Krishna&amp;author=Xinxi%20Lyu&amp;author=Mike%20Lewis&amp;author=Wen-tau%20Yih&amp;author=Pang%20Koh&amp;author=Mohit%20Iyyer&amp;author=Luke%20Zettlemoyer&amp;author=Hannaneh%20Hajishirzi&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib66" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Abhika</div> <div class="surname">Mishra</div></span>, <span class="name string-name"><div class="given-names">Akari</div> <div class="surname">Asai</div></span>, <span class="name string-name"><div class="given-names">Vidhisha</div> <div class="surname">Balachandran</div></span>, <span class="name string-name"><div class="given-names">Yizhong</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Graham</div> <div class="surname">Neubig</div></span>, <span class="name string-name"><div class="given-names">Yulia</div> <div class="surname">Tsvetkov</div></span>, and <span class="name string-name"><div class="given-names">Hannaneh</div> <div class="surname">Hajishirzi</div></span></span>. <div class="year">2024</div>. <div class="article-title">Fine-grained hallucination detection and editing for language models</div>. <div class="source">arXiv preprint arXiv:2401.06855</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Fine-grained%20hallucination%20detection%20and%20editing%20for%20language%20models&amp;author=Abhika%20Mishra&amp;author=Akari%20Asai&amp;author=Vidhisha%20Balachandran&amp;author=Yizhong%20Wang&amp;author=Graham%20Neubig&amp;author=Yulia%20Tsvetkov&amp;author=Hannaneh%20Hajishirzi&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A2401.06855&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib67" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Deepak</div> <div class="surname">Nathani</div></span>, <span class="name string-name"><div class="given-names">David</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Liangming</div> <div class="surname">Pan</div></span>, and <span class="name string-name"><div class="given-names">William</div> <div class="surname">Wang</div></span></span>. <div class="year">2023</div>. <div class="article-title">MAF: Multi-aspect feedback for improving reasoning in large language models</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">6591</div>–<div class="lpage">6616</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.407" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.407</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=MAF%3A%20Multi-aspect%20feedback%20for%20improving%20reasoning%20in%20large%20language%20models&amp;author=Deepak%20Nathani&amp;author=David%20Wang&amp;author=Liangming%20Pan&amp;author=William%20Wang&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib68" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Hwee Tou</div> <div class="surname">Ng</div></span>, <span class="name string-name"><div class="surname">Siew Mei</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="given-names">Ted</div> <div class="surname">Briscoe</div></span>, <span class="name string-name"><div class="given-names">Christian</div> <div class="surname">Hadiwinoto</div></span>, <span class="name string-name"><div class="given-names">Raymond Hendy</div> <div class="surname">Susanto</div></span>, and <span class="name string-name"><div class="given-names">Christopher</div> <div class="surname">Bryant</div></span></span>. <div class="year">2014</div>. <div class="article-title">The CoNLL-2014 shared task on grammatical error correction</div>. In <div class="source">Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task</div>, pages <div class="fpage">1</div>–<div class="lpage">14</div>, <div class="publisher-loc">Baltimore, Maryland</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.3115/v1/W14-1701" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.3115/v1/W14-1701</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=The%20CoNLL-2014%20shared%20task%20on%20grammatical%20error%20correction&amp;author=Hwee%20Tou%20Ng&amp;author=Wu%20Siew%20Mei&amp;author=Ted%20Briscoe&amp;author=Christian%20Hadiwinoto&amp;author=Raymond%20Hendy%20Susanto&amp;author=Christopher%20Bryant&amp;publication_year=2014&amp;book=Proceedings%20of%20the%20Eighteenth%20Conference%20on%20Computational%20Natural%20Language%20Learning%3A%20Shared%20Task" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib69" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ansong</div> <div class="surname">Ni</div></span>, <span class="name string-name"><div class="given-names">Srini</div> <div class="surname">Iyer</div></span>, <span class="name string-name"><div class="given-names">Dragomir</div> <div class="surname">Radev</div></span>, <span class="name string-name"><div class="given-names">Veselin</div> <div class="surname">Stoyanov</div></span>, <span class="name string-name"><div class="given-names">Wen-Tau</div> <div class="surname">Yih</div></span>, <span class="name string-name"><div class="given-names">Sida</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="surname">Xi</div> <div class="given-names">Victoria Lin</div></span></span>. <div class="year">2023</div>. <div class="article-title">LEVER: Learning to verify language-to-code generation with execution</div>. In <div class="source">Proceedings of the 40th International Conference on Machine Learning</div>, volume <div class="volume">202 of Proceedings of Machine Learning Research</div>, pages <div class="fpage">26106</div>–<div class="lpage">26128</div>. <div class="publisher-name">PMLR</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=LEVER%3A%20Learning%20to%20verify%20language-to-code%20generation%20with%20execution&amp;author=Ansong%20Ni&amp;author=Srini%20Iyer&amp;author=Dragomir%20Radev&amp;author=Veselin%20Stoyanov&amp;author=Wen-Tau%20Yih&amp;author=Sida%20Wang&amp;author=Victoria%20Lin%20Xi&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2040th%20International%20Conference%20on%20Machine%20Learning" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib70" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Theo X.</div> <div class="surname">Olausson</div></span>, <span class="name string-name"><div class="given-names">Jeevana Priya</div> <div class="surname">Inala</div></span>, <span class="name string-name"><div class="given-names">Chenglong</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Jianfeng</div> <div class="surname">Gao</div></span>, and <span class="name string-name"><div class="given-names">Armando</div> <div class="surname">Solar-Lezama</div></span></span>. <div class="year">2024</div>. <div class="article-title">Is self-repair a silver bullet for code generation?</div> In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Is%20self-repair%20a%20silver%20bullet%20for%20code%20generation%3F&amp;author=Theo%20X.%20Olausson&amp;author=Jeevana%20Priya%20Inala&amp;author=Chenglong%20Wang&amp;author=Jianfeng%20Gao&amp;author=Armando%20Solar-Lezama&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib71" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Liangming</div> <div class="surname">Pan</div></span>, <span class="name string-name"><div class="given-names">Alon</div> <div class="surname">Albalak</div></span>, <span class="name string-name"><div class="given-names">Xinyi</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">William</div> <div class="surname">Wang</div></span></span>. <div class="year">2023</div>. <div class="article-title">Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning</div>. In <div class="source">Findings of the Association for Computational Linguistics: EMNLP 2023</div>, pages <div class="fpage">3806</div>–<div class="lpage">3824</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Logic-LM%3A%20Empowering%20large%20language%20models%20with%20symbolic%20solvers%20for%20faithful%20logical%20reasoning&amp;author=Liangming%20Pan&amp;author=Alon%20Albalak&amp;author=Xinyi%20Wang&amp;author=William%20Wang&amp;publication_year=2023&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20EMNLP%202023" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib72" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Liangming</div> <div class="surname">Pan</div></span>, <span class="name string-name"><div class="given-names">Michael</div> <div class="surname">Saxon</div></span>, <span class="name string-name"><div class="surname">Wenda</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Deepak</div> <div class="surname">Nathani</div></span>, <span class="name string-name"><div class="given-names">Xinyi</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">William Yang</div> <div class="surname">Wang</div></span></span>. <div class="year">2024</div>. <div class="article-title">Automatically correcting large language models: Surveying the landscape of diverse automated correction strategies</div>. <div class="source">Transactions of the Association for Computational Linguistics</div>, <div class="volume">12</div>:<div class="fpage">484</div>–<div class="lpage">506</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1162/tacl_a_00660" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1162/tacl_a_00660</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Automatically%20correcting%20large%20language%20models%3A%20Surveying%20the%20landscape%20of%20diverse%20automated%20correction%20strategies&amp;author=Liangming%20Pan&amp;author=Michael%20Saxon&amp;author=Xu%20Wenda&amp;author=Deepak%20Nathani&amp;author=Xinyi%20Wang&amp;author=William%20Yang%20Wang&amp;publication_year=2024&amp;journal=Transactions%20of%20the%20Association%20for%20Computational%20Linguistics&amp;volume=12&amp;pages=484-506" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib73" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jing-Cheng</div> <div class="surname">Pang</div></span>, <span class="name string-name"><div class="given-names">Pengyuan</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Kaiyuan</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Xiong-Hui</div> <div class="surname">Chen</div></span>, <span class="name string-name"><div class="surname">Jiacheng</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Zongzhang</div> <div class="surname">Zhang</div></span>, and <span class="name string-name"><div class="surname">Yang</div> <div class="given-names">Yu</div></span></span>. <div class="year">2024</div>. <div class="article-title">Language model self-improvement by reinforcement learning contemplation</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Language%20model%20self-improvement%20by%20reinforcement%20learning%20contemplation&amp;author=Jing-Cheng%20Pang&amp;author=Pengyuan%20Wang&amp;author=Kaiyuan%20Li&amp;author=Xiong-Hui%20Chen&amp;author=Xu%20Jiacheng&amp;author=Zongzhang%20Zhang&amp;author=Yu%20Yang&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib74" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Debjit</div> <div class="surname">Paul</div></span>, <span class="name string-name"><div class="given-names">Mete</div> <div class="surname">Ismayilzada</div></span>, <span class="name string-name"><div class="given-names">Maxime</div> <div class="surname">Peyrard</div></span>, <span class="name string-name"><div class="given-names">Beatriz</div> <div class="surname">Borges</div></span>, <span class="name string-name"><div class="given-names">Antoine</div> <div class="surname">Bosselut</div></span>, <span class="name string-name"><div class="given-names">Robert</div> <div class="surname">West</div></span>, and <span class="name string-name"><div class="given-names">Boi</div> <div class="surname">Faltings</div></span></span>. <div class="year">2024</div>. <div class="article-title">REFINER: Reasoning feedback on intermediate representations</div>. In <div class="source">Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">1100</div>–<div class="lpage">1126</div>, <div class="publisher-loc">St. Julian’s, Malta</div>. <div class="publisher-name">Association for Computational Linguistics</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=REFINER%3A%20Reasoning%20feedback%20on%20intermediate%20representations&amp;author=Debjit%20Paul&amp;author=Mete%20Ismayilzada&amp;author=Maxime%20Peyrard&amp;author=Beatriz%20Borges&amp;author=Antoine%20Bosselut&amp;author=Robert%20West&amp;author=Boi%20Faltings&amp;publication_year=2024&amp;book=Proceedings%20of%20the%2018th%20Conference%20of%20the%20European%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib75" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Baolin</div> <div class="surname">Peng</div></span>, <span class="name string-name"><div class="given-names">Michel</div> <div class="surname">Galley</div></span>, <span class="name string-name"><div class="given-names">Pengcheng</div> <div class="surname">He</div></span>, <span class="name string-name"><div class="given-names">Hao</div> <div class="surname">Cheng</div></span>, <span class="name string-name"><div class="given-names">Yujia</div> <div class="surname">Xie</div></span>, <span class="name string-name"><div class="surname">Yu</div> <div class="given-names">Hu</div></span>, <span class="name string-name"><div class="given-names">Qiuyuan</div> <div class="surname">Huang</div></span>, <span class="name string-name"><div class="given-names">Lars</div> <div class="surname">Liden</div></span>, <span class="name string-name"><div class="surname">Zhou</div> <div class="given-names">Yu</div></span>, <span class="name string-name"><div class="given-names">Weizhu</div> <div class="surname">Chen</div></span>, and <span class="name string-name"><div class="given-names">Jianfeng</div> <div class="surname">Gao</div></span></span>. <div class="year">2023</div>. <div class="article-title">Check your facts and try again: Improving large language models with external knowledge and automated feedback</div>. <div class="source">arXiv preprint arXiv:2302.12813</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Check%20your%20facts%20and%20try%20again%3A%20Improving%20large%20language%20models%20with%20external%20knowledge%20and%20automated%20feedback&amp;author=Baolin%20Peng&amp;author=Michel%20Galley&amp;author=Pengcheng%20He&amp;author=Hao%20Cheng&amp;author=Yujia%20Xie&amp;author=Hu%20Yu&amp;author=Qiuyuan%20Huang&amp;author=Lars%20Liden&amp;author=Yu%20Zhou&amp;author=Weizhu%20Chen&amp;author=Jianfeng%20Gao&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2302.12813&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib76" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Mansi</div> <div class="surname">Phute</div></span>, <span class="name string-name"><div class="given-names">Alec</div> <div class="surname">Helbling</div></span>, <span class="name string-name"><div class="given-names">Matthew</div> <div class="surname">Hull</div></span>, <span class="name string-name"><div class="given-names">ShengYun</div> <div class="surname">Peng</div></span>, <span class="name string-name"><div class="given-names">Sebastian</div> <div class="surname">Szyller</div></span>, <span class="name string-name"><div class="given-names">Cory</div> <div class="surname">Cornelius</div></span>, and <span class="name string-name"><div class="given-names">Duen Horng</div> <div class="surname">Chau</div></span></span>. <div class="year">2024</div>. <div class="article-title">Llm self defense: By self examination, llms know they are being tricked</div>. <div class="source">arXiv preprint arXiv:2308.07308</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Llm%20self%20defense%3A%20By%20self%20examination%2C%20llms%20know%20they%20are%20being%20tricked&amp;author=Mansi%20Phute&amp;author=Alec%20Helbling&amp;author=Matthew%20Hull&amp;author=ShengYun%20Peng&amp;author=Sebastian%20Szyller&amp;author=Cory%20Cornelius&amp;author=Duen%20Horng%20Chau&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A2308.07308&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib77" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Reid</div> <div class="surname">Pryzant</div></span>, <span class="name string-name"><div class="given-names">Dan</div> <div class="surname">Iter</div></span>, <span class="name string-name"><div class="given-names">Jerry</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Yin</div> <div class="surname">Lee</div></span>, <span class="name string-name"><div class="given-names">Chenguang</div> <div class="surname">Zhu</div></span>, and <span class="name string-name"><div class="given-names">Michael</div> <div class="surname">Zeng</div></span></span>. <div class="year">2023</div>. <div class="article-title">Automatic prompt optimization with “gradient descent” and beam search</div>. In <div class="source">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">7957</div>–<div class="lpage">7968</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.494" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.494</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Automatic%20prompt%20optimization%20with%20%E2%80%9Cgradient%20descent%E2%80%9D%20and%20beam%20search&amp;author=Reid%20Pryzant&amp;author=Dan%20Iter&amp;author=Jerry%20Li&amp;author=Yin%20Lee&amp;author=Chenguang%20Zhu&amp;author=Michael%20Zeng&amp;publication_year=2023&amp;book=Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib78" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Maribeth</div> <div class="surname">Rauh</div></span>, <span class="name string-name"><div class="given-names">John F. J.</div> <div class="surname">Mellor</div></span>, <span class="name string-name"><div class="given-names">Jonathan</div> <div class="surname">Uesato</div></span>, <span class="name string-name"><div class="given-names">Po-Sen</div> <div class="surname">Huang</div></span>, <span class="name string-name"><div class="given-names">Johannes</div> <div class="surname">Welbl</div></span>, <span class="name string-name"><div class="given-names">Laura</div> <div class="surname">Weidinger</div></span>, <span class="name string-name"><div class="given-names">Sumanth</div> <div class="surname">Dathathri</div></span>, <span class="name string-name"><div class="given-names">Amelia</div> <div class="surname">Glaese</div></span>, <span class="name string-name"><div class="given-names">Geoffrey</div> <div class="surname">Irving</div></span>, <span class="name string-name"><div class="given-names">Iason</div> <div class="surname">Gabriel</div></span>, <span class="name string-name"><div class="given-names">William</div> <div class="surname">Isaac</div></span>, and <span class="name string-name"><div class="given-names">Lisa Anne</div> <div class="surname">Hendricks</div></span></span>. <div class="year">2022</div>. <div class="article-title">Characteristics of harmful text: Towards rigorous benchmarking of language models</div>. In <div class="source">Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Characteristics%20of%20harmful%20text%3A%20Towards%20rigorous%20benchmarking%20of%20language%20models&amp;author=Maribeth%20Rauh&amp;author=John%20F.%20J.%20Mellor&amp;author=Jonathan%20Uesato&amp;author=Po-Sen%20Huang&amp;author=Johannes%20Welbl&amp;author=Laura%20Weidinger&amp;author=Sumanth%20Dathathri&amp;author=Amelia%20Glaese&amp;author=Geoffrey%20Irving&amp;author=Iason%20Gabriel&amp;author=William%20Isaac&amp;author=Lisa%20Anne%20Hendricks&amp;publication_year=2022&amp;journal=Thirty-sixth%20Conference%20on%20Neural%20Information%20Processing%20Systems%20Datasets%20and%20Benchmarks%20Track&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib79" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Vikas</div> <div class="surname">Raunak</div></span>, <span class="name string-name"><div class="given-names">Amr</div> <div class="surname">Sharaf</div></span>, <span class="name string-name"><div class="given-names">Yiren</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Hany</div> <div class="surname">Awadalla</div></span>, and <span class="name string-name"><div class="given-names">Arul</div> <div class="surname">Menezes</div></span></span>. <div class="year">2023</div>. <div class="article-title">Leveraging GPT-4 for automatic translation post-editing</div>. In <div class="source">Findings of the Association for Computational Linguistics: EMNLP 2023</div>, pages <div class="fpage">12009</div>–<div class="lpage">12024</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.findings-emnlp.804" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.findings-emnlp.804</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Leveraging%20GPT-4%20for%20automatic%20translation%20post-editing&amp;author=Vikas%20Raunak&amp;author=Amr%20Sharaf&amp;author=Yiren%20Wang&amp;author=Hany%20Awadalla&amp;author=Arul%20Menezes&amp;publication_year=2023&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20EMNLP%202023" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib80" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Swarnadeep</div> <div class="surname">Saha</div></span>, <span class="name string-name"><div class="given-names">Omer</div> <div class="surname">Levy</div></span>, <span class="name string-name"><div class="given-names">Asli</div> <div class="surname">Celikyilmaz</div></span>, <span class="name string-name"><div class="given-names">Mohit</div> <div class="surname">Bansal</div></span>, <span class="name string-name"><div class="given-names">Jason</div> <div class="surname">Weston</div></span>, and <span class="name string-name"><div class="given-names">Xian</div> <div class="surname">Li</div></span></span>. <div class="year">2024</div>. <div class="article-title">Branch-solve-merge improves large language model evaluation and generation</div>. In <div class="source">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</div>, pages <div class="fpage">8352</div>–<div class="lpage">8370</div>, <div class="publisher-loc">Mexico City, Mexico</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.naacl-long.462" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.naacl-long.462</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Branch-solve-merge%20improves%20large%20language%20model%20evaluation%20and%20generation&amp;author=Swarnadeep%20Saha&amp;author=Omer%20Levy&amp;author=Asli%20Celikyilmaz&amp;author=Mohit%20Bansal&amp;author=Jason%20Weston&amp;author=Xian%20Li&amp;publication_year=2024&amp;book=Proceedings%20of%20the%202024%20Conference%20of%20the%20North%20American%20Chapter%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20Human%20Language%20Technologies%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib81" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">William</div> <div class="surname">Saunders</div></span>, <span class="name string-name"><div class="given-names">Catherine</div> <div class="surname">Yeh</div></span>, <span class="name string-name"><div class="surname">Jeff</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="given-names">Steven</div> <div class="surname">Bills</div></span>, <span class="name string-name"><div class="given-names">Long</div> <div class="surname">Ouyang</div></span>, <span class="name string-name"><div class="given-names">Jonathan</div> <div class="surname">Ward</div></span>, and <span class="name string-name"><div class="given-names">Jan</div> <div class="surname">Leike</div></span></span>. <div class="year">2022</div>. <div class="article-title">Self-critiquing models for assisting human evaluators</div>. <div class="source">arXiv preprint arXiv:2206.05802</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-critiquing%20models%20for%20assisting%20human%20evaluators&amp;author=William%20Saunders&amp;author=Catherine%20Yeh&amp;author=Wu%20Jeff&amp;author=Steven%20Bills&amp;author=Long%20Ouyang&amp;author=Jonathan%20Ward&amp;author=Jan%20Leike&amp;publication_year=2022&amp;journal=arXiv%20preprint%20arXiv%3A2206.05802&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib82" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Timo</div> <div class="surname">Schick</div></span>, <span class="name string-name"><div class="given-names">Sahana</div> <div class="surname">Udupa</div></span>, and <span class="name string-name"><div class="given-names">Hinrich</div> <div class="surname">Schütze</div></span></span>. <div class="year">2021</div>. <div class="article-title">Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in NLP</div>. <div class="source">Transactions of the Association for Computational Linguistics</div>, <div class="volume">9</div>:<div class="fpage">1408</div>–<div class="lpage">1424</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1162/tacl_a_00434" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1162/tacl_a_00434</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-diagnosis%20and%20self-debiasing%3A%20A%20proposal%20for%20reducing%20corpus-based%20bias%20in%20NLP&amp;author=Timo%20Schick&amp;author=Sahana%20Udupa&amp;author=Hinrich%20Sch%C3%BCtze&amp;publication_year=2021&amp;journal=Transactions%20of%20the%20Association%20for%20Computational%20Linguistics&amp;volume=9&amp;pages=1408-1424" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib83" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Timo</div> <div class="surname">Schick</div></span>, <span class="name string-name"><div class="surname">Jane</div> <div class="given-names">A. Yu</div></span>, <span class="name string-name"><div class="given-names">Zhengbao</div> <div class="surname">Jiang</div></span>, <span class="name string-name"><div class="given-names">Fabio</div> <div class="surname">Petroni</div></span>, <span class="name string-name"><div class="given-names">Patrick</div> <div class="surname">Lewis</div></span>, <span class="name string-name"><div class="given-names">Gautier</div> <div class="surname">Izacard</div></span>, <span class="name string-name"><div class="given-names">Qingfei</div> <div class="surname">You</div></span>, <span class="name string-name"><div class="given-names">Christoforos</div> <div class="surname">Nalmpantis</div></span>, <span class="name string-name"><div class="given-names">Edouard</div> <div class="surname">Grave</div></span>, and <span class="name string-name"><div class="given-names">Sebastian</div> <div class="surname">Riedel</div></span></span>. <div class="year">2023</div>. <div class="article-title">PEER: A collaborative language model</div>. In <div class="source">The Eleventh International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=PEER%3A%20A%20collaborative%20language%20model&amp;author=Timo%20Schick&amp;author=A.%20Yu%20Jane&amp;author=Zhengbao%20Jiang&amp;author=Fabio%20Petroni&amp;author=Patrick%20Lewis&amp;author=Gautier%20Izacard&amp;author=Qingfei%20You&amp;author=Christoforos%20Nalmpantis&amp;author=Edouard%20Grave&amp;author=Sebastian%20Riedel&amp;publication_year=2023&amp;journal=The%20Eleventh%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib84" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Thomas</div> <div class="surname">Scialom</div></span>, <span class="name string-name"><div class="given-names">Paul-Alexis</div> <div class="surname">Dray</div></span>, <span class="name string-name"><div class="given-names">Sylvain</div> <div class="surname">Lamprier</div></span>, <span class="name string-name"><div class="given-names">Benjamin</div> <div class="surname">Piwowarski</div></span>, <span class="name string-name"><div class="given-names">Jacopo</div> <div class="surname">Staiano</div></span>, <span class="name string-name"><div class="given-names">Alex</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">Patrick</div> <div class="surname">Gallinari</div></span></span>. <div class="year">2021</div>. <div class="article-title">QuestEval: Summarization asks for fact-based evaluation</div>. In <div class="source">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">6594</div>–<div class="lpage">6604</div>, <div class="publisher-loc">Online and Punta Cana, Dominican Republic</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2021.emnlp-main.529" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2021.emnlp-main.529</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=QuestEval%3A%20Summarization%20asks%20for%20fact-based%20evaluation&amp;author=Thomas%20Scialom&amp;author=Paul-Alexis%20Dray&amp;author=Sylvain%20Lamprier&amp;author=Benjamin%20Piwowarski&amp;author=Jacopo%20Staiano&amp;author=Alex%20Wang&amp;author=Patrick%20Gallinari&amp;publication_year=2021&amp;book=Proceedings%20of%20the%202021%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib85" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Darsh</div> <div class="surname">Shah</div></span>, <span class="name string-name"><div class="given-names">Tal</div> <div class="surname">Schuster</div></span>, and <span class="name string-name"><div class="given-names">Regina</div> <div class="surname">Barzilay</div></span></span>. <div class="year">2020</div>. <div class="article-title">Automatic fact-guided sentence modification</div>. <div class="source">Proceedings of the AAAI Conference on Artificial Intelligence</div>, <div class="volume">34</div>(<div class="issue">05</div>):<div class="fpage">8791</div>–<div class="lpage">8798</div>. <div class="pub-id-doi"><a href="https://doi.org/10.1609/aaai.v34i05.6406" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.1609/aaai.v34i05.6406</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Automatic%20fact-guided%20sentence%20modification&amp;author=Darsh%20Shah&amp;author=Tal%20Schuster&amp;author=Regina%20Barzilay&amp;publication_year=2020&amp;journal=Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence&amp;volume=34&amp;pages=8791-8798" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib86" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jianhao</div> <div class="surname">Shen</div></span>, <span class="name string-name"><div class="given-names">Yichun</div> <div class="surname">Yin</div></span>, <span class="name string-name"><div class="given-names">Lin</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Lifeng</div> <div class="surname">Shang</div></span>, <span class="name string-name"><div class="given-names">Xin</div> <div class="surname">Jiang</div></span>, <span class="name string-name"><div class="given-names">Ming</div> <div class="surname">Zhang</div></span>, and <span class="name string-name"><div class="given-names">Qun</div> <div class="surname">Liu</div></span></span>. <div class="year">2021</div>. <div class="article-title">Generate &amp; rank: A multi-task framework for math word problems</div>. In <div class="source">Findings of the Association for Computational Linguistics: EMNLP 2021</div>, pages <div class="fpage">2269</div>–<div class="lpage">2279</div>, <div class="publisher-loc">Punta Cana, Dominican Republic</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2021.findings-emnlp.195" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2021.findings-emnlp.195</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Generate%20%26%20rank%3A%20A%20multi-task%20framework%20for%20math%20word%20problems&amp;author=Jianhao%20Shen&amp;author=Yichun%20Yin&amp;author=Lin%20Li&amp;author=Lifeng%20Shang&amp;author=Xin%20Jiang&amp;author=Ming%20Zhang&amp;author=Qun%20Liu&amp;publication_year=2021&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20EMNLP%202021" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib87" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Freda</div> <div class="surname">Shi</div></span>, <span class="name string-name"><div class="given-names">Daniel</div> <div class="surname">Fried</div></span>, <span class="name string-name"><div class="given-names">Marjan</div> <div class="surname">Ghazvininejad</div></span>, <span class="name string-name"><div class="given-names">Luke</div> <div class="surname">Zettlemoyer</div></span>, and <span class="name string-name"><div class="given-names">Sida I.</div> <div class="surname">Wang</div></span></span>. <div class="year">2022</div>. <div class="article-title">Natural language to code translation with execution</div>. In <div class="source">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">3533</div>–<div class="lpage">3546</div>, <div class="publisher-loc">Abu Dhabi, United Arab Emirates</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2022.emnlp-main.231" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2022.emnlp-main.231</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Natural%20language%20to%20code%20translation%20with%20execution&amp;author=Freda%20Shi&amp;author=Daniel%20Fried&amp;author=Marjan%20Ghazvininejad&amp;author=Luke%20Zettlemoyer&amp;author=Sida%20I.%20Wang&amp;publication_year=2022&amp;book=Proceedings%20of%20the%202022%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib88" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Noah</div> <div class="surname">Shinn</div></span>, <span class="name string-name"><div class="given-names">Federico</div> <div class="surname">Cassano</div></span>, <span class="name string-name"><div class="given-names">Ashwin</div> <div class="surname">Gopinath</div></span>, <span class="name string-name"><div class="given-names">Karthik</div> <div class="surname">Narasimhan</div></span>, and <span class="name string-name"><div class="given-names">Shunyu</div> <div class="surname">Yao</div></span></span>. <div class="year">2023</div>. <div class="article-title">Reflexion: Language agents with verbal reinforcement learning</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">36</div>, pages <div class="fpage">8634</div>–<div class="lpage">8652</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Reflexion%3A%20Language%20agents%20with%20verbal%20reinforcement%20learning&amp;author=Noah%20Shinn&amp;author=Federico%20Cassano&amp;author=Ashwin%20Gopinath&amp;author=Karthik%20Narasimhan&amp;author=Shunyu%20Yao&amp;publication_year=2023&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib89" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Kaya</div> <div class="surname">Stechly</div></span>, <span class="name string-name"><div class="given-names">Matthew</div> <div class="surname">Marquez</div></span>, and <span class="name string-name"><div class="given-names">Subbarao</div> <div class="surname">Kambhampati</div></span></span>. <div class="year">2023</div>. <div class="article-title">GPT-4 doesn’t know it’s wrong: An analysis of iterative prompting for reasoning problems</div>. In <div class="source">NeurIPS 2023 Foundation Models for Decision Making Workshop</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=GPT-4%20doesn%E2%80%99t%20know%20it%E2%80%99s%20wrong%3A%20An%20analysis%20of%20iterative%20prompting%20for%20reasoning%20problems&amp;author=Kaya%20Stechly&amp;author=Matthew%20Marquez&amp;author=Subbarao%20Kambhampati&amp;publication_year=2023&amp;journal=NeurIPS%202023%20Foundation%20Models%20for%20Decision%20Making%20Workshop&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib90" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Elias</div> <div class="surname">Stengel-Eskin</div></span>, <span class="name string-name"><div class="given-names">Archiki</div> <div class="surname">Prasad</div></span>, and <span class="name string-name"><div class="given-names">Mohit</div> <div class="surname">Bansal</div></span></span>. <div class="year">2024</div>. <div class="article-title">Regal: Refactoring programs to discover generalizable abstractions</div>. <div class="source">arXiv preprint arXiv:2401.16467</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Regal%3A%20Refactoring%20programs%20to%20discover%20generalizable%20abstractions&amp;author=Elias%20Stengel-Eskin&amp;author=Archiki%20Prasad&amp;author=Mohit%20Bansal&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A2401.16467&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib91" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Oyvind</div> <div class="surname">Tafjord</div></span>, <span class="name string-name"><div class="given-names">Bhavana Dalvi</div> <div class="surname">Mishra</div></span>, and <span class="name string-name"><div class="given-names">Peter</div> <div class="surname">Clark</div></span></span>. <div class="year">2022</div>. <div class="article-title">Entailer: Answering questions with faithful and truthful chains of reasoning</div>. In <div class="source">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">2078</div>–<div class="lpage">2093</div>, <div class="publisher-loc">Abu Dhabi, United Arab Emirates</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2022.emnlp-main.134" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2022.emnlp-main.134</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Entailer%3A%20Answering%20questions%20with%20faithful%20and%20truthful%20chains%20of%20reasoning&amp;author=Oyvind%20Tafjord&amp;author=Bhavana%20Dalvi%20Mishra&amp;author=Peter%20Clark&amp;publication_year=2022&amp;journal=Proceedings%20of%20the%202022%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing&amp;volume=&amp;pages=2078-2093" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib92" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">James</div> <div class="surname">Thorne</div></span> and <span class="name string-name"><div class="given-names">Andreas</div> <div class="surname">Vlachos</div></span></span>. <div class="year">2021</div>. <div class="article-title">Evidence-based factual error correction</div>. In <div class="source">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</div>, pages <div class="fpage">3298</div>–<div class="lpage">3309</div>, <div class="comment">Online</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2021.acl-long.256" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2021.acl-long.256</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Evidence-based%20factual%20error%20correction&amp;author=James%20Thorne&amp;author=Andreas%20Vlachos&amp;publication_year=2021&amp;book=Proceedings%20of%20the%2059th%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20and%20the%2011th%20International%20Joint%20Conference%20on%20Natural%20Language%20Processing%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib93" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Gladys</div> <div class="surname">Tyen</div></span>, <span class="name string-name"><div class="given-names">Hassan</div> <div class="surname">Mansoor</div></span>, <span class="name string-name"><div class="given-names">Victor</div> <div class="surname">Carbune</div></span>, <span class="name string-name"><div class="given-names">Peter</div> <div class="surname">Chen</div></span>, and <span class="name string-name"><div class="given-names">Tony</div> <div class="surname">Mak</div></span></span>. <div class="year">2024</div>. <div class="article-title">LLMs cannot find reasoning errors, but can correct them given the error location</div>. In <div class="source">Findings of the Association for Computational Linguistics ACL 2024</div>, pages <div class="fpage">13894</div>–<div class="lpage">13908</div>, <div class="publisher-loc">Bangkok, Thailand and virtual meeting</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.findings-acl.826" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.findings-acl.826</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=LLMs%20cannot%20find%20reasoning%20errors%2C%20but%20can%20correct%20them%20given%20the%20error%20location&amp;author=Gladys%20Tyen&amp;author=Hassan%20Mansoor&amp;author=Victor%20Carbune&amp;author=Peter%20Chen&amp;author=Tony%20Mak&amp;publication_year=2024&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%20ACL%202024" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib94" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jonathan</div> <div class="surname">Uesato</div></span>, <span class="name string-name"><div class="given-names">Nate</div> <div class="surname">Kushman</div></span>, <span class="name string-name"><div class="given-names">Ramana</div> <div class="surname">Kumar</div></span>, <span class="name string-name"><div class="given-names">Francis</div> <div class="surname">Song</div></span>, <span class="name string-name"><div class="given-names">Noah</div> <div class="surname">Siegel</div></span>, <span class="name string-name"><div class="given-names">Lisa</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Antonia</div> <div class="surname">Creswell</div></span>, <span class="name string-name"><div class="given-names">Geoffrey</div> <div class="surname">Irving</div></span>, and <span class="name string-name"><div class="given-names">Irina</div> <div class="surname">Higgins</div></span></span>. <div class="year">2022</div>. <div class="article-title">Solving math word problems with process- and outcome-based feedback</div>. <div class="source">arXiv preprint arXiv:2211.14275</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Solving%20math%20word%20problems%20with%20process-%20and%20outcome-based%20feedback&amp;author=Jonathan%20Uesato&amp;author=Nate%20Kushman&amp;author=Ramana%20Kumar&amp;author=Francis%20Song&amp;author=Noah%20Siegel&amp;author=Lisa%20Wang&amp;author=Antonia%20Creswell&amp;author=Geoffrey%20Irving&amp;author=Irina%20Higgins&amp;publication_year=2022&amp;journal=arXiv%20preprint%20arXiv%3A2211.14275&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib95" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Karthik</div> <div class="surname">Valmeekam</div></span>, <span class="name string-name"><div class="given-names">Matthew</div> <div class="surname">Marquez</div></span>, and <span class="name string-name"><div class="given-names">Subbarao</div> <div class="surname">Kambhampati</div></span></span>. <div class="year">2023</div>. <div class="article-title">Investigating the effectiveness of self-critiquing in LLMs solving planning tasks</div>. In <div class="source">NeurIPS 2023 Foundation Models for Decision Making Workshop</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Investigating%20the%20effectiveness%20of%20self-critiquing%20in%20LLMs%20solving%20planning%20tasks&amp;author=Karthik%20Valmeekam&amp;author=Matthew%20Marquez&amp;author=Subbarao%20Kambhampati&amp;publication_year=2023&amp;journal=NeurIPS%202023%20Foundation%20Models%20for%20Decision%20Making%20Workshop&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib96" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Neeraj</div> <div class="surname">Varshney</div></span>, <span class="name string-name"><div class="given-names">Wenlin</div> <div class="surname">Yao</div></span>, <span class="name string-name"><div class="given-names">Hongming</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Jianshu</div> <div class="surname">Chen</div></span>, and <span class="name string-name"><div class="surname">Dong</div> <div class="given-names">Yu</div></span></span>. <div class="year">2023</div>. <div class="article-title">A stitch in time saves nine: Detecting and mitigating hallucinations of LLMs by validating low-confidence generation</div>. <div class="source">arXiv preprint arXiv: 2307.03987</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=A%20stitch%20in%20time%20saves%20nine%3A%20Detecting%20and%20mitigating%20hallucinations%20of%20LLMs%20by%20validating%20low-confidence%20generation&amp;author=Neeraj%20Varshney&amp;author=Wenlin%20Yao&amp;author=Hongming%20Zhang&amp;author=Jianshu%20Chen&amp;author=Yu%20Dong&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A%202307.03987&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib97" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Alex</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Kyunghyun</div> <div class="surname">Cho</div></span>, and <span class="name string-name"><div class="given-names">Mike</div> <div class="surname">Lewis</div></span></span>. <div class="year">2020</div>. <div class="article-title">Asking and answering questions to evaluate the factual consistency of summaries</div>. In <div class="source">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</div>, pages <div class="fpage">5008</div>–<div class="lpage">5020</div>, <div class="comment">Online</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2020.acl-main.450" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2020.acl-main.450</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Asking%20and%20answering%20questions%20to%20evaluate%20the%20factual%20consistency%20of%20summaries&amp;author=Alex%20Wang&amp;author=Kyunghyun%20Cho&amp;author=Mike%20Lewis&amp;publication_year=2020&amp;book=Proceedings%20of%20the%2058th%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib98" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Qineng</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Zihao</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="surname">Ying</div> <div class="given-names">Su</div></span>, <span class="name string-name"><div class="given-names">Hanghang</div> <div class="surname">Tong</div></span>, and <span class="name string-name"><div class="given-names">Yangqiu</div> <div class="surname">Song</div></span></span>. <div class="year">2024a</div>. <div class="article-title">Rethinking the bounds of LLM reasoning: Are multi-agent discussions the key?</div> In <div class="source">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">6106</div>–<div class="lpage">6131</div>, <div class="publisher-loc">Bangkok, Thailand</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.acl-long.331" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.acl-long.331</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Rethinking%20the%20bounds%20of%20LLM%20reasoning%3A%20Are%20multi-agent%20discussions%20the%20key%3F&amp;author=Qineng%20Wang&amp;author=Zihao%20Wang&amp;author=Su%20Ying&amp;author=Hanghang%20Tong&amp;author=Yangqiu%20Song&amp;publication_year=2024a&amp;book=Proceedings%20of%20the%2062nd%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib99" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Xuezhi</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Jason</div> <div class="surname">Wei</div></span>, <span class="name string-name"><div class="given-names">Dale</div> <div class="surname">Schuurmans</div></span>, <span class="name string-name"><div class="given-names">Quoc V.</div> <div class="surname">Le</div></span>, <span class="name string-name"><div class="surname">Ed</div> <div class="given-names">H. Chi</div></span>, <span class="name string-name"><div class="given-names">Sharan</div> <div class="surname">Narang</div></span>, <span class="name string-name"><div class="given-names">Aakanksha</div> <div class="surname">Chowdhery</div></span>, and <span class="name string-name"><div class="given-names">Denny</div> <div class="surname">Zhou</div></span></span>. <div class="year">2023</div>. <div class="article-title">Self-consistency improves chain of thought reasoning in language models</div>. In <div class="source">The Eleventh International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-consistency%20improves%20chain%20of%20thought%20reasoning%20in%20language%20models&amp;author=Xuezhi%20Wang&amp;author=Jason%20Wei&amp;author=Dale%20Schuurmans&amp;author=Quoc%20V.%20Le&amp;author=H.%20Chi%20Ed&amp;author=Sharan%20Narang&amp;author=Aakanksha%20Chowdhery&amp;author=Denny%20Zhou&amp;publication_year=2023&amp;journal=The%20Eleventh%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib100" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yifei</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="surname">Yuyang</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="given-names">Zeming</div> <div class="surname">Wei</div></span>, <span class="name string-name"><div class="given-names">Stefanie</div> <div class="surname">Jegelka</div></span>, and <span class="name string-name"><div class="given-names">Yisen</div> <div class="surname">Wang</div></span></span>. <div class="year">2024b</div>. <div class="article-title">A theoretical understanding of self-correction through in-context alignment</div>. In <div class="source">ICML 2024 Workshop on In-Context Learning</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=A%20theoretical%20understanding%20of%20self-correction%20through%20in-context%20alignment&amp;author=Yifei%20Wang&amp;author=Wu%20Yuyang&amp;author=Zeming%20Wei&amp;author=Stefanie%20Jegelka&amp;author=Yisen%20Wang&amp;publication_year=2024b&amp;journal=ICML%202024%20Workshop%20on%20In-Context%20Learning&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib101" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Sean</div> <div class="surname">Welleck</div></span>, <span class="name string-name"><div class="surname">Ximing</div> <div class="given-names">Lu</div></span>, <span class="name string-name"><div class="given-names">Peter</div> <div class="surname">West</div></span>, <span class="name string-name"><div class="given-names">Faeze</div> <div class="surname">Brahman</div></span>, <span class="name string-name"><div class="given-names">Tianxiao</div> <div class="surname">Shen</div></span>, <span class="name string-name"><div class="given-names">Daniel</div> <div class="surname">Khashabi</div></span>, and <span class="name string-name"><div class="given-names">Yejin</div> <div class="surname">Choi</div></span></span>. <div class="year">2023</div>. <div class="article-title">Generating sequences by learning to self-correct</div>. In <div class="source">The Eleventh International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Generating%20sequences%20by%20learning%20to%20self-correct&amp;author=Sean%20Welleck&amp;author=Lu%20Ximing&amp;author=Peter%20West&amp;author=Faeze%20Brahman&amp;author=Tianxiao%20Shen&amp;author=Daniel%20Khashabi&amp;author=Yejin%20Choi&amp;publication_year=2023&amp;journal=The%20Eleventh%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib102" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yixuan</div> <div class="surname">Weng</div></span>, <span class="name string-name"><div class="given-names">Minjun</div> <div class="surname">Zhu</div></span>, <span class="name string-name"><div class="given-names">Fei</div> <div class="surname">Xia</div></span>, <span class="name string-name"><div class="given-names">Bin</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Shizhu</div> <div class="surname">He</div></span>, <span class="name string-name"><div class="given-names">Shengping</div> <div class="surname">Liu</div></span>, <span class="name string-name"><div class="given-names">Bin</div> <div class="surname">Sun</div></span>, <span class="name string-name"><div class="given-names">Kang</div> <div class="surname">Liu</div></span>, and <span class="name string-name"><div class="given-names">Jun</div> <div class="surname">Zhao</div></span></span>. <div class="year">2023</div>. <div class="article-title">Large language models are better reasoners with self-verification</div>. In <div class="source">Findings of the Association for Computational Linguistics: EMNLP 2023</div>, pages <div class="fpage">2550</div>–<div class="lpage">2575</div>, <div class="publisher-loc">Singapore</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.findings-emnlp.167" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.findings-emnlp.167</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Large%20language%20models%20are%20better%20reasoners%20with%20self-verification&amp;author=Yixuan%20Weng&amp;author=Minjun%20Zhu&amp;author=Fei%20Xia&amp;author=Bin%20Li&amp;author=Shizhu%20He&amp;author=Shengping%20Liu&amp;author=Bin%20Sun&amp;author=Kang%20Liu&amp;author=Jun%20Zhao&amp;publication_year=2023&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%3A%20EMNLP%202023" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib103" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="surname">Zhenyu</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="given-names">Qingkai</div> <div class="surname">Zeng</div></span>, <span class="name string-name"><div class="given-names">Zhihan</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Zhaoxuan</div> <div class="surname">Tan</div></span>, <span class="name string-name"><div class="given-names">Chao</div> <div class="surname">Shen</div></span>, and <span class="name string-name"><div class="given-names">Meng</div> <div class="surname">Jiang</div></span></span>. <div class="year">2024</div>. <div class="article-title">Large language models can self-correct with minimal effort</div>. <div class="source">arXiv preprint arXiv: 2405.14092</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Large%20language%20models%20can%20self-correct%20with%20minimal%20effort&amp;author=Wu%20Zhenyu&amp;author=Qingkai%20Zeng&amp;author=Zhihan%20Zhang&amp;author=Zhaoxuan%20Tan&amp;author=Chao%20Shen&amp;author=Meng%20Jiang&amp;publication_year=2024&amp;journal=arXiv%20preprint%20arXiv%3A%202405.14092&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib104" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yuxi</div> <div class="surname">Xie</div></span>, <span class="name string-name"><div class="given-names">Kenji</div> <div class="surname">Kawaguchi</div></span>, <span class="name string-name"><div class="given-names">Yiran</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="given-names">Xu</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="given-names">Min-Yen</div> <div class="surname">Kan</div></span>, <span class="name string-name"><div class="given-names">Junxian</div> <div class="surname">He</div></span>, and <span class="name string-name"><div class="given-names">Qizhe</div> <div class="surname">Xie</div></span></span>. <div class="year">2023</div>. <div class="article-title">Self-evaluation guided beam search for reasoning</div>. In <div class="source">Thirty-seventh Conference on Neural Information Processing Systems</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-evaluation%20guided%20beam%20search%20for%20reasoning&amp;author=Yuxi%20Xie&amp;author=Kenji%20Kawaguchi&amp;author=Yiran%20Zhao&amp;author=Xu%20Zhao&amp;author=Min-Yen%20Kan&amp;author=Junxian%20He&amp;author=Qizhe%20Xie&amp;publication_year=2023&amp;journal=Thirty-seventh%20Conference%20on%20Neural%20Information%20Processing%20Systems&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib105" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="surname">Wenda</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Danqing</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Liangming</div> <div class="surname">Pan</div></span>, <span class="name string-name"><div class="given-names">Zhenqiao</div> <div class="surname">Song</div></span>, <span class="name string-name"><div class="given-names">Markus</div> <div class="surname">Freitag</div></span>, <span class="name string-name"><div class="given-names">William Yang</div> <div class="surname">Wang</div></span>, and <span class="name string-name"><div class="given-names">Lei</div> <div class="surname">Li</div></span></span>. <div class="year">2023</div>. <div class="article-title">INSTRUCTSCORE: Towards explainable text generation evaluation with automatic feedback</div>. In <div class="source">The 2023 Conference on Empirical Methods in Natural Language Processing</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.emnlp-main.365" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.emnlp-main.365</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=INSTRUCTSCORE%3A%20Towards%20explainable%20text%20generation%20evaluation%20with%20automatic%20feedback&amp;author=Xu%20Wenda&amp;author=Danqing%20Wang&amp;author=Liangming%20Pan&amp;author=Zhenqiao%20Song&amp;author=Markus%20Freitag&amp;author=William%20Yang%20Wang&amp;author=Lei%20Li&amp;publication_year=2023&amp;journal=The%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib106" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Chengrun</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="given-names">Xuezhi</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="surname">Yifeng</div> <div class="given-names">Lu</div></span>, <span class="name string-name"><div class="given-names">Hanxiao</div> <div class="surname">Liu</div></span>, <span class="name string-name"><div class="given-names">Quoc V.</div> <div class="surname">Le</div></span>, <span class="name string-name"><div class="given-names">Denny</div> <div class="surname">Zhou</div></span>, and <span class="name string-name"><div class="given-names">Xinyun</div> <div class="surname">Chen</div></span></span>. <div class="year">2024</div>. <div class="article-title">Large language models as optimizers</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Large%20language%20models%20as%20optimizers&amp;author=Chengrun%20Yang&amp;author=Xuezhi%20Wang&amp;author=Lu%20Yifeng&amp;author=Hanxiao%20Liu&amp;author=Quoc%20V.%20Le&amp;author=Denny%20Zhou&amp;author=Xinyun%20Chen&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib107" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Kaiyu</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="given-names">Jia</div> <div class="surname">Deng</div></span>, and <span class="name string-name"><div class="given-names">Danqi</div> <div class="surname">Chen</div></span></span>. <div class="year">2022a</div>. <div class="article-title">Generating natural language proofs with verifier-guided search</div>. In <div class="source">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">89</div>–<div class="lpage">105</div>, <div class="publisher-loc">Abu Dhabi, United Arab Emirates</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2022.emnlp-main.7" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2022.emnlp-main.7</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Generating%20natural%20language%20proofs%20with%20verifier-guided%20search&amp;author=Kaiyu%20Yang&amp;author=Jia%20Deng&amp;author=Danqi%20Chen&amp;publication_year=2022a&amp;book=Proceedings%20of%20the%202022%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib108" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Kevin</div> <div class="surname">Yang</div></span>, <span class="name string-name"><div class="given-names">Yuandong</div> <div class="surname">Tian</div></span>, <span class="name string-name"><div class="given-names">Nanyun</div> <div class="surname">Peng</div></span>, and <span class="name string-name"><div class="given-names">Dan</div> <div class="surname">Klein</div></span></span>. <div class="year">2022b</div>. <div class="article-title">Re3: Generating longer stories with recursive reprompting and revision</div>. In <div class="source">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</div>, pages <div class="fpage">4393</div>–<div class="lpage">4479</div>, <div class="publisher-loc">Abu Dhabi, United Arab Emirates</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2022.emnlp-main.296" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2022.emnlp-main.296</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Re3%3A%20Generating%20longer%20stories%20with%20recursive%20reprompting%20and%20revision&amp;author=Kevin%20Yang&amp;author=Yuandong%20Tian&amp;author=Nanyun%20Peng&amp;author=Dan%20Klein&amp;publication_year=2022b&amp;book=Proceedings%20of%20the%202022%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib109" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Shunyu</div> <div class="surname">Yao</div></span>, <span class="name string-name"><div class="surname">Dian</div> <div class="given-names">Yu</div></span>, <span class="name string-name"><div class="given-names">Jeffrey</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="given-names">Izhak</div> <div class="surname">Shafran</div></span>, <span class="name string-name"><div class="given-names">Tom</div> <div class="surname">Griffiths</div></span>, <span class="name string-name"><div class="given-names">Yuan</div> <div class="surname">Cao</div></span>, and <span class="name string-name"><div class="given-names">Karthik</div> <div class="surname">Narasimhan</div></span></span>. <div class="year">2023</div>. <div class="article-title">Tree of thoughts: Deliberate problem solving with large language models</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">36</div>, pages <div class="fpage">11809</div>–<div class="lpage">11822</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Tree%20of%20thoughts%3A%20Deliberate%20problem%20solving%20with%20large%20language%20models&amp;author=Shunyu%20Yao&amp;author=Yu%20Dian&amp;author=Jeffrey%20Zhao&amp;author=Izhak%20Shafran&amp;author=Tom%20Griffiths&amp;author=Yuan%20Cao&amp;author=Karthik%20Narasimhan&amp;publication_year=2023&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib110" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Michihiro</div> <div class="surname">Yasunaga</div></span> and <span class="name string-name"><div class="given-names">Percy</div> <div class="surname">Liang</div></span></span>. <div class="year">2020</div>. <div class="article-title">Graph-based, self-supervised program repair from diagnostic feedback</div>. In <div class="source">Proceedings of the 37th International Conference on Machine Learning</div>, volume <div class="volume">119 of Proceedings of Machine Learning Research</div>, pages <div class="fpage">10799</div>–<div class="lpage">10808</div>. <div class="publisher-name">PMLR</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Graph-based%2C%20self-supervised%20program%20repair%20from%20diagnostic%20feedback&amp;author=Michihiro%20Yasunaga&amp;author=Percy%20Liang&amp;publication_year=2020&amp;book=Proceedings%20of%20the%2037th%20International%20Conference%20on%20Machine%20Learning" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib111" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Michihiro</div> <div class="surname">Yasunaga</div></span> and <span class="name string-name"><div class="given-names">Percy</div> <div class="surname">Liang</div></span></span>. <div class="year">2021</div>. <div class="article-title">Break-it-fix-it: Unsupervised learning for program repair</div>. In <div class="source">Proceedings of the 38th International Conference on Machine Learning</div>, volume <div class="volume">139</div> of <div class="source">Proceedings of Machine Learning Research</div>, pages <div class="fpage">11941</div>–<div class="lpage">11952</div>. <div class="publisher-name">PMLR</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Break-it-fix-it%3A%20Unsupervised%20learning%20for%20program%20repair&amp;author=Michihiro%20Yasunaga&amp;author=Percy%20Liang&amp;publication_year=2021&amp;book=Proceedings%20of%20the%2038th%20International%20Conference%20on%20Machine%20Learning" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib112" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Seonghyeon</div> <div class="surname">Ye</div></span>, <span class="name string-name"><div class="given-names">Yongrae</div> <div class="surname">Jo</div></span>, <span class="name string-name"><div class="given-names">Doyoung</div> <div class="surname">Kim</div></span>, <span class="name string-name"><div class="given-names">Sungdong</div> <div class="surname">Kim</div></span>, <span class="name string-name"><div class="given-names">Hyeonbin</div> <div class="surname">Hwang</div></span>, and <span class="name string-name"><div class="given-names">Minjoon</div> <div class="surname">Seo</div></span></span>. <div class="year">2023</div>. <div class="article-title">Selfee: Iterative self-revising LLM empowered by self-feedback generation</div>. <div class="comment">Blog post</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Selfee%3A%20Iterative%20self-revising%20LLM%20empowered%20by%20self-feedback%20generation&amp;author=Seonghyeon%20Ye&amp;author=Yongrae%20Jo&amp;author=Doyoung%20Kim&amp;author=Sungdong%20Kim&amp;author=Hyeonbin%20Hwang&amp;author=Minjoon%20Seo&amp;publication_year=2023&amp;journal=&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib113" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Shukang</div> <div class="surname">Yin</div></span>, <span class="name string-name"><div class="surname">Chaoyou</div> <div class="given-names">Fu</div></span>, <span class="name string-name"><div class="given-names">Sirui</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="surname">Tong</div> <div class="given-names">Xu</div></span>, <span class="name string-name"><div class="given-names">Hao</div> <div class="surname">Wang</div></span>, <span class="name string-name"><div class="given-names">Dianbo</div> <div class="surname">Sui</div></span>, <span class="name string-name"><div class="given-names">Yunhang</div> <div class="surname">Shen</div></span>, <span class="name string-name"><div class="surname">Ke</div> <div class="given-names">Li</div></span>, <span class="name string-name"><div class="given-names">Xing</div> <div class="surname">Sun</div></span>, and <span class="name string-name"><div class="given-names">Enhong</div> <div class="surname">Chen</div></span></span>. <div class="year">2023</div>. <div class="article-title">Woodpecker: Hallucination correction for multimodal large language models</div>. <div class="source">arXiv preprint arXiv:2310.16045</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Woodpecker%3A%20Hallucination%20correction%20for%20multimodal%20large%20language%20models&amp;author=Shukang%20Yin&amp;author=Fu%20Chaoyou&amp;author=Sirui%20Zhao&amp;author=Xu%20Tong&amp;author=Hao%20Wang&amp;author=Dianbo%20Sui&amp;author=Yunhang%20Shen&amp;author=Li%20Ke&amp;author=Xing%20Sun&amp;author=Enhong%20Chen&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A2310.16045&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib114" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="surname">Wenhao</div> <div class="given-names">Yu</div></span>, <span class="name string-name"><div class="given-names">Zhihan</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Zhenwen</div> <div class="surname">Liang</div></span>, <span class="name string-name"><div class="given-names">Meng</div> <div class="surname">Jiang</div></span>, and <span class="name string-name"><div class="given-names">Ashish</div> <div class="surname">Sabharwal</div></span></span>. <div class="year">2023</div>. <div class="article-title">Improving language models via plug-and-play retrieval feedback</div>. <div class="source">arXiv preprint arXiv: 2305.14002</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Improving%20language%20models%20via%20plug-and-play%20retrieval%20feedback&amp;author=Yu%20Wenhao&amp;author=Zhihan%20Zhang&amp;author=Zhenwen%20Liang&amp;author=Meng%20Jiang&amp;author=Ashish%20Sabharwal&amp;publication_year=2023&amp;journal=arXiv%20preprint%20arXiv%3A%202305.14002&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib115" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Eric</div> <div class="surname">Zelikman</div></span>, <span class="name string-name"><div class="surname">Yuhuai</div> <div class="given-names">Wu</div></span>, <span class="name string-name"><div class="surname">Jesse</div> <div class="given-names">Mu</div></span>, and <span class="name string-name"><div class="given-names">Noah</div> <div class="surname">Goodman</div></span></span>. <div class="year">2022</div>. <div class="article-title">Star: Bootstrapping reasoning with reasoning</div>. In <div class="source">Advances in Neural Information Processing Systems</div>, volume <div class="volume">35</div>, pages <div class="fpage">15476</div>–<div class="lpage">15488</div>. <div class="publisher-name">Curran Associates, Inc.</div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Star%3A%20Bootstrapping%20reasoning%20with%20reasoning&amp;author=Eric%20Zelikman&amp;author=Wu%20Yuhuai&amp;author=Mu%20Jesse&amp;author=Noah%20Goodman&amp;publication_year=2022&amp;book=Advances%20in%20Neural%20Information%20Processing%20Systems" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib116" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Jintian</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="surname">Xin</div> <div class="given-names">Xu</div></span>, and <span class="name string-name"><div class="given-names">Shumin</div> <div class="surname">Deng</div></span></span>. <div class="year">2023a</div>. <div class="article-title">Exploring collaboration mechanisms for llm agents: A social psychology view</div>. <div class="source">arXiv preprint arXiv:2310.02124</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Exploring%20collaboration%20mechanisms%20for%20llm%20agents%3A%20A%20social%20psychology%20view&amp;author=Jintian%20Zhang&amp;author=Xu%20Xin&amp;author=Shumin%20Deng&amp;publication_year=2023a&amp;journal=arXiv%20preprint%20arXiv%3A2310.02124&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib117" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Kechi</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Zhuo</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Jia</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="surname">Ge</div> <div class="given-names">Li</div></span>, and <span class="name string-name"><div class="given-names">Zhi</div> <div class="surname">Jin</div></span></span>. <div class="year">2023b</div>. <div class="article-title">Self-edit: Fault-aware code editor for code generation</div>. In <div class="source">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">769</div>–<div class="lpage">787</div>, <div class="publisher-loc">Toronto, Canada</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.acl-long.45" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.acl-long.45</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Self-edit%3A%20Fault-aware%20code%20editor%20for%20code%20generation&amp;author=Kechi%20Zhang&amp;author=Zhuo%20Li&amp;author=Jia%20Li&amp;author=Li%20Ge&amp;author=Zhi%20Jin&amp;publication_year=2023b&amp;book=Proceedings%20of%20the%2061st%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib118" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Muru</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Ofir</div> <div class="surname">Press</div></span>, <span class="name string-name"><div class="given-names">William</div> <div class="surname">Merrill</div></span>, <span class="name string-name"><div class="given-names">Alisa</div> <div class="surname">Liu</div></span>, and <span class="name string-name"><div class="given-names">Noah A.</div> <div class="surname">Smith</div></span></span>. <div class="year">2023c</div>. <div class="article-title">How language model hallucinations can snowball</div>. <div class="source">arXiv preprint arXiv:2305.13534</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=How%20language%20model%20hallucinations%20can%20snowball&amp;author=Muru%20Zhang&amp;author=Ofir%20Press&amp;author=William%20Merrill&amp;author=Alisa%20Liu&amp;author=Noah%20A.%20Smith&amp;publication_year=2023c&amp;journal=arXiv%20preprint%20arXiv%3A2305.13534&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib119" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Tianyi</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="surname">Tao</div> <div class="given-names">Yu</div></span>, <span class="name string-name"><div class="given-names">Tatsunori</div> <div class="surname">Hashimoto</div></span>, <span class="name string-name"><div class="given-names">Mike</div> <div class="surname">Lewis</div></span>, <span class="name string-name"><div class="given-names">Wen-Tau</div> <div class="surname">Yih</div></span>, <span class="name string-name"><div class="given-names">Daniel</div> <div class="surname">Fried</div></span>, and <span class="name string-name"><div class="given-names">Sida</div> <div class="surname">Wang</div></span></span>. <div class="year">2023d</div>. <div class="article-title">Coder reviewer reranking for code generation</div>. In <div class="source">Proceedings of the 40th International Conference on Machine Learning</div>, volume <div class="volume">202 of Proceedings of Machine Learning Research</div>, pages <div class="fpage">41832</div>–<div class="lpage">41846</div>. <div class="publisher-name">PMLR</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Coder%20reviewer%20reranking%20for%20code%20generation&amp;author=Tianyi%20Zhang&amp;author=Yu%20Tao&amp;author=Tatsunori%20Hashimoto&amp;author=Mike%20Lewis&amp;author=Wen-Tau%20Yih&amp;author=Daniel%20Fried&amp;author=Sida%20Wang&amp;publication_year=2023d&amp;book=Proceedings%20of%20the%2040th%20International%20Conference%20on%20Machine%20Learning" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib120" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yunxiang</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Muhammad</div> <div class="surname">Khalifa</div></span>, <span class="name string-name"><div class="given-names">Lajanugen</div> <div class="surname">Logeswaran</div></span>, <span class="name string-name"><div class="given-names">Jaekyeom</div> <div class="surname">Kim</div></span>, <span class="name string-name"><div class="given-names">Moontae</div> <div class="surname">Lee</div></span>, <span class="name string-name"><div class="given-names">Honglak</div> <div class="surname">Lee</div></span>, and <span class="name string-name"><div class="given-names">Lu</div> <div class="surname">Wang</div></span></span>. <div class="year">2024</div>. <div class="article-title">Small language models need strong verifiers to self-correct reasoning</div>. In <div class="source">Findings of the Association for Computational Linguistics ACL 2024</div>, pages <div class="fpage">15637</div>–<div class="lpage">15653</div>, <div class="publisher-loc">Bangkok, Thailand and virtual meeting</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2024.findings-acl.924" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2024.findings-acl.924</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Small%20language%20models%20need%20strong%20verifiers%20to%20self-correct%20reasoning&amp;author=Yunxiang%20Zhang&amp;author=Muhammad%20Khalifa&amp;author=Lajanugen%20Logeswaran&amp;author=Jaekyeom%20Kim&amp;author=Moontae%20Lee&amp;author=Honglak%20Lee&amp;author=Lu%20Wang&amp;publication_year=2024&amp;book=Findings%20of%20the%20Association%20for%20Computational%20Linguistics%20ACL%202024" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib121" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Ruochen</div> <div class="surname">Zhao</div></span>, <span class="name string-name"><div class="given-names">Xingxuan</div> <div class="surname">Li</div></span>, <span class="name string-name"><div class="given-names">Shafiq</div> <div class="surname">Joty</div></span>, <span class="name string-name"><div class="given-names">Chengwei</div> <div class="surname">Qin</div></span>, and <span class="name string-name"><div class="given-names">Lidong</div> <div class="surname">Bing</div></span></span>. <div class="year">2023</div>. <div class="article-title">Verify-and-edit: A knowledge-enhanced chain-of-thought framework</div>. In <div class="source">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</div>, pages <div class="fpage">5823</div>–<div class="lpage">5840</div>, <div class="publisher-loc">Toronto, Canada</div>. <div class="publisher-name">Association for Computational Linguistics</div>. <div class="pub-id-doi"><a href="https://doi.org/10.18653/v1/2023.acl-long.320" class="link link-pub-id-doi openInAnotherWindow" target="_blank">
          https://doi.org/10.18653/v1/2023.acl-long.320</a></div><div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Verify-and-edit%3A%20A%20knowledge-enhanced%20chain-of-thought%20framework&amp;author=Ruochen%20Zhao&amp;author=Xingxuan%20Li&amp;author=Shafiq%20Joty&amp;author=Chengwei%20Qin&amp;author=Lidong%20Bing&amp;publication_year=2023&amp;book=Proceedings%20of%20the%2061st%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics%20%28Volume%201%3A%20Long%20Papers%29" target="_blank">Google Scholar</a></div> </div></div></div></div></div><div data-content-id="bib122" xmlns:helper="urn:XsltStringHelper"><div class="ref false"><div class="ref-content "><div class="citation mixed-citation"><span class="person-group"><span class="name string-name"><div class="given-names">Yiyang</div> <div class="surname">Zhou</div></span>, <span class="name string-name"><div class="given-names">Chenhang</div> <div class="surname">Cui</div></span>, <span class="name string-name"><div class="given-names">Jaehong</div> <div class="surname">Yoon</div></span>, <span class="name string-name"><div class="given-names">Linjun</div> <div class="surname">Zhang</div></span>, <span class="name string-name"><div class="given-names">Zhun</div> <div class="surname">Deng</div></span>, <span class="name string-name"><div class="given-names">Chelsea</div> <div class="surname">Finn</div></span>, <span class="name string-name"><div class="given-names">Mohit</div> <div class="surname">Bansal</div></span>, and <span class="name string-name"><div class="given-names">Huaxiu</div> <div class="surname">Yao</div></span></span>. <div class="year">2024</div>. <div class="article-title">Analyzing and mitigating object hallucination in large vision-language models</div>. In <div class="source">The Twelfth International Conference on Learning Representations</div>.<div class="citation-links"><div class="google-scholar-ref-link js-ref-link"><a href="https://scholar.google.com/scholar_lookup?title=Analyzing%20and%20mitigating%20object%20hallucination%20in%20large%20vision-language%20models&amp;author=Yiyang%20Zhou&amp;author=Chenhang%20Cui&amp;author=Jaehong%20Yoon&amp;author=Linjun%20Zhang&amp;author=Zhun%20Deng&amp;author=Chelsea%20Finn&amp;author=Mohit%20Bansal&amp;author=Huaxiu%20Yao&amp;publication_year=2024&amp;journal=The%20Twelfth%20International%20Conference%20on%20Learning%20Representations&amp;volume=&amp;pages=" target="_blank">Google Scholar</a></div> </div></div></div></div></div></div>
                </div>
                <div id="5111496-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111495">

                    <p></p>
                </div>
                <div id="5111497-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111495">

                    <a id = "5111497" scrollto-destination="5111497"></a><div content-id="T9 " class="table-wrap table-wide"><div id="T9" data-id="T9" class="table-wrap-title "><span class="label title-label" id="label-89484">Table 9: </span><div class="caption caption-id-" id="caption-89484"><p>Prompts for Dialogue Response Generation used in Self-Refine (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>). Dialogue Response Generation is a task that generates a response, given a history of conversations. Prompts used by Madaan et al. (<a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) for generating initial responses instruct to generate responses that are <img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i007.png?Expires=1766635869&amp;Signature=mzM5Arj8EiTk8ck6b6cxACCvrfM4sfnlNsiYFWL~rv5s95M2yNGwipdfGvglC22-Aw9HRf0NXW7R5F4i6YkakhHIfaGdbGP~hpYfHhab4-VFZHaXa9scCjrLE7SzlcQT9~Fuejx4yhlb4Op38sxZY5mfpeLUdkOXTPOEJJaV0jsuC9rwD0yIUOA2AoSMBkNRkva-tH3k27gwJBYd7XLH~gBhGfmFidkcD-cOp2FioHR06glBLnMZ2uzJGjI2dnSeT0txeogcCrE5RxBXBDW2vGPnzJr5IPjUSnYM5Zd74GHe8odiLDaLqqU~eKHfqYOMqS-505PaSc7u9YKLYf5XfQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i007.png?Expires=1766635869&amp;Signature=mzM5Arj8EiTk8ck6b6cxACCvrfM4sfnlNsiYFWL~rv5s95M2yNGwipdfGvglC22-Aw9HRf0NXW7R5F4i6YkakhHIfaGdbGP~hpYfHhab4-VFZHaXa9scCjrLE7SzlcQT9~Fuejx4yhlb4Op38sxZY5mfpeLUdkOXTPOEJJaV0jsuC9rwD0yIUOA2AoSMBkNRkva-tH3k27gwJBYd7XLH~gBhGfmFidkcD-cOp2FioHR06glBLnMZ2uzJGjI2dnSeT0txeogcCrE5RxBXBDW2vGPnzJr5IPjUSnYM5Zd74GHe8odiLDaLqqU~eKHfqYOMqS-505PaSc7u9YKLYf5XfQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="" path-from-xml="tacl_a_00713_i007.tif" />not interesting and <img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i008.png?Expires=1766635869&amp;Signature=ScusxmZS1eustcNDPHk4bDC83DyquaiOAGAtI9o0Tamu-~azthVM0gMy7-4voS49UYyym6SDJRuoqOUMrxxu2kccMc12oKZiljX8vT~Q4LBExQzSkAAuDMdIYg-YXa2Ir4Bs93NaIv0gf9XdPa6bzxUPT~fmxV9EnqZ-SrfNHU3v~5xj3f5B9bUVL-IyjfduMLObD4AYV5iMDOKMb~CZ3ykaJGtlCDibbYCKchpR2hX2XqDQbmw8VV~1Wv7PJ0T7egKHcNyju1jQFhBZ1uT35geEcClgr12LmBLYpXMJZIYzD9lcMOuk6RC684~L-flp~qgsfdjwaEWaqAzU-WvFBQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i008.png?Expires=1766635869&amp;Signature=ScusxmZS1eustcNDPHk4bDC83DyquaiOAGAtI9o0Tamu-~azthVM0gMy7-4voS49UYyym6SDJRuoqOUMrxxu2kccMc12oKZiljX8vT~Q4LBExQzSkAAuDMdIYg-YXa2Ir4Bs93NaIv0gf9XdPa6bzxUPT~fmxV9EnqZ-SrfNHU3v~5xj3f5B9bUVL-IyjfduMLObD4AYV5iMDOKMb~CZ3ykaJGtlCDibbYCKchpR2hX2XqDQbmw8VV~1Wv7PJ0T7egKHcNyju1jQFhBZ1uT35geEcClgr12LmBLYpXMJZIYzD9lcMOuk6RC684~L-flp~qgsfdjwaEWaqAzU-WvFBQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="" path-from-xml="tacl_a_00713_i008.tif" />not very engaging, which are contradicting to the task goal. They unfairly instruct the models to generate initial responses that have problems intentionally, over-evaluating self-correction performance. Prompts for generating initial responses: <a class="link link-uri" href="https://github.com/madaan/self-refine/blob/main/src/responsegen/task_init.py" target="_blank">https://github.com/madaan/self-refine/blob/main/src/responsegen/task_init.py</a> and feedback: <a class="link link-uri" href="https://github.com/madaan/self-refine/blob/main/src/responsegen/feedback.py" target="_blank">https://github.com/madaan/self-refine/blob/main/src/responsegen/feedback.py</a>. Few-shot examples for generating initial responses: <a class="link link-uri" href="https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/init.jsonl" target="_blank">https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/init.jsonl</a> and feedback: <a class="link link-uri" href="https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/feedback.jsonl" target="_blank">https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/feedback.jsonl</a>.</p></div></div><div class="fig-graphic"><a class="jumplink-placeholder" data-sectionId="5111497" id="tacl_a_00713_i006.tif"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i006.png?Expires=1766635869&amp;Signature=Jxe1HiUqhJtRcvL2KeQ41SoUnh-UDImCIMRwx7kNvri17IL-VplXOa-F8-iiuywJEmJQfxe-J37Aue6LCCfW4F5eeOVQMiawZQWP92CK8jpL25e5zY4UTqiBJ8eJQ7aAAUmuVp797808yiDKfsxOuGMscJ~ai5hZZ8OuBa80dEunYbR7agL6TdHhBZBbt4t-rR~AZHSBEbt0eoSuOXZQiANW5QQR2g3cHJWdpvzGa0Q8sY7OmbefkxyUJJIFEFbdQNpoqWmzjkaJBr9xnp9~79BF4SoiCN6ppaiOJzPuii2qyWkLofF7sNp3DZMQasJY7vrXhg8cdkOrg1y2xWTl2A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i006.png?Expires=1766635869&amp;Signature=Jxe1HiUqhJtRcvL2KeQ41SoUnh-UDImCIMRwx7kNvri17IL-VplXOa-F8-iiuywJEmJQfxe-J37Aue6LCCfW4F5eeOVQMiawZQWP92CK8jpL25e5zY4UTqiBJ8eJQ7aAAUmuVp797808yiDKfsxOuGMscJ~ai5hZZ8OuBa80dEunYbR7agL6TdHhBZBbt4t-rR~AZHSBEbt0eoSuOXZQiANW5QQR2g3cHJWdpvzGa0Q8sY7OmbefkxyUJJIFEFbdQNpoqWmzjkaJBr9xnp9~79BF4SoiCN6ppaiOJzPuii2qyWkLofF7sNp3DZMQasJY7vrXhg8cdkOrg1y2xWTl2A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Prompts for Dialogue Response Generation used in Self-Refine (Madaan et al., 2023). Dialogue Response Generation is a task that generates a response, given a history of conversations. Prompts used by Madaan et al. (2023) for generating initial responses instruct to generate responses that are not interesting and not very engaging, which are contradicting to the task goal. They unfairly instruct the models to generate initial responses that have problems intentionally, over-evaluating self-correction performance. Prompts for generating initial responses: https://github.com/madaan/self-refine/blob/main/src/responsegen/task_init.py and feedback: https://github.com/madaan/self-refine/blob/main/src/responsegen/feedback.py. Few-shot examples for generating initial responses: https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/init.jsonl and feedback: https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/feedback.jsonl." path-from-xml="tacl_a_00713_i006.tif" /></a></div><div class="fig-orig original-slide"><a section="5111497" class="fig-view-orig" href="/view-large/figure/5111497/tacl_a_00713_i006.tif" path-from-xml="tacl_a_00713_i006.tif" target="_blank">View large</a></div><div content-id="T9" class="table-modal"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i006.png?Expires=1766635869&amp;Signature=Jxe1HiUqhJtRcvL2KeQ41SoUnh-UDImCIMRwx7kNvri17IL-VplXOa-F8-iiuywJEmJQfxe-J37Aue6LCCfW4F5eeOVQMiawZQWP92CK8jpL25e5zY4UTqiBJ8eJQ7aAAUmuVp797808yiDKfsxOuGMscJ~ai5hZZ8OuBa80dEunYbR7agL6TdHhBZBbt4t-rR~AZHSBEbt0eoSuOXZQiANW5QQR2g3cHJWdpvzGa0Q8sY7OmbefkxyUJJIFEFbdQNpoqWmzjkaJBr9xnp9~79BF4SoiCN6ppaiOJzPuii2qyWkLofF7sNp3DZMQasJY7vrXhg8cdkOrg1y2xWTl2A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i006.png?Expires=1766635869&amp;Signature=Jxe1HiUqhJtRcvL2KeQ41SoUnh-UDImCIMRwx7kNvri17IL-VplXOa-F8-iiuywJEmJQfxe-J37Aue6LCCfW4F5eeOVQMiawZQWP92CK8jpL25e5zY4UTqiBJ8eJQ7aAAUmuVp797808yiDKfsxOuGMscJ~ai5hZZ8OuBa80dEunYbR7agL6TdHhBZBbt4t-rR~AZHSBEbt0eoSuOXZQiANW5QQR2g3cHJWdpvzGa0Q8sY7OmbefkxyUJJIFEFbdQNpoqWmzjkaJBr9xnp9~79BF4SoiCN6ppaiOJzPuii2qyWkLofF7sNp3DZMQasJY7vrXhg8cdkOrg1y2xWTl2A__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Prompts for Dialogue Response Generation used in Self-Refine (Madaan et al., 2023). Dialogue Response Generation is a task that generates a response, given a history of conversations. Prompts used by Madaan et al. (2023) for generating initial responses instruct to generate responses that are not interesting and not very engaging, which are contradicting to the task goal. They unfairly instruct the models to generate initial responses that have problems intentionally, over-evaluating self-correction performance. Prompts for generating initial responses: https://github.com/madaan/self-refine/blob/main/src/responsegen/task_init.py and feedback: https://github.com/madaan/self-refine/blob/main/src/responsegen/feedback.py. Few-shot examples for generating initial responses: https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/init.jsonl and feedback: https://github.com/madaan/self-refine/blob/main/data/prompt/responsegen/feedback.jsonl." path-from-xml="tacl_a_00713_i006.tif" /></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111497" target="_blank" rel="nofollow" aria-label="View large Table 9: ">
                  View Large</a></div></div>
                </div>
                <div id="5111498-content" class="article-section-wrapper js-article-section js-content-section  " data-section-parent-id="5111495">

                    <a id = "5111498" scrollto-destination="5111498"></a><div content-id="T10 " class="table-wrap table-wide"><div id="T10" data-id="T10" class="table-wrap-title "><span class="label title-label" id="label-25364">Table 10: </span><div class="caption caption-id-" id="caption-25364"><p>Few-shot examples in prompts for the Sentiment Reversal task (positive to negative) used in Self-Refine (Madaan et al., <a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>). Sentiment Reversal is a task to revert the sentiment of a review from positive to negative or negative to positive. Few-shot examples for generating initial responses include examples in settings different from the target task (positive to negative), while all few-shot examples for refinement are positive to negative. The few-shot examples used by Madaan et al. (<a href="javascript:;" data-modal-source-id="bib59" class="link link-ref xref-bibr">2023</a>) for generating initial responses unfairly have different properties from the target task. Prompts for initial responses: <a class="link link-uri" href="https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_init.py" target="_blank">https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_init.py</a> and refinement: <a class="link link-uri" href="https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_iterate.py" target="_blank">https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_iterate.py</a>.</p></div> </div><div class="fig-graphic"><a class="jumplink-placeholder" data-sectionId="5111498" id="tacl_a_00713_i009.tif"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i009.png?Expires=1766635869&amp;Signature=KO0rEiC3tbfQU7k8NMEh2IP~CM1p3G-CH7nHTXSk50l9xYA3WmDd12G3ZFcr5BdyAGvN18yXj6ECJJgB-vj0pIjerEWJeOYsVN11LZI9QGPioDLa7ca8HyvsjLSXk~TMgF3LoB809fnF9OKZj-qoAIbSzK9yBtb9SbVgRQNEGuybScaNO7Ye7ewtG9UPiiH9ilPj2dQhFAwwrBQo0HwfaHU8iCKf7g6Gsg7bThIJQVmCifmOoEhajI6c1znar~V3JHhioWmSeNLPpk41HEOgvze24X-xnk0uRYnKLVjqh595XG0Ob6Ekx6PdE5LvxNI39OAweW5d1a~LSYpPYBcqwg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i009.png?Expires=1766635869&amp;Signature=KO0rEiC3tbfQU7k8NMEh2IP~CM1p3G-CH7nHTXSk50l9xYA3WmDd12G3ZFcr5BdyAGvN18yXj6ECJJgB-vj0pIjerEWJeOYsVN11LZI9QGPioDLa7ca8HyvsjLSXk~TMgF3LoB809fnF9OKZj-qoAIbSzK9yBtb9SbVgRQNEGuybScaNO7Ye7ewtG9UPiiH9ilPj2dQhFAwwrBQo0HwfaHU8iCKf7g6Gsg7bThIJQVmCifmOoEhajI6c1znar~V3JHhioWmSeNLPpk41HEOgvze24X-xnk0uRYnKLVjqh595XG0Ob6Ekx6PdE5LvxNI39OAweW5d1a~LSYpPYBcqwg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Few-shot examples in prompts for the Sentiment Reversal task (positive to negative) used in Self-Refine (Madaan et al., 2023). Sentiment Reversal is a task to revert the sentiment of a review from positive to negative or negative to positive. Few-shot examples for generating initial responses include examples in settings different from the target task (positive to negative), while all few-shot examples for refinement are positive to negative. The few-shot examples used by Madaan et al. (2023) for generating initial responses unfairly have different properties from the target task. Prompts for initial responses: https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_init.py and refinement: https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_iterate.py." path-from-xml="tacl_a_00713_i009.tif" /></a></div><div class="fig-orig original-slide"><a section="5111498" class="fig-view-orig" href="/view-large/figure/5111498/tacl_a_00713_i009.tif" path-from-xml="tacl_a_00713_i009.tif" target="_blank">View large</a></div><div content-id="T10" class="table-modal"><img class="content-image" src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i009.png?Expires=1766635869&amp;Signature=KO0rEiC3tbfQU7k8NMEh2IP~CM1p3G-CH7nHTXSk50l9xYA3WmDd12G3ZFcr5BdyAGvN18yXj6ECJJgB-vj0pIjerEWJeOYsVN11LZI9QGPioDLa7ca8HyvsjLSXk~TMgF3LoB809fnF9OKZj-qoAIbSzK9yBtb9SbVgRQNEGuybScaNO7Ye7ewtG9UPiiH9ilPj2dQhFAwwrBQo0HwfaHU8iCKf7g6Gsg7bThIJQVmCifmOoEhajI6c1znar~V3JHhioWmSeNLPpk41HEOgvze24X-xnk0uRYnKLVjqh595XG0Ob6Ekx6PdE5LvxNI39OAweW5d1a~LSYpPYBcqwg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" data-src="https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/12/10.1162_tacl_a_00713/1/m_tacl_a_00713_i009.png?Expires=1766635869&amp;Signature=KO0rEiC3tbfQU7k8NMEh2IP~CM1p3G-CH7nHTXSk50l9xYA3WmDd12G3ZFcr5BdyAGvN18yXj6ECJJgB-vj0pIjerEWJeOYsVN11LZI9QGPioDLa7ca8HyvsjLSXk~TMgF3LoB809fnF9OKZj-qoAIbSzK9yBtb9SbVgRQNEGuybScaNO7Ye7ewtG9UPiiH9ilPj2dQhFAwwrBQo0HwfaHU8iCKf7g6Gsg7bThIJQVmCifmOoEhajI6c1znar~V3JHhioWmSeNLPpk41HEOgvze24X-xnk0uRYnKLVjqh595XG0Ob6Ekx6PdE5LvxNI39OAweW5d1a~LSYpPYBcqwg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Few-shot examples in prompts for the Sentiment Reversal task (positive to negative) used in Self-Refine (Madaan et al., 2023). Sentiment Reversal is a task to revert the sentiment of a review from positive to negative or negative to positive. Few-shot examples for generating initial responses include examples in settings different from the target task (positive to negative), while all few-shot examples for refinement are positive to negative. The few-shot examples used by Madaan et al. (2023) for generating initial responses unfairly have different properties from the target task. Prompts for initial responses: https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_init.py and refinement: https://github.com/madaan/self-refine/blob/main/src/sentiment_reversal/task_iterate.py." path-from-xml="tacl_a_00713_i009.tif" /></div><div class="graphic-wrap hide"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/5111498" target="_blank" rel="nofollow" aria-label="View large Table 10: ">
                  View Large</a></div></div>
                </div>
        <!-- /foreach -->
        </div> 









        <div class="authornotes-section-wrapper ">
                <h2 class="authorNotes-section-title" id="authorNotesSectionTitle" scrollto-destination="authorNotesSectionTitle">Author notes</h2>

            <div class="fn" content-id=""><p>Action Editor: Grzegorz Chrupała</p></div>
        </div>
        <div class="permissionstatement-section-wrapper ">

            <div class="copyright copyright-statement">© 2024 Association for Computational Linguistics</div><div class="copyright copyright-year">2024</div><div class="copyright copyright-holder">Association for Computational Linguistics</div><div class="license "><div class="license-p">This is an open-access article distributed under the terms of the <a class="link link-uri" href="https://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. For a full description of the license, please visit <a class="link link-uri" href="https://creativecommons.org/licenses/by/4.0/legalcode" target="_blank">https://creativecommons.org/licenses/by/4.0/legalcode</a>.</div></div>
        </div>
<!-- /foreach -->


        <span id="UserHasAccess" data-userHasAccess="True"></span>

    </div><!-- /.widget-items -->
</div><!-- /.module-widget --> 
    </div>

        <div id="ContentTabFilteredView"></div>

    </div>
</div>


    </div>


    </div>
<div class="user-comments-wrap js-userComments">
    <div class="widget-UserCommentBody widget-instance-UserCommentBody" 
         data-widget-name="UserCommentBody" 
         data-widget-instance="UserCommentBody">

    </div>
    <div class="widget-UserComment widget-instance-UserComment" 
         data-widget-name="UserComment" 
         data-widget-instance="UserComment">

    </div>

</div>

            <div>    <a id="FullTextLink"></a></div>



        </div>
    </div> 
    <div id="Sidebar" class="page-column page-column--right">
        <input type="hidden" class="js-sidebar-stick-only-last-ad" value=true>

    <div class="widget-AdBlock widget-instance-ArticlePageTopSidebar" 
         data-widget-name="AdBlock" 
         data-widget-instance="ArticlePageTopSidebar">


    </div>


        <div class="sidebar-widget_wrap">
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRail" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRail">
        <div class="widget widget-dynamic " data-count="1">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0">
        <div class="widget widget-dynamic right-rail" data-count="7">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B0" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B0">
        <div class="widget widget-dynamic article-alerts alerts" data-count="1">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-Alerts widget-instance-Article_RightRailB0B0article-alerts" 
         data-widget-name="Alerts" 
         data-widget-instance="Article_RightRailB0B0article-alerts">
            <div id="alerts" class="widget widget-alerts rail-widget_wrap vt-widget-alerts">
        <h3 class="alerts-widget-header">Email alerts</h3>
        <div class="widget-links_wrap">
                    <div class="userAlert alertType-1">
                            <a href="javascript:;"
                               class="js-open-alert-modal"
                               data-user-logged-in="False"
                               data-alert-type="1"
                               rel=nofollow>Article Activity Alert</a>
                    </div>
                    <div class="userAlert alertType-23">
                            <a href="javascript:;"
                               class="js-open-alert-modal"
                               data-user-logged-in="False"
                               data-alert-type="23"
                               rel=nofollow>Closed Issue Alert</a>
                    </div>
                    <div class="userAlert alertType-30">
                            <a href="javascript:;"
                               class="js-open-alert-modal"
                               data-user-logged-in="False"
                               data-alert-type="30"
                               rel=nofollow>Continuous Publishing Added Articles Alert</a>
                    </div>
                                    <div class="userAlertSignUpModal reveal-modal small"
                 data-bypass-confirmation="False"
                 data-enable-guest-signup="false"
                 data-reveal
                 role="dialog"
                 aria-hidden="true"
                 aria-live="assertive"
                 aria-labelledby="userAlertSignUpModalTitle">
                <div class="userAlertSignUp">               
                </div>
                <a href="javascript:;" role="button" class="close-reveal-modal js-close-modal" aria-label="Close alert sign-up modal">
                    <i class="icon-general-close"><span aria-hidden="true"></span></i>
                    <span class="screenreader-text">Close Modal</span>
                </a>
            </div>
        </div>
    </div>

    </div>

    </div>

</div> 
    </div>
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B1" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B1">
        <div class="widget widget-dynamic article-article-level-metrics article-level-metrics" data-count="1">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-ArticleLevelMetrics widget-instance-Article_RightRailB0B1article-article-level-metrics" 
         data-widget-name="ArticleLevelMetrics" 
         data-widget-instance="Article_RightRailB0B1article-article-level-metrics">




    <div class="artmet-wrapper horizontal-artmet">
<div class="artmet-condensed-wrap clearfix">
    <div class="artmet-condensed-stats clearfix">
            <div class="artmet-item artmet-views">
                <span class="artmet-number">8,420</span>
                <span class="artmet-text">Views</span>
            </div>

                <div class="artmet-item artmet-citations">
                    <span class="artmet-number">
                            <a href="https://www.webofscience.com/api/gateway?GWVersion=2&amp;SrcApp=silverchair&amp;SrcAuth=WosAPI&amp;KeyUT=WOS:001350672600002&amp;DestLinkType=CitingArticles&amp;DestApp=WOS_CPL" target="_blank" rel=nofollow>7</a>
                    </span>
                    <span class="artmet-text">Web of Science</span>
                </div>
                <div class="artmet-item artmet-citations">
                    <span class="artmet-number">
                            <a href="https://direct.mit.edu/tacl/crossref-citedby/125177" target="_blank" rel=nofollow>13</a>
                    </span>
                    <span class="artmet-text">Crossref</span>
                </div>

            <div class="artmet-item artmet-badges-wrap">

                    <div class="artmet-item artmet-dimensions">
    <div class="widget-DimensionsBadge widget-instance-ArticleLevelMetrics_DimensionsBadge" 
         data-widget-name="DimensionsBadge" 
         data-widget-instance="ArticleLevelMetrics_DimensionsBadge">
        <span class="__dimensions_badge_embed__" 
      data-doi="10.1162/tacl_a_00713" 
      data-legend="false" 
      data-style="small_circle" 
      data-hide-zero-citations="true"></span>
<script async src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script>

    </div>

                    </div>
            </div>
    </div>
        <div class="artmet-modal-trigger-wrap clearfix">
            <a href="javascript:;" class="artmet-modal-trigger js-artmet-modal-trigger at-alm-metrics-modal-trigger" data-article-id="125177" rel=nofollow><i class="icon-metrics"></i><span>View Metrics</span></a>
        </div>
</div>


            <div class="artmet-modal js-artmet-modal" id="MetricsModal" role="dialog" aria-hidden="true" aria-live="assertive" aria-labelledby="widget-title-1-id">
                <div class="artmet-modal-contents js-metric-modal-contents at-alm-modal-contents" id="MetricsModalContents">
                    <a href="javascript:;" role="button" class="artmet-close-modal js-artmet-close-modal" aria-label="Close metrics modal">
                        <span aria-hidden="true">&#215;</span>
                        <span class="screenreader-text">Close Modal</span>
                    </a>
                </div>
            </div>
    </div>


    </div>

    </div>

</div> 
    </div>
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B2" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B2">
        <div class="widget widget-dynamic home-adblock" data-count="1">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-AdBlock widget-instance-Article_RightRailB0B2Article_RightRail_Pillow_Ad_Bottom" 
         data-widget-name="AdBlock" 
         data-widget-instance="Article_RightRailB0B2Article_RightRail_Pillow_Ad_Bottom">
            <input type="hidden"
           class="hfAdBlockInfo"
           data-divid="placement_451584_adBlockNone"
           data-slotname="451584"
           data-targetname="179758"
           data-sizes="[[300, 350]]"
           data-enabled-on-mobile="True"
           data-adprovider-typeid="2"
           data-accountid=""
           data-outofpagead="False"
           data-sticky-time="5"
           data-lazyloaded="False"
           data-position-keyword=""
           data-skip-size-mapping="False"
           data-wps-adsize-number="0"
           data-wps-network-id="0"
           data-wps-site-id="0"
           data-wps-zone-ids=""
           data-wps-brandlock-keyword=""
           data-tapnative-aid=""
           data-tapnative-div-id=""/>
    <div class="adblock-wrap js-adblock-wrap " style="width:300px;">
                    <p class="adblock-advertisement-text js-adblock-advertisement-text hide">Advertisement</p>

<div id="placement_451584_adBlockNone" adslot="451584" class="adblock-slot-placeholder js-adblock" style="width:300px; height:350px;"></div>


    </div>


    </div>

    </div>

</div> 
    </div>
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B3" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B3">
        <div class="widget widget-dynamic articlelistnewandpopular article-list-new-popular" data-count="1">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-ArticleListNewAndPopular widget-instance-Article_RightRailB0B3Article_ArticleNewPopularCombined" 
         data-widget-name="ArticleListNewAndPopular" 
         data-widget-instance="Article_RightRailB0B3Article_ArticleNewPopularCombined">
            <div class="vt-new-and-popular-combined new-and-popular-combined">
        <ul class="articleListNewAndPopularCombinedView">
                <li>
                    <a href="javascript:;" class="js-new-and-popular-mode active" data-mode="MostRecent" data-instanceName="Article_RightRailB0B3Article_ArticleNewPopularCombined">Latest</a>
                </li>
                <li>
                    <a href="javascript:;" class="js-new-and-popular-mode " data-mode="MostRead" data-instanceName="Article_RightRailB0B3Article_ArticleNewPopularCombined">Most Read</a>
                </li>
                <li>
                    <a href="javascript:;" class="js-new-and-popular-mode " data-mode="MostCited" data-instanceName="Article_RightRailB0B3Article_ArticleNewPopularCombined">Most Cited</a>
                </li>
        </ul>
            <section class="js-new-and-popular-content js-new-and-popular-content-MostRecent hasContent">




    <div id="newPopularList-Article_RightRailB0B3Article_ArticleNewPopularCombined" class="fb new-and-popular vt-new-and-popular-Article_RightRailB0B3Article_ArticleNewPopularCombined">


        <div class="widget-dynamic-entry-wrap">
<div class="widget-dynamic-entry">
    <div class="fb-item-title">
                <a href="/tacl/article/doi/10.1162/TACL.a.50/134149/Objectifying-the-Subjective-Cognitive-Biases-in">Objectifying the Subjective: Cognitive Biases in Topic Interpretations</a>


    </div>
</div>
<div class="widget-dynamic-entry">
    <div class="fb-item-title">
                <a href="/tacl/article/doi/10.1162/TACL.a.44/133861/Safe-Pruning-LoRA-Robust-Distance-Guided-Pruning">Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs</a>


    </div>
</div>
<div class="widget-dynamic-entry">
    <div class="fb-item-title">
                <a href="/tacl/article/doi/10.1162/TACL.a.45/133863/CRVQ-Channel-Relaxed-Vector-Quantization-for">CRVQ: Channel-Relaxed Vector Quantization for Extreme Compression of LLMs</a>


    </div>
</div>
<div class="widget-dynamic-entry">
    <div class="fb-item-title">
                <a href="/tacl/article/doi/10.1162/TACL.a.43/133801/Adversarial-Defense-without-Adversarial-Defense">Adversarial Defense without <em>Adversarial Defense</em>: Enhancing Language Model Robustness via Instance-level Principal Component Removal</a>


    </div>
</div>
        </div>
    </div>
            </section>
            <section class="js-new-and-popular-content js-new-and-popular-content-MostRead hide">
            </section>
            <section class="js-new-and-popular-content js-new-and-popular-content-MostCited hide">
            </section>
        <div class="spinner hide"></div>
    </div>

    </div>

    </div>

</div> 
    </div>
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B4" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B4">
        <div class="widget widget-dynamic article-article-cited-by article-cited-by" data-count="1">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-ArticleCitedBy widget-instance-Article_RightRailB0B4article-article-cited-by" 
         data-widget-name="ArticleCitedBy" 
         data-widget-instance="Article_RightRailB0B4article-article-cited-by">
        <div class="rail-widget_wrap vt-articles-cited-by">
    <h3 class="article-cited-title">Cited By</h3>
    <div class="widget-links_wrap">
            <div class="article-cited-link-wrap web-of-science">
                <a href="https://www.webofscience.com/api/gateway?GWVersion=2&SrcApp=silverchair&SrcAuth=WosAPI&KeyUT=WOS:001350672600002&DestLinkType=CitingArticles&DestApp=WOS_CPL" target="_blank" rel="nofollow">Web of Science (7)</a>
            </div>
                    <div class="article-cited-link-wrap google-scholar-url">
                <a href="http://scholar.google.com/scholar?q=link:https%3A%2F%2Fdirect.mit.edu%2Ftacl%2Farticle%2Fdoi%2F10.1162%2Ftacl_a_00713%2F125177" target="_blank" rel="nofollow">Google Scholar</a>
            </div>
                    <div class="article-cited-link-wrap crossref-citedby">
                <a href="https://direct.mit.edu/tacl/crossref-citedby/125177" rel="nofollow">Crossref (13)</a>
            </div>
    </div>
</div> 
    </div>

    </div>

</div> 
    </div>
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B5" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B5">
        <div class="widget widget-dynamic article-related-content-solr-articles related-content-solr" data-count="2">


    <div class="widget-dynamic-inner-wrap">

    <div class="widget-RelatedContentSolr widget-instance-Article_RightRailB0B5Article_RightRail_RelatedContentArticles" 
         data-widget-name="RelatedContentSolr" 
         data-widget-instance="Article_RightRailB0B5Article_RightRail_RelatedContentArticles">
            <div class="vt-related-content related-content_wrap rail-widget_wrap">
        <h3>Related Articles</h3>

        <div class="widget-links_wrap">
                <div class="article-title">
                    <a href="/daed/article/143/2/53/27016/Correcting-Past-Health-Policy-Mistakes">Correcting Past Health Policy Mistakes</a>
    <div class="content-meta"><span class="j-name">Daedalus</span> <span class="j-date">(April,2014)</span></div>

                </div>
                <div class="article-title">
                    <a href="/tacl/article/doi/10.1162/tacl_a_00251/43532/Grammar-Error-Correction-in-Morphologically-Rich">Grammar Error Correction in Morphologically Rich Languages: The Case of Russian</a>
    <div class="content-meta"><span class="j-name">Transactions of the Association for Computational Linguistics</span> <span class="j-date">(March,2019)</span></div>

                </div>
                <div class="article-title">
                    <a href="/coli/article/41/1/175/1493/Spelling-Error-Patterns-in-Brazilian-Portuguese">Spelling Error Patterns in Brazilian Portuguese</a>

                </div>
                <div class="article-title">
                    <a href="/ngtn/article/34/4/401/121663/The-Eight-Big-Negotiation-Mistakes-that">The Eight Big Negotiation Mistakes that Entrepreneurs Make</a>

                </div>
        </div>
    </div>

    </div>
    <div class="widget-RelatedContentSolr widget-instance-Article_RightRailB0B5Article_RightRail_RelatedContentChapters" 
         data-widget-name="RelatedContentSolr" 
         data-widget-instance="Article_RightRailB0B5Article_RightRail_RelatedContentChapters">
            <div class="vt-related-content related-content_wrap rail-widget_wrap">
        <h3>Related Book Chapters</h3>

        <div class="widget-links_wrap">
                <div class="article-title">
                    <a href="https://direct.mit.edu/books/book/5573/chapter/4142237/Our-Moral-Mistakes">Our Moral Mistakes</a>
    <div class="content-meta"><span class="b-name">Parenting on Earth: A Philosopher's Guide to Doing Right by Your Kids—and Everyone Else</span></div>

                </div>
                <div class="article-title">
                    <a href="https://direct.mit.edu/books/monograph/3793/chapter/124659/Why-Action-Theory-Rests-on-a-Mistake">Why Action Theory Rests on a Mistake</a>
    <div class="content-meta"><span class="b-name">Dynamics in Action: Intentional Behavior as a Complex System</span></div>

                </div>
                <div class="article-title">
                    <a href="https://direct.mit.edu/books/book/3659/chapter/121893/The-Belated-Actuality-of-Marx-s-Critique-of">The Belated Actuality of Marx’s Critique of Political Economy</a>
    <div class="content-meta"><span class="b-name">Incontinence of the Void: Economico-Philosophical Spandrels</span></div>

                </div>
        </div>
    </div>

    </div>

    </div>

</div> 
    </div>
    <div class="widget-DynamicWidgetLayout widget-instance-Article_RightRailB0B6" 
         data-widget-name="DynamicWidgetLayout" 
         data-widget-instance="Article_RightRailB0B6">
        <div class="widget widget-dynamic article-self-serve-content-ad-bottom self-serve-content-ad-bottom self-serve-content-ad" data-count="1">


    <div class="widget-dynamic-inner-wrap">


    </div>

</div> 
    </div>

    </div>

</div> 
    </div>

    </div>

</div> 
    </div>

        </div>

    <div class="widget-AdBlock widget-instance-ArticlePageTopMainBodyBottom" 
         data-widget-name="AdBlock" 
         data-widget-instance="ArticlePageTopMainBodyBottom">


    </div>




    </div> 
</div>



    <div class="widget-Lockss widget-instance-Article_Lockss" 
         data-widget-name="Lockss" 
         data-widget-instance="Article_Lockss">

    </div>




    <div class="widget-VideoListAccess widget-instance-Article_VideoListAccess" 
         data-widget-name="VideoListAccess" 
         data-widget-instance="Article_VideoListAccess">

    </div>



        </div><!-- /.content-main_content -->
    </section>
</div>
<div class="mobile-mask">
</div>
<section class="footer_wrap vt-site-footer">



<div class="ad-banner js-ad-banner ad-banner-footer">
    <div class="widget-AdBlock widget-instance-FooterAd" 
         data-widget-name="AdBlock" 
         data-widget-instance="FooterAd">
            <input type="hidden"
           class="hfAdBlockInfo"
           data-divid="placement_451585_adBlockFooter"
           data-slotname="451585"
           data-targetname="179758"
           data-sizes="[[728, 90]]"
           data-enabled-on-mobile="True"
           data-adprovider-typeid="2"
           data-accountid=""
           data-outofpagead="False"
           data-sticky-time="5"
           data-lazyloaded="False"
           data-position-keyword=""
           data-skip-size-mapping="False"
           data-wps-adsize-number="0"
           data-wps-network-id="0"
           data-wps-site-id="0"
           data-wps-zone-ids=""
           data-wps-brandlock-keyword=""
           data-tapnative-aid=""
           data-tapnative-div-id=""/>
    <div class="adblock-wrap js-adblock-wrap " style="width:728px;">
                    <p class="adblock-advertisement-text js-adblock-advertisement-text hide">Advertisement</p>

<div id="placement_451585_adBlockFooter" adslot="451585" class="adblock-slot-placeholder js-adblock" style="width:728px; height:90px;"></div>


    </div>


    </div>

</div>

<div class="sticky-footer-ad js-sticky-footer-ad">
    <div class="widget-AdBlock widget-instance-StickyAd" 
         data-widget-name="AdBlock" 
         data-widget-instance="StickyAd">


    </div>

</div>


    <div class="widget-SitePageFooter widget-instance-SitePageFooter" 
         data-widget-name="SitePageFooter" 
         data-widget-instance="SitePageFooter">
            <div class="journal-footer journal-bg">
        <div class="journal-footer_content clearfix foot-left">
    <div class="journal-footer-affiliations aff-left">
        <!-- <h3>Affiliations</h3> -->
            <a href="#" target="">
                <img id="footer-logo-TransactionsoftheAssociationforComputationalLinguistics" class="journal-footer-affiliations-logo" src="//mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/tacl/TACL_title-606805150.svg" alt="Transactions of the Association for Computational Linguistics" />
            </a>
    </div>
        </div>
    <div class="journal-footer-colophon">
        <ul>
                <li><span>Online ISSN</span> 2307-387X</li>
                                </ul>
    </div>
    </div>

    </div>



<div class="site-theme-footer">
        <div class="site-theme-footer_content">
    <div class="widget-SelfServeContent widget-instance-UmbrellaFooterSelfServe" 
         data-widget-name="SelfServeContent" 
         data-widget-instance="UmbrellaFooterSelfServe">




    <input type="hidden" class="SelfServeContentId" value="GlobalFooter_Links" />
    <input type="hidden" class="SelfServeVersionId" value="0" />

<footer>
<div class="site-theme-footer">
<div class="site-theme-footer_content">
<div class="widget-SelfServeContent widget-instance-UmbrellaFooterSelfServe">
<div class="site-theme-footer">
<div class="site-theme-footer_content">
<div class="widget-SelfServeContent widget-instance-UmbrellaFooterSelfServe">
<div class="theme-footer">
<div class="flex-row">
<div class="col-3 custom footer-branding">
<div class="footer-logo-wrap">
<div class="footer-logo">
<a href="https://direct.mit.edu">
<img alt="MIT Press Direct, home" src="//mitp.silverchair-cdn.com/UI/app/svg/umbrella/logo.svg" />
</a>
</div>
</div>
<div class="contact-info-wrap">
<h5 class="mb-1">A product of <a href="https://mitpress.mit.edu" target="_blank">The MIT Press</a></h5>
<a href="https://mitpress.mit.edu/newsletter/" class="btn mb-1">Newsletter sign up</a>
</div>
<div class="social-icons-wrap">
<ul class="social-icons-list">
    <!-- Bluesky -->
    <li><a class="social-link" href="https://bsky.app/profile/mitpress.bsky.social" target="_blank"><span class="icon-social-bluesky"></span><span class="screenreader-text">Bluesky</span></a></li>
    <!-- Facebook -->
    <li><a class="social-link" href="https://www.facebook.com/mitpress/" target="_blank"><span class="icon-social-facebook"></span><span class="screenreader-text">Facebook</span></a></li>
    <!-- Instagram -->
    <li><a class="social-link" href="https://www.instagram.com/mitpress/" target="_blank"><span class="icon-social-instagram"></span><span class="screenreader-text">Instagram</span></a></li>
    <!-- Linked In -->
    <li><a class="social-link" href="https://www.linkedin.com/company/the-mit-press/" target="_blank"><span class="icon-social-linkedin"></span><span class="screenreader-text">LinkedIn</span></a></li>
    <!-- X -->
    <li><a class="social-link" href="https://twitter.com/mitpress" target="_blank"><span class="icon-social-twitter"></span><span class="screenreader-text">X</span></a></li>
    <!-- YouTube -->
    <li><a class="social-link" href="https://www.youtube.com/channel/UCeH0hmlPjGW2DN0Ntmd0FCQ" target="_blank"><span class="icon-social-youtube"></span><span class="screenreader-text">YouTube</span></a></li>
</ul>
</div>
</div>
<div class="col-9 custom footer-nav">
<div class="flex-row">
<div class="col-3">
<div class="footer-links-group with-header">
<h3 class="footer-links-header">MIT Press Direct</h3>
<ul class="list-lvl-0">
    <li class="list-lvl-0"><a href="/about">About MIT Press Direct</a></li>
    <li class="list-lvl-0"><a href="/books">Books</a></li>
    <li class="list-lvl-0"><a href="/journals">Journals</a></li>
    <li class="list-lvl-0"><a href="/pages/cognet">CogNet</a></li>
</ul>
</div>
</div>
<div class="col-3">
<div class="footer-links-group with-header">
<h3 class="footer-links-header">Information</h3>
<ul class="list-lvl-0">
    <li class="list-lvl-0"><a href="https://accessibility.mit.edu/" target="_blank">Accessibility at MIT<br />
    </a></li>
    <li class="list-lvl-0"><a href="https://direct.mit.edu/pages/accessibility">MIT Press Direct VPAT</a></li>
    <li class="list-lvl-0"><a href="/journals/pages/authors">For Authors</a></li>
    <li class="list-lvl-0"><a href="/pages/customer_support">For Customers</a></li>
    <li class="list-lvl-0"><a href="/pages/librarians">For Librarians</a></li>
    <li class="list-lvl-0"><a href="/books/pages/direct-to-open">Direct to Open</a></li>
    <li class="list-lvl-0"><a href="/journals/pages/open-access">Open Access</a></li>
    <li class="list-lvl-0"><a href="https://mitpress.mit.edu/media-inquiries/" target="_new">Media Inquiries</a></li>
    <li class="list-lvl-0"><a href="/journals/pages/rights-permissions">Rights and Permissions</a></li>
    <li class="list-lvl-0"><a href="/journals/pages/advertising-info">For Advertisers</a></li>
</ul>
</div>
</div>
<div class="col-3">
<div class="footer-links-group with-header">
<h3 class="footer-links-header">MIT Press</h3>
<ul class="list-lvl-0">
    <li class="list-lvl-0"><a href="https://mitpress.mit.edu/about" target="_blank">About the MIT Press</a></li>
    <li class="list-lvl-0"><a href="https://thereader.mitpress.mit.edu/" target="_blank">The MIT Press Reader</a></li>
    <li class="list-lvl-0"><a href="https://mitpress.mit.edu/blog" target="_blank">MIT Press Blog</a></li>
    <li class="list-lvl-0"><a href="https://mitpress.mit.edu/catalogs" target="_blank">Seasonal Catalogs</a></li>
    <li class="list-lvl-0"><a href="https://mitpress.mit.edu" target="_blank">MIT Press Home</a></li>
    <li class="list-lvl-0"><a href="https://mitpress.mit.edu/give-mit-press" target="_blank">Give to the MIT Press</a></li>
</ul>
</div>
</div>
<div class="col-3">
<div class="footer-links-group with-header">
<h3 class="footer-links-header">Contact Us</h3>
<ul class="list-lvl-0">
    <li class="list-lvl-0"><a href="/books/pages/User_Guides_and_FAQ">FAQ</a></li>
    <li class="list-lvl-0"><a href="https://mitpress.atlassian.net/servicedesk/customer/portal/3" target="_blank">Direct Service Desk</a></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="legal-links-wrap">
<div class="copyright-date">
© 2025 The MIT Press
</div>
<ul class="legal-links">
    <li>
    <a href="https://mitpress.mit.edu/terms-use">Terms of Use</a>
    </li>
    <li>
    <a href="https://mitpress.mit.edu/privacy" target="_new">Privacy
    Statement</a>
    </li>
    <li>
    <a href="https://www.crossref.org/" target="_blank">Crossref Member</a>
    </li>
    <li>
    <a href="https://www.projectcounter.org/" target="_blank">COUNTER Member</a>&nbsp;</li>
    <li class="copyright">The MIT Press colophon is registered in the U.S. Patent and Trademark Office</li>
</ul>
</div>
</div>
</div>
</div>
<!-- /.center-inner-row -->
</div>
<!-- /.site-theme-footer --></div>
</div>
</div>
</footer>




    </div>



        </div><!-- /.center-inner-row -->
</div><!-- /.site-theme-footer -->
<div class="ss-ui-only">

    <div class="widget-SelfServeContent widget-instance-SSuiOnlySelfServe" 
         data-widget-name="SelfServeContent" 
         data-widget-instance="SSuiOnlySelfServe">




    <input type="hidden" class="SelfServeContentId" value="SSuiOnly" />
    <input type="hidden" class="SelfServeVersionId" value="0" />

<style type="text/css">
    .jumplink-list .section-jump-link a, .jumplink-list-flyout .section-jump-link a, .list-book-jumplinks .section-jump-link a, .list-issue-jumplinks .section-jump-link a, .section-jump-link__sublist .section-jump-link a {
    text-transform: none;
    }
    .article-list-resources .articleClientType {
    text-transform: none;
    }
    /*DO NOT REMOVE - JL - 8/31/20*/
    .icon-corresponding_author:before {
    content: "\f199";
    }
    .pg_Book h1.book-info__title {
    font-size: 2.6rem;
    }
    .pg_Book h1.book-info__title i {
    font-size: 1.5rem;
    }
    .widget-SelfServeContent ul.article-list, .widget-SelfServeContent ul.topic-list, .widget-SelfServeContent ul.nb {
    list-style-type: none;
    }
    .pg_Book #divBookToc .book-info__meta .book-info__abstract .abstract p {
    margin-top: 1rem;
    }
    .pg_Book #divBookToc .book-info__meta .book-info__abstract .abstract p:first-of-type {
    margin-top: 0;
    }
    /*homepage layout*/
    .homepage-panel-wrap {
    display: block;
    }
    body[theme-umbrella] .home-hero-feature .homepage-panel-text {
    padding: 1.5rem;
    }
    body[theme-umbrella] .homepage-panel-wrap{
    display: flex;
    border-bottom: 1px solid #ededed;
    padding-bottom: 1rem;
    margin-bottom: 1rem;
    }
    body[theme-umbrella] .homepage-panel-wrap:last-of-type {
    border-bottom: none;
    }
    @include for-size(sm-phone-only) {
    body[theme-umbrella] .homepage-panel-wrap{
    flex-direction: column;
    }
    }
    body[theme-umbrella] .homepage-panel-wrap .homepage-panel-image {
    flex-grow: 1;
    }
    body[theme-umbrella] .homepage-panel-wrap .homepage-panel-image img {
    border: solid 1px #ededed;
    }
    body[theme-umbrella] .homepage-panel-wrap .homepage-panel-text {
    flex-basis: 60%;
    }
    @media all and (max-width: $bp_x-small) {
    body[theme-umbrella] .homepage-panel-wrap .homepage-panel-text {
    flex-basis: 100%;
    }
    }
    body[theme-umbrella] &.pg_Index .home-row1 .home-hero-feature .widget-instance-_home-hero-feature .homepage-panel-wrap {
    @include for-size(sm-phone-only) {
    width: 100% !important;
    }
    }
    /**/
    .widget-instance-_home-hero-feature .homepage-panel-text {flex-basis: 100% !important;}
    .home-row1 .home-self-serve-content-new .homepage-panel-text {
    padding: 0 1rem;
    }
    .home-row1 .homepage-panel-wrap img {max-width: 200px;}
    @media all and (max-width: 899px) {
    .home-row1 .theme-homepage-layout div[class*=home-row]>.widget-dynamic-inner-wrap {display: block;}
    }
    @media all and (max-width: 899px) {
    .home-row1 .widget-instance-_home-self-serve-content-new {margin-top: 1rem;}
    }
    body[theme-umbrella] .home-row1 .homepage-panel-wrap .homepage-panel-image {flex-grow: 0;}
    /**/
    .widget-instance-_home-hero-feature .homepage-panel-text {flex-basis: 100% !important;}
    .home-row1 .home-self-serve-content-new .homepage-panel-text {
    padding: 0 1rem;
    }
    .home-row1 .homepage-panel-wrap img {max-width: 200px;}
    @media all and (max-width: 899px) {
    .home-row1 .theme-homepage-layout div[class*=home-row]>.widget-dynamic-inner-wrap {display: block;}
    }
    @media all and (max-width: 899px) {
    .home-row1 .widget-instance-_home-self-serve-content-new {margin-top: 1rem;}
    }
    body[theme-umbrella] .home-row1 .homepage-panel-wrap .homepage-panel-image {flex-grow: 0;}
    /*SCMP-26926*/
    body.leftRailModalOpen .page-column--center.can-stick {
    z-index: 1;
    }
    /*SCMP-26926*/
</style>




    </div>

</div>

<div class="ad-banner js-ad-interstitial">
    <div class="widget-AdBlock widget-instance-Interstitial" 
         data-widget-name="AdBlock" 
         data-widget-instance="Interstitial">


    </div>

</div>
</section>









    <div class="widget-SiteWideModals widget-instance-SiteWideModals" 
         data-widget-name="SiteWideModals" 
         data-widget-instance="SiteWideModals">
        <div id="revealModal" class="reveal-modal" data-reveal aria-hidden="true" aria-live="assertive" tabindex="-1">
    <div id="revealContent"></div>
    <a class="close-reveal-modal" href="javascript:;" aria-label="Close modal"><i class="icon-general-close"><span class="screenreader-text">Close Modal</span></i></a>
</div>

<div id="globalModalContainer" class="modal-global-container"
     role="dialog"
     aria-hidden="true"
     aria-live="assertive"
     tabindex="-1">
    <div id="globalModalContent">
        <div class="js-globalModalPlaceholder"></div>
    </div>
    <a href="javascript:;" class="close-modal js-close-modal" role="button" aria-label="Close modal">
        <i class="icon-general-close" aria-hidden="true"></i>
        <span class="screenreader-text">Close Modal</span>
    </a>
</div>
<div id="globalModalOverlay" class="modal-overlay js-modal-overlay"></div>

    <div id="NeedSubscription" class="reveal-modal small" data-reveal>
            <div class="subscription-needed">
                <h5 class="modal-heading">This Feature Is Available To Subscribers Only</h5>
                <p><a class="btn modal-sign_in-btn" href="/sign-in?returnUrl=%2ftacl%2farticle%2fdoi%2f10.1162%2ftacl_a_00713%2f125177%2fWhen-Can-LLMs-Actually-Correct-Their-Own-Mistakes">Sign In</a> or <a class="modal-register-link" href="/my-account/register?siteId=1000067&amp;returnUrl=%2ftacl%2farticle%2fdoi%2f10.1162%2ftacl_a_00713%2f125177%2fWhen-Can-LLMs-Actually-Correct-Their-Own-Mistakes">Create an Account</a></p>
            </div>


        <a class="close-reveal-modal" href="javascript:;"><i class="icon-general-close"><span class="screenreader-text">Close Modal</span></i></a>
    </div>


<div id="noAccessReveal" class="reveal-modal tiny" data-reveal>
    <a class="close-reveal-modal" href="javascript:;" aria-label="Close modal"><i class="icon-general-close"><span class="screenreader-text">Close Modal</span></i></a>
    <div id="noAccessForm">
        <div class="spinner"></div>
    </div>
</div> 
    </div>





<script type="text/javascript">
    MathJax = {
        tex: {
            inlineMath: [['|$', '$|'], ['\\(', '\\)']]
        }
    };
</script>
<script id="MathJax-script" async src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


    <!-- CookiePro Default Categories -->
    <!-- When the Cookie Compliance code loads, if cookies for the associated group have consent...
         it will dynamically change the tag to: script type=text/JavaScript...
         the code inside the tags will then be recognized and run as normal. -->
























    <script type="text/javascript" src="//mitp.silverchair-cdn.com/Themes/Client/app/jsdist/v-638984277138505729/site.min.js"></script>




    <script async="async" src="//cdn.jsdelivr.net/chartist.js/latest/chartist.min.js"></script>












    <div class="widget-GdprCookieBanner widget-instance-GdprCookieBanner" 
         data-widget-name="GdprCookieBanner" 
         data-widget-instance="GdprCookieBanner">
        <div class="gdpr-cookie-wrapper js-gdpr-banner at-gdprprompt hidden">
    <div class="gdpr-cookie-body">
        This site uses cookies. By continuing to use our website, you are agreeing to <a href="https://direct.mit.edu/DocumentLibrary/MITP%20Direct%20PRIVACY%20POLICY%202019-02-26.pdf">our privacy policy.</a> No content on this site may be used to train artificial intelligence systems without permission in writing from the MIT Press.
    </div>
    <div class="gdpr-cookie-links_wrap">
        <a href="javascript:;" class="js-gdpr-cookie-acceptLink at-acceptgdpr" aria-label="Accept cookie consent">Accept</a>
    </div>
            <input id="hdnDomain" type="hidden" value=".mit.edu" />

    <input id="hdnDomainGdpr" type="hidden" value=".mit.edu" />
    <input id="hdnClientIdGdpr" type="hidden" value="32" />
</div> 
    </div>


    <div class="ad-banner js-ad-riser ad-banner-riser">
    <div class="widget-AdBlock widget-instance-RiserAd" 
         data-widget-name="AdBlock" 
         data-widget-instance="RiserAd">


    </div>

    </div>




    <div class="end-of-page-js"></div>
<script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9a159c208eb3ebc9',t:'MTc2MzYxNzE5OC4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
</html>            </div>
        </div>

    </div>
</body>
</html>