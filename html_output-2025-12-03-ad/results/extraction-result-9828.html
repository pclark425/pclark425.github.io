<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9828 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9828</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9828</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-247291786</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2203.02540v5.pdf" target="_blank">Evolving symbolic density functionals</a></p>
                <p><strong>Paper Abstract:</strong> Systematic development of accurate density functionals has been a decades-long challenge for scientists. Despite emerging applications of machine learning (ML) in approximating functionals, the resulting ML functionals usually contain more than tens of thousands of parameters, leading to a huge gap in the formulation with the conventional human-designed symbolic functionals. We propose a new framework, Symbolic Functional Evolutionary Search (SyFES), that automatically constructs accurate functionals in the symbolic form, which is more explainable to humans, cheaper to evaluate, and easier to integrate to existing codes than other ML functionals. We first show that, without prior knowledge, SyFES reconstructed a known functional from scratch. We then demonstrate that evolving from an existing functional Ï‰B97M-V, SyFES found a new functional, GAS22 (Google Accelerated Science 22), that performs better for most of the molecular types in the test set of Main Group Chemistry Database (MGCDB84). Our framework opens a new direction in leveraging computing power for the systematic development of symbolic density functionals.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9828.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9828.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Schmidt-Lipson 2009</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distilling free-form natural laws from experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A symbolic-regression approach for automatically discovering closed-form mathematical relations (natural laws) from experimental data; cited here among related works on symbolic discovery of equations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distilling free-form natural laws from experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Schmidt & Lipson symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A symbolic regression technique that searches over expressions to fit observed data and extracts closed-form laws; no architecture or parameter-size information is given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>physics / general empirical sciences</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>physical law / empirical formula / closed-form equation</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Symbolic regression over candidate algebraic expressions evaluated against experimental data (as cited by title and placement in related-work list).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9828.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Feynman</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A physics-inspired method for symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A physics-inspired symbolic regression method (AI Feynman) for discovering symbolic formulas from data; cited as a relevant prior on symbolic discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A physics-inspired method for symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>AI Feynman</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A physics-inspired symbolic-regression pipeline that leverages physics heuristics to simplify and decompose problems for symbolic discovery; no implementation details are provided in this supplementary text.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>physics / symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>physical law / symbolic formula</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Physics-inspired decomposition and symbolic regression (as implied by the cited title and context).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9828.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SISSO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SISSO: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A compressed-sensing-based symbolic descriptor discovery method (SISSO) for finding low-dimensional models from large candidate feature spaces; cited in context of symbolic/model-discovery methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SISSO (compressed-sensing symbolic regression)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A compressed-sensing approach that selects sparse, physically meaningful descriptors from a very large pool of candidate functions; no architecture/size details appear in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science / descriptor discovery</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>empirical descriptor / low-dimensional model</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compressed-sensing-based selection of symbolic descriptors from a candidate space (as cited by title and placement).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9828.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural-guided SR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-guided symbolic regression with semantic prior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-guided symbolic regression approach that uses learned priors to guide symbolic search; cited among prior methods for discovering symbolic relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural-guided symbolic regression with semantic prior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Neural-guided symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A hybrid approach combining neural-network guidance with symbolic-regression search (paper cites the title; no implementation details provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>machine learning / symbolic discovery</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>symbolic formula / empirical relationship</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Neural networks provide semantic priors to guide symbolic-regression search (implied by the cited title).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9828.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cranmer et al. 2020</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discovering symbolic models from deep learning with inductive biases</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work on extracting compact symbolic models from deep-learning representations by leveraging inductive biases; cited as related work on discovering symbolic models from learned models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Discovering symbolic models from deep learning with inductive biases</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Deep-learning-derived symbolic discovery</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An approach that seeks to derive symbolic expressions from deep-learning models by incorporating inductive biases; no architecture/size specifics are provided in the supplement.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>machine learning / physics / general modeling</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>symbolic formula / governing equation</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Extract symbolic models from deep-learning representations using inductive biases (as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9828.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic Physics Learner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic physics learner: Discovering governing equations via Monte Carlo tree search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method using Monte Carlo tree search for symbolic discovery of governing equations; cited as part of the literature on equation discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Symbolic physics learner: Discovering governing equations via Monte Carlo tree search</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Symbolic Physics Learner (MCTS-based)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A Monte Carlo tree search approach to symbolic regression for governing-equation discovery; implementation specifics are not provided in this supplement.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>physics / dynamical systems</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>governing equations / symbolic laws</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Monte Carlo tree search over symbolic expression space to find equations that explain data (as implied by the cited title).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9828.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Equation Learning Network (Lin et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Analytical classical density functionals from an equation learning network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An equation-learning-network approach used to obtain analytical classical density functionals; cited in the references as closely related work on deriving analytical functionals from data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Analytical classical density functionals from an equation learning network</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Equation Learning Network</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A neural equation-learning network designed to produce analytical (symbolic) classical density functionals; further architectural or size details are not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>density functional theory / computational physics</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>analytical density functional (mathematical functional form)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use of an equation-learning neural network to produce analytical expressions for classical density functionals (as per title and citation context).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9828.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9828.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Davies et al. 2021</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Advancing mathematics by guiding human intuition with ai</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-level example of AI assisting mathematical discovery and conjecturing, cited among works showing AI can guide human intuition in discovering new mathematical results.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Advancing mathematics by guiding human intuition with ai</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>AI-assisted mathematical conjecturing</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An AI system used to guide human intuition in mathematical discovery; the supplement only cites the title and does not give method/architecture specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mathematics / AI-assisted discovery</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>mathematical conjectures / formal results</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>AI guidance of human mathematicians to propose conjectures and insights (as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Distilling free-form natural laws from experimental data <em>(Rating: 2)</em></li>
                <li>A physics-inspired method for symbolic regression <em>(Rating: 2)</em></li>
                <li>Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates <em>(Rating: 2)</em></li>
                <li>Neural-guided symbolic regression with semantic prior <em>(Rating: 2)</em></li>
                <li>Discovering symbolic models from deep learning with inductive biases <em>(Rating: 2)</em></li>
                <li>Symbolic physics learner: Discovering governing equations via Monte Carlo tree search <em>(Rating: 2)</em></li>
                <li>Analytical classical density functionals from an equation learning network <em>(Rating: 2)</em></li>
                <li>Advancing mathematics by guiding human intuition with ai <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9828",
    "paper_id": "paper-247291786",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [
        {
            "name_short": "Schmidt-Lipson 2009",
            "name_full": "Distilling free-form natural laws from experimental data",
            "brief_description": "A symbolic-regression approach for automatically discovering closed-form mathematical relations (natural laws) from experimental data; cited here among related works on symbolic discovery of equations.",
            "citation_title": "Distilling free-form natural laws from experimental data",
            "mention_or_use": "mention",
            "model_name": "Schmidt & Lipson symbolic regression",
            "model_description": "A symbolic regression technique that searches over expressions to fit observed data and extracts closed-form laws; no architecture or parameter-size information is given in this paper.",
            "scientific_domain": "physics / general empirical sciences",
            "law_type": "physical law / empirical formula / closed-form equation",
            "method_description": "Symbolic regression over candidate algebraic expressions evaluated against experimental data (as cited by title and placement in related-work list).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.0",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "AI Feynman",
            "name_full": "A physics-inspired method for symbolic regression",
            "brief_description": "A physics-inspired symbolic regression method (AI Feynman) for discovering symbolic formulas from data; cited as a relevant prior on symbolic discovery.",
            "citation_title": "A physics-inspired method for symbolic regression",
            "mention_or_use": "mention",
            "model_name": "AI Feynman",
            "model_description": "A physics-inspired symbolic-regression pipeline that leverages physics heuristics to simplify and decompose problems for symbolic discovery; no implementation details are provided in this supplementary text.",
            "scientific_domain": "physics / symbolic regression",
            "law_type": "physical law / symbolic formula",
            "method_description": "Physics-inspired decomposition and symbolic regression (as implied by the cited title and context).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.1",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "SISSO",
            "name_full": "SISSO: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates",
            "brief_description": "A compressed-sensing-based symbolic descriptor discovery method (SISSO) for finding low-dimensional models from large candidate feature spaces; cited in context of symbolic/model-discovery methods.",
            "citation_title": "Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates",
            "mention_or_use": "mention",
            "model_name": "SISSO (compressed-sensing symbolic regression)",
            "model_description": "A compressed-sensing approach that selects sparse, physically meaningful descriptors from a very large pool of candidate functions; no architecture/size details appear in this paper.",
            "scientific_domain": "materials science / descriptor discovery",
            "law_type": "empirical descriptor / low-dimensional model",
            "method_description": "Compressed-sensing-based selection of symbolic descriptors from a candidate space (as cited by title and placement).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.2",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Neural-guided SR",
            "name_full": "Neural-guided symbolic regression with semantic prior",
            "brief_description": "A neural-guided symbolic regression approach that uses learned priors to guide symbolic search; cited among prior methods for discovering symbolic relationships.",
            "citation_title": "Neural-guided symbolic regression with semantic prior",
            "mention_or_use": "mention",
            "model_name": "Neural-guided symbolic regression",
            "model_description": "A hybrid approach combining neural-network guidance with symbolic-regression search (paper cites the title; no implementation details provided here).",
            "scientific_domain": "machine learning / symbolic discovery",
            "law_type": "symbolic formula / empirical relationship",
            "method_description": "Neural networks provide semantic priors to guide symbolic-regression search (implied by the cited title).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.3",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Cranmer et al. 2020",
            "name_full": "Discovering symbolic models from deep learning with inductive biases",
            "brief_description": "Work on extracting compact symbolic models from deep-learning representations by leveraging inductive biases; cited as related work on discovering symbolic models from learned models.",
            "citation_title": "Discovering symbolic models from deep learning with inductive biases",
            "mention_or_use": "mention",
            "model_name": "Deep-learning-derived symbolic discovery",
            "model_description": "An approach that seeks to derive symbolic expressions from deep-learning models by incorporating inductive biases; no architecture/size specifics are provided in the supplement.",
            "scientific_domain": "machine learning / physics / general modeling",
            "law_type": "symbolic formula / governing equation",
            "method_description": "Extract symbolic models from deep-learning representations using inductive biases (as cited).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.4",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Symbolic Physics Learner",
            "name_full": "Symbolic physics learner: Discovering governing equations via Monte Carlo tree search",
            "brief_description": "A method using Monte Carlo tree search for symbolic discovery of governing equations; cited as part of the literature on equation discovery.",
            "citation_title": "Symbolic physics learner: Discovering governing equations via Monte Carlo tree search",
            "mention_or_use": "mention",
            "model_name": "Symbolic Physics Learner (MCTS-based)",
            "model_description": "A Monte Carlo tree search approach to symbolic regression for governing-equation discovery; implementation specifics are not provided in this supplement.",
            "scientific_domain": "physics / dynamical systems",
            "law_type": "governing equations / symbolic laws",
            "method_description": "Monte Carlo tree search over symbolic expression space to find equations that explain data (as implied by the cited title).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.5",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Equation Learning Network (Lin et al.)",
            "name_full": "Analytical classical density functionals from an equation learning network",
            "brief_description": "An equation-learning-network approach used to obtain analytical classical density functionals; cited in the references as closely related work on deriving analytical functionals from data.",
            "citation_title": "Analytical classical density functionals from an equation learning network",
            "mention_or_use": "mention",
            "model_name": "Equation Learning Network",
            "model_description": "A neural equation-learning network designed to produce analytical (symbolic) classical density functionals; further architectural or size details are not provided here.",
            "scientific_domain": "density functional theory / computational physics",
            "law_type": "analytical density functional (mathematical functional form)",
            "method_description": "Use of an equation-learning neural network to produce analytical expressions for classical density functionals (as per title and citation context).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.6",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Davies et al. 2021",
            "name_full": "Advancing mathematics by guiding human intuition with ai",
            "brief_description": "A high-level example of AI assisting mathematical discovery and conjecturing, cited among works showing AI can guide human intuition in discovering new mathematical results.",
            "citation_title": "Advancing mathematics by guiding human intuition with ai",
            "mention_or_use": "mention",
            "model_name": "AI-assisted mathematical conjecturing",
            "model_description": "An AI system used to guide human intuition in mathematical discovery; the supplement only cites the title and does not give method/architecture specifics.",
            "scientific_domain": "mathematics / AI-assisted discovery",
            "law_type": "mathematical conjectures / formal results",
            "method_description": "AI guidance of human mathematicians to propose conjectures and insights (as cited).",
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": null,
            "notable_examples": null,
            "limitations_challenges": null,
            "baseline_comparison": null,
            "uuid": "e9828.7",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Distilling free-form natural laws from experimental data",
            "rating": 2
        },
        {
            "paper_title": "A physics-inspired method for symbolic regression",
            "rating": 2
        },
        {
            "paper_title": "Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates",
            "rating": 2
        },
        {
            "paper_title": "Neural-guided symbolic regression with semantic prior",
            "rating": 2
        },
        {
            "paper_title": "Discovering symbolic models from deep learning with inductive biases",
            "rating": 2
        },
        {
            "paper_title": "Symbolic physics learner: Discovering governing equations via Monte Carlo tree search",
            "rating": 2
        },
        {
            "paper_title": "Analytical classical density functionals from an equation learning network",
            "rating": 2
        },
        {
            "paper_title": "Advancing mathematics by guiding human intuition with ai",
            "rating": 1
        }
    ],
    "cost": 0.011592,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Supplementary Materials for Evolving symbolic density functionals He Ma et al. This PDF file includes: Sections S1 to S7 Figs. S1 to S5 References
2022</p>
<p>Sci 
Adv 
Supplementary Materials for Evolving symbolic density functionals He Ma et al. This PDF file includes: Sections S1 to S7 Figs. S1 to S5 References
8279202210.1126/sciadv.abq0279Corresponding author:</p>
<p>Supplementary Materials 1 Functional forms</p>
<p>In this section we present the functional forms in main text Eq. 2-3 for general systems (which may contains spin polarization).</p>
<p>The semilocal part of the exchange-correlation functional assumes the following form where a = !/k F with k F = (3â‡¡ 2 â‡¢) 1/3 being the Fermi wave vector and ! being the rangeseparation parameter.</p>
<p>F x, , F c-ss, and F c-os are the exchange, same-spin correlation and opposite-spin correlation enhancement factors that depends on reduced density gradient and kinetic energy density
F x, = F x, (x 2 , w ), F c-ss, = F c-ss, (x 2 , w ), F c-os = F c-os (x 2 ave , w ave )(S3)
where x = |râ‡¢ | â‡¢ 4/3 denotes the reduced density gradient. w is an auxiliary quantity that depends on kinetic energy density âŒ§ = 1 2 P occ i |r i | 2 , with 's being Kohn-Sham orbitals and the summation runs over occupied Kohn-Sham orbitals. In particular, w = (t 1)/(t + 1), with t = âŒ§ HEG /âŒ§ where âŒ§ HEG = 3 10 (6â‡¡ 2 ) 2/3 â‡¢ 5/3 is the kinetic energy density of homogenous electron gas (HEG). The opposite-spin correlation enhancement factor F c-ss, depends on spinaveraged version of x 2 and w, defined as x 2 ave = 1 2 (x 2 â†µ + x 2 ) and w ave = (t ave 1)/(t ave + 1) with t ave = 1 2 (t â†µ + t ). We note that the form of input features for enhancement factors defined here are widely-used in B97-inspired functional forms.</p>
<p>The nonlocal part of the exchange-correlation functional contains the short-range exactexchange E exact</p>
<p>x-sr , long-range exact exchange E exact x-lr and VV10 nonlocal correlation E VV10 c . The short-range and long-range exact exchange assume the following form
E exact x-sr [â‡¢] = c x 2 X occ X i,j Z Z â‡¤ i (r 1 ) â‡¤ j (r 2 ) erfc(!r) r j (r 1 ) i (r 2 )dr 1 dr 2 (S4) E exact x-lr [â‡¢] = 1 2 X occ X i,j Z Z â‡¤ i (r 1 ) â‡¤ j (r 2 ) erf(!r) r j (r 1 ) i (r 2 )dr 1 dr 2 (S5)
where r = |r 1 r 2 | and ! is a range-separation parameter controlling the characteristic length scale for range separation. Note that there is a prefactor c x controlling the amount of short-range exact exchange used in the functional form. The exchange functional used in this work thus behaves as purely exact exchange in long range and a mixture of semilocal and exact exchange in short range. The VV10 nonlocal correlation E VV10 c assumes the form
E VV10 c [â‡¢] = Z â‡¢(r 1 ) " 1 32 ï£¿ 3 b 2 3/4 + 1 2 Z â‡¢(r 2 ) (r 1 , r 2 ; b, C)dr 2 # dr 1 (S6)
where integration kernel depends on two empirical parameters b and C (see Ref. (76) for expression). We keep all the empirical parameters in nonlocal terms to be identical to those in
!B97M-V, namely ! = 0.3, c x = 0.15, b = 6 and C = 0.01.</p>
<p>Evolution of symbolic functional forms</p>
<p>The simplified mathematical forms of functional forms shown in Fig. 4 of the main text is shown below. c's and are parameters. The same symbol (e.g. c 0 ) in different enhancement factors of the same functional represent different parameters. See Table S1 for numerical values for the parameters in the GAS22 functional.</p>
<dl>
<dt>GAS22-a (!B97M-V):</dt>
<dt>F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 0 + c 1 w + c 2 w 2 + c 3 4 x 8 (1 + x 2 ) 4 + c 4 3 w 4 x 6 (1 + x 2 ) 3 F c-os = c 0 + c 1 w + c 2 w 2 + c 3 w 6 + c 4 w 2 x 2 1 + x 2 + c 5 w 6 x 2 1 + x 2 GAS22-b: F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 1 w + c 2 w 2 + c 3 6 w 4 x 12 (1 + x 2 ) 6 + c 4 4 x 8 (1 + x 2 ) 4 + x 2 1 + x 2 F c-os = c 0 + c 2 w 2 + c 3 w 6 + c 4 w 6 x 2 1 + x 2 + c 5 w 2 x 2 1 + x 2 GAS22-c: F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 1 w + c 2 w 2 + c 3 6 w 4 x 12 (1 + x 2 ) 6 + c 4 6 x 12 (1 + x 2 ) 6 + x 2 1 + x 2 F c-os = c 0 + c 2 w 2 + c 3 w 6 + c 4 w 6 3 p x 2 + c 5 w 2 3 p x 2 GAS22</dt>
<dd>F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 1 w + c 2 w 2 + c 3 6 w 4 x 12 (1 + x 2 ) 6 + c 4 6 x 12 (1 + x 2 ) 6 + x 2 1 + x 2 F c-os = c 0 + c 2 w 2 + c 3 w 6 + c 4 w 6 3 p x 2 + c 5 w 2 3 p x 2 F x c 0 0.862139736374172 c 1 0.317533683085033 c 2 0.936993691972698 0.003840616724010807 F c-ss c 1 4.10753796482853 c 2 5.24218990333846 c 3 7.5380689617542 c 4 1.76643208454076 0.46914023462026644 F c-os c 0 0.805124374375355 c 2 7.98909430970845 c 3 7.54815900595292 c 4 2.00093961824784 c 5 1.76098915061634</dd>
</dl>
<p>Symbolic representations of density functionals</p>
<p>As stated in the Table 1   Symbolic representation of !B97M-V: Figure S1: Exchange enhancement factors F x for functional forms in main text Fig. 4. For reference, the enhancement factor for the !B97M-V functional is plotted in grey. Figure S2: Same-spin correlation enhancement factors F c-ss for functional forms in main text Fig. 4. For reference, the enhancement factor for the !B97M-V functional is plotted in grey. Figure S3: Opposite-spin correlation enhancement factors F c-os for functional forms in main text Fig. 4. For reference, the enhancement factor for the !B97M-V functional is plotted in grey.
Algorithm 1: F !B97M-V x Features: w, x 2 Variables: F , v 0 , v 1 Parameters: , c 00 , c 10 , c 01 Instructions: v 0 = x 2 /(1 + x 2 ) F = c 00 + F v 1 = c 10 â‡¥ w F = F + v 1 v 1 = c 01 â‡¥ v 0 F = F + v 1 return F Algorithm 2: F !B97M-V c-ss Features: w, x 2 Variables: F , v 0 , v 1 , v 2 , v 3 Parameters: , c 00 , c 10 , c 20 , c 43 , c 04 Instructions: v 0 = x 2 /(1 + x 2 ) F = c 00 + F F + = c 10 â‡¥ w v 1 = w 2 F + = c 20 â‡¥ v 1 v 1 = w 4 v 2 = v 3 0 v 3 = v 3 â‡¥ v 2 F + = c 43 â‡¥ v 3 v 2 = v 4 0 F + = c 04 â‡¥ v 2 return F Algorithm 3: F !B97M-V c-os Features: w, x 2 Variables: F , v 0 , v 1 , v 2 , v 3 Parameters: , c 00 , c 10 , c 20 , c 21 , c 60 , c 61 Instructions: v 0 = x 2 /(1 + x 2 ) F = c 00 + F F + = c 10 â‡¥ w v 1 = w 2 F + = c 20 â‡¥ v 1 v 3 = v 1 â‡¥ v 0 F + = c 21 â‡¥ v 1 v 1 = w 6 F + = c 60 â‡¥ v 1 v 3 = v 1 â‡¥ v 0 F + = c 61 â‡¥ v 3 return F</p>
<p>Enhancement factors of symbolic functionals</p>
<p>Random search studies starting from !B97M-V</p>
<p>In main text Fig. 4 we presented regularized evolution calculations starting from the !B97M-V functional. For comparison, in Fig. S4 we report random search calculations (dash lines). The random search studies are performed with identical set up as regularized evolution experiments, except that the tournament size is set to 1. Therefore, in each iteration of random search experiment, the parent functional used for mutation is randomly selected from the population without referring to the fitness of functional forms. Compared to regularized evolution calculations, random search is found to be ineffective in traversing the search space and generating better functional forms than existing forms. To check for equivalent functional forms and avoid duplicated computations, each functional is assigned a fingerprint. The fingerprint is evaluated by computing the functional values using a set of features and parameters that are randomly chosen but kept consistent during the entire program. The functional values are then hashed and the hash value serves as the functional Figure S5: Distributed design of symbolic regression software program. The program consists of a population server, a population database, a fingerprint server for functional equivalence checking and a number of workers for training and evaluating functional forms. The regularized evolution process is performed on the population server, and all child functionals are sent to workers for training and evaluation. The workers will first check if equivalence forms are already explored. If equivalence forms are explored before, the worker will directly send the cached fitness value in fingerprint server to the population server.</p>
<p>fingerprint. The fingerprint is identical across all equivalent functional forms because they all evaluates to the same values with same parameters and features. All fingerprints and fitness values of explored functionals are cached during the regularized evolution calculations. Every time a new functional form is generated from mutation, its fingerprint will be evaluated to check if equivalent forms have already been explored. If equivalent forms are explored before, the cached fitness values are used without re-training the functional form.</p>
<p>Colab notebook demonstration of GAS22 in self-consistent calculations</p>
<p>We provide an example Colab notebook to demonstrate self-consistent DFT calculations with GAS22 functional at https://colab.research.google.com/github/google-research/ google-research/blob/master/symbolic_functionals/colab/run_GAS22.</p>
<p>ipynb.</p>
<p>ss, F c-ss, + e LDA c-os F c-os ! dr (S1) where 2 {â†µ, } is the spin index; e LDA x-sr, , e LDA c-ss, , and e LDA c-os are short-range exchange, same-spin correlation and opposite-spin correlation energy densities within local (spin) density approximation. The partition of correlation energy into same-spin and opposite-spin contributions adopts the widely-used scheme proposed by Stoll et al. (59). The short-range LDA exchange energy density e LDA x-sr, is obtained by multiplying the LDA exchange energy density e</p>
<p>.We design the probability such that similar instructions receive identical probabilities andprobabilities distribute evenly among different types of instructions. For the 5 arithmetic operations, each operation receive a probability of 0.06; for the 6 power instructions, each receive a probability of 0.05; u transform receive a probability of 0.1, and the other 4 building block receive a 0.075 each.</p>
<p>Figure S4 :
S4Validation error of symbolic functionals generated by random search and regularized evolution experiments starting from the !B97M-V functional. Random search and regularized evolution results are shown with dashed (solid) lines, with different lines represent independent experiments. The reference values in MGCDB84 database are used as targets for training and evaluation of functionals. Here we make some additional remark on the starting point (termed GAS22-a in the main text) of the regularized evolution and random search studies. GAS22-a has identical symbolic form as !B97M-V, but with all parameters (including 's) optimized on the training set as done for all the symbolic functional forms generated in this work. In the original work that created the !B97M-V functional, the nonlinear parameters 's are not optimized and only linear parameters are optimized. Thus GAS22-a is a different functional as !B97M-V and have different training/validation/test errors: 2.97/3.82/4.47 kcal/mol. 6 Software design In Fig. S5 we present the high-level software design of the distributed regularized evolution program. The program consists of a population server, a population database, a fingerprint server for functional equivalence checking and a number of workers for training and evaluating functional forms. The training of a functional form is performed with the CMA-ES algorithm, which require to compute the the training error on tens of thousands of sets of different parameters. Such calculations are efficiently performed by porting the calculation of training errors to GPU processors through just-in-time compilation.As briefly mentioned in the main text, one functional form may have multiple equivalent symbolic representations. For the purpose the functional equivalence checking, we define equivalent forms as forms that evaluates to the same value given same parameters and features, and we do not consider more complicated forms of equivalence such as the those requiring a mapping of parameters (e.g. the equivalence of B97 exchange functional and the symbolic functional obtained in main text).</p>
<p>Table S1 :
S1Parameters in the GAS22 functional.</p>
<p>of the main text, the instructions used in this work include 3 categories: arithmetic operations, power operations and building blocks from existing functionals. For the category of building blocks of existing functionals, we considered a few additional instructions in addition to the x/(1 + x) presented inTable 1, including PBE exchange enhancementfactor F PBE </p>
<p>x </p>
<p>(63), RPBE exchange enhancement factor F RPBE </p>
<p>x </p>
<p>(77), B88 exchange enhancement </p>
<p>factor F B88 </p>
<p>x </p>
<p>(78) and PBE correlation energy functional E PBE </p>
<p>c </p>
<p>Inhomogeneous electron gas. P Hohenberg, W Kohn, Phys. Rev. 136864P. Hohenberg, W. Kohn, Inhomogeneous electron gas. Phys. Rev. 136, B864 (1964).</p>
<p>R M Martin, Electronic Structure: Basic Theory and Practical Methods. Cambridge Univ. PressR. M. Martin, Electronic Structure: Basic Theory and Practical Methods (Cambridge Univ. Press, 2020).</p>
<p>Density functional theory: Its origins, rise to prominence, and future. R O Jones, Rev. Mod. Phys. 87R. O. Jones, Density functional theory: Its origins, rise to prominence, and future. Rev. Mod. Phys. 87, 897-923 (2015).</p>
<p>Novel algorithms and high-performance cloud computing enable efficient fully quantum mechanical protein-ligand scoring. N Mardirossian, Y Wang, D A Pearlman, G K Chan, T Shiozaki, arXiv:2004.08725physics.chem-ph]N. Mardirossian, Y. Wang, D. A. Pearlman, G. K. Chan, T. Shiozaki, Novel algorithms and high-performance cloud computing enable efficient fully quantum mechanical protein-ligand scoring. arXiv:2004.08725 [physics.chem-ph] (18 April 2020).</p>
<p>Density functional theory in surface chemistry and catalysis. J K NÃ¸rskov, F Abild-Pedersen, F Studt, T Bligaard, Proc. Natl. Acad. Sci. 108J. K. NÃ¸rskov, F. Abild-Pedersen, F. Studt, T. Bligaard, Density functional theory in surface chemistry and catalysis. Proc. Natl. Acad. Sci. 108, 937-943 (2011).</p>
<p>The long and winding road: Predicting materials properties through theory and computation. G Galli, Handbook of Materials Modeling: Methods: Theory and Modeling. G. Galli, The long and winding road: Predicting materials properties through theory and computation, in Handbook of Materials Modeling: Methods: Theory and Modeling (2020), pp. 37-48.</p>
<p>Self-consistent equations including exchange and correlation effects. W Kohn, L J Sham, Phys. Rev. 140W. Kohn, L. J. Sham, Self-consistent equations including exchange and correlation effects. Phys. Rev. 140, A1133-A1138 (1965).</p>
<p>Perspective: Fifty years of density-functional theory in chemical physics. A D Becke, J. Chem. Phys. 140A. D. Becke, Perspective: Fifty years of density-functional theory in chemical physics. J. Chem. Phys. 140, 18A301 (2014).</p>
<p>Perspective: Kohn-sham density functional theory descending a staircase. H S Yu, S L Li, D G Truhlar, J. Chem. Phys. 130901H. S. Yu, S. L. Li, D. G. Truhlar, Perspective: Kohn-sham density functional theory descending a staircase. J. Chem. Phys., 130901 (2016).</p>
<p>Recent developments in density functional approximations. L Li, K Burke, Handbook of Materials Modeling: Methods: Theory and Modeling. L. Li, K. Burke, Recent developments in density functional approximations, in Handbook of Materials Modeling: Methods: Theory and Modeling (2020), pp. 213-226.</p>
<p>Thirty years of density functional theory in computational chemistry: An overview and extensive assessment of 200 density functionals. N Mardirossian, M Head-Gordon, Mol. Phys. 115N. Mardirossian, M. Head-Gordon, Thirty years of density functional theory in computational chemistry: An overview and extensive assessment of 200 density functionals, Mol. Phys. 115, 2315-2372 (2017).</p>
<p>Systematic optimization of long-range corrected hybrid density functionals. J.-D Chai, M Head-Gordon, J. Chem. Phys. 12884106J.-D. Chai, M. Head-Gordon, Systematic optimization of long-range corrected hybrid density functionals. J. Chem. Phys. 128, 084106 (2008).</p>
<p>Ï‰b97x-v: A 10-parameter, range-separated hybrid, generalized gradient approximation density functional with nonlocal correlation, designed by a survival-of-the-fittest strategy. N Mardirossian, M Head-Gordon, Phys. Chem. Chem. Phys. 16N. Mardirossian, M. Head-Gordon, Ï‰b97x-v: A 10-parameter, range-separated hybrid, generalized gradient approximation density functional with nonlocal correlation, designed by a survival-of-the-fittest strategy. Phys. Chem. Chem. Phys. 16, 9904-9924 (2014).</p>
<p>Mapping the genome of meta-generalized gradient approximation density functionals: The search for b97m-v. N Mardirossian, M Head-Gordon, J. Chem. Phys. 14274111N. Mardirossian, M. Head-Gordon, Mapping the genome of meta-generalized gradient approximation density functionals: The search for b97m-v, J. Chem. Phys. 142, 074111 (2015).</p>
<p>Ï‰b97m-v: A combinatorially optimized, range-separated hybrid, meta-gga density functional with vv10 nonlocal correlation. N Mardirossian, M Head-Gordon, J. Chem. Phys. 144214110N. Mardirossian, M. Head-Gordon, Ï‰b97m-v: A combinatorially optimized, range-separated hybrid, meta-gga density functional with vv10 nonlocal correlation. J. Chem. Phys. 144, 214110 (2016).</p>
<p>Survival of the most transferable at the top of Jacob's ladder: Defining and testing the Ï‰b97m (2) double hybrid density functional. N Mardirossian, M Head-Gordon, J. Chem. Phys. 148241736N. Mardirossian, M. Head-Gordon, Survival of the most transferable at the top of Jacob's ladder: Defining and testing the Ï‰b97m (2) double hybrid density functional. J. Chem. Phys. 148, 241736 (2018).</p>
<p>Applications and validations of the minnesota density functionals. Y Zhao, D G Truhlar, Chem. Phys. Lett. 502Y. Zhao, D. G. Truhlar, Applications and validations of the minnesota density functionals. Chem. Phys. Lett. 502, 1-13 (2011).</p>
<p>Improving the accuracy of hybrid meta-gga density functionals by range separation. R Peverati, D G Truhlar, J. Phys. Chem. Lett. 2R. Peverati, D. G. Truhlar, Improving the accuracy of hybrid meta-gga density functionals by range separation. J. Phys. Chem. Lett. 2, 2810-2817 (2011).</p>
<p>Mn15-l: A new local exchange-correlation functional for kohn-sham density functional theory with broad accuracy for atoms, molecules, and solids. H S Yu, X He, D G Truhlar, J. Chem. Theor. Comput. 12H. S. Yu, X. He, D. G. Truhlar, Mn15-l: A new local exchange-correlation functional for kohn-sham density functional theory with broad accuracy for atoms, molecules, and solids, J. Chem. Theor. Comput. 12, 1280-1293 (2016).</p>
<p>M06-sx screenedexchange density functional for chemistry and solid-state physics. Y Wang, P Verma, L Zhang, Y Li, Z Liu, D G Truhlar, X He, Proc. Natl. Acad. Sci. 117Y. Wang, P. Verma, L. Zhang, Y. Li, Z. Liu, D.G. Truhlar, X. He, M06-sx screened- exchange density functional for chemistry and solid-state physics. Proc. Natl. Acad. Sci. 117, 2294-2301 (2020).</p>
<p>Density-functional thermochemistry. V. Systematic optimization of exchangecorrelation functionals. A D Becke, J. Chem. Phys. 107A. D. Becke, Density-functional thermochemistry. V. Systematic optimization of exchange- correlation functionals. J. Chem. Phys. 107, 8554-8560 (1997).</p>
<p>Quest for a universal density functional: The accuracy of density functionals across a broad spectrum of databases in chemistry and physics. R Peverati, D G Truhlar, Philos. Trans. R. Soc. A Math. Phys. Eng. Sci. 37220120476R. Peverati, D. G. Truhlar, Quest for a universal density functional: The accuracy of density functionals across a broad spectrum of databases in chemistry and physics. Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.372, 20120476 (2014).</p>
<p>Learning to approximate density functionals. B Kalita, L Li, R J Mccarty, K Burke, Acc. Chem. Res. 54B. Kalita, L. Li, R. J. McCarty, K. Burke, Learning to approximate density functionals. Acc. Chem. Res. 54, 818-826 (2021).</p>
<p>Finding density functionals with machine learning. J C Snyder, M Rupp, K Hansen, K.-R MÃ¼ller, K Burke, Phys. Rev. Lett. 108253002J. C. Snyder, M. Rupp, K. Hansen, K.-R. MÃ¼ller, K. Burke, Finding density functionals with machine learning. Phys. Rev. Lett. 108, 253002 (2012).</p>
<p>. L Li, J C Snyder, I M Pelaschier, J Huang, U N Niranjan, P Duncan, M Rupp, K R , L. Li, J. C. Snyder, I. M. Pelaschier, J. Huang, U.N. Niranjan, P. Duncan, M. Rupp, K.R.</p>
<p>Understanding machine-learned density functionals. K MÃ¼ller, Burke, Int. J. Quant. Chem. 116MÃ¼ller, K. Burke, Understanding machine-learned density functionals. Int. J. Quant. Chem. 116, 819-833 (2016).</p>
<p>Pure density functional for strong correlation and the thermodynamic limit from machine learning. L Li, T E Baker, S R White, K Burke, Phys. Rev. B. 94245129L. Li, T. E. Baker, S. R. White, K. Burke, Pure density functional for strong correlation and the thermodynamic limit from machine learning. Phys. Rev. B 94, 245129 (2016).</p>
<p>Bypassing the kohn-sham equations with machine learning. F Brockherde, L Vogt, L Li, M E Tuckerman, K Burke, K.-R MÃ¼ller, Nat. Commun. 8872F. Brockherde, L. Vogt, L. Li, M. E. Tuckerman, K. Burke, K.-R. MÃ¼ller, Bypassing the kohn-sham equations with machine learning. Nat. Commun. 8, 872 (2017).</p>
<p>Quantum chemical accuracy from density functional approximations via machine learning. M Bogojeski, L Vogt-Maranto, M E Tuckerman, K.-R MÃ¼ller, K Burke, Nat. Commun. 115223M. Bogojeski, L. Vogt-Maranto, M. E. Tuckerman, K.-R. MÃ¼ller, K. Burke, Quantum chemical accuracy from density functional approximations via machine learning. Nat. Commun. 11, 5223 (2020).</p>
<p>Semi-local machine-learned kinetic energy density functional with third-order gradients of electron density. J Seino, R Kageyama, M Fujinami, Y Ikabata, H Nakai, J. Chem. Phys. 148241705J. Seino, R. Kageyama, M. Fujinami, Y. Ikabata, H. Nakai, Semi-local machine-learned kinetic energy density functional with third-order gradients of electron density. J. Chem. Phys. 148, 241705 (2018).</p>
<p>Deep learning and density-functional theory. K Ryczko, D A Strubbe, I Tamblyn, Phys. Rev. A. 10022512K. Ryczko, D. A. Strubbe, I. Tamblyn, Deep learning and density-functional theory. Phys. Rev. A 100, 022512 (2019).</p>
<p>Orbital-free density functional theory calculation applying semi-local machine-learned kinetic energy density functional and kinetic potential. M Fujinami, R Kageyama, J Seino, Y Ikabata, H Nakai, Chem. Phys. Lett. 748137358M. Fujinami, R. Kageyama, J. Seino, Y. Ikabata, H. Nakai, Orbital-free density functional theory calculation applying semi-local machine-learned kinetic energy density functional and kinetic potential. Chem. Phys. Lett. 748, 137358 (2020).</p>
<p>Machine learning approaches toward orbitalfree density functional theory: Simultaneous training on the kinetic energy density functional and its functional derivative. R Meyer, M Weichselbaum, A W Hauser, J. Chem. Theor. Comput. 16R. Meyer, M. Weichselbaum, A. W. Hauser, Machine learning approaches toward orbital- free density functional theory: Simultaneous training on the kinetic energy density functional and its functional derivative. J. Chem. Theor. Comput. 16, 5685-5694 (2020).</p>
<p>Density functionals for surface science: Exchange-correlation model development with bayesian error estimation. J Wellendorff, K T Lundgaard, A MÃ¸gelhÃ¸j, V Petzold, D D Landis, J K NÃ¸rskov, T Bligaard, K W Jacobsen, Phys. Rev. B. 85235149J. Wellendorff, K. T. Lundgaard, A. MÃ¸gelhÃ¸j, V. Petzold, D. D. Landis, J. K. NÃ¸rskov, T. Bligaard, K. W. Jacobsen, Density functionals for surface science: Exchange-correlation model development with bayesian error estimation. Phys. Rev. B 85, 235149 (2012).</p>
<p>mbeef-vdw: Robust fitting of error estimation density functionals. K T Lundgaard, J Wellendorff, J Voss, K W Jacobsen, T Bligaard, Phys. Rev. B. 93235162K. T. Lundgaard, J. Wellendorff, J. Voss, K. W. Jacobsen, T. Bligaard, mbeef-vdw: Robust fitting of error estimation density functionals. Phys. Rev. B 93, 235162 (2016).</p>
<p>Exploring density functional subspaces with genetic algorithms. M Gastegger, L GonzÃ¡lez, P Marquetand, Monatsh. Chem. 150M. Gastegger, L. GonzÃ¡lez, P. Marquetand, Exploring density functional subspaces with genetic algorithms. Monatsh. Chem. 150, 173-182 (2019).</p>
<p>Bayesian optimization for calibrating and selecting hybrid-density functional models. R A Vargas-Hernandez, J. Phys. Chem. A. 124R. A. Vargas-Hernandez, Bayesian optimization for calibrating and selecting hybrid-density functional models, J. Phys. Chem. A 124, 4053-4061 (2020).</p>
<p>Approximation capabilities of multilayer feedforward networks. K Hornik, Neural Netw. 4K. Hornik, Approximation capabilities of multilayer feedforward networks. Neural Netw. 4, 251-257 (1991).</p>
<p>Kohn-Sham equations as regularizer: Building prior knowledge into machine-learned physics. L Li, S Hoyer, R Pederson, R Sun, E D Cubuk, P Riley, K Burke, Phys. Rev. Lett. 12636401L. Li, S. Hoyer, R. Pederson, R. Sun, E. D. Cubuk, P. Riley, K. Burke, Kohn-Sham equations as regularizer: Building prior knowledge into machine-learned physics. Phys. Rev. Lett. 126, 036401 (2021).</p>
<p>Learning the exchange-correlation functional from nature with fully differentiable density functional theory. M F Kasim, S M Vinko, Phys. Rev. Lett. 127126403M. F. Kasim, S. M. Vinko, Learning the exchange-correlation functional from nature with fully differentiable density functional theory, Phys. Rev. Lett. 127, 126403 (2021).</p>
<p>Using differentiable programming to obtain an energy and density-optimized exchange-correlation functional. S Dick, M Fernandez-Serra, arXiv:2106.04481physics.chem-phS. Dick, M. Fernandez-Serra, Using differentiable programming to obtain an energy and density-optimized exchange-correlation functional. arXiv:2106.04481 [physics.chem-ph] (8 June 2021).</p>
<p>Completing density functional theory by machine learning hidden messages from molecules. R Nagai, R Akashi, O Sugino, Comput. Mater. 643R. Nagai, R. Akashi, O. Sugino, Completing density functional theory by machine learning hidden messages from molecules. npj Comput. Mater. 6, 43 (2020).</p>
<p>Machine-learning-based exchange correlation functional with physical asymptotic constraints. R Nagai, R Akashi, O Sugino, Phys. Rev. Res. 413106R. Nagai, R. Akashi, O. Sugino, Machine-learning-based exchange correlation functional with physical asymptotic constraints. Phys. Rev. Res. 4, 013106 (2022).</p>
<p>A comprehensive data-driven approach toward chemically accurate density functional theory. Y Chen, L Zhang, H Wang, W E , Deepks , J. Chem. Theor. Comput. 17Y. Chen, L. Zhang, H. Wang, W. E, Deepks: A comprehensive data-driven approach toward chemically accurate density functional theory. J. Chem. Theor. Comput. 17, (2021).</p>
<p>Machine learning accurate exchange and correlation functionals of the electronic density. S Dick, M Fernandez-Serra, Nat. Commun. 113509S. Dick, M. Fernandez-Serra, Machine learning accurate exchange and correlation functionals of the electronic density. Nat. Commun. 11, 3509 (2020).</p>
<p>. J Kirkpatrick, B Mcmorrow, D H P Turban, A L Gaunt, J S Spencer, A G D , J. Kirkpatrick, B. McMorrow, D. H. P. Turban, A. L. Gaunt, J. S. Spencer, A. G. D. G.</p>
<p>. A Matthews, L Obika, M Thiry, D Fortunato, L R Pfau, S Castellanos, A W Petersen, Matthews, A. Obika, L. Thiry, M. Fortunato, D. Pfau, L.R. Castellanos, S. Petersen, A. W. R.</p>
<p>Pushing the frontiers of density functionals by solving the fractional electron problem. P Nelson, P Kohli, D Mori-SÃ¡nchez, A J Hassabis, Cohen, Science. 374Nelson, P. Kohli, P. Mori-SÃ¡nchez, D. Hassabis, A. J. Cohen, Pushing the frontiers of density functionals by solving the fractional electron problem, Science 374, 1385-1389 (2021).</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 324M. Schmidt, H. Lipson, Distilling free-form natural laws from experimental data, Science 324, 81-85 (2009).</p>
<p>A physics-inspired method for symbolic regression. S.-M Udrescu, M Tegmark, Ai Feynman, Sci. Adv. 62631S.-M. Udrescu, M. Tegmark, Ai Feynman: A physics-inspired method for symbolic regression. Sci. Adv. 6, eaay2631 (2020).</p>
<p>Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates. R Ouyang, S Curtarolo, E Ahmetcik, M Scheffler, L M Ghiringhelli, Phys. Rev. Mater. 283802R. Ouyang, S. Curtarolo, E. Ahmetcik, M. Scheffler, L. M. Ghiringhelli, Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates, Phys. Rev. Mater. 2, 083802 (2018).</p>
<p>New tolerance factor to predict the stability of perovskite oxides and halides. C J Bartel, C Sutton, B R Goldsmith, R Ouyang, C B Musgrave, L M Ghiringhelli, M Scheffler, Sci. Adv. 5693C. J. Bartel, C. Sutton, B. R. Goldsmith, R. Ouyang, C. B. Musgrave, L. M. Ghiringhelli, M. Scheffler, New tolerance factor to predict the stability of perovskite oxides and halides. Sci. Adv. 5, eaav0693 (2019).</p>
<p>Neural-guided symbolic regression with semantic prior. L Li, M Fan, R Singh, P Riley, arXiv:1901.07714[cs.LGL. Li, M. Fan, R. Singh, P. Riley, Neural-guided symbolic regression with semantic prior. arXiv:1901.07714 [cs.LG] (23 January 2019).</p>
<p>Discovering symbolic models from deep learning with inductive biases. M D Cranmer, A Sanchez-Gonzalez, P Battaglia, R Xu, K Cranmer, D Spergel, S Ho, Proceedings of the 34th Conference on Neural Information Processing Systems. the 34th Conference on Neural Information Processing SystemsVancouver, CanadaM. D. Cranmer, A. Sanchez-Gonzalez, P. Battaglia, R. Xu, K. Cranmer, D. Spergel, S. Ho, Discovering symbolic models from deep learning with inductive biases, in Proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada, 6 to 12 December 2020 (2020).</p>
<p>Fast, accurate, and transferable many-body interatomic potentials by symbolic regression. A Hernandez, A Balasubramanian, F Yuan, S A Mason, T Mueller, Comput. Mater. 5112A. Hernandez, A. Balasubramanian, F. Yuan, S. A. Mason, T. Mueller, Fast, accurate, and transferable many-body interatomic potentials by symbolic regression. npj Comput. Mater. 5, 112 (2019).</p>
<p>Application of symbolic regression for constitutive modeling of plastic deformation. E Kabliman, A H Kolody, J Kronsteiner, M Kommenda, G Kronberger, Appl. Eng. Sci. 6100052E. Kabliman, A. H. Kolody, J. Kronsteiner, M. Kommenda, G. Kronberger, Application of symbolic regression for constitutive modeling of plastic deformation. Appl. Eng. Sci. 6, 100052 (2021).</p>
<p>Symbolic regression in materials science. Y Wang, N Wagner, J M Rondinelli, MRS Commun. 9Y. Wang, N. Wagner, J. M. Rondinelli, Symbolic regression in materials science. MRS Commun. 9, 793-805 (2019).</p>
<p>Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data. H Vaddireddy, A Rasheed, A E Staples, O San, Phys. Fluids. 3215113H. Vaddireddy, A. Rasheed, A. E. Staples, O. San, Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data, Phys. Fluids 32, 015113 (2020).</p>
<p>Symbolic physics learner: Discovering governing equations via Monte Carlo tree search. F Sun, Y Liu, J.-X Wang, H Sun, arXiv:2205.13134[cs.AIF. Sun, Y. Liu, J.-X. Wang, H. Sun, Symbolic physics learner: Discovering governing equations via Monte Carlo tree search. arXiv:2205.13134 [cs.AI] (26 May 2022).</p>
<p>Regularized evolution for image classifier architecture search. E Real, A Aggarwal, Y Huang, Q V Le, Proc. AAAI Conf. AAAI Conf33E. Real, A. Aggarwal, Y. Huang, Q. V. Le, Regularized evolution for image classifier architecture search. Proc. AAAI Conf. Artif. Intell. 33, 4780-4789 (2019).</p>
<p>Accurate and simple analytic representation of the electron-gas correlation energy. J P Perdew, Y Wang, Phys. Rev. B. 45J. P. Perdew, Y. Wang, Accurate and simple analytic representation of the electron-gas correlation energy, Phys. Rev. B 45, 13244-13249 (1992).</p>
<p>Correlation energies in the spin-density functional formalism. H Stoll, C Pavlidou, H PreuÃŸ, Theor. Chim. Acta. 55H. Stoll, C. Pavlidou, H. PreuÃŸ, Correlation energies in the spin-density functional formalism. Theor. Chim. Acta 55, 29-41 (1980).</p>
<p>AutoML-Zero: Evolving machine learning algorithms from scratch. E Real, C Liang, D R So, Q V Le, Proceedings of 37th International Conference on Machine Learning (ICML). 37th International Conference on Machine Learning (ICML)ICML13E. Real, C. Liang, D. R. So, Q. V. Le, AutoML-Zero: Evolving machine learning algorithms from scratch, in Proceedings of 37th International Conference on Machine Learning (ICML), 13 to 18 July 2020 (ICML, 2020).</p>
<p>J D Co-Reyes, Y Miao, D Peng, E Real, S Levine, Q V Le, H Lee, A Faust, arXiv:2101.03958[cs.LGEvolving reinforcement learning algorithms. J. D. Co-Reyes, Y. Miao, D. Peng, E. Real, S. Levine, Q. V. Le, H. Lee, A. Faust, Evolving reinforcement learning algorithms. arXiv:2101.03958 [cs.LG] (8 January 2021).</p>
<p>Density functionals that recognize covalent, metallic, and weak bonds. J Sun, B Xiao, Y Fang, R Haunschild, P Hao, A Ruzsinszky, G I Csonka, G E Scuseria, J P Perdew, Phys. Rev. Lett. 111106401J. Sun, B. Xiao, Y. Fang, R. Haunschild, P. Hao, A. Ruzsinszky, G.I. Csonka, G.E. Scuseria, J.P. Perdew, Density functionals that recognize covalent, metallic, and weak bonds. Phys. Rev. Lett. 111, 106401 (2013).</p>
<p>Generalized gradient approximation made simple. J P Perdew, K Burke, M Ernzerhof, Phys. Rev. Lett. 77J. P. Perdew, K. Burke, M. Ernzerhof, Generalized gradient approximation made simple. Phys. Rev. Lett. 77, 3865-3868 (1996).</p>
<p>Recent developments in LIBXC-A comprehensive library of functionals for density functional theory. S Lehtola, C Steigemann, M J Oliveira, M A Marques, SoftwareX. 7S. Lehtola, C. Steigemann, M. J. Oliveira, M. A. Marques, Recent developments in LIBXC- A comprehensive library of functionals for density functional theory, SoftwareX 7, 1-5 (2018).</p>
<p>Jacob's ladder of density functional approximations for the exchange-correlation energy. J P Perdew, K Schmidt, AIP Conf. Proc. 5771J. P. Perdew, K. Schmidt, Jacob's ladder of density functional approximations for the exchange-correlation energy. AIP Conf. Proc. 577, 1 (2001).</p>
<p>Imagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition. the 2009 IEEE Conference on Computer Vision and Pattern RecognitionIEEEJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A large-scale hierarchical image database, in Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition (IEEE, 2009), pp. 248-255.</p>
<p>New developments in classical density functional theory. R Evans, M Oettel, R Roth, G Kahl, J. Phys. Condens. Matter. 28240401R. Evans, M. Oettel, R. Roth, G. Kahl, New developments in classical density functional theory. J. Phys. Condens. Matter 28, 240401 (2016).</p>
<p>Analytical classical density functionals from an equation learning network. S.-C Lin, G Martius, M Oettel, J. Chem. Phys. 15221102S.-C. Lin, G. Martius, M. Oettel, Analytical classical density functionals from an equation learning network. J. Chem. Phys. 152, 021102 (2020).</p>
<p>Densityfunctional fluctuation theory of crowds. J F MÃ©ndez-Valderrama, Y A Kinkhabwala, J Silver, I Cohen, T Arias, Nat. Commun. 93538J. F. MÃ©ndez-Valderrama, Y. A. Kinkhabwala, J. Silver, I. Cohen, T. Arias, Density- functional fluctuation theory of crowds, Nat. Commun. 9, 3538 (2018).</p>
<p>Advancing mathematics by guiding human intuition with ai. A Davies, P VeliÄkoviÄ‡, L Buesing, S Blackwell, D Zheng, N TomaÅ¡ev, R Tanburn, P Battaglia, C Blundell, A JuhÃ¡sz, M Lackenby, G Williamson, D Hassabis, P Kohli, Nature. 600A. Davies, P. VeliÄkoviÄ‡, L. Buesing, S. Blackwell, D. Zheng, N. TomaÅ¡ev, R. Tanburn, P. Battaglia, C. Blundell, A. JuhÃ¡sz, M. Lackenby, G. Williamson, D. Hassabis, P. Kohli, Advancing mathematics by guiding human intuition with ai, Nature 600, 70-74 (2021).</p>
<p>Jax: Composable transformations of python+ numpy programs. J Bradbury, J. Bradbury, Jax: Composable transformations of python+ numpy programs (2018);</p>
<p>. N Hansen, Y Akimoto, P Baudis, Cma-Es/Pycma On Github, 10.5281/zenodo.2559634N. Hansen, Y. Akimoto, P. Baudis, CMA-ES/pycma on Github, Zenodo, 10.5281/zenodo.2559634 (2019).</p>
<p>PySCF: The python-based simulations of chemistry framework. Q Sun, T C Berkelbach, N S Blunt, G H Booth, S Guo, Z Li, J Liu, J Mcclain, E R Sayfutyarova, S Sharma, S Wouters, G K.-L Chan, Wiley Interdiscip. Rev. Comput. Mol. Sci. 81340Q. Sun, T. C. Berkelbach, N. S. Blunt, G. H. Booth, S. Guo, Z. Li, J. Liu, J. McClain, E. R. Sayfutyarova, S. Sharma, S. Wouters, G. K.-L. Chan, PySCF: The python-based simulations of chemistry framework. Wiley Interdiscip. Rev. Comput. Mol. Sci. 8, e1340 (2017).</p>
<p>Property-optimized gaussian basis sets for molecular response calculations. D Rappoport, F Furche, J. Chem. Phys. 133134105D. Rappoport, F. Furche, Property-optimized gaussian basis sets for molecular response calculations, J. Chem. Phys. 133, 134105 (2010).</p>
<p>A standard grid for density functional calculations. P M Gill, B G Johnson, J A Pople, Chem. Phys. Lett. 209P. M. Gill, B. G. Johnson, J. A. Pople, A standard grid for density functional calculations, Chem. Phys. Lett. 209. 506-512 (1993).</p>
<p>Nonlocal van der waals density functional: The simpler the better. O A Vydrov, T Van Voorhis, J. Chem. Phys. 133244103O. A. Vydrov, T. Van Voorhis, Nonlocal van der waals density functional: The simpler the better. J. Chem. Phys. 133, 244103 (2010).</p>
<p>Improved adsorption energetics within densityfunctional theory using revised perdew-burke-ernzerhof functionals. B Hammer, L B Hansen, J K NÃ¸rskov, Phys. Rev. B. 59B. Hammer, L. B. Hansen, J. K. NÃ¸rskov, Improved adsorption energetics within density- functional theory using revised perdew-burke-ernzerhof functionals. Phys. Rev. B 59, 7413- 7421 (1999).</p>
<p>Density-functional exchange-energy approximation with correct asymptotic behavior. A D Becke, Phys. Rev. A. 38A. D. Becke, Density-functional exchange-energy approximation with correct asymptotic behavior. Phys. Rev. A 38, 3098-3100 (1988).</p>            </div>
        </div>

    </div>
</body>
</html>