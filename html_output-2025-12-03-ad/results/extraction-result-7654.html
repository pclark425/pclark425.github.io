<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7654 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7654</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7654</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‑tuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-270924281</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2407.02511v2.pdf" target="_blank">LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning</a></p>
                <p><strong>Paper Abstract:</strong> Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles. Traditional algorithms like A* and its variants are capable of ensuring path validity but suffer from significant computational and memory inefficiencies as the state space grows. Conversely, large language models (LLMs) excel in broader environmental analysis through contextual understanding, providing global insights into environments. However, they fall short in detailed spatial and temporal reasoning, often leading to invalid or inefficient routes. In this work, we propose LLM-A*, an new LLM based route planning method that synergistically combines the precise pathfinding capabilities of A* with the global reasoning capability of LLMs. This hybrid approach aims to enhance pathfinding efficiency in terms of time and space complexity while maintaining the integrity of path validity, especially in large-scale scenarios. By integrating the strengths of both methodologies, LLM-A* addresses the computational and memory limitations of conventional algorithms without compromising on the validity required for effective pathfinding.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7654",
    "paper_id": "paper-270924281",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00420975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning
9 Apr 2025</p>
<p>Silin Meng silinmeng@cs.ucla.edu 
University of California
Los Angeles</p>
<p>University of California
Merced</p>
<p>Yiwei Wang 
University of California
Los Angeles</p>
<p>University of California
Merced</p>
<p>Cheng-Fu Yang 
University of California
Los Angeles</p>
<p>University of California
Merced</p>
<p>Nanyun Peng 
University of California
Los Angeles</p>
<p>University of California
Merced</p>
<p>Kai-Wei Chang 
University of California
Los Angeles</p>
<p>University of California
Merced</p>
<p>LLM-A<em>: Large Language Model Enhanced Incremental Heuristic Search on Path Planning
9 Apr 2025D8C494D1121A360958E8FBEC08BBA376arXiv:2407.02511v2[cs.RO]
Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles.Traditional algorithms like A</em> and its variants are capable of ensuring path validity but suffer from significant computational and memory inefficiencies as the state space grows.Conversely, large language models (LLMs) excel in broader environmental analysis through contextual understanding, providing global insights into environments.However, they fall short in detailed spatial and temporal reasoning, often leading to invalid or inefficient routes.In this work, we propose LLM-A<em>, an new LLM based route planning method that synergistically combines the precise pathfinding capabilities of A</em> with the global reasoning capability of LLMs.This hybrid approach aims to enhance pathfinding efficiency in terms of time and space complexity while maintaining the integrity of path validity, especially in large-scale scenarios.By integrating the strengths of both methodologies, LLM-A* addresses the computational and memory limitations of conventional algorithms without compromising on the validity required for effective pathfinding.</p>
<p>Introduction</p>
<p>Path planning is the computational process of determining a path from an initial point to a destination point that adheres to specific criteria, such as avoiding obstacles, minimizing travel distance or time, and satisfying other constraints (LaValle, 2006;Hart et al., 1968b;Karaman and Frazzoli, 2011).This problem is crucial across several fields, such as robotics, autonomous vehicle navigation, industrial automation, and virtual environment navigation due to its direct impact on the efficiency, safety, and feasibility of operational systems (Thrun et al., 2005;Karaman and  2011; Fiorini and Shiller, 1998;Fox et al., 1997).</p>
<p>Existing path planning algorithms are capable of effectively completing planning tasks and ensuring the validity of their paths.However, as the environment and map scale up, algorithms like A* and its variants (Hart et al., 1968b;Korf et al., 2001;Harabor and Grastien, 2011;Jansen and Buro, 2007) encounter an exponential increase in computational and memory demands.This occurs because the pathfinding process can become suboptimal (see Figure 1 and 2), where the algorithm might spend unnecessary effort exploring less relevant areas, leading to exponential increases in time complexity as the map size enlarges.</p>
<p>Meanwhile, Large Language Models (LLMs) have achieved notable milestones in various planning tasks (Naveed et al., 2023;Yin et al., 2023;Chen et al., 2023a;Shinn et al., 2024;Dou et al., 2024).These models demonstrate capabilities in processing and reasoning over long-context input to provide valuable global insights that reflect their understanding of the environment, such as identifying the relative positions of barriers, agents, and goals.However, they struggle with complex, long-term planning and complex spatial reasoning tasks such as grid-based path planning.LLMs often generate paths that are either invalid or ungrounded, resulting in incomplete or colliding paths, indicating a gap in their capability to handle detailed spatial intricacies (Aghzal et al., 2023).</p>
<p>Related Work</p>
<p>Traditional Algorithms in Path Planning.Pathfinding has been pivotal in artificial intelligence, robotics, and computer graphics, with numerous algorithms developed to address various challenges.Among the foundational methods, the A* algorithm, introduced by Hart, Nilsson, and Raphael in 1968, stands out for its use of a heuristic to estimate the cost from the current to the goal node, balancing greedy best-first search with uniform-cost search for efficient pathfinding (Hart et al., 1968a).Similarly, Pearl's Best First Search (BFS), proposed in 1984, prioritizes nodes based on heuristic values but can lead to longer paths due to its focus on the most promising nodes (Pearl, 1984).</p>
<p>Extensions of A<em> have aimed to enhance its efficiency and adaptability.Korf's Iterative Deepening A</em> (IDA<em>), from 1985, combines depth-first search with A</em>'s heuristic to create a memoryefficient approach (Korf, 1985).Korf also introduced Learning Real-time A<em> (LRTA</em>) in 1990, incorporating real-time learning to dynamically update heuristic values, improving performance in changing environments (Korf, 1990).Russell's Simplified Memory Bounded A<em> (SMA</em>), from 1992, addresses memory constraints by selectively forgetting less promising paths, making it suitable for resource-limited applications (Russell, 1992).</p>
<p>Further enhancements include Stentz's Dynamic A<em> (D</em>) from 1994, which recalculates paths as the environment changes, proving effective for navigation in unknown or evolving terrains (Stentz, 1994).Koenig et al.'s Lifelong Planning A<em> (LPA</em>), introduced in 2004, incrementally updates paths in dynamic and large-scale environments (Koenig et al., 2004).Harabor and Grastien's Jump Point Search (JPS), proposed in 2011, optimizes A<em> for only grid-based maps by identifying key "jump points", reducing the number of expanded nodes (Harabor and Grastien, 2011).Nash et al.'s Theta</em>, from 2007, allows line-of-sight checks between nodes, resulting in more direct paths (Nash et al., 2007).</p>
<p>Hierarchical approaches, such as Holte et al.'s Hierarchical A<em> (HA</em>) from 1996, decompose large pathfinding problems into smaller subproblems through a hierarchy of abstractions, reducing computational complexity (Holte et al., 1996).Botea et al.'s Hierarchical Path-finding A<em> (HPA</em>), introduced in 2004, improves transitions between abstraction levels for efficient large-map pathfinding (Botea et al., 2004).</p>
<p>Specialized methods also contribute significantly.Demyen and Buro's Triangulation-Based Pathfinding (TRA<em>), proposed in 2006, navigates polygonal environments using triangulation, suited for non-grid-based settings (Demyen and Buro, 2006).Koch's Grid-specific Hierarchical Path-finding (GHPA</em>), introduced in 2011, optimizes grid maps pathfinding by integrating hierarchical and grid-specific optimizations (Koch, 2011).</p>
<p>Large Language Models in Path Planning.Large Language Models (LLMs) have recently achieved remarkable success in natural language processing tasks and other domains (Naveed et al., 2023).Studies such as (Shridhar et al., 2020b;Song et al., 2023;Shah et al., 2023) explore LLMs in high-level planning, highlighting challenges in long-term planning and spatial reasoning (Aghzal et al., 2023).Our research shifts focus to continuous environments, offering a more realistic setting compared to grid-based maps.Continuous spaces align better with real-world conditions, providing a more natural interface for human interaction and allowing higher precision in spatial reasoning.</p>
<p>LLMs show varying proficiency in spatial rea- soning (Ilharco et al., 2020;Patel and Pavlick, 2021;Bubeck et al., 2023;Abdou et al., 2021;Yang et al., 2023b), yet face limitations in spatial reasoning and planning (Agrawal, 2023;Xie et al., 2023;Wu et al., 2023).We introduce a benchmark for path planning in continuous environments, integrating spatial and temporal reasoning.Prior benchmarks (Côté et al., 2019;Shridhar et al., 2020a;Ruis et al., 2020;Wu et al., 2021) often neglect temporal planning aspects.Our study further evaluates LLMs in robot motion and path planning contexts, addressing limitations in end-to-end planning (Liu et al., 2023;Chen et al., 2023b;Xie et al., 2023;Silver et al., 2022).</p>
<p>Recent work, such as the LLM3 framework (Wang et al., 2024) leverages pre-trained LLMs to integrate symbolic task planning with continuous motion generation through motion failure reasoning, where LLM3 iteratively refines both symbolic actions and continuous parameters, significantly improving planning efficiency in dynamic environments, which aligns with our focus on LLMs' adaptability in correcting low-level planning errors and enhancing resilience in dynamic conditions.</p>
<p>Understanding the interplay between high-level and low-level planning is crucial (Latif, 2024;Yang et al., 2023a;Ding et al., 2024;Zhou et al., 2024).High-level planning involves strategic goals, while low-level focuses on detailed task execution.Our research explores LLMs' adaptability in correcting low-level planning errors, ensuring resilience in dynamic conditions.</p>
<p>Methodology 3.1 A* Algorithm</p>
<p>The A* algorithm is a widely used pathfinding and graph traversal algorithm.It seeks to find the shortest path from a start node s 0 to a goal node s g by combining the strengths of Dijkstra's Algorithm and Greedy Best-First Search.</p>
<p>A* employs a heuristic function h(s) to estimate the cost from a node s to the goal, and a cost function g(s) to track the exact cost from the start to s.The total cost function f (s), defined as f (s) = g(s) + h(s), guides the search towards the goal.The algorithm operates as follows:</p>
<ol>
<li>
<p>Initialization: Place the start node s 0 in the OPEN list with f (s 0 ) = g(s 0 ) + h(s 0 ), and initialize the CLOSED list as empty.</p>
</li>
<li>
<p>Search: Continuously select the node s from the OPEN list with the lowest f -cost, expand its neighbors, and update their costs.If a neighbor s n offers a cheaper path than previously recorded, update its cost and parent node.Repeat until the goal node s g is reached or the OPEN list is empty.</p>
</li>
<li>
<p>Path Reconstruction: Once s g is reached, reconstruct the path by tracing back from s g to s 0 via parent nodes.</p>
</li>
</ol>
<p>The heuristic h(s) should be admissible, meaning it does not overestimate the true cost to reach the goal.This ensures the path optimality of A<em>.   , s).This step introduces an additional computational amount to the pathfinding process, and the time complexity scales linearly with both the length of T and the increasing size of O.However, it is important that this re-computation process ensures that the f -cost of visited states in O remains accurate and updated with the new target t.
g(s n ) ← g tent 19: f (s n ) ← g(s n ) + h(s n ) + cost(t, s n ) 20: if s n / ∈ O(s) = g(s) + h(s) + cost(t
General Applicability.LLM-A</em> retains the versatility of the original A<em>, making it suitable for a wide range of pathfinding tasks across various environments, where specialized A</em> variants such as JPS and GHPA<em> (Harabor and Grastien, 2011;Koch, 2011), which are tailored to grid maps and specific scenarios, and the mechanism of LLM-A</em> is able to handle diverse and large-scale environments effectively.This generality positions LLM-A<em> as a robust alternative to A</em>.</p>
<p>Prompt Techniques</p>
<p>Few shot Learning.In the methodology we termed "Few Shot Learning" or "Vanilla Prompting," our initial approach involves directly presenting the Large Language Model (LLM) with ground-truth sequences of actions as prompts.This method is informed by previous studies which have demonstrated that the performance of such models can vary significantly based on the volume of task-specific examples provided (Cao et al., 2019;Razeghi et al., 2022).To investigate this further, we employed a few-shot learning technique, wherein we provides five demonstrations (See Table 2 in Appendix) presented to the LLM.This approach aimed to determine the optimal number of examples that would enhance the model's accuracy and learning efficiency.</p>
<p>Chain of Thought.The Chain-of-Thought (CoT) methodology, as proposed by (Wei et al., 2022), introduces a technique that encourages a Large Language Model (LLM) to engage in a sequential, step-by-step reasoning process.This approach has demonstrated substantial efficacy in tasks necessitating multiple layers of reasoning and decision-making.In light of its proven effectiveness, we have adapted the CoT strategy (See Table 3 in Appendix) to the specific requirements of path planning.</p>
<p>Recursive Path Evaluation.The Recursive Path Evaluation (RePE) methodology (See Table 4 in Appendix) is designed to guide Large Language Models (LLMs) in generating paths incrementally, with a particular emphasis on evaluating each step in the process.This approach gains its effectiveness from deconstructing the path planning problem into three distinct sub-problems: environment analysis, path generation, and path evaluation.By following these sub-problems in a recursive manner, the model systematically navigates towards the goal, ensuring compliance with predefined constraints at each stage.This concept bears a resemblance to the ReAct approach, Step Back QA, and Self Reflection (Yao et al., 2022;Zheng et al., 2023;Renze and Guven, 2024) in its processing step by step foundational principles.Meanwhile, RePE receives no feedback or observation from environment, and it distinctively focuses on a step-by-step progression and only intrinsic reasoning, where the path is constructed one point at a time with environment analysis and path evaluation.This methodical approach not only facilitates more precise navigation by the LLM but also allows for continuous assessment and adjustment at each juncture, thereby may enhancing the overall accuracy of the path planning process.</p>
<p>Experiments</p>
<p>Dataset</p>
<p>Our dataset consists of 100 manually selected 50 × 30 maps from a randomly generated collection, each with 10 different start and goal positions.Therefore, there are 1000 samples in total (see Figure 1 for sample visualization).Our data conform to the standard of search-based algorithm environments in a continuous space.Each map includes the following parameters:</p>
<p>• x range: The minimum and maximum xcoordinates of the environment boundary range as [x min, x max].</p>
<p>• y range: The minimum and maximum ycoordinates of the environment boundary range as [y min, y max].</p>
<p>• horizontal barriers: List of horizontal barriers, each represented as [y, x start, x end].</p>
<p>• vertical barriers: List of vertical barriers, each represented as [x, y start, y end].</p>
<p>• start goal: List of 10 unique start and goal positions for each map.</p>
<p>These parameters define the structure and constraints of each map, ensuring consistency and relevance to the standard experimental environment conditions for search-based algorithms.Notably, the discretization of points and actions within this continuous framework is a necessary simplification that allows us to make the problem tractable and effectively evaluate algorithms.Meanwhile, the map environment is able to scale properly for scalability experiment.</p>
<p>Experimental Setup</p>
<p>Large Language Model.We employ GPT-3.5-TURBO and LLAMA3-8B-16bit for their balance of robustness and cost-effectiveness in validating the LLM-A* algorithm.Prompts include simple instructions, standard 5-shot examples, chain of thought with 3-shot, and recursive path evaluation with 3-shot for in-context learning (see Section 3.3).</p>
<p>Experiment Environment.Our system facilitates search-based pathfinding within a scalable framework designed for environments of varying complexity.It consists of modules for environment management, agent control, and visualization (see Section 4.1).</p>
<p>• Environment Management: Configures the environment and provides feedback, ensuring a challenging setup.</p>
<p>• Agent Control: Customizes the agent's operations using the algorithm and model, operating on discrete points and actions to make the problem tractable.</p>
<p>• Visualization: Offers real-time and final visual outputs for comprehensive analysis.</p>
<p>While the environments considered are presented within a continuous framework, both the LLM and A<em> algorithms operate on discrete points and actions.This necessary simplification allows us to effectively evaluate the proposed LLM-A</em> algorithm, ensuring the system remains applicable to a wide range of complex environments.</p>
<p>Experiment Subject.Our experiments focus on two critical aspects: efficiency and scalability.For efficiency, we assess the number of operations and the storage required for the pathfinding process, defined as time and space complexity, respectively.Additionally, we evaluate the generated path length to assess path efficiency.These metrics are used to compute a composite efficiency score, as presented in Table 1.Larger environments and maps are employed to better illustrate algorithm efficiency, as they offer a more comprehensive reflection of the algorithm's performance under increased complexity.Specifically, we conducted efficiency experiments on a 50 × 30 map of the original sample size.This size was selected as it provides a substantial basis for evaluating efficiency while keeping the computational demands within a manageable range.Beyond this scale, the experiment run times become excessively long.For scalability, we tested both A<em> and LLM-A</em> algorithms across 10 different scales, from 1 to 10, to examine how they adapt to progressively larger environments, as depicted in Figure 3.</p>
<p>Evaluation Metrics</p>
<p>We assess LLM-A<em> against A</em> using metrics for operation efficiency, storage efficiency, and path quality.Performance is summarized by the geometric mean of performance ratios between LLM-A<em> and A</em> for operation, storage, path length, offering a balanced view less affected by outliers.</p>
<p>Operation and Storage Ratios.We compute the geometric mean of the ratios of operations and storage used by LLM-A<em> relative to A</em> ( LLM-A<em> A</em> ).A lower score indicates better efficiency, e.g., a 50% score means LLM-A<em> uses 50% of the resources compared to A</em>.</p>
<p>Relative Path Length.Path quality is evaluated by comparing the path lengths from LLM-A<em>, A</em> and LLM-only approach to the optimal path.The geometric mean of these ratios indicates how close LLM-A* paths are to optimal.</p>
<p>Valid Path Ratio.This metric measures the proportion of successful pathfinding attempts, often indicating that the generated path is collision-free and completable.A higher ratio indicates better reliability, showing the algorithm's effectiveness in generating valid paths consistently.</p>
<p>Growth Factor.We assess how performance scales from a 50 × 30 environment to larger sizes by calculating the arithmetic mean of the growth factors for operations and storage.This normalizes efficiency and scalability across different environment sizes.</p>
<p>Quantitative Analysis</p>
<p>Table 1 presents a comparative analysis of three pathfinding methodologies: the classical A<em> algorithm, an LLM-only approach, and our proposed LLM-A</em> approach.The A<em> algorithm serves as the baseline, with an index value of 100 indicating performance equivalent to A</em>, as outlined in Section 4.3.The methodologies are evaluated on maps 50 × 30 of original map sizes.</p>
<p>The results demonstrate that LLM-A<em> significantly enhances both operation and storage efficiencies compared to A</em>.Specifically, when utilizing the LLM-A<em> model, GPT-3.5 achieves a 57.39% score in operations and a 74.96% score in storage, with a modest 2.44% increase in relative path length.Superior, with the LLAMA3 model, LLM-A</em> reduces operations by 44.59% and storage by 64.02%, accompanied by a slight 2.47% increase in relative path length.These results highlight that LLM-A* not only reduces resource consumption but also maintains path validity, consistently achieving a valid path ratio of 100% across all scenarios.The observed increase in path length remains relatively low compared to the optimal path.</p>
<p>When compared to other variants using nonadmissible heuristics, LLM-A<em> demonstrates an superior performance in term of operation and storage efficiency.Dynamic weighted A</em> (with initial weight of 2 and 0.99 decay) employs a static logic to dynamically update the weight, but it lacks the flexibility inherent to LLM-A<em>.Consequently, dynamic weighted A</em> falls short in terms of both operation efficiency and storage efficiency compared to our advanced LLM-A* approach.</p>
<p>Meanwhile, the LLM-only approach underperforms compared to LLM-A<em> and A</em> algorithms in terms of both path efficiency and validity.When used in isolation, LLMs may struggle with comprehensive path planning due to their lack of heuristic guidance, which is provided by LLM-A<em>, or the deterministic guarantees inherent in A</em>.The integration of LLM insights in LLM-A<em> significantly enhances its operational and storage efficiencies, surpassing the performance of A</em>.</p>
<p>Ablation Analysis.The Recursive Path Evaluation (RePE) prompting method achieves marginal improvements in relative path length for the LLM-A<em> approach using GPT-3.5, with an increment of 2.41%.This suggests some potential of RePE's step-by-step progression and intrinsic reasoning capabilities in generating more optimal waypoints, resulting in slightly more efficient paths.However, it is important to acknowledge that RePE underperforms compared to Chain of Thought (CoT) and few-shot prompting in a both operation and storage ratio, as well as efficiency in the LLMonly approach.This observation aligns with the limitations of LLMs in executing end-to-end path planning and spatial-temporal reasoning, which can affect their proficiency in sequentially reasoning out detailed path sequences and lead to issues such as hallucinations and misunderstandings, highlighting the diminish of RePE's efficiency for long-horizon tasks, where the intermediate points chosen using this technique are not optimal.Therefore, while RePE shows some promise, its overall effectiveness is limited compared to other methods in both LLM-A</em> and LLM-only scenarios.</p>
<p>Scalability Analysis.Figure 3 provides a comparative analysis of the computational and memory efficiency of the A<em> and LLM-A</em> algorithms across environments of different scales.The analysis is presented through two metrics: the growth factor of operations and the growth factor of storage, with respect to different environment scales.</p>
<p>The results from Fig. 3 indicate that LLM-A<em> significantly outperforms A</em> in both computational and memory efficiency across various environment scales.While A<em> grows exponentially in operations and storage, LLM-A</em> achieves near-linear scalability relative to the environment size.This performance advantage arises from the learning-based enhanced heuristic values incorporated into LLM-A<em>, which allow it to avoid unnecessary node exploration and facilitate a more direct search towards the goal.This adaptation proves especially effective in larger and more complex environments.The efficiency gains of LLM-A</em> are particularly noteworthy in environments scaled up to 10 times, where the inefficiencies of A* become increasingly pronounced.</p>
<p>Qualitative Analysis</p>
<p>From the visualization in Figure 1, LLM-A<em> identifies the optimal path with only 140 operations, less than one-fifth the 859 operations required by A</em>, as well as the storage reduction.Both algorithms utilize a priority queue that stores the fcost of each reached state, with the state having the lowest f -cost selected for exploration.The fundamental distinction between the two algorithms lies in their calculation of the f -cost or heuristic values.In addition, as the map size increases, this operational efficiency difference could become more pronounced, as further illustrated in Figure 3.As illustrated in Figure 4, LLM-A<em> leverages heuristic values derived from LLM-generated waypoints in addition to standard heuristic from A</em>, resulting in a dynamic heuristic that changes as the algorithm progresses.This dynamic adjustment is achieved through switching to the next target state during search when the current target state is reached.Each time the target state changes, the heuristic values for all previously reached states are recalculated.This allows LLM-A* to steer the search direction towards areas deemed more favorable by the large model at various stages of the search.</p>
<p>In contrast, A* employs a static heuristic for each state, which remains unchanged throughout the search.This static approach can lead to extensive exploration of non-optimal paths, including dead-end areas in the environment.</p>
<p>Conclusion</p>
<p>In this work, we propose a novel path planning algorithm, LLM-A<em>, which outperforms traditional algorithms like A</em> in terms of both computational and memory efficiency, as well as LLM-only approach in path robustness and optimality.LLM-A<em> integrates heuristic values derived from LLMgenerated waypoints (serves as global insight), with the deterministic guarantees in the A</em> algorithm.This hybrid approach addresses the shortcomings of both LLM-only approach and the A<em> algorithm by combining their respective strengths.Furthermore, the methodology of LLM-A</em> retains the general applicability of A<em>, making it suitable for pathfinding tasks in a wide range of environments.Thus, LLM-A</em> serves as an effective alternative to A* algorithm for path planning, especially in large-scale scenarios.</p>
<p>Limitations</p>
<p>Although around 90% of the paths generated by LLM-A* are optimal, our algorithm does not guarantee optimal path.While these cases are relatively few, they indicate that the algorithm may sometimes yield paths that are not the shortest or most efficient.Future improvements could focus on enhancing the optimality of the generated paths to ensure more consistent performance.</p>
<p>Our experiments mainly utilized GPT-3.5-TURBO and LLAMA3-8B-16bit with basic prompt techniques.Although these models and prompts were adequate to validate the robustness of the LLM-A* algorithm, we did not explore a wider array of models or advanced prompt engineering strategies.Further testing with additional models and varied prompting methods could provide more comprehensive insights into the algorithm's performance across different scenarios.</p>
<p>A Admissible Heuristic and Optimality</p>
<p>In path planning algorithms such as A<em>, a heuristic function h(n) is deemed admissible if it never overestimates the cost to reach the goal from any given node n.This ensures that the estimated cost from n to the goal does not exceed the actual lowest possible cost, thereby providing a lower bound on the true cost.An admissible heuristic guarantees that the A</em> algorithm will find an optimal solution, as it always explores the least costly path first.</p>
<p>The standard A* heuristic is often the Euclidean distance or straight-line distance between the current node and the goal, which is both admissible and consistent.This heuristic function accurately reflects the minimum possible cost in scenarios where there are no obstacles or other constraints that might alter the cost path.</p>
<p>However, the LLM-A<em> algorithm integrates an additional heuristic component, influenced by insights from large language models (LLMs), into the traditional A</em> heuristic function.Specifically, LLM-A* incorporates a modified heuristic h LLM A * (n) which includes an additional cost term that estimates the difficulty of transitioning from the current state to the target state, based on the learned patterns from the LLM.This adjustment effectively amplifies the traditional heuristic by adding a factor derived from the LLM's assessment of the state-space complexity and the likely transitions required.</p>
<p>Let h A * (n) represent the conventional heuristic, and c LLM (n) represent the cost component derived from the LLM insights.The modified heuristic can be expressed as:
h LLM A * (n) = h A * (n) + c LLM (n)
The term c LLM (n) may include factors such as predicted transition costs, obstacle avoidance strategies, or other environmental complexities inferred by the LLM, through selected target states in target list.Consequently, the heuristic function h LLM A * (n) provides a more nuanced estimate of the cost to reach the goal, potentially guiding the search more effectively by leveraging the LLM's understanding of the domain.</p>
<p>While this enhanced heuristic expedites the search process by prioritizing paths that the LLM identifies as promising, it introduces a deviation from admissibility.By incorporating the additional cost c LLM (n), the heuristic may overes-timate the true cost to the goal, particularly if the LLM-derived costs are overly conservative or based on non-optimal path predictions.This overestimation violates the admissibility condition because the total estimated cost g(n) + h LLM A * (n) could exceed the actual optimal path cost, where g(n) is the cost from the start to the current node.</p>
<p>The implications of this non-admissibility are significant: while the LLM-A<em> heuristic can potentially lead to faster convergence towards the goal by focusing the search in promising regions of the state space, it compromises the guarantee of finding the optimal path.The trade-off between search efficiency and optimality must be carefully considered in the application of LLM-A</em>.In scenarios where the heuristic insights from the LLM offer substantial benefits in reducing search time and computational resources, the potential loss of optimality may be justified.However, for applications where finding the absolute optimal path is crucial, relying solely on an admissible heuristic might be preferable.</p>
<p>B Prompts in LLMs</p>
<p>This appendix outlines the prompting techniques used in our LLM-A* algorithm to generate paths between start and goal points while navigating around obstacles.We employed different prompting strategies to evaluate their effectiveness in guiding the model.Below are the details of each technique along with the templates used.</p>
<p>B.1 Standard 5-Shot Demonstration</p>
<p>In the standard 5-shot demonstration in Table 2, the model is provided with five examples (or demonstrations) to guide the generation of the path.Each example includes start and goal points, along with horizontal and vertical barriers.The model is prompted to generate a path by following the pattern observed in the examples.</p>
<p>B.2 Chain of Thought (CoT) Prompting</p>
<p>The chain of thought prompting technique in Table 3 provides a sequence of reasoning steps that the model follows to arrive at the final path.This technique includes a detailed thought process and evaluation for each step, helping the model to understand the rationale behind the path generation.</p>
<p>B.3 Recursive Path Evaluation (RePE)</p>
<p>In the recursive path evaluation technique shown Table 4, the model iteratively evaluates the path Identify a path between the start and goal points to navigate around obstacles and find the shortest path to the goal.Horizontal barriers are represented as [y, x start, x end], and vertical barriers are represented as [x, y start, y end].Conclude your response with the generated path in the format "Generated Path: [[x1, y1], [x2, y2], ...]".</p>
<p>Start Point: [5,5] Goal Point: [20,20] Horizontal Barriers: [[10, 0, 25], [15,30,50]] Vertical Barriers: [[25, 10, 22]] Generated Path: [[5, 5], [26,9], [25,23], [20,20]]  3: The template of the prompt we used for LLM-A* using standard 3-shot demonstration with chain of thought generation process.at each step and makes decisions based on previous iterations.This process involves selecting points, evaluating their effectiveness, and adjusting the path as necessary to avoid obstacles and reach the goal.</p>
<p>C Details of Dataset Construction</p>
<p>The dataset for A* path planning is generated using a custom Python script, leveraging several key packages for randomization, geometric manipulation, visualization, and data management.The process involves the following steps:</p>
<ol>
<li>
<p>Initialization: The script initializes with specified map dimensions (x and y boundaries) and parameters (number of barriers and obstacles) for the number of unique environments and start-goal pairs.</p>
</li>
<li>
<p>Environment Creation: For each map configuration, do the following: within defined x and y ranges using the shapely.geometry.LineString for line segments.• Start and goal points are randomly placed on the map, ensuring they do not intersect with any obstacles.Valid pairs form non-intersecting line segments.</p>
</li>
<li>
<p>Data Storage: The generated environments, including the obstacles and start-goal pairs, are stored in JSON format.</p>
</li>
</ol>
<p>Query Generation:</p>
<p>Natural language queries are appended to each start-goal pair.These queries describe the task of finding a path that avoids the obstacles, which is supported as text input for LLMs.</p>
<p>Visualization:</p>
<p>The environments are visualized using matplotlib, displaying the grid, obstacles, and paths.The plots are supported to be saved as image files for reference and stream in a show..</p>
<p>The Python packages utilized include:</p>
<p>• random: For generating random coordinates.</p>
<p>• shapely: For geometric operations, specifically creating and validating the positions of obstacles and points.</p>
<p>• matplotlib: For plotting and saving visual representations of the environments.</p>
<p>• inquirer: For command-line prompts to make user decisions during dataset generation.</p>
<p>• json and os: For managing the reading and writing of dataset files.</p>
<p>• search env: A custom package for environment setup and plotting specific to the search based path planning task.</p>
<p>This process ensures a comprehensive dataset with varied environments and queries, suitable for training and testing A* path planning algorithms.</p>
<p>D Evaluation Metric</p>
<p>In this study, we evaluate the performance of our algorithm using the geometric mean of ratios.This metric provides a robust measure for comparing the efficiency and effectiveness of different path planning algorithms.Below, we outline the rationale for choosing this metric, the calculation procedure, and its advantages.</p>
<p>D.1 Rationale</p>
<p>The geometric mean of ratios is used in this study to assess the relative performance of different path planning algorithms or approaches.It provides a balanced evaluation by aggregating multiple performance ratios, ensuring that no single extreme value disproportionately affects the overall metric.This is particularly useful in scenarios where the distribution of ratios can be skewed, and a simple arithmetic mean might be misleading.</p>
<p>D.2 Calculation Procedure</p>
<p>Let R i represent the ratio of performance measures (such as path length, computation time, or any other relevant metric) between the proposed algorithm and a baseline or reference algorithm for the i-th test case.The geometric mean G of N ratios is calculated as follows:
G = N i=1 R i 1 N(1)
The geometric mean G provides a multiplicative average, effectively normalizing the ratios and providing a single representative value that reflects the overall performance across all test cases.</p>
<p>D.3 Advantages</p>
<p>Using the geometric mean of ratios offers several benefits in the context of evaluating path planning algorithms:</p>
<ol>
<li>
<p>Sensitivity to Relative Changes: The geometric mean is sensitive to the relative differences between performance measures, making it suitable for comparing ratios.</p>
</li>
<li>
<p>Mitigation of Outliers: Unlike the arithmetic mean, the geometric mean minimizes the impact of extreme values or outliers, providing a more stable and representative metric.</p>
</li>
<li>
<p>Interpretability: The geometric mean allows for easy interpretation of performance improvements or deteriorations.A geometric mean greater than 1 indicates that, on average, the proposed algorithm performs better than the baseline, while a value less than 1 suggests poorer performance.</p>
</li>
</ol>
<p>Figure 1 :
1
Figure 1: An comparison between LLM-A<em> and A</em> in computation and memory efficiency during pathfinding process.LLM-A<em> leverages target states generated by LLMs as waypoints to guide the searching process, significantly reducing the number of visited states, which leads to fewer operations and storage usage than A</em>.</p>
<p>Figure 2 :
2
Figure 2: Visual comparison of pathfinding efficiency Between A<em> and LLM-A</em>.This figure illustrates the performance differences between the traditional A<em> algorithm (left and upper images) and the LLM-A</em> algorithm (right and lower images).Red lines indicate the computed paths, blue dots mark the starting state, green dots indicate the goal state, gray areas represent visited states, and black lines denote obstacles.The LLM-A<em> algorithm demonstrates more efficient pathfinding by requiring significantly fewer visited states than A</em>.</p>
<p>Figure 3 :
3
Figure 3: The comparative analysis examines the computational and memory efficiency between A<em> and LLM-A</em> (incorporating LLAMA3 with few-shot prompting) across scaled environments ranging from 1 to 10 times enlargement, based on the means of 10 trials of random sampling.A<em> exhibits exponential growth in both (a) OPERATION and (b) STORAGE with linear increasing, environment scale, in contrast, LLM-A</em> achieves a near linear scalability.</p>
<p>Figure 4 :
4
Figure 4: Visualization of pathfinding process with LLM-A<em> algorithms (under chebyshev heuristic setting in 11 × 11 grid environment) utilizing each LLMgenerated waypoint, as well as comparison with A</em> in number of explored states.The blue and green rectangles denote the start and goal states, respectively.Grey rectangles indicate the states explored by the LLM-A<em> algorithms, while pink rectangles represent states explored by A</em>.Red line illustrate the generated paths.Stars indicate LLM-generated waypoints.(See Section 4.5 for more)</p>
<p>[5 in-context demonstrations abbreviated] Start Point: {start} Goal Point: {goal} Horizontal Barriers: {horizontal barriers} Vertical Barriers: {vertical barriers} Generated Path: Model Generated Answer Goes Here Table 2: The template of the prompt we used for LLM-A* using standard 5-shot demonstration.Identify a path between the start and goal points to navigate around obstacles and find the shortest path to the goal.Horizontal are represented as [y, x start, x end], and vertical barriers are represented as [x, y start, y end].Conclude your response with the generated path in the format "Generated Path: [[x1, y1], [x2, y2], ...]".Start Point: [5, 5] Goal Point: [20, 20] Horizontal Barriers: [[10, 0, 25],[15, 30, 50]] Vertical Barriers:[[25, 10, 22]] Thought: Identify a path from[5, 5]  to[20, 20]  while avoiding the horizontal barrier at y=10 spanning x=0 to x=25 by moving upwards and right, then bypass the vertical barrier at x=25 spanning y=10 to y=22, and finally move directly to[20, 20].Generated Path:[[5, 5],[26, 9],[25, 23],[20, 20]] [3 in-context demonstrations abbreviated] Start Point: {start} Goal Point: {goal} Horizontal Barriers: {horizontal barriers} Vertical Barriers: {vertical barriers} Generated Path: Model Generated Answer Goes Here Table</p>
<p>Algorithm 1 LLM-A* Algorithm for Path Planning 1: Require: START state s 0 , GOAL state s g , OBSTACLE set obs, heuristic function h(), cost function g(), Large Language Model llm() 2: OPEN list O open ← {s 0 }, CLOSE list C close ← {}, TARGET list T ← llm(s 0 , s g , O), TARGET state t ← T start , g(s 0 ) ← 0, f (s 0 ) ← h(s 0 ), P ← {} 3: while O open ̸ = ∅ do
4:s a ← arg min s∈Oopen f (s)5:if s a = s g then6:return reconstruct path(s a )7:Remove s a from O open8:Add s a to C close9:for all neighbors s n of s a do10:if s n = t and s g ̸ = t then11:t ← T next12:Update f -cost of states in O open13:if s n ∈ (C close ∪ obs) then14:continue15:Tentative cost g tent ← g(s a ) + cost(s a , s n )16:if s n / ∈ O open or g tent &lt; g(s n ) then17:Update path to s n to go through s a18:</p>
<p>This obstacle state is utilized to compute a TARGET list T , which comprises a sequence of path nodes from the start state s 0 to the goal state s g .This list is generated through a prompt to a large language model, reflecting the model's understanding and global perspective of the current environment.The returned T must meet two critical constraints in the following:
open then21:Add s n to O open22: return failure3.2 LLM-A<em> AlgorithmLLM-A</em> integrates the global insights providedby Large Language Models (LLMs) with theA<em> algorithm's optimal local search mechanism,where achieves a balance between the efficiency ofthe pathfinding process and optimality. The pseu-docode for LLM-A</em> is shown in Algorithm 1, andit closely resembles the original A<em> algorithm.LLM-A</em> accepts the same inputs as A<em>, withthe addition of an obstacle state variable, denotedas obs.
1. Containment of Start and Goal Points: T must include the start point and goal point that match the inputs s 0 and s g .If the returned T does not satisfy this requirement, s 0 and s g must be inserted by algorithm.2. Obstacle Avoidance: Every target node t in T must not be located within any obstacle obs.If any node t is found within an obstacle, it is removed from T by algorithm.The pathfinding process of LLM-A</em> is similar to that of A<em>.It uses a heuristic function h, a cost function g, an OPEN list O, and a CLOSED list C. The algorithm searches through each state in O until the goal state s g is reached.Each explored state s a is saved into C to avoid redundant searches.The distinction that encapsulates the main differences between LLM-A</em> and A<em> happens during the expansion of the neighbor state s n (see in Algorithm 1:13-15).For each s n , we check if it matches the current target t from T .If the current t is reached, t is updated to the next target in T .Subsequently, the f -cost of every state in the current O is re-computed, where the f -cost in LLM-A</em> is computed as the sum of the state's cost, the heuristic value, and the cost from the state to current t (see in Algorithm 1:20), de-fined as f</p>
<p>Table 1 :
1
MethodologyBase Model Prompt Approach Operation Ratio ↓ (%) Storage Ratio ↓ (%) Relative Path Length ↓ (%) Valid Path Ratio ↑ (%) Quantitative analysis of three pathfinding methodologies: the classical A<em> algorithm, dynamic weighted A</em> with initial weight of 2 and 0.99 decay, an LLM-only approach, and our proposed LLM-A<em> approach.The methodologies are evaluated on the map size (50 × 30) of original samples.The LLM-only approaches explore the path without explicitly searching the space grid by grid, so we do not report the operation and storage ratio.The table includes the results from GPT-3.5 and LLAMA3 models with three prompting approaches: Few-Shot, Chain of Thought (CoT), and Recursive Path Evaluation (RePE) for both LLM-only and LLM-A</em> approaches (see Section 4.4 for details).
A<em>--100100100100Dynamic WA</em> (w = 2) --60.9178.53100.24100Few-Shot--119.3812.80GPT-3.5CoT--151.7315.20LLMRePE--183.877.80Few-Shot--111.0512.60LLAMA3CoT--114.8912.00RePE--138.3216.40Few-Shot57.3974.96102.44100GPT-3.5CoT69.5083.65102.54100LLM-A* (Ours)RePE85.4796.53102.41100Few-Shot44.5964.02102.47100LLAMA3CoT47.6066.27102.46100RePE64.0880.19102.54100</p>
<p>•</p>
<p>Random obstacles, horizontal barriers, and vertical barriers are generated Identify a path between the start and goal points to navigate around obstacles and find the shortest path to the goal.Horizontal barriers are represented as [y, x start, x end], and vertical barriers are represented as [x, y start, y end].Conclude your response with the generated path in the format "Generated Path: [[x1, y1], [x2, y2], ...]".The path is obstructed by the vertical barrier, leading to a collision.A more effective route involves moving around this vertical barrier.Thought: To bypass the vertical barrier at x=25, we should move along its length and then turn around it to continue toward the goal.Selected Point: [25, 23] Evaluation: The selected point [25, 23] successfully avoids the vertical barrier and brings us closer to the goal without encountering further obstacles.-ThirdIterationon[25,23]Thought:Fromthis position, there are no barriers directly obstructing the path to the goal.Selected Point:[20, 20]Evaluation: The path to the goal is clear from here, allowing a direct move to the goal.
Start Point: [5, 5]Goal Point: [20, 20]Horizontal Barriers: [[10, 0, 25], [15, 30, 50]]Vertical Barriers: [[25, 10, 22]]-First Iteration on [5, 5]Thought: The horizontal barrier at y=10 spanning x=0 to x=25 blocks the direct path to the goal. To navigatearound it, we should move to the upper-right corner of the barrier.Selected Point: [26, 9]Evaluation: The selected point [26, 9] effectively bypasses the horizontal barrier, positioning us at its cornerand maintaining progress toward the goal without encountering additional obstacles.-Second Iteration on [26, 9]Thought: Now that we have bypassed the horizontal barrier, the path to the goal seems clear.Selected Point: [20, 20]Evaluation: Generated Path: [[5, 5], [26, 9], [25, 23], [20, 20]][3 in-context demonstrations abbreviated]Start Point: {start}Goal Point: {goal}Horizontal Barriers: {horizontal barriers}Vertical Barriers: {vertical barriers}Generated Path: Model Generated Answer Goes Here</p>
<p>Table 4 :
4
The template of the prompt we used for LLM-A* using standard 3-shot demonstration with recursive path evaluation generation process.</p>
<p>. Scalability: The geometric mean naturally scales with multiplicative factors, making it appropriate for comparing algorithms across different scales or units of measurement.
AcknowledgementThe work is partially support by a DARPA ANSR program FA8750-23-2-0004 and a National Science Foundation CAREER award #2339766.The views and conclusions are those of the authors and should not reflect the official policy or position of DARPA or the U.S. Government.
Can language models encode perceptual structure without grounding? a case study in color. Mostafa Abdou, Artur Kulmizev, Daniel Hershcovich, Stella Frank, Ellie Pavlick, Anders Søgaard, arXiv:2109.061292021arXiv preprint</p>
<p>Can large language models be good path planners? a benchmark and investigation on spatial-temporal reasoning. Mohamed Aghzal, Erion Plaku, Ziyu Yao, arXiv:2310.032492023arXiv preprint</p>
<p>Are llms the master of all trades?: Exploring domain-agnostic reasoning skills of llms. Shrivats Agrawal, arXiv:2303.128102023arXiv preprint</p>
<p>Near optimal hierarchical path-finding. Adi Botea, Martin Müller, Jonathan Schaeffer, Journal of Game Development. 112004</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>A theoretical analysis of the number of shots in few-shot learning. Tianshi Cao, Marc Law, Sanja Fidler, arXiv:1909.117222019arXiv preprint</p>
<p>Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik Narasimhan, Shunyu Yao, arXiv:2310.05915Fireact: Toward language agent fine-tuning. 2023aarXiv preprint</p>
<p>Textworld: A learning environment for text-based games. Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, Chuchu Fan ; Akos Kádár, Xingdi Yuan, Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud Adada, arXiv:2306.06531Computer Games: 7th Workshop, CGW 2018, Held in Conjunction with the 27th International Conference on Artificial Intelligence. Stockholm, SwedenSpringer2023b. 2019. 2018. July 13. 2018arXiv preprintAutotamp: Autoregressive task and motion planning with llms as translators and checkers. Revised Selected Papers 7</p>
<p>Efficient triangulation-based pathfinding. Douglas Demyen, Michael Buro, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2006</p>
<p>Peng Ding, Jiading Fang, Peng Li, Kangrui Wang, Xiaochen Zhou, Mo Yu, Jing Li, Matthew R Walter, Hongyuan Mei, arXiv:2403.19913Mango: A benchmark for evaluating mapping and navigation abilities of large language models. 2024arXiv preprint</p>
<p>Reflectionreinforced self-training for language agents. Zi-Yi Dou, Cheng-Fu Yang, Xueqing Wu, Kai-Wei Chang, Nanyun Peng, arXiv:2406.014952024arXiv preprint</p>
<p>Motion planning in dynamic environments using velocity obstacles. Paolo Fiorini, Zvi Shiller, IEEE International Conference on Robotics and Automation. IEEE1998</p>
<p>The dynamic window approach to collision avoidance. Dieter Fox, Wolfram Burgard, Sebastian Thrun, IEEE Robotics &amp; Automation Magazine. 411997</p>
<p>Online graph pruning for pathfinding on grid maps. Daniel Harabor, Alban Grastien, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201125</p>
<p>A formal basis for the heuristic determination of minimum cost paths. Peter Hart, Nils Nilsson, Bertram Raphael, IEEE Transactions on Systems Science and Cybernetics. 421968a</p>
<p>A formal basis for the heuristic determination of minimum cost paths. Nils J Peter E Hart, Bertram Nilsson, Raphael, IEEE transactions on Systems Science and Cybernetics. 1968b4</p>
<p>Robert Holte, Perez, Zimmer, Macdonald, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence1996</p>
<p>Probing contextual language models for common ground with visual representations. Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi, arXiv:2005.006192020arXiv preprint</p>
<p>Hpa* enhancements. M Jansen, Michael Buro, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment20073</p>
<p>Samplingbased algorithms for optimal motion planning. Sertac Karaman, Emilio Frazzoli, The International Journal of Robotics Research. 3072011</p>
<p>Grid-specific feature of hpa*. Uwe Koch, Proceedings of the International Conference on Artificial Intelligence. the International Conference on Artificial Intelligence2011</p>
<p>. Sven Koenig, Maxim Likhachev, David Furcy, Lifelong planning a. Artificial Intelligence. 1551-22004</p>
<p>Depth-first iterative-deepening: An optimal admissible tree search. Artificial Intelligence. Richard E Korf, 198527</p>
<p>Real-time heuristic search. Richard E Korf, Artificial Intelligence. 422-31990</p>
<p>Time complexity of iterative-deepening-a*. Richard E Korf, Michael Reid, Stefan Edelkamp, Artificial Intelligence. 1291-22001</p>
<p>Ehsan Latif, arXiv:2403.18778Probabilistic path planning using large language model for autonomous robot navigation. 20243arXiv preprint</p>
<p>Planning Algorithms. Steven M Lavalle, 2006Cambridge University Press</p>
<p>Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, Peter Stone, arXiv:2304.11477Llm+ p: Empowering large language models with optimal planning proficiency. 2023arXiv preprint</p>
<p>Theta: Any-angle path planning on grids. Alex Nash, Kenny Daniel, Sven Koenig, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2007and Ariel Felner</p>
<p>Muhammad Saqib. Humza Naveed, Asad Ullah Khan, Shi Qiu, arXiv:2307.06435Saeed Anwar, Muhammad Usman, Nick Barnes, and Ajmal Mian. 2023. A comprehensive overview of large language models. arXiv preprint</p>
<p>Mapping language models to grounded conceptual spaces. Roma Patel, Ellie Pavlick, International Conference on Learning Representations. 2021</p>
<p>Heuristics: Intelligent Search Strategies for Computer Problem Solving. Judea Pearl, 1984Addison-Wesley</p>
<p>Impact of pretraining term frequencies on few-shot numerical reasoning. Yasaman Razeghi, Robert L Logan, I V , Matt Gardner, Sameer Singh, Findings of the Association for Computational Linguistics: EMNLP 2022. 2022</p>
<p>A benchmark for systematic generalization in grounded language understanding. Matthew Renze, Erhan Guven, Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, Brenden M Lake, arXiv:2405.06682Advances in neural information processing systems. 2024. 202033arXiv preprintSelfreflection in llm agents: Effects on problem-solving performance</p>
<p>Memory-bounded heuristic search. Russell Stuart, Artificial Intelligence. 491-31992</p>
<p>Navigation with large language models: Semantic guesswork as a heuristic for planning. Dhruv Shah, Michael Robert Equi, Błażej Osiński, Fei Xia, Brian Ichter, Sergey Levine, Conference on Robot Learning. PMLR2023</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202436</p>
<p>Alfred: A benchmark for interpreting grounded instructions for everyday tasks. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, Dieter Fox, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2020a</p>
<p>Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, Matthew Hausknecht, arXiv:2010.03768Alfworld: Aligning text and embodied environments for interactive learning. 2020barXiv preprint</p>
<p>Pddl planning with pretrained large language models. Tom Silver, Varun Hariprasad, Reece S Shuttleworth, Nishanth Kumar, Tomás Lozano-Pérez, Leslie Pack, Kaelbling , NeurIPS 2022 foundation models for decision making workshop. 2022</p>
<p>Llm-planner: Few-shot grounded planning for embodied agents with large language models. Hee Chan, Jiaman Song, Clayton Wu, Brian M Washington, Wei-Lun Sadler, Yu Chao, Su, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Optimal and efficient path planning for partially-known environments. Anthony Stentz, Proceedings of the IEEE International Conference on Robotics and Automation (ICRA). the IEEE International Conference on Robotics and Automation (ICRA)1994</p>
<p>Probabilistic Robotics. Sebastian Thrun, Wolfram Burgard, Dieter Fox, 2005MIT press</p>
<p>Shu Wang, Muzhi Han, Ziyuan Jiao, Zeyu Zhang, Ying Nian Wu, Song-Chun Zhu, Hangxin Liu, arXiv:2403.11552Llmˆ3: Large language model-based task and motion planning with motion failure reasoning. 2024arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, Yoon Kim, arXiv:2307.024772023arXiv preprint</p>
<p>Zhengxuan Wu, Elisa Kreiss, Desmond C Ong, Christopher Potts, arXiv:2109.08994Reascan: Compositional reasoning in language grounding. 2021arXiv preprint</p>
<p>Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, Harold Soh, arXiv:2302.05128Translating natural language to planning goals with large-language models. 2023arXiv preprint</p>
<p>Lacma: Languagealigning contrastive learning with meta-actions for embodied instruction following. Cheng-Fu Yang, Yen-Chun Chen, Jianwei Yang, Xiyang Dai, Lu Yuan, Yu-Chiang Frank, Wang , Kai-Wei Chang, arXiv:2310.123442023aarXiv preprint</p>
<p>Cheng-Fu Yang, Haoyang Xu, Te-Lin Wu, Xiaofeng Gao, Kai-Wei Chang, Feng Gao, arXiv:2312.01097Planning as in-painting: A diffusion-based embodied task planning framework for environments under uncertainty. 2023barXiv preprint</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprint</p>
<p>Lumos: Learning agents with unified data, modular design, and open-source llms. Faeze Da Yin, Abhilasha Brahman, Khyathi Ravichander, Kai-Wei Chandu, Yejin Chang, Bill Choi, Lin Yuchen, arXiv:2311.056572023arXiv preprint</p>
<p>Swaroop Huaixiu Steven Zheng, Xinyun Mishra, Heng-Tze Chen, Ed H Cheng, Quoc V Chi, Denny Le, Zhou, arXiv:2310.06117Take a step back: Evoking reasoning via abstraction in large language models. 2023arXiv preprint</p>
<p>Navgpt: Explicit reasoning in vision-and-language navigation with large language models. Gengze Zhou, Yicong Hong, Qi Wu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>            </div>
        </div>

    </div>
</body>
</html>