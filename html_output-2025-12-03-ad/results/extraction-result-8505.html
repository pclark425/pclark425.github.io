<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8505 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8505</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8505</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-152.html">extraction-schema-152</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-875d71bae61a66f7e65a2b6d363b7a0a27a6ed25</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/875d71bae61a66f7e65a2b6d363b7a0a27a6ed25" target="_blank">Tree of Uncertain Thoughts Reasoning for Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> IEEE International Conference on Acoustics, Speech, and Signal Processing</p>
                <p><strong>Paper TL;DR:</strong> The Tree of Uncertain Thoughts (TouT) is introduced — a reasoning framework tailored for Large Language Models that effectively leverages Monte Carlo Dropout to quantify uncertainty scores associated with LLMs’ diverse local responses at these intermediate steps and enhances the model’s precision in response generation.</p>
                <p><strong>Paper Abstract:</strong> While the recently introduced Tree of Thoughts (ToT) has heralded advancements in allowing Large Language Models (LLMs) to reason through foresight and backtracking for global decision-making, it has overlooked the inherent local uncertainties in intermediate decision points or "thoughts". These local uncertainties, intrinsic to LLMs given their potential for diverse responses, remain a significant concern in the reasoning process. Addressing this pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) — a reasoning framework tailored for LLMs. Our TouT effectively leverages Monte Carlo Dropout to quantify uncertainty scores associated with LLMs’ diverse local responses at these intermediate steps. By marrying this local uncertainty quantification with global search algorithms, TouT enhances the model’s precision in response generation. We substantiate our approach with rigorous experiments on two demanding planning tasks: Game of 24 and Mini Crosswords. The empirical evidence underscores TouT’s superiority over both ToT and chain-of-thought prompting methods.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8505.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8505.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TouT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree of Uncertain Thoughts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reasoning framework that augments Tree-of-Thoughts search with local uncertainty quantification via Monte Carlo Dropout and an uncertainty-aware global search using a value/uncertainty (V/u) ranking to prefer high-value, low-uncertainty intermediate states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LLaMA-2 family large pretrained transformer; the paper uses the released LLaMA-2-70B weights as the black-box language model for generation and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Tree-of-Thoughts style search (BFS/DFS over partial solutions)', 'Local uncertainty quantification via Monte Carlo Dropout sampling', 'Uncertainty-aware global search using V/u ranking (value divided by uncertainty)', 'Diverse candidate generation via sampling (temperature interpolation and dropout)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>TouT generates multiple candidate intermediate 'thoughts' per tree node (k candidates) and, for each candidate, performs m Monte Carlo Dropout sampling runs (varying temperature via linear interpolation) to produce diverse local responses; it computes the variance across sampled responses as a local uncertainty score u and uses an evaluator V to score state value; global selection ranks states by V/u and uses BFS or DFS (with thresholds) to choose the most promising low-uncertainty states.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse (explicitly generates and quantifies multiple varied local responses per intermediate step and selects among them)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared baseline IO, CoT, CoT-SC, and ToT baselines to TouT; ablation toggled Local Uncertainty Quantification (LUQ) and Uncertainty-aware Global Search (UGS) separately and together (Table 3); additionally varied Monte Carlo sampling steps m in LUQ (5,10,20,50,100) to study effect on diversity/uncertainty estimation (Table 4); compared breadth settings b=1 and b=5 for ToT and TouT.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Game of 24 (1,362 games, test subset indexed 901-1000; 3-step thoughts) and Mini Crosswords (156 5x5 games, 5-10 intermediate steps; evaluate letters, words, and games).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Game of 24 success rates: IO 6%, CoT 3%, CoT-SC 7.2%, ToT (b=1) 37%, TouT (b=1) 42%; ToT (b=5) 56%, TouT (b=5) 65% (Table 1). Mini Crosswords: Letter/Word/Game: IO 29.5/10/0, CoT 33.2/10.8/0, ToT 59/48/12, TouT 61/52/15; ToT+best state 62.2/53.9/21, TouT+best state 64.5/58.2/29 (Table 2). Ablation (Table 3) on LUQ and UGS: neither (baseline) Game24 56; LUQ only -> 60; UGS only -> 61; LUQ+UGS -> 65. Monte Carlo sampling steps (Table 4): m=5 -> Game24 61; m=10 -> 63; m=20 -> 65 (best); m=50 -> 65; m=100 -> 64.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Quantifying local uncertainty and incorporating it into global search improves selection of intermediate states and final performance; LUQ and UGS each provide gains and their combination gives the largest improvement; Monte Carlo sampling increases robustness up to ~20 samples (diminishing returns beyond); TouT's V/u ranking prefers high-value, low-variance (less uncertain) partial solutions, leading to fewer incorrect branches and better backtracking decisions compared to ToT which lacks explicit local uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Explicitly measuring and using local uncertainty of diverse intermediate responses via Monte Carlo Dropout and ranking states by value/uncertainty leads to consistent improvements over ToT and CoT baselines across planning tasks; LUQ and UGS are both important and complementary, and about 20 Monte Carlo samples are sufficient for the tested tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Tree of Uncertain Thoughts Reasoning for Large Language Models', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8505.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8505.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree of Thoughts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior deliberative reasoning framework that searches over a tree of partial solutions by generating multiple candidate thoughts per state and evaluating states with a value function V, enabling foresight and backtracking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of Thoughts: Deliberate problem solving with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-70B (as used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Used as the baseline language model for ToT experiments in this paper; the ToT method itself is a search/meta-reasoning framework applied on top of a pre-trained LM.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Tree-of-Thoughts search (generate k candidate thoughts per state, evaluate states independently, BFS/DFS search/backtracking)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>ToT decomposes intermediate steps into tree states, uses a thought generator G(p_theta, s, k) to create k candidate continuations and a state evaluator V(p_theta, S) to estimate state promise, then runs a search algorithm (BFS/DFS) to select states without explicit local uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse (generates multiple candidate thoughts per state), but does not explicitly quantify local uncertainty for each candidate</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Serves as a primary baseline compared to TouT; evaluated with breadth limits b=1 and b=5 and compared against TouT which augments ToT with LUQ and UGS.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Game of 24 and Mini Crosswords (same tasks and splits as TouT experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Game of 24: ToT (b=1) 37%, ToT (b=5) 56% (Table 1). Mini Crosswords: Letter/Word/Game = 59/48/12; ToT + best state = 62.2/53.9/21 (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>ToT benefits from multiple candidate generation and global search but can be improved by taking into account local uncertainty of candidate thoughts; without uncertainty-aware ranking it selects states based only on V, which can miss reliable low-variance options.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>ToT is a strong baseline for deliberate problem solving with LLMs but augmenting it with local uncertainty estimation and uncertainty-aware global ranking (as in TouT) yields measurable gains in accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Tree of Uncertain Thoughts Reasoning for Large Language Models', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8505.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8505.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain of Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting technique that elicits step-by-step chain-of-thought reasoning from LMs by demonstrating or prompting intermediate reasoning steps, typically producing a single sequential reasoning trace per query.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-70B (as used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Applied as a prompting baseline where the LM is prompted to produce a single chain of intermediate reasoning steps (a sequential, left-to-right thought process).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-thought (single sequential reasoning chain)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>CoT produces a single, linear sequence of intermediate thoughts z1...zn appended to the prompt, and the final answer is produced conditioned on this chain; in experiments CoT is used as a baseline without ensembling or search.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>similar (single sequential chain per run)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared as a baseline against ensemble methods (CoT-SC), tree search (ToT), and TouT; CoT performance measured directly in Game of 24 and Mini Crosswords.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Game of 24 and Mini Crosswords.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Game of 24: CoT 3% success (Table 1). Mini Crosswords: Letter/Word/Game = 33.2/10.8/0 (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Single-chain CoT produces low performance on these multi-step planning tasks compared to methods that produce or aggregate multiple candidate reasoning traces or perform explicit search; it is particularly weak on Game of 24 and full-game mini crossword accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Sequential single-chain prompting (CoT) is insufficient for these deliberate multi-step planning tasks; methods that produce multiple candidate thoughts (ToT, TouT) or aggregate multiple chains (CoT-SC) perform substantially better.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Tree of Uncertain Thoughts Reasoning for Large Language Models', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8505.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8505.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-SC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain of Thought with Self-Consistency</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble-style extension of chain-of-thought prompting that samples multiple reasoning chains and selects the final answer by majority or highest consistency among sampled chains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-70B (as used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Used as a baseline that generates multiple CoT samples and aggregates them (self-consistency) to improve robustness over single-chain CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Ensembled Chain-of-Thought (self-consistency aggregation of multiple sampled chains)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>CoT-SC samples multiple independent chain-of-thought outputs and selects or aggregates the final answer by frequency/consensus, increasing robustness by leveraging diverse sampled chains.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse (multiple sampled chains are generated and aggregated)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Included as a baseline (CoT-SC) that uses multiple sampled CoT traces and selects by frequency; compared to ToT and TouT which use structured search/uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Game of 24 and Mini Crosswords.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Game of 24: CoT-SC 7.2% success (Table 1). Mini Crosswords: not separately tabulated beyond CoT baselines in Table 2, but CoT-SC reported in Game of 24 comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Self-consistency improves over single CoT but remains far below tree-search based approaches for these structured planning tasks; aggregation of sampled chains helps but lacks explicit global search and local uncertainty-aware selection.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Ensembling multiple chains (self-consistency) yields modest gains over single-chain CoT, but structured search with multiple candidates (ToT/TouT) and explicit uncertainty-aware selection provides larger improvements on multi-step planning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Tree of Uncertain Thoughts Reasoning for Large Language Models', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8505.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8505.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MC Dropout</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Monte Carlo Dropout (as uncertainty estimator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sampling-based technique that uses multiple forward passes with dropout enabled at inference to approximate model uncertainty via the variance of outputs; used here to quantify local uncertainty of candidate intermediate thoughts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dropout as a bayesian approximation: Representing model uncertainty in deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-70B (dropout applied during sampling runs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Monte Carlo Dropout is applied during repeated inference runs (m sampling steps) on the same prompt/state to produce diverse outputs whose variance is used as an uncertainty score for each candidate thought.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Uncertainty quantification via Monte Carlo Dropout sampling to produce diverse local responses and estimate per-candidate variance']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>For each candidate thought, the LM performs m forward passes with dropout (and temperature interpolation) to generate m sampled states; the variance across these samples is computed and used as the local uncertainty score u, which is then combined with the value evaluator V via V/u for global ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse (explicitly creates multiple varied local responses per candidate to estimate uncertainty)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Ablation and exploration varied m in {5,10,20,50,100} (Table 4) to measure the effect of sampling depth on uncertainty estimation and downstream performance; LUQ (using MC Dropout) was ablated against UGS and baseline in Table 3.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Game of 24 and Mini Crosswords (used to quantify local uncertainties in TouT's LUQ module).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Varying m: m=5 -> Game24 61; m=10 -> 63; m=20 -> 65 (best); m=50 -> 65; m=100 -> 64 (Table 4). Ablation (Table 3) shows adding LUQ (MC Dropout based) to baseline increased Game24 from 56 to 60 and improved Mini Crosswords metrics as reported.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>MC Dropout provides an effective, lightweight way to estimate local uncertainty in black-box LLMs; sampling more runs improves uncertainty estimates up to ~20 samples for these tasks, after which returns diminish; variance-based uncertainty helps avoid high-value but high-variance (unreliable) branches.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Monte Carlo Dropout is an effective method for quantifying the local uncertainty of diverse model responses and, when integrated into global selection (V/u), improves search-based reasoning performance; ~20 MC samples provide a practical tradeoff between cost and performance for the tested tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Tree of Uncertain Thoughts Reasoning for Large Language Models', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tree of Thoughts: Deliberate problem solving with large language models <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Dropout as a bayesian approximation: Representing model uncertainty in deep learning <em>(Rating: 2)</em></li>
                <li>Generating with confidence: Uncertainty quantification for black-box large language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8505",
    "paper_id": "paper-875d71bae61a66f7e65a2b6d363b7a0a27a6ed25",
    "extraction_schema_id": "extraction-schema-152",
    "extracted_data": [
        {
            "name_short": "TouT",
            "name_full": "Tree of Uncertain Thoughts",
            "brief_description": "A reasoning framework that augments Tree-of-Thoughts search with local uncertainty quantification via Monte Carlo Dropout and an uncertainty-aware global search using a value/uncertainty (V/u) ranking to prefer high-value, low-uncertainty intermediate states.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-70B",
            "model_description": "LLaMA-2 family large pretrained transformer; the paper uses the released LLaMA-2-70B weights as the black-box language model for generation and evaluation.",
            "reasoning_methods": [
                "Tree-of-Thoughts style search (BFS/DFS over partial solutions)",
                "Local uncertainty quantification via Monte Carlo Dropout sampling",
                "Uncertainty-aware global search using V/u ranking (value divided by uncertainty)",
                "Diverse candidate generation via sampling (temperature interpolation and dropout)"
            ],
            "reasoning_methods_description": "TouT generates multiple candidate intermediate 'thoughts' per tree node (k candidates) and, for each candidate, performs m Monte Carlo Dropout sampling runs (varying temperature via linear interpolation) to produce diverse local responses; it computes the variance across sampled responses as a local uncertainty score u and uses an evaluator V to score state value; global selection ranks states by V/u and uses BFS or DFS (with thresholds) to choose the most promising low-uncertainty states.",
            "reasoning_diversity": "diverse (explicitly generates and quantifies multiple varied local responses per intermediate step and selects among them)",
            "reasoning_diversity_experimental_setup": "Compared baseline IO, CoT, CoT-SC, and ToT baselines to TouT; ablation toggled Local Uncertainty Quantification (LUQ) and Uncertainty-aware Global Search (UGS) separately and together (Table 3); additionally varied Monte Carlo sampling steps m in LUQ (5,10,20,50,100) to study effect on diversity/uncertainty estimation (Table 4); compared breadth settings b=1 and b=5 for ToT and TouT.",
            "task_or_benchmark": "Game of 24 (1,362 games, test subset indexed 901-1000; 3-step thoughts) and Mini Crosswords (156 5x5 games, 5-10 intermediate steps; evaluate letters, words, and games).",
            "performance_results": "Game of 24 success rates: IO 6%, CoT 3%, CoT-SC 7.2%, ToT (b=1) 37%, TouT (b=1) 42%; ToT (b=5) 56%, TouT (b=5) 65% (Table 1). Mini Crosswords: Letter/Word/Game: IO 29.5/10/0, CoT 33.2/10.8/0, ToT 59/48/12, TouT 61/52/15; ToT+best state 62.2/53.9/21, TouT+best state 64.5/58.2/29 (Table 2). Ablation (Table 3) on LUQ and UGS: neither (baseline) Game24 56; LUQ only -&gt; 60; UGS only -&gt; 61; LUQ+UGS -&gt; 65. Monte Carlo sampling steps (Table 4): m=5 -&gt; Game24 61; m=10 -&gt; 63; m=20 -&gt; 65 (best); m=50 -&gt; 65; m=100 -&gt; 64.",
            "qualitative_findings": "Quantifying local uncertainty and incorporating it into global search improves selection of intermediate states and final performance; LUQ and UGS each provide gains and their combination gives the largest improvement; Monte Carlo sampling increases robustness up to ~20 samples (diminishing returns beyond); TouT's V/u ranking prefers high-value, low-variance (less uncertain) partial solutions, leading to fewer incorrect branches and better backtracking decisions compared to ToT which lacks explicit local uncertainty.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Explicitly measuring and using local uncertainty of diverse intermediate responses via Monte Carlo Dropout and ranking states by value/uncertainty leads to consistent improvements over ToT and CoT baselines across planning tasks; LUQ and UGS are both important and complementary, and about 20 Monte Carlo samples are sufficient for the tested tasks.",
            "uuid": "e8505.0",
            "source_info": {
                "paper_title": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "ToT",
            "name_full": "Tree of Thoughts",
            "brief_description": "A prior deliberative reasoning framework that searches over a tree of partial solutions by generating multiple candidate thoughts per state and evaluating states with a value function V, enabling foresight and backtracking.",
            "citation_title": "Tree of Thoughts: Deliberate problem solving with large language models",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-70B (as used in experiments)",
            "model_description": "Used as the baseline language model for ToT experiments in this paper; the ToT method itself is a search/meta-reasoning framework applied on top of a pre-trained LM.",
            "reasoning_methods": [
                "Tree-of-Thoughts search (generate k candidate thoughts per state, evaluate states independently, BFS/DFS search/backtracking)"
            ],
            "reasoning_methods_description": "ToT decomposes intermediate steps into tree states, uses a thought generator G(p_theta, s, k) to create k candidate continuations and a state evaluator V(p_theta, S) to estimate state promise, then runs a search algorithm (BFS/DFS) to select states without explicit local uncertainty quantification.",
            "reasoning_diversity": "diverse (generates multiple candidate thoughts per state), but does not explicitly quantify local uncertainty for each candidate",
            "reasoning_diversity_experimental_setup": "Serves as a primary baseline compared to TouT; evaluated with breadth limits b=1 and b=5 and compared against TouT which augments ToT with LUQ and UGS.",
            "task_or_benchmark": "Game of 24 and Mini Crosswords (same tasks and splits as TouT experiments).",
            "performance_results": "Game of 24: ToT (b=1) 37%, ToT (b=5) 56% (Table 1). Mini Crosswords: Letter/Word/Game = 59/48/12; ToT + best state = 62.2/53.9/21 (Table 2).",
            "qualitative_findings": "ToT benefits from multiple candidate generation and global search but can be improved by taking into account local uncertainty of candidate thoughts; without uncertainty-aware ranking it selects states based only on V, which can miss reliable low-variance options.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "ToT is a strong baseline for deliberate problem solving with LLMs but augmenting it with local uncertainty estimation and uncertainty-aware global ranking (as in TouT) yields measurable gains in accuracy.",
            "uuid": "e8505.1",
            "source_info": {
                "paper_title": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT",
            "name_full": "Chain of Thought prompting",
            "brief_description": "A prompting technique that elicits step-by-step chain-of-thought reasoning from LMs by demonstrating or prompting intermediate reasoning steps, typically producing a single sequential reasoning trace per query.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-70B (as used in experiments)",
            "model_description": "Applied as a prompting baseline where the LM is prompted to produce a single chain of intermediate reasoning steps (a sequential, left-to-right thought process).",
            "reasoning_methods": [
                "Chain-of-thought (single sequential reasoning chain)"
            ],
            "reasoning_methods_description": "CoT produces a single, linear sequence of intermediate thoughts z1...zn appended to the prompt, and the final answer is produced conditioned on this chain; in experiments CoT is used as a baseline without ensembling or search.",
            "reasoning_diversity": "similar (single sequential chain per run)",
            "reasoning_diversity_experimental_setup": "Compared as a baseline against ensemble methods (CoT-SC), tree search (ToT), and TouT; CoT performance measured directly in Game of 24 and Mini Crosswords.",
            "task_or_benchmark": "Game of 24 and Mini Crosswords.",
            "performance_results": "Game of 24: CoT 3% success (Table 1). Mini Crosswords: Letter/Word/Game = 33.2/10.8/0 (Table 2).",
            "qualitative_findings": "Single-chain CoT produces low performance on these multi-step planning tasks compared to methods that produce or aggregate multiple candidate reasoning traces or perform explicit search; it is particularly weak on Game of 24 and full-game mini crossword accuracy.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Sequential single-chain prompting (CoT) is insufficient for these deliberate multi-step planning tasks; methods that produce multiple candidate thoughts (ToT, TouT) or aggregate multiple chains (CoT-SC) perform substantially better.",
            "uuid": "e8505.2",
            "source_info": {
                "paper_title": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-SC",
            "name_full": "Chain of Thought with Self-Consistency",
            "brief_description": "An ensemble-style extension of chain-of-thought prompting that samples multiple reasoning chains and selects the final answer by majority or highest consistency among sampled chains.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-70B (as used in experiments)",
            "model_description": "Used as a baseline that generates multiple CoT samples and aggregates them (self-consistency) to improve robustness over single-chain CoT.",
            "reasoning_methods": [
                "Ensembled Chain-of-Thought (self-consistency aggregation of multiple sampled chains)"
            ],
            "reasoning_methods_description": "CoT-SC samples multiple independent chain-of-thought outputs and selects or aggregates the final answer by frequency/consensus, increasing robustness by leveraging diverse sampled chains.",
            "reasoning_diversity": "diverse (multiple sampled chains are generated and aggregated)",
            "reasoning_diversity_experimental_setup": "Included as a baseline (CoT-SC) that uses multiple sampled CoT traces and selects by frequency; compared to ToT and TouT which use structured search/uncertainty quantification.",
            "task_or_benchmark": "Game of 24 and Mini Crosswords.",
            "performance_results": "Game of 24: CoT-SC 7.2% success (Table 1). Mini Crosswords: not separately tabulated beyond CoT baselines in Table 2, but CoT-SC reported in Game of 24 comparison.",
            "qualitative_findings": "Self-consistency improves over single CoT but remains far below tree-search based approaches for these structured planning tasks; aggregation of sampled chains helps but lacks explicit global search and local uncertainty-aware selection.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Ensembling multiple chains (self-consistency) yields modest gains over single-chain CoT, but structured search with multiple candidates (ToT/TouT) and explicit uncertainty-aware selection provides larger improvements on multi-step planning tasks.",
            "uuid": "e8505.3",
            "source_info": {
                "paper_title": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "MC Dropout",
            "name_full": "Monte Carlo Dropout (as uncertainty estimator)",
            "brief_description": "A sampling-based technique that uses multiple forward passes with dropout enabled at inference to approximate model uncertainty via the variance of outputs; used here to quantify local uncertainty of candidate intermediate thoughts.",
            "citation_title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-70B (dropout applied during sampling runs)",
            "model_description": "Monte Carlo Dropout is applied during repeated inference runs (m sampling steps) on the same prompt/state to produce diverse outputs whose variance is used as an uncertainty score for each candidate thought.",
            "reasoning_methods": [
                "Uncertainty quantification via Monte Carlo Dropout sampling to produce diverse local responses and estimate per-candidate variance"
            ],
            "reasoning_methods_description": "For each candidate thought, the LM performs m forward passes with dropout (and temperature interpolation) to generate m sampled states; the variance across these samples is computed and used as the local uncertainty score u, which is then combined with the value evaluator V via V/u for global ranking.",
            "reasoning_diversity": "diverse (explicitly creates multiple varied local responses per candidate to estimate uncertainty)",
            "reasoning_diversity_experimental_setup": "Ablation and exploration varied m in {5,10,20,50,100} (Table 4) to measure the effect of sampling depth on uncertainty estimation and downstream performance; LUQ (using MC Dropout) was ablated against UGS and baseline in Table 3.",
            "task_or_benchmark": "Game of 24 and Mini Crosswords (used to quantify local uncertainties in TouT's LUQ module).",
            "performance_results": "Varying m: m=5 -&gt; Game24 61; m=10 -&gt; 63; m=20 -&gt; 65 (best); m=50 -&gt; 65; m=100 -&gt; 64 (Table 4). Ablation (Table 3) shows adding LUQ (MC Dropout based) to baseline increased Game24 from 56 to 60 and improved Mini Crosswords metrics as reported.",
            "qualitative_findings": "MC Dropout provides an effective, lightweight way to estimate local uncertainty in black-box LLMs; sampling more runs improves uncertainty estimates up to ~20 samples for these tasks, after which returns diminish; variance-based uncertainty helps avoid high-value but high-variance (unreliable) branches.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Monte Carlo Dropout is an effective method for quantifying the local uncertainty of diverse model responses and, when integrated into global selection (V/u), improves search-based reasoning performance; ~20 MC samples provide a practical tradeoff between cost and performance for the tested tasks.",
            "uuid": "e8505.4",
            "source_info": {
                "paper_title": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
                "publication_date_yy_mm": "2023-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tree of Thoughts: Deliberate problem solving with large language models",
            "rating": 2
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2
        },
        {
            "paper_title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
            "rating": 2
        },
        {
            "paper_title": "Generating with confidence: Uncertainty quantification for black-box large language models",
            "rating": 2
        }
    ],
    "cost": 0.013455499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Shentong Mo ${ }^{1,2} \quad$ Miao Xin $^{3 *}$</p>
<h1>${ }^{1}$ Carnegie Mellon University, ${ }^{2}$ MBZUAI, ${ }^{3}$ Institute of Automation, Chinese Academy of Sciences</h1>
<h4>Abstract</h4>
<p>While the recently introduced Tree of Thoughts (ToT) has heralded advancements in allowing Large Language Models (LLMs) to reason through foresight and backtracking for global decision-making, it has overlooked the inherent local uncertainties in intermediate decision points or "thoughts". These local uncertainties, intrinsic to LLMs given their potential for diverse responses, remain a significant concern in the reasoning process. Addressing this pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a reasoning framework tailored for LLMs. Our TouT effectively leverages Monte Carlo Dropout to quantify uncertainty scores associated with LLMs' diverse local responses at these intermediate steps. By marrying this local uncertainty quantification with global search algorithms, TouT enhances the model's precision in response generation. We substantiate our approach with rigorous experiments on two demanding planning tasks: Game of 24 and Mini Crosswords. The empirical evidence underscores TouT's superiority over both ToT and chain-ofthought prompting methods.</p>
<p>Index Terms- large language models, tree of thoughts, uncertainty estimation</p>
<h2>1. INTRODUCTION</h2>
<p>Modern Large-scale Language Models (LLMs), including GPT's early iterations [1, 2, 3], the recent GPT-4 [4], and LLaMA-2 [5], have showcased remarkable prowess in tasks that demand mathematical, symbolic, commonsense, and knowledge reasoning. Despite this, their reasoning process primarily hinges on the autoregressive mechanism, sequentially generating text and making token-level decisions from left-to-right $[6,7]$.</p>
<p>The recently conceptualized Tree of Thoughts (ToT) [8] made significant strides in enabling LLMs to exercise foresight and backtrack for holistic decision-making. Yet, an apparent blind spot has been the oversight of local uncertainties in the intermediate [9]. These uncertainties, stemming from LLMs' propensity for varied responses [10], pose a considerable challenge to the reasoning process.</p>
<p>One fundamental obstacle is the monumental scale of LLMs, rendering them impervious to fine-tuning. They pre-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>dominantly serve as black boxes, with the Bayesian modification to obtain a distribution-based uncertainty qualification (UQ) being far from practical [11]. However, the LLMs with emergent abilities can be perceived as approximately unbiased estimations of our inherently uncertain reality [12]. This makes them less susceptible to the influence of the out-of-domain data on uncertainty estimation, allowing inference approximation of low training-complexity to work. Hence, the complexity caused by vast scale and the fascinating nature associated with it advocate a direct and effective mechanism for dealing with uncertainty.</p>
<p>Our novel solution comes in the form of the Tree of Uncertain Thoughts (TouT), a pioneering reasoning framework expressly crafted for LLMs. Central to TouT is its ingenious employment of Monte Carlo Dropout [13] for uncertainty qualification. This decision was not arbitrary. Given the challenges with LLMs, Monte Carlo Dropout presents an elegant, minimalistic, yet robust technique to gauge uncertainty scores linked with the diverse responses of LLMs at intermediate junctures. By integrating this local uncertainty measurement with comprehensive sorting algorithms, TouT bolsters the accuracy of model responses.</p>
<p>To validate our method, we undertook rigorous experimentation on two intricate planning tasks: Game of 24 and Mini Crosswords. The experimental results decisively highlight the supremacy of TouT over both ToT and the chain-ofthought prompting techniques.</p>
<p>Our pivotal contributions encapsulate:</p>
<ul>
<li>The inception of TouT, a groundbreaking Tree of Uncertain Thoughts framework, ushering in uncertaintyaware inference in LLMs.</li>
<li>The innovative integration of Monte Carlo Dropout for local uncertainty quantification and sorting, amplifying model response confidence.</li>
<li>Thorough experimental validation confirming TouT's dominance over the extant ToT and chain-of-thought prompting standards.</li>
</ul>
<h2>2. RELATED WORK</h2>
<p>Large Language Models. The advent and progression of Large Language Models (LLMs) [1, 2, 3, 14] have been transformative for the fields of natural language processing and machine learning. Central to this transformation is the</p>
<p>GPT series, which was spearheaded by Radford et al. [1]. Their seminal work led to the development of subsequent iterations, each building upon the strengths and addressing the challenges of the previous versions. While the early GPT models [2, 3] laid the foundation, GPT-4 [4] marked a paradigm shift in the capabilities and applications of LLMs. It showcased enhanced reasoning, comprehension, and generation abilities, bridging gaps previously identified in LLMs. Parallelly, models like LLaMA-2 [5] have also contributed significantly to the domain. LLaMA-2, in particular, emphasized the intersection of linguistic properties with the deep learning capabilities of LLMs, opening new avenues for research and application. In this work, our main focus is to propose an innovative thoughts reasoning framework tailored for LLaMA-2, aiming to unravel complex deliberative challenges.
Thoughts Reasoning. With the sophistication of LLMs, there arose a need to understand, modulate, and enhance the reasoning capabilities underlying their decision-making processes. The initial Input-Output models established a basic framework for how models perceive and respond to given prompts. Building on this, the Chain of Thoughts (CoT) [6] model was introduced, emphasizing a chained, sequential approach to decision-making. It was further refined with CoT-SC [7], which provided a more structured and systematic framework for thoughts sequencing. More recently, ToT [8] incorporated both a hierarchical and lateral understanding of reasoning, enabling LLMs to not only draw from a depth of knowledge but also to assess and reassess decisions in a tree-like structure. This approach facilitated greater foresight, backtracking, and holistic decision-making in LLMs. Yet, a noticeable gap persisted: the oversight of local uncertainties during intermediate decision-making. Addressing this, our work pioneers a framework that synergizes local uncertainty quantification with advanced global algorithms, intending to heighten the accuracy of LLM responses.
Uncertainty Quantification. The prediction of uncertainty $[13,15]$ represents the foundation for dependable and consistent automated decision-making, and consequently is receiving increasing attention. However, obtaining uncertainty quantification in LLM is very challenging, mainly due to the extremely high dimensionality [16]. Certain recent methodologies explore the issue of uncertainty quantification with black-box LLMs [10, 11]. However, these techniques concentrate mostly on free-form question answering. Scant research has explored the uncertainty quantification for LLMs in complex reasoning, the emphasis of the present paper.</p>
<h2>3. METHOD</h2>
<p>Given a deliberate problem with several intermediate steps, our target is to leverage pre-trained large language models for problem-solving and decision-making. We propose a novel framework with the Tree of Uncertain Thoughts, named TouT,
for language model inference, which mainly consists of two modules, Local Uncertainty Quantification in Section 3.2 and Uncertainty Global Search in Section 3.3.</p>
<h3>3.1. Preliminaries</h3>
<p>In this section, we first describe the problem setup and notations and then revisit the tree of thoughts reasoning for LLMs inference.
Problem Setup and Notations. Given a pre-trained language model (LM) ( $p_{\theta}$ ) with parameters $\theta$ and a language sequence ${x, y, z, s, \ldots}$, our target is to infer $\operatorname{LM}\left(p_{\theta}(x)\right)$ for generating answers to a deliberate problem. For each language sequence $x$ with $t$ tokens, we denote $x={x[1], x[2], \ldots, x[t]}$.
Revisit Non-Tree-Based Prompting. To address the task, Input-output (IO) prompting generated the output $y$ from LM with $x$ as input instructions, which can be denoted as $y \sim$ $p_{\theta}^{\mathrm{IN}}(y \mid x)$. When it comes to non-trivial questions with multiple steps, Chain-of-thought (CoT) prompting [6] introduced a chain of $n$ thoughts $z_{1}, z_{2}, \ldots, z_{n}$ to solve the problem, where the output is formulated as $y \sim p_{\theta}^{\mathrm{COT}}\left(y \mid x, z_{1}, z_{2}, \ldots, z_{n}\right)$. To improve COT further, ensemble-based CoT-SC [7] proposed to generate multiple chains of thoughts and select the highest frequency output.
Revisit Tree-of-Thoughts. To solve the problem in a human problem-solving manner, ToT [8] proposed to search over a tree consisting of multiple partial solutions (state $s=$ $\left.\left{x, z_{1,2, \ldots, i}\right}\right)$ as nodes. Given the properties of different problems, ToT first decomposed intermediate thought steps and used a thought generator $G\left(p_{\theta}, s, k\right)$ to generate $k$ candidates based on a tree state $s$. With a set $S$ of different states, they adopted a state evaluator $V\left(p_{\theta}, S\right)$ to independently measure the possibility of solving the problem for each state. Finally, they plugged a search algorithm to select the most promising state for the final output.</p>
<p>However, the ToT reasoning paradigm grapples with the complexities of local uncertainties at intermediate "thoughts". Given the innate capacity of LLMs to generate a spectrum of responses, these local uncertainties can become significant impediments in the reasoning process. We introduce the "Tree of Uncertain Thoughts" framework to address this challenge, pioneering a shift towards uncertainty-aware inference within LLMs.</p>
<h3>3.2. Local Uncertainty Quantification</h3>
<p>To explicitly quantify the uncertainty for each local response in intermediate steps, we introduce a novel uncertainty evaluator $U\left(p_{\theta}, S_{1,2, \ldots, m}\right)$ to generate a scalar value to represent the confidence score for each local intermediate states, that is, $U\left(p_{\theta}, S\right)(s) \sim p^{\text {uncertain }}(u \mid s), \forall s \in S$. Specifically, we are inspired by Monte Carlo Dropout [13] and generate $S_{1,2, \ldots, m}$ with $m$ sampling steps on LLMs inference. Meanwhile, we adopt an $m$-step-based linear interpolation on the input tem-</p>
<div class="codehilite"><pre><span></span><code>Algorithm 1 TouT-BFS( \(x, p_{\theta}, G, k, V, T, b, U, m\) )
Require: Input \(x\), LM \(p_{\theta}\), thought generator \(G(\cdot)\), candidates
    size \(k\), states evaluator \(V(\cdot)\), global steps \(T\), breadth limit
    \(b\), uncertainty evaluator \(U(\cdot)\), sampling steps \(m\).
    \(S_{0} \leftarrow\{x\}\)
    for \(t=1,2, \ldots, T\) do
        \(S_{t}^{\prime} \leftarrow\left\{[s, z] \mid s \in S_{t-1}, z_{t} \in G\left(p_{\theta}, s, k\right)\right\}\)
        \(U_{t} \leftarrow U\left(p_{\theta},\left\{S_{t}^{\prime}\right\}\right)\)
        \(V_{t} \leftarrow V\left(p_{\theta},\left\{S_{t}^{\prime}\right\}\right)\)
        \(S_{t} \leftarrow \arg \max <span class="ge">_{S \subset S_</span>{t}^{\prime},|S|=b} \sum_{s \in S} V_{t}(S) / U_{t}(S)\)
    end for
    return \(G\left(\theta, \arg \max <span class="ge">_{s \in S_</span>{T}} V_{t}(S) / U_{t}(S), 1\right)\)
</code></pre></div>

<p>perature of LLMs to control the quality of responses for each intermediate step.</p>
<p>After sampling, we compute the variance of values from a set $\left{S_{t}^{\prime}\right}$ of $m$ states in this step, where the variance of values is used as the local uncertainty score $u$ for each state. Such evaluations will enable us to comprehensively evaluate diverse local responses instead of generating candidates using one fixed model temperature. Furthermore, we can use quantified states for later global searching to find the correct answers to the problem more confidently.</p>
<h3>3.3. Uncertainty-aware Global Search</h3>
<p>Benefiting from the above uncertainty quantification on local responses, we leverage a novel and explicit uncertaintyaware global search mechanism to select a more precise state. During searching, we use $v / u$ as the final evaluation score for criteria to finalize the state with the largest score, where $v, u$ denote the value and uncertainty of the state, respectively. Based on the new criteria, we propose two search algorithms for uncertainty-aware global search.</p>
<p>One is based on Breadth-first search (BFS), TouT-BFS uses a set of the $b$ most confident states per step by selecting from $m$ states using the new score $V_{t}(S) / U_{t}(S)$, as illustrated in Algorithm 1. The other one is Depth-first search (DFS), we either explore the most confident state in global steps $T$ or use $V\left(p_{\theta},\left{s^{\prime}\right}\right)(s) \leq v_{t h}$ for a value threshold $v_{t h}$ and $U\left(p_{\theta},\left{s^{\prime}\right}\right)(s) \geq u_{t h}$ for a uncertainty threshold $u_{t h}$. For both cases, the algorithm backtracks to the parent state of $s$ with the higher value and lower uncertainty and continually finds the correct answers, as shown in Algorithm 2.</p>
<h2>4. EXPERIMENTS</h2>
<h3>4.1. Experimental setup</h3>
<p>Tasks. Game of 24 [8] contains 1,362 games with human solving levels from easy to hard, and a subset of relatively hard games indexed 901-1,000 is used for testing. The thoughts in this task are decomposed into 3 steps. Mini</p>
<div class="codehilite"><pre><span></span><code>Algorithm 2 TouT-DFS( \(s, t, p_{\theta}, G, k V, T, v_{t h}, U, u_{t h}\) )
Require: Current state \(s\), step \(t\), LM \(p_{\theta}\), thought generator
    \(G(\cdot)\), candidates size \(k\), states evaluator \(V(\cdot)\), global steps
    T, state threshold \(v_{t h}\), uncertainty evaluator \(U(\cdot)\), uncertainty threshold \(u_{t h}\).
    if \(t&gt;T\) then
        record output \(G\left(p_{\theta}, s, 1\right)\)
    end if
    for \(s^{\prime} \in G\left(p_{\theta}, s, k\right)\) do
        if \(V\left(p_{\theta},\left\{s^{\prime}\right\}\right)(s)&gt;v_{t h}\) and \(U\left(p_{\theta},\left\{s^{\prime}\right\}\right)(s)&lt;u_{t h}\)
    then
        DFS \(\left(s^{\prime}, t+1\right)\)
        end if
    end for
</code></pre></div>

<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Success Rate (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">IO prompt</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: left;">CoT prompt [6]</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: left;">CoT-SC [7]</td>
<td style="text-align: center;">7.2</td>
</tr>
<tr>
<td style="text-align: left;">ToT [8] $(b=1)$</td>
<td style="text-align: center;">37</td>
</tr>
<tr>
<td style="text-align: left;">TouT (ours, $b=1$ )</td>
<td style="text-align: center;">$\mathbf{4 2}$</td>
</tr>
<tr>
<td style="text-align: left;">ToT [8] $(b=5)$</td>
<td style="text-align: center;">56</td>
</tr>
<tr>
<td style="text-align: left;">TouT (ours, $b=5$ )</td>
<td style="text-align: center;">$\mathbf{6 5}$</td>
</tr>
</tbody>
</table>
<p>Table 1. Quantitative results of Game of 24.</p>
<p>Crosswords [8] includes 156 games of $5 \times 5$ mini crosswords. For this task, the input is the 5 horizontal clues and 5 vertical clues, and the output should be a board of 25 letters to solve the problem. This task has 5-10 intermediate steps for solving, such as h1. shown and v5. naled.
Evaluation Metrics. For Game of 24, if the output is an equation that uses the input numbers each exactly once equals 24, it is regarded as a success, such as (13-9)*(10-4)=24. We compute the average success rate of total testing games, where the Breadth-first search algorithm is used for this task. For Mini Crosswords, we follow ToT [8], and adopt three levels of success: the accuracy of letters ( 25 per game), words (10 per game), and games.
Implementation. For LLMs, we use officially released LLaMA-2-70B [5] weights. Since GPT-4 is more expensive to use, we reproduce all baseline results using the same LLM weight for a fair comparison. The number of Monte Carlo sampling steps $m$ is 20 . Our experiments are conducted on NVIDIA-A100 GPUs.</p>
<h3>4.2. Comparison to prior work</h3>
<p>In this work, we propose a novel and effective framework for deliberate problem-solving with LLMs inference. In order to demonstrate the effectiveness of the proposed TouT, we compare it to previous non-tree-based prompting $[6,7]$ and tree-of-thoughts [8] methods.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Success Rate (\%)</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Letter</td>
<td>Word</td>
<td>Game</td>
</tr>
<tr>
<td>IO prompt</td>
<td>29.5</td>
<td>10</td>
<td>0</td>
</tr>
<tr>
<td>CoT prompt [6]</td>
<td>33.2</td>
<td>10.8</td>
<td>0</td>
</tr>
<tr>
<td>ToT [8]</td>
<td>59</td>
<td>48</td>
<td>12</td>
</tr>
<tr>
<td>TouT (ours)</td>
<td>61</td>
<td>52</td>
<td>15</td>
</tr>
<tr>
<td>ToT [8] + best state</td>
<td>62.2</td>
<td>53.9</td>
<td>21</td>
</tr>
<tr>
<td>TouT (ours) + best state</td>
<td>64.5</td>
<td>58.2</td>
<td>29</td>
</tr>
</tbody>
</table>
<p>Table 2. Quantitative results of Mini Crosswords.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">LUQ</th>
<th style="text-align: center;">UGS</th>
<th style="text-align: center;">Game of 24</th>
<th style="text-align: center;">Mini Crosswords</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Letter</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Game</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">56</td>
<td style="text-align: center;">61</td>
<td style="text-align: center;">52</td>
<td style="text-align: center;">15</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">62</td>
<td style="text-align: center;">55.6</td>
<td style="text-align: center;">21</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">61</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">23</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">64.5</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">29</td>
</tr>
</tbody>
</table>
<p>Table 3. Ablation study on Local Uncertainty Quantification (LUQ) and Uncertainty-aware Global Search (UGS).</p>
<p>For the Game of 24 task, we report the quantitative comparison results in Table 1. As can be seen, we achieve the best results regarding both $b=1$ and $b=5$ for solving the Game of 24 problem. In particular, the proposed TouT superiorly outperforms ToT [8], the current state-of-the-art LLM inference baseline, by $5 \%$ and $9 \%$. Furthermore, we achieve significant performance gains compared to previous non-treebased prompting approaches [6, 7]. These significant improvements demonstrate the superiority of our approach in deliberate problem-solving with LLMs inference.</p>
<p>In addition, In addition, significant gains in the Mini Crosswords task can be observed in Table 2. Compared to ToT [8], we achieve the results gains of $2 \%, 4 \%$, and $3 \%$ on letter, word and game. We also achieve highly better results against IO and CoT prompting baselines. These results demonstrate the effectiveness of our approach in using LLMs inference for solving problems.</p>
<h3>4.3. Experimental analysis</h3>
<p>In this section, we performed ablation studies to demonstrate the benefit of introducing the Local Uncertainty Quantification and Uncertainty-aware Global Search modules. We also conducted extensive experiments to explore the impact of Monte Carlo sampling steps in uncertainty quantification.
Local Uncertainty Quantification \&amp; Uncertainty-aware Global Search. In order to demonstrate the effectiveness of the introduced Local Uncertainty Quantification (LUQ) and Uncertainty-aware Global Search (UGS), we ablate the necessity of each module and report the quantitative results in Table 3. As can be observed, adding LUQ to the vanilla baseline highly increases the results of $4 \%, 2 \%, 3.6 \%$, and</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Steps</th>
<th style="text-align: center;">Game of 24</th>
<th style="text-align: center;">Mini Crosswords</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Letter</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Game</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">61</td>
<td style="text-align: center;">62.7</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">22</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">56.8</td>
<td style="text-align: center;">25</td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">64.5</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">29</td>
</tr>
<tr>
<td style="text-align: center;">50</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">58.1</td>
<td style="text-align: center;">29</td>
</tr>
<tr>
<td style="text-align: center;">100</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">63.9</td>
<td style="text-align: center;">57.8</td>
<td style="text-align: center;">28</td>
</tr>
</tbody>
</table>
<p>Table 4. Exploration studies on the Monte Carlo sampling steps in Local Uncertainty Quantification.
$6 \%$, which validates the benefit of LUQ in quantifying the uncertainty for each local response in intermediate steps. Meanwhile, introducing only UGS in the baseline increases the performance regarding all metrics. More importantly, incorporating LUQ and UGS into the baseline significantly raises the performance, and achieves the best. These improving results validate the importance of local uncertainty quantification and uncertainty-aware global search in deliberate problem-solving with LLMs inference.
Impact of Monte Carlo sampling steps. The number of Monte Carlo sampling steps used in the proposed LUQ affects the selected state in global searching for the final answer. To explore such effects more comprehensively, we varied the number of sampling steps from ${5,10,20,50,100}$. We report the comparison results of Game of 24 and Mini Crosswords in Table 4. When the number of Monte Carlo sampling steps is 20 , we achieve the best performance regarding all metrics. With increased depth from 5 to 20, the proposed TouT consistently increases performance as best states are extracted from more quantified local responses. Nevertheless, increasing the steps from 20 to 100 will not continually improve the results since 20 steps might be enough to extract the best state from these quantified states for addressing our deliberate problems with at most 10 intermediate thoughts.</p>
<h2>5. CONCLUSION</h2>
<p>In this work, we present TouT, a novel framework with the Tree of Uncertain Thoughts for large-scale language model inference. We leverage Monte Carlo Dropout for local uncertainty quantification on diverse responses at intermediate steps. Furthermore, we integrate local uncertainty into global sorting to amplify model response confidence. Experimental results on Game of 24 and Mini Crosswords comprehensively demonstrate the state-of-the-art superiority against previous ToT and CoT prompting methods. Extensive ablation studies also validate the importance of local uncertainty quantification and Local Uncertainty Sorting in generating more accurate answers for LLMs inference to solve deliberate problems.</p>
<h2>6. REFERENCES</h2>
<p>[1] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever, "Improving language understanding by generative pre-training," OpenAI blog, 2018.
[2] Alec Radford, Rewon Child Jeffrey Wu, David Luan, Dario Amodei, and Ilya Sutskever, "Language models are unsupervised multitask learners," OpenAI blog, 2019.
[3] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei, "Language models are few-shot learners," NeurIPS, vol. 33, pp. 1877-1901, 2020.
[4] OpenAI, "Gpt-4 technical report," arXiv preprint arXiv:2303.08774, 2023.
[5] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom, "Llama 2: Open foundation and fine-tuned chat models," arXiv preprint arXiv:2307.09288, 2023.
[6] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and Denny Zhou, "Chain of thought prompting elicits reasoning in large language models," arXiv preprint arXiv:2201.11903, 2022.
[7] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai hsin Chi, and Denny Zhou, "Self-consistency improves chain of thought reasoning in language models," arXiv preprint arXiv:2203.11171, 2022.
[8] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan, "Tree of Thoughts: Deliberate problem solving with large language models," arXiv preprint arXiv:2305.10601, 2023.
[9] Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Lee Boyd-Graber, and Lijuan Wang, "Prompting gpt-3 to be reliable," in $I C L R$, 2022.
[10] Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar, "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation," $I C L R$, vol. abs/2302.09664, 2023.
[11] Zhen Lin, Shubhendu Trivedi, and Jimeng Sun, "Generating with confidence: Uncertainty quantification for black-box large language models," ArXiv, vol. abs/2305.19187, 2023.
[12] Stephanie C. Lin, Jacob Hilton, and Owain Evans, "Teaching models to express their uncertainty in words," $T M L R$, vol. 2022, 2022.
[13] Yarin Gal and Zoubin Ghahramani, "Dropout as a bayesian approximation: Representing model uncertainty in deep learning," in ICML, 2015.
[14] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer, "Opt: Open pretrained transformer language models," arXiv preprint arXiv:2205.01068, 2022.
[15] Andrew Foong, David Burt, Yingzhen Li, and Richard Turner, "On the expressiveness of approximate inference in bayesian neural networks," NeurIPS, vol. 33, pp. 15897-15908, 2020.
[16] Yuxin Xiao, Paul Pu Liang, Umang Bhatt, Willie Neiswanger, Ruslan Salakhutdinov, and Louis-Philippe Morency, "Uncertainty quantification with pre-trained language models: A large-scale empirical analysis," in EMNLP, 2022.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ul>
<li>Corresponding author.</li>
</ul>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>