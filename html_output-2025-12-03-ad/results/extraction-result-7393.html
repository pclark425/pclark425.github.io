<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7393 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7393</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7393</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-275789826</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2501.11960v2.pdf" target="_blank">TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks. Despite the growing adoption of embedding-based methods, their effectiveness and generalizability across diverse application scenarios remain under-explored. To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection. TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms. Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks. These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7393.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7393.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>O-ada</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>text-embedding-ada-002 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI embedding model used to produce dense sentence embeddings (1536-dim reported) which are fed to classical anomaly detectors for text anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-embedding-ada-002 (O-ada)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI proprietary embedding model (task-specific embedding API producing fixed-size dense vectors).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based anomaly detection: compute dense embeddings for text then apply classical unsupervised anomaly detectors (kNN, INNE, ECOD, OCSVM, iForest, LOF, HBOS, COPOD) on embedding vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC (Area Under ROC)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported strong and consistent performance across datasets; examples from paper: O-ada + ECOD achieved AUROC 0.8822 on SMS-Spam; O-ada + kNN achieved AUROC 0.7921 on LIAR2. Overall OpenAI embeddings were described as the most robust across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against other embedding models (BERT, MiniLM, Llama, stella, Qwen) and anomaly detectors (kNN, OCSVM, iForest, LOF, HBOS, INNE, ECOD, COPOD). kNN, INNE and ECOD often ranked highest when using OpenAI embeddings; LOF, COPOD, iForest tended to rank lower.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning; detectors run with default hyperparameters and with separate hyperparameter search)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>While OpenAI embeddings performed well on spam and some fake-news datasets, performance still degrades on context-dependent tasks like hate/offensive language where AUROC rarely exceeded ~0.6.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>OpenAI embeddings were noted as relatively slow compared to lightweight models (embedding time reported as higher; exact seconds per dataset reported in Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7393.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>O-small</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>text-embedding-3-small (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A smaller OpenAI embedding variant (document embedding) used to produce dense representations for downstream anomaly detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-embedding-3-small (O-small)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI embedding model (smaller embedding variant), produces fixed-size dense embeddings for sentences/documents.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based anomaly detection (extract embeddings, apply classical unsupervised AD algorithms).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported high performance on several tasks; examples: O-small + kNN achieved AUROC 0.6416 on Hate Speech and 0.5587 on OLID (these are detector-specific results reported in the paper). O-small also achieves very high AUROC on spam/fake-news in specific detector pairings (see paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to other embeddings and detectors; kNN, INNE and ECOD are competitive baselines; OpenAI models generally outperform other embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same as other embeddings: weaker on offensive/hate-speech detection, variable performance on fact-checking datasets requiring external knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported to be slower than MiniLM but faster than large autoregressive models; specific embedding times reported in Table 3.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7393.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>O-large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>text-embedding-3-large (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Largest OpenAI embedding variant used in the benchmark, producing higher-dimensional embeddings used with classical anomaly detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-embedding-3-large (O-large)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI large embedding model producing higher-dimensional vectors (reported 3072-dim in paper's model table).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based anomaly detection (extract embeddings, apply detectors).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Strong results on spam/fake-news: e.g., O-large + COPOD achieved AUROC 0.9639 on Email-Spam, and O-large + kNN achieved AUROC 0.9537 on COVID-Fake (reported in paper). Overall competitive but varying by detector/dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperformed many other embeddings in average robustness; compared across kNN, INNE, ECOD, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High-dimensional embeddings can be more expensive to compute and still fail on context-dependent tasks (hate/offensive language).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported as relatively slow; O-large has larger embedding dimensionality which increased runtime (embedding time reported in Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7393.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MINILM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>all-MiniLM-L6-v2 (MiniLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A small, efficient transformer-based encoder producing sentence embeddings used in the benchmark; noted for fast embedding extraction and strong performance on explicit-pattern tasks like spam.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>all-MiniLM-L6-v2 (MiniLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Lightweight encoder transformer distilled for compact sentence embeddings (task-agnostic distilled model).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>22.7M</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based anomaly detection: extract MiniLM embeddings then apply unsupervised detectors (kNN, INNE, OCSVM, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Exceptional on spam: paper reports MiniLM + INNE AUROC 0.9526 and MiniLM + OCSVM AUROC 0.9626 on the Email-Spam dataset; performance degrades on OLID and LIAR2 (contextual tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to larger embeddings (OpenAI, BERT, Llama, Qwen); MiniLM is fastest and competitive on explicit-pattern tasks, but less consistent on nuanced datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Strong on explicit linguistic patterns (spam) but significantly worse on context-dependent tasks (hate/offensive language, complex fact-checking).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Fastest embedding extraction across datasets (few seconds reported); recommended where inference speed is critical.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7393.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>bert-base-uncased (BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bidirectional transformer encoder used to produce contextual embeddings which are averaged / pooled and used by classical anomaly detectors in the benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>bert-base-uncased (BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Bidirectional transformer encoder (encoder-only) pretrained on masked language modeling; standard contextual embedding model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>110M</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based anomaly detection using pooled BERT representations fed to detectors like kNN, OCSVM, INNE, ECOD, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Mixed: BERT showed weaker separation in embedding space on several datasets (t-SNE visualizations) and produced lower AUROC on some tasks compared to other embeddings; specific per-detector numbers are in Table 2 of the paper (example kNN average AUROC reported ~0.6223 for BERT+kNN across datasets in the table).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against MiniLM, OpenAI embeddings, Llama, Qwen, stella; generally outperformed by OpenAI embeddings and MiniLM on explicit-pattern spam tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>BERT embeddings sometimes overlapped anomalous and normal instances (poorer separation), leading to lower anomaly detection performance on several datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Moderate embedding time (slower than MiniLM but faster than large autoregressive models); reported timings in Table 3.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7393.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-3.2-1B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Auto-regressive LLM repurposed by the authors to produce sentence embeddings via attention-weighted mean pooling of last hidden states and then used with classical anomaly detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-3.2-1B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive large language model (decoder-only) repurposed for embedding extraction by pooling hidden states.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.24B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding extraction from last hidden states (attention-weighted mean) followed by classical unsupervised anomaly detectors applied to embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Competitive on some datasets but inconsistent; specific detector-dataset AUROC values reported in paper tables (e.g., several combinations yield AUROC in 0.6â€“0.9 depending on dataset). Paper notes Llama required truncation to 512 tokens due to resource limits which may affect performance on long texts.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with other embeddings; INNE improved after hyperparameter tuning with Llama embeddings, indicating complementarity between isolation-based detectors and Llama embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Truncated to 512 tokens in experiments (resource constraint), limiting use of longer context; inconsistent performance on nuanced datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>High computational cost relative to small encoders; Llama inference time reported higher than MiniLM/BERT (timings in Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7393.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2.5-1.5B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Autoregressive Qwen family model repurposed for embedding extraction (attention-weighted pooling of last hidden states) and used with classical anomaly detectors in the benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-1.5B (Qwen)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive large language model (decoder-only) repurposed for embeddings by pooling hidden states.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.54B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based anomaly detection: pooled Qwen embeddings fed to kNN, INNE, ECOD, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Moderate: Qwen achieved competitive AUROC on several tasks but had high computational cost; per-detector AUROC values listed in paper tables (varying widely by detector and dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with BERT, MiniLM, OpenAI embeddings; often outperformed by OpenAI models and MiniLM on several datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High computational cost (paper reports Qwen taking up to 745.85 seconds on Email-Spam embedding extraction), and inconsistent detection performance on nuanced datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Very high embedding time reported (e.g., up to 745.85s on Email-Spam in Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7393.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7393.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>stella</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>stella_en_400M_v5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mid-sized embedding model (stella) used to extract embeddings (pooled) which were evaluated with classical anomaly detectors in the benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>stella_en_400M_v5 (stella)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mid-sized transformer-based embedding model (encoder) designed for high-quality sentence embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>400M</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding extraction followed by classical unsupervised anomaly detectors (kNN, INNE, ECOD, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text (emails, SMS, social posts, fact-checked statements, tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Moderate performance, better on some datasets after hyperparameter tuning with isolation-based detectors; specific AUROC numbers per detector/dataset in paper tables.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with MiniLM, BERT, OpenAI embeddings, Llama, Qwen; performance inconsistent but competitive in some pairings.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>unsupervised embedding-based (no fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Inconsistent across datasets; required hyperparameter tuning for some detectors to reach competitive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Moderate; slower than MiniLM, faster than large autoregressive models (reported in Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Ad-nlp: A benchmark for anomaly detection in natural language processing <em>(Rating: 2)</em></li>
                <li>Nlpadbench: Nlp anomaly detection benchmark <em>(Rating: 2)</em></li>
                <li>Ad-llm: Benchmarking large language models for anomaly detection <em>(Rating: 2)</em></li>
                <li>Isolation-based anomaly detection using nearest-neighbor ensembles <em>(Rating: 1)</em></li>
                <li>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7393",
    "paper_id": "paper-275789826",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "O-ada",
            "name_full": "text-embedding-ada-002 (OpenAI)",
            "brief_description": "OpenAI embedding model used to produce dense sentence embeddings (1536-dim reported) which are fed to classical anomaly detectors for text anomaly detection.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "text-embedding-ada-002 (O-ada)",
            "model_description": "OpenAI proprietary embedding model (task-specific embedding API producing fixed-size dense vectors).",
            "model_size": null,
            "anomaly_detection_approach": "Embedding-based anomaly detection: compute dense embeddings for text then apply classical unsupervised anomaly detectors (kNN, INNE, ECOD, OCSVM, iForest, LOF, HBOS, COPOD) on embedding vectors.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC (Area Under ROC)",
            "performance": "Reported strong and consistent performance across datasets; examples from paper: O-ada + ECOD achieved AUROC 0.8822 on SMS-Spam; O-ada + kNN achieved AUROC 0.7921 on LIAR2. Overall OpenAI embeddings were described as the most robust across tasks.",
            "baseline_comparison": "Compared against other embedding models (BERT, MiniLM, Llama, stella, Qwen) and anomaly detectors (kNN, OCSVM, iForest, LOF, HBOS, INNE, ECOD, COPOD). kNN, INNE and ECOD often ranked highest when using OpenAI embeddings; LOF, COPOD, iForest tended to rank lower.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning; detectors run with default hyperparameters and with separate hyperparameter search)",
            "limitations_or_failure_cases": "While OpenAI embeddings performed well on spam and some fake-news datasets, performance still degrades on context-dependent tasks like hate/offensive language where AUROC rarely exceeded ~0.6.",
            "computational_cost": "OpenAI embeddings were noted as relatively slow compared to lightweight models (embedding time reported as higher; exact seconds per dataset reported in Table 3).",
            "uuid": "e7393.0",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "O-small",
            "name_full": "text-embedding-3-small (OpenAI)",
            "brief_description": "A smaller OpenAI embedding variant (document embedding) used to produce dense representations for downstream anomaly detectors.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "text-embedding-3-small (O-small)",
            "model_description": "OpenAI embedding model (smaller embedding variant), produces fixed-size dense embeddings for sentences/documents.",
            "model_size": null,
            "anomaly_detection_approach": "Embedding-based anomaly detection (extract embeddings, apply classical unsupervised AD algorithms).",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Reported high performance on several tasks; examples: O-small + kNN achieved AUROC 0.6416 on Hate Speech and 0.5587 on OLID (these are detector-specific results reported in the paper). O-small also achieves very high AUROC on spam/fake-news in specific detector pairings (see paper tables).",
            "baseline_comparison": "Compared to other embeddings and detectors; kNN, INNE and ECOD are competitive baselines; OpenAI models generally outperform other embeddings.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "Same as other embeddings: weaker on offensive/hate-speech detection, variable performance on fact-checking datasets requiring external knowledge.",
            "computational_cost": "Reported to be slower than MiniLM but faster than large autoregressive models; specific embedding times reported in Table 3.",
            "uuid": "e7393.1",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "O-large",
            "name_full": "text-embedding-3-large (OpenAI)",
            "brief_description": "Largest OpenAI embedding variant used in the benchmark, producing higher-dimensional embeddings used with classical anomaly detectors.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "text-embedding-3-large (O-large)",
            "model_description": "OpenAI large embedding model producing higher-dimensional vectors (reported 3072-dim in paper's model table).",
            "model_size": null,
            "anomaly_detection_approach": "Embedding-based anomaly detection (extract embeddings, apply detectors).",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Strong results on spam/fake-news: e.g., O-large + COPOD achieved AUROC 0.9639 on Email-Spam, and O-large + kNN achieved AUROC 0.9537 on COVID-Fake (reported in paper). Overall competitive but varying by detector/dataset.",
            "baseline_comparison": "Outperformed many other embeddings in average robustness; compared across kNN, INNE, ECOD, etc.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "High-dimensional embeddings can be more expensive to compute and still fail on context-dependent tasks (hate/offensive language).",
            "computational_cost": "Reported as relatively slow; O-large has larger embedding dimensionality which increased runtime (embedding time reported in Table 3).",
            "uuid": "e7393.2",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "MINILM",
            "name_full": "all-MiniLM-L6-v2 (MiniLM)",
            "brief_description": "A small, efficient transformer-based encoder producing sentence embeddings used in the benchmark; noted for fast embedding extraction and strong performance on explicit-pattern tasks like spam.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "all-MiniLM-L6-v2 (MiniLM)",
            "model_description": "Lightweight encoder transformer distilled for compact sentence embeddings (task-agnostic distilled model).",
            "model_size": "22.7M",
            "anomaly_detection_approach": "Embedding-based anomaly detection: extract MiniLM embeddings then apply unsupervised detectors (kNN, INNE, OCSVM, etc.).",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Exceptional on spam: paper reports MiniLM + INNE AUROC 0.9526 and MiniLM + OCSVM AUROC 0.9626 on the Email-Spam dataset; performance degrades on OLID and LIAR2 (contextual tasks).",
            "baseline_comparison": "Compared to larger embeddings (OpenAI, BERT, Llama, Qwen); MiniLM is fastest and competitive on explicit-pattern tasks, but less consistent on nuanced datasets.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "Strong on explicit linguistic patterns (spam) but significantly worse on context-dependent tasks (hate/offensive language, complex fact-checking).",
            "computational_cost": "Fastest embedding extraction across datasets (few seconds reported); recommended where inference speed is critical.",
            "uuid": "e7393.3",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "BERT",
            "name_full": "bert-base-uncased (BERT)",
            "brief_description": "Bidirectional transformer encoder used to produce contextual embeddings which are averaged / pooled and used by classical anomaly detectors in the benchmark.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "bert-base-uncased (BERT)",
            "model_description": "Bidirectional transformer encoder (encoder-only) pretrained on masked language modeling; standard contextual embedding model.",
            "model_size": "110M",
            "anomaly_detection_approach": "Embedding-based anomaly detection using pooled BERT representations fed to detectors like kNN, OCSVM, INNE, ECOD, etc.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Mixed: BERT showed weaker separation in embedding space on several datasets (t-SNE visualizations) and produced lower AUROC on some tasks compared to other embeddings; specific per-detector numbers are in Table 2 of the paper (example kNN average AUROC reported ~0.6223 for BERT+kNN across datasets in the table).",
            "baseline_comparison": "Compared against MiniLM, OpenAI embeddings, Llama, Qwen, stella; generally outperformed by OpenAI embeddings and MiniLM on explicit-pattern spam tasks.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "BERT embeddings sometimes overlapped anomalous and normal instances (poorer separation), leading to lower anomaly detection performance on several datasets.",
            "computational_cost": "Moderate embedding time (slower than MiniLM but faster than large autoregressive models); reported timings in Table 3.",
            "uuid": "e7393.4",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Llama",
            "name_full": "Llama-3.2-1B",
            "brief_description": "Auto-regressive LLM repurposed by the authors to produce sentence embeddings via attention-weighted mean pooling of last hidden states and then used with classical anomaly detectors.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "Llama-3.2-1B",
            "model_description": "Autoregressive large language model (decoder-only) repurposed for embedding extraction by pooling hidden states.",
            "model_size": "1.24B",
            "anomaly_detection_approach": "Embedding extraction from last hidden states (attention-weighted mean) followed by classical unsupervised anomaly detectors applied to embeddings.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Competitive on some datasets but inconsistent; specific detector-dataset AUROC values reported in paper tables (e.g., several combinations yield AUROC in 0.6â€“0.9 depending on dataset). Paper notes Llama required truncation to 512 tokens due to resource limits which may affect performance on long texts.",
            "baseline_comparison": "Compared with other embeddings; INNE improved after hyperparameter tuning with Llama embeddings, indicating complementarity between isolation-based detectors and Llama embeddings.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "Truncated to 512 tokens in experiments (resource constraint), limiting use of longer context; inconsistent performance on nuanced datasets.",
            "computational_cost": "High computational cost relative to small encoders; Llama inference time reported higher than MiniLM/BERT (timings in Table 3).",
            "uuid": "e7393.5",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Qwen",
            "name_full": "Qwen2.5-1.5B",
            "brief_description": "Autoregressive Qwen family model repurposed for embedding extraction (attention-weighted pooling of last hidden states) and used with classical anomaly detectors in the benchmark.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "Qwen2.5-1.5B (Qwen)",
            "model_description": "Autoregressive large language model (decoder-only) repurposed for embeddings by pooling hidden states.",
            "model_size": "1.54B",
            "anomaly_detection_approach": "Embedding-based anomaly detection: pooled Qwen embeddings fed to kNN, INNE, ECOD, etc.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Moderate: Qwen achieved competitive AUROC on several tasks but had high computational cost; per-detector AUROC values listed in paper tables (varying widely by detector and dataset).",
            "baseline_comparison": "Compared with BERT, MiniLM, OpenAI embeddings; often outperformed by OpenAI models and MiniLM on several datasets.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "High computational cost (paper reports Qwen taking up to 745.85 seconds on Email-Spam embedding extraction), and inconsistent detection performance on nuanced datasets.",
            "computational_cost": "Very high embedding time reported (e.g., up to 745.85s on Email-Spam in Table 3).",
            "uuid": "e7393.6",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "stella",
            "name_full": "stella_en_400M_v5",
            "brief_description": "A mid-sized embedding model (stella) used to extract embeddings (pooled) which were evaluated with classical anomaly detectors in the benchmark.",
            "citation_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "stella_en_400M_v5 (stella)",
            "model_description": "Mid-sized transformer-based embedding model (encoder) designed for high-quality sentence embeddings.",
            "model_size": "400M",
            "anomaly_detection_approach": "Embedding extraction followed by classical unsupervised anomaly detectors (kNN, INNE, ECOD, etc.).",
            "prompt_template": null,
            "training_data": null,
            "data_type": "text (emails, SMS, social posts, fact-checked statements, tweets)",
            "dataset_name": "Email-Spam, SMS-Spam, COVID-Fake, LIAR2, OLID, Hate-Speech",
            "evaluation_metric": "AUROC",
            "performance": "Moderate performance, better on some datasets after hyperparameter tuning with isolation-based detectors; specific AUROC numbers per detector/dataset in paper tables.",
            "baseline_comparison": "Compared with MiniLM, BERT, OpenAI embeddings, Llama, Qwen; performance inconsistent but competitive in some pairings.",
            "zero_shot_or_few_shot": "unsupervised embedding-based (no fine-tuning)",
            "limitations_or_failure_cases": "Inconsistent across datasets; required hyperparameter tuning for some detectors to reach competitive performance.",
            "computational_cost": "Moderate; slower than MiniLM, faster than large autoregressive models (reported in Table 3).",
            "uuid": "e7393.7",
            "source_info": {
                "paper_title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
                "publication_date_yy_mm": "2025-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Ad-nlp: A benchmark for anomaly detection in natural language processing",
            "rating": 2,
            "sanitized_title": "adnlp_a_benchmark_for_anomaly_detection_in_natural_language_processing"
        },
        {
            "paper_title": "Nlpadbench: Nlp anomaly detection benchmark",
            "rating": 2,
            "sanitized_title": "nlpadbench_nlp_anomaly_detection_benchmark"
        },
        {
            "paper_title": "Ad-llm: Benchmarking large language models for anomaly detection",
            "rating": 2,
            "sanitized_title": "adllm_benchmarking_large_language_models_for_anomaly_detection"
        },
        {
            "paper_title": "Isolation-based anomaly detection using nearest-neighbor ensembles",
            "rating": 1,
            "sanitized_title": "isolationbased_anomaly_detection_using_nearestneighbor_ensembles"
        },
        {
            "paper_title": "Ecod: Unsupervised outlier detection using empirical cumulative distribution functions",
            "rating": 1,
            "sanitized_title": "ecod_unsupervised_outlier_detection_using_empirical_cumulative_distribution_functions"
        }
    ],
    "cost": 0.016256,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</p>
<p>Yang Cao 
School of Computing and Information Technology
Great Bay University
China</p>
<p>Great Bay Institute for Advanced Study
Great Bay University
China</p>
<p>Tsinghua Shenzhen International Graduate School
Tsinghua University
China</p>
<p>Sikun Yang 
Chen Li 
School of Computing and Information Technology
Great Bay University
China</p>
<p>Great Bay Institute for Advanced Study
Great Bay University
China</p>
<p>D3 Center
Osaka University
Japan</p>
<p>Haolong Xiang 
School of Software
Nanjing University of Information Science and Technology
China</p>
<p>Lianyong Qi 
College of Computer Science
Technology China University of Petroleum</p>
<p>Bo Liu 
College of Cyberspace Security
Zhengzhou University
China</p>
<p>Rongsheng Li 
School of Computer
Harbin Engineering University
China</p>
<p>Ming Liu 
School of IT
Deakin University
Australia</p>
<p>East China), China</p>
<p>TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection
0D7BB3D61519F9970B37A23F2C7AABD9
Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks.Despite the growing adoption of embeddingbased methods, their effectiveness and generalizability across diverse application scenarios remain insufficiently explored.To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection.TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms.Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks.These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.All the code are available at https://anonymous.4open.science/r/TAD-Bench-B4C6/.</p>
<p>Introduction</p>
<p>Anomaly detection (AD) is a critical task in machine learning, widely applied in fraud detection and content moderation to user behavior analysis (Pang et al., 2021).Within natural language processing (NLP), anomaly detection has become increasingly relevant for identifying outliers such as harmful content, phishing attempts, and spam reviews.However, while AD tasks in structured data (e.g., tabular, time series, graphs) (Steinbuss and BÃ¶hm, 2021;BlÃ¡zquez-GarcÃ­a et al., 2021;Qiao et al., 2024) have been extensively studied, anomaly detection in the unstructured and highdimensional domain of text remains underexplored.</p>
<p>The inherent complexity of textual data, driven by its diverse syntactic, semantic, and pragmatic structures, presents significant challenges for robust and reliable anomaly detection.</p>
<p>The rise of deep learning and transformer-based models has revolutionized NLP, enabling the development of contextualized embeddings that encode rich semantic and syntactic information.Techniques such as BERT (Devlin et al., 2019) and OpenAI's text-embedding models (OpenAI, 2024) have demonstrated remarkable success across a wide range of NLP tasks, offering dense, highdimensional representations that effectively capture linguistic nuances.These embeddings have become a cornerstone for many downstream tasks, providing powerful tools for applications such as text classification (da Costa et al., 2023) and retrieval (Zhu et al., 2023).Their ability to generalize across tasks and domains positions them as a promising foundation for complex challenges, including anomaly detection.gained significant attention in anomaly detection tasks due to their ability to capture semantic and contextual nuances in data (Wang et al., 2024).These methods typically involve two key stages: 1) extracting high-dimensional representations from textual data using pre-trained language models, which encode rich contextual and semantic features.Figure 1 demonstrates the anomaly distribution of SMS_Spam dataset embedding extracted from Ope-nAI model.2) Applying specialized algorithms to identify anomalies based on these embeddings.The embeddings serve as a compact and expressive feature space, enabling downstream algorithms to efficiently identify deviations or outliers.Figure 2 shows the steps involved in embedding-based anomaly detection.</p>
<p>Recent efforts, such as AD-NLP (Bejan et al., 2023), TAD (Xu et al., 2023) and NLP-ADBench (Li et al., 2024), have significantly advanced anomaly detection in NLP.AD-NLP (Bejan et al., 2023) finds that semantic and stylistic anomalies are easier to detect than those partially dependent on text; TAD (Xu et al., 2023) shows the effectiveness of embedding-based methods on multi language applications; NLP-ADBench (Li et al., 2024) reveals that no single model performs best across all datasets and high-dimensional embeddings improve detection.However, they only use a few embedding models, none of them explore the impact of embeddings quality to anomaly detection performance and tradeoffs between embedding models and anomaly detectors, raising questions about generalization capabilities of embedding-based methods in complex, real-world scenarios.</p>
<p>Our work aims to move beyond simply filling these gaps, by systematically exploring the following questions: 1) What types of tasks are LLMs (Large Language Models) embeddings paired with anomaly detectors most suitable for, and where do they face limitations?2) Which embedding methods consistently excel across different anomaly detection tasks? 3) Which anomaly detection algorithms perform robustly across various embeddings and tasks?</p>
<p>In this work, we introduce TAD-Bench, a novel benchmark specifically designed for text anomaly detection.Our objective is to enable a more comprehensive and systematic evaluation of state-ofthe-art embeddings, anomaly detection techniques, and their various combinations, offering valuable insights for a broad spectrum of NLP applications.The main contributions of this work are summa-rized as follows:</p>
<p>â€¢ Propose TAD-Bench, a benchmark integrating diverse datasets for text anomaly detection across domains such as spam, fake news, and offensive language.</p>
<p>â€¢ Conduct a systematic evaluation of LLMbased embeddings and anomaly detection algorithms, revealing their relative strengths and weaknesses.</p>
<p>â€¢ Provide insights into effective embeddingdetector configurations for improving robustness and generalizability in NLP anomaly detection tasks.</p>
<p>The key insights of TAD-Bench have been summarized as follows: 1) The effectiveness of embedding models varies significantly by task type: they can extract meaningful embeddings on tasks with explicit patterns (e.g.email spam with gibberish text) but struggle with context-dependent anomalies (e.g.offensive language).2) Among different detection algorithms applied to various embeddings, there are significant performance differences, but with default parameters, nearestneighbor-based methods including kNN and INNE show better robustness.3) Clustering patterns in embedding spaces reveal that spam anomalies form distinct, compact clusters, whereas hate speech and offensive language anomalies are scattered among normal instances, explaining why detection performance varies across domains despite using the same embedding-detector combinations.4) On texts with explicit linguistic patterns like email spam, lightweight embedding models (MINILM) perform comparably to larger models (e.g.OpenAI, Llama), suggesting efficient model selection based on task characteristics.</p>
<p>Related Work</p>
<p>Text representations</p>
<p>Early methods like TF-IDF (Term Frequency-Inverse Document Frequency) (Salton and Buckley, 1988) represented text in sparse vector spaces by measuring word importance relative to a corpus.While interpretable and computationally efficient, TF-IDF could not capture semantic relationships between words.Later, dense embeddings such as Word2Vec (Word to Vector) (Mikolov, 2013) and GloVe (Global Vectors for Word Representation) (Pennington et al., 2014) addressed this lim- itation by mapping words into continuous vector spaces based on their co-occurrence patterns in large corpora.However, these embeddings were static, assigning the same vector to a word regardless of its context.</p>
<p>To overcome the limitations of static embeddings, contextualized embeddings were introduced, with models like ELMo (Embeddings from Language Models) (Peters et al., 2018) producing word representations that vary based on context.This innovation was further advanced by transformer-based models like BERT (Bidirectional Encoder Representations from Transformers) (Devlin et al., 2019), which used bidirectional attention mechanisms to simultaneously capture left and right context.BERT set new benchmarks in NLP and inspired numerous improvements, including RoBERTa (Robustly Optimized BERT Approach) (Zhuang et al., 2021) and ALBERT (A Lite BERT) (Lan et al., 2020).</p>
<p>More recently, large language models such as GPT (Generative Pre-trained Transformer (Brown et al., 2020) have significantly advanced the capabilities of embedding methods.These models, trained on massive and diverse datasets, generate highly expressive embeddings that capture both deep semantic relationships and rich generative properties of text.LLMs have exhibited unprecedented performance across a broad spectrum of NLP tasks, solidifying their role as dominant tools for text representation in numerous applications, including anomaly detection, information retrieval, and text generation.</p>
<p>Anomaly Detection</p>
<p>Distance-based methods, such as kNN (k-Nearest Neighbors) (Ramaswamy et al., 2000), identify anomalies by measuring the distance of a given data point to its nearest neighbors.Points that are far from their neighbors are considered anomalous.These methods are intuitive and straightforward but suffer from the curse of dimensionality in highdimensional spaces, where distances lose their discriminative power, reducing their effectiveness.</p>
<p>Density-based methods identify points with significantly lower local density compared to their surroundings as anomaly.LOF (Local Outlier Factor) (Breunig et al., 2000) measures the local density of a point relative to its neighbors.HBOS (Histogram-Based Outlier Score) (Goldstein and Dengel, 2012) estimates densities using histograms for individual features.</p>
<p>Isolation-based methods assume anomalies are rare and different, iForest (Isolation Forest) (Liu et al., 2008(Liu et al., , 2012)), detect anomalies by recursively partitioning the feature space where anomalies require fewer partitions than normal points.Improved techniques, such as iNNE (Isolation-based Nearest Neighbor Ensembles) (Bandaragoda et al., 2018), use hypersphere to partition data space and assigns larger hyperspheres to anomalies, improving robustness in detecting local anomalies.</p>
<p>Probabilistic and statistical methods identify anomalies based on deviations from the data distribution.These approaches assume that normal instances follow a certain statistical pattern, and anomalies appear as outliers that do not conform to this pattern.ECOD (Empirical Cumulative Distribution Function-based Outlier Detection) (Li et al., 2022) uses cumulative distribution functions for efficient anomaly scoring, while COPOD (Copula-Based Outlier Detection) (Li et al., 2020) leverages copulas to model feature dependencies, handling multivariate data effectively.Projection-based methods, such as OCSVM (One-Class SVM) (SchÃ¶lkopf et al., 2001), separate normal and anomalous data by learning a decision boundary in a high-dimensional feature space.(Ruff et al., 2018) and LUNAR (Unifying Local Outlier Detection Methods via Graph Neural Networks) (Goodge et al., 2022) capture nonlinear patterns but require substantial data and computational resources.</p>
<p>3 Benchmark Settings</p>
<p>Datasets</p>
<p>The scarcity of dedicated datasets poses a challenge to the development and evaluation of effective anomaly detection methods in NLP.To address this gap, we curated and transformed 6 existing classification datasets from three common NLP domains: spam detection, fake news detection, and offensive language detection.By incorporating datasets from diverse domains, our benchmark facilitates a comprehensive evaluation of embeddingbased anomaly detection methods across various NLP tasks.</p>
<p>Anomalies, as defined in our problem, are inherently rare.However, due to the lack of dedicated datasets for text anomaly detection, we adapted classification datasets by designating specific classes as anomalies and down-sampling them to simulate realistic anomaly rates (Li et al., 2024).For each dataset, the anomaly rate was set to approximately 3%, reflecting the typical rarity of anomalies in real-world scenarios.</p>
<p>While some studies treat anomaly detection as novelty detection-assuming only normal instances in training (e.g., NLP-ADBench (Li et al., 2024)).TAD-Bench removes this constraint and directly utilizes all available data for anomaly detection.Additionally, we retain the original text without extra pre-processing, as any token, word, or symbol may carry critical information indicative of an anomaly.This approach preserves linguis-tic, structural, and contextual features essential for detecting anomalies.Table 1 presents the statistics of the six pre-processed datasets used in this benchmark, including Email-Spam (Metsis et al., 2006), SMS-Spam(Almeida et al., 2011), COVID-Fake(Das et al., 2021), LIAR2 (Xu and Kechadi, 2024), OLID (Zampieri et al., 2019a), and Hate-Speech (Davidson et al., 2017).</p>
<p>Embedding Models</p>
<p>To extract high-quality embeddings from the datasets, 8 embedding models were utilized.These include BERT (bert-base-uncased) (Devlin et al., 2019), MiniLM (all-MiniLM-L6-v2) (Wang et al., 2020), LLAMA (Llama-3.2-1B),stella (stella_en_400M_v5) (Zhang et al., 2024), and Qwen (Qwen2.5-1.5B)(Yang et al., 2024a;Team, 2024) from the HuggingFace platform, as well as OpenAI-provided models: O-ada (text-embeddingada-002), O-small (text-embedding-3-small), and O-large (text-embedding-3-large) (OpenAI, 2024).All these models are based on the Transformer architecture, which has become the standard for representation learning in NLP tasks.The OpenAI models (O-ada, O-small, O-large) are specifically designed for embedding generation, offering embeddings with varying levels of granularity.On the other hand, LLAMA and Qwen are primarily auto-regressive language models optimized for text generation.In this paper, we repurposed these models for embedding extraction by computing the attention-weighted mean of their last hidden states, ensuring that only valid tokens contribute to the final sentence embeddings.</p>
<p>Notably, LLAMA and Qwen were constrained to a maximum token length of 512 tokens, same as BERT, due to computational resource limitations.Other models, such as MiniLM, Stella, and the OpenAI embeddings, utilized automatic truncation to process longer input sequences.This limitation may restrict LLAMA and Qwen's ability to fully leverage their extended context capabilities, particularly for datasets with longer text instances, such as LIAR2 and Hate-Speech.However, this unified token length ensures a fair comparison of runtime efficiency across models under consistent experimental conditions.It also highlights the trade-offs between computational cost and embedding quality, particularly when resource constraints are a factor in model deployment.</p>
<p>Anomaly Detectors</p>
<p>The embeddings derived from these models were subsequently used as input features for anomaly detection algorithms.To identify anomalous instances, we employed 8 anomaly detection methods sourced from the PyOD library1 (Zhao et al., 2019).These algorithms include KNN, LOF, OCSVM, iForest, INNE, ECOD, HBOS and COPOD .These algorithms were selected to capture diverse anomaly detection paradigms, ensuring robust detection across datasets with varying characteristics, structures, and distributions.</p>
<p>For reproducibility and consistency, we implemented all algorithms using their default hyperparameter settings as specified in their original implementations and research papers.This approach minimizes subjective bias and enables fair comparison across different embedding models.Additionally, we conducted comprehensive grid search for optimal hyperparameter configurations, with search ranges detailed in Table 4.By evaluating both default and optimized settings across our diverse collection of embedding models and detection algorithms, we provide a thorough assessment of text anomaly detection performance in terms of both computational efficiency and detection effectiveness.</p>
<p>Evaluation Criteria and Trials</p>
<p>Performance was evaluated using the Area Under the Receiver Operating Characteristic Curve (AU-ROC), a widely adopted metric in anomaly detection tasks for measuring the trade-off between true positive and false positive rates.To ensure the reliability and robustness of the results, each experiment was repeated 5 times, and the average AUROC score was reported.</p>
<p>Experiments</p>
<p>Domain Generalization</p>
<p>Table 5 summarizes the performance of various anomaly detectors combined with LLM-derived embeddings across different datasets, while Figure 1 highlights their strong performance in specific tasks, particularly spam detection.In both the email spam and SMS spam detection tasks (Figure 5a and Figure 5d, many embedding-detector combinations achieve high AUC scores, with several exceeding 0.8.This strong performance can be attributed to the explicit nature of spam-related features, such as the presence of URLs, nonsensical text, or repetitive patterns.An example Case 1 from the Email Spam dataset is shown below:</p>
<p>Case 1: Subject: oxyccontttin no script needeeed your place to ggo too for all ur prreexxxxiscrlpt 10 n pi sx , paaaaain killerzxss noeoo presscippt http : / / hyyydroccodeeeine vicccodinne / vic geeet reeeliefff noowee http : / / offfmeebabyy Figure 3 shows that case 1 is located at the edge of the embedding space and deviates from the main data distribution, thus making it easy to be detected.</p>
<p>These features are effectively represented in the semantic spaces created by general-purpose embeddings, enabling anomaly detectors to distinguish spam messages from legitimate ones.Additionally, the relatively small variance in detection performance across embeddings suggests that spam detection primarily relies on surface-level linguistic patterns, which are effectively captured by the embeddings employed in this study.</p>
<p>For fake news detection, the results indicate a more mixed performance across datasets.On the Covid Fake News dataset (Figure 5b, multiple embedding-detector combinations achieve AUC scores close to or exceeding 0.8, suggesting that these methods are capable of identifying subtle stylistic and linguistic differences between fake and real news.These differences may include deviations in tone, phrasing, or structural composition of the text.However, on the LIAR2 dataset (Figure 5e, the AUC scores exhibit much greater variability across different combinations of embeddings and detectors.This variability likely stems from the greater factual complexity of the LIAR2 dataset, where detecting anomalies may require external knowledge or sophisticated reasoning that is not inherently encoded within the embeddings.Despite this variability, the relatively strong performance on the Covid Fake News dataset underscores the potential of embedding-based approaches for fake news detection, particularly when the anomalies are stylistic or linguistic in nature.</p>
<p>In contrast, the performance on hate speech and offensive language detection tasks (Figure 5c and Figure 5f) is consistently weaker, with AUC scores rarely exceeding 0.6 across embeddingdetector combinations.This suggests that the embeddings struggle to capture the nuanced and context-dependent features necessary for these tasks.For instance, hate speech often relies on implicit cues such as sarcasm, cultural references, or subtle forms of hostility, which may not be fully captured by standard embeddings.Similarly, offensive language detection, as observed in the OLID dataset, requires identifying fine-grained differences in tone, intent, and subjectivity, such as distinguishing between neutral, offensive, and sarcastic expressions.These distinctions often depend on broader contextual information, such as the discourse or dialogue in which the language appears.For example, without additional context, such as the speaker's intent or the conversational background, the following statement from OLID dataset remains ambiguous whether this statement qualifies as hate speech:</p>
<p>Case 2: @USER #metoo are all racist! Figure 4 shows that case 2 is mixed in the normal data distribution, making it difficult to be detected.</p>
<p>Comparative Effectiveness of Embeddings in Anomaly Detection</p>
<p>The results in In comparison, other embeddings, such as MINILM, exhibit strong performance in specific tasks but lack consistency across more complex datasets.For instance, MINILM achieves exceptional AUC scores of 0.9526 and 0.9626 on the Email Spam datasets when paired with INNE and OCSVM, respectively.However, its performance declines significantly on datasets like OLID and LIAR2, suggesting limitations in capturing deeper contextual or domain-specific cues essential for these tasks.Similarly, embeddings such as stella and Qwen exhibit moderate performance, excelling in a limited subset of tasks but failing to match the versatility of OpenAI embeddings.Their inconsistent performance across datasets indicates that while they may effectively capture certain linguistic patterns, they struggle with tasks requiring a broader understanding of context, intent, or nuanced semantics.</p>
<p>These observations suggest that OpenAI embeddings, deliver the most robust and consistent performance across a diverse set of tasks.Their ability to effectively capture both explicit textual features (e.g., in spam detection) and nuanced contextual variations (e.g., in Covid Fake News and OLID) highlights their versatility.This underscores their suitability for anomaly detection scenarios that demand both surface-level pattern recognition and deeper linguistic comprehension, making them well-equipped for handling a wide range of textbased anomalies.</p>
<p>Performance Across Anomaly Detectors</p>
<p>To evaluate the robustness of anomaly detection algorithms across various embeddings and tasks, we analyze their average rankings using OpenAI embeddings (O-ada, O-small, and O-large) as representative examples (Figure 6).These embeddings were selected based on their strong and consistent performance across datasets, as demonstrated in Section 4.2.The rankings provide insight into which detection algorithms perform reliably regardless of the embedding or task.This indicates their robustness and adaptability to the semantic structures of LLM-derived embeddings.kNN, in particular, excels due to its ability to effectively model local density variations in feature space, making it well-suited for both explicitpattern tasks like spam detection and nuanced tasks like fake news and hate speech detection.INNE, with its efficiency and strong generalization capabilities, complements kNN as a reliable alternative in diverse anomaly detection scenarios.</p>
<p>ECOD also ranks highly, consistently appearing among the top three detectors across embeddings.Its lightweight design and ability to estimate density-based anomalies make it a strong candidate for scenarios where computational efficiency is critical.On the other hand, methods like LOF, COPOD, and iForest consistently rank lower, highlighting their limitations in high-dimensional and semantically complex embedding spaces.These methods struggle with noise, data sparsity, and the nuanced patterns encoded in LLM embeddings, which limits their effectiveness across diverse tasks.</p>
<p>Conclusion</p>
<p>In this paper, we present a comprehensive benchmark for embedding-based text anomaly detection, systematically evaluating the interplay between LLM embeddings and classical anomaly detection algorithms across three diverse domains.Our results reveal both the strengths and limitations of embedding-based anomaly detection methods, demonstrating their effectiveness in tasks with explicit and well-defined patterns while highlighting challenges in capturing implicit, context-dependent anomalies that require broader contextual cues.These findings emphasize the need for more adaptive embeddings and hybrid detection strategies that integrate external knowledge and contextual reasoning.</p>
<p>Limitations</p>
<p>TAD-Bench evaluates anomaly detection across three domains: spam detection, fake news detection, and offensive language detection.While these tasks provide diverse and relevant benchmarks, they do not fully capture the complexity of realworld applications.Strong performance in spam detection highlights the ability of LLM embeddings to capture explicit patterns, while mixed results in fake news detection and poor performance in offensive language detection reveal their limitations in modeling implicit, context-sensitive cues.Expanding to domains like medical, financial, or legal texts that involve unique challenges, and exploring datasets with more implicit anomalies, could better evaluate the adaptability and robustness of these methods.</p>
<p>Moreover, TAD-Bench focuses solely on embedding-based methods, excluding end-to-end approaches that directly process raw text because due to modularity and efficiency of embeddingbased methods, and NLP-ADBench has also shown better performance of embedding-based methods than end-to-end methods.However, end-to-end models like autoencoders or transformer-based methods may capture richer contextual information and handle more complex anomalies.Future work should incorporate end-to-end models and explore hybrid approaches that combine the strengths of both paradigms, providing a more comprehensive evaluation of anomaly detection methods in NLP.</p>
<p>Ethic Statement</p>
<p>This study adheres to ethical research practices and considerations in the development and evaluation of text anomaly detection methods.</p>
<p>Use of Potentially Offensive Language.Some examples in this paper may contain offensive, harmful, or misleading language.These examples are used purely for illustrative purposes to demonstrate the challenges of text anomaly detection in realworld scenarios.They do not reflect the opinions, beliefs, or endorsements of the authors.</p>
<p>Data Sources and Usage.All datasets used in this study are sourced from publicly available research datasets that have been previously used in NLP and anomaly detection research.Proper citations and references to the original datasets are provided in the paper.No private, proprietary, or personally identifiable information was used in this study.</p>
<p>Risks and Responsible Use.Because anomaly detection models can be misused for purposes such as censorship, surveillance, or unfair content moderation.We strongly emphasize that our benchmark is intended for research and academic purposes only and should be used responsibly with consideration of ethical and societal implications.</p>
<p>Use of AI Assistance We acknowledge the use of AI-based writing assistants for grammar refinement, spelling correction, and improving the clarity of our manuscript.However, all intellectual contributions, experimental designs, analyses, and conclusions in this paper are solely the work of the authors.</p>
<p>A Problem Definitions</p>
<p>Let D = {x 1 , x 2 , . . ., x N } represent a corpus consisting of N textual instances, where each instance x i âˆˆ X is represented as a sequence of tokens:
x i = [t 1 , t 2 , . . . , t L i ],
where L i denotes the sequence length of x i .The goal of text anomaly detection is to identify a subset of instances D anomaly âŠ‚ D, such that D anomaly contains samples that deviate significantly from the majority of the dataset D normal = D \ D anomaly .</p>
<p>To achieve this, an anomaly detection algorithm g is applied to the representations of the textual instances to identify potential anomalies.</p>
<p>(1) Each text instance x i is first mapped to a fixeddimensional vector z i âˆˆ R d using an embedding model Ï• :
X â†’ R d , such that z i = Ï•(x i ).
(2) The anomaly detection algorithm then assigns an anomaly score s i = g(z i ) to each instance, s i âˆˆ [0, 1].Based on a predefined threshold Ï„ , an instance x i is classified as anomalous if:
x i âˆˆ D anomaly â‡â‡’ s i â‰¥ Ï„.
The objective of text anomaly detection is to ensure that g effectively distinguishes between normal and anomalous instances, even in the absence of labeled data, while being robust to the inherent variability and high dimensionality of textual data.</p>
<p>B Clarification Between Anomaly and Novelty Detection</p>
<p>Text Anomaly Detection (TAD), as defined in Section A, focuses on identifying instances that deviate significantly from the majority of a dataset, regardless of whether anomalies are present during training.While some prior studies (e.g., AD-NLP (Bejan et al., 2023), NLP-ADBench (Li et al., 2024) and AD-LLM (Yang et al., 2024b)) assume training data contains only normal instances and testing data includes both normal and anomalous samples, this setup aligns more closely with novelty detection (Pimentel et al., 2014).Novelty detection specifically targets never-before-seen anomalies that are absent from the training phase, often treating anomalies as entirely novel classes.In contrast, our benchmark evaluates a broader spectrum of anomaly detection scenarios.We do not restrict the training data to purely normal instances, allowing for potential partial supervision or contaminated training sets (e.g., realistic scenarios where anomalies may unintentionally exist in training data).This setup reflects real-world applications where anomaly types are not always fully known a prior, and detection systems must generalize across domains and anomaly types.</p>
<p>This distinction underscores our goal of advancing generalizable anomaly detection systems for real-world NLP applications, where anomalies may exhibit both explicit and context-dependent patterns.</p>
<p>C Datasets</p>
<p>Email-Spam2 (Metsis et al., 2006) contains 5,171 emails labeled as spam or ham, with spam treated as the anomaly class.We utilized the preprocessed version provided in (Li et al., 2024).</p>
<p>SMS-Spam3 (Almeida et al., 2011) comprises 5,574 SMS messages originally labeled as spam or ham.Spam messages are designated as the anomaly.</p>
<p>COVID-Fake4 (Das et al., 2021) comprises posts collected from social media platforms and fact-checking websites.Real news items were sourced from verified outlets providing accurate COVID-19 information, while fake news was gathered from tweets, posts, and articles containing misinformation about COVID-19.Fake news is treated as the anomaly class.</p>
<p>LIAR25 (Xu and Kechadi, 2024) consists of approximately 23,000 statements manually labeled by professional fact-checkers for fake news detection tasks.The "True" class, representing accurate statements, is considered the normal class, while the "Pants on Fire" class, representing highly misleading statements, is treated as the anomaly.</p>
<p>OLID6 (Zampieri et al., 2019b) (Zampieri et al., 2019a) contains 14,200 annotated English tweets, categorized using a three-level annotation model.For this benchmark, only the Level A (Offensive Language Detection) annotations are used, where tweets labeled as offensive are considered as anomalies, and non-offensive tweets are considered â€¢ Qwen 15 (Qwen2.5-1.5B)</p>
<p>Beyond model size and token limits, computational efficiency is a key factor in selecting embedding models, particularly for real-world applications where inference speed is critical.Table 3 presents the embedding time (in seconds) required to process six datasets using each embedding model.</p>
<p>From the Table 3, we observe a significant variation in embedding extraction time.MINILM is the fastest across all datasets, taking only a few seconds, making it ideal for applications requiring real-time embedding generation.BERT offers a moderate trade-off, with embedding times significantly lower than larger models but higher than MINILM.OpenAI's embeddings (O-ada, O-small, O-large) are relatively slow, likely due to their highdimensional output and extended token support.Llama and Qwen models require the most computation, with Qwen taking up to 745.85 seconds on the Email-Spam dataset, reflecting the high computational cost of large autoregressive models.</p>
<p>F Comparative Analysis of Anomaly Detection Algorithms</p>
<p>Anomaly detection algorithms vary in their underlying assumptions, computational efficiency, and effectiveness across different types of data distributions.In this section, we provide a comparative analysis of the eight anomaly detection methods used in this study: kNN, OCSVM, iForest, LOF, HBOS, ECOD, INNE and COPOD.Distance-based methods, such as kNN, define anomalies based on their relative distance to surrounding points.kNN anomaly detection computes the distance between a data point and its kth nearest neighbor, with larger distances indicating potential anomalies.This method is conceptually simple 15 https://huggingface.co/Qwen/Qwen2.5-1.5B and effective in low-dimensional spaces with clear separation between normal and anomalous points.However, its primary drawback is the curse of dimensionality, where distance metrics lose discriminative power as dimensionality increases.Additionally, kNN is computationally expensive, with a worst-case complexity of O(n 2 ), making it impractical for large datasets without optimizations such as approximate nearest neighbor search.</p>
<p>Density-based approaches assume that anomalies reside in low-density regions relative to normal points.LOF estimates the local density of a point by comparing it with the densities of its neighbors.It is highly effective in detecting anomalies in datasets with non-uniform density distributions, where global models may fail.However, LOF is computationally expensive complexity O(n 2 ) in the worst case and sensitive to the choice of neighborhood size, requiring careful hyperparameter tuning.</p>
<p>A more efficient density estimation approach is HBOS, which models feature distributions independently using histograms.This makes it computationally extremely fast O(n) and scalable to large datasets.However, HBOS assumes feature independence, limiting its effectiveness when strong feature correlations exist.In such cases, its effectiveness diminishes as it fails to capture intricate relationships between features, potentially leading to suboptimal anomaly detection performance.</p>
<p>Isolation-based approaches, such as iForest, take a different perspective by recursively partitioning the feature space.Since anomalies are typically isolated with fewer splits, iForest identifies them based on the depth required to isolate each point.iForest is computationally efficient O(nlogn) and performs well in high-dimensional spaces compared to distance-based methods, but it is struggle with local anomalies.An extension of iForest, INNE, replaces axis-aligned splits with hypersphere-based partitions.This enhances robustness in detecting anomalies in complex distributions, particularly local anomalies.</p>
<p>Statistical approaches model the underlying distribution of data and identify anomalies as points that significantly deviate from expected behavior.ECOD estimates anomaly scores based on the empirical cumulative distribution function (ECDF) for each feature independently.It is parameterfree and computationally efficient O(n), making it highly scalable.However, like HBOS, ECOD assumes feature independence, which can limit its effectiveness in multivariate settings.COPOD improves upon ECOD by leveraging copula functions to model dependencies between features, making it more effective for detecting anomalies in correlated data.However, this comes at the cost of increased computational complexity, making COPOD less scalable for very large datasets.</p>
<p>G Embedding Analysis</p>
<p>To better understand how different embedding models encode normal and anomalous instances, we visualize their embedding spaces using t-SNE projections across 6 datasets.Figure 6 presents the t-SNE plots for embeddings extracted from 8 embedding models, blue points represent normal instances, while red points denote anomalies.</p>
<p>Separation of Normal and Anomalous Instances.As defined in Section A, anomalies should ideally exhibit significant deviation from normal instances in the embedding space.The extent to which embeddings separate anomalies from normal data is a crucial factor in determining their effectiveness for anomaly detection.</p>
<p>Most embedding models exhibits clear separation, particularly in the Email Spam dataset, where anomalous points form distinct regions away from the normal distribution.BERT struggles with clear separation, with many anomalies still embedded within normal clusters.This indicates that these models may not encode sufficient discriminative features for anomaly detection tasks.</p>
<p>Dataset-Specific Challenges.The effectiveness of embedding-based anomaly detection varies significantly across datasets, highlighting the influence of domain characteristics:</p>
<p>â€¢ Spam Detection (Email Spam, SMS Spam): most embedding models perform well, reflecting their ability to capture explicit spam patterns (e.g., domain-specific keywords, unusual syntax).In contrast, BERT shows more overlap between spam and normal messages, leading to weaker anomaly separation.</p>
<p>â€¢ Fake News Detection (COVID-Fake, LIAR2):</p>
<p>The separation of anomalies is less pronounced across most embeddings, likely due to the subtle and nuanced nature of misinformation.This suggests that effective detection may require external knowledge or factual reasoning beyond what standard embeddings can provide.</p>
<p>â€¢ Offensive Language (Hate Speech, OLID): All embeddings perform poorly, with anomalies scattered among normal instances.This suggests that hate speech and offensive language often depend on implicit contextual cues rather than explicit linguistic differences, making them harder to distinguish using standard embeddings.</p>
<p>Clustered Anomalies in Spam Detection.For both Email Spam and SMS Spam datasets, the anomalies tend to form compact clusters rather than being scattered as isolated points.This behavior contrasts with other datasets, where anomalies are often more dispersed.</p>
<p>Unlike anomalies in misinformation or hate speech detection, which can manifest in subtle linguistic variations, spam messages tend to exhibit repetitive patterns, including URLs, phone numbers, irregular word spacing and excessive punctuation.Since these patterns are highly distinct but internally consistent, embeddings may cluster them into a well-defined anomaly group rather than spreading them across the feature space.</p>
<p>H Experiments Environment</p>
<p>The entire pipeline, including embedding extraction and anomaly detection, was implemented in Python 3.9.Experiments were executed on a computational setup equipped with a Ryzen 9 5900X 12-core CPU for data preprocessing and model orchestration, and an Nvidia RTX 3060 GPU with 12GB of memory for model inference and embedding generation.</p>
<p>Figure 1
1
Figure 1: t-SNE visualization of SMS_Spam dataset's embedding extracted by OpenAI model.Blue and red points are normal and anomaly points, respectively.</p>
<p>Figure 2 :
2
Figure 2: Illustration of the embedding-based anomaly detection pipeline, encompassing embedding extraction and anomaly scoring.</p>
<p>Figure 3
3
Figure 3: t-SNE demonstration of Case 1 (green star) embedding extracted by O-large.</p>
<p>Figure 4
4
Figure 4: t-SNE demonstration of Case 2 (green star) embedding extracted by O-large.</p>
<p>Figure 5 :
5
Figure 5: Boxplot of AUCROC scores for anomaly detectors on different embeddings across 6 datasets.</p>
<p>Figure 6 :
6
Figure 6: Average rank (lower the better) of 3 differernt OpenAI embeddings-based methods on AUCROC across 6 datasets.</p>
<p>Table 1 :
1
Dataset description.Nor. and Ano.stand for Normal and Anomaly.
Dataset# Samples # Nor. # Ano. % Ano.Email Spam357834321464.0805SMS Spam496948251442.8980COVID-Fake11731120534.5183LIAR221302068622.9108OLID641620213.2761Hate Speech428741631242.8925While effective for complex distributions.Deep learning-based methods train on normaldata to learn representations, identifying anoma-lies as deviations. Approaches like Deep SVDD(Deep Support Vector Data Description)</p>
<p>Table 2
2demonstrate the remark-able capabilities of the OpenAI family of embed-dings (O-ada, O-small, and O-large), consistentlyoutperforming other embeddings across a varietyof anomaly detection tasks. Specifically, O-adaachieves the highest average AUC scores withthe ECOD detector (0.8822) on the SMS Spamdataset and with kNN (0.7921) on the LIAR2dataset. Similarly, O-small demonstrates outstand-ing performance, achieving the highest AUC scoreswith kNN on the Hate Speech (0.6416) and OLID(0.5587) datasets. Additionally, O-large securestop AUC scores with COPOD (0.9639) on theEmail Spam dataset and with kNN (0.9537) onthe COVID Fake News dataset.</p>
<p>Table 2 :
2
Evaluation across 6 datasets in terms of AUROC.
Embeddings Detectors Email-Spam SMS-Spam COVID-Fake LIAR2 Hate-Speech OLID AveragekNN0.76250.44840.84670.65940.50330.51370.6223OCSVM0.73620.63230.78670.62370.48660.48660.6254IForest0.71520.61640.77010.60510.49250.47830.6129BERTLOF0.67860.32300.87130.67170.46320.49700.5841ECOD0.73090.62350.77220.61750.48890.49330.6211INNE0.77320.64970.80120.63620.48500.47400.6366HBOS0.71450.62510.76980.61900.49350.50020.5317COPOD0.64540.59290.77140.62420.49710.51890.5214kNN0.94140.31800.84130.72490.58040.50630.6520OCSVM0.96260.59150.78430.64700.40620.45200.6406IForest0.90780.54720.74550.59360.46970.45310.6195MINILMLOF0.55870.50240.74330.68040.50780.54220.5891ECOD0.95250.59340.75810.65320.37860.42080.6261INNE0.95260.57370.80350.66010.42230.48240.6491HBOS0.94780.61370.74410.64470.38880.43160.5387COPOD0.94530.63170.74160.66950.37100.40370.5375kNN0.88650.32120.90940.79210.63410.52430.6779OCSVM0.93100.82210.81430.71690.48070.50480.7116IForest0.88720.73760.74320.64210.46320.48910.6604O-adaLOF0.38080.50330.73160.75410.43280.53760.5567ECOD0.93800.88220.81500.72000.46100.49860.7191INNE0.85070.80310.85330.73780.48200.51020.7062HBOS0.94330.88130.81640.71860.45830.50980.6182COPOD0.95020.87590.81530.72010.45130.48110.6134kNN0.89210.22900.94000.77560.64160.55870.6728OCSVM0.94750.57550.89320.70240.45770.55470.6885IForest0.90580.61770.80850.59730.50250.55800.6650O-smallLOF0.38630.52570.78090.74890.41390.55810.5690ECOD0.94810.63010.88080.70220.42490.52950.6859INNE0.86730.60800.91850.71980.44910.53820.6835HBOS0.95220.62730.87190.70080.42450.51570.5846COPOD0.96050.57220.86640.69740.40170.49630.5706kNN0.82920.16980.95370.76870.62910.54970.6500OCSVM0.94030.56300.89240.66210.42600.49710.6635IForest0.89990.52970.80410.56870.45160.50680.6268O-largeLOF0.40480.47190.82330.73560.38330.51670.5559ECOD0.94870.64220.88750.65400.39590.49670.6708INNE0.82300.59700.92610.68760.41970.51700.6617HBOS0.95380.65250.88490.64040.38350.49890.5734COPOD0.96390.67980.88540.65360.35370.49800.5763kNN0.87150.36550.86680.72290.49910.40810.6223OCSVM0.90230.73790.81320.68920.47740.40570.6710IForest0.89620.72750.78330.68600.46470.40820.6610LlamaLOF0.60560.40530.86730.72740.43760.39720.5734ECOD0.88440.75730.78190.69890.46430.39980.6644INNE0.91220.70650.81600.69350.47020.39170.6650HBOS0.90170.78950.77580.70640.45800.38980.5745COPOD0.91530.81630.75840.72910.44350.35260.5736kNN0.86540.32120.90340.68840.47460.50160.6258OCSVM0.89220.71650.80630.51030.37290.44390.6237IForest0.88620.73770.77380.49990.35450.43250.6141stellaLOF0.39310.47330.71290.65490.40360.52850.5277ECOD0.90750.78940.81150.50230.34210.43950.6321INNE0.82710.69260.83660.53300.33250.45320.6125HBOS0.91780.80170.80860.49520.33550.42520.5406COPOD0.93000.85890.81670.49360.30180.37970.5401kNN0.86180.21100.84380.66260.51630.46020.5926OCSVM0.88040.62290.78680.62160.49160.48820.6486IForest0.88290.61950.76860.61550.48250.48690.6427QwenLOF0.60430.36000.85550.68940.46000.45180.5702ECOD0.86780.66480.76800.61720.48520.47730.6467INNE0.88390.59400.78330.63390.49020.46930.6424HBOS0.88540.68770.76380.61700.48470.46850.5582COPOD0.90440.73930.74630.62910.47940.43360.5617</p>
<p>Table 5 :
5
Embedding Models Overview.M and B are for million and billion, respectively.
ModelsMax Tokens # Dimensions # ParametersBERT512768110 MMINILM51238422.7 MO-ada81911536-O-small81911536-O-large81913072-LLAMA409620481.24 Bstella20481024435 MQwen819215361.54 B</p>
<p>Table 6 :
6
t-SNE visualization of embeddings from 8 models across 6 datasets.Blue points represent normal instances, while red points denote anomalies.</p>
<p>PyOD: https://pyod.readthedocs.io/en/latest/ index.html
https://huggingface.co/datasets/kendx/ NLP-ADBench/tree/main/datasets/email_spam
https://archive.ics.uci.edu/dataset/228/sms+ spam+collection
https://github.com/diptamath/covid_fake_news? tab=readme-ov-file
https://github.com/chengxuphd/liar2?tab= readme-ov-file
https://sites.google.com/site/ offensevalsharedtask/olid
D Evaluation with Hyperparameter SearchExperiments with hyperparameter search reveal significant insights into the performance dynamics of anomaly detection algorithms when paired with various embedding models.When comparing Table4with the default parameters results in Table2, we observe that kNN emerges as a particularly strong performer across multiple embedding models, especially with the OpenAI family of embeddings.This suggests that distance-based approaches effectively leverage the semantic information captured by these models, particularly in tasks like spam and fake news detection.INNE demonstrates the most balanced and robust performance profile when considering average scores across all datasets and embedding combinations.Its isolation-based approach with hypersphere partitioning appears particularly well-suited to the complex topological structure of embedding spaces, allowing it to identify local anomalies that other methods might miss.The performance improvement of INNE after hyperparameter optimization is especially notable with embedding models 7 https://github.com/t-davidson/hate-speech-and-offensive-language like Llama and stella, suggesting a strong complementarity between isolation-based algorithms and these embedding architectures.E Embedding ModelsTo effectively represent textual data, we use various pre-trained embedding models that transform text into dense vector representations.Table5summarizes the embedding models employed in this paper.These embeddings serve as feature inputs for anomaly detection models, enabling them to capture semantic similarities and deviations in text.We selected a diverse set of embedding models, balancing between model size, token length limits, and computational efficiency.The models used in this study are:â€¢ BERT 8 (bert-base-uncased)â€¢ MINILM 9 (all-MiniLM-L6-v2)â€¢ O-ada 10 (text-embedding-ada-002)â€¢ O-small 11 (text-embedding-3-small)â€¢ O-large 12 (text-embedding-3-large)â€¢ LLAMA 13 (Llama-3.2-1B)â€¢ stella 14 (stella_en_400M_v5)
Contributions to the study of sms spam filtering: new collection and results. JosÃ© Tiago A Almeida, G MarÃ­a, Akebo Hidalgo, Yamakami, Proceedings of the 11th ACM symposium on Document engineering. the 11th ACM symposium on Document engineering2011</p>
<p>Isolation-based anomaly detection using nearest-neighbor ensembles. Kai Ming Tharindu R Bandaragoda, David Ting, Albrecht, Tony Fei, Ye Liu, Jonathan R Zhu, Wells, Computational Intelligence. 3442018</p>
<p>Ad-nlp: A benchmark for anomaly detection in natural language processing. Matei Bejan, Andrei Manolache, Marius Popescu, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>A review on outlier/anomaly detection in time series data. Ane BlÃ¡zquez-GarcÃ­a, Angel Conde, Usue Mori, Jose A Lozano, ACM computing surveys (CSUR). 5432021</p>
<p>Lof: identifying densitybased local outliers. Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, JÃ¶rg Sander, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data2000</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Text classification using embeddings: a survey. Liliane Soares Da Costa, Italo L Oliveira, Renato Fileto, Knowledge and Information Systems. 6572023</p>
<p>A heuristic-driven ensemble framework for covid-19 fake news detection. Dipta Sourya, Ayan Das, Saikat Basak, Dutta, Combating Online Hostile Posts in Regional Languages during Emergency Situation: First International Workshop, CONSTRAINT 2021, Collocated with AAAI 2021, Virtual Event. Springer2021. February 8, 20211</p>
<p>Automated hate speech detection and the problem of offensive language. Thomas Davidson, Dana Warmsley, Michael Macy, Ingmar Weber, Proceedings of the international AAAI conference on web and social media. the international AAAI conference on web and social media201711</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191</p>
<p>Histogram-based outlier score (hbos): A fast unsupervised anomaly detection algorithm. KI-2012: poster and demo track. Markus Goldstein, Andreas Dengel, 20121</p>
<p>Lunar: Unifying local outlier detection methods via graph neural networks. Adam Goodge, Bryan Hooi, See-Kiong Ng, Wee Siong Ng, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>Albert: A lite bert for self-supervised learning of language representations. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, arXiv:1909.119422020PreprintPiyush Sharma, and Radu Soricut</p>
<p>Yuangang Li, Jiaqi Li, Zhuo Xiao, Tiankai Yang, Yi Nian, Xiyang Hu, Yue Zhao, arXiv:2412.04784Nlpadbench: Nlp anomaly detection benchmark. 2024arXiv preprint</p>
<p>Copod: copula-based outlier detection. Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, Xiyang Hu, 2020 IEEE international conference on data mining (ICDM). IEEE2020</p>
<p>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions. Zheng Li, Yue Zhao, Xiyang Hu, Nicola Botta, Cezar Ionescu, George H Chen, IEEE Transactions on Knowledge and Data Engineering. 35122022</p>
<p>Isolation forest. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, 2008 eighth ieee international conference on data mining. IEEE2008</p>
<p>Isolation-based anomaly detection. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, ACM Transactions on Knowledge Discovery from Data (TKDD). 612012</p>
<p>Vangelis Metsis, Spam filtering with naive bayeswhich naive bayes? In CEAS. Mountain View, CA200617Ion Androutsopoulos, and Georgios Paliouras</p>
<p>Tomas Mikolov, arXiv:1301.3781Efficient estimation of word representations in vector space. 20133781arXiv preprint</p>
<p>New embedding models and api updates. 2024OpenAI</p>
<p>Longbing Cao, and Anton Van Den Hengel. 2021. Deep learning for anomaly detection: A review. Guansong Pang, Chunhua Shen, ACM computing surveys (CSUR). 54</p>
<p>Glove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). the 2014 conference on empirical methods in natural language processing (EMNLP)2014</p>
<p>Deep contextualized word representations. Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, 10.18653/v1/N18-1202Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational Linguistics20181</p>
<p>A review of novelty detection. A F Marco, David A Pimentel, Lei Clifton, Lionel Clifton, Tarassenko, Signal processing. 992014</p>
<p>Charu Aggarwal, and Guansong Pang. Hezhe Qiao, Hanghang Tong, Bo An, Irwin King, arXiv:2409.09957Deep graph anomaly detection: A survey and new perspectives. 2024arXiv preprint</p>
<p>Efficient algorithms for mining outliers from large data sets. Sridhar Ramaswamy, Rajeev Rastogi, Kyuseok Shim, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data2000</p>
<p>Deep one-class classification. Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Ahmed Shoaib, Alexander Siddiqui, Emmanuel Binder, Marius MÃ¼ller, Kloft, International conference on machine learning. PMLR2018</p>
<p>Termweighting approaches in automatic text retrieval. Gerard Salton, Christopher Buckley, formation processing &amp; management. 198824</p>
<p>Estimating the support of a high-dimensional distribution. Bernhard SchÃ¶lkopf, John C Platt, John Shawe-Taylor, Alex J Smola, Robert C Williamson, Neural computation. 1372001</p>
<p>Benchmarking unsupervised outlier detection with realistic synthetic data. Georg Steinbuss, Klemens BÃ¶hm, ACM Transactions on Knowledge Discovery from Data (TKDD). 1542021</p>
<p>Qwen Team. 2024. Qwen2.5: A party of foundation models. </p>
<p>Log2graphs: An unsupervised framework for log anomaly detection with efficient feature extraction. Caihong Wang, Du Xu, Zonghang Li, arXiv:2409.118902024arXiv preprint</p>
<p>Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers. Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, Ming Zhou, Advances in Neural Information Processing Systems. 202033</p>
<p>An enhanced fake news detection system with fuzzy deep learning. Cheng Xu, M-Tahar Kechadi, 10.1109/ACCESS.2024.3418340IEEE Access. 122024</p>
<p>Comparative analysis of anomaly detection algorithms in text data. Yizhou Xu, JÃ©rÃ´me Milleret, FrÃ©dÃ©rique Segond, Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing. the 14th International Conference on Recent Advances in Natural Language Processing2023</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, arXiv:2407.10671Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. 2024a. Qwen2 technical report. Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei ChuarXiv preprint</p>
<p>Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, arXiv:2412.11142Ad-llm: Benchmarking large language models for anomaly detection. 2024barXiv preprint</p>
<p>Predicting the Type and Target of Offensive Posts in Social Media. Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar, Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar, 10.18653/v1/N19-1144Proceedings of the 2019 Conference of the North American Chapter. Long and Short Papers. the 2019 Conference of the North American ChapterMinneapolis, MinnesotaAssociation for Computational Linguistics2019a. 2019b1Proceedings of NAACL</p>
<p>Dun Zhang, Jiacheng Li, Ziyang Zeng, Fulong Wang, arXiv:2412.19048Jasper and stella: distillation of sota embedding models. 2024arXiv preprint</p>
<p>Pyod: A python toolbox for scalable outlier detection. Yue Zhao, Zain Nasrullah, Zheng Li, Journal of Machine Learning Research. 20962019</p>
<p>Large language models for information retrieval: A survey. Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, Ji-Rong Wen, arXiv:2308.071072023arXiv preprint</p>
<p>A robustly optimized BERT pre-training approach with post-training. Liu Zhuang, Lin Wayne, Shi Ya, Zhao, Proceedings of the 20th Chinese National Conference on Computational Linguistics. the 20th Chinese National Conference on Computational LinguisticsHuhhot, ChinaChinese Information Processing Society of ChinaJun. 2021</p>            </div>
        </div>

    </div>
</body>
</html>