<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6867 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6867</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6867</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-259138569</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.06283v4.pdf" target="_blank">14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon</a></p>
                <p><strong>Paper Abstract:</strong> Large-language models (LLMs) such as GPT-4 caught the interest of many scientists. Recent studies suggested that these models could be useful in chemistry and materials science. To explore these possibilities, we organized a hackathon. This article chronicles the projects built as part of this hackathon. Participants employed LLMs for various applications, including predicting properties of molecules and materials, designing novel interfaces for tools, extracting knowledge from unstructured data, and developing new educational applications. The diverse topics and the fact that working prototypes could be generated in less than two days highlight that LLMs will profoundly impact the future of our fields. The rich collection of ideas and projects also indicates that the applications of LLMs are not limited to materials science and chemistry but offer potential benefits to a wide range of scientific disciplines.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6867.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6867.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-GA (McGill)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model guided Genetic Algorithm (McGill University project)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prototype that uses a pretrained decoder-only LLM (OpenAI GPT-3.5 family) to perform GA-like operations on molecules: fragmenting SMILES, recombining fragments, proposing mutations, and iteratively generating candidate molecules to optimize a scoring function (demonstrated with Tanimoto similarity to vitamin C). Developed and evaluated during the hackathon described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 / GPT-3.5-turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>decoder-only LLM used via prompting; few-shot / in-context learning; iterative/agent-like loop (LLM-as-GA)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified (OpenAI GPT-3.5 family; proprietary)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not specified in the paper; model is a pretrained OpenAI GPT-3.5-family model (trained by OpenAI on large web-scale corpora and code; chemistry-specific pretraining not described).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt-based fragment/recombine and mutation of SMILES (few-shot in-context prompting). Iterative loop: provide top-scoring parent SMILES and scores, ask LLM to propose new SMILES; repeat for multiple generations. Low sampling temperature (<0.1) used to encourage adherence to prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES strings</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>General molecule generation and optimization (demonstration: optimize Tanimoto similarity to a target small molecule — vitamin C); examples used druglike molecules and similarity-guided search.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Prompt-provided parent examples and scores; low-temperature sampling (<0.1); repeated retries for invalid outputs; no explicit synthetic-accessibility or toxicity filters reported.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>External scoring function computing Tanimoto similarity (used to evaluate candidates); embedding + SVM pipeline (GPT-2 tokenizer + scikit-learn SVM) used to embed/ retrieve relevant prior structures outside the context window. Tooling for exact similarity calculator not named but an external fingerprint/Tanimoto calculator was used.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Ad hoc example sets from the hackathon: 30 parent SMILES with associated Tanimoto scores used as few-shot context; additional small drug-like molecules used for fragmentation experiments (no standard public generative training dataset used for the generation experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Validity of SMILES (qualitative counts), success rate of fragmentation, expert human chemical reasonableness (binary judgments), and property-improvement metric (Tanimoto similarity progression across generations).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Fragmentation: GPT-3.5 (no fine-tuning) fragmented SMILES at rotatable bonds with ~70% success. In a 10-molecule test: 2/10 fragments produced were not part of the original molecule; 1/10 molecules could not produce valid SMILES even after ten attempts. Expert evaluation: in a blind comparison 32/32 LLM-GA generated molecules were judged chemically reasonable, versus 21/32 for random recombination. Iterative optimization runs (25 SMILES per generation, repeated over ~20 iterations) produced multiple new best molecules (plots show best/mean Tanimoto similarity improving per generation), but exact numerical improvement values for the similarity were not reported in tabular form.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Models often output invalid SMILES without retries or prompt engineering; some fragments/mutations not chemically faithful to parents; outputs can be non-deterministic and require many sampling attempts; context-length limits constrain how many parent examples can be given; no synthesis feasibility or ADMET/safety filters were applied; reliability and robustness across chemistries not established; need for systematic benchmarking against conventional GA methods and generative models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6867.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6867.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-as-GA Tanimoto optimization (detailed)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Iterative in-context LLM optimization of molecular similarity (Tanimoto) demonstrated in hackathon</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concrete hackathon demonstration of using GPT-3.5-turbo as the proposal mechanism in an evolutionary-style loop to maximize Tanimoto similarity to a target (vitamin C). The LLM receives a few-shot set of high-scoring parent SMILES and is prompted to produce candidate SMILES for the next generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>decoder-only LLM; few-shot in-context generation used iteratively as a proposal operator within a GA-like loop</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained OpenAI GPT-3.5-family weights (details not provided in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Few-shot prompting with example SMILES and associated scores; LLM asked to output a list of SMILES predicted to improve scores; iterative loop where top candidates are re-scored externally and the top performers seed the next prompt; low-temperature sampling used to reduce stochasticity.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Proof-of-concept property optimization (similarity to vitamin C) and general molecule optimization workflows (could be applied to optimizing other computed properties).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Prompted instructions and example-based guidance; temperature set low (<< 0.1) to enforce adherence to pattern; similarity-based selection used externally to decide survivors; no chemical-synthesis or ADMET constraints applied.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>External Tanimoto similarity calculator used to score candidates; GPT-2 tokenizer + SVM embedding from scikit-learn used to include previous structures outside context window. (Exact fingerprinting library not explicitly named in text.)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>30 top parent SMILES included per prompt; vitamin C target for similarity metric. No large standard generative training dataset used for this procedural experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Tanimoto similarity to target (per-candidate), best and mean similarity per generation; expert visual/chemical reasonableness scoring by organic chemists; SMILES validity rate.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Multiple generations produced new best-scoring molecules (plots reported). No absolute numerical Tanimoto trajectories were reported in tables; qualitative statement that multiple new best molecules were found. Expert assessment indicated LLM-produced modifications were more chemically sound than quasi-random GA string-splicing.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Invalid SMILES sometimes produced (necessitating retries); stochastic generation requires many samples; lacking synthesis feasibility checks; results are preliminary and require systematic comparison to conventional GA and generative-model baselines; context-window limits number of seed examples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6867.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6867.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScholarBERT screening (GlobusLabs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ScholarBERT-based contextual screening for hydrogen carrier molecules (GlobusLabs team)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Screening approach that uses ScholarBERT sentence/context embeddings aggregated per molecule (from a large corpus of scientific text) to rank candidate molecules for a target application (hydrogen carriers) by cosine similarity to known carriers; intended as a literature-context driven candidate prioritization method rather than de novo generative chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ScholarBERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>encoder (BERT-style) contextual embedding model used for retrieval and similarity ranking</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>ScholarBERT trained on a large corpus of scientific articles (Public.Resource.Org collection cited: ~75M English-language research articles); science-focused pretraining/finetuning described in the ScholarBERT reference.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not generative: retrieval/embedding-based screening. For each candidate molecule, sentences mentioning the molecule were found in the corpus; contextual token embeddings for those sentences were averaged (three aggregation strategies tested) to create a fingerprint; candidates were ranked by cosine similarity to embeddings of known hydrogen carriers.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Molecule names (text mentions in literature); mapping of names to chemical structures for downstream evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Discovery/prioritization of hydrogen carrier molecules for energy storage (application-specific screening).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Three candidate sets evaluated: Known (78 known hydrogen carriers), Relevant (577 structurally similar molecules), Random (111 PubChem random molecules); no explicit chemical-property constraints applied during initial ranking stage; downstream rigorous energy/thermodynamic computations used for validation on selected hits.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Downstream quantum-chemistry calculations used to compute energy capacity (wt% H2) and energy penalty (kJ/mol/H2) for candidates (traditional quantum chemistry used as validation), executed separately on CPU clusters. PubChem used as a source for random candidate selection.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Public.Resource.Org corpus for contexts (~75M articles). Candidate datasets: Known = 78, Relevant = 577, Random = 111 (PubChem).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Enrichment / ranking quality measured qualitatively versus random baseline; downstream quantitative metrics computed by quantum chemistry: gravimetric H2 capacity (wt%) and energy penalty (kJ/mol H2); throughput/speed comparison between screening pipeline and quantum calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>ScholarBERT approach recommended molecules with a success rate better than random (qualitative); screening throughput ~100 molecules/second on a V100 GPU (embedding-based screening) versus ~30 seconds per molecule for quantum-chemistry validation on a 64-core Intel Xeon Phi — a reported ~3000x speedup in screening throughput. No absolute values for H2 capacity or energy penalty of specific candidates were tabulated in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Biases in retrieved candidates (tendency to favor 5- and 6-membered rings and halogenated species observed); need for more systematic benchmarking versus conventional generative and screening methods; dependency on literature coverage and naming/mention ambiguity; mapping from textual mentions to unambiguous chemical structures can be noisy and requires careful entity resolution.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6867.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6867.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM agent tool-augmented synthesis planning (mentions)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM agents augmented with external chemistry tools (ChemCrow / cloud-lab agents / MAPI-LLM mentions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Multiple cited/mentioned works and hackathon prototypes demonstrate giving LLMs access to external chemistry tools (search engines, retrosynthesis planners, databases, laboratory APIs, reaction predictors) to plan, rank, or even execute syntheses; these are mentions in the paper and not new experiments presented here.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various (ChatGPT / GPT-3.5 / GPT-4 referenced in discussion; project-specific agents such as ChemCrow cited)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Tool-using LLM agents (ReAct/MRKL paradigms) that combine language-model reasoning with external API/tool calls</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>varies / not specified in paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained foundation LLMs (OpenAI models) and tool-specific documentation; papers cited describe augmentations rather than new pretraining datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not direct molecular string generation alone — LLMs are used to orchestrate calls to external tools (retrosynthesis engines, reaction predictors, databases, cloud lab APIs) to plan or attempt synthesis; in some cited systems LLMs can trigger experiments via cloud lab APIs.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Varies by tool (SMILES, textual names, reaction SMARTS, structured APIs); LLM operates on natural language plus calls to tool-specific structured inputs/outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Retrosynthesis planning, automated lab execution, synthesis planning, workflow orchestration, and multi-tool retrosynthesis/analysis pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Tool-level constraints (safety, API limits) depend on the integrated external systems; no single constraint set described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Cited examples include Google Search, IBM RXN retrosynthesis tool, Materials Project API, Open Reaction Database, and cloud lab APIs; the paper specifically references ChemCrow (LLM augmented with chemistry tools) and Boiko et al. (LLM+cloud lab execution) as literature examples.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Depends on integrated tool (reaction databases, literature corpora); examples cited reference public databases and tool APIs rather than new LLM training datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not consistently standardized across cited works; reported metrics in the literature include task success rates, accuracy of predicted routes, reliability of tool calls, and ability to execute workflows, but specific quantitative metrics are not tabulated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>This paper cites prior work and describes hackathon prototypes showing that tool-augmented LLM agents can combine resources to answer complex materials/chemistry prompts that neither tools nor the LLM could solve alone; no novel quantitative experimental synthesis validations are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Dependence on tool availability and versions, brittleness of agent orchestration, hallucination risk if tools are not used or results misinterpreted, reproducibility challenges (tool and model versioning), safety and dual-use concerns for automated synthesis planning/execution, limited transparency into proprietary LLM internals when using closed APIs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6867.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6867.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flam‑Shepherd / Aspuru‑Guzik (cited)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files (Flam‑Shepherd & Aspuru‑Guzik)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited preprint claiming language models can directly generate 3D coordinates for molecules, materials, and proteins (XYZ/CIF/PDB formats), representing an extension of LLM capabilities to geometry-aware molecular generation; discussed in the paper as related work but not used in the hackathon experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Not specified in this paper (referenced external preprint)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Language-model based generative system capable of producing 3D coordinate files (per the cited preprint)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not described in this paper (see cited preprint for details).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct generation of 3D coordinate files (XYZ/CIF/PDB) from language models (as reported by the cited preprint).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>3D coordinate files (XYZ, CIF, PDB) and presumably standard textual/graph representations as scaffolding.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>De novo generation of molecular/material geometries and protein binding sites (structural design), enabling geometry-aware generative design.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Not described here; likely evaluated with molecular validation tools in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Not described here; see referenced preprint for dataset details.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not reported in this paper (see cited preprint).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Mentioned as an example of language-model-driven molecular generation in the literature; no numbers reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Referenced as promising direction; the paper notes general limitations across literature such as tokenization mismatches, chemical validity issues, and the need for chemistry-specific tokenization or foundation models for chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files <em>(Rating: 2)</em></li>
                <li>ChemCrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>Is GPT-3 all you need for low-data discovery in chemistry? <em>(Rating: 2)</em></li>
                <li>Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3 <em>(Rating: 1)</em></li>
                <li>Bayesian Optimization of Catalysts With In-context Learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6867",
    "paper_id": "paper-259138569",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "LLM-GA (McGill)",
            "name_full": "Large Language Model guided Genetic Algorithm (McGill University project)",
            "brief_description": "Prototype that uses a pretrained decoder-only LLM (OpenAI GPT-3.5 family) to perform GA-like operations on molecules: fragmenting SMILES, recombining fragments, proposing mutations, and iteratively generating candidate molecules to optimize a scoring function (demonstrated with Tanimoto similarity to vitamin C). Developed and evaluated during the hackathon described in this paper.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 / GPT-3.5-turbo (OpenAI)",
            "model_type": "decoder-only LLM used via prompting; few-shot / in-context learning; iterative/agent-like loop (LLM-as-GA)",
            "model_size": "not specified (OpenAI GPT-3.5 family; proprietary)",
            "training_data_description": "Not specified in the paper; model is a pretrained OpenAI GPT-3.5-family model (trained by OpenAI on large web-scale corpora and code; chemistry-specific pretraining not described).",
            "generation_method": "Prompt-based fragment/recombine and mutation of SMILES (few-shot in-context prompting). Iterative loop: provide top-scoring parent SMILES and scores, ask LLM to propose new SMILES; repeat for multiple generations. Low sampling temperature (&lt;0.1) used to encourage adherence to prompts.",
            "chemical_representation": "SMILES strings",
            "target_application": "General molecule generation and optimization (demonstration: optimize Tanimoto similarity to a target small molecule — vitamin C); examples used druglike molecules and similarity-guided search.",
            "constraints_used": "Prompt-provided parent examples and scores; low-temperature sampling (&lt;0.1); repeated retries for invalid outputs; no explicit synthetic-accessibility or toxicity filters reported.",
            "integration_with_external_tools": "External scoring function computing Tanimoto similarity (used to evaluate candidates); embedding + SVM pipeline (GPT-2 tokenizer + scikit-learn SVM) used to embed/ retrieve relevant prior structures outside the context window. Tooling for exact similarity calculator not named but an external fingerprint/Tanimoto calculator was used.",
            "dataset_used": "Ad hoc example sets from the hackathon: 30 parent SMILES with associated Tanimoto scores used as few-shot context; additional small drug-like molecules used for fragmentation experiments (no standard public generative training dataset used for the generation experiments).",
            "evaluation_metrics": "Validity of SMILES (qualitative counts), success rate of fragmentation, expert human chemical reasonableness (binary judgments), and property-improvement metric (Tanimoto similarity progression across generations).",
            "reported_results": "Fragmentation: GPT-3.5 (no fine-tuning) fragmented SMILES at rotatable bonds with ~70% success. In a 10-molecule test: 2/10 fragments produced were not part of the original molecule; 1/10 molecules could not produce valid SMILES even after ten attempts. Expert evaluation: in a blind comparison 32/32 LLM-GA generated molecules were judged chemically reasonable, versus 21/32 for random recombination. Iterative optimization runs (25 SMILES per generation, repeated over ~20 iterations) produced multiple new best molecules (plots show best/mean Tanimoto similarity improving per generation), but exact numerical improvement values for the similarity were not reported in tabular form.",
            "experimental_validation": false,
            "challenges_or_limitations": "Models often output invalid SMILES without retries or prompt engineering; some fragments/mutations not chemically faithful to parents; outputs can be non-deterministic and require many sampling attempts; context-length limits constrain how many parent examples can be given; no synthesis feasibility or ADMET/safety filters were applied; reliability and robustness across chemistries not established; need for systematic benchmarking against conventional GA methods and generative models.",
            "uuid": "e6867.0",
            "source_info": {
                "paper_title": "14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "LLM-as-GA Tanimoto optimization (detailed)",
            "name_full": "Iterative in-context LLM optimization of molecular similarity (Tanimoto) demonstrated in hackathon",
            "brief_description": "Concrete hackathon demonstration of using GPT-3.5-turbo as the proposal mechanism in an evolutionary-style loop to maximize Tanimoto similarity to a target (vitamin C). The LLM receives a few-shot set of high-scoring parent SMILES and is prompted to produce candidate SMILES for the next generation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo (OpenAI)",
            "model_type": "decoder-only LLM; few-shot in-context generation used iteratively as a proposal operator within a GA-like loop",
            "model_size": "not specified",
            "training_data_description": "Pretrained OpenAI GPT-3.5-family weights (details not provided in paper).",
            "generation_method": "Few-shot prompting with example SMILES and associated scores; LLM asked to output a list of SMILES predicted to improve scores; iterative loop where top candidates are re-scored externally and the top performers seed the next prompt; low-temperature sampling used to reduce stochasticity.",
            "chemical_representation": "SMILES",
            "target_application": "Proof-of-concept property optimization (similarity to vitamin C) and general molecule optimization workflows (could be applied to optimizing other computed properties).",
            "constraints_used": "Prompted instructions and example-based guidance; temperature set low (&lt;&lt; 0.1) to enforce adherence to pattern; similarity-based selection used externally to decide survivors; no chemical-synthesis or ADMET constraints applied.",
            "integration_with_external_tools": "External Tanimoto similarity calculator used to score candidates; GPT-2 tokenizer + SVM embedding from scikit-learn used to include previous structures outside context window. (Exact fingerprinting library not explicitly named in text.)",
            "dataset_used": "30 top parent SMILES included per prompt; vitamin C target for similarity metric. No large standard generative training dataset used for this procedural experiment.",
            "evaluation_metrics": "Tanimoto similarity to target (per-candidate), best and mean similarity per generation; expert visual/chemical reasonableness scoring by organic chemists; SMILES validity rate.",
            "reported_results": "Multiple generations produced new best-scoring molecules (plots reported). No absolute numerical Tanimoto trajectories were reported in tables; qualitative statement that multiple new best molecules were found. Expert assessment indicated LLM-produced modifications were more chemically sound than quasi-random GA string-splicing.",
            "experimental_validation": false,
            "challenges_or_limitations": "Invalid SMILES sometimes produced (necessitating retries); stochastic generation requires many samples; lacking synthesis feasibility checks; results are preliminary and require systematic comparison to conventional GA and generative-model baselines; context-window limits number of seed examples.",
            "uuid": "e6867.1",
            "source_info": {
                "paper_title": "14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ScholarBERT screening (GlobusLabs)",
            "name_full": "ScholarBERT-based contextual screening for hydrogen carrier molecules (GlobusLabs team)",
            "brief_description": "Screening approach that uses ScholarBERT sentence/context embeddings aggregated per molecule (from a large corpus of scientific text) to rank candidate molecules for a target application (hydrogen carriers) by cosine similarity to known carriers; intended as a literature-context driven candidate prioritization method rather than de novo generative chemistry.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ScholarBERT",
            "model_type": "encoder (BERT-style) contextual embedding model used for retrieval and similarity ranking",
            "model_size": "not specified",
            "training_data_description": "ScholarBERT trained on a large corpus of scientific articles (Public.Resource.Org collection cited: ~75M English-language research articles); science-focused pretraining/finetuning described in the ScholarBERT reference.",
            "generation_method": "Not generative: retrieval/embedding-based screening. For each candidate molecule, sentences mentioning the molecule were found in the corpus; contextual token embeddings for those sentences were averaged (three aggregation strategies tested) to create a fingerprint; candidates were ranked by cosine similarity to embeddings of known hydrogen carriers.",
            "chemical_representation": "Molecule names (text mentions in literature); mapping of names to chemical structures for downstream evaluation.",
            "target_application": "Discovery/prioritization of hydrogen carrier molecules for energy storage (application-specific screening).",
            "constraints_used": "Three candidate sets evaluated: Known (78 known hydrogen carriers), Relevant (577 structurally similar molecules), Random (111 PubChem random molecules); no explicit chemical-property constraints applied during initial ranking stage; downstream rigorous energy/thermodynamic computations used for validation on selected hits.",
            "integration_with_external_tools": "Downstream quantum-chemistry calculations used to compute energy capacity (wt% H2) and energy penalty (kJ/mol/H2) for candidates (traditional quantum chemistry used as validation), executed separately on CPU clusters. PubChem used as a source for random candidate selection.",
            "dataset_used": "Public.Resource.Org corpus for contexts (~75M articles). Candidate datasets: Known = 78, Relevant = 577, Random = 111 (PubChem).",
            "evaluation_metrics": "Enrichment / ranking quality measured qualitatively versus random baseline; downstream quantitative metrics computed by quantum chemistry: gravimetric H2 capacity (wt%) and energy penalty (kJ/mol H2); throughput/speed comparison between screening pipeline and quantum calculations.",
            "reported_results": "ScholarBERT approach recommended molecules with a success rate better than random (qualitative); screening throughput ~100 molecules/second on a V100 GPU (embedding-based screening) versus ~30 seconds per molecule for quantum-chemistry validation on a 64-core Intel Xeon Phi — a reported ~3000x speedup in screening throughput. No absolute values for H2 capacity or energy penalty of specific candidates were tabulated in the paper.",
            "experimental_validation": false,
            "challenges_or_limitations": "Biases in retrieved candidates (tendency to favor 5- and 6-membered rings and halogenated species observed); need for more systematic benchmarking versus conventional generative and screening methods; dependency on literature coverage and naming/mention ambiguity; mapping from textual mentions to unambiguous chemical structures can be noisy and requires careful entity resolution.",
            "uuid": "e6867.2",
            "source_info": {
                "paper_title": "14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "LLM agent tool-augmented synthesis planning (mentions)",
            "name_full": "LLM agents augmented with external chemistry tools (ChemCrow / cloud-lab agents / MAPI-LLM mentions)",
            "brief_description": "Multiple cited/mentioned works and hackathon prototypes demonstrate giving LLMs access to external chemistry tools (search engines, retrosynthesis planners, databases, laboratory APIs, reaction predictors) to plan, rank, or even execute syntheses; these are mentions in the paper and not new experiments presented here.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Various (ChatGPT / GPT-3.5 / GPT-4 referenced in discussion; project-specific agents such as ChemCrow cited)",
            "model_type": "Tool-using LLM agents (ReAct/MRKL paradigms) that combine language-model reasoning with external API/tool calls",
            "model_size": "varies / not specified in paper",
            "training_data_description": "Pretrained foundation LLMs (OpenAI models) and tool-specific documentation; papers cited describe augmentations rather than new pretraining datasets.",
            "generation_method": "Not direct molecular string generation alone — LLMs are used to orchestrate calls to external tools (retrosynthesis engines, reaction predictors, databases, cloud lab APIs) to plan or attempt synthesis; in some cited systems LLMs can trigger experiments via cloud lab APIs.",
            "chemical_representation": "Varies by tool (SMILES, textual names, reaction SMARTS, structured APIs); LLM operates on natural language plus calls to tool-specific structured inputs/outputs.",
            "target_application": "Retrosynthesis planning, automated lab execution, synthesis planning, workflow orchestration, and multi-tool retrosynthesis/analysis pipelines.",
            "constraints_used": "Tool-level constraints (safety, API limits) depend on the integrated external systems; no single constraint set described in this paper.",
            "integration_with_external_tools": "Cited examples include Google Search, IBM RXN retrosynthesis tool, Materials Project API, Open Reaction Database, and cloud lab APIs; the paper specifically references ChemCrow (LLM augmented with chemistry tools) and Boiko et al. (LLM+cloud lab execution) as literature examples.",
            "dataset_used": "Depends on integrated tool (reaction databases, literature corpora); examples cited reference public databases and tool APIs rather than new LLM training datasets.",
            "evaluation_metrics": "Not consistently standardized across cited works; reported metrics in the literature include task success rates, accuracy of predicted routes, reliability of tool calls, and ability to execute workflows, but specific quantitative metrics are not tabulated in this paper.",
            "reported_results": "This paper cites prior work and describes hackathon prototypes showing that tool-augmented LLM agents can combine resources to answer complex materials/chemistry prompts that neither tools nor the LLM could solve alone; no novel quantitative experimental synthesis validations are reported here.",
            "experimental_validation": null,
            "challenges_or_limitations": "Dependence on tool availability and versions, brittleness of agent orchestration, hallucination risk if tools are not used or results misinterpreted, reproducibility challenges (tool and model versioning), safety and dual-use concerns for automated synthesis planning/execution, limited transparency into proprietary LLM internals when using closed APIs.",
            "uuid": "e6867.3",
            "source_info": {
                "paper_title": "14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Flam‑Shepherd / Aspuru‑Guzik (cited)",
            "name_full": "Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files (Flam‑Shepherd & Aspuru‑Guzik)",
            "brief_description": "Cited preprint claiming language models can directly generate 3D coordinates for molecules, materials, and proteins (XYZ/CIF/PDB formats), representing an extension of LLM capabilities to geometry-aware molecular generation; discussed in the paper as related work but not used in the hackathon experiments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Not specified in this paper (referenced external preprint)",
            "model_type": "Language-model based generative system capable of producing 3D coordinate files (per the cited preprint)",
            "model_size": "not specified here",
            "training_data_description": "Not described in this paper (see cited preprint for details).",
            "generation_method": "Direct generation of 3D coordinate files (XYZ/CIF/PDB) from language models (as reported by the cited preprint).",
            "chemical_representation": "3D coordinate files (XYZ, CIF, PDB) and presumably standard textual/graph representations as scaffolding.",
            "target_application": "De novo generation of molecular/material geometries and protein binding sites (structural design), enabling geometry-aware generative design.",
            "constraints_used": "Not described in this paper.",
            "integration_with_external_tools": "Not described here; likely evaluated with molecular validation tools in the cited work.",
            "dataset_used": "Not described here; see referenced preprint for dataset details.",
            "evaluation_metrics": "Not reported in this paper (see cited preprint).",
            "reported_results": "Mentioned as an example of language-model-driven molecular generation in the literature; no numbers reported here.",
            "experimental_validation": null,
            "challenges_or_limitations": "Referenced as promising direction; the paper notes general limitations across literature such as tokenization mismatches, chemical validity issues, and the need for chemistry-specific tokenization or foundation models for chemistry.",
            "uuid": "e6867.4",
            "source_info": {
                "paper_title": "14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files",
            "rating": 2,
            "sanitized_title": "language_models_can_generate_molecules_materials_and_protein_binding_sites_directly_in_three_dimensions_as_xyz_cif_and_pdb_files"
        },
        {
            "paper_title": "ChemCrow: Augmenting large-language models with chemistry tools",
            "rating": 2,
            "sanitized_title": "chemcrow_augmenting_largelanguage_models_with_chemistry_tools"
        },
        {
            "paper_title": "Is GPT-3 all you need for low-data discovery in chemistry?",
            "rating": 2,
            "sanitized_title": "is_gpt3_all_you_need_for_lowdata_discovery_in_chemistry"
        },
        {
            "paper_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
            "rating": 1,
            "sanitized_title": "extracting_structured_seedmediated_gold_nanorod_growth_procedures_from_literature_with_gpt3"
        },
        {
            "paper_title": "Bayesian Optimization of Catalysts With In-context Learning",
            "rating": 1,
            "sanitized_title": "bayesian_optimization_of_catalysts_with_incontext_learning"
        }
    ],
    "cost": 0.025667,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>4 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon
14 Jul 2023</p>
<p>Kevin Maik Jablonka 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>Qianxiang Ai 
Department of Chemical Engineering
Massachusetts Institute of Technology
02139CambridgeMassachusettsUnited States</p>
<p>Alexander Al-Feghali 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Shruti Badhwar 
Reincarnate Inc</p>
<p>Joshua D Bocarsly 
Yusuf Hamied Department of Chemistry
University of Cambridge
Lensfield RoadCB2 1EWCambridgeUnited Kingdom</p>
<p>Andres M Bran 
Laboratory of Artificial Chemical Intelligence (LIAC), Institut des Sciences et Ingénierie Chimiques, Ecole Polytechnique Fédérale de Lausanne (EPFL)
LausanneSwitzerland</p>
<p>National Centre of Competence in Research (NCCR) Catalysis, Ecole Polytechnique Fédérale de Lausanne (EPFL)
LausanneSwitzerland</p>
<p>Stefan Bringuier 
Independent Researcher
San DiegoCAUnited States</p>
<p>L Catherine Brinson 
Mechanical Engineering and Materials Science, Duke University, United States. 10 Material Measurement Laboratory
National Institute of Standards and Technology, Maryland
20899United States</p>
<p>Kamal Choudhary 
Defne Circi 
Mechanical Engineering and Materials Science, Duke University, United States. 10 Material Measurement Laboratory
National Institute of Standards and Technology, Maryland
20899United States</p>
<p>Sam Cox 
Department of Chemical Engineering
University of Rochester
United States</p>
<p>Wibe A De Jong 
Applied Mathematics and Computational Research Division, Lawrence Berkeley National Laboratory
94720BerkeleyCAUnited States</p>
<p>Matthew L Evans 
Institut de la Matière Condensée et des Nanosciences (IMCN)
UCLouvain, Chemin desÉtoiles 8, Louvain-la-Neuve1348Belgium</p>
<p>Matgenix SRL
185 Rue Armand Bury6534GozéeBelgium</p>
<p>Nicolas Gastellu 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Jerome Genzling 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Victoria María 
Gil 
Instituto de Ciencia y Tecnología del Carbono (INCAR), CSIC
Francisco Pintado Fe 2633011OviedoSpain</p>
<p>Ankur K Gupta 
Applied Mathematics and Computational Research Division, Lawrence Berkeley National Laboratory
94720BerkeleyCAUnited States</p>
<p>Zhi Hong 
Department of Computer Science
University of Chicago
60637ChicagoIllinoisUnited States</p>
<p>Alishba Imran 
Computer Science
University of California
18 Bundesanstalt für Materialforschung und -prüfung, Unter den Eichen 8794704, 12205Berkeley, BerlinBerkeley CAUnited States., Germany</p>
<p>Sabine Kruschwitz 
Anne Labarre 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Jakub Lála 
Francis Crick Institute
1 Midland RdNW1 1ATLondonUnited Kingdom</p>
<p>University of Wisconsin-Madison
53706MadisonWIUnited States</p>
<p>Tao Liu 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Steven Ma 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Sauradeep Majumdar 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>Garrett W Merz 
Nicolas Moitessier 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Elias Moubarak 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>Beatriz Mouriño 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>Brenden Pelkie 
Department of Chemical Engineering
University of Washington
98105SeattleWAUnited States</p>
<p>Michael Pieler 
Caldas Mayk 
Ramos 
Department of Chemical Engineering
University of Rochester
United States</p>
<p>Bojana Ranković 
Laboratory of Artificial Chemical Intelligence (LIAC), Institut des Sciences et Ingénierie Chimiques, Ecole Polytechnique Fédérale de Lausanne (EPFL)
LausanneSwitzerland</p>
<p>National Centre of Competence in Research (NCCR) Catalysis, Ecole Polytechnique Fédérale de Lausanne (EPFL)
LausanneSwitzerland</p>
<p>Samuel G Rodriques 
Francis Crick Institute
1 Midland RdNW1 1ATLondonUnited Kingdom</p>
<p>University of Wisconsin-Madison
53706MadisonWIUnited States</p>
<p>Jacob N Sanders 
Department of Chemistry and Biochemistry
University of California
90095Los AngelesCAUnited States</p>
<p>Philippe Schwaller 
Laboratory of Artificial Chemical Intelligence (LIAC), Institut des Sciences et Ingénierie Chimiques, Ecole Polytechnique Fédérale de Lausanne (EPFL)
LausanneSwitzerland</p>
<p>National Centre of Competence in Research (NCCR) Catalysis, Ecole Polytechnique Fédérale de Lausanne (EPFL)
LausanneSwitzerland</p>
<p>Marcus Schwarting 
Department of Computer Science
University of Chicago
60490ChicagoILUnited States</p>
<p>Jiale Shi 
Department of Chemical Engineering
Massachusetts Institute of Technology
02139CambridgeMassachusettsUnited States</p>
<p>Berend Smit 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>Ben E Smith 
Yusuf Hamied Department of Chemistry
University of Cambridge
Lensfield RoadCB2 1EWCambridgeUnited Kingdom</p>
<p>Joren Van Herck 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>Christoph Völker 
Logan Ward 
Department of Computer Science
Data Science and Learning Division, Argonne National Lab, United States. 27 Globus, University of Chicago, Data Science and Learning Division, Argonne National Lab, United States. 28
University of Chicago</p>
<p>Sean Warren 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Benjamin Weiser 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Sylvester Zhang 
Department of Chemistry
McGill University
MontrealQuebecCanada</p>
<p>Xiaoqi Zhang 
Institut des Sciences et Ingénierie Chimiques
Laboratory of Molecular Simulation (LSMO)
Ecole Polytechnique Fédérale de Lausanne (EPFL)
Sion, ValaisSwitzerland</p>
<p>† Ghezal 
Ahmad Zia 
Aristana Scourtas 
K J Schmidt 
Ian Foster 
Andrew D White 
Department of Chemical Engineering
University of Rochester
United States</p>
<p>Ben Blaiszik 
Department of Chemical Engineering
Massachusetts Institute of Technology
02139CambridgeMassachusettsUnited States</p>
<p>Stability Ai 
4 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon
14 Jul 202320 American Family Insurance Data Science Institute, Data Science and Learning Division, Argonne National Lab, United States.
Large-language models (LLMs) such as GPT-4 caught the interest of many scientists. Recent studies suggested that these models could be useful in chemistry and materials science. To explore these possibilities, we organized a hackathon.This article chronicles the projects built as part of this hackathon. Participants employed LLMs for various applications, including predicting properties of molecules and materials, designing novel interfaces for tools, extracting knowledge from unstructured data, and developing new educational applications.The diverse topics and the fact that working prototypes could be generated in less than two days highlight that LLMs will profoundly impact the future of our fields. The rich collection of ideas and projects also indicates that the applications of LLMs are not limited to materials science and chemistry but offer potential benefits to a wide range of scientific disciplines.XiaoqZhang/i-Digest 10.5281/zenodo.8080962 projects show that natural language might be the universal "glue" connecting our toolsperhaps in the future, we will need not to focus on new formats or standards but rather use natural language descriptions to connect across the existing diversity and different modalities [35].LLMs can also help make knowledge more accessible, as the projects in the "knowledge extraction" category show; they can extract structured information from unstructured text. In addition, as the project in the "education" category shows, LLMs can also offer new educational opportunities.A. Predictive modelingPredictive modeling is a common application of ML in chemistry. Based on the language-interfaced fine-tuning (LIFT) framework [37], Jablonka et al. [32]  have shown</p>
<p>I. INTRODUCTION</p>
<p>The intersection of machine learning (ML) with chemistry and materials science has witnessed remarkable advancements in recent years [1][2][3][4][5][6][7][8][9]. Much progress has been made in using ML to, e.g., accelerate simulations [10,11] or to directly predict properties or compounds for a given application [12]. Thereby, developing custom, hand-crafted models for any given application is still common practice. Since science rewards doing novel things for the first time, we now face a deluge of tools and machine-learning models for various tasks. These tools commonly require input data in their own rigid, welldefined form (e.g., a table with specific columns or images from a specific microscope with specific dimensions). Further, they typically also report their outputs in non-standard and sometimes proprietary forms.</p>
<p>This rigidity sharply contrasts the standard practice in the (experimental) molecular and materials sciences, which is intrinsically fuzzy and highly context-dependent [13].</p>
<p>For instance, researchers have many ways to refer to a molecule (e.g., IUPAC name, conventional name, simplified molecular-input line-entry system (SMILES) [14]) and to report results and procedures. In particular, for the latter, it is known that small details such as the order of addition or the strength of stirring (e.g., "gently" vs. "strongly") are crucial in determining the outcome of reactions. We do not have a natural way to deal with this fuzziness, and often a conversion into structured tabular form (the conventional input format for ML models) is impossible. Our current "solution" is to write conversion programs and chain many tools with plenty of application-specific "glue code" to enable scientific workflows. However, this fuzziness chemistry and heterogeneity of tools have profound consequences: A never-ending stream of new file formats, interfaces, and interoperability tools exists, and users cannot keep up with learning [15]. In addition, almost any transformation of highly context-dependent text (e.g., description of a reaction procedure) into structured, tabular form will lead to a loss of information.</p>
<p>One of the aims of this work is to demonstrate how large language models (LLMs) such as the generative pretrained transformer (GPT)-4 [16][17][18][19][20][21], can be used to address these challenges. Foundation models such as GPTs are general-purpose technologies [22] that can solve tasks they have not explicitly been trained on [23,24], use tools [25][26][27], and be grounded in knowledge bases [28,29]. As we also show in this work, they provide new pathways of exploration, new opportunities for flexible interfaces, and may be used to effectively solve certain tasks themselves; e.g., we envision LLMs enabling non-experts to program ("malleable software") using natural language as the "programming language" [30], extract structured information, and create digital assistants that make our tools interoperable-all based on unstructured, natural-language inputs. Inspired by early reports on the use of these LLMs in chemical research [31][32][33][34], we organized a virtual hackathon event focused on understanding the applicability of LLMs to materials science and chemistry. The hackathon aimed to explore the multifaceted applications of LLMs in materials science and chemistry and encourage creative solutions to some of the pressing challenges in the field. This article showcases some of the projects (Table I) developed during the hackathon.</p>
<p>One of the conclusions of this work is that without these LLMs, such projects would take many months. The diversity of topics these projects address illustrates the broad applicability of LLMs; the projects touch many different aspects of materials science and chemistry, from the wet lab to the computational chemistry lab, software interfaces, and even the classroom. While the examples below are not yet polished products, the simple observation that such capabilities could be created in hours underlines that we need to start thinking about how LLMs will impact the future of materials science, chemistry, and beyond [35]. The diverse applications show that LLMs are here to stay and are likely a foundational capability that will be integrated into most aspects of the research process.</p>
<p>Even so, the pace of the developments highlights that we are only beginning to scratch the surface of what LLMs can do for chemistry and materials science. Table I lists the different projects created in this collaborative effort across eight countries and 22 institutions (SI section V). One might expect that 1.5 days of intense collaborations would, at best, allow a cursory exploration of a topic. However, the diversity of topics and the diversity in the participants' expertise, combined with the need to deliver a working prototype (within a short window of time) and the ease of prototyping with LLMs, generated not only many questions but also pragmatic solutions. In the remainder of this article, we focus on the insights we obtained from this collective effort. For the details of each project, we refer to the SI.</p>
<p>We have grouped the projects into four categories: 1. predictive modeling, 2. automation and novel interfaces, 3. knowledge extraction, and 4. education. The projects in the predictive modeling category use LLMs for classification and regression tasks-and also investigate ways to incorporate established concepts such as ∆-ML [36] or novel concepts such as "fuzzy" context into the modeling. The automation and novel interfaces that LLMs can be employed to predict various chemical properties, such as solubility or HOMO-LUMO gaps based on line representations of molecules such as self-referencing embedded strings (SELFIES) [38,39] and SMILES. Taking this idea even further, Ramos et al. [34] used this framework (with in-context learning (ICL)) for Bayesian optimization-guiding experiments without even training models.</p>
<p>The projects in the following build on top of those initial results and extend them in novel ways as well as by leveraging established techniques from quantum machine learning.</p>
<p>Given that these encouraging results could be achieved with and without fine-tuning (i.e., updates to the weights of the model) for the language-interfaced training on tabular datasets, we use the term LIFT also for ICL settings in which structured data is converted into text prompts for an LLM.</p>
<p>a. Molecular Energy Predictions</p>
<p>A critical property in quantum chemistry is the atomization energy of a molecule, which gives us the basic thermochemical data used to determine a molecule's stability or reactivity. State-of-the-art quantum chemical methods (i.e., G4(MP2) [40]) can predict this energy with an accuracy of 0.034 eV (or 0.79 kcal/mol) [41,42]. This accuracy is similar to, and in some cases even better than, the accuracy that can be reached experimentally. This motivated Ramakrishnan et al. [41] and Narayanan et al. [42] to compute these atomization energies for the 134,000 molecules in the QM9-G4MP2 dataset.</p>
<p>The Berkeley-Madison team (Ankur Gupta, Garrett Merz, Alishba Imran, and Wibe de Jong) used this dataset to fine-tune different LLMs using the LIFT framework. The team investigated if they could use an LLM to predict atomization energies with chemical accuracy. Jablonka et al. [32] emphasized that these LLMs might be particularly useful in the low-data limit. Here, we have a relatively large dataset, so it is an ideal system to gather insights into the performance of these models for datasets much larger than those used by Jablonka et al. [32].</p>
<p>The Berkeley-Madison team showed that the LIFT framework based on simple line representations such as SMILES and SELFIES [38,39] can yield good predictions (R 2 &gt; 0.95 on a holdout test set), that are, however, still inferior to dedicated models that have access to 3D information [43,44]. An alternative approach to achieve chemical accuracy with LLMs tuned only on string representations is to leverage a ∆-ML scheme [45] in which the LLM is tuned to predict the difference between G4(MP2) and B3LYP [46] Table II: LIFT for molecular atomization energies on the QM9-G4MP2 dataset. Metrics for models tuned on 90% of the QM9-G4MP2 dataset (117,232 molecules), using 10% (13,026 molecules) as a holdout test set. GPTChem refers to the approach reported by Jablonka et al. [32], GPT-2-LoRA to PEFT of the GPT-2 model using LoRA. The results indicate that the LIFT framework can also be used to build predictive models for atomization energies, that can reach chemical accuracy using a ∆-ML scheme. Baseline performance (mean absolute error reported by Ward et al. [44]): 0.0223 eV for FCHL-based prediction of GP4(MP2) atomization energies and 0.0045 eV (SchNet) and 0.0052 eV (FCHL) for the ∆-ML scheme. mol energies. Table II shows that good agreement could be achieved for the ∆-ML approach.</p>
<p>This showcases how techniques established for conventional ML on molecules can also be applied with LLMs.</p>
<p>Importantly, this approach is not limited to the OpenAI application programming interface (API). With parameter efficient fine-tuning (PEFT) with low-rank adaptors (LoRA) [47] of the GPT-2 model [48], one can also obtain comparable results on consumer hardware. These results make the LIFT approach widely more accessible and allow research to the LIFT framework for chemistry without relying on OpenAI.</p>
<p>b. Text2Concrete</p>
<p>Concrete is the most used construction material, and the mechanical properties and climate impact of these materials are a complex function of the processing and formulation. Much research is focused on formulations of concrete that are less CO 2 intensive. [49] To expedite the design process, e.g., by prioritizing experiments using ML-predictions, data-driven methods have been investigated by Völker et al. [50] The Text2Concrete team (Sabine Kruschwitz, Christoph Völker, and Ghezal Ahmad Zia) explored, based on data reported by Rao and Rao [51], whether LLMs can be used for this task. This data set provides 240 alternative, more sustainable, concrete formulations and their respective compressive strengths. From a practical point of view, one would like to have a model that can predict the compressive strength of the concrete as a function of its formulation.</p>
<p>Interestingly, the largest LLMs can already give predictions without any fine-tuning.</p>
<p>These models can "learn" from the few examples provided by the user in the prompt.</p>
<p>Of course, such a few-shot approach (or ICL, [20]) does not allow for the same type of optimization as fine-tuning, and one can therefore expect it to be less accurate. However, Ramos et al. [34] showed that this method could perform well-especially if only so few data points are available such that fine-tuning is not a suitable approach.</p>
<p>For their case study, the Text2Concrete team found a predictive accuracy comparable to a Gaussian process regression (GPR) model (but inferior to a random forest (RF) model). However, one significant advantage of LLMs is that one can easily incorporate context. The Text2Concrete team used this to include well-established design principles like the influence of the water-to-cement ratio on strength ( Figure 1) into the modeling by simply stating the relationship between the features in natural language (e.g., "high water/cement ratio reduces strength"). This additional context reduced the outliers and outperformed the RF model (R 2 of 0.67 and 0.72, respectively).</p>
<p>The exciting aspect is that this is a typical example of domain knowledge that cannot be captured with a simple equation incorporable into conventional modeling workflows.</p>
<p>Such "fuzzy" domain knowledge, which may sometimes exist only in the minds of researchers, is common in chemistry and materials science. With the incorporation of such "fuzzy" knowledge into LIFT-based predictions using LLMs, we now have a novel and very promising approach to leverage such domain expertise that we could not leverage before. Interestingly, this also may provide a way to test "fuzzy" hypotheses, e.g., a researcher could describe the hypothesis in natural language and see how it affects the model accuracy. While the Text2Concrete example has not exhaustively analyzed how "fuzzy" context alterations affect LLM performance, we recognize this as a key area for future research that could enhance the application of LLMs and our approach to leveraging "fuzzy" domain knowledge within materials science.</p>
<p>c. Molecule Discovery by Context</p>
<p>Much context is available in the full text of scientific articles. This has been exploited by Tshitoyan et al. [52] who used a Word2Vec [53] approach to embed words into a vector space. Word2Vec does so by tasking a model to predict for a word the probability for all possible next words in a vocabulary. In this way, word embeddings capture syntactic and semantic details of lexical items (i.e., words). When applied to material science abstracts, the word embeddings of compounds such as Li 2 CuSb could be used for materials discovery by measuring their distance (cosine similarity) to concepts such as "thermoelectric". [54] However, traditional Word2Vec, as used by Tshitoyan et al. [52], only produces static embeddings, which remain unchanged after training. Word embeddings Figure 1: Using LLMs to predict the compressive strength of concretes. An illustration of the conventional approach for solving this task, i.e., training classical prediction models using ten training data points as tabular data (left). Using the LIFT framework LLMs can also use tabular data and leverage context information provided in natural language (right). The context can be "fuzzy" design rules often known in chemistry and materials science but hard to incorporate in conventional ML models. Augmented with this context and ten training examples, ICL with LLM leads to a performance that outperforms baselines such as RFs or GPR.</p>
<p>extracted from an LLM, on the other hand, are contextualized on the specific sequence (sentence) in which they are used and, therefore, can more effectively capture the contexts of words within a given corpus [55].  [58]. The efficiency of such a genetic algorithm often depends on how well the genes and genetic operations match the underlying chemistry. For example, if the algorithm replaces atom by atom, it may take several generations before a complete functional group is replaced.</p>
<p>One might hypothesize that LLMs can make the evolution process more efficient, e.g., by using an LLM to handle the reproduction. One might expect that inductive biases in the LLM help create recombined molecules which are more chemically viable, maintaining the motifs of the two parent molecules better than a random operation.</p>
<p>The team from McGill University (Benjamin Weiser, Jerome Genzling, Nicolas Gastellu, Sylvester Zhang, Tao Liu, Alexander Al-Feghali, Nicolas Moitessier) set out the first steps to test this hypothesis ( Figure 2). In initial experiments, they found that GPT-3.5, without any finetuning, can fragment molecules provided as SMILES at rotatable bonds with a success rate of 70 %. This indicates that GPT-3.5 understands SMILES strings and aspects of their relation to the chemical structures they represent.</p>
<p>Subsequently, they asked the LLMs to fragment and recombine two given molecules. The LLM frequently created new combined molecules with fragments of each species which were reasonable chemical structures more often than a random SMILES string combining Figure 2: GA using an LLM. This figure illustrates how different aspects of a GA can be performed by an LLM. GPT-3.5 was used to fragment, reproduce, and optimize molecules represented by SMILES strings. The first column illustrated how an LLM can fragment a molecule represented by a SMILES string (input molecule on top, output LLM fragments below). The middle column showcases how an LLM can reproduce/mix two molecules as is done in a GA (input molecule on top, output LLM below). The right column illustrates an application in which an LLM is used to optimize molecules given their SMILES and an associated score. The LLM suggested potential modifications to optimize molecules. The plot shows best (blue) and mean (orange) Tanimoto similarity to Vitamin C per LLM produced generations.</p>
<p>operation (two independent organic chemists judged the LLM-GA-generated molecules to be chemically reasonable in 32 /32 cases, but only in 21 /32 cases for the random recombination operation).</p>
<p>Encouraged by these findings, they prompted an LLM with 30 parent molecules and their performance scores (Tanimoto similarity to vitamin C) with the task to come up with n new molecules that the LLM "believes" to improve the score. A preliminary visual inspection suggests that the LLM might produce chemically reasonable modifications.</p>
<p>Future work will need to systematically investigate potential improvements compared to conventional GAs.</p>
<p>The importance of the results of the McGill team is that they indicate that these LLMs (when suitably conditioned) might not only reproduce known structures but generate new structures that make chemical sense [32,59].</p>
<p>A current limitation of this approach is that most LLMs still struggle to output valid SMILES without explicit fine-tuning [33]. We anticipate that this problem might be mitigated by building foundation models for chemistry (with more suitable tokeniza-tion [60,61]), as, for instance, the ChemNLP project of OpenBioML.org attempts to do (https://github.com/OpenBioML/chemnlp). In addition, the context length limits the number of parent molecules that can be provided as examples.</p>
<p>Overall, we see that the flexibility of the natural language input and the in-context learning abilities allows using LLMs in very different ways-to very efficiently build predictive models or to approach molecular and material design in entirely unprecedented ways, like by providing context-such as "fuzzy" design rules-or simply prompting the LLM to come up with new structures. However, we also find that some "old" ideas, such as ∆-ML and data augmentation, can also be applied in this new paradigm.</p>
<p>B. Automation and novel interfaces</p>
<p>Yao et al. [62] and Schick et al. [25] have shown that LLMs can be used as agents that can autonomously make use of external tools such as Web-APIs-a paradigm that some call MRKL (pronounced "miracle") Systems-modular reasoning, knowledge, and language systems [26]. By giving LLMs access to tools and forcing them to think step-bystep [63], we can thereby convert LLMs from hyperconfident models that often hallucinate to systems that can reason based on observations made by querying robust tools. As the technical report for GPT-4 highlighted [64], giving LLMs access to tools can lead to emergent behavior, i.e., enabling the system to do things that none of its parts could do before. In addition, this approach can make external tools more accessible-since users no longer have to learn tool-specific APIs. It can also make tools more interoperable-by using natural language instead of "glue code" to connect tools. </p>
<p>b. sMolTalk</p>
<p>The previous application already touches on the problem that software for chemical applications requires scientists to invest a significant amount of time in learning even the most basic applications. An example of this is visualization software. Depending on the package and its associated documentation, chemists and materials scientists might spend hours to days learning the details of specific visualization software that is sometimes poorly documented. And in particular, for occasional use, if it takes a long time to learn the basics, it won't be used. It uses LLMs to process the user's input and decide which available tools (e.g., Materials Project API, the Reaction-Network package, and Google Search) to use following an iterative chain-of-thought procedure. In this way, it can answer questions such as "Is the material AnByCz stable?".</p>
<p>As the sMolTalk-team (Jakub Lála, Sean Warren, Samuel G. Rodriques) showed, one can use LLMs to write code for visualization tools such as 3dmol.js to address this inefficiency [68]. Interestingly, few-shot prompting with several examples of user input with the expected JavaScript code that manipulates the 3dmol.js viewer is all that is needed to create a prototype of an interface that can retrieve protein structures from the protein data bank (PDB) and create custom visualization solutions, e.g., to color parts of a structure in a certain way ( Figure 4). The beauty of the language models is that the user can write the prompt in many different ("fuzzy") ways: whether one writes "color" or "colour", or terms like "light yellow" or "pale yellow" the LLM translates it into something the visualization software can interpret.</p>
<p>However, this application also highlights that further developments of these LLMbased tools are needed. For example, a challenge the sMolTalk tool faces is robustness.</p>
<p>For instance, fragments from the prompt tend to leak into the output and must be handled with more involved mechanisms, such as retries in which one gives the LLMs access to the error messages or prompt engineering. Further improvement can also be expected if the application leverages a knowledge base such as the documentation of 3dmol.js.</p>
<p>As the work of Glenn Hocky and Andrew White shows [69], an LLM-interface for software can also be used with other programs such as VMD [70] and extended with speechto-text models (such as Whisper [71]) to enable voice control of such programs. In particular, such an LLM-based agent approach might be implemented for the PyMOL program, where various tools for protein engineering could be interfaced through a chat interface, lowering the barrier to entry for biologists to use recent advancements within in silico protein engineering (such as RosettaFold [72] or RFDiffusion [73]).</p>
<p>c. ELN interface: whinchat</p>
<p>In addition to large, highly curated databases with well-defined data models [74] (such as those addressed by the MAPI-LLM project), experimental materials and chemistry data is increasingly being captured using digital tools such as ELNs and or laboratory information systems (LIMS). Importantly, these tools can be used to record both struc-tured and unstructured lab data in a manner that is actionable by both humans and computers. However, one challenge in developing these systems is that it is difficult for a traditional user interface to have enough flexibility to capture the richness and diversity of real, interconnected, experimental data. Interestingly, LLMs can interpret and contextualize both structured and unstructured data and can therefore be used to create a novel type of flexible, conversational interface to such experimental data. It is easy to envision that this tool could be even more helpful by fine-tuning or conditioning it on a research group's knowledge base (e.g., group Wiki or standard operating procedures) and communication history (e.g., a group's Slack history). An important limitation of the current implementation is that the small context window of available LLMs limits the amount of JSON data one can directly provide within the prompt, limiting each conversation to analyzing a relatively small number of samples. Therefore, one needs to either investigate the use of embeddings to determine which samples to include in the context or adopt an "agent" approach where the assistant is allowed to query the API of the ELN (interleaved with extraction and summarization calls).</p>
<p>d. BOLLaMa: facilitating Bayesian optimization with large language models</p>
<p>Bayesian optimization (BO) is a powerful tool for optimizing expensive functions, such as mapping of reaction conditions to the reaction yield. Chemists would greatly benefit from using this method to reduce the number of costly experiments they need Figure 5: Using an LLM as an interface to an ELN/data management system. LLM-based assistants can provide powerful interfaces to digital experimental data. The figure shows a screenshot of a conversation with whinchat in the datalab data management system (https:// github.com/the-grey-group/datalab). Here, whinchat is provided with data from the JSON API of datalab of an experimental battery cell. The user then prompts (green box) the system to build a flowchart of the provenance of the sample. The assistant responds with mermaid.js markdown code, which the datalab interface automatically recognizes and translates into a visualization.</p>
<p>to run [75,76]. However, BO faces an interface and accessibility problem, too. The existing frameworks require significant background knowledge and coding experience not conventionally taught in chemistry curricula. Therefore, many chemists cannot benefit from tools such as BO. The BOLLaMa-team (Bojana Ranković, Andres M. Bran, Philippe Schwaller) showed that LLMs can lower the barrier for the use of BO by providing a natural language chat-like interface to BO algorithms. Figure 6 shows a prototype of a chat interface in which the LLM interprets the user request, initializes a BO run by suggesting initial experimental conditions, and then uses the feedback of the user to drive the BO algorithm and suggest new experiments. The example used data on various additives for a cooperative nickel-photoredox catalyzed reaction [77] and the BO code from Ranković et al. [78]. This ideally synergizes with an LLM interface to a data management solution (as discussed in the previous project) as one could directly persist the experimental results and leverage prior records to "bootstrap" BO runs. As the examples in this section show, we find that LLMs have the potential to greatly enhance the efficiency of a diverse array of processes in chemistry and materials science by providing novel interfaces to tools or by completely automating their use. This can help streamline workflows, reduce human error, and increase productivity-often by replacing "glue code" with natural language or studying a software library by chatting with an LLM.</p>
<p>C. Knowledge Extraction</p>
<p>Beyond proving novel interfaces for tools, LLMs can also serve as powerful tools for extracting knowledge from the vast amount of chemical literature available. With LLMs, researchers can rapidly mine and analyze large volumes of data, enabling them to uncover novel insights and advance the frontiers of chemical knowledge. Tools such as paperqa [28] can help to dramatically cut down the time required for literature search by automatically retrieving, summarizing, and contextualizing relevant fragments from the entire corpus of the scientific literature-for example, answering questions (with suitable citations) based on a library of hundreds of documents [35]. As the examples in the Figure 7: The InsightGraph interface. A suitably prompted LLM can create knowledge graph representations of scientific text that can be visualized using tools such as neo4j's visualization tools. [81] previous section indicated, this is particularly useful if the model is given access to search engines on the internet.</p>
<p>a. InsightGraph</p>
<p>To facilitate downstream use of the information, LLMs can also convert unstructured data-the typical form of these literature reports-into structured data. The use of GPT for this application has been reported by Dunn et al. [79] and Walker et al. [80], who used an iterative fine-tuning approach to extract data structured in JSON from papers.</p>
<p>In their approach, initial </p>
<p>b. Extracting Structured Data from Free-form Organic Synthesis Text</p>
<p>Unstructured text is commonly used for describing organic synthesis procedures. Due to the large corpus of literature, manual conversion from unstructured text to struc- The Organic Synthesis Parser interface. The top box shows text describing an organic reaction (https://open-reaction-database.org/client/id/ord-1f99b308e17340cb8e0e3080c270fd08), which the finetuned LLM converts into structured JSON (bottom). A demo application can be found at https://qai222.github.io/LLM_ organic_synthesis/. tured data is unrealistic. However, structured data are needed for building conventional ML models for reaction prediction and condition recommendation. The Open Reaction Database (ORD) [82] is a database of curated organic reactions. In the ORD, while reaction data are structured by the ORD schema, many of their procedures are also available as plain text. Interestingly, an LLM (e.g., OpenAI's text-davinci-003) can, after finetuning on only 300 prompt-completion pairs, extract 93 % of the components from the free-text reaction description into valid JSONs ( Figure 8). Such models might significantly increase the data available for training models on tasks such as predicting reaction conditions and yields. It is worth noting that all reaction data submitted to ORD are made available under the CC-BY-SA license, which makes ORD a suitable data source for fine-tuning or training an LLM to extract structured data from organic procedures. A recent study on gold nanorod growth procedures also demonstrated the ability of LLM in a similar task. [80] In contrast to the LIFT-based prediction of atomization energies reported in the first section by the Berkeley-Madison team, parameter-efficient fine-tuning of the open-source Alpaca model [83][84][85] using LoRA [47] did not yield a model that can construct valid JSONs.</p>
<p>c. TableToJson: Structured information from tables in scientific papers</p>
<p>The previous example shows how structured data can be extracted from plain text using LLMs. However, relevant information in the scientific literature is not only found in text form. Research papers often contain tables that collect data on material properties, synthesis conditions, and results of characterization and experiments. Converting table information into structured formats is essential to enable automated data analysis, extraction, and integration into computational workflows. Although some techniques could help in the process of extracting this information (performing OCR or parsing XML), converting this information in structured data following, for example, a specific To potentially address this problem the team utilized the jsonformer approach. This tool reads the keys from the JSON schema and only generates the value tokens, guaranteeing the generation of a syntactically valid JSON (corresponding to the desired schema) by the LLM [93,94]. Using an LLM without such a decoding strategy cannot guarantee that valid JSON outputs are produced. With the jsonformer approach, in most cases, by using a simple descriptive prompt about the type of input text, structured data can be obtained with 100 % correctness of the generated values. In one example, an accuracy of 80 % was obtained due to errors in the generation of numbers in scientific notation.</p>
<p>For a table with more complex content (long molecule names, hyphens, power numbers, subscripts, and superscripts,. . . ) the team achieved an accuracy of only 46 %. Most of these issues could be solved by adding a specific explanation in the prompt, increasing the accuracy to 100 % in most cases.</p>
<p>Overall, both approaches performed well in generating the JSON format. The OpenAI text-davinci-003 model could correctly extract structured information from tables and give a valid JSON output, but it cannot guarantee that the outputs will always follow the provided schema. Jsonformer may present problems when special characters need to be generated, but most of these issues could be solved with careful prompting. These results show that LLMs can be a useful tool to help to extract scientific information in tables and convert it into a structured form with a fixed schema that can be stored in a database, which could encourage the creation of more topic-specific databases of research results. In both cases, JSON objects were always obtained. The output of the OpenAI model did not always follow the provided schema, although this might be solved by modifying the schema. The accuracy of the results from the jsonformer approach used with OpenAI models could be increased (as shown by the blue arrows) by solving errors in the generation of power numbers and special characters with a more detailed prompt. The results can be visualized in this demo app: https://vgvinter-tabletojson-app-kt5aiv.streamlit.app/</p>
<p>d. AbstractToTitle &amp; TitleToAbstract: text summarization and text generation</p>
<p>Technical writing is a challenging task that often requires presenting complex abstract ideas in limited space. For this, frequent rewrites of sections are needed, in which LLMs could assist domain experts. Still, evaluating their ability to generate text such as a scientific paper is essential, especially for chemistry and materials science applications.</p>
<p>Large datasets of chemistry-related text are available from open-access platforms such as arXiv and PubChem. These articles contain titles, abstracts, and often complete manuscripts, which can be a testbed for evaluating LLMs as these titles and abstracts are usually written by expert researchers. Ideally, an LLM should be able to generate a title of an abstract close to the one developed by the expert, which can be considered a specialized text-summarization task. Similarly, given a title, an LLM should generate text close to the original abstract of the article, which can be considered a specialized text-generation task.</p>
<p>These tasks have been introduced by the AbstractToTitle &amp; TitleToAbstract team (Kamal Choudhary) in the JARVIS-ChemNLP package [95]. For text summarization, it uses a pre-trained Text-to-Text Transfer Transformer (T5) model developed by</p>
<p>Google [96] that is further fine-tuned to produce summaries of abstracts. On the arXiv condensed-matter physics (cond-mat) data, the team found that fine-tuning the model can help improve the performance (Recall-Oriented Understudy for Gisting Evaluation (ROUGE)-1 score of 39.0 % which is better than an untrained model score of 30.8 % for an 80/20 split).</p>
<p>For text generation, JARVIS-ChemNLP finetunes the pretrained GPT-2-medium [48] model available in the HuggingFace library. [97] After finetuning, the team found a ROUGE score of 31.7 %, which is a good starting point for pre-suggestion text applications. Both tasks with well-defined train and test splits are now available in the JARVIS-Leaderboard platform for the AI community to compare other LLMs and systematically improve the performance.</p>
<p>In the future, such title to abstract capabilities can be extended to generating fulllength drafts with appropriate tables, multi-modal figures, and results as an initial start for the human researcher to help in the technical writing processes. Note that there have been recent developments in providing guidelines for using LLM-generated text in technical manuscripts [98], so such an LLM model should be considered as an assistant of writing and not the master/author of the manuscripts.</p>
<p>D. Education</p>
<p>Given all the opportunities LLM open for materials science and chemistry, there is an urgent need for education to adapt. Interestingly, LLMs also provide us with entirely  Figure 10). In the future, these questions might be shown to students before a video starts, allowing them to skip parts they already know or after the video, guiding students to the relevant timestamps or additional material in case of an incorrect answer.</p>
<p>Importantly, and in contrast to conventional educational materials, this approach can generate a practically infinite number of questions and could, in the future, be continuously be improved by student feedback. In addition, it is easy to envision extending this approach to consider lecture notes or books to guide the students further or even recommend specific exercises.</p>
<p>II. CONCLUSION</p>
<p>The fact that the groups were able to present prototypes that could do quite complex tasks in such a short time illustrates the power of LLMs. Some of these prototypes would have taken many months of programming just a few months ago, but the fact that LLMs could reduce this time to a few hours is one of the primary reasons for the success of our hackathon. Combined with the time-constrained environment in teams (with practically zero cost of "failure"), we found more energy and motivation. The teams delivered more results than in most other hackathons we participated in.</p>
<p>Through the LIFT framework, one can use LLMs to address problems that could already be addressed with conventional approaches-but in a much more accessible way (using the same approach for different problems), while also reusing established concepts such as ∆-ML. At the same time, however, we can use LLMs to model chemistry and materials science in novel ways; for example, by incorporating context information such as "fuzzy" design rules or directly operating on unstructured data. Overall, a common use case has been to use LLMs to deal with "fuzziness" in programming and tool development. We can already see tools like Copilot and ChatGPT being used to convert "fuzzy abstractions" or hard-to-define tasks into code. These advancements may soon allow everyone to write small apps or customize them to their needs (end-user programming). Additionally, we can observe an interesting trend in tool development: most of the logic in the showcased tools is written in English, not in Python or another programming language. The resulting code is shorter, easier to understand, and has fewer dependencies because LLMs are adept at handling fuzziness that is difficult to address with conventional code. This suggests that we may not need more formats or standards for interoperability; instead, we can simply describe existing solutions in natural language to make them interoperable. Exploring this avenue further is exciting, but it is equally important to recognize the limitations of LLMs, as they currently have limited interpretability and lack robustness.</p>
<p>It is interesting to note that none of the projects relied on the knowledge or understanding of chemistry by LLMs. Instead, they relied on general reasoning abilities and provided chemistry information through the context or fine-tuning. However, this also brings new and unique challenges. All projects used the models provided by OpenAI's API. While these models are powerful, we cannot examine how they were built or have any guarantee of continued reliable access to them.</p>
<p>Although there are open-source language models and techniques available, they are generally more difficult to use compared to simply using OpenAI's API. Furthermore, the performance of language models can be fragile, especially for zero-or few-shot applications. To further investigate this, new benchmarks are needed that go beyond the tabular datasets we have been using for ML for molecular and materials science-we simply have no frameworks to compare and evaluate predictive models that use context, unstructured data, or tools. Without automated tests, however, it is difficult to improve these systems systematically. On top of that, consistent benchmarking is hard because de-duplication is ill-defined even if the training data are known. To enable a scientific approach to the development and analysis of these systems, we will also need to revisit versioning frameworks to ensure reproducibility as systems that use external tools depend on the exact versions of training data, LLM, as well as of the external tools and prompting setup.</p>
<p>The diversity of the prototypes presented in this work shows that the potential applications are almost unlimited, and we can probably only see the tip of the iceberg-for instance, we didn't even touch modalities other than text thus far.</p>
<p>Given these new ways of working and thinking, combined with the rapid pace of developments in the field, we believe that we urgently need to rethink how we work and teach. We must discuss how we ensure safe use [103], standards for evaluating and sharing those models, and robust and reliable deployments. But we also need to discuss how we ensure that the next generation of chemists and materials scientists are proficient and critical users of these tools-that can use them to work more efficiently while critically reflecting on the outputs of the systems. We believe that to truly leverage the power of LLMs in the molecular and material sciences, we need a community effort-including not only chemists and computer scientists but also lawyers, philosophers, and ethicists: the possibilities and challenges are too broad and profound to tackle alone. K.C. thank the National Institute of Standards and Technology for funding, computational, and data-management resources. Please note certain equipment, instruments, software, or materials are identified in this paper in order to specify the experimental procedure adequately. Such identification is not intended to imply recommendation or endorsement of any product or service by NIST, nor is it intended to imply that the materials or equipment identified are necessarily the best available for the purpose.         [28] White, A. paper-qa. https://github.com/whitead/paper-qa, 2022.       Accurate prediction of chemical properties has long been the ultimate objective in computational chemistry and materials science. However, the significant computational demands of precise methods often hinder their routine application in modeling chemical processes. The recent surge in machine learning development, along with the subsequent popularity of large language models (LLMs), offers innovative and effective approaches to overcome these computational limitations. Our project takes steps toward establishing a comprehensive, open-source framework that harnesses the full potential of LLMs to accurately model chemical problems and uncover novel solutions to chemical challenges. In this study, we assessed the capability of LLMs to predict the atomization energies of molecules at the G4(MP2) [2] level of theory from the QM9-G4MP2 dataset [3,4] using solely string representations for molecules, specifically, SMILES [5] and SELFIES [6,7]. G4(MP2) is a highly accurate composite quantum chemistry method, known for its accuracy within 1.0 kcal/mol for molecular energies compared to experimental values, making atomization energy an ideal property to predict to demonstrate the usefulness and impact of LLMs on the field of computational chemistry.</p>
<p>Jablonka et al. [8] recently demonstrated the potential of fine-tuning pre-trained LLMs on chemistry datasets for a broad array of predictive chemistry tasks. As an initial validation for our project, we finetuned generative pretrained transformer (GPT)-3 [9] to learn how to reproduce a molecule's atomization energy at the G4(MP2) level of theory, using its SMILES or SELFIES string through the prompt, "What is the G4MP2 atomization energy in kcal/mol of 'SMILES/SELFIES string of a molecule' ?" Additionally, we fine-tuned LLMs to predict the atomization energy difference between B3LYP/6-31G(2df,p) and G4(MP2) levels of theory with the prompt, "What is the G4MP2 and B3LYP atomization energy difference in kcal/mol of 'SMILES/SELFIES string of a molecule' ?", which mirrors the ∆-machine learning (∆-ML) schemes [10] found in the existing literature. We fine-tuned the GPT-3 (Ada) model using 90% of the QM9-G4MP2 dataset (117,232 molecules) for eight epochs with the GPTChem [8] framework's default settings. The remaining 10 % (13,026 molecules) was kept as the hold-out set, following the same data split as Ward et al. [1], to evaluate the model's performance. Table I summarizes the regression metrics for the hold-out set. The strong correlation between the predicted and ground truth values suggests that the model effectively learned the structural information from the molecular string representation. Although the MAD remains relatively high compared to state-ofthe-art models in the literature [1,11] that utilize a molecule's full 3D structural information for descriptor construction, we achieved chemical accuracy (&lt; 1.0 kcal/mol ≈ 0.04 eV) for the ∆-ML task. Consequently, this approach can predict G4(MP2) energies with high accuracy when B3LYP energies are available. We also compared the model's performance using SMILES and SELFIES molecular representations, with the former proving marginally superior for predicting atomization energies, possibly due to its more compact representation for molecules. We additionally calculated regression metrics for the G4MP2-Heavy dataset [1], the results of which are provided in Table II. While GPT-3 fine-tuning models are accessible through the OpenAI application programming interface (API), their usage costs can become prohibitive for larger datasets, rendering hyperparameter searches and other exploratory research economically unfeasible. Consequently, we aim to develop a free and open-source framework for fine-tuning LLMs to perform a wide range of predictive modeling tasks, encompassing chemical property prediction and inverse design.</p>
<p>To fine-tune a pre-trained LLM locally on a GPU instead of querying OpenAI's API, we employed the Hugging Face parameter efficient fine-tuning (PEFT) library [12] to implement the low-rank adaptors (LoRA) tuning paradigm [13]. Conventional fine-tuning updates all model parameters, utilizing pretrained weights from a large training dataset as a starting point for gradient descent. However, fine-tuning memory-intensive LLMs on consumer hardware is often impractical. The LoRA approach addresses this by freezing the model's weights and tuning a low-rank adapter layer rather than the entire model, parameterizing changes concerning the initial weights rather than the updated weights.</p>
<p>Using this approach, we fine-tuned the smallest version of GPT-2 [14] (124 million parameters) for 20 epochs on the same 90 % training set as used in GPTChem, allocating 10 % of that training set for validation, and computed metrics on the same 10 % hold-out set as in the GPTChem run, employing the same prompt structure. Although the model performs well, it demonstrates slightly inferior performance to GPT-3 on the G4MP2 task and moderately worse on the (G4(MP2)-B3LYP) task. This is not unexpected, given that GPT-3 is a more recent model with substantially more parameters than GPT-2 (175 billion vs. 124 million) and has exhibited superior few-shot performance on various tasks [15].</p>
<p>Moving forward, we plan to employ the LoRA tuning framework to fine-tune other models, such as LLaMA [16] and GPT-J, to investigate the impact of LLM selection on performance in chemistry-related tasks. Moreover, we intend to experiment with molecular-input representations beyond string formats to more accurately represent a molecule's 3D environment [17]. c. Results and Impact Even though simpler, direct fine-tuning for a complicated property on SMILES leads to errors one order of magnitude higher than baselines, and the error can only be brought close to the baselines with an ∆ − M L approach-first demonstration of ∆-ML in the LIFT framework for chemistry.</p>
<p>d. Challenges and Future Work Since the predictions without 3D coordinates is not satisfactory, a question for future work is how the approach would perform when provided with 3D coordinates.</p>
<p>B. From Text to Cement: Developing Sustainable Concretes Using In-Context Learning</p>
<p>The inherently intricate chemistry and variability of feedstocks in the construction industry have limited the development of novel sustainable concretes to labor-intensive laboratory testing. This major bottleneck in material innovation has significant consequences due to the substantial contribution of CO 2 emissions of materials in use today. The production of Portland cement alone amounts to approximately 8 % of anthropogenic CO 2 emissions [18]. The increasing complexity of alternative raw materials and the uncertain future availability of established substitutes like fly ash and granulated blast furnace slag make the experimental development of more sustainable formulations time-consuming and challenging. Traditional trial-and-error approaches are ill-suited to efficiently explore the vast design space of potential formulations.</p>
<p>In previous studies, inverse design (ID) has been shown to accelerate the discovery of novel, sustainable, and high-performance materials by reducing labor-intensive laboratory testing [19][20][21]. Despite their potential, the adoption of these techniques has been impeded by several difficulties that are connected to the predictive model at the core of ID: Incorporating domain knowledge typically requires extensive data collection to accurately capture underlying relationships, which makes representing complex tasks in practice challenging due to the high costs of data acquisition. Furthermore, ID necessitates formulating research problems as search space vectors. This process can be unintuitive and challenging for lab personnel, limiting the comprehension and adoption of these techniques. Lastly, sparse training samples in high dimensions can lead to co-linearities and overfitting, negatively impacting prediction performance. With in-context learning Figure 2. Using LLMs to predict the compressive strength of concretes. The left part illustrates the conventional approach for solving this task, i.e., training classical prediction models using tabular data. Using the LIFT framework LLM can also use tabular data but also leverage context information provided in natural language. Augmented with this context, in-context-learning with LLM leads to a performance that outperforms baselines such as RFs or GPRs.</p>
<p>(ICL), Jablonka et al. [8] and Ramos et al. [22] demonstrated that LLMs offer a solution by incorporating context and general knowledge, providing flexibility in handling non-numeric inputs and overcoming the limitations of traditional vector space formulations ( Figure 2).</p>
<p>In this study, we have adopted an ICL approach based on a dataset from a study by Rao and Rao [23]. The dataset comprises 240 alternative and more sustainable concrete formulations based on fly ash and ground granulated slag binders, along with their respective compressive strengths. The goal is to compare the prediction performance of the compressive strength with ICL using the text-davinci-003 model [24] against established methods, RF [25].</p>
<p>Randomly sampled training subsets containing ten formulations are drawn. The prediction performance is assessed on a separate, randomly sampled test set of 25 samples and evaluated using the coefficient of determination (R-squared) [26]. This process is repeated ten times to ensure more reliable results.</p>
<p>The experimental results reveal that ICL attains comparable performance to GPR but underperforms RF when provided with small training data sets (R-squared of 0.5, 0.54, and 0.67, respectively). However, when using general, qualitative concrete design knowledge, such as the influence of the water-to-cement ratio on strength, the models significantly reduce prediction outliers and ultimately surpass RF (R-squared = 0.71). When we incorrectly changed the context of the ratio of fly ash to GGBFS, it negatively affected the R-squared value for ICL, causing it to drop to 0.6. This misrepresentation of the rule led to a decrease in the model's predictive accuracy, demonstrating that the quality of the information included in the "fuzzy" context is critical to the overall performance of LLMs. It should be noted, however, that the impact on the R-squared value may vary depending on the importance of the rule in the overall context. That is, not all changes in context have a similar impact, and the drop to 0.6 might occur only in the case of the ratio of fly ash to GGBFS. Other studies, such as those conducted in the LIFT work, [27] have shown LLM performance for minor changes in wording or the presence of noise in the features. In these experiments, the robustness of LIFT-based predictions was comparable to classical ML algorithms, making it a promising alternative for using fuzzy domain knowledge in predictive modeling.</p>
<p>LLMs have been shown to provide significant advantages in sustainable concrete development, including context incorporation, adaptable handling of non-numeric inputs, and efficient domain knowledge integration, surpassing traditional methods' limitations. ICLs simplifies formulating data-driven research questions, increasing accessibility and democratizing a data-driven approach within the building materials sector. This highlights LLMs potential to contribute to the construction industry's sustainability objectives and foster efficient solutions.</p>
<p>One sentence summaries a. Problem/Task Predicting the compressive strength of concrete formulations. b. Approach ICL on language-interfaced tabular data, with and without "fuzzy" domain expertise (such as relationship between columns) provided in natural language.</p>
<p>c. Results and Impact Predictive models can be built without any training; if provided with domain expertise, those models outperform the baselines-first demonstration in chemistry of such fuzzy knowledge can be incorporated into models.</p>
<p>d. Challenges and Future Work ICL can be very sensitive to the prompt, hence future work should investigate the robustness of this approach.</p>
<p>C. Molecule Discovery by Context</p>
<p>The escalating climate crisis necessitates the deployment of clean, sustainable fuels to reduce carbon emissions. Hydrogen, with its potential to prevent approximately 60 gigatons of CO 2 emissions by 2050, according to the World Economic Forum, stands as a promising solution [28]. However, its storage and shipping remain formidable challenges due to the necessity for high-pressure tanks. To address this, we sought new molecules to which hydrogen could be conveniently added for storage. Traditional screening methods, like brainstorming, are insufficient due to their limited throughput. This research proposes a novel method of leveraging ScholarBERT, [29] a pre-trained science-focused LLM, to screen potential hydrogen carrier molecules efficiently. This approach utilizes ScholarBERT's ability to understand and relate the context of scientific literature. The data used for this study consisted of three datasets. The "Known" dataset comprised 78 known hydrogen carrier molecules. The "Relevant" dataset included 577 molecules, all of which are structurally similar to the "Known" molecules. The "Random" dataset contained 111 randomly selected molecules from the PubChem database [30]. The first step involved searching for contexts for molecules in the Public Resource Dataset (PRD), which includes 75M English language research articles. These contexts (i.e. sentences that mentioned the molecule name) were then fed into ScholarBERT. For each context, three calculations were made: Subsequently, we calculated the similarity between the known and candidate molecules. The definition of "similarity" used in this study was the cosine similarity between the ScholarBERT representations of two molecules. We then sorted the candidates based on the similarity score in descending order, with a higher score indicating greater potential as a hydrogen carrier. Figure 3 and 4 show the candidate molecules with the highest similarity to the known molecules. We can see that ScholarBERT does a passable job finding similar molecules from the random set. We do see that it favors finding molecules with 5-and 6-member rings, though with features we didn't expect, like halogens. On the other hand, ScholarBERT does a much better job when we reduce the search space to those with structural similarity. We see that molecules with 5-member rings, for instance, are found to be similar structurally and in how they are described in the literature via ScholarBERT. Based on our empirical data, computing the energy capacity (wt%H 2 ) and energy penalty (kJ/mol/H 2 ) of adding and removing H 2 to the molecule (which are the quantitative "success metrics" for this project) of a candidate molecule using traditional quantum chemistry takes around 30 seconds per molecule on a 64-core Intel Xeon Phi 7230 processor, whereas the proposed LLM approach can screen around 100 molecules per second on a V100 GPU, achieving a 3000 times speedup.</p>
<p>One sentence summaries a. Problem/Task Recommending hydrogen carrier molecules. c. Results and Impact Approach can recommend molecules with a success rate better than random. d. Challenges and Future Work More benchmarks compared to conventional generative modeling are needed.</p>
<p>D. Text template paraphrasing with LLMs</p>
<p>Problem</p>
<p>Text data is much trickier to augment for machine learning applications due to the discrete nature of the data modality. There are some traditional augmentation approaches for these tasks. However, they can be inefficient or still need extensive manual checks to be sure they deliver the desired results, especially for scientific or chemistry applications.</p>
<p>Solution</p>
<p>To automate high-quality text data augmentations, LLMs have been explored by Dai and his coworkers [31] as a very recent and promising solution to this problem. We investigated such a setup in the scope of the OpenBioML chemistry NLP project (https://github.com/OpenBioML/chemnlp) to paraphrase text templates for the insertion of chemical raw data into natural language for LIFT. [27] An example prompt is shown below. The outlined prompt setup has after "Question:" the desired task with additional information and after "Sentence:" the starting text template for the paraphrasing. The "Question:" and "Answer:" headers are not used if the LLM interface uses a chat interface, i.e., with OpenAI GPT-4.</p>
<p>Example Prompt</p>
<p>Question: Please paraphrase the sentence below ten times without changing the original meaning and the placeholder in the curly {} brackets. Please use all the placeholders in the curly {} brackets for every rephrased sentence.  In the above answer, there is the {SMILES description} representation of {SMILES query}, but we don't use it in the sentence yet. And there is no curly brackets for the excepted answer.</p>
<p>Impact</p>
<p>The outlined approach allows to automatically create new paraphrased high-quality prompts for LIFT LLM training data very efficiently. With the additional paraphrased text templates, overfitting to special text passages should be avoided. We explore this setup in follow-up work in more detail.</p>
<p>Lessons learned</p>
<p>The outlined paraphrasing setup works well for the latest state-of-the-art models, e.g., OpenAI's GPT-4 and Anthropic's Claude v1. Less capable open-source models seem to lack the understanding of this paraphrasing task. Still, new and upcoming open-source LLM efforts could change that soon, enabling a cost-effective and broader application of this setup.</p>
<p>One sentence summaries a. Problem/Task Generation of many text-templates for language-interfaced fine-tuning of LLMs b. Approach Prompting of LLM to rephrase templates (with template syntax similar to Jinja). c. Results and Impact Large models (GPT-4, Claude), in contrast to smaller ones, can successfully rephrase templates, offering a potential avenue for data-augmentation.</p>
<p>d. Challenges and Future Work As next step, ablation studies need to carried out that test the effect of data augmentation by template rephrasing on regression and classification case studies.</p>
<p>13</p>
<p>E. GA without genes</p>
<p>We investigate the ability for a LLM to work in parallel with genetic algorithms (GAs) for molecular property optimization. By employing a LLM to guide genetic algorithm operations, it could be possible to produce better results using fewer generations. We hypothesize that a GA can take advantage of the "smart" randomness of the outputs of the LLM. This work explores the potential of LLMs to improve molecular fragmentation, mutation, variation, and reproduction processes and the ability of a LLM to gather information from a simplified molecular-input line-entry system (SMILES) string [5,6] and an associated score to produce new SMILES strings. Although computational efficiency is not the primary focus, the proposed method has potential implications for enhancing property prediction searches and future improvements in LLM understanding of molecular representations.</p>
<p>We used GPT-3.5-turbo [9], which could frequently fragment druglike molecules into valid SMILES strings successfully. For 2 /10 molecules, the fragments produced were not in the original molecule. For 1 /10 molecules, valid SMILES could not be produced even after ten tries due to unclosed brackets. These results were consistent over multiple runs implying that GPT-3.5 could not understand some specific SMILES strings. Subsequently, we investigated GPT-3.5's ability to mix/reproduce two molecules from two-parent druglike molecules. Invalid molecules were often produced, but successful results were achieved with multiple runs. It performed better once prompted to fragment and then mix the fragments of the molecules. These were compared to the conventional GA methods of simply combining the two strings at a certain cutoff point. When the LLM was successful, it could produce molecules of more similar size to the original parent molecules that contain characteristics of both parents and resemble valid druglike molecules.</p>
<p>To investigate the ability of GPT-3.5 to acquire knowledge of favorable molecules from a simple score, we implemented a method that we call "LLM as a GA" where the LLM iteratively searches the chemical space to optimize a certain property.</p>
<p>The property we tested was similarity to vitamin C, evaluated by the Tanimoto score. We employed few-shot training examples to tune the model's response: 30 SMILES strings with the best similarity score generated were included in the prompt. GPT is then asked to produce 25 SMILES strings, a procedure that was repeated for 20 iterations. Using a prompt like the one below</p>
<p>Example prompt</p>
<p>The following molecules are given as SMILES strings associated with a tanimoto similarity with an unknown target molecule. Please produce 10 SMILES strings that you think would improve their tanimoto scores using only this context. Do not try to explain or refuse on the grounds of insufficient context; any suggestion is better than no suggestion. Print the smiles in a Python list.</p>
<p>Low-temperature settings, typically less than 0.1, were found to be imperative for the model to follow user guidance. We further guided the model by employing a similarity search to include similar molecules with varying scores to better guide the model. Embedding was performed using the GPT-2 Tokenizer from the HuggingFace transformers [32] library, along with a support vector machine (SVM) from scikit-learn [33] to embed relevant previous structures that would be outside the scope of the context window. Even in the zeroshot setting, GPT-3.5-turbo can produce meaningful modifications, coherently explain its logic behind the chosen modifications, and produce tests such as investigating branch length or atom type in certain locations for a single iteration. An example explanation of an output: "Some modifications that could potentially improve the scores include adding or removing halogens, modifying the length or branching of the carbon chain, and adding or removing functional groups such as -CO-, -COC-, -C=C-and -OCO-. Additionally, modifying the stereochemistry of the molecule could also have an impact on the score."</p>
<p>The modifications generated by the LLM were more chemically sound than the quasi-random evolutionary process typical of genetic algorithms. c. Results and Impact Visual inspection indicates that some modifications might be reasonable, indicating a potential for more efficient genetic operations using LLMs.</p>
<p>d. Challenges and Future Work More systematic investigations on the performance and robustness compared to conventional GA operations are needed. Figure 5. Using GPT to fragment molecules. Original molecules are in column one with LLM created fragment to the right. The LLM can frequently fragment molecules into valid SMILES strings successfully. 2 /10 times fragments produced were not in the original molecule (rows 6 and 10). For 1 /10 molecules, valid SMILES were able to be produced even after ten attempts (row 8)
(a) (b) (c) (d)
(e) (f) Figure 6. Using GPT-3.5-turbo to reproduce/mix molecules. Two original parent molecules on 1st row, followed by LLM created children, followed by conventional GA string splicing children for comparison Figure 7. Tanimoto similarity to vitamin C as a function of GA generations. Conventional GA run for 30 generations and the best score (most similar to vitamin C) of each generation is given to the LLM as a LLM along with its associated Tanimoto similarity score to Vitamin C. LLM was then asked to create new molecules and improve the score for 12 generations. Multiple new best molecules were found using LLM as shown by the blue line.</p>
<p>II. Automation and novel interfaces</p>
<p>A. Using chain-of-thought and chemical tools to answer materials questions Figure 8. Schematic overview of the MAPI-LLM workflow. It uses LLMs to process the user's input and decide which available tools (e.g., Materials Project API, and Google Search) to use following an iterative chain-of-thought procedure. In this way, it can answer questions such as "Is the material AnByCz stable?". [34][35][36]. Recently, LLMs have gained attention in chemistry, demonstrating exceptional ability to model chemical systems [37] and predicting tabular data [8,22,27]. Predicting the properties of materials is challenging since it requires computationally intensive techniques, such as density functional theory (DFT) [38][39][40]. Data-driven models offer a viable option to balance accuracy and computational time. Here we presented the MAPI-LLM, a multi-task package that employs LangChain [41] agents with access to multiple tools to address users' questions about materials.</p>
<p>LLMs have demonstrated remarkable success in various tasks</p>
<p>It has been shown that providing chemistry-specific tools to an LLM allows the LLM to solve chemistry problems with significantly higher accuracy [42]. In a similar manner, we developed tools to iteratively query the Materials Project (MAPI) dataset [43] and utilize the reaction-network package [44], among others. MAPI-LLM can process user prompts in natural language using LLMs and follow a chain of thought (COT) [45] approach to determine the most suitable tools and inputs to answer the prompt. Due to MAPI-LLM's design, more tools can be added as needed, and tools can be combined (multiple tools can be used for a given prompt), opening the door for a large variety of applications. Figure 8 illustrates MAPI-LLM's capabilities. The code for the app is available in https://github.com/maykcaldas/MAPI_LLM, and a graphical user interface (GUI) is implemented in https://huggingface.co/spaces/maykcaldas/MAPI_LLM.</p>
<p>An important feature implemented into MAPI-LLM is a technique known as ICL [9], which allows the model to learn from the context within the prompt. For example, users can use MAPI-LLM's tool to query the MAPI dataset, first triggering the dataset search in the COT. However, if the desired material is not found in the dataset, MAPI-LLM still has access to other tools (such as ICL) to build context around the user prompt and adjust the COT actions to make a prediction. Another interesting tool is the ability to use the reaction-network package [44], which is a package for predicting inorganic reaction pathways. We showed the promising capabilities of MAPI-LLM by simply asking for reactions that use a given material as reactants or products. It can suggest such reactions for material synthesis or decomposition.</p>
<p>We built from the knowledge that LLMs are suitable for such tasks of interest in this application, for instance, classification and regression tasks [8]. Nevertheless, this application still needs a systematic validation of its predictions, such as the reinforcement learning from human feedback (RLHF) implementation in GPT-3.5 [46].</p>
<p>One sentence summaries a. Problem/Task Answering complex materials science questions based on reliable data and tools. b. Approach LLM-based agent in the ReAct framework that has access to tools such as the Materials Project API and uses ICL to answer questions for materials that are not in the materials project.</p>
<p>c. Results and Impact Coupling of tools allows answering questions that none of the tools or LLMs alone could solve by themselves, providing a very accessible interface to materials informatics tools. d. Challenges and Future Work If a description of tools is incorporated in the prompt, this limits the number of tools that can be coupled. In addition, LLM agents still tend to not perform equally well on all prompts, and systematic investigation to better understand this and to increase the robustness is needed. 20 B. sMolTalk Figure 9. The sMolTalk interface. Based on few-shot prompting LLMs can create code for visualization tools such as 3dmol.js.</p>
<p>Since the advent of 3D visualization methods, chemists have employed computers to display their molecules of interest to better understand their underlying structure and properties. Nevertheless, a lot of chemists are not equipped with the required coding skills to use and customize their visualizations. Depending on the package, and its associated documentation, chemists might end up spending hours to days learning the details of the specific visualization software.</p>
<p>We developed a natural language interface that generates code for 3dmol.js, an open-source visualization JavaScript library [47], meaning the visualizations are run in a web browser (Figure 9). The user input is fed into ChatGPT API, using the GPT-3.5-turbo model. We use in-context learning (few-shot prompting), giving several examples of the user input with the expected JavaScript code that manipulates the 3dmol.js viewer. Before the user submits further commands, we update the prompt with the current state of the viewer.</p>
<p>The current implementation might lead to a one-stop solution for visualizing and retrieving properties for molecules. This would accelerate chemists' workflow for querying information about molecules. Furthermore, if an LLM is able to control structural software, it might be possible to perform reasoning on the molecular structure itself. For instance, in drug discovery, one may ask what functional group of the ligand needs to be changed for binding affinity to the protein to increase. Another example might involve proteins, looking at what amino acid residues could be mutated to cysteines in order to create new disulfide bonds between chains. This would presumably require specific fine-tuning and equipping the LLM with more tools. The approach of generating code and structural reasoning might be similar but is most likely going to require a different set of tools that were specifically developed for protein structure manipulation (such as PyMoL [48], or MolStar [49]). Then, another set of highly accurate tools for binding affinity predictions or protein folding is also required. The major problem encountered is prompt leakage, where examples from in-context learning would leak into the actual LLM output. For the best evaluation, it is best to have as few and as different examples as possible. Moreover, although OpenAI's GPT models can sometimes correctly recall protein data bank (PDB) IDs of proteins or Chemical Abstract Services (CAS) numbers of compounds, it's not reliable, making tooling the models with API calls to PubChem, or the PDB, much more robust. We are currently developing an agent based on the ReAct approach [50] tooled with these APIs so that correct structures are always retrieved (i.e., to avoid the LLM needs to remember internally all such IDs). This framework would then help us iteratively add tools to the agent, creating a chatbot one can query about any molecule of interest, including the structural reasoning task mentioned above. Lastly, we hypothesize we could improve the generation of 3dmol.js code by using self-instruct fine-tuning. Using an external LLM with access to the documentation would create a dataset that could be used for fine-tuning. The same approach might be utilized for generating code for any other type of software, not just visualization packages. Therefore, such LLM could control molecular dynamics software, such as LAMMPS [51], or GROMACS [52].</p>
<p>One sentence summaries a. Problem/Task Making bioinformatics tools, in particular the visualization software 3dmol.js accessible to non-experts.</p>
<p>b. Approach Chat-interface by prompting a LLM to produce commands to 3dmol.js, which are then passed to the software.</p>
<p>c. Results and Impact The LLM can, without consulting the documentation, generate code that often successfully performs the requested actions, demonstrating that LLM might help make tools more accessible by providing access to complex interfaces via natural language.</p>
<p>d. Challenges and Future Work The approach suffers from robustness issues, which might be overcome with conditioning on a knowledge base, more advanced decoding strategies, or error handling (e.g., giving the agent access to error messages and logs and prompting it to reflect).</p>
<p>22</p>
<p>C. whinchat: A Conversational ELN Interface</p>
<p>Laboratory data management systems such as ELNs and laboratory information systems (LIMS) can record rich data about experimental samples and the experiments that have been performed on them. Then, the user interfaces for these systems typically allow researchers to explore their samples with various preprogrammed visualizations. However, it is difficult for a traditional user interface to have enough flexibility to capture the richness and diversity of real, interconnected, experimental data. Here, our aim was to investigate whether an LLM could process digital laboratory data and serve as a flexible, conversational interface to a data management system. As a proof-of-concept for this approach, we introduced an automated data management assistant into the open-sourced "Datalab" software, which we have been developing to address needs in experimental materials chemistry (https://github.com/the-grey-group/datalab). Datalab can be used to capture data and metadata about materials chemistry samples, their synthesis constituents, and resulting devices. The system tracks each sample's provenance through the research lifecycle and makes this data available via a JavaScript object notation (JSON) API that can be explored programmatically or with a Vue.js-based web user interface (UI). During the hackathon, we embedded a prompted LLM into the UI and gave it access to raw responses from datalab's JSON API. We used the most recent publicly available models from OpenAI (gpt-3.5-turbo) via their Python API. We found that the LLM does a very good job at interpreting JSON and inferring the meaning of fields (including linked data) and can:</p>
<ol>
<li>Contextualize existing data: Explain a set of related experiments from linked JSON responses, resolve acronyms/ short-hand used by experimentalists or create simple text summaries.</li>
</ol>
<p>Contextualizing existing data</p>
<p>Assistant Hello! I am your virtual assistant and I am here to help you manage your experimental data. How can I assist you today?</p>
<p>User Can you provide a brief summary of this experiment?</p>
<p>Assistant Based on the provided JSON data, this experiment involves the synthesis and characterization of NaCoO 2 as a battery cathode material. The synthesis method used was solid-state reaction, and the starting materials used were sodium carbonate and cobalt (II,III) oxide. The synthesized NaCoO 2 was then used to make an electrode, which was characterized using X-ray diffraction. The electrode was then incorporated into a coin cell battery, which was cycled electrochemically and characterized using various techniques.</p>
<ol>
<li>
<p>Generate text and graphical representations of the data: Aggregate data from different fields in the JSON response and convert to formats such as tables (potentially formatted for a particular journal), CSV, and even mermaid.js graph visualizations.</p>
</li>
<li>
<p>Suggest future experiments: The assistant readily identifies related materials to study, additives to try, additional characterization techniques, and synthesis protocols.</p>
</li>
</ol>
<p>Suggest experiments</p>
<p>User: What NMR nuclei could I probe in this sample?</p>
<p>Assistant: Based on the information provided in the JSON file, the sample is NaCoO 2 , which contains sodium, cobalt, and oxygen. Therefore, the NMR nuclei that could be probed in this sample are:  It is worth noting that NMR spectroscopy is a powerful technique for probing the local environment of atoms in a material, but it requires a relatively large amount of sample and may not be sensitive to all types of nuclei. Therefore, it may be necessary to use other techniques in conjunction with NMR to fully characterize the sample.</p>
<p>User: What techniques (that I haven't already used) should I use in conjunction with the NMR?</p>
<p>Assistant: In addition to the techniques I mentioned earlier, you could use the following techniques in conjunction with NMR to fully characterize the NaCoO 2 sample:</p>
<p>(a) X-ray photoelectron spectroscopy (XPS): This can provide information about the chemical composition and oxidation state of the NaCoO 2 sample, which can help to interpret the NMR spectra.</p>
<p>(b) Transmission electron microscopy (TEM): This can provide information about the crystal structure, morphology, and defects of the NaCoO 2 sample, which can help to interpret the NMR spectra.</p>
<p>(c) Electrochemical impedance spectroscopy (EIS): This can provide information about the electrical properties and performance of the NaCoO 2 sample as an electrode material, which can help to interpret the NMR spectra.</p>
<p>(d) Thermogravimetric analysis (TGA): This can provide information about the thermal stability and decomposition behavior of the NaCoO 2 sample, which can help to interpret the NMR spectra.</p>
<p>By using a combination of these techniques, you can gain a more complete understanding of the NaCoO 2 sample</p>
<p>The assistant performs quite well at certain tasks out-of-the-box, but we believe it should also be possible to further increase its general utility by fine-tuning the model on the domain knowledge present in a research group's Wiki and papers. Furthermore, while we have only given the model data from a single project so far (up to 8 samples/starting materials, 1700 tokens of JSON), it would be of great interest to provide the model with a larger context across multiple projects to attempt to facilitate cross-fertilization of ideas. One notable challenge in this area is the limited context size of currently available LLM models (e.g., 4097 tokens for GPT-3.5-turbo). Therefore, future work will investigate larger models (e.g., GPT-4 with 30K token context), as well as approaches to give existing LLMs access to larger context (e.g., an embedding-based approach or allowing an LLM agent to query the OpenAPI directly as needed). At present, we note that the scientific usefulness of this assistant is highly task-and model-dependent; however, any additional interface that can lower the barrier to improving data capture and dissemination in the field should be investigated further and will be a future development target for Datalab.</p>
<p>One sentence summaries a. Problem/Task Providing very flexible access to data in ELNs/LIMS. b. Approach Prompting of a large language model with questions provided in a chat interface and context coming from the response of the API of an LLM.</p>
<p>c. Results and Impact The system can successfully provide a novel interface to the data and let user interact with it in a very flexible and personalized way, e.g, creating custom summaries or visuals for which the developers did not implement specific tools.</p>
<p>d. Challenges and Future Work Since the current approach relies on incorporating the response of the ELN/LIMS into the prompt, this limits how much context (i.e., how many experiments/samples) the system can be aware of. One potential remedy is to use retrieval-augmented generation, where the entries are embedded in a vector store and the agent will be able to query this database on put (parts of) the most relevant entries into the prompt.</p>
<p>D. BOLLaMa</p>
<p>The field of chemistry is continuously evolving towards sustainability, with the optimization of chemical reactions being a key component [53]. The selection of optimal conditions, such as temperature, reagents, catalysts, and other additives, is challenging and time-consuming due to the vast search space and high cost of experiments [54]. Expert chemists typically rely on previous knowledge and intuition, leading to weeks or even months of experimentation [55].</p>
<p>Bayesian optimization (BO) has recently been applied to chemistry optimization tasks, outperforming humans in optimization speed and quality of solutions [55]. However, mainstream access to these tools remains limited due to requirements for programming knowledge and the numerous parameters these tools offer. To address this issue, we developed BOLLaMa. This artificial intelligence (AI)-powered chatbot simplifies BO for chemical reactions with an easy-to-use natural language interface, which facilitates access to a broader audience. BOLLaMa combines LLMs with BO algorithms to assist chemical reaction optimization. The user-friendly interface allows even those with limited technical knowledge to engage with the tool. BOLLaMa's current implementation provides two main tools: the initialization function and the optimization step function [56], that are retrieved on LLM-demand as shown in Figure 11.</p>
<p>The primary contribution of this project is democratizing access to advanced BO techniques in chemistry, promoting widespread adoption of sustainable optimization tools, and impacting sustainability efforts within the community. This approach can be further enhanced to provide a more comprehensive assistant experience, such as with additional recommendations or safety warnings, and improve the explainability of the BO process to foster user trust and informed decision-making.</p>
<p>Key insights gained from this project include the critical role of accessibility in developing expert tools and the potential of LLMs in chemistry through various agent architectures [50]. In addition, the initial BO tool adapted for BOLLaMa was designed for closed-loop automated laboratories, emphasizing the need for accessible tools catering to diverse user backgrounds.</p>
<p>One sentence summaries a. Problem/Task Giving scientists without coding and machine learning expertise access to Bayesian optimization.</p>
<p>b. Approach LLM as a chat-interface for a Python package for Bayesian optimization by using ReActlike approach in which the LLM has access to text-description of relevant functions (such as initialization and stepping of the BO run).</p>
<p>c. Results and Impact The chat interface can successfully initialize a BO run and then convert observations reported in natural language into calls to the stepping function of the BO tool.</p>
<p>d. Challenges and Future Work As most LLM agents, the tools suffers from robustness issues and the correct functioning cannot be guaranteed for all possible prompts.</p>
<p>III. Knowledge Extraction</p>
<p>A. InsightGraph Figure 12. The Insight Graph interface. A suitably prompted LLM can create knowledge graph representations of scientific text that can be visualized using tools such as neo4j's visualization tools. [57] The traditional method of performing a literature review involves months of reading relevant articles to find crucial information on material properties, structure, reaction pathways, and applications. Knowledge graphs are sources of structured information that enable data visualization, data discovery, insights, and downstream machine-learning tasks. Knowledge graphs extracted from published scientific literature covering broad materials science domains [58] as well as more-focused domains such as polymer nanocomposites [59] empower material scientists to discover new concepts and accelerate research. Until recently, capturing complex and hierarchical relationships for a knowledge graph within the materials science literature was a time-consuming effort, often spanning multi-disciplinary collaborations and many Ph.D. years. By leveraging zero to few-shot training and pre-trained LLMs, it is now possible to rapidly extract complex scientific entities with minimal technical expertise [58,60,61]. We envision that knowledge graphs built by LLMs based on scientific publications can offer a concise and visual means to launch a literature review.</p>
<p>To demonstrate a proof of concept of a zero-shot entity and relationship extraction, we identified 200 abstracts on polymer-nanocomposite materials for which detailed structured information was already available [62]. Each abstract was fed as a prompt to GPT-3.5-turbo, a language model powering the popular ChatGPT web application by OpenAI. The instructions in our prompt consisted of an example JSON containing high-level schema and information on possible entities and pairwise relationships. The nodes and relationships in the output JSON response were then stored in a neo4j graph database using Cypher, a graph query language ( Figure 12). [57] The zero-shot capabilities of the model allowed the specification of an arbitrary entity and relationship types depending upon the information contained in the text. Given that this required a change in the neo4j pipeline every time the prompt changed, we found it necessary to constrain the JSON schema to a standard format.</p>
<p>While large language models on their own are prone to hallucinations, leveraging them with guidance to create structured databases empowers chemists/materials scientists with no expertise in natural language processing to search and build on existing knowledge leading to new insights. The speed at which LLMs can create structured graphs dramatically exceeds the years required for humans to manually curate data into existing knowledge graphs. Access to structured databases will accelerate the pace of data-driven material science research, synthesizing details embedded in dispersed scientific publications. Additionally, other scientific fields could benefit from a similar use of LLMs to extract entities and relationships to build knowledge graphs.</p>
<p>Owing to the non-deterministic nature of LLMs, we found that the output response would vary even when the same prompt was provided. An instruction constraining the JSON schema minimized the variability. A systematic study comparing different foundation models, prompt techniques (zero-shot, one-shot, few-shot), prompt chaining, and the role of fine-tuning is needed to evaluate the precision and recall of extracted entities and relationships. Notably, pairwise links between the nodes are not often enough to model the complex nature of materials requiring improvement in the input schema.</p>
<p>One sentence summaries a. Problem/Task Extraction of entities and their relationships from text. b. Approach Prompting of GPT-3.5-turbo prompted with abstract and example JSON and the task to extract entities and their relationships in a structure as provided in the example.</p>
<p>c. Results and Impact The approach can successfully create meaningful JSON data structures with extracted entities and their relationships for hundreds of abstracts.</p>
<p>d. Challenges and Future Work The non-deterministic behavior of LLMs can lead to variability and fragile behavior. To better understand this as well as the performance of this approach, more systematic benchmarking is needed. a. Problem As data-driven approaches and machine learning (ML) techniques gain traction in the field of organic chemistry and its various subfields, it is becoming clear that, as most data in chemistry is represented by unstructured text, the predictive power of these approaches is limited by the lack of structured, wellcurated data. Due to the large corpus of organic chemistry literature, manual conversion from unstructured text to structured data is unrealistic, making software tools for this task necessary to improve or enable downstream applications, such as reaction prediction and condition recommendation.</p>
<p>b. Solution In this project, we leverage the power of fine-tuned LLMs to extract reactant information from organic synthesis text to structured data. 350 reaction entries were randomly selected from the Open Reaction Database (ORD) [63]. The field of reaction.notes.procedure details is used as the input (prompt), and the field of reaction.inputs is used as the output (completion). 300 of these promptcompletion pairs were used to fine-tune a GPT-3 (OpenAI Davinci) model using the OpenAI command line interface (version 0.27.2), and the rest were used for evaluation. In addition to this, we also explored fine-tuning the Alpaca-LoRA model [16,64,65] for this task. All data and scripts used in this project are available in the GitHub repository.</p>
<p>c. Results and Discussion Surprisingly, the pre-trained language model (OpenAI Davinci), fine-tuned with only 300 prompt-completion pairs, is capable of generating valid JSON complying with the ORD data model. For the 50 prompt-completion pairs in evaluation, 93 % of the components in reaction inputs were correctly extracted from the free text reaction description by the GPT-3 based model. The model also associates existing properties, such as volume or mass used in the reaction, to these components. In addition to recognizing in-text chemical entities (such as molecule names), as shown in Figure 13, tokens referencing external chemical entities (compound numbers) can also be captured by the model. On the other hand, while completing the prompts with extracted chemical information, the fine-tuned Alpaca-LoRA model was unable to properly construct a valid JSON complying with the ORD data model. Despite these encouraging preliminary results, there are still challenges to a robust synthesis text parser. One of them is the ambiguous and often artificial boundary between descriptions of reactions and workups, which leads to misplaced chemical entities in the structured data, e.g., a solvent used in the extraction of products is instead labeled as a reaction solvent. The aforementioned external reference problem, where a compound number in the procedure is only explicitly identified in an earlier section of the manuscript, can only be solved by prompting the LLM with multiple paragraphs or even the entire document, adding more irrelevant tokens to the prompt. It is also important to prevent the LLM from "auto-completing" extracted named entities with information outside the prompt, e.g., the chemical is extracted as "sodium chloride" in the completion while it is only specified as "chloride" in the prompt.</p>
<p>One sentence summaries d. Problem/Task Extraction of structured reaction condition and procedure data from text. e. Approach Fine-tuning of LLMs on hundreds of prompt (unstructured text)-completion (extracted structured data) pairs.</p>
<p>f. Results and Impact OpenAI's davinci model can extract the relevant data with a success rate of 93 %. g. Challenges and Future Work Parameter efficient fine-tuning could not match the performance of OpenAI's models. In addition, there are instances in which the LLM goes beyond the specified tasks (e.g., modifies/"autocompletes") extracted entries, which can lead to fragile systems.</p>
<p>C. TableToJson: Extracting structured information from tables in scientific papers</p>
<p>Much of the scientific information published in research articles is presented in an unstructured format, primarily as free text, making it a difficult input for computational processing. However, relevant information in scientific literature is not only found in text form. Tables are commonly employed in scientific articles, e.g., to collect precursors and raw materials' characteristics, synthesis conditions, synthesized materials' properties, or chemical process results. Converting this information into a structured data format is usually a manual time-consuming and tedious task. Neural-network-based table extraction methods and optical character recognition (OCR) [66], which can convert typed, handwritten, or printed documents into machine-encoded text, can be used to extract information from tables in PDF files. However, it is often not straightforward to extract the data in the desired structured format. Nonetheless, structured data is essential for creating databases that aggregate research results, and enable data integration, comparison, and analysis.</p>
<p>In this context, JSON is a widely adopted structured data format due to its simplicity, flexibility and compatibility with different programming languages and systems. However, obtaining structured data following a specific JSON schema with models can be challenging. The generated JSON needs to be syntactically correct and conform to a schema that defines the JSON's structure. Models typically do not provide structured output that perfectly matches the desired JSON schema. Some manual post-processing or data transformation is often necessary to map the extracted information to the appropriate schema fields.</p>
<p>In this work, we have studied two approaches to generate structured JSON from data contained in tables of scientific papers focused on different research topics within the field of chemistry [67][68][69][70][71][72][73]. The Python json module was used to parse JSON data and validate the outputs.</p>
<p>As a first approach, the OpenAI text-davinci-003 model was used to generate structured JSON from data in tables. The input to the LLM is the HyperText Markup Language (HTML) code of the table, obtained directly from the digital object identifier (DOI) of the article using the Python selenium library, while the output of the model is the data extracted in JSON form ( Figure 14). The OpenAI text-curie-001 model, although not tested in this work, can also be utilized if the number of input tokens, considering both the HTML text of the table and the schema, meets the requirements of this model (máximum 2049 input tokens, compared to 4097 for text-davinci-003).</p>
<p>The use of the OpenAI model to generate structured JSON was compared with a second approach, i.e., the use of jsonformer (https://github.com/1rgs/jsonformer), which implements a data processing pipeline that combines the model generation with appropriate data transformation. This method introduces an efficient way to generate structured JSON using LLMs by generating only the content tokens and filling in the fixed tokens. This avoids generating a complete JSON string and parsing it. This approach ensures that the produced JSON is always syntactically correct and aligns with the specified schema. [74]  TableToJson. Extraction of structured information from scientific data in tables using LLMs. The input to the LLM model is the HTML code of a table contained in a scientific paper. The output of the LLM model is data structured in JSON form. Results can be visualized in this demo app: https://vgvinter-tabletojson-app-kt5aiv. streamlit.app/.</p>
<p>In our first approach, we directly asked the OpenAI text-davinci-003 model to generate a JSON object according to a desired JSON schema provided in the model prompt. The table content was also included in the prompt as HTML code. The accuracy in the prediction, calculated as the percentage of schema values generated correctly, is shown in Figure 15. In all examples, the OpenAI model was queried with a simple prompt, and it correctly extracted all the data in the table and inserted every value into the corresponding position in the schema, with 100 % accuracy, providing as output a JSON object. This model also correctly generated both string and number values according to the type assigned in the schema. However, in two of the examples, the OpenAI model did not generate the JSON object name specified in the schema when the corresponding name was not found in the table, generating only the list of components. This was solved by modifying the object name in the schema to a term that more closely aligned with the content of the table. It appears that when the model could not establish a clear relationship between the provided name and the table content, it disregards that part of the schema during generation. These results indicate that the OpenAI text-davinci-003 model is able to convert scientific data from tables of research papers to a structured format following the approach used in this work, where the desired JSON schema was included in the model prompt. Nevertheless, the model retains a certain degree of freedom to modify the requested scheme if it considers that something may be wrong. The second approach used to generate structured information was a version of the jsonformer approach adapted for use with OpenAI LLMs (https://github.com/martinezpl/jsonformer/tree/add-openai), with the implementation of the inclusion of the table text as an input parameter to the jsonformer function.</p>
<p>Detection of strings indicating null values was also added when the schema type is number, as "nan", "NaN", "NA", and "NAN" entries are common in research data tables. The OpenAI text-davinci-003 model was used. In this case, the model was prompted with the desired JSON schema and the HTML code of the studied table. Jsonformer reads the keys from the JSON schema and only delegates the generation of the value tokens to the language model, ensuring that a valid JSON is generated by the LLM model.</p>
<p>For this approach, the accuracy in the prediction is also shown in Figure 15. The use of the OpenAI text-davinci-003 model together with jsonformer generated valid JSON objects with 100% accuracy for most of the tables evaluated using a simple prompt. Figure 16 shows the results of one of the examples studied, where using a simple descriptive prompt denoting the type of input text, this approach correctly generated structured data JSON from a table with a complex header. However, it was detected that when the values to be generated contain special characters or specific texts, a more detailed prompt with some simple examples, but without finetuning, can be necessary to provide good results, as shown in Figure 17 for a special numeric notation that included power numbers. Figure 16. TableToJson. Structured JSON generation of tables contained in scientific articles using a prompt with a simple description of the type of input text. One example is shown for a table that contains data on properties of biomass materials [71].</p>
<p>As shown in Figure 15, in one of these examples, an accuracy of 94 % was obtained from a table containing a few catalyst names that included the "-" character, and those values were erroneously generated. In another example, an accuracy of 80 % was initially obtained due to errors in the generation of numbers with powers (e.g., 9.161 × 10 4 ), which could be solved by adding an explanation in the prompt: "if you find numbers as 1.025 × 10<sup>3</sup>, this means 1.025e-3", increasing the accuracy to 100 %.</p>
<p>Next, a table with more complex content (long molecule names, hyphens, power numbers, subscripts, and superscripts. . . ) was selected (Figure 15), resulting in an accuracy of 46% in the JSON generation, meaning that only 46% of the schema values were correctly generated. The erroneous generation of long formula or molecule names with a mixture of letters and numbers as subscripts could be solved by increasing the value of the max string token length argument of the jsonformer function to get a longer response where the end of the string can be detected more easily, which increased the accuracy to 60 %. Jsonformer also showed some issues in this example in generating power numbers, which are represented as 10<sup>−n</sup> in the input HTML text. As mentioned above, this was solved by adding a specific explanation in the prompt, increasing the accuracy to 86%. A specific explanation was also included in the prompt to address the issues related to the presence of hyphens in the text. Still, this problem could not be solved systematically, and the resulting accuracy varied between 86 % and 100 % for several JSON generation attempts. In this particular case, the generated value provided by the model included Unicode text instead of the "-" character (and usually several "\" characters). An instruction to "decode Unicode characters in your response" was then included in the prompt. Although this solution sometimes yielded satisfactory results, it did not systematically guarantee correct output. These results indicate that the OpenAI model combined with jsonformer can provide wrong outputs when the values to be generated contain some special characters, such as the "-" character in this example. This issue requires further investigation to be improved. Lastly, for one of the examples, a test was performed by providing a wrong schema to the model ( Figure 15). In this case, as expected, jsonformer inserted the values contained in the table into the given wrong schema in a more or less ordered fashion, generating an invalid output. However, the OpenAI model created a new schema according to the table structure and headers, providing a valid result, and confirming its freedom to decide what may be wrong with the user's query. An example of these results is shown in Figure 18.</p>
<p>The two approaches used in this work showed a good performance in the generation of JSON format when the data contained in the table are regular strings or numbers, with an accuracy of 100 % in most of the examples. The results of this work show that, although the OpenAI text-davinci-003 is able to easily extract structured information from tables and give a valid JSON output, this approach cannot guarantee that the outputs will always follow a specific schema. On the other hand, although jsonformer may present problems when special characters need to be generated, some of these issues have been solved with careful prompting, and others could probably be solved with further research. It can be concluded that jsonformer can be a powerful tool for the generation of structured data from unstructured information in most tables, ensuring the generation of valid JSON syntax as the output of LLMs that always complies with the provided schema. The use of jsonformer could facilitate and promote the creation of databases and datasets for numerous topics within the field of chemistry, especially in experimental domains, where the availability of structured data is very scarce.</p>
<p>One sentence summaries a. Problem/Task Extracting structured data in a JSON-schema-compliant form from HTML tables. b. Approach Two approaches were compared: Direct prompting of OpenAI's text-davinci-003 model with the input table and the JSON schema, as well as the Jsonformer approach, which only samples from a subset of tokens in field-wise generation steps.</p>
<p>c. Results and Impact Both approaches can extract data in schema-compliant from tables with high success rates. Due to hard-coded decoding rules, Jsonformer failed in some cases.</p>
<p>d. Challenges and Future Work While the Jsonformer approach can guarantee valid syntax, it can fail in cases that were not considered in the development of the decoding rules. Hence, future work is needed for increasing the general applicability of constrained decoding strategies.</p>
<p>Text summarization and text generation are some of most the common tasks in natural language processing (NLP). Often it is tricky to obtain well-defined and curated datasets for these tasks. Also, evaluating the performance of an NLP model is challenging because there is no unique way to summarize and generate text. Luckily, there are many publicly available manuscripts for chemistry and materials science in open access platforms such as arXiv and PubChem. These datasets can be used along with LLMs to solve problems such as: 1) given title of the article; generate an abstract, 2) given an abstract; generate a title, which should be similar to the one available in the literature. Such models can greatly help in technical writing, especially with a human expert in the loop.</p>
<p>Solution</p>
<p>The above challenging tasks require an organized infrastructure for curated data and tools. JARVIS-ChemNLP [75] is an integrated library for materials chemistry text data for NLP tasks such as text classification, token classification, abstractive summarization, text generation, and integrating with existing DFT databases. ChemNLP uses transformer models to generate titles from abstracts and vice versa for arXiv condensed matter category articles.</p>
<p>There is no unique approach for both tasks. Nevertheless, highly qualified scientists and engineers generate such abstracts and titles and can act as a valuable benchmark to evaluate model performance. Moreover, developing metrics for text generation is a difficult task. Here, for the sake of simplicity, we choose the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics for evaluating the model performance.</p>
<p>ChemNLP uses models such as a pre-trained Text-to-Text Transfer Transformer (T5) developed by Google for text summarization. The pre-trained model is further fine-tuned to produce summaries of abstracts and analyze the performance by analyzing its closeness to the title of the given paper.</p>
<p>For the text generation, ChemNLP fine-tunes LLMs such as the pre-trained GPT-2-medium model from the HuggingFace library.</p>
<p>For these tasks, the community can contribute their models on a benchmarking platform called the JARVIS-Leaderboard (https://pages.nist.gov/jarvis_leaderboard/). Specifically, the TextGen task is available at: https://pages.nist.gov/jarvis_leaderboard/AI/TextSummary/arxiv_summary_text/ and TextSummary task is available at https://pages.nist.gov/jarvis_leaderboard/AI/TextGen/ arxiv_gen_text/</p>
<p>Example</p>
<p>Title to Abstract example for cond-mat/0105402. [76] Question MgB2 under pressure: phonon calculations, Raman spectroscopy, and optical reflectance can be described as</p>
<p>Fine-tuned GPT-2-medium model output</p>
<p>The amplitude of phonon vibrations in a material exhibiting an unconventional lattice structure has been measured in the low pressure region of the granular MgB2 phase. The peak in the high pressure region is the first measurement of phonon amplitude ever presented in a granular superconducting material, and it indicates a potential source of superconductivity. Superconducting Transition from Fluctuations to Brillouin T-Wings in CeFo Josephson Junctions can be described as We report electronic and numerical calculations for solving the electron-wave (E-W) conduction spectra of a quasi-two-dimensional superconducting monolith CeFo Josephson junctions: The amplitude of phonon vibrations in the low pressure region (KPSM), and in the high pressure region of the superconducting density wave (SDW) densities, are used to understand the superconductivity.</p>
<p>Actual abstract</p>
<p>The effect of pressure on optical phonon frequencies of MgB 2 has been calculated using the frozenphonon approach based on a pseudopotential method. Gruneisen parameters of the harmonic mode frequencies are reported for the high-frequency zone-center E 2g and B 1g and the zone-boundary E 2u and B 2u modes at A. Anharmonic effects of phonon frequencies and the implications of the calculated phonon frequency shifts for the pressure dependence of the superconducting transition temperature of MgB 2 are discussed. Also reported are Raman and optical reflectance spectra of MgB 2 measured at high pressures. The experimental observations in combination with calculated results indicate that broad spectral features we observed in the Raman spectra at frequencies between 500 and 900 cm −1 cannot be attributed to first-order scattering by zone-center modes, but originate in part from a chemical species other than MgB 2 at the sample surface and in part from a maximum in the MgB 2 phonon density of states. Low-temperature Raman spectra taken at ambient pressure showed increased scattering intensity in the region below 300 cm −1 .</p>
<p>Interestingly, the generated abstract contains grammatically and syntactically incorrect sentences. We suspect that this is due to our use of a small, outdated, base model. However, more systematic analysis will need to be performed in future work.</p>
<p>One sentence summaries a. Problem/Task Text summarization and generation, in specific, a summary of an abstract into a title and generation of an abstract conditioned on a title.</p>
<p>b. Approach Fine-tuning of transformer models such as T-5 and GPT-2 on data from arXiv. c. Results and Impact Initial exploration indicates that transformer models might be suitable for this task.</p>
<p>d. Challenges and Future Work More systematic analysis, including rating of the generated titles and abstracts by domain experts is required to identify the limitations of this approach.</p>
<p>IV. Education</p>
<p>A. i-Digest a. Problem Over the last few years, especially during the Covid period, most of us had to switch to the online mode of working in our day-to-day jobs. And even today, the online mode of working has, to some extent, stayed on as it turned out to be convenient for both employers and employees. One clear example can be found in the field of education, where the use of video lectures became the norm for teaching students in universities and schools. Likewise, podcasts and three-minute thesis videos, which communicate important scientific information to society at large, have grown tremendously [77,78]. This has led to a situation where, at present, we have an enormous amount of important scientific information stored in the form of videos and audio all over the internet. A current challenge is to summarize and make use of this knowledge efficiently. Some efforts in this direction have been made by using AI Youtube summarizers and QnA Bots [79]. We would like to build upon such efforts and create a tool for the field of education.</p>
<p>b. Solution We present a tool that self-guides students and other users toward a better understanding of the content of a video lecture or a podcast. In order to accomplish this, we used publicly available LLMs like Open AI's Whisper [80] and GPT-3.5-turbo model. All the user needs to do is provide a link to the lecture video or audio file. After only a short time, the overview page shows some technical keywords on which the video is based, a short but comprehensive summary, and some questions for the user to assess his or her understanding of the concepts discussed in the video/audio ( Figure 19). Additionally, for chemistry enthusiasts, if some chemical elements/molecules are discussed in the content, we link them to online databases. At the backend, we first convert the video to audio using Pytube (In the case of a podcast, this step is not needed). Then we use the Whisper model to transcribe the audio to text. Next, we make use of the OpenAI GPT-3.5-turbo model to obtain a short summary and a set of questions based on the text. Finally, we extract the name of chemical elements/molecules and list the PubChem database entry for that element/molecule on the overview page. [81][82][83] The web interface was made using the open-source app framework Streamlit [84].</p>
<p>Key Words</p>
<p>Summary</p>
<p>The lecture is about the Monte Carlo simulations and its algorithm.</p>
<p>The speaker discusses … Questions 1) Could you explain the acceptance rule? 2)</p>
<p>Why is it important to select a particle at random for displacement? 3) …</p>
<p>Transcript</p>
<p>Chemicals</p>
<p>Pubchem Search</p>
<p>Large Language Model</p>
<p>"Come up with questions" "Give a summary" "Suggest three keywords" 1) Monte Carlo Simulation 2)</p>
<p>Metropolis algorithm 3) Importance Sampling Figure 19. A schematic of the i-digest interface. On providing a link to an online video or audio, i-digest generates some technical keywords, a short but comprehensive summary, and a list of questions based on the content in the video/audio. Additionally, chemicals discussed in the content are linked to online databases such as PubChem.</p>
<p>c. Impact We strongly believe that extracting important scientific information in terms of short lecture notes and questions would help to push forward the field of education towards creating and using resources more efficiently. Moreover, by providing additional links to resources, e.g., databases, journals, and books, we provide an opportunity for the user to go beyond the content of the lecture and spark interest in a more detailed understanding of the topic. Specifically, this would help researchers/teachers/professors to create new course content or to update/modify already available content. In general, our tool covers a broad range of users, from the youngest learner to the chemistry novice who wants to kickstart his research, all the way to professors, course creators, and lifetime learners.</p>
<p>d. Lessons learned Working together with colleagues can be fun and enriching and often help to solve big problems. This hackathon taught us that even in one day, coming together can help achieve something significant.</p>
<p>One sentence summaries e. Problem/Task Provide students with automatically generated active learning tasks for lecture recordings.</p>
<p>f. Approach Transcription of videos using OpenAI's Whisper model, prompting of OpenAI's GPT-3.5turbo model to produce a short summary and questions based on the transcript, as well as to extract mentions of chemicals in the text.</p>
<p>g. Results and Impact The system can transcribe the text, generate meaningful questions, and successfully extract mentions of chemicals.</p>
<p>h. Challenges and Future Work It is difficult to systematically evaluate the performance of this system due to the lack of suitable benchmarks/eval. An obvious extension of this approach is to condition it on further material (e.g., lecture notes and books). In addition, one might automatically score the answers and show them at the beginning and at the end of the video. This would allow us to evaluate the learning of the students and to guide them to the relevant material in case a question was not answered correctly.</p>
<p>40</p>
<p>V. Meta analysis of the workshop contributions</p>
<p>We have a female/male ratio of about 30 % among the workshop participants who co-authored this paper. We have participants from 22 different institutions in 8 countries.</p>
<p>Most teams combine expertise from different institutions (Figure 21), in several cases beyond academia ( Figure 22). Around 20 % of the teams are international, with participants from two countries ( Figure 23). 5 10 15 20 Number of participants    </p>
<p>Figure 3 :
3Schematic overview of the MAPI-LLM workflow.</p>
<p>Figure 4 :
4The sMolTalk interface. Based on few-shot prompting LLMs can create code for visualization tools such as 3dmol.js that can create custom visualization based on a naturallanguage description of the desired output. The top left box is the input field where users can enter commands in natural language. The top right box prints the code the LLM generates. This code generates the visualization shown in the lower box. In this example, the user entered a sequence of four commands: the LLM (1) generates code for retrieving the structure, (2) colors the carbons blue, (3) displays the hydrogens as red spheres, and (4) reduces the size of the spheres.</p>
<p>Figure 6 :
6Schematic overview of BoLLama. An LLM can act as an interface to a BO algorithm. An experimental chemist can bootstrap an optimization and then, via a chat interface, update the state of the simulation to which the bot responds with the recommended next steps.</p>
<p>(zero-shot) completions of the LLM are corrected by domain experts. Those corrected completions are then used to finetune LLMs, showing improved performance on this task. However, for certain applications, one can construct powerful prototypes using only careful prompting. For instance, the InsightGraph team (Defne Circi, Shruti Badhwar) showed that GPT-3.5-turbo, when prompted with an example JSON containing a highlevel schema and information on possible entities (e.g., materials) and pairwise relationships (e.g., properties), can, as Figure 7 illustrates, provide a knowledge graph representation of the entities and their relationships in a text describing the properties and composition of polymer nanocomposites. A further optimized version of this tool might offer a concise and visual means to quickly understand and compare material types and uses across sets of articles and could be used to launch a literature review. An advanced potential application is the creation of structured, materials-specific datasets for fact-based question-answering and downstream machine-learning tasks.</p>
<p>Figure 8 :
8Figure 8:</p>
<p>JSON schema with models remains a challenge. The INCAR-CSIC team showed that the OpenAI text-davinci-003 model, when prompted with a desired JSON schema and the HyperText Markup Language (HTML) of a table contained in a scientific paper, can generate structured JSON with the data in the table. First, the OpenAI text-davinci-003 model was directly used to generate JSON objects from the table information. This approach was applied to several examples using tables collected from papers on different research topics within the field of chemistry [86-92]. The accuracy for those different examples, calculated as the percentage of schema values generated correctly, is shown in Figure 9. When the OpenAI model was prompted with the table and desired schema to generate a JSON object, it worked remarkably well in extracting the information from each table cell and inserting it at the expected place in the schema. As output, it provided a valid JSON object with a 100 % success rate of error-free generated values in all the studied examples. However, in some examples, the model did not follow the schema.</p>
<p>Figure 9 :
9TableToJson. Results of the structured JSON generation of tables contained in scientific articles. Two approaches are compared: (i) the use of an OpenAI model prompted with the desired JSON schema, and (ii) the use of an OpenAI model together with jsonformer.</p>
<p>Figure 10 :
10The I-digest interface. A video (e.g., of a lecture recording) can be described using the Whisper model. Based on the transcript, an LLM can generate questions (and answers). Those can assist students in their learning. The LLM can also detect mentions of chemicals and link to further information about them (e.g., on PubChem[100][101][102]). novel educational opportunities[99], for example, by personalizing content or providing almost limitless varied examples. The I-Digest (Information-Digestor) hackathon team (Beatriz Mouriño, Elias Moubarak, Joren Van Herck, Sauradeep Majumdar, Xiaoqi Zhang) created a path toward such a new educational opportunity by providing students with a digital tutor based on course material such as lecture recordings. Using the Whisper model [71], videos of lecture recordings can be transcribed to text transcripts. The transcripts can then be fed into an LLM with the prompt to come up with questions about the content presented in the video (</p>
<p>.J., S.M., J.v.H., X.Z., B.M., E.M., and B.S. were supported by the MAR-VEL National Centre for Competence in Research funded by the Swiss National Science Foundation (grant agreement ID 51NF40-182892) and the USorb-DAC Project, which is funded by a grant from The Grantham Foundation for the Protection of the Environment to RMI's climate tech accelerator program, Third Derivative. B.M. was further supported by the European Union's Horizon 2020 research and innovation programme under the Marie Sk lodowska-Curie grant agreement No. 945363. M.C.R., S.C., and A.D.W. were supported by the National Science Foundation and the National Institute of General Medical Sciences under Grant No. 1764415 and award number R35GM137966, respectively. Q.A.'s contribution to this work was supported by the National Center for Advancing Translational Sciences of the National Institutes of Health under award number U18TR004149. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. M.V.G. acknowledges support from the Spanish National Research Council (CSIC) through the Programme for internationalization i-LINK 2021 (Project LINKA20412), and from the Spanish Agencia Estatal de Investigación (AEI) through the Grant TED2021-131693B-I00 funded by MCIN/AEI/ 10.13039/501100011033 and by the "European Union NextGenerationEU/PRTR" and through the Ramón y Cajal Grant RYC-2017-21937 funded by MCIN/AEI/ 10.13039/501100011033 and by "ESF Investing in your future". The datalab project (M.L.E., B.E.S. and J.D.B.) has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement 957189 (DOI: 10.3030/957189), the Battery Interface Genome -Materials Acceleration Platform (BIG-MAP), as an external stakeholder project. M.L.E. additionally thanks the BEWARE scheme of the Wallonia-Brussels Federation for funding under the European Commission's Marie Curie-Sk lodowska Action (COFUND 847587). B.E.S. acknowledges support from the UK's Engineering and Physical Sciences Research Council (ESPRC). B.P. acknowledges support from the National Science Foundation through NSF-CBET Grant No. 1917340. The authors thank Phung Cheng Fei, Hassan Harb, and Vinayak Bhat for their helpful comments on this project. D.C. and L.C.B. thank NSF DGE-2022040 for the aiM NRT funding support.</p>
<p>A.K.G., G.W.M., A.I., and W.A.d.J. were supported by the U.S. Department of Energy, Office of Science, Basic Energy Sciences, Materials Sciences and Engineering Division under Contract No. DE-AC02-05CH11231, FWP No. DAC-LBL-Long, and by the U.S. Department of Energy, Office of Science, Office of High Energy Physics under Award Number DE-FOA-0002705. M.B, B.R., and P.S. were supported by the NCCR Catalysis (grant number 180544), a National Centre of Competence in Research funded by the Swiss National Science Foundation. S.G.R. and J.L. acknowledge the generous support of Eric and Wendy Schmidt, and the core funding of the Francis Crick Institute, which receives its funding from Cancer Research UK, the UK Medical Research Council, and the Wellcome Trust.</p>
<p>[ 1 ]
1Butler, K. T.; Davies, D. W.; Cartwright, H.; Isayev, O.; Walsh, A. Machine learning for molecular and materials science. Nature 2018, 559, 547-555.</p>
<p>[ 2 ]
2Moosavi, S. M.; Jablonka, K. M.; Smit, B. The Role of Machine Learning in the Understanding and Design of Materials. J. Am. Chem. Soc. 2020, 142, 20273-20287.</p>
<p>[ 3 ]
3Morgan, D.; Jacobs, R. Opportunities and Challenges for Machine Learning in Materials Science. Annu. Rev. Mater. Res. 2020, 50, 71-103.</p>
<p>[ 4 ]
4Ramprasad, R.; Batra, R.; Pilania, G.; Mannodi-Kanakkithodi, A.; Kim, C. Machine learning in materials informatics: recent applications and prospects. npj Comput. Mater. 2017, 3, 54.</p>
<p>[ 5 ]
5Schmidt, J.; Marques, M. R. G.; Botti, S.; Marques, M. A. L. Recent advances and applications of machine learning in solid-state materials science. npj Comput. Mater. methods in materials science. npj Comput. Mater. 2022, 8, 59.[7] Jablonka, K. M.; Ongari, D.; Moosavi, S. M.; Smit, B. Big-Data Science in Porous Materials: Materials Genomics and Machine Learning. Chem. Rev. 2020, 120, 8066-8129. [8] Shi, J.; Quevillon, M. J.; Amorim Valença, P. H.; Whitmer, J. K. Predicting Adhesive Free Energies of Polymer-Surface Interactions with Machine Learning. ACS Appl. Mater. Interfaces 2022, 14, 37161-37169. [9] Shi, J.; Albreiki, F.; Colón, Y. J.; Srivastava, S.; Whitmer, J. K. Transfer Learning Facilitates the Prediction of Polymer-Surface Adhesion Strength. J. Chem. Theory Comput. 2023, [10] Noé, F.; Tkatchenko, A.; Müller, K.-R.; Clementi, C. Machine Learning for Molecular Simulation. Annu. Rev. Phys. Chem. 2020, 71, 361-390. [11] Batzner, S.; Musaelian, A.; Sun, L.; Geiger, M.; Mailoa, J. P.; Kornbluth, M.; Molinari, N.; Smidt, T. E.; Kozinsky, B. E(3)equivariant graph neural networks for data efficient and accurate interatomic potentials. Nat. Commun. 2022, 13, 2453. [12] Sanchez-Lengeling, B.; Aspuru-Guzik, A. Inverse molecular design using machine learning: Generative models for matter engineering. Science 2018, 361, 360-365. [13] Gonthier, J. F.; Steinmann, S. N.; Wodrich, M. D.; Corminboeuf, C. Quantification of "fuzzy" chemical concepts: a computational perspective. Chem. Soc. Rev. 2012, 41, 4671. [14] Weininger, D. SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. J. Chem. Inf. Comput. Sci. 1988, 28, 31-36.</p>
<p>[ 15 ]
15Jablonka, K. M.; Patiny, L.; Smit, B. Making the collective knowledge of chemistry open and machine actionable. Nat. Chem. 2022, 14, 365-376.</p>
<p>[ 16 ]
16Bommasani, R. et al. On the Opportunities and Risks of Foundation Models. CoRR 2021, abs/2108.07258 . [17] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; Polosukhin, I. Attention is all you need. Advances in neural information processing systems 2017, 30 .</p>
<p>[ 18 ]
18Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. arXiv preprint: A.; Shyam, P.; Sastry, G.; Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems 2020, 33, 1877-1901. [21] Edwards, C. N.; Lai, T.; Ros, K.; Honke, G.; Ji, H. Translation between Molecules and Natural Language. Conference On Empirical Methods In Natural Language Processing 2022, [22] Eloundou, T.; Manning, S.; Mishkin, P.; Rock, D. GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models. arXiv preprint: Arxiv-2303.10130 2023, [23] Srivastava, A. et al. Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. arXiv preprint: Arxiv-2206.04615. 2022. [24] Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y. T.; Li, Y.; Lundberg, S.; Nori, H.; Palangi, H.; Ribeiro, M. T.; Zhang, Y. Sparks of Artificial General Intelligence: Early experiments with GPT-4. arXiv preprint: Arxiv-2303.12712 2023, [25] Schick, T.; Dwivedi-Yu, J.; Dessì, R.; Raileanu, R.; Lomeli, M.; Zettlemoyer, L.; Cancedda, N.; Scialom, T. Toolformer: Language Models Can Teach Themselves to Use Tools. arXiv preprint: Arxiv-2302.04761 2023, [26] Karpas, E. et al. MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. arXiv preprint: Arxiv-2205.00445 2022, [27] Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; Zhuang, Y. HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. arXiv preprint: Arxiv-2303.17580. 2023.</p>
<p>[ 29 ]
29Liu, J. LlamaIndex. 2022; https://github.com/jerryjliu/llama_index, last accessed 2023-05-30. [30] Andrej Karpathy [@karpathy], The Hottest New Programming Language Is English. 2023; https://twitter.com/karpathy/status/1617979122625712128, last accessed 2023-05-11.</p>
<p>Approximations: The ∆-Machine Learning Approach. J. Chem. Theory Comput. 2015, 11, 2087-2096. [46] Becke, A. D. Density-functional thermochemistry. III. The role of exact exchange. J. Chem. Phys. 1993, 98, 5648-5652. [47] Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; Chen, W. LoRA: Low-Rank Adaptation of Large Language Models. arXiv preprint: Arxiv-2106.09685 2021, [48] Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I. Language Models are Unsupervised Multitask Learners. 2019, https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_ learners.pdf.</p>
<p>[ 49 ]
49Scrivener, K. L.; John, V. M.; Gartner, E. M. Eco-efficient cements: Potential economically viable solutions for a low-CO2 cement-based materials industry. Cem. Concr. Res. 2018, 114, 2-26.</p>
<p>[ 50 ]
50Völker, C.; Benjami Moreno Torres,; Tehseen Rug,; Firdous, R.; Ghezal Ahmad,; Zia, J.; Lüders, S.; Scaffino, H. L.; Höpler, M.; Böhmer, F.; Pfaff, M.; Stephan, D.; Kruschwitz, S. Green building materials: a new frontier in data-driven sustainable concrete design. Preprint 10.13140/RG.2.2.29079.85925. 2023. [51] Rao, G. M.; Rao, T. D. G. A quantitative method of approach in designing the mix proportions of fly ash and GGBS-based geopolymer concrete. Aust. J. Civ. Eng. 2018, 16, 53-63.</p>
<p>[ 52 ]
52Tshitoyan, V.; Dagdelen, J.; Weston, L.; Dunn, A.; Rong, Z.; Kononova, O.; Persson, K. A.; Ceder, G.; Jain, A. Unsupervised word embeddings capture latent knowledge from materials science literature. Nature 2019, 571, 95-98.</p>
<p>[ 53 ]
53Mikolov, T.; Chen, K.; Corrado, G.; Dean, J. Efficient Estimation of Word Representations in Vector Space. International Conference On Learning Representations. 2013. [54] Olivetti, E. A.; Cole, J. M.; Kim, E.; Kononova, O.; Ceder, G.; Han, T. Y.-J.; Hiszpanski, A. M. Data-driven materials research enabled by natural language processing and information extraction. Appl. Phys. Rev. 2020, 7, 041317. [55] Selva Birunda, S.; Kanniga Devi, R. A review on word embedding techniques for text classification. Innovative Data Communication Technologies and Application: Proceedings of ICIDCA 2020 2021, 267-281. [56] Hong, Z.; Ajith, A.; Pauloski, G.; Duede, E.; Malamud, C.; Magoulas, R.; Chard, K.; Foster, I. ScholarBERT: Bigger is Not Always Better. arXiv preprint: Arxiv-2205.11342. 2022. [57] Dai, H. et al. AugGPT: Leveraging ChatGPT for Text Data Augmentation. arXiv preprint: Arxiv-2302.13007. 2023. [58] Venkatasubramanian, V.; Chan, K.; Caruthers, J. M. Computer-aided molecular design using genetic algorithms. Comput. Chem. Eng. 1994, 18, 833-844. [59] Flam-Shepherd, D.; Aspuru-Guzik, A. Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files. arXiv preprint: Arxiv-2305.05708. 2023. [60] Taylor, R.; Kardas, M.; Cucurull, G.; Scialom, T.; Hartshorn, A.; Saravia, E.; Poulton, A.; Kerkez, V.; Stojnic, R. Galactica: A Large Language Model for Science. arXiv preprint: Arxiv-2211.09085 2022, [61] Schwaller, P.; Gaudin, T.; Lányi, D.; Bekas, C.; Laino, T. "Found in Translation": predicting outcomes of complex organic chemistry reactions using neural sequence-to-sequence models. Chem. Sci. 2018, 9, 6091-6098. [62] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.; Cao, Y. ReAct: Synergizing Reasoning and Acting in Language Models. arXiv preprint: Arxiv-2210.03629 2023, [63] Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Xia, F.; Le, Q.; Zhou, D. Chainof-Thought Prompting Elicits Reasoning in Large Language Models. Neural Information Processing Systems 2022, [64] OpenAI, GPT-4 Technical Report. arXiv preprint: Arxiv-2303.08774v3. 2023. [65] Bran, A. M.; Cox, S.; White, A. D.; Schwaller, P. ChemCrow: Augmenting large-language models with chemistry tools. arXiv preprint: Arxiv-2304.05376 2023, [66] Boiko, D. A.; MacKnight, R.; Gomes, G. Emergent autonomous scientific research capabilities of large language models. arXiv preprint: Arxiv-2304.05332 2023, [67] Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G.; Persson, K. A. Commentary: The Materials Project:</p>
<p>Figure 1 .
1Illustration of the molecular property prediction workflow, from molecule representation to model fine-tuning and performance evaluation.</p>
<p>/Task Predicting the atomization energies of molecules using large language models. b. Approach Fine-tuning of GPT-3 ada model as well as PEFT of a small open-source model (GPT-2) on SMILES to either directly predict the atomization energies or the difference between a lower and a higher level of theory.</p>
<ol>
<li>the average of the last four encoder layers in ScholarBERT 2. the average embedding of all tokens constituting the molecule name as one contextualized embedding for this molecule, and 3. the average of all contextualized embeddings for a molecule as ScholarBERT's representation of this molecule.</li>
</ol>
<p>Figure 3 .
3Each column shows a Known molecule on the bottom and its top candidate molecule from the Random set on the top</p>
<p>Figure 4 .
4Each column shows a Known molecule on the bottom and its top candidate molecule from the Relevant set on the top b. Approach Ranking of molecules based on similarity of embeddings created with a language model by showing aggregating the embeddings of mentions of the molecules in scientific texts.</p>
<p>7 .
7{SMILES data} denotes the {SMILES description} for the molecule possessing a {target name} of {target value}{target units}. 8. The molecule defined by {SMILES description} {SMILES data} presents a {target name} of {target value}{target units}. 9. {SMILES description} {SMILES data} specifies the molecule which displays a {target name} of {target value}{target units}. 10. A {target name} amounting to {target value}{target units} is a property of the molecule represented with {SMILES description} {SMILES data}. Example Response by GPT-J The molecule with the {SMILES description} representation {SMILES A} has a {target name} of {target value}{target units}. {SMILES A} has a {target name} of {target units}. The molecule with the {target units} representation {target name} has a TARGET UNITS of {target value}{target units}. {target name} of {target units} have a TARGET UNITS of {target value}{target units}.</p>
<p>Problem/Task Increasing the efficiency of GAs. b. Approach Prompting a LLM to propose new children based on molecules with scores provided in the prompt.</p>
<p>( a )
aSodium-23 (23Na) NMR: This can provide information about the local environment and coordination of sodium ions in the NaCoO 2 lattice. (b) Cobalt-59 (59Co) NMR: This can provide information about the local environment and coordination of cobalt ions in the NaCoO 2 lattice. (c) Oxygen-17 (17O) NMR: This can provide information about the local environment and coordination of oxygen ions in the NaCoO 2 lattice.</p>
<p>Figure 10 .
10The chatbot can generate mermaid.js markdown code, which our interface automatically recognizes and translates into the visualization.</p>
<p>Figure 11 .
11Schematic overview of BOLLaMa. A LLM can act as an interface to a BO algorithm. An experimental chemist can bootstrap an optimization and then, via a chat interface, update the state of the simulation to which the bot responds with the recommended next steps.</p>
<p>Figure 13 .
13The Organic Synthesis Parser interface. The top part shows text describing an organic reaction (https: //open-reaction-database.org/client/id/ord-1f99b308e17340cb8e0e3080c270fd08), which the finetuned LLM converts into structured JSON (bottom). A demo application can be found at https://qai222.github.io/LLM_ organic_synthesis/.</p>
<p>Figure 14 .
14Figure 14. TableToJson. Extraction of structured information from scientific data in tables using LLMs. The input to the LLM model is the HTML code of a table contained in a scientific paper. The output of the LLM model is data structured in JSON form. Results can be visualized in this demo app: https://vgvinter-tabletojson-app-kt5aiv. streamlit.app/.</p>
<p>Figure 15 .
15TableToJson. Results of the structured JSON generation of tables contained in scientific articles. Two approaches are compared: (i) the use of an OpenAI model prompted with the desired JSON schema, and (ii) the use of an OpenAI model together with jsonformer.</p>
<p>Figure 17 .
17TableToJson. Structured JSON generation of a table contained in a scientific article using a standard prompt and a prompt with a few simple examples of the special numeric notation found in some of the cells of the input table[72].</p>
<p>Figure 18 .
18TableToJson. Results of the structured JSON generation of a table after providing the model with a wrong schema. The output generated using the OpenAI model together with jsonformer is shown on the left (values in the table are inserted in the provided wrong schema), while the output generated using directly the OpenAI model is shown on the right (a new schema is created following the table content).</p>
<p>Figure 20 .
20Worldmap (Robin projection) with the number of participants shown in color.</p>
<p>Figure 21 .Figure 22 .
2122Histogram of the number of unique affiliations per team. Number of teams with participants only from academia or academia and industry/nonprofit, respectively. We counted national labs as "academia".</p>
<p>Figure 23 .
23Histogram of the number of unique countries per team.</p>
<p>Table I :
IOverview of the developed tools and links to source code repositories. Full descriptions of the projects can be found in the Supplementary Material.</p>
<p>Inspired by this, the GlobusLabs team (Zhi Hong, Logan Ward) investigated if similar embeddings could be used to discover hydrogen carrier molecules, that are relevant for energy storage applications. For this, they leverage the ScholarBert model[56] trained on a large corpus of scientific articles collected by the Public.Resource.Org nonprofit organization. For different candidate molecules, they searched for sentences in the Public.Resource.Org corpus and used the average of the embeddings of these sentences as a fingerprint of the molecules. Given those fingerprints, they could rank molecules by how close their fingerprints are to the ones of known hydrogen carrier molecules. Visual inspection indicates that the selected molecules indeed bear similarities to known hydrogen carrier molecules.In the LIFT framework used in the examples above, the data are embedded in socalled prompt templates that can have a form like What is the <property name> of <representation>?, where the texts in chevrons are placeholders that are replaced with actual values such as "solubility" and "2-acetyloxybenzoic acid". In the low-data regime, data points are "wasted" by the model needing to learn the syntax of the prompt templates. In the big-data regime, in contrast, one might worry that the model loses some of its general language modeling abilities by always dealing with the same template. This naturally raises the question if one can augment the dataset to mitigate these problemsthereby leveraging again, similar to ∆-ML, a technique that has found use in conventional ML previously. However, text-based data are challenging to augment due to their discrete nature and the fact that the augmented text still needs to be syntactically and seman-Genetic algorithms are popular methods for generating new structures; they are evolutionary algorithms in which building blocks (e.g., fragments of SMILES strings) are iteratively crossed over, mutated, and subjected to other genetic operations to evolve structures with better performance (such as catalysts with higher conversion)d. Text template paraphrasing </p>
<p>tically valid. Interestingly, as Michael Pieler (OpenBioML.org and Stability.AI) shows </p>
<p>(and as has been explored by Dai et al. [57]), it turns out that LLMs can also be used to </p>
<p>address this problem by simply prompting an LLM (e.g., GPT-4 or Anthrophic's Claude) </p>
<p>to paraphrase a prompt template (see SI section ID). </p>
<p>This approach will allow us to automatically create new paraphrased high-quality </p>
<p>prompts for LIFT-based training very efficiently-to augment the dataset and reduce the </p>
<p>risk of overfitting to a specific template. Latter might be particularly important if one </p>
<p>still wants to retain general language abilities of the LLMs after finetuning. </p>
<p>e. Genetic algorithm using an LLM </p>
<p>This paradigm has recently been used by Bran et al.[65] to create digital assistants that can call and combine various tools such as Google search and the IBM RXN retrosynthesis tool when prompted with natural language. Boiko et al.[66] used a similar approach and gave LLMs access to laboratories via cloud lab APIs. In their system, the LLM could use external tools to plan a synthesis, which it could execute using the cloud lab.Electronic structure calculations have reached such a high level of accuracy that one can answer questions like "Is the material AnByCz stable?" Indeed, the Materials Project[67] stores thermodynamic data on many components from which one can obtain a reasonable estimate of the stability of a given material. Or, if the material is not in the database, one can do a simulation instead. Similarly, to answer prompts such as "Give me a reaction to produce CaCO3", there is a lot of helpful information in the Materials Project database and the internet that can help to come up with an answer.To answer these questions, state-of-the-art computational tools or existing databases can be used. However, their use often requires expert knowledge. To use existing databases, one must choose which database to use, how to query the database, and what Is the material AnByCz stable?" In addition, MAPI-LLM is capable of handling classification queries, such as "Is Fe2O3 magnetic?", as well as regression problems, such as "What is the band gap of Mg(Fe2O3)2?".Because an LLM is used to create the workflow, MAPI-LLM can process even more complex questions. For instance, the question "If Mn23FeO32 is not metallic, what is its band gap?" should create a two-step workflow first to check if the material is metallic and then calculate its band gap if it is not.Moreover, MAPI-LLM applies ICL if the data for a material's property is unavailable via the MAPI. MAPI-LLM generates an ICL prompt, building context based on the data for similar materials available in Materials Project database. This context is then leveraged by an LLM to infer properties for the unknown material. This innovative use of ICL bridges data gaps and enhances MAPI-LLM's robustness and versatility.a. MAPI-LLM </p>
<p>representation of the compound is used (e.g., international chemical identifier (InChI), </p>
<p>SMILES, etc.). Otherwise, if the data is not in a database, one must run calculations, </p>
<p>which requires a deep understanding of technical details. LLMs can simplify the use of </p>
<p>such tools. By typing in a question, we can prompt the LLM to translate this question </p>
<p>into a workflow that leads to the answer. </p>
<p>The MAPI-LLM team (Mayk Caldas Ramos, Sam Cox, Andrew White) made the first </p>
<p>steps towards developing such a system (MAPI-LLM) and created a procedure to convert </p>
<p>a text prompt into a query of the Materials Project API (MAPI) to answer questions </p>
<p>such as "</p>
<p>2 28
2Department of Computer Science, University of Chicago, Data Science and Learning Division, Argonne National Lab, United States.Contents </p>
<p>I. Predictive Modeling 
3 
A. Leveraging LLMs for Accurate Molecular Energy Predictions 
3 
B. From Text to Cement: Developing Sustainable Concretes Using In-Context Learning 
6 
C. Molecule Discovery by Context 
8 
D. Text template paraphrasing with LLMs 
10 
1. Problem 
10 
2. Solution 
10 
3. Impact 
12 
4. Lessons learned 
12 
E. GA without genes 
13 </p>
<p>II. Automation and novel interfaces 
18 
A. Using chain-of-thought and chemical tools to answer materials questions 
18 
B. sMolTalk 
20 
C. whinchat: A Conversational electronic lab notebook (ELN) Interface 
22 
D. BOLLaMa 
25 </p>
<p>III. Knowledge Extraction 
27 
A. InsightGraph 
27 
B. Extracting Structured Data from Free-form Organic Synthesis Text 
29 
C. TableToJson: Extracting structured information from tables in scientific papers 
31 
D. AbstractToTitle &amp; TitleToAbstract: text summarization and text generation 
36 
1. Problem 
36 
2. Solution 
36 
3. Example 
36 </p>
<p>IV. Education 
38 
A. i-Digest 
38 </p>
<p>V. Meta analysis of the workshop contributions 
40 </p>
<p>References 
42 
3 </p>
<p>I. Predictive Modeling </p>
<p>A. Leveraging LLMs for Accurate Molecular Energy Predictions </p>
<p>Table I. LIFT for molecular atomization energies on the QM9-G4MP2 dataset. Metrics for models tuned on 90% 
of the QM9-G4MP2 dataset (117,232 molecules), using 10% (13,026 molecules) as a holdout test set. Note that the 
metric used for the baseline results [1] is MAE, whereas this work used the MAD. The results indicate that the LIFT 
framework can also be used to build predictive models for atomization energies, that can reach chemical accuracy 
using a ∆-ML scheme. </p>
<p>mol. repr. &amp; framework 
G4(MP2) Atomization Energy 
(G4(MP2)-B3LYP) Atomization Energy 
R 2 
MAD / eV 
R 2 
MAD / eV </p>
<p>SMILES: GPTChem 
0.984 
0.99 
0.976 
0.03 
SELFIES: GPTChem 
0.961 
1.18 
0.973 
0.03 
SMILES: GPT2-LoRA 
0.931 
2.03 
0.910 
0.06 
SELFIES: GPT2-LoRA 
0.959 
1.93 
0.915 
0.06 </p>
<h2>SchNet baseline</h2>
<h2>-</h2>
<p>0.0045 
FCHL baseline 
-
0.0223 
-
0.0052 </p>
<p>Table II .
IIRegression metrics, (Coefficient of Determination), and MAD (Mean Absolute Deviation) for predicting G4(MP2) and (G4(MP2)B3LYP) atomization energies for the G4MP2-Heavy dataset using a fine-tuned GPT-3 model with GPTChemmol. repr. &amp; framework 
G4(MP2) Atomization Energy 
(G4(MP2)-B3LYP) Atomization Energy 
R 2 
MAD / eV 
R 2 
MAD / eV </p>
<p>SMILES: GPTChem 
0.583 
6.02 
0.856 
0.13 
SELFIES: GPTChem 
0.146 
9.44 
0.659 
0.15 </p>
<p>Sentence: The molecule with the {SMILES description} representation {SMILES data} has a {target name} of {target value}{target units}. Example Response by GPT-4 1. The {SMILES description} representation of the molecule is {SMILES data}, and its {target name} is {target value}{target units}. 2. With a {SMILES description} representation of {SMILES data}, the molecule has a {target name} of {target value}{target units}. 3. The molecule, represented by {SMILES description} as {SMILES data}, possesses a {target name} of {target value}{target units}. 4. A molecule having a {SMILES description} representation of {SMILES data} also has a {target name} equal to {target value}{target units}. 5. The {SMILES description}-represented molecule with {SMILES data} exhibits a {target name} of {target value}{target units}. 6. For the molecule with a {SMILES description} representation of {SMILES data}, its {target name} measures {target value}{target units}. 7. The {target name} of the molecule having a {SMILES description} representation of {SMILES data} is {target value}{target units}. 8. Represented by {SMILES description} as {SMILES data}, the molecule's {target name} is {target value}{target units}. 9. The molecule's {target name} is {target value}{target units} when its {SMILES description} representation is {SMILES data}. 10. A {target name} of {target value}{target units} is associated with the molecule whose {SMILES description} representation is {SMILES data}. {target name} of {target value}{target units} is possessed by the molecule depicted using {SMILES description} as {SMILES data}. 4. {SMILES data} signifies the {SMILES description} of the molecule which has a {target name} of {target value}{target units}. 5. The {SMILES description} {SMILES data} characterizes the molecule that exhibits a {target name} of {target value}{target units}. 6. A {target name} equal to {target value}{target units} belongs to the molecule expressed with {SMILES description} code {SMILES data}.Answer: </p>
<p>Example Response by Anthropic Claude v1 </p>
<p>Here are 10 paraphrased sentences of the original sentence with the placeholders retained: </p>
<ol>
<li>
<p>The molecule represented by the {SMILES description} code {SMILES data} has a 
{target name} of {target value}{target units}. </p>
</li>
<li>
<p>The {SMILES description} notation {SMILES data} denotes a molecule with a 
{target name} equal to {target value}{target units}. </p>
</li>
<li>
<p>A 
AcknowledgementsWe would like to specifically thank Jim Warren (NIST) for his contributions to discussions leading up to the hackathon and his participation as a judge during the event. We would also like to thank Anthony Costa and Christian Dallago (NVIDIA) for supporting the hackathon.B.B., I.T.F, and ZH acknowledge support from the the National Science Foundation awards #2226419 and #2209892. This work was performed under the following financial
Natural language processing models that automate programming will transform chemistry research and teaching. G M Hocky, A D White, Digital Discovery. 2022Hocky, G. M.; White, A. D. Natural language processing models that automate program- ming will transform chemistry research and teaching. Digital Discovery 2022, 1, 79-83.</p>
</li>
</ol>
<p>Is GPT-3 all you need for low-data discovery in chemistry?. K M Jablonka, P Schwaller, A Ortega-Guerrero, B Smit, 10.26434/chemrxiv-2023-fw8n42023Jablonka, K. M.; Schwaller, P.; Ortega-Guerrero, A.; Smit, B. Is GPT-3 all you need for low-data discovery in chemistry? ChemRxiv preprint 10.26434/chemrxiv-2023-fw8n4 2023,</p>
<p>Assessment of chemistry knowledge in large language models that generate code. A D White, G M Hocky, H A Gandhi, M Ansari, S Cox, G P Wellawatte, S Sasmal, Z Yang, K Liu, Y Singh, Digital DiscoveryWhite, A. D.; Hocky, G. M.; Gandhi, H. A.; Ansari, M.; Cox, S.; Wellawatte, G. P.; Sasmal, S.; Yang, Z.; Liu, K.; Singh, Y., et al. Assessment of chemistry knowledge in large language models that generate code. Digital Discovery 2023,</p>
<p>. M C Ramos, S S Michtavy, M D Porosoff, A D White, Bayesian Optimization of Catalysts With In-context Learning. arXiv preprintRamos, M. C.; Michtavy, S. S.; Porosoff, M. D.; White, A. D. Bayesian Optimization of Catalysts With In-context Learning. arXiv preprint: Arxiv-2304.05341 2023,</p>
<p>The future of chemistry is language. A D White, Nat. Rev. Chem. White, A. D. The future of chemistry is language. Nat. Rev. Chem. 2023,</p>
<p>Big data meets quantum chemistry approximations: the ∆-machine learning approach. R Ramakrishnan, P O Dral, M Rupp, O A Von Lilienfeld, J. Chem. Theory Comput. 11Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Big data meets quantum chemistry approximations: the ∆-machine learning approach. J. Chem. Theory Comput. 2015, 11, 2087-2096.</p>
<p>T Dinh, Y Zeng, R Zhang, Z Lin, M Gira, S Rajput, J.-Y Sohn, D Papailiopoulos, K Lee, Arxiv-2206.06565. 2022Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks. arXiv preprint. Dinh, T.; Zeng, Y.; Zhang, R.; Lin, Z.; Gira, M.; Rajput, S.; Sohn, J.-Y.; Papail- iopoulos, D.; Lee, K. LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks. arXiv preprint: Arxiv-2206.06565. 2022.</p>
<p>Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation. M Krenn, F Häse, A Nigam, P Friederich, A Aspuru-Guzik, Mach. Learn.: Sci. Technol. 202045024Krenn, M.; Häse, F.; Nigam, A.; Friederich, P.; Aspuru-Guzik, A. Self-referencing embed- ded strings (SELFIES): A 100% robust molecular string representation. Mach. Learn.: Sci. Technol. 2020, 1, 045024.</p>
<p>SELFIES and the future of molecular string representations. M Krenn, Q Ai, S Barthel, N Carson, A Frei, N C Frey, P Friederich, T Gaudin, A A Gayle, K M Jablonka, Patterns 2022, 3, 100588Krenn, M.; Ai, Q.; Barthel, S.; Carson, N.; Frei, A.; Frey, N. C.; Friederich, P.; Gaudin, T.; Gayle, A. A.; Jablonka, K. M., et al. SELFIES and the future of molecular string repre- sentations. Patterns 2022, 3, 100588.</p>
<p>Gaussian-4 theory using reduced order perturbation theory. L A Curtiss, P C Redfern, K Raghavachari, J. Chem. Phys. 124105Curtiss, L. A.; Redfern, P. C.; Raghavachari, K. Gaussian-4 theory using reduced order perturbation theory. J. Chem. Phys. 2007, 127, 124105.</p>
<p>Quantum chemistry structures and properties of 134 kilo molecules. R Ramakrishnan, P O Dral, M Rupp, O A Von Lilienfeld, Sci. Data. 1Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Quantum chemistry structures and properties of 134 kilo molecules. Sci. Data 2014, 1, 1-7.</p>
<p>Accurate quantum chemical energies for 133000 organic molecules. B Narayanan, P C Redfern, R S Assary, L A Curtiss, Chem. Sci. 10Narayanan, B.; Redfern, P. C.; Assary, R. S.; Curtiss, L. A. Accurate quantum chemical energies for 133000 organic molecules. Chem. Sci. 2019, 10, 7449-7455.</p>
<p>Three-Dimensional Convolutional Neural Networks Utilizing Molecular Topological Features for Accurate Atomization Energy Predictions. A K Gupta, K Raghavachari, J. Chem. Theory Comput. 18Gupta, A. K.; Raghavachari, K. Three-Dimensional Convolutional Neural Networks Uti- lizing Molecular Topological Features for Accurate Atomization Energy Predictions. J. Chem. Theory Comput. 2022, 18, 2132-2143.</p>
<p>A materials genome approach to accelerating materials innovation. APL Materials. 111002A materials genome approach to accelerating materials innovation. APL Materials 2013, 1, 011002.</p>
<p>Koes, D. 3Dmol.js: molecular visualization with WebGL. N Rego, Bioinformatics. 31Rego, N.; Koes, D. 3Dmol.js: molecular visualization with WebGL. Bioinformatics 2014, 31, 1322-1324.</p>
<p>. A White, G Hocky, Audio, White, A.; Hocky, G. marvis -VMD Audio/Text control with natural language. https: //github.com/whitead/marvis, 2022.</p>
<p>VMD: Visual molecular dynamics. W Humphrey, A Dalke, K Schulten, J. Mol. Graph. 14Humphrey, W.; Dalke, A.; Schulten, K. VMD: Visual molecular dynamics. J. Mol. Graph. 1996, 14, 33-38.</p>
<p>Robust speech recognition via large-scale weak supervision. A Radford, J W Kim, T Xu, G Brockman, C Mcleavey, I Sutskever, ArXiv-2212.04356. 2022arXiv preprintRadford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.; Sutskever, I. Robust speech recognition via large-scale weak supervision. arXiv preprint: ArXiv-2212.04356. 2022.</p>
<p>Accurate prediction of protein structures and interactions using a threetrack neural network. M Baek, Science. 373Baek, M. et al. Accurate prediction of protein structures and interactions using a three- track neural network. Science 2021, 373, 871-876.</p>
<p>Broadly applicable and accurate protein design by integrating structure prediction networks and diffusion generative models. J L Watson, bioRxivpreprint:10.1101/2022.12.09.519842.2022Watson, J. L. et al. Broadly applicable and accurate protein design by integrat- ing structure prediction networks and diffusion generative models. bioRxiv preprint: 10.1101/2022.12.09.519842. 2022.</p>
<p>OPTIMADE, an API for exchanging materials data. C W Andersen, Sci. Data. 8217Andersen, C. W. et al. OPTIMADE, an API for exchanging materials data. Sci. Data 2021, 8, 217.</p>
<p>AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning. A A Volk, R W Epps, D T Yonemoto, B S Masters, F N Castellano, K G Reyes, M Abolhasani, Nat. Commun. 2023. 141403Volk, A. A.; Epps, R. W.; Yonemoto, D. T.; Masters, B. S.; Castellano, F. N.; Reyes, K. G.; Abolhasani, M. AlphaFlow: autonomous discovery and optimization of multi-step chem- istry using a self-driven fluidic lab guided by reinforcement learning. Nat. Commun. 2023, 14, 1403.</p>
<p>Bayesian reaction optimization as a tool for chemical synthesis. B J Shields, J Stevens, J Li, M Parasram, F Damani, J I M Alvarado, J M Janey, R P Adams, A G Doyle, Nature. 590Shields, B. J.; Stevens, J.; Li, J.; Parasram, M.; Damani, F.; Alvarado, J. I. M.; Janey, J. M.; Adams, R. P.; Doyle, A. G. Bayesian reaction optimization as a tool for chemical synthesis. Nature 2021, 590, 89-96.</p>
<p>Accelerating reaction generality and mechanistic insight through additive mapping. C N Prieto Kullmer, J A Kautzky, S W Krska, T Nowak, S D Dreher, D W Macmillan, Science. 2022Prieto Kullmer, C. N.; Kautzky, J. A.; Krska, S. W.; Nowak, T.; Dreher, S. D.; MacMil- lan, D. W. Accelerating reaction generality and mechanistic insight through additive map- ping. Science 2022, 376, 532-539.</p>
<p>Bayesian optimisation for additive screening and yield improvements in chemical reactions -beyond one-hot encodings. B Ranković, R.-R Griffiths, H B Moss, P Schwaller, 10.26434/chemrxiv-2022-nll2j.2022ChemRxiv preprintRanković, B.; Griffiths, R.-R.; Moss, H. B.; Schwaller, P. Bayesian optimisation for addi- tive screening and yield improvements in chemical reactions -beyond one-hot encodings. ChemRxiv preprint 10.26434/chemrxiv-2022-nll2j. 2022.</p>
<p>Structured information extraction from complex scientific text with fine-tuned large language models. A Dunn, J Dagdelen, N Walker, S Lee, A S Rosen, G Ceder, K A Persson, A Jain, Arxiv-2212.05238 2022arXiv preprintDunn, A.; Dagdelen, J.; Walker, N.; Lee, S.; Rosen, A. S.; Ceder, G.; Persson, K. A.; Jain, A. Structured information extraction from complex scientific text with fine-tuned large language models. arXiv preprint: Arxiv-2212.05238 2022,</p>
<p>N Walker, J Dagdelen, K Cruse, S Lee, S Gleason, A Dunn, G Ceder, A P Alivisatos, K A Persson, Jain, A. Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3. arXiv preprint: Arxiv-2304. Walker, N.; Dagdelen, J.; Cruse, K.; Lee, S.; Gleason, S.; Dunn, A.; Ceder, G.; Alivisatos, A. P.; Persson, K. A.; Jain, A. Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3. arXiv preprint: Arxiv- 2304.13846 2023,</p>
<p>Neo4j -The World's Leading Graph Database. Neo4j, Neo4j, Neo4j -The World's Leading Graph Database. 2012; http://neo4j.org/.</p>
<p>The Open Reaction Database. S M Kearnes, M R Maser, M Wleklinski, A Kast, A G Doyle, S D Dreher, J M Hawkins, K F Jensen, C W Coley, J. Am. Chem. Kearnes, S. M.; Maser, M. R.; Wleklinski, M.; Kast, A.; Doyle, A. G.; Dreher, S. D.; Hawkins, J. M.; Jensen, K. F.; Coley, C. W. The Open Reaction Database. J. Am. Chem.</p>
<p>. Soc, 143Soc. 143, 18820-18826.</p>
<p>Alpaca: An Instruction-following LLaMA model. R Taori, I Gulrajani, T Zhang, Y Dubois, X Li, C Guestrin, P Liang, T B Hashimoto, Stanford, 2023Taori, R.; Gulrajani, I.; Zhang, T.; Dubois, Y.; Li, X.; Guestrin, C.; Liang, P.; Hashimoto, T. B. Stanford Alpaca: An Instruction-following LLaMA model. https: //github.com/tatsu-lab/stanford_alpaca, 2023.</p>
<p>. Alpaca-Lora, Alpaca-LoRA. https://github.com/tloen/alpaca-lora.</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, Open and efficient foundation language models. 2302arXiv preprintTouvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F., et al. Llama: Open and efficient foun- dation language models. arXiv preprint:2302.13971 2023,</p>
<p>Adsorption of CO 2 using biochar -Review of the impact of gas mixtures and water on adsorption. Z G Mamaghani, K A Hawboldt, S Macquarrie, J. Environ. Chem. Eng. 109643Mamaghani, Z. G.; Hawboldt, K. A.; MacQuarrie, S. Adsorption of CO 2 using biochar - Review of the impact of gas mixtures and water on adsorption. J. Environ. Chem. Eng. 2023, 11, 109643.</p>
<p>Methane Storage in Metal-Organic Frameworks: Current Records, Surprise Findings, and Challenges. Y Peng, V Krungleviciute, I Eryazici, J T Hupp, O K Farha, T Yildirim, J. Am. Chem. Soc. 135Peng, Y.; Krungleviciute, V.; Eryazici, I.; Hupp, J. T.; Farha, O. K.; Yildirim, T. Methane Storage in Metal-Organic Frameworks: Current Records, Surprise Findings, and Chal- lenges. J. Am. Chem. Soc. 2013, 135, 11887-11894.</p>
<p>A state-of-art review on 2D material-boosted metal oxide nanoparticle electrodes: Supercapacitor applications. B Sahoo, V Pandey, A Dogonchi, P Mohapatra, D Thatoi, N Nayak, M Nayak, J. Energy Storage. 65107335Sahoo, B.; Pandey, V.; Dogonchi, A.; Mohapatra, P.; Thatoi, D.; Nayak, N.; Nayak, M. A state-of-art review on 2D material-boosted metal oxide nanoparticle electrodes: Super- capacitor applications. J. Energy Storage 2023, 65, 107335.</p>
<p>Supported Metal Oxide Catalysts for CO 2 Fischer-Tropsch Conversion to Liquid Fuels-A Review. D D Suppiah, W M A W Daud, M R Johan, Energy Fuels. 35Suppiah, D. D.; Daud, W. M. A. W.; Johan, M. R. Supported Metal Oxide Catalysts for CO 2 Fischer-Tropsch Conversion to Liquid Fuels-A Review. Energy Fuels. 2021, 35, 17261-17278.</p>
<p>Comparison of the gasification performance of multiple biomass types in a bubbling fluidized bed. M González-Vázquez, R García, M Gil, C Pevida, F Rubiera, Energy Convers. Manag. 176González-Vázquez, M.; García, R.; Gil, M.; Pevida, C.; Rubiera, F. Comparison of the gasification performance of multiple biomass types in a bubbling fluidized bed. Energy Convers. Manag. 2018, 176, 309-323.</p>
<p>The electrochemical study of NixCe 1 -x O 2 -δ electrodes using natural gas as a fuel. M Mohsin, S Farhan, N Ahmad, A H Raza, Z N Kayani, S H M Jafri, R Raza, New J. Chem. 47Mohsin, M.; Farhan, S.; Ahmad, N.; Raza, A. H.; Kayani, Z. N.; Jafri, S. H. M.; Raza, R. The electrochemical study of NixCe 1 -x O 2 -δ electrodes using natural gas as a fuel. New J. Chem. 2023, 47, 8679-8692.</p>
<p>Review of perovskite-structure related cathode materials for solid oxide fuel cells. P Kaur, K Singh, Ceram. Int. 46Kaur, P.; Singh, K. Review of perovskite-structure related cathode materials for solid oxide fuel cells. Ceram. Int. 2020, 46, 5521-5535.</p>
<p>. R Sengottuvelu, Jsonformer, Sengottuvelu, R. jsonformer. https://github.com/1rgs/jsonformer, 2018.</p>
<p>. R Sengottuvelu, Jsonformer, Sengottuvelu, R. jsonformer. https://github.com/martinezpl/jsonformer/tree/ add-openai, 2018.</p>
<p>K Choudhary, M L Kelley, Chemnlp, arXiv:2209.082032022A Natural Language Processing based Library for Materials Chemistry Text Data. arXiv preprintChoudhary, K.; Kelley, M. L. ChemNLP: A Natural Language Processing based Library for Materials Chemistry Text Data. arXiv preprint arXiv:2209.08203 2022,</p>
<p>. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformerRaffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer.</p>
<p>. J. Mach. Learn. Res. 2020J. Mach. Learn. Res. 2020, 21, 5485-5551.</p>
<p>Transformers: State-of-the-Art Natural Language Processing. T Wolf, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsWolf, T. et al. Transformers: State-of-the-Art Natural Language Processing. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2020.</p>
<p>Tools such as ChatGPT threaten transparent science; here are our ground rules for their use. N Editorials, Nature. 613Editorials, N. Tools such as ChatGPT threaten transparent science; here are our ground rules for their use. Nature 2023, 613, 10-1038.</p>
<p>Using AI to Implement Effective Teaching Strategies in Classrooms: Five Strategies, Including Prompts. E R Mollick, L Mollick, SSRN Electronic Journal. Mollick, E. R.; Mollick, L. Using AI to Implement Effective Teaching Strategies in Class- rooms: Five Strategies, Including Prompts. SSRN Electronic Journal 2023,</p>
<p>. S Kim, J Chen, T Cheng, A Gindulyte, J He, S He, Q Li, B A Shoemaker, P A Thiessen, B Yu, L Zaslavsky, J Zhang, E E Bolton, Pubchem, Nucleic Acids Res. 51updateKim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.; Zaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2023 update. Nucleic Acids Res. 2022, 51, D1373-D1380.</p>
<p>An update on PUG-REST: RESTful interface for programmatic access to PubChem. S Kim, P A Thiessen, T Cheng, B Yu, E E Bolton, Nucleic Acids Res. 46Kim, S.; Thiessen, P. A.; Cheng, T.; Yu, B.; Bolton, E. E. An update on PUG-REST: RESTful interface for programmatic access to PubChem. Nucleic Acids Res. 2018, 46, W563-W570.</p>
<p>PubChem 2019 update: improved access to chemical data. S Kim, J Chen, T Cheng, A Gindulyte, J He, S He, Q Li, B A Shoemaker, P A Thiessen, B Yu, L Zaslavsky, J Zhang, E E Bolton, Nucleic Acids Res. 47Kim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.; Zaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2019 update: improved access to chemical data. Nucleic Acids Res. 2018, 47, D1102-D1109.</p>
<p>Censoring chemical data to mitigate dual use risk. Q Campbell, J Herington, A D White, Arxiv-2304.10510 2023, D. AbstractToTitle &amp; TitleToAbstract: text summarization and text generation. 1arXiv preprintCampbell, Q.; Herington, J.; White, A. D. Censoring chemical data to mitigate dual use risk. arXiv preprint: Arxiv-2304.10510 2023, D. AbstractToTitle &amp; TitleToAbstract: text summarization and text generation 1. Problem</p>
<p>Machine learning prediction of accurate atomization energies of organic molecules from low-fidelity quantum chemical calculations. L Ward, B Blaiszik, I Foster, R S Assary, B Narayanan, L Curtiss, MRS Commun. 9Ward, L.; Blaiszik, B.; Foster, I.; Assary, R. S.; Narayanan, B.; Curtiss, L. Machine learning prediction of accurate atomization energies of organic molecules from low-fidelity quantum chemical calculations. MRS Commun. 2019, 9, 891-899.</p>
<p>Gaussian-4 theory using reduced order perturbation theory. L A Curtiss, P C Redfern, K Raghavachari, J. Chem. Phys. 124105Curtiss, L. A.; Redfern, P. C.; Raghavachari, K. Gaussian-4 theory using reduced order perturbation theory. J. Chem. Phys. 2007, 127, 124105.</p>
<p>Quantum chemistry structures and properties of 134 kilo molecules. R Ramakrishnan, P O Dral, M Rupp, O A Von Lilienfeld, Sci. Data. 1Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Quantum chemistry structures and properties of 134 kilo molecules. Sci. Data 2014, 1, 1-7.</p>
<p>Accurate quantum chemical energies for 133000 organic molecules. B Narayanan, P C Redfern, R S Assary, L A Curtiss, Chem. Sci. 10Narayanan, B.; Redfern, P. C.; Assary, R. S.; Curtiss, L. A. Accurate quantum chemical energies for 133000 organic molecules. Chem. Sci. 2019, 10, 7449-7455.</p>
<p>SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. D Weininger, J. Chem. Inf. Comput. Sci. 28Weininger, D. SMILES, a chemical language and information system. 1. Introduction to methodology and en- coding rules. J. Chem. Inf. Comput. Sci. 1988, 28, 31-36.</p>
<p>Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation. M Krenn, F Häse, A Nigam, P Friederich, A Aspuru-Guzik, Mach. Learn.: Sci. Technol. 202045024Krenn, M.; Häse, F.; Nigam, A.; Friederich, P.; Aspuru-Guzik, A. Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation. Mach. Learn.: Sci. Technol. 2020, 1, 045024.</p>
<p>SELFIES and the future of molecular string representations. M Krenn, Q Ai, S Barthel, N Carson, A Frei, N C Frey, P Friederich, T Gaudin, A A Gayle, K M Jablonka, Patterns 2022, 3, 100588Krenn, M.; Ai, Q.; Barthel, S.; Carson, N.; Frei, A.; Frey, N. C.; Friederich, P.; Gaudin, T.; Gayle, A. A.; Jablonka, K. M., et al. SELFIES and the future of molecular string representations. Patterns 2022, 3, 100588.</p>
<p>Is GPT-3 all you need for low-data discovery in chemistry?. K M Jablonka, P Schwaller, A Ortega-Guerrero, B Smit, 10.26434/chemrxiv-2023-fw8n42023Jablonka, K. M.; Schwaller, P.; Ortega-Guerrero, A.; Smit, B. Is GPT-3 all you need for low-data discovery in chemistry? ChemRxiv preprint 10.26434/chemrxiv-2023-fw8n4 2023,</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in neural information processing systems 2020. 33Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems 2020, 33, 1877-1901.</p>
<p>Big data meets quantum chemistry approximations: the ∆-machine learning approach. R Ramakrishnan, P O Dral, M Rupp, O A Von Lilienfeld, J. Chem. Theory Comput. 11Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Big data meets quantum chemistry approxima- tions: the ∆-machine learning approach. J. Chem. Theory Comput. 2015, 11, 2087-2096.</p>
<p>Three-Dimensional Convolutional Neural Networks Utilizing Molecular Topological Features for Accurate Atomization Energy Predictions. A K Gupta, K Raghavachari, J. Chem. Theory Comput. 18Gupta, A. K.; Raghavachari, K. Three-Dimensional Convolutional Neural Networks Utilizing Molecular Topo- logical Features for Accurate Atomization Energy Predictions. J. Chem. Theory Comput. 2022, 18, 2132-2143.</p>
<p>State-of-the-art Parameter-Efficient Fine-Tuning methods. S Mangrulkar, S Gugger, L Debut, Y Belkada, S Paul, Peft, Mangrulkar, S.; Gugger, S.; Debut, L.; Belkada, Y.; Paul, S. PEFT: State-of-the-art Parameter-Efficient Fine- Tuning methods. https://github.com/huggingface/peft, 2022.</p>
<p>E J Hu, Y Shen, P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, W Chen, Lora, Low-Rank Adaptation of Large Language Models. arXiv preprintHu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; Chen, W. LoRA: Low-Rank Adaptation of Large Language Models. arXiv preprint: Arxiv-2106.09685 2021,</p>
<p>Sutskever, I. Language Models are Unsupervised Multitask Learners. A Radford, J Wu, R Child, D Luan, D Amodei, Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I. Language Models are Unsupervised Mul- titask Learners. 2019, https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_ are_unsupervised_multitask_learners.pdf.</p>
<p>Large Language Models are Zero-Shot Reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; Iwasawa, Y. Large Language Models are Zero-Shot Reasoners. 2023.</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, Open and efficient foundation language models. 2302arXiv preprintTouvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Ham- bro, E.; Azhar, F., et al. Llama: Open and efficient foundation language models. arXiv preprint:2302.13971 2023,</p>
<p>Evolutionary-scale prediction of atomic-level protein structure with a language model. Z Lin, H Akin, R Rao, B Hie, Z Zhu, W Lu, N Smetanin, R Verkuil, O Kabeli, Y Shmueli, Science. 379Lin, Z.; Akin, H.; Rao, R.; Hie, B.; Zhu, Z.; Lu, W.; Smetanin, N.; Verkuil, R.; Kabeli, O.; Shmueli, Y., et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science 2023, 379, 1123-1130.</p>
<p>Global Co2 Emissions From Cement Production. R Andrew, Andrew, R. Global Co2 Emissions From Cement Production. 2017; https://zenodo.org/record/831455.</p>
<p>Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design. npj Comput. T Lookman, P V Balachandran, D Xue, R Yuan, Lookman, T.; Balachandran, P. V.; Xue, D.; Yuan, R. Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design. npj Comput. Mater. 2019, 5 .</p>
<p>Sequential learning to accelerate discovery of alkali-activated binders. C Völker, R Firdous, D Stephan, S Kruschwitz, Journal of Materials Science. 56Völker, C.; Firdous, R.; Stephan, D.; Kruschwitz, S. Sequential learning to accelerate discovery of alkali-activated binders. Journal of Materials Science 2021, 56, 15859-15881.</p>
<p>. C Völker, Benjami Moreno, Torres, Völker, C.; Benjami Moreno Torres,;</p>
<p>. Tehseen Rug. Tehseen Rug,;</p>
<p>. R Firdous, Ghezal AhmadFirdous, R.; Ghezal Ahmad,;</p>
<p>Green building materials: a new frontier in data-driven sustainable concrete design. J Zia, S Lüders, H L Scaffino, M Höpler, F Böhmer, M Pfaff, D Stephan, S Kruschwitz, 10.13140/RG.2.2.29079.85925.2023Zia, J.; Lüders, S.; Scaffino, H. L.; Höpler, M.; Böhmer, F.; Pfaff, M.; Stephan, D.; Kruschwitz, S. Green building materials: a new frontier in data-driven sustainable concrete design. Preprint 10.13140/RG.2.2.29079.85925. 2023.</p>
<p>. M C Ramos, S S Michtavy, M D Porosoff, A D White, Bayesian Optimization of Catalysts With In-context Learning. arXiv preprintRamos, M. C.; Michtavy, S. S.; Porosoff, M. D.; White, A. D. Bayesian Optimization of Catalysts With In-context Learning. arXiv preprint: Arxiv-2304.05341 2023,</p>
<p>A quantitative method of approach in designing the mix proportions of fly ash and GGBS-based geopolymer concrete. G M Rao, T D G Rao, Aust. J. Civ. Eng. 16Rao, G. M.; Rao, T. D. G. A quantitative method of approach in designing the mix proportions of fly ash and GGBS-based geopolymer concrete. Aust. J. Civ. Eng. 2018, 16, 53-63.</p>
<p>. Openai, Text-davinci-003OpenAI, Text-davinci-003. https://platform.openai.com/models/text-davinci-003.</p>
<p>. A Bousquet, Lolopy, Bousquet, A. lolopy. https://pypi.org/project/lolopy/, 2017; Accessed: 2023-02-27.</p>
<p>Principles and Procedures of Statistics. (With special Reference to the Biological Sciences. O Heinisch, R G D Steel, J H Torrie, Biometrische Zeitschrift. 4McGraw-Hill Book Company481 S., 15 Abb. 81 s 6 dHeinisch, O. Steel, R. G. D., and J. H. Torrie: Principles and Procedures of Statistics. (With special Reference to the Biological Sciences.) McGraw-Hill Book Company, New York, Toronto, London 1960, 481 S., 15 Abb. 81 s 6 d. Biometrische Zeitschrift 1962, 4, 207-208.</p>
<p>T Dinh, Y Zeng, R Zhang, Z Lin, M Gira, S Rajput, J.-Y Sohn, D Papailiopoulos, K Lee, Arxiv-2206.06565. 2022Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks. arXiv preprint. Dinh, T.; Zeng, Y.; Zhang, R.; Lin, Z.; Gira, M.; Rajput, S.; Sohn, J.-Y.; Papailiopoulos, D.; Lee, K. LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks. arXiv preprint: Arxiv-2206.06565. 2022.</p>
<p>The Net-Zero Challenge: Fast-Forward to Decisive Climate Action. P Herhold, E Farnworth, World Economic Forum. 2020Herhold, P.; Farnworth, E. The Net-Zero Challenge: Fast-Forward to Decisive Climate Action. World Economic Forum, available at: https://www3. weforum. org/docs/WEF The Net Zero Challenge. pdf (accessed 4 October 2021). 2020.</p>
<p>Z Hong, A Ajith, G Pauloski, E Duede, C Malamud, R Magoulas, K Chard, I Foster, Scholarbert, Arxiv-2205.11342. 2022Bigger is Not Always Better. arXiv preprint. Hong, Z.; Ajith, A.; Pauloski, G.; Duede, E.; Malamud, C.; Magoulas, R.; Chard, K.; Foster, I. ScholarBERT: Bigger is Not Always Better. arXiv preprint: Arxiv-2205.11342. 2022.</p>
<p>PubChem substance and compound databases. S Kim, P A Thiessen, E E Bolton, J Chen, G Fu, A Gindulyte, L Han, J He, S He, B A Shoemaker, Nucleic acids research. 44Kim, S.; Thiessen, P. A.; Bolton, E. E.; Chen, J.; Fu, G.; Gindulyte, A.; Han, L.; He, J.; He, S.; Shoemaker, B. A., et al. PubChem substance and compound databases. Nucleic acids research 2016, 44, D1202-D1213.</p>
<p>H Dai, Arxiv-2302.13007. 2023Leveraging ChatGPT for Text Data Augmentation. arXiv preprintDai, H. et al. AugGPT: Leveraging ChatGPT for Text Data Augmentation. arXiv preprint: Arxiv-2302.13007. 2023.</p>
<p>Transformers: State-of-the-Art Natural Language Processing. T Wolf, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online. the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. OnlineWolf, T. et al. Transformers: State-of-the-Art Natural Language Processing. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online, 2020; pp 38-45.</p>
<p>Scikit-learn: Machine Learning in Python. F Pedregosa, Journal of Machine Learning Research. 12Pedregosa, F. et al. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 2011, 12, 2825-2830.</p>
<p>Know What You Don't Know: Unanswerable Questions for SQuAD. P Rajpurkar, R Jia, P Liang, Rajpurkar, P.; Jia, R.; Liang, P. Know What You Don't Know: Unanswerable Questions for SQuAD. 2018,</p>
<p>Fast multi-resolution transformer fine-tuning for extreme multilabel text classification. J Zhang, W.-C Chang, H.-F Yu, I Dhillon, Adv. Neural Inf. Process. Syst. 34Zhang, J.; Chang, W.-C.; Yu, H.-F.; Dhillon, I. Fast multi-resolution transformer fine-tuning for extreme multi- label text classification. Adv. Neural Inf. Process. Syst. 2021, 34, 7267-7280.</p>
<p>Assessment of chemistry knowledge in large language models that generate code. A D White, G M Hocky, H A Gandhi, M Ansari, S Cox, G P Wellawatte, S Sasmal, Z Yang, K Liu, Y Singh, Digital DiscoveryWhite, A. D.; Hocky, G. M.; Gandhi, H. A.; Ansari, M.; Cox, S.; Wellawatte, G. P.; Sasmal, S.; Yang, Z.; Liu, K.; Singh, Y., et al. Assessment of chemistry knowledge in large language models that generate code. Digital Discovery 2023,</p>
<p>Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction. P Schwaller, T Laino, T Gaudin, P Bolgar, C A Hunter, C Bekas, A A Lee, ACS Central Science. 5Schwaller, P.; Laino, T.; Gaudin, T.; Bolgar, P.; Hunter, C. A.; Bekas, C.; Lee, A. A. Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction. ACS Central Science 2019, 5, 1572-1583.</p>
<p>Theoretical thermodynamics for large molecules: walking the thin line between accuracy and computational cost. T Schwabe, S Grimme, Acc. Chem. Res. 41Schwabe, T.; Grimme, S. Theoretical thermodynamics for large molecules: walking the thin line between accuracy and computational cost. Acc. Chem. Res. 2008, 41, 569-579.</p>
<p>A review of methods for the calculation of solution free energies and the modelling of systems in solution. R E Skyner, J L Mcdonagh, C R Groom, T Van Mourik, J B Mitchell, Phys. Chem. Chem. Phys. 17Skyner, R. E.; McDonagh, J. L.; Groom, C. R.; van Mourik, T.; Mitchell, J. B. O. A review of methods for the calculation of solution free energies and the modelling of systems in solution. Phys. Chem. Chem. Phys. 2015, 17, 6174-6191.</p>
<p>From DFT to machine learning: recent approaches to materials science-a review. G R Schleder, A C M Padilha, C M Acosta, M Costa, A Fazzio, J. Phys. Mater. Schleder, G. R.; Padilha, A. C. M.; Acosta, C. M.; Costa, M.; Fazzio, A. From DFT to machine learning: recent approaches to materials science-a review. J. Phys. Mater. 2019, 2, 032001.</p>
<p>. H Chase, Langchain, Chase, H. LangChain. 2022; https://github.com/hwchase17/langchain.</p>
<p>A M Bran, S Cox, A D White, P Schwaller, Chemcrow, Augmenting large-language models with chemistry tools. arXiv preprint: Arxiv-2304. 053762023Bran, A. M.; Cox, S.; White, A. D.; Schwaller, P. ChemCrow: Augmenting large-language models with chemistry tools. arXiv preprint: Arxiv-2304.05376 2023,</p>
<p>Commentary: The Materials Project: A materials genome approach to accelerating materials innovation. A Jain, S P Ong, G Hautier, W Chen, W D Richards, S Dacek, S Cholia, D Gunter, D Skinner, G Ceder, K A Persson, APL Materials. 111002Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G.; Persson, K. A. Commentary: The Materials Project: A materials genome approach to accelerating materials innovation. APL Materials 2013, 1, 011002.</p>
<p>A Graph-Based Network for Predicting Chemical Reaction Pathways in Solid-State Materials Synthesis. M J Mcdermott, S S Dwaraknath, K A Persson, Nat. Commun. 2021. 123097McDermott, M. J.; Dwaraknath, S. S.; Persson, K. A. A Graph-Based Network for Predicting Chemical Reaction Pathways in Solid-State Materials Synthesis. Nat. Commun. 2021, 12, 3097.</p>
<p>Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models. Z Shao, Y Gong, Y Shen, M Huang, N Duan, W Chen, Shao, Z.; Gong, Y.; Shen, Y.; Huang, M.; Duan, N.; Chen, W. Synthetic Prompting: Generating Chain-of- Thought Demonstrations for Large Language Models. 2023,</p>
<p>Scaling Laws for Reward Model Overoptimization. L Gao, J Schulman, J Hilton, ARXIV.ORG 2022Gao, L.; Schulman, J.; Hilton, J. Scaling Laws for Reward Model Overoptimization. ARXIV.ORG 2022,</p>
<p>Koes, D. 3Dmol.js: molecular visualization with WebGL. N Rego, Bioinformatics. 31Rego, N.; Koes, D. 3Dmol.js: molecular visualization with WebGL. Bioinformatics 2014, 31, 1322-1324.</p>
<p>. L Schrödinger, W Delano, Pymol, Schrödinger, L.; DeLano, W. PyMOL. http://www.pymol.org/pymol.</p>
<p>Mol * Viewer: modern web app for 3D visualization and analysis of large biomolecular structures. D Sehnal, S Bittrich, M Deshpande, R Svobodová, K Berka, V Bazgier, S Velankar, S K Burley, J Koča, A S Rose, Nucleic Acids Res. 49Sehnal, D.; Bittrich, S.; Deshpande, M.; Svobodová, R.; Berka, K.; Bazgier, V.; Velankar, S.; Burley, S. K.; Koča, J.; Rose, A. S. Mol * Viewer: modern web app for 3D visualization and analysis of large biomolecular structures. Nucleic Acids Res. 2021, 49, W431-W437.</p>
<p>S Yao, J Zhao, D Yu, N Du, I Shafran, K Narasimhan, Y Cao, Arxiv-2210.03629Synergizing Reasoning and Acting in Language Models. arXiv preprintYao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.; Cao, Y. ReAct: Synergizing Reasoning and Acting in Language Models. arXiv preprint: Arxiv-2210.03629 2023,</p>
<p>LAMMPS -a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales. A P Thompson, H M Aktulga, R Berger, D S Bolintineanu, W M Brown, P S Crozier, P J Veld, A Kohlmeyer, S G Moore, T D Nguyen, R Shan, M J Stevens, J Tranchida, C Trott, S J Plimpton, Comp. Phys. Comm. 108171Thompson, A. P.; Aktulga, H. M.; Berger, R.; Bolintineanu, D. S.; Brown, W. M.; Crozier, P. S.; in 't Veld, P. J.; Kohlmeyer, A.; Moore, S. G.; Nguyen, T. D.; Shan, R.; Stevens, M. J.; Tranchida, J.; Trott, C.; Plimpton, S. J. LAMMPS -a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales. Comp. Phys. Comm. 2022, 271, 108171.</p>
<p>High performance molecular simulations through multi-level parallelism from laptops to supercomputers. M J Abraham, T Murtola, R Schulz, S Páll, J C Smith, B Hess, E Lindahl, Gromacs, Abraham, M. J.; Murtola, T.; Schulz, R.; Páll, S.; Smith, J. C.; Hess, B.; Lindahl, E. GROMACS: High performance molecular simulations through multi-level parallelism from laptops to supercomputers. SoftwareX 2015, 1-2, 19-25.</p>
<p>AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning. A A Volk, R W Epps, D T Yonemoto, B S Masters, F N Castellano, K G Reyes, M Abolhasani, Nat. Commun. 141403Volk, A. A.; Epps, R. W.; Yonemoto, D. T.; Masters, B. S.; Castellano, F. N.; Reyes, K. G.; Abolhasani, M. AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning. Nat. Commun. 2023, 14, 1403.</p>
<p>GAUCHE: A Library for Gaussian Processes in Chemistry. R.-R Griffiths, arXiv:2212.04450cond-mat, physics:physicsGriffiths, R.-R. et al. GAUCHE: A Library for Gaussian Processes in Chemistry. 2022; http://arxiv.org/abs/ 2212.04450, arXiv:2212.04450 [cond-mat, physics:physics].</p>
<p>Bayesian reaction optimization as a tool for chemical synthesis. B J Shields, J Stevens, J Li, M Parasram, F Damani, J I M Alvarado, J M Janey, R P Adams, A G Doyle, Nature. 590Shields, B. J.; Stevens, J.; Li, J.; Parasram, M.; Damani, F.; Alvarado, J. I. M.; Janey, J. M.; Adams, R. P.; Doyle, A. G. Bayesian reaction optimization as a tool for chemical synthesis. Nature 2021, 590, 89-96.</p>
<p>Bayesian optimisation for additive screening and yield improvements in chemical reactions -beyond one-hot encodings. B Ranković, R.-R Griffiths, H B Moss, P Schwaller, 10.26434/chemrxiv-2022-nll2j.2022ChemRxiv preprintRanković, B.; Griffiths, R.-R.; Moss, H. B.; Schwaller, P. Bayesian optimisation for additive screening and yield improvements in chemical reactions -beyond one-hot encodings. ChemRxiv preprint 10.26434/chemrxiv-2022- nll2j. 2022.</p>
<p>Neo4j -The World's Leading Graph Database. Neo4j, Neo4j, Neo4j -The World's Leading Graph Database. 2012; http://neo4j.org/.</p>
<p>V Venugopal, S Pai, E Olivetti, Matkg, The Largest Knowledge Graph in Materials Science-Entities, Relations, and Link Prediction through Graph Representation Learning. 2210arXiv preprintVenugopal, V.; Pai, S.; Olivetti, E. MatKG: The Largest Knowledge Graph in Materials Science-Entities, Rela- tions, and Link Prediction through Graph Representation Learning. arXiv preprint:2210.17340 2022,</p>
<p>Creating and Visualizing the Materials Science Knowledge Graph with Whyis. J P Mccusker, M Deagen, T Fateye, A Wallace, S M Rashid, D L Mcguinness, 2021McCusker, J. P.; Deagen, M.; Fateye, T.; Wallace, A.; Rashid, S. M.; McGuinness, D. L. Creating and Visualizing the Materials Science Knowledge Graph with Whyis. ISWC (Posters/Demos/Industry). 2021.</p>
<p>Structured information extraction from complex scientific text with fine-tuned large language models. A Dunn, J Dagdelen, N Walker, S Lee, A S Rosen, G Ceder, K A Persson, A Jain, arXiv preprintDunn, A.; Dagdelen, J.; Walker, N.; Lee, S.; Rosen, A. S.; Ceder, G.; Persson, K. A.; Jain, A. Structured information extraction from complex scientific text with fine-tuned large language models. arXiv preprint: Arxiv- 2212.05238 2022,</p>
<p>Smart Manufacturing -A Case for Creating a Knowledge Network Using Data Mining. S Badhwar, Badhwar, S. Smart Manufacturing -A Case for Creating a Knowledge Network Using Data Mining. 2022.</p>
<p>NanoMine: A knowledge graph for nanocomposite materials science. J P Mccusker, N Keshan, S Rashid, M Deagen, C Brinson, D L Mcguinness, The Semantic Web-ISWC 2020: 19th International Semantic Web Conference. Athens, GreeceMcCusker, J. P.; Keshan, N.; Rashid, S.; Deagen, M.; Brinson, C.; McGuinness, D. L. NanoMine: A knowledge graph for nanocomposite materials science. The Semantic Web-ISWC 2020: 19th International Semantic Web Conference, Athens, Greece, November 2-6, 2020, Proceedings, Part II. 2020; pp 144-159.</p>
<p>The Open Reaction Database. S M Kearnes, M R Maser, M Wleklinski, A Kast, A G Doyle, S D Dreher, J M Hawkins, K F Jensen, C W Coley, J. Am. Chem. Soc. 143Kearnes, S. M.; Maser, M. R.; Wleklinski, M.; Kast, A.; Doyle, A. G.; Dreher, S. D.; Hawkins, J. M.; Jensen, K. F.; Coley, C. W. The Open Reaction Database. J. Am. Chem. Soc. 143, 18820-18826.</p>
<p>Alpaca: An Instruction-following LLaMA model. R Taori, I Gulrajani, T Zhang, Y Dubois, X Li, C Guestrin, P Liang, T B Hashimoto, Stanford, 2023Taori, R.; Gulrajani, I.; Zhang, T.; Dubois, Y.; Li, X.; Guestrin, C.; Liang, P.; Hashimoto, T. B. Stanford Alpaca: An Instruction-following LLaMA model. https://github.com/tatsu-lab/stanford_alpaca, 2023.</p>
<p>. Alpaca-Lora, Alpaca-LoRA. https://github.com/tloen/alpaca-lora.</p>
<p>Tablext: A combined neural network and heuristic based table extractor. Z Colter, M Fayazi, Z B Youbi, .-E Kamp, S Yu, S Dreslinski, R , 15100220Colter, Z.; Fayazi, M.; Youbi, Z. B.-E.; Kamp, S.; Yu, S.; Dreslinski, R. Tablext: A combined neural network and heuristic based table extractor. Array 2022, 15, 100220.</p>
<p>Adsorption of CO2 using biochar -Review of the impact of gas mixtures and water on adsorption. Z G Mamaghani, K A Hawboldt, S Macquarrie, J. Environ. Chem. Eng. 11109643Mamaghani, Z. G.; Hawboldt, K. A.; MacQuarrie, S. Adsorption of CO2 using biochar -Review of the impact of gas mixtures and water on adsorption. J. Environ. Chem. Eng. 2023, 11, 109643.</p>
<p>Methane Storage in Metal-Organic Frameworks: Current Records, Surprise Findings, and Challenges. Y Peng, V Krungleviciute, I Eryazici, J T Hupp, O K Farha, T Yildirim, J. Am. Chem. Soc. 135Peng, Y.; Krungleviciute, V.; Eryazici, I.; Hupp, J. T.; Farha, O. K.; Yildirim, T. Methane Storage in Metal-Organic Frameworks: Current Records, Surprise Findings, and Challenges. J. Am. Chem. Soc. 2013, 135, 11887-11894.</p>
<p>A state-of-art review on 2D material-boosted metal oxide nanoparticle electrodes: Supercapacitor applications. B Sahoo, V Pandey, A Dogonchi, P Mohapatra, D Thatoi, N Nayak, M Nayak, J. Energy Storage. 65107335Sahoo, B.; Pandey, V.; Dogonchi, A.; Mohapatra, P.; Thatoi, D.; Nayak, N.; Nayak, M. A state-of-art review on 2D material-boosted metal oxide nanoparticle electrodes: Supercapacitor applications. J. Energy Storage 2023, 65, 107335.</p>
<p>Supported Metal Oxide Catalysts for CO2 Fischer-Tropsch Conversion to Liquid Fuels-A Review. D D Suppiah, W M A W Daud, M R Johan, Energy Fuels. 35Suppiah, D. D.; Daud, W. M. A. W.; Johan, M. R. Supported Metal Oxide Catalysts for CO2 Fischer-Tropsch Conversion to Liquid Fuels-A Review. Energy Fuels. 2021, 35, 17261-17278.</p>
<p>Comparison of the gasification performance of multiple biomass types in a bubbling fluidized bed. M González-Vázquez, R García, M Gil, C Pevida, F Rubiera, Energy Convers. Manag. 176González-Vázquez, M.; García, R.; Gil, M.; Pevida, C.; Rubiera, F. Comparison of the gasification performance of multiple biomass types in a bubbling fluidized bed. Energy Convers. Manag. 2018, 176, 309-323.</p>
<p>The electrochemical study of NixCe1-x O2-δ electrodes using natural gas as a fuel. M Mohsin, S Farhan, N Ahmad, A H Raza, Z N Kayani, S H M Jafri, R Raza, New J. Chem. 47Mohsin, M.; Farhan, S.; Ahmad, N.; Raza, A. H.; Kayani, Z. N.; Jafri, S. H. M.; Raza, R. The electrochemical study of NixCe1-x O2-δ electrodes using natural gas as a fuel. New J. Chem. 2023, 47, 8679-8692.</p>
<p>Review of perovskite-structure related cathode materials for solid oxide fuel cells. P Kaur, K Singh, Ceram. Int. 46Kaur, P.; Singh, K. Review of perovskite-structure related cathode materials for solid oxide fuel cells. Ceram. Int. 2020, 46, 5521-5535.</p>
<p>. R Sengottuvelu, Jsonformer, Sengottuvelu, R. jsonformer. https://github.com/1rgs/jsonformer, 2018.</p>
<p>K Choudhary, M L Kelley, Chemnlp, arXiv:2209.082032022A Natural Language Processing based Library for Materials Chemistry Text Data. arXiv preprintChoudhary, K.; Kelley, M. L. ChemNLP: A Natural Language Processing based Library for Materials Chemistry Text Data. arXiv preprint arXiv:2209.08203 2022,</p>
<p>MgB2 under pressure: phonon calculations, Raman spectroscopy, and optical reflectance. K Kunc, I Loa, K Syassen, R Kremer, K Ahn, cond-mat/0105402arXiv preprintKunc, K.; Loa, I.; Syassen, K.; Kremer, R.; Ahn, K. MgB2 under pressure: phonon calculations, Raman spec- troscopy, and optical reflectance. arXiv preprint cond-mat/0105402</p>
<p>last accessed 2023-05-30FameLab International -Cheltenham Festivals. FameLab International -Cheltenham Festivals. https://www.cheltenhamfestivals.com/famelab,last accessed 2023-05-30.</p>
<p>MT 180 -My Thesis in 180 Seconds. MT 180 -My Thesis in 180 Seconds. https://www.epfl.ch/campus/events/events/public-events/ my-thesis-in-180-seconds,last accessed 2023-07-07.</p>
<p>. Clipdigest, ClIPDIGEST. https://clipdigest.com/, last accessed 2023-05-30.</p>
<p>Robust speech recognition via large-scale weak supervision. A Radford, J W Kim, T Xu, G Brockman, C Mcleavey, I Sutskever, ArXiv-2212.04356. 2022arXiv preprintRadford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.; Sutskever, I. Robust speech recognition via large-scale weak supervision. arXiv preprint: ArXiv-2212.04356. 2022.</p>
<p>. S Kim, J Chen, T Cheng, A Gindulyte, J He, S He, Q Li, B A Shoemaker, P A Thiessen, B Yu, L Zaslavsky, J Zhang, E E Bolton, Pubchem, Nucleic Acids Res. 51updateKim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.; Zaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2023 update. Nucleic Acids Res. 2022, 51, D1373-D1380.</p>
<p>PubChem 2019 update: improved access to chemical data. S Kim, J Chen, T Cheng, A Gindulyte, J He, S He, Q Li, B A Shoemaker, P A Thiessen, B Yu, L Zaslavsky, J Zhang, E E Bolton, Nucleic Acids Res. 47Kim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He, S.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.; Zaslavsky, L.; Zhang, J.; Bolton, E. E. PubChem 2019 update: improved access to chemical data. Nucleic Acids Res. 2018, 47, D1102-D1109.</p>
<p>An update on PUG-REST: RESTful interface for programmatic access to PubChem. S Kim, P A Thiessen, T Cheng, B Yu, E E Bolton, Nucleic Acids Res. 46Kim, S.; Thiessen, P. A.; Cheng, T.; Yu, B.; Bolton, E. E. An update on PUG-REST: RESTful interface for programmatic access to PubChem. Nucleic Acids Res. 2018, 46, W563-W570.</p>
<p>. Streamlit, Streamlit. https://streamlit.io/. Acronyms AI: artificial intelligence.</p>
<p>COT: chain of thought. DFT: density functional theory. CAS: Chemical Abstract Services. API: application programming interfaceAPI: application programming interface. BO: Bayesian optimization. CAS: Chemical Abstract Services. COT: chain of thought. DFT: density functional theory.</p>
<p>ELN: electronic lab notebook. DOI: digital object identifier. DOI: digital object identifier. ELN: electronic lab notebook.</p>
<p>GA: genetic algorithm. GPR: Gaussian process regression. GA: genetic algorithm. GPR: Gaussian process regression.</p>
<p>GPT: generative pretrained transformer. GUI: graphical user interface. HTML: HyperText Markup Language. ICL: in-context learning. GPT: generative pretrained transformer. GUI: graphical user interface. HTML: HyperText Markup Language. ICL: in-context learning.</p>
<p>ID: inverse design. InChI: international chemical identifier. JSON: JavaScript object notation. LIFT: language. interfaced fine-tuningID: inverse design. InChI: international chemical identifier. JSON: JavaScript object notation. LIFT: language-interfaced fine-tuning.</p>
<p>LIMS: laboratory information system. LLM: large language model. LIMS: laboratory information system. LLM: large language model.</p>
<p>LoRA: low-rank adaptors. MAD: median absolute deviation. LoRA: low-rank adaptors. MAD: median absolute deviation.</p>
<p>MAE: mean absolute error. MAPI: Materials Project API. MAE: mean absolute error. MAPI: Materials Project API.</p>
<p>NLM: national library of medicine. NLP: natural language processing. OCR: optical character recognition. Acronyms 46 ORD: Open Reaction Database. PDB: protein data bank. ML: machine learning. NER: named entity recognition. PEFT: parameter efficient fine-tuningML: machine learning. NER: named entity recognition. NLM: national library of medicine. NLP: natural language processing. OCR: optical character recognition. Acronyms 46 ORD: Open Reaction Database. PDB: protein data bank. PEFT: parameter efficient fine-tuning.</p>
<p>ROUGE: Recall-Oriented Understudy for Gisting Evaluation. SELFIES: self-referencing embedded strings. SMILES: simplified molecular-input line-entry system. RF: random forest. RLHF: reinforcement learning from human feedback. SVM: support vector machineRF: random forest. RLHF: reinforcement learning from human feedback. ROUGE: Recall-Oriented Understudy for Gisting Evaluation. SELFIES: self-referencing embedded strings. SMILES: simplified molecular-input line-entry system. SVM: support vector machine.</p>
<p>UI: user interface. UI: user interface.</p>            </div>
        </div>

    </div>
</body>
</html>