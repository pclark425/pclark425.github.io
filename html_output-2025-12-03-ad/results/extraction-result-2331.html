<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2331 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2331</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2331</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-246281204</p>
                <p><strong>Paper Title:</strong> Reviewing machine learning of corrosion prediction in a data-oriented perspective</p>
                <p><strong>Paper Abstract:</strong> This work provides a data-oriented overview of the rapidly growing research ﬁ eld covering machine learning (ML) applied to predicting electrochemical corrosion. Our main aim was to determine which ML models have been applied and how well they performed depending on the corrosion topic considered. From an extensive review of corrosion articles presenting comparable performance metrics, a ‘ Machine learning for corrosion database ’ was created, guiding corrosion experts and model developers in their applications of ML to corrosion. Potential research gaps and recommendations are discussed, and a broad perspective for future research paths is provided.</p>
                <p><strong>Cost:</strong> 0.028</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2331.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2331.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ANN_atmospheric_Cai1999</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Artificial Neural Network for atmospheric corrosion (Cai et al. 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Feed-forward/backpropagation neural network used to model atmospheric corrosion rates and depths from multi-source environmental data; used sensitivity analysis to extract variable importance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Phenomenological modelling of atmospheric corrosion using an artificial neural network.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Atmospheric corrosion prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict corrosion rates and corrosion depths of steel and zinc exposed to outdoor atmospheric conditions using environmental and pollutant descriptors aggregated from worldwide datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited to moderate: multi-source compiled dataset (from multiple publications, 42 sources) with noise and bias; labelled supervised data (corrosion rates/depths); small-to-moderate sample size for long-term predictions and noisy heterogenous measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data aggregated from literature: environmental variables (T, RH, SO2, Cl-, rainfall, TOW), material descriptors; time-related features limited; high dimensionality and noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High non-linearity and heterogeneity; high variance in measurements due to multiple data sources; multi-variable interactions (e.g., TOW, SO2, RH) and temporal dependence not fully represented.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established field with empirical models (log-linear, power laws, Arrhenius) but ML application was pioneering; moderate domain knowledge available but incomplete mechanistic capture.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — interpretation and knowledge mining desired to relate predictors (SO2, TOW, pH) to corrosion mechanisms, not just black-box prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Artificial Neural Network (backpropagation)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised feed-forward ANN trained by backpropagation using compiled environmental and material features; sensitivity analysis performed to rank input importance (e.g., effect of TOW, SO2). No deep architectures; standard ANN regression.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and appropriate for nonlinear interpolation across heterogeneous atmospheric datasets; limited extrapolation to very long-term predictions due to data scarcity.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported testing performance: steel R² = 0.548 (MAPE = 39%); zinc R² = 0.608 (MAPE = 53%).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Worked reasonably for interpolation and revealed plausible variable importance (e.g., moisture and pollutant effects) but high variance and limited long-term extrapolation due to incomplete features and noisy, multi-source data.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Provided early demonstration that ANN can model nonlinear atmospheric corrosion and extract domain-relevant patterns; potential to improve predictions with more and cleaner data and additional features.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed prior linear regression approaches in capturing nonlinear behaviour; however, limited long-term predictive ability compared to what might be achievable with larger, more representative datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Ability of ANN to fit nonlinear relationships and perform sensitivity analysis; availability of multi-source labelled data allowed training despite noise; shortcomings due to small/heterogeneous dataset for long-term extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>ANNs can capture nonlinear environmental-material interactions in atmospheric corrosion and provide variable-importance insights, but predictive utility is limited by noisy, heterogeneous, and insufficient long-term data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2331.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RF_atmospheric_Zhi2019</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Forest for outdoor atmospheric corrosion of low-alloy steels (Zhi et al. 2019)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Random Forest regression applied to multi-material, multi-station atmospheric corrosion datasets to predict corrosion rates and perform knowledge mining (feature importance, time-split analyses).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prediction and knowledge mining of outdoor atmospheric corrosion rates of low alloy steels based on the random forests approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Atmospheric corrosion of low-alloy steels</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Forecast outdoor corrosion rates (CR) across different materials and environmental monitoring stations over up to 16 years' exposures; tackle steep-manifold structure, nonlinearity and small sample sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited/moderate: dataset comprised corrosion data of 17 low-alloy steels across 6 stations over 16 years (relatively small sample counts per combination); labelled supervised data; structured but small and heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data with environmental descriptors (pH, SO2, Cl-, T, RH, rainfall), material composition; time series split into sub-datasets by exposure time (1, 2, 4, 8, 16 years).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: nonlinear, steep-manifold structure, relatively small sample counts per manifold, temporal dependence, multi-factor interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied corrosion field with domain knowledge but limited comprehensive datasets for ML; growing adoption of ML methods.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — feature importance and interpretability valued to identify dominant environmental vs material influences and provide operational thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Random Forest (RF)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Ensemble of decision trees used for regression; trained on tabular corrosion features; used for prediction and feature-importance analysis over whole and time-split datasets; relatively robust to small sample sizes and nonlinearity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / ensemble tree-based</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable for this structured, nonlinear problem and small-to-moderate dataset sizes; less sensitive to small sample sizes than kernel methods in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported testing MAPE = 16.08% (RF) on LAS dataset; ANN testing MAPE = 22.12%; LR and SVR testing MAPE = 45.63% and 41.35% respectively.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>RF demonstrated best generalisation among tested methods on small LAS datasets and supplied interpretable feature importance results (e.g., pH, Cl− importance). Limitations: still affected by data sparsity in certain regimes and limited extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enabled identification of dominant drivers (environment > material initially), quantitative thresholds for environmental variables, and improved predictive accuracy vs linear/kernel methods; useful for monitoring and design decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Direct comparisons showed RF outperformed LR and SVR markedly and outperformed ANN in generalisation for the dataset sizes considered; ANN and tree-based were more stable than kernel methods.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Tree ensembles' robustness to nonlinearities and small samples, ability to provide feature-importance measures, and time-split analysis to reveal stage-dependent importance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Random forests are well-suited to heterogeneous, nonlinear corrosion datasets with limited samples, offering better generalisation and interpretable feature importance than kernel or linear methods in this domain.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2331.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DCCF-WKNNs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Densely Connected Cascade Forest - Weighted K-Nearest Neighbours hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep cascade forest ensemble combined with a weighted KNN module to enhance feature extraction and generalisation on small, steep-manifold atmospheric corrosion data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An improved deep forest model for forecast the outdoor atmospheric corrosion rate of low-alloy steels.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Atmospheric corrosion forecasting for low-alloy steels</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve generalisation and predictive accuracy over small, manifold-structured atmospheric corrosion datasets collected across different exposure durations and materials.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited: same dataset as Zhi et al. (multi-station LAS dataset) with modest sample sizes and significant manifold structure; labelled regression targets (CR).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular features with environmental and material descriptors; temporal sub-datasets by exposure times.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High non-linearity, steep-manifold geometry in feature space, small-sample regime per manifold.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application of deep/ensemble hybrid architectures in corrosion modelling; domain knowledge exists but data-driven representations are still maturing.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — method designed primarily for prediction but also used for knowledge mining (feature importance, thresholds); interpretability not primary.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Densely Connected Cascade Forest with Weighted K-Nearest Neighbours (DCCF-WKNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A representation-learning cascade forest (deep ensemble of tree forests) architecture densely connected across layers, with a weighted KNN post-module (WKNNs) to assist generalisation; trained in supervised regression mode on corrosion features to leverage ensemble robustness and deep feature extraction without heavy parameterization like deep neural nets.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / ensemble / representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate for small, structured, nonlinear corrosion datasets where deep feature extraction and ensemble robustness are needed; designed to inherit RF generalisation with improved representation learning.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported testing MAPE = 12.95% (DCCF-WKNNs) — best among tested models on same LAS dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Demonstrated superior generalisation and feature extraction capacity relative to RF and ANN on the same dataset; better at capturing manifold structure; offers improved extrapolation within data ranges.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Improves forecasting accuracy for atmospheric corrosion with limited data and could inform threshold-based domain insights (e.g., critical pH, rainfall levels) with better confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed RF, ANN, SVR and other tested methods on the LAS dataset; inherited RF's generalisation and exceeded it via deeper representation learning.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Cascade forest architecture that augments feature extraction without heavy data needs of deep nets, combined with WKNN smoothing for improved local generalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Deep ensemble structures (cascade forests) can outperform single-tree ensembles and ANNs on small, manifold-structured corrosion datasets by improving representation learning while retaining robustness to limited data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2331.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SVR_PSO_marine_Wen2009</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Support Vector Regression with Particle Swarm Optimization for marine corrosion (Wen et al. 2009)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SVR whose hyperparameters were tuned by particle swarm optimization to predict corrosion rates of 3C steel in varying seawater environments; tested with varying training sample sizes including LOOCV.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Corrosion rate prediction of 3C steel under different seawater environment by using support vector regression.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Marine corrosion rate prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict corrosion rate (CR) of 3C steel across different seawater environments using environmental descriptors; address small sample regimes and hyperparameter sensitivity of SVR.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Small dataset (tens of samples); labelled, structured data; potentially limited feature ranges and missing documentation on electrochemical acquisition methods.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular environmental and material features; not strongly temporal (static snapshots of different seawater conditions).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate non-linearity; small sample size makes kernel methods sensitive to hyperparameter choice and risk overfitting/poor extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied corrosion study; earlier ML work with known challenges (limited generalisation of ANNs; sensitivity of SVR to kernel/hyperparameters).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — predictive accuracy prioritized but generalisation and explanation of important factors also desired.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Support Vector Regression (SVR) with Particle Swarm Optimization (PSO) hyperparameter tuning</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>SVR regression with PSO used to search hyperparameter space (kernel parameters, regularization) to optimise predictive performance, tested with different training sizes including leave-one-out CV (LOOCV).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / kernel methods + metaheuristic optimization</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable but sensitive: SVR can model nonlinearity but requires careful hyperparameter tuning; PSO aids optimisation but SVR showed limited extrapolation ability in this domain.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported testing MAPE values: 3.840%, 3.180% and 1.360% for different high-training-sample regimes; lowest reported testing R² (LOOCV) = 0.836 in one configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>When training set size increased, SVR performance improved markedly; SVR-PSO performed well for interpolation but displayed limited extrapolation and sensitivity to sample size and kernel choice.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Demonstrated that kernel methods can be effective for marine corrosion with careful tuning and sufficient samples; highlighted need for larger datasets for robust deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>SVR-PSO achieved competitive MAPE but sometimes lower R² compared to ANN and ensemble methods; exhibited higher sensitivity and scatter compared to tree/ensemble models.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>PSO-based hyperparameter search improved SVR performance; increasing training sample size reduced error; but overall success limited by small and possibly biased datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Kernel methods like SVR can yield low interpolation errors in marine corrosion if hyperparameters are optimised and sample size is sufficient, but they remain sensitive and less robust than ensemble methods on small, heterogeneous datasets.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2331.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SFA-LSSVR_Chou2017</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Smart Firefly Algorithm optimized Least-Squares Support Vector Regression (SFA-LSSVR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Hybrid SFA-LSSVR metaheuristic + kernel regression model used as a high-performance predictor for steel corrosion rates and pitting risk, outperforming multiple individual and ensemble baselines in the reported study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The use of artificial intelligence combiners for modeling steel pitting risk and corrosion rate.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Marine corrosion and rebar pitting risk prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Accurately predict corrosion rates of carbon steel in seawater and pitting risk metrics from structured environmental and material inputs; address complex nonlinear relationships and improve extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Small-to-moderate datasets drawn from prior studies; labelled regression targets; separate datasets used for marine CR and rebar pitting risk.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data (environmental variables, chloride levels, DO, temperature, pH, binding), sometimes static snapshots; some temporal aspects for corrosion rate tests.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High nonlinearity and noisy measurements; pitting risk especially complex due to many interacting factors and scattered property definitions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied corrosion modelling with varied prior methods; advanced hybrid metaheuristic approaches are emerging to tackle optimisation challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium; model interpretability is valuable but primary goal is high predictive accuracy for risk assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Smart Firefly Algorithm optimized Least-Squares Support Vector Regression (SFA-LSSVR)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>LSSVR (a kernelized linear system variant of SVM) whose hyperparameters are tuned by a Smart Firefly Algorithm (a nature-inspired metaheuristic) to find optimal kernel and regularization settings; used to construct hybrid/tiered ensemble predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / hybrid (kernel method + metaheuristic optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective in reported cases; particularly suited to problems where standard hyperparameter tuning is challenging and metaheuristics can find better optima.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported MAPE (testing) for marine CR: 1.26% (SFA-LSSVR) — best among tested models; for rebar pitting risk: MAPE (testing) = 5.60%.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>High accuracy and outperformed other tested single and ensemble learners on the provided datasets; however, generalisation to broader settings needs further validation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential for accurate corrosion rate and pitting risk prediction in operational settings if validated on wider datasets; reduces error substantially compared to baseline models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed SVR, CART+LR, LR, ensemble tiering models and other combinations tested in the same study.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Combining robust regression (LSSVR) with efficient metaheuristic hyperparameter optimisation (SFA) yielded better model calibration than naive tuning; tiered ensemble strategies further improved performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Metaheuristic-optimized kernel regressors can achieve very low errors in corrosion prediction when data supports it, but validation across broader datasets is required to ensure generalisability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2331.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pipeline_DNN_GBM_RF_Ossai2019</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Neural Network, Gradient Boosting Machine, Random Forest and PSO-FFANN for pipeline defect depth prediction (Ossai et al. 2019)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Comparative data-driven study applying multivariate polynomial data generation, PCA preprocessing and several ML models (PSO-FFANN, GBM, RF, DNN) to predict defect depth growth in aged pipelines over a 10-year horizon.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A data-driven machine learning approach for corrosion risk assessment -a comparative study.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Pipeline internal corrosion defect depth growth prediction / corrosion risk assessment</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Estimate defect depth evolution in pipelines using multiphase flow operational parameters, geometrical pipeline characteristics, and deterministic model outputs (used to augment data), addressing uncertainties from multiple interacting mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Originally limited real data from 60 wells; augmented via multivariate polynomial regression to expand training set (data generation); labelling available (defect depth trajectories); data heterogeneous across wells.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data combining generated and measured features: operational variables, PCA-transformed inputs, deterministic model outputs; time series trajectories over 10 years.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High complexity: multivariate interactions, time-dependent growth, uncertain mechanisms (electrochemical, multiphase flow), high dimensionality reduced via PCA.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Industrially mature problem with deterministic risk models, but data-driven ML approaches are relatively recent; integration between deterministic models and ML is emerging.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — domain experts need interpretable risk assessments; ML used to complement deterministic models rather than entirely replace them.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>PSO-FFANN, Gradient Boosting Machine (GBM), Random Forest (RF), Deep Neural Network (DNN); multivariate polynomial data generation + PCA preprocessing</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Comparative application: multivariate polynomial used to generate synthetic training examples; PCA applied for dimensionality reduction; models trained for regression of defect depth: PSO-optimized feed-forward ANN, GBM, RF, and DNN; training and testing MAPE reported for PCA transformed and non-transformed inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / ensemble and deep learning; hybrid data-augmentation + preprocessing</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective when synthetic data augmentation and PCA are used; DNN and tree-based methods benefited from PCA transformation, reducing MAPE significantly.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported training MAPE (non-transformed): PSO-FFANN 34.1329%, GBM 31.9266%, RF 32.4267%, DNN 23.647%; (PCA-transformed inputs): PSO-FFANN 7.8588%, GBM 6.0082%, RF 7.7421%, DNN 6.6813%; multivariate polynomial regression baseline R² (training) = 0.9819.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>PCA transformation and synthetic data generation substantially improved model performance; GBM and DNN achieved low MAPE when preprocessing applied; demonstrates benefit of feature engineering and data augmentation for pipeline prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High practical impact: improved identification of pipeline sections at higher corrosion risk, enabling targeted inspections and maintenance planning; combination with deterministic models increases trustworthiness.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared across multiple ML algorithms and with multivariate polynomial data-generation baseline; PCA-transformed GBM and DNN provided best transformed-input results; ensemble/ML outperformed single deterministic-only predictions on risk localization.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Data augmentation via multivariate polynomial regression, PCA-based dimensionality reduction, ensemble/deep models able to capture time-dependent patterns; inclusion of diverse input types (operational, geometric) improved performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining deterministic model outputs, synthetic data generation, PCA, and modern ML (GBM/DNN) can transform scarce operational datasets into highly predictive risk models for pipeline corrosion.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2331.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RF_rebar_Salami2020</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Forest ensemble for rebar corrosion initiation time estimation (Salami et al. 2020)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Random Forest models used to predict corrosion initiation time of embedded steel in concrete using electrochemical potentials and material mixture descriptors, with careful train-test splitting and cross-validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Ensemble machine learning model for corrosion initiation time estimation of embedded steel reinforced self-compacting concrete.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Reinforced concrete rebar corrosion initiation prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Estimate time to corrosion initiation for embedded steel under chloride exposure using material composition, concrete mixture proportions, electrochemical indicators and environmental variables.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate dataset collected under laboratory conditions; labelled data for corrosion initiation times; some split/validation details provided; field validation recommended but not performed.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data: concrete mixture design variables (cement, aggregates, water/cement ratio), electrochemical measurements (corrosion potential), and environmental descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Highly nonlinear system with many interacting factors (material, environment, exposure duration); number of relevant variables moderate-to-high, potential multicollinearity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established corrosion research area with mechanistic understanding of chloride-driven depassivation but variability in threshold values and influence of many factors; ML application is maturing.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — domain experts need interpretable predictions for service-life planning and to trust model outputs; RF provides some interpretability (feature importance).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Random Forest (ensemble)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised RF regression trained on raw dataset (no heavy transformations found to affect performance); tested with varying train/test splits; used ensemble predictions and cross-validation to estimate initiation times.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / ensemble tree-based</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable — RF combined flexibility and generalisation to model corrosion initiation time from multivariate concrete and electrochemical data.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported testing R² = 0.897 (initial), with best performance R² (testing) = 0.974 using an 85/15 train/test split.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>RF delivered high accuracy and robustness; performance improved with larger training proportions; results indicate RF is suitable for lab datasets but field validation needed.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential for predictive maintenance and service-life estimation of concrete structures if validated in-situ; could reduce monitoring costs by predicting high-risk locations/time frames.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared across different ML methods and dataset transformations; RF outperformed or matched others and showed low sensitivity to feature-engineering in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Inclusion of electrochemical potential as predictive target, adequate training data proportion, and RF's ability to handle multicollinearity and mixed data types.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Random forests can accurately predict corrosion initiation times in controlled rebar datasets and scale well with increased training data, making them useful for service-life estimation pending field validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2331.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KSOM_ANN_rebar_Zhu2021</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kohonen Self-Organizing Map combined with Artificial Neural Network for chloride threshold prediction (Zhu et al. 2021)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>KSOM used to impute missing literature data and cluster features, followed by ANN regression to predict chloride threshold values (CT) in reinforced concrete from sparse literature-derived datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Corrosion of rebar in concrete. Part III: Artificial Neural Network analysis of chloride threshold data.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Chloride threshold (CT) prediction for rebar pitting in concrete</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict the chloride threshold parameter for pitting initiation in reinforced concrete using sparse literature data comprising primary (pH, corrosion potential, breakdown potential) and secondary (cement composition, porosity, w/c ratio) variables.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate-sized compiled literature database (~1242 vectors) but with missing entries; labelled target definitions vary (three CT definitions), data is noisy, heterogeneous and partially missing.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular dataset with missing values; mixture of electrochemical measures, concrete composition descriptors and physical properties; some variables interdependent.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High complexity: CT is ambiguous and scattered depending on definition; multicollinearity and missingness complicate modelling; high dimensionality (many descriptors) reduced by clustering.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Research area with incomplete mechanistic consensus on CT; empirical and statistical analyses prevalent; ML applied to extract patterns from scattered literature data.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — outputs used to inform safety/service-life decisions; interpretability and careful handling of correlated variables are essential.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Kohonen Self-Organizing Map (KSOM) + Artificial Neural Network (KSOM-ANN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>KSOM used for clustering and imputing most-probable values for missing data; the augmented dataset then used to train ANN regression models to predict CT (multiple CT definitions); validation by comparing predicted vs experimental CR and %TotalCl/cem.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Unsupervised (KSOM) + supervised (ANN) hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable for literature-derived sparse datasets with missingness; KSOM aids in imputing missing values and organizing data prior to ANN training.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported high training performance: R² = 0.99 on modelling dataset (training), dataset size 1242 vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Model yielded high apparent fit on training but findings must be interpreted cautiously due to definition-dependency of CT, potential biases from imputation, and limited mechanistic guarantee; useful for exploring correlations but not definitive mechanistic conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Can synthesize scattered literature data to provide hypotheses on CT dependencies and guide experiments, potentially accelerating understanding of factors affecting pitting threshold.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Approach addresses missing-data limitations of standard supervised modelling; direct comparisons to other imputation + modelling schemes not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large compiled literature dataset, KSOM's ability to fill missing entries and cluster similar records, and ANN's flexibility to fit complex nonlinear mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining unsupervised imputation (KSOM) with ANN regression enables modelling of a highly scattered, partially missing literature dataset for CT, but results depend strongly on imputation quality and CT definition.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2331.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BRANNGP_inhibitors_Winkler2016</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Regularized Artificial Neural Network with Gaussian Prior (BRANNGP) for corrosion inhibitor screening</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian-regularised feed-forward neural network using Gaussian priors trained on high-throughput experimental inhibitor data to predict inhibition scores from molecular descriptors, demonstrating improved predictive accuracy over linear models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Using high throughput experimental data and in silico models to discover alternatives to toxic chromate corrosion inhibitors.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Corrosion inhibitor performance prediction (aluminium alloys)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict inhibition score (0-10) of organic molecules on aluminium alloys (AA2024, AA7075) across pH conditions using molecular descriptors from high-throughput experiments and in silico calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Relatively abundant within study: 100-molecule library with ~2000 molecular descriptors; labelled inhibition scores from high-throughput experiments; publicly shared dataset and follow-up classification work.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional molecular descriptor vectors (~2000 descriptors reduced via feature selection), structured tabular data; not time-series.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional input space, complex structure-property relationships, potential nonlinearity between molecular descriptors and inhibition performance.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Developing field where prior structure-inhibition hypotheses existed but dataset sizes were limited; the study is among the more comprehensive ML-driven inhibitor studies.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — mechanistic interpretability desired to discover chemical design rules and replace toxic chromates; black-box predictions insufficient alone.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Bayesian Regularized Artificial Neural Networks with Gaussian Prior (BRANNGP)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Feed-forward ANN trained with Bayesian regularization (Gaussian prior) to prevent overfitting in high-dimensional descriptor space; models linked molecular descriptors (non-quantum-chemical and DFT-derived) to inhibition scores; compared with multiple linear regression (MLREM).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / Bayesian regularized neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited due to large descriptor sets and moderate sample size; Bayesian regularization helps control overfitting and provides more robust generalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Training R² (80/20 split) improved from MLREM to BRANNGP: AA7075 (pH 4) 0.79→0.82, AA7075 (pH 10) 0.56→0.60, AA2024 (pH 4) 0.75→0.82; AA2024 (pH 10) exception where MLREM 0.76 > BRANNGP 0.74.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>BRANNGP generally outperformed linear regression, suggesting nonlinear relationships between descriptors and inhibition; DFT quantum-chemical properties showed negligible correlation in this dataset while other descriptors were predictive.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: enables screening for benign inhibitor alternatives, reduces experimental burden by prioritising candidates, and informs descriptor-based design rules when combined with feature analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to MLREM (multiple linear regression) and quantum-chemical based descriptors; BRANNGP outperformed MLREM in most cases and showed that non-quantum descriptors were more predictive than DFT features in this dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, diverse high-throughput dataset, large descriptor pool with effective feature selection, and Bayesian regularisation preventing overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Bayesian-regularized neural networks can effectively predict inhibitor performance from high-dimensional molecular descriptors and outperform linear models when non-DFT descriptors capture relevant structure-property signals.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2331.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NGBM_GA_RGANGBM_atmospheric_Zhi2017</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Nonlinear Grey Bernoulli Model combined with Genetic Algorithm and Regularization (RGANGBM(1,1)) for long-term atmospheric CR time-series</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Grey forecasting model (NGBM(1,1)) optimised by genetic algorithms and regularisation to predict long-term corrosion rate time series using small monotonic series with enhanced generalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Long-term prediction on atmospheric corrosion data series of carbon steel in China based on NGBM(1,1) model and genetic algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Long-term atmospheric corrosion time-series forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict long-term (1,2,4,8,16 year) corrosion rate trajectories from small historical monotonic CR series where conventional ML methods risk overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Small monotonic time-series datasets from specific stations (single-station training, multiple-station testing), labelled with CR vs time; scarce long-term data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Univariate time-series (CR vs time) with monotonic trends; small sample counts per series.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high due to small-sample time-series forecasting and trend extrapolation; risk of overfitting and low generalisability.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Time-series forecasting methods are mature, but grey models are niche for small-sample systems; hybridisation with GA/regularization is an applied innovation here.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — goal is accurate forecasting rather than mechanistic inference; regularisation parameter was interpreted as related to corrosivity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>NGBM(1,1) + Genetic Algorithm (GA) with Regularization (RGANGBM(1,1))</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Nonlinear grey Bernoulli forecasting model for small-sample time series; GA optimises model parameters and a regularization parameter η introduced to avoid overfitting and improve generalisation; trained on one station and tested on five others.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised forecasting / hybrid (grey models + metaheuristic optimization + regularization)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable to small monotonic corrosion time series where conventional ML would overfit; designed for extrapolation across years.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported mean testing MAPE = 9.15% for 16th-year predictions across tested datasets using RGANGBM(1,1).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provided relatively high prediction accuracy for long-term forecasting compared to BPNN and SVR on the same small datasets (BPNN MAPE=28.02%, SVR MAPE=83.55% for 16th year), indicating better handling of small monotonic series.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Useful for long-term corrosion forecasting at specific sites where long historical series are limited; improves planning for infrastructure maintenance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed BPNN and SVR on the small monotonic series; regularization critical to avoid overfitting that hampered GA+NGBM without regularization.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Grey model suitability for small-sample monotonic trends, GA for parameter search, and regularisation to control overfitting and improve cross-site generalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Grey forecasting combined with optimisation and regularization can outperform general ML models on very small monotonic corrosion time-series by avoiding overfitting and leveraging trend structure.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2331.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HighTemp_GB_RF_kNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gradient Boosting, Random Forest and k-Nearest Neighbours for predicting parabolic rate constants of high-temperature oxidation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised regression models (gradient boosting, RF, k-NN and others) trained on literature-compiled k_p values for high-temperature oxidation to relate alloy composition and process variables to oxidation kinetics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting the parabolic rate constants of high-temperature oxidation of Ti alloys using learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>High-temperature oxidation kinetics prediction (materials science)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict parabolic rate constant k_p for oxidation of Ti and other alloys from descriptors including composition, temperature, time, atmosphere and phase information assembled from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate: 115 to 237 compiled k_p data points across multiple alloys and environments; labelled supervised data built from literature and calculated from corrosion product data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data: compositional descriptors, phases, process conditions (T, time, atmosphere), environmental descriptors; moderate dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate complexity: composition-process interactions controlling oxidation kinetics; limited data size relative to descriptor space.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established mechanistic theories (parabolic oxidation laws) exist; ML used to accelerate screening and design by mapping composition-process to k_p.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — understanding dominant elemental influences is valuable; ML used to identify important controlling elements (Ni, Cr, Al, Fe).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Gradient Boosting (GB), Random Forest (RF), k-Nearest Neighbours (k-NN), neural networks and other supervised regressors</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised regression pipelines trained on curated k_p datasets with alloy composition and process descriptors; gradient boosting achieved highest accuracy for the Ti-alloy dataset (R² = 0.92 on 115 points); broader dataset modelling across 237 entries used several algorithms (logistic/linear/RF/NN) with supervised learning.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / ensemble & instance-based methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective for correlating composition and processing to oxidation kinetics with limited-but-curated literature datasets; useful for materials design screening.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Gradient boosting reported R² = 0.92 on 115-point Ti alloy dataset; broader modelling on 237 k_p dataset produced lowest errors with supervised ML (specific metrics not enumerated in review).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>ML provided accurate predictions and identified dominant elemental controls on oxidation kinetics (Ni, Cr, Al, Fe), enabling extension toward alloy design for oxidation resistance.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for materials design: accelerates identification of composition-process combinations for improved high-temperature oxidation resistance, reducing experimental iteration time.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Supervised ML achieved lower errors than simpler regression approaches; gradient boosting outperformed RF and k-NN on the Ti dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Curated literature database, appropriate feature selection (composition and process descriptors), and use of ensemble methods that handle complex nonlinear relationships with limited data.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Ensemble supervised regressors like gradient boosting can accurately predict oxidation kinetics from moderate-sized curated datasets and reveal key elemental drivers useful for alloy design.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2331.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2331.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>General_ensembles_deep_learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ensemble and deep learning methods for corrosion prediction (general observation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Across reviewed studies, ensemble methods (RF, GBDT, XGBoost, cascade forests) and deep neural networks generally produced the best predictive performances on nonlinear, high-dimensional corrosion datasets when data size permitted.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reviewing machine learning of corrosion prediction in a data-oriented perspective</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Multiple corrosion-related prediction tasks (atmospheric, marine, pipeline, rebar, inhibitors, crevice, SCC)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Various regression tasks predicting corrosion rate, depth, defect growth, pitting risk, inhibitor performance and oxidation constants from heterogeneous input features.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varied across problems: many tasks suffer from small or moderate datasets, noisy heterogeneous sources, missingness and low-value-density; inhibitors and some atmospheric datasets are richer.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Predominantly structured tabular datasets (environmental, material, electrochemical descriptors), often time-series for corrosion rate targets; high-dimensional molecular descriptors for inhibitors; missing and heterogeneous entries common.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Overall high: nonlinearity, temporal dependencies, multi-scale mechanisms, multi-factor interactions, manifold structures, and often limited sample sizes per manifold.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Domain has mature empirical/mechanistic models but ML application is emerging; need for data sharing and standardised datasets to mature ML deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high — many studies require interpretable results for scientific insight and operational decision-making; black-box models are useful but explainability and domain knowledge integration are emphasised.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Ensemble methods (Random Forest, GBDT, XGBoost, cForest), deep learning (DNN, cascade forests), hybrid/metaheuristic-enhanced models (RF-WKNNs, DCCF-WKNNs, SFA-LSSVR, PSO-FFANN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A range of supervised learning approaches applied: tree ensembles for robustness and feature importance; deep networks/cascade forests for representation learning when sufficient data; hybrids combining ensembles with KNN or metaheuristics to improve generalisation and hyperparameter optimisation; preprocessing (PCA), data augmentation (multivariate polynomial), and imputation methods (KSOM) used as supporting workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (ensemble, deep learning) and hybrid approaches</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Generally applicable: ensemble and hybrid methods are appropriate for heterogeneous corrosion data and small-to-moderate sample sizes; deep learning effective when sufficient data/time-series available.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Across reviewed works, ensemble/deep/hybrid methods often yielded the best metrics (examples: RF testing MAPE 16.08% for LAS; DCCF-WKNNs MAPE 12.95%; SFA-LSSVR MAPE 1.26% in marine CR; GBM R²=0.92 for oxidation k_p), but performance depends strongly on dataset size and preprocessing.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Ensembles and hybrids balanced bias-variance effectively and offered superior generalisation vs linear and kernel methods on many corrosion tasks; deep learning provided strong fits when data abundant but risks overfitting on small datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: ensemble and hybrid ML methods can significantly improve predictive accuracy for corrosion tasks, inform mechanistic hypotheses via feature importance, and accelerate materials/inhibitor discovery and asset management.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Linear and simple kernel methods often underperformed; SVR showed high scatter and sensitivity; ANNs performed well with sufficient data; ensembles/hybrids typically outperformed other classes across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Larger dataset sizes, inclusion of time as a feature, careful feature selection/engineering, ensemble/hybrid architectures, hyperparameter optimisation, and integration with domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Ensemble and hybrid ML approaches most effectively handle corrosion's nonlinearity, heterogeneity and small-sample challenges, while deep models excel given sufficient data and temporal features; success depends primarily on data quantity/quality and domain-informed feature selection.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Phenomenological modelling of atmospheric corrosion using an artificial neural network. <em>(Rating: 2)</em></li>
                <li>Prediction and knowledge mining of outdoor atmospheric corrosion rates of low alloy steels based on the random forests approach. <em>(Rating: 2)</em></li>
                <li>An improved deep forest model for forecast the outdoor atmospheric corrosion rate of low-alloy steels. <em>(Rating: 2)</em></li>
                <li>Corrosion rate prediction of 3C steel under different seawater environment by using support vector regression. <em>(Rating: 2)</em></li>
                <li>The use of artificial intelligence combiners for modeling steel pitting risk and corrosion rate. <em>(Rating: 2)</em></li>
                <li>A data-driven machine learning approach for corrosion risk assessment -a comparative study. <em>(Rating: 2)</em></li>
                <li>Ensemble machine learning model for corrosion initiation time estimation of embedded steel reinforced self-compacting concrete. <em>(Rating: 2)</em></li>
                <li>Corrosion of rebar in concrete. Part III: Artificial Neural Network analysis of chloride threshold data. <em>(Rating: 2)</em></li>
                <li>Using high throughput experimental data and in silico models to discover alternatives to toxic chromate corrosion inhibitors. <em>(Rating: 2)</em></li>
                <li>Long-term prediction on atmospheric corrosion data series of carbon steel in China based on NGBM(1,1) model and genetic algorithm. <em>(Rating: 2)</em></li>
                <li>Predicting the parabolic rate constants of high-temperature oxidation of Ti alloys using learning. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2331",
    "paper_id": "paper-246281204",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "ANN_atmospheric_Cai1999",
            "name_full": "Artificial Neural Network for atmospheric corrosion (Cai et al. 1999)",
            "brief_description": "Feed-forward/backpropagation neural network used to model atmospheric corrosion rates and depths from multi-source environmental data; used sensitivity analysis to extract variable importance.",
            "citation_title": "Phenomenological modelling of atmospheric corrosion using an artificial neural network.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Atmospheric corrosion prediction",
            "problem_description": "Predict corrosion rates and corrosion depths of steel and zinc exposed to outdoor atmospheric conditions using environmental and pollutant descriptors aggregated from worldwide datasets.",
            "data_availability": "Limited to moderate: multi-source compiled dataset (from multiple publications, 42 sources) with noise and bias; labelled supervised data (corrosion rates/depths); small-to-moderate sample size for long-term predictions and noisy heterogenous measurements.",
            "data_structure": "Structured tabular data aggregated from literature: environmental variables (T, RH, SO2, Cl-, rainfall, TOW), material descriptors; time-related features limited; high dimensionality and noisy.",
            "problem_complexity": "High non-linearity and heterogeneity; high variance in measurements due to multiple data sources; multi-variable interactions (e.g., TOW, SO2, RH) and temporal dependence not fully represented.",
            "domain_maturity": "Established field with empirical models (log-linear, power laws, Arrhenius) but ML application was pioneering; moderate domain knowledge available but incomplete mechanistic capture.",
            "mechanistic_understanding_requirements": "Medium — interpretation and knowledge mining desired to relate predictors (SO2, TOW, pH) to corrosion mechanisms, not just black-box prediction.",
            "ai_methodology_name": "Artificial Neural Network (backpropagation)",
            "ai_methodology_description": "Supervised feed-forward ANN trained by backpropagation using compiled environmental and material features; sensitivity analysis performed to rank input importance (e.g., effect of TOW, SO2). No deep architectures; standard ANN regression.",
            "ai_methodology_category": "Supervised learning",
            "applicability": "Applicable and appropriate for nonlinear interpolation across heterogeneous atmospheric datasets; limited extrapolation to very long-term predictions due to data scarcity.",
            "effectiveness_quantitative": "Reported testing performance: steel R² = 0.548 (MAPE = 39%); zinc R² = 0.608 (MAPE = 53%).",
            "effectiveness_qualitative": "Worked reasonably for interpolation and revealed plausible variable importance (e.g., moisture and pollutant effects) but high variance and limited long-term extrapolation due to incomplete features and noisy, multi-source data.",
            "impact_potential": "Provided early demonstration that ANN can model nonlinear atmospheric corrosion and extract domain-relevant patterns; potential to improve predictions with more and cleaner data and additional features.",
            "comparison_to_alternatives": "Outperformed prior linear regression approaches in capturing nonlinear behaviour; however, limited long-term predictive ability compared to what might be achievable with larger, more representative datasets.",
            "success_factors": "Ability of ANN to fit nonlinear relationships and perform sensitivity analysis; availability of multi-source labelled data allowed training despite noise; shortcomings due to small/heterogeneous dataset for long-term extrapolation.",
            "key_insight": "ANNs can capture nonlinear environmental-material interactions in atmospheric corrosion and provide variable-importance insights, but predictive utility is limited by noisy, heterogeneous, and insufficient long-term data.",
            "uuid": "e2331.0"
        },
        {
            "name_short": "RF_atmospheric_Zhi2019",
            "name_full": "Random Forest for outdoor atmospheric corrosion of low-alloy steels (Zhi et al. 2019)",
            "brief_description": "Random Forest regression applied to multi-material, multi-station atmospheric corrosion datasets to predict corrosion rates and perform knowledge mining (feature importance, time-split analyses).",
            "citation_title": "Prediction and knowledge mining of outdoor atmospheric corrosion rates of low alloy steels based on the random forests approach.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Atmospheric corrosion of low-alloy steels",
            "problem_description": "Forecast outdoor corrosion rates (CR) across different materials and environmental monitoring stations over up to 16 years' exposures; tackle steep-manifold structure, nonlinearity and small sample sizes.",
            "data_availability": "Limited/moderate: dataset comprised corrosion data of 17 low-alloy steels across 6 stations over 16 years (relatively small sample counts per combination); labelled supervised data; structured but small and heterogeneous.",
            "data_structure": "Structured tabular data with environmental descriptors (pH, SO2, Cl-, T, RH, rainfall), material composition; time series split into sub-datasets by exposure time (1, 2, 4, 8, 16 years).",
            "problem_complexity": "High: nonlinear, steep-manifold structure, relatively small sample counts per manifold, temporal dependence, multi-factor interactions.",
            "domain_maturity": "Applied corrosion field with domain knowledge but limited comprehensive datasets for ML; growing adoption of ML methods.",
            "mechanistic_understanding_requirements": "Medium — feature importance and interpretability valued to identify dominant environmental vs material influences and provide operational thresholds.",
            "ai_methodology_name": "Random Forest (RF)",
            "ai_methodology_description": "Ensemble of decision trees used for regression; trained on tabular corrosion features; used for prediction and feature-importance analysis over whole and time-split datasets; relatively robust to small sample sizes and nonlinearity.",
            "ai_methodology_category": "Supervised learning / ensemble tree-based",
            "applicability": "Highly applicable for this structured, nonlinear problem and small-to-moderate dataset sizes; less sensitive to small sample sizes than kernel methods in this context.",
            "effectiveness_quantitative": "Reported testing MAPE = 16.08% (RF) on LAS dataset; ANN testing MAPE = 22.12%; LR and SVR testing MAPE = 45.63% and 41.35% respectively.",
            "effectiveness_qualitative": "RF demonstrated best generalisation among tested methods on small LAS datasets and supplied interpretable feature importance results (e.g., pH, Cl− importance). Limitations: still affected by data sparsity in certain regimes and limited extrapolation.",
            "impact_potential": "Enabled identification of dominant drivers (environment &gt; material initially), quantitative thresholds for environmental variables, and improved predictive accuracy vs linear/kernel methods; useful for monitoring and design decisions.",
            "comparison_to_alternatives": "Direct comparisons showed RF outperformed LR and SVR markedly and outperformed ANN in generalisation for the dataset sizes considered; ANN and tree-based were more stable than kernel methods.",
            "success_factors": "Tree ensembles' robustness to nonlinearities and small samples, ability to provide feature-importance measures, and time-split analysis to reveal stage-dependent importance.",
            "key_insight": "Random forests are well-suited to heterogeneous, nonlinear corrosion datasets with limited samples, offering better generalisation and interpretable feature importance than kernel or linear methods in this domain.",
            "uuid": "e2331.1"
        },
        {
            "name_short": "DCCF-WKNNs",
            "name_full": "Densely Connected Cascade Forest - Weighted K-Nearest Neighbours hybrid",
            "brief_description": "A deep cascade forest ensemble combined with a weighted KNN module to enhance feature extraction and generalisation on small, steep-manifold atmospheric corrosion data.",
            "citation_title": "An improved deep forest model for forecast the outdoor atmospheric corrosion rate of low-alloy steels.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Atmospheric corrosion forecasting for low-alloy steels",
            "problem_description": "Improve generalisation and predictive accuracy over small, manifold-structured atmospheric corrosion datasets collected across different exposure durations and materials.",
            "data_availability": "Limited: same dataset as Zhi et al. (multi-station LAS dataset) with modest sample sizes and significant manifold structure; labelled regression targets (CR).",
            "data_structure": "Structured tabular features with environmental and material descriptors; temporal sub-datasets by exposure times.",
            "problem_complexity": "High non-linearity, steep-manifold geometry in feature space, small-sample regime per manifold.",
            "domain_maturity": "Emerging application of deep/ensemble hybrid architectures in corrosion modelling; domain knowledge exists but data-driven representations are still maturing.",
            "mechanistic_understanding_requirements": "Medium — method designed primarily for prediction but also used for knowledge mining (feature importance, thresholds); interpretability not primary.",
            "ai_methodology_name": "Densely Connected Cascade Forest with Weighted K-Nearest Neighbours (DCCF-WKNNs)",
            "ai_methodology_description": "A representation-learning cascade forest (deep ensemble of tree forests) architecture densely connected across layers, with a weighted KNN post-module (WKNNs) to assist generalisation; trained in supervised regression mode on corrosion features to leverage ensemble robustness and deep feature extraction without heavy parameterization like deep neural nets.",
            "ai_methodology_category": "Supervised learning / ensemble / representation learning",
            "applicability": "Appropriate for small, structured, nonlinear corrosion datasets where deep feature extraction and ensemble robustness are needed; designed to inherit RF generalisation with improved representation learning.",
            "effectiveness_quantitative": "Reported testing MAPE = 12.95% (DCCF-WKNNs) — best among tested models on same LAS dataset.",
            "effectiveness_qualitative": "Demonstrated superior generalisation and feature extraction capacity relative to RF and ANN on the same dataset; better at capturing manifold structure; offers improved extrapolation within data ranges.",
            "impact_potential": "Improves forecasting accuracy for atmospheric corrosion with limited data and could inform threshold-based domain insights (e.g., critical pH, rainfall levels) with better confidence.",
            "comparison_to_alternatives": "Outperformed RF, ANN, SVR and other tested methods on the LAS dataset; inherited RF's generalisation and exceeded it via deeper representation learning.",
            "success_factors": "Cascade forest architecture that augments feature extraction without heavy data needs of deep nets, combined with WKNN smoothing for improved local generalisation.",
            "key_insight": "Deep ensemble structures (cascade forests) can outperform single-tree ensembles and ANNs on small, manifold-structured corrosion datasets by improving representation learning while retaining robustness to limited data.",
            "uuid": "e2331.2"
        },
        {
            "name_short": "SVR_PSO_marine_Wen2009",
            "name_full": "Support Vector Regression with Particle Swarm Optimization for marine corrosion (Wen et al. 2009)",
            "brief_description": "SVR whose hyperparameters were tuned by particle swarm optimization to predict corrosion rates of 3C steel in varying seawater environments; tested with varying training sample sizes including LOOCV.",
            "citation_title": "Corrosion rate prediction of 3C steel under different seawater environment by using support vector regression.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Marine corrosion rate prediction",
            "problem_description": "Predict corrosion rate (CR) of 3C steel across different seawater environments using environmental descriptors; address small sample regimes and hyperparameter sensitivity of SVR.",
            "data_availability": "Small dataset (tens of samples); labelled, structured data; potentially limited feature ranges and missing documentation on electrochemical acquisition methods.",
            "data_structure": "Structured tabular environmental and material features; not strongly temporal (static snapshots of different seawater conditions).",
            "problem_complexity": "Moderate non-linearity; small sample size makes kernel methods sensitive to hyperparameter choice and risk overfitting/poor extrapolation.",
            "domain_maturity": "Applied corrosion study; earlier ML work with known challenges (limited generalisation of ANNs; sensitivity of SVR to kernel/hyperparameters).",
            "mechanistic_understanding_requirements": "Medium — predictive accuracy prioritized but generalisation and explanation of important factors also desired.",
            "ai_methodology_name": "Support Vector Regression (SVR) with Particle Swarm Optimization (PSO) hyperparameter tuning",
            "ai_methodology_description": "SVR regression with PSO used to search hyperparameter space (kernel parameters, regularization) to optimise predictive performance, tested with different training sizes including leave-one-out CV (LOOCV).",
            "ai_methodology_category": "Supervised learning / kernel methods + metaheuristic optimization",
            "applicability": "Applicable but sensitive: SVR can model nonlinearity but requires careful hyperparameter tuning; PSO aids optimisation but SVR showed limited extrapolation ability in this domain.",
            "effectiveness_quantitative": "Reported testing MAPE values: 3.840%, 3.180% and 1.360% for different high-training-sample regimes; lowest reported testing R² (LOOCV) = 0.836 in one configuration.",
            "effectiveness_qualitative": "When training set size increased, SVR performance improved markedly; SVR-PSO performed well for interpolation but displayed limited extrapolation and sensitivity to sample size and kernel choice.",
            "impact_potential": "Demonstrated that kernel methods can be effective for marine corrosion with careful tuning and sufficient samples; highlighted need for larger datasets for robust deployment.",
            "comparison_to_alternatives": "SVR-PSO achieved competitive MAPE but sometimes lower R² compared to ANN and ensemble methods; exhibited higher sensitivity and scatter compared to tree/ensemble models.",
            "success_factors": "PSO-based hyperparameter search improved SVR performance; increasing training sample size reduced error; but overall success limited by small and possibly biased datasets.",
            "key_insight": "Kernel methods like SVR can yield low interpolation errors in marine corrosion if hyperparameters are optimised and sample size is sufficient, but they remain sensitive and less robust than ensemble methods on small, heterogeneous datasets.",
            "uuid": "e2331.3"
        },
        {
            "name_short": "SFA-LSSVR_Chou2017",
            "name_full": "Smart Firefly Algorithm optimized Least-Squares Support Vector Regression (SFA-LSSVR)",
            "brief_description": "Hybrid SFA-LSSVR metaheuristic + kernel regression model used as a high-performance predictor for steel corrosion rates and pitting risk, outperforming multiple individual and ensemble baselines in the reported study.",
            "citation_title": "The use of artificial intelligence combiners for modeling steel pitting risk and corrosion rate.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Marine corrosion and rebar pitting risk prediction",
            "problem_description": "Accurately predict corrosion rates of carbon steel in seawater and pitting risk metrics from structured environmental and material inputs; address complex nonlinear relationships and improve extrapolation.",
            "data_availability": "Small-to-moderate datasets drawn from prior studies; labelled regression targets; separate datasets used for marine CR and rebar pitting risk.",
            "data_structure": "Structured tabular data (environmental variables, chloride levels, DO, temperature, pH, binding), sometimes static snapshots; some temporal aspects for corrosion rate tests.",
            "problem_complexity": "High nonlinearity and noisy measurements; pitting risk especially complex due to many interacting factors and scattered property definitions.",
            "domain_maturity": "Applied corrosion modelling with varied prior methods; advanced hybrid metaheuristic approaches are emerging to tackle optimisation challenges.",
            "mechanistic_understanding_requirements": "Medium; model interpretability is valuable but primary goal is high predictive accuracy for risk assessment.",
            "ai_methodology_name": "Smart Firefly Algorithm optimized Least-Squares Support Vector Regression (SFA-LSSVR)",
            "ai_methodology_description": "LSSVR (a kernelized linear system variant of SVM) whose hyperparameters are tuned by a Smart Firefly Algorithm (a nature-inspired metaheuristic) to find optimal kernel and regularization settings; used to construct hybrid/tiered ensemble predictors.",
            "ai_methodology_category": "Supervised learning / hybrid (kernel method + metaheuristic optimization)",
            "applicability": "Applicable and effective in reported cases; particularly suited to problems where standard hyperparameter tuning is challenging and metaheuristics can find better optima.",
            "effectiveness_quantitative": "Reported MAPE (testing) for marine CR: 1.26% (SFA-LSSVR) — best among tested models; for rebar pitting risk: MAPE (testing) = 5.60%.",
            "effectiveness_qualitative": "High accuracy and outperformed other tested single and ensemble learners on the provided datasets; however, generalisation to broader settings needs further validation.",
            "impact_potential": "High potential for accurate corrosion rate and pitting risk prediction in operational settings if validated on wider datasets; reduces error substantially compared to baseline models.",
            "comparison_to_alternatives": "Outperformed SVR, CART+LR, LR, ensemble tiering models and other combinations tested in the same study.",
            "success_factors": "Combining robust regression (LSSVR) with efficient metaheuristic hyperparameter optimisation (SFA) yielded better model calibration than naive tuning; tiered ensemble strategies further improved performance.",
            "key_insight": "Metaheuristic-optimized kernel regressors can achieve very low errors in corrosion prediction when data supports it, but validation across broader datasets is required to ensure generalisability.",
            "uuid": "e2331.4"
        },
        {
            "name_short": "Pipeline_DNN_GBM_RF_Ossai2019",
            "name_full": "Deep Neural Network, Gradient Boosting Machine, Random Forest and PSO-FFANN for pipeline defect depth prediction (Ossai et al. 2019)",
            "brief_description": "Comparative data-driven study applying multivariate polynomial data generation, PCA preprocessing and several ML models (PSO-FFANN, GBM, RF, DNN) to predict defect depth growth in aged pipelines over a 10-year horizon.",
            "citation_title": "A data-driven machine learning approach for corrosion risk assessment -a comparative study.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Pipeline internal corrosion defect depth growth prediction / corrosion risk assessment",
            "problem_description": "Estimate defect depth evolution in pipelines using multiphase flow operational parameters, geometrical pipeline characteristics, and deterministic model outputs (used to augment data), addressing uncertainties from multiple interacting mechanisms.",
            "data_availability": "Originally limited real data from 60 wells; augmented via multivariate polynomial regression to expand training set (data generation); labelling available (defect depth trajectories); data heterogeneous across wells.",
            "data_structure": "Structured tabular data combining generated and measured features: operational variables, PCA-transformed inputs, deterministic model outputs; time series trajectories over 10 years.",
            "problem_complexity": "High complexity: multivariate interactions, time-dependent growth, uncertain mechanisms (electrochemical, multiphase flow), high dimensionality reduced via PCA.",
            "domain_maturity": "Industrially mature problem with deterministic risk models, but data-driven ML approaches are relatively recent; integration between deterministic models and ML is emerging.",
            "mechanistic_understanding_requirements": "High — domain experts need interpretable risk assessments; ML used to complement deterministic models rather than entirely replace them.",
            "ai_methodology_name": "PSO-FFANN, Gradient Boosting Machine (GBM), Random Forest (RF), Deep Neural Network (DNN); multivariate polynomial data generation + PCA preprocessing",
            "ai_methodology_description": "Comparative application: multivariate polynomial used to generate synthetic training examples; PCA applied for dimensionality reduction; models trained for regression of defect depth: PSO-optimized feed-forward ANN, GBM, RF, and DNN; training and testing MAPE reported for PCA transformed and non-transformed inputs.",
            "ai_methodology_category": "Supervised learning / ensemble and deep learning; hybrid data-augmentation + preprocessing",
            "applicability": "Applicable and effective when synthetic data augmentation and PCA are used; DNN and tree-based methods benefited from PCA transformation, reducing MAPE significantly.",
            "effectiveness_quantitative": "Reported training MAPE (non-transformed): PSO-FFANN 34.1329%, GBM 31.9266%, RF 32.4267%, DNN 23.647%; (PCA-transformed inputs): PSO-FFANN 7.8588%, GBM 6.0082%, RF 7.7421%, DNN 6.6813%; multivariate polynomial regression baseline R² (training) = 0.9819.",
            "effectiveness_qualitative": "PCA transformation and synthetic data generation substantially improved model performance; GBM and DNN achieved low MAPE when preprocessing applied; demonstrates benefit of feature engineering and data augmentation for pipeline prediction.",
            "impact_potential": "High practical impact: improved identification of pipeline sections at higher corrosion risk, enabling targeted inspections and maintenance planning; combination with deterministic models increases trustworthiness.",
            "comparison_to_alternatives": "Compared across multiple ML algorithms and with multivariate polynomial data-generation baseline; PCA-transformed GBM and DNN provided best transformed-input results; ensemble/ML outperformed single deterministic-only predictions on risk localization.",
            "success_factors": "Data augmentation via multivariate polynomial regression, PCA-based dimensionality reduction, ensemble/deep models able to capture time-dependent patterns; inclusion of diverse input types (operational, geometric) improved performance.",
            "key_insight": "Combining deterministic model outputs, synthetic data generation, PCA, and modern ML (GBM/DNN) can transform scarce operational datasets into highly predictive risk models for pipeline corrosion.",
            "uuid": "e2331.5"
        },
        {
            "name_short": "RF_rebar_Salami2020",
            "name_full": "Random Forest ensemble for rebar corrosion initiation time estimation (Salami et al. 2020)",
            "brief_description": "Random Forest models used to predict corrosion initiation time of embedded steel in concrete using electrochemical potentials and material mixture descriptors, with careful train-test splitting and cross-validation.",
            "citation_title": "Ensemble machine learning model for corrosion initiation time estimation of embedded steel reinforced self-compacting concrete.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Reinforced concrete rebar corrosion initiation prediction",
            "problem_description": "Estimate time to corrosion initiation for embedded steel under chloride exposure using material composition, concrete mixture proportions, electrochemical indicators and environmental variables.",
            "data_availability": "Moderate dataset collected under laboratory conditions; labelled data for corrosion initiation times; some split/validation details provided; field validation recommended but not performed.",
            "data_structure": "Structured tabular data: concrete mixture design variables (cement, aggregates, water/cement ratio), electrochemical measurements (corrosion potential), and environmental descriptors.",
            "problem_complexity": "Highly nonlinear system with many interacting factors (material, environment, exposure duration); number of relevant variables moderate-to-high, potential multicollinearity.",
            "domain_maturity": "Established corrosion research area with mechanistic understanding of chloride-driven depassivation but variability in threshold values and influence of many factors; ML application is maturing.",
            "mechanistic_understanding_requirements": "High — domain experts need interpretable predictions for service-life planning and to trust model outputs; RF provides some interpretability (feature importance).",
            "ai_methodology_name": "Random Forest (ensemble)",
            "ai_methodology_description": "Supervised RF regression trained on raw dataset (no heavy transformations found to affect performance); tested with varying train/test splits; used ensemble predictions and cross-validation to estimate initiation times.",
            "ai_methodology_category": "Supervised learning / ensemble tree-based",
            "applicability": "Highly applicable — RF combined flexibility and generalisation to model corrosion initiation time from multivariate concrete and electrochemical data.",
            "effectiveness_quantitative": "Reported testing R² = 0.897 (initial), with best performance R² (testing) = 0.974 using an 85/15 train/test split.",
            "effectiveness_qualitative": "RF delivered high accuracy and robustness; performance improved with larger training proportions; results indicate RF is suitable for lab datasets but field validation needed.",
            "impact_potential": "High potential for predictive maintenance and service-life estimation of concrete structures if validated in-situ; could reduce monitoring costs by predicting high-risk locations/time frames.",
            "comparison_to_alternatives": "Compared across different ML methods and dataset transformations; RF outperformed or matched others and showed low sensitivity to feature-engineering in this context.",
            "success_factors": "Inclusion of electrochemical potential as predictive target, adequate training data proportion, and RF's ability to handle multicollinearity and mixed data types.",
            "key_insight": "Random forests can accurately predict corrosion initiation times in controlled rebar datasets and scale well with increased training data, making them useful for service-life estimation pending field validation.",
            "uuid": "e2331.6"
        },
        {
            "name_short": "KSOM_ANN_rebar_Zhu2021",
            "name_full": "Kohonen Self-Organizing Map combined with Artificial Neural Network for chloride threshold prediction (Zhu et al. 2021)",
            "brief_description": "KSOM used to impute missing literature data and cluster features, followed by ANN regression to predict chloride threshold values (CT) in reinforced concrete from sparse literature-derived datasets.",
            "citation_title": "Corrosion of rebar in concrete. Part III: Artificial Neural Network analysis of chloride threshold data.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Chloride threshold (CT) prediction for rebar pitting in concrete",
            "problem_description": "Predict the chloride threshold parameter for pitting initiation in reinforced concrete using sparse literature data comprising primary (pH, corrosion potential, breakdown potential) and secondary (cement composition, porosity, w/c ratio) variables.",
            "data_availability": "Moderate-sized compiled literature database (~1242 vectors) but with missing entries; labelled target definitions vary (three CT definitions), data is noisy, heterogeneous and partially missing.",
            "data_structure": "Structured tabular dataset with missing values; mixture of electrochemical measures, concrete composition descriptors and physical properties; some variables interdependent.",
            "problem_complexity": "High complexity: CT is ambiguous and scattered depending on definition; multicollinearity and missingness complicate modelling; high dimensionality (many descriptors) reduced by clustering.",
            "domain_maturity": "Research area with incomplete mechanistic consensus on CT; empirical and statistical analyses prevalent; ML applied to extract patterns from scattered literature data.",
            "mechanistic_understanding_requirements": "High — outputs used to inform safety/service-life decisions; interpretability and careful handling of correlated variables are essential.",
            "ai_methodology_name": "Kohonen Self-Organizing Map (KSOM) + Artificial Neural Network (KSOM-ANN)",
            "ai_methodology_description": "KSOM used for clustering and imputing most-probable values for missing data; the augmented dataset then used to train ANN regression models to predict CT (multiple CT definitions); validation by comparing predicted vs experimental CR and %TotalCl/cem.",
            "ai_methodology_category": "Unsupervised (KSOM) + supervised (ANN) hybrid",
            "applicability": "Applicable for literature-derived sparse datasets with missingness; KSOM aids in imputing missing values and organizing data prior to ANN training.",
            "effectiveness_quantitative": "Reported high training performance: R² = 0.99 on modelling dataset (training), dataset size 1242 vectors.",
            "effectiveness_qualitative": "Model yielded high apparent fit on training but findings must be interpreted cautiously due to definition-dependency of CT, potential biases from imputation, and limited mechanistic guarantee; useful for exploring correlations but not definitive mechanistic conclusions.",
            "impact_potential": "Can synthesize scattered literature data to provide hypotheses on CT dependencies and guide experiments, potentially accelerating understanding of factors affecting pitting threshold.",
            "comparison_to_alternatives": "Approach addresses missing-data limitations of standard supervised modelling; direct comparisons to other imputation + modelling schemes not detailed.",
            "success_factors": "Large compiled literature dataset, KSOM's ability to fill missing entries and cluster similar records, and ANN's flexibility to fit complex nonlinear mappings.",
            "key_insight": "Combining unsupervised imputation (KSOM) with ANN regression enables modelling of a highly scattered, partially missing literature dataset for CT, but results depend strongly on imputation quality and CT definition.",
            "uuid": "e2331.7"
        },
        {
            "name_short": "BRANNGP_inhibitors_Winkler2016",
            "name_full": "Bayesian Regularized Artificial Neural Network with Gaussian Prior (BRANNGP) for corrosion inhibitor screening",
            "brief_description": "A Bayesian-regularised feed-forward neural network using Gaussian priors trained on high-throughput experimental inhibitor data to predict inhibition scores from molecular descriptors, demonstrating improved predictive accuracy over linear models.",
            "citation_title": "Using high throughput experimental data and in silico models to discover alternatives to toxic chromate corrosion inhibitors.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Corrosion inhibitor performance prediction (aluminium alloys)",
            "problem_description": "Predict inhibition score (0-10) of organic molecules on aluminium alloys (AA2024, AA7075) across pH conditions using molecular descriptors from high-throughput experiments and in silico calculations.",
            "data_availability": "Relatively abundant within study: 100-molecule library with ~2000 molecular descriptors; labelled inhibition scores from high-throughput experiments; publicly shared dataset and follow-up classification work.",
            "data_structure": "High-dimensional molecular descriptor vectors (~2000 descriptors reduced via feature selection), structured tabular data; not time-series.",
            "problem_complexity": "High-dimensional input space, complex structure-property relationships, potential nonlinearity between molecular descriptors and inhibition performance.",
            "domain_maturity": "Developing field where prior structure-inhibition hypotheses existed but dataset sizes were limited; the study is among the more comprehensive ML-driven inhibitor studies.",
            "mechanistic_understanding_requirements": "High — mechanistic interpretability desired to discover chemical design rules and replace toxic chromates; black-box predictions insufficient alone.",
            "ai_methodology_name": "Bayesian Regularized Artificial Neural Networks with Gaussian Prior (BRANNGP)",
            "ai_methodology_description": "Feed-forward ANN trained with Bayesian regularization (Gaussian prior) to prevent overfitting in high-dimensional descriptor space; models linked molecular descriptors (non-quantum-chemical and DFT-derived) to inhibition scores; compared with multiple linear regression (MLREM).",
            "ai_methodology_category": "Supervised learning / Bayesian regularized neural networks",
            "applicability": "Well-suited due to large descriptor sets and moderate sample size; Bayesian regularization helps control overfitting and provides more robust generalisation.",
            "effectiveness_quantitative": "Training R² (80/20 split) improved from MLREM to BRANNGP: AA7075 (pH 4) 0.79→0.82, AA7075 (pH 10) 0.56→0.60, AA2024 (pH 4) 0.75→0.82; AA2024 (pH 10) exception where MLREM 0.76 &gt; BRANNGP 0.74.",
            "effectiveness_qualitative": "BRANNGP generally outperformed linear regression, suggesting nonlinear relationships between descriptors and inhibition; DFT quantum-chemical properties showed negligible correlation in this dataset while other descriptors were predictive.",
            "impact_potential": "High: enables screening for benign inhibitor alternatives, reduces experimental burden by prioritising candidates, and informs descriptor-based design rules when combined with feature analysis.",
            "comparison_to_alternatives": "Compared to MLREM (multiple linear regression) and quantum-chemical based descriptors; BRANNGP outperformed MLREM in most cases and showed that non-quantum descriptors were more predictive than DFT features in this dataset.",
            "success_factors": "Large, diverse high-throughput dataset, large descriptor pool with effective feature selection, and Bayesian regularisation preventing overfitting.",
            "key_insight": "Bayesian-regularized neural networks can effectively predict inhibitor performance from high-dimensional molecular descriptors and outperform linear models when non-DFT descriptors capture relevant structure-property signals.",
            "uuid": "e2331.8"
        },
        {
            "name_short": "NGBM_GA_RGANGBM_atmospheric_Zhi2017",
            "name_full": "Nonlinear Grey Bernoulli Model combined with Genetic Algorithm and Regularization (RGANGBM(1,1)) for long-term atmospheric CR time-series",
            "brief_description": "Grey forecasting model (NGBM(1,1)) optimised by genetic algorithms and regularisation to predict long-term corrosion rate time series using small monotonic series with enhanced generalisation.",
            "citation_title": "Long-term prediction on atmospheric corrosion data series of carbon steel in China based on NGBM(1,1) model and genetic algorithm.",
            "mention_or_use": "use",
            "scientific_problem_domain": "Long-term atmospheric corrosion time-series forecasting",
            "problem_description": "Predict long-term (1,2,4,8,16 year) corrosion rate trajectories from small historical monotonic CR series where conventional ML methods risk overfitting.",
            "data_availability": "Small monotonic time-series datasets from specific stations (single-station training, multiple-station testing), labelled with CR vs time; scarce long-term data.",
            "data_structure": "Univariate time-series (CR vs time) with monotonic trends; small sample counts per series.",
            "problem_complexity": "Moderate-to-high due to small-sample time-series forecasting and trend extrapolation; risk of overfitting and low generalisability.",
            "domain_maturity": "Time-series forecasting methods are mature, but grey models are niche for small-sample systems; hybridisation with GA/regularization is an applied innovation here.",
            "mechanistic_understanding_requirements": "Low-to-medium — goal is accurate forecasting rather than mechanistic inference; regularisation parameter was interpreted as related to corrosivity.",
            "ai_methodology_name": "NGBM(1,1) + Genetic Algorithm (GA) with Regularization (RGANGBM(1,1))",
            "ai_methodology_description": "Nonlinear grey Bernoulli forecasting model for small-sample time series; GA optimises model parameters and a regularization parameter η introduced to avoid overfitting and improve generalisation; trained on one station and tested on five others.",
            "ai_methodology_category": "Supervised forecasting / hybrid (grey models + metaheuristic optimization + regularization)",
            "applicability": "Applicable to small monotonic corrosion time series where conventional ML would overfit; designed for extrapolation across years.",
            "effectiveness_quantitative": "Reported mean testing MAPE = 9.15% for 16th-year predictions across tested datasets using RGANGBM(1,1).",
            "effectiveness_qualitative": "Provided relatively high prediction accuracy for long-term forecasting compared to BPNN and SVR on the same small datasets (BPNN MAPE=28.02%, SVR MAPE=83.55% for 16th year), indicating better handling of small monotonic series.",
            "impact_potential": "Useful for long-term corrosion forecasting at specific sites where long historical series are limited; improves planning for infrastructure maintenance.",
            "comparison_to_alternatives": "Outperformed BPNN and SVR on the small monotonic series; regularization critical to avoid overfitting that hampered GA+NGBM without regularization.",
            "success_factors": "Grey model suitability for small-sample monotonic trends, GA for parameter search, and regularisation to control overfitting and improve cross-site generalisation.",
            "key_insight": "Grey forecasting combined with optimisation and regularization can outperform general ML models on very small monotonic corrosion time-series by avoiding overfitting and leveraging trend structure.",
            "uuid": "e2331.9"
        },
        {
            "name_short": "HighTemp_GB_RF_kNN",
            "name_full": "Gradient Boosting, Random Forest and k-Nearest Neighbours for predicting parabolic rate constants of high-temperature oxidation",
            "brief_description": "Supervised regression models (gradient boosting, RF, k-NN and others) trained on literature-compiled k_p values for high-temperature oxidation to relate alloy composition and process variables to oxidation kinetics.",
            "citation_title": "Predicting the parabolic rate constants of high-temperature oxidation of Ti alloys using learning.",
            "mention_or_use": "use",
            "scientific_problem_domain": "High-temperature oxidation kinetics prediction (materials science)",
            "problem_description": "Predict parabolic rate constant k_p for oxidation of Ti and other alloys from descriptors including composition, temperature, time, atmosphere and phase information assembled from literature.",
            "data_availability": "Moderate: 115 to 237 compiled k_p data points across multiple alloys and environments; labelled supervised data built from literature and calculated from corrosion product data.",
            "data_structure": "Structured tabular data: compositional descriptors, phases, process conditions (T, time, atmosphere), environmental descriptors; moderate dimensionality.",
            "problem_complexity": "Moderate complexity: composition-process interactions controlling oxidation kinetics; limited data size relative to descriptor space.",
            "domain_maturity": "Well-established mechanistic theories (parabolic oxidation laws) exist; ML used to accelerate screening and design by mapping composition-process to k_p.",
            "mechanistic_understanding_requirements": "Medium — understanding dominant elemental influences is valuable; ML used to identify important controlling elements (Ni, Cr, Al, Fe).",
            "ai_methodology_name": "Gradient Boosting (GB), Random Forest (RF), k-Nearest Neighbours (k-NN), neural networks and other supervised regressors",
            "ai_methodology_description": "Supervised regression pipelines trained on curated k_p datasets with alloy composition and process descriptors; gradient boosting achieved highest accuracy for the Ti-alloy dataset (R² = 0.92 on 115 points); broader dataset modelling across 237 entries used several algorithms (logistic/linear/RF/NN) with supervised learning.",
            "ai_methodology_category": "Supervised learning / ensemble & instance-based methods",
            "applicability": "Applicable and effective for correlating composition and processing to oxidation kinetics with limited-but-curated literature datasets; useful for materials design screening.",
            "effectiveness_quantitative": "Gradient boosting reported R² = 0.92 on 115-point Ti alloy dataset; broader modelling on 237 k_p dataset produced lowest errors with supervised ML (specific metrics not enumerated in review).",
            "effectiveness_qualitative": "ML provided accurate predictions and identified dominant elemental controls on oxidation kinetics (Ni, Cr, Al, Fe), enabling extension toward alloy design for oxidation resistance.",
            "impact_potential": "High for materials design: accelerates identification of composition-process combinations for improved high-temperature oxidation resistance, reducing experimental iteration time.",
            "comparison_to_alternatives": "Supervised ML achieved lower errors than simpler regression approaches; gradient boosting outperformed RF and k-NN on the Ti dataset.",
            "success_factors": "Curated literature database, appropriate feature selection (composition and process descriptors), and use of ensemble methods that handle complex nonlinear relationships with limited data.",
            "key_insight": "Ensemble supervised regressors like gradient boosting can accurately predict oxidation kinetics from moderate-sized curated datasets and reveal key elemental drivers useful for alloy design.",
            "uuid": "e2331.10"
        },
        {
            "name_short": "General_ensembles_deep_learning",
            "name_full": "Ensemble and deep learning methods for corrosion prediction (general observation)",
            "brief_description": "Across reviewed studies, ensemble methods (RF, GBDT, XGBoost, cascade forests) and deep neural networks generally produced the best predictive performances on nonlinear, high-dimensional corrosion datasets when data size permitted.",
            "citation_title": "Reviewing machine learning of corrosion prediction in a data-oriented perspective",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Multiple corrosion-related prediction tasks (atmospheric, marine, pipeline, rebar, inhibitors, crevice, SCC)",
            "problem_description": "Various regression tasks predicting corrosion rate, depth, defect growth, pitting risk, inhibitor performance and oxidation constants from heterogeneous input features.",
            "data_availability": "Varied across problems: many tasks suffer from small or moderate datasets, noisy heterogeneous sources, missingness and low-value-density; inhibitors and some atmospheric datasets are richer.",
            "data_structure": "Predominantly structured tabular datasets (environmental, material, electrochemical descriptors), often time-series for corrosion rate targets; high-dimensional molecular descriptors for inhibitors; missing and heterogeneous entries common.",
            "problem_complexity": "Overall high: nonlinearity, temporal dependencies, multi-scale mechanisms, multi-factor interactions, manifold structures, and often limited sample sizes per manifold.",
            "domain_maturity": "Domain has mature empirical/mechanistic models but ML application is emerging; need for data sharing and standardised datasets to mature ML deployment.",
            "mechanistic_understanding_requirements": "Medium-to-high — many studies require interpretable results for scientific insight and operational decision-making; black-box models are useful but explainability and domain knowledge integration are emphasised.",
            "ai_methodology_name": "Ensemble methods (Random Forest, GBDT, XGBoost, cForest), deep learning (DNN, cascade forests), hybrid/metaheuristic-enhanced models (RF-WKNNs, DCCF-WKNNs, SFA-LSSVR, PSO-FFANN)",
            "ai_methodology_description": "A range of supervised learning approaches applied: tree ensembles for robustness and feature importance; deep networks/cascade forests for representation learning when sufficient data; hybrids combining ensembles with KNN or metaheuristics to improve generalisation and hyperparameter optimisation; preprocessing (PCA), data augmentation (multivariate polynomial), and imputation methods (KSOM) used as supporting workflows.",
            "ai_methodology_category": "Supervised learning (ensemble, deep learning) and hybrid approaches",
            "applicability": "Generally applicable: ensemble and hybrid methods are appropriate for heterogeneous corrosion data and small-to-moderate sample sizes; deep learning effective when sufficient data/time-series available.",
            "effectiveness_quantitative": "Across reviewed works, ensemble/deep/hybrid methods often yielded the best metrics (examples: RF testing MAPE 16.08% for LAS; DCCF-WKNNs MAPE 12.95%; SFA-LSSVR MAPE 1.26% in marine CR; GBM R²=0.92 for oxidation k_p), but performance depends strongly on dataset size and preprocessing.",
            "effectiveness_qualitative": "Ensembles and hybrids balanced bias-variance effectively and offered superior generalisation vs linear and kernel methods on many corrosion tasks; deep learning provided strong fits when data abundant but risks overfitting on small datasets.",
            "impact_potential": "High: ensemble and hybrid ML methods can significantly improve predictive accuracy for corrosion tasks, inform mechanistic hypotheses via feature importance, and accelerate materials/inhibitor discovery and asset management.",
            "comparison_to_alternatives": "Linear and simple kernel methods often underperformed; SVR showed high scatter and sensitivity; ANNs performed well with sufficient data; ensembles/hybrids typically outperformed other classes across tasks.",
            "success_factors": "Larger dataset sizes, inclusion of time as a feature, careful feature selection/engineering, ensemble/hybrid architectures, hyperparameter optimisation, and integration with domain knowledge.",
            "key_insight": "Ensemble and hybrid ML approaches most effectively handle corrosion's nonlinearity, heterogeneity and small-sample challenges, while deep models excel given sufficient data and temporal features; success depends primarily on data quantity/quality and domain-informed feature selection.",
            "uuid": "e2331.11"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Phenomenological modelling of atmospheric corrosion using an artificial neural network.",
            "rating": 2,
            "sanitized_title": "phenomenological_modelling_of_atmospheric_corrosion_using_an_artificial_neural_network"
        },
        {
            "paper_title": "Prediction and knowledge mining of outdoor atmospheric corrosion rates of low alloy steels based on the random forests approach.",
            "rating": 2,
            "sanitized_title": "prediction_and_knowledge_mining_of_outdoor_atmospheric_corrosion_rates_of_low_alloy_steels_based_on_the_random_forests_approach"
        },
        {
            "paper_title": "An improved deep forest model for forecast the outdoor atmospheric corrosion rate of low-alloy steels.",
            "rating": 2,
            "sanitized_title": "an_improved_deep_forest_model_for_forecast_the_outdoor_atmospheric_corrosion_rate_of_lowalloy_steels"
        },
        {
            "paper_title": "Corrosion rate prediction of 3C steel under different seawater environment by using support vector regression.",
            "rating": 2,
            "sanitized_title": "corrosion_rate_prediction_of_3c_steel_under_different_seawater_environment_by_using_support_vector_regression"
        },
        {
            "paper_title": "The use of artificial intelligence combiners for modeling steel pitting risk and corrosion rate.",
            "rating": 2,
            "sanitized_title": "the_use_of_artificial_intelligence_combiners_for_modeling_steel_pitting_risk_and_corrosion_rate"
        },
        {
            "paper_title": "A data-driven machine learning approach for corrosion risk assessment -a comparative study.",
            "rating": 2,
            "sanitized_title": "a_datadriven_machine_learning_approach_for_corrosion_risk_assessment_a_comparative_study"
        },
        {
            "paper_title": "Ensemble machine learning model for corrosion initiation time estimation of embedded steel reinforced self-compacting concrete.",
            "rating": 2,
            "sanitized_title": "ensemble_machine_learning_model_for_corrosion_initiation_time_estimation_of_embedded_steel_reinforced_selfcompacting_concrete"
        },
        {
            "paper_title": "Corrosion of rebar in concrete. Part III: Artificial Neural Network analysis of chloride threshold data.",
            "rating": 2,
            "sanitized_title": "corrosion_of_rebar_in_concrete_part_iii_artificial_neural_network_analysis_of_chloride_threshold_data"
        },
        {
            "paper_title": "Using high throughput experimental data and in silico models to discover alternatives to toxic chromate corrosion inhibitors.",
            "rating": 2,
            "sanitized_title": "using_high_throughput_experimental_data_and_in_silico_models_to_discover_alternatives_to_toxic_chromate_corrosion_inhibitors"
        },
        {
            "paper_title": "Long-term prediction on atmospheric corrosion data series of carbon steel in China based on NGBM(1,1) model and genetic algorithm.",
            "rating": 2,
            "sanitized_title": "longterm_prediction_on_atmospheric_corrosion_data_series_of_carbon_steel_in_china_based_on_ngbm11_model_and_genetic_algorithm"
        },
        {
            "paper_title": "Predicting the parabolic rate constants of high-temperature oxidation of Ti alloys using learning.",
            "rating": 2,
            "sanitized_title": "predicting_the_parabolic_rate_constants_of_hightemperature_oxidation_of_ti_alloys_using_learning"
        }
    ],
    "cost": 0.027559999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Reviewing machine learning of corrosion prediction in a data-oriented perspective
26 January 2022</p>
<p>Leonardo Bertolucci Coelho leonardo.bertolucci.coelho@vub.be 0000-0002-7106-7603
Department of Materials and Chemistry
Research Group Electrochemical and Surface Engineering
Vrije Universiteit Brussel
BrusselsBelgium</p>
<p>Dawei Zhang 
Beijing Advanced Innovation Center for Materials Genome Engineering
Institute for Advanced Materials and Technology
National Materials Corrosion and Protection Data Center
University of Science and Technology Beijing
BeijingChina</p>
<p>Yves Van Ingelgem 
Department of Materials and Chemistry
Research Group Electrochemical and Surface Engineering
Vrije Universiteit Brussel
BrusselsBelgium</p>
<p>Denis Steckelmacher 
VUB Artificial Intelligence Lab
Vrije Universiteit Brussel
BrusselsBelgium</p>
<p>Ann Nowé 
VUB Artificial Intelligence Lab
Vrije Universiteit Brussel
BrusselsBelgium</p>
<p>Herman Terryn 0000-0003-2639-5496
Department of Materials and Chemistry
Research Group Electrochemical and Surface Engineering
Vrije Universiteit Brussel
BrusselsBelgium</p>
<p>Reviewing machine learning of corrosion prediction in a data-oriented perspective
26 January 20227F0414D8272483ED9AF8CAB7F0BB6E8310.1038/s41529-022-00218-4Received: 7 September 2021; Accepted: 22 December 2021;
This work provides a data-oriented overview of the rapidly growing research field covering machine learning (ML) applied to predicting electrochemical corrosion.Our main aim was to determine which ML models have been applied and how well they performed depending on the corrosion topic considered.From an extensive review of corrosion articles presenting comparable performance metrics, a 'Machine learning for corrosion database' was created, guiding corrosion experts and model developers in their applications of ML to corrosion.Potential research gaps and recommendations are discussed, and a broad perspective for future research paths is provided.</p>
<p>INTRODUCTION</p>
<p>The data-centric analysis presented in this review article derives from the refs [1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19] .The Materials Genome Initiative (MGI) 20 has recently resulted in concentrated efforts to collect materials properties in the form of shared databases 21 .As a result, datadriven approaches have provided effective tools for driving the prediction of properties and the discovery of new materials [21][22][23] .In the era of big materials data 24 , machine learning (ML) has led to a conceptual leap in the field (especially in energy storage applications) 21,[23][24][25][26][27] .Although ML has been gradually applied to corrosion research 28 , the corrosion community has benefited far less from the progress in Big Data technologies.</p>
<p>As with batteries research data 21,29 , corrosion data is typically incomplete, noisy, heterogeneous and large in volume (low-value density).Moreover, the in-service corrosive scenarios are complex and changeable, constituting a highly nonlinear system hardly approachable by traditional statistical methods.</p>
<p>ML is the specific area of AI that allows computers to learn from data solving a given task.It consists of a flexible fitting function approach that, in comparison to traditional computational methods, can provide cheap and accurate simulation processes 21,24,30 .ML aims to acquire knowledge from (very) large datasets by continuously improving their own performance.Despite the lack of prior knowledge of the system, knowledge mining based on ML methods could help the domain expert link outcomes to underlying physical laws or confirm some of the already established concepts 24,27,31 .</p>
<p>A variety of electrochemical techniques has been employed for the prediction of the corrosion behaviour of metals.Accelerated corrosion tests and weathering tests have been historically used to simulate the working conditions of various systems.However, the simulated environmental factors in accelerated tests are distributed in ranges that often differ from the actual application.While in weathering tests, the environmental factors are time-varying with periodicity randomness 32,33 .As there are no clear principles on setting fully representative test profiles, the extrapolation of short-term corrosion test results to field exposures in different environments is a challenging topic 32,33 .</p>
<p>Despite disposing of huge volumes of testing data, the corrosion community still relies on inaccurate predictive models (log-linear 34 , time-varying function 35 , dose-response function 36 , power function 36,37 , Eyring and Arrhenius 38 ) of the in-service corrosion rate (CR).To the best of our knowledge, only one review referring to ML and corrosion is available 39 (this work focused on image recognition and pattern classification).</p>
<p>The selection of the most suitable ML approach is a multifaceted question, depending on the amount of data available, the quality of results desired and the necessity of physical interpretation of the results 27 .Therefore, the present investigation highlights assessing the predictive power of different machine learning approaches and elaborate on the current status of regression modelling for various corrosion topics.</p>
<p>The data mining approach proposed here also aims at identifying unseen patterns from the intersectional ML and corrosion literature (knowledge mining).We encourage new experimental and computer-oriented scientists to apply ML to corrosion prediction studies by discussing challenges and providing recommendations.</p>
<p>BIBLIOMETRIC DATA MINING</p>
<p>The main tool used for identifying relevant literature for this Review was the Web of Science search engine, a large abstract/ citation database covering mainly peer-reviewed journals 40 .The queries employed in the search engine were the following: 'machine learning' AND 'corrosion' ('Topic' search, all types of documents).The 164 records returned from the queries (sent on 1 March 2021) were carefully reviewed and filtered based on domain knowledge.</p>
<p>A co-citation network of publications and their citation relations is presented in Fig. 1 for the 2017-2020 period (the size of the nodes is scaled by the number of citations of each source) 41,42 .The two largest nodes ('machine learning' and 'corrosion') are highly interconnected and are predominantly related to the 'prediction' node than with the 'design' or 'classification' nodes.The obtained cluster illustrates that research has been conducted on distinct corrosion topics (atmospheric corrosion, pitting corrosion) and materials (alloys, carbon steel, reinforced concrete), using different models (artificial neural network (ANN), random forest (RF), support vector machine (SVM)).</p>
<p>Initially, 35 papers in which supervised learning were explicitly used for corrosion prediction were considered (classification modelling investigations were excluded).From this preselection, 16 references where regression models were employed while providing comparable metrics were selected [1][2][3][4][5][6][7][8][9][10][13][14][15][16][17][18] . Finall, 3 other works on artificial neural networks (not designated as ML) 11,12,19 were also included.</p>
<p>Machine learning for corrosion database</p>
<p>The final dataset used for this Review consisted of 19 papers comprising 34 ML works whose models were evaluated by comparable metrics (absolute percentage error (MAPE) and/or the correlation coefficient (R²)).The dataset was loaded in a Jupyter Notebook (Python language), and a ML and corrosion database was built into a Pandas DataFrame (further details in the Supplementary information).</p>
<p>The database 43 disposes of 47 features and 1 indexing column, the 'Reference', the same reference numbering of this article.The features list describes the investigation approach ('Orientationstrategy', 'Targets').It includes essential descriptors of the data ('Data collection', 'Data availability'), corrosion ('Corrosion topic', 'Material') and ML ('Models description', 'Evaluation method', 'Train-Test split').All plots presented in this publication were derived from this database 43 , which is available to download at Mendeley data (related codes available at GitHub).</p>
<p>Based on the 'Selected features' attribute in our ML for corrosion database 43 , Table 1 displays the predictors organised by different categories (environment, material, etc.) for all selected papers [1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19] .</p>
<p>It is essential to remember that our reviewing exercise was conducted with 34 investigations coming from at least 9 broad corrosion topics.A case-by-base judgement of the validity of the predictions was out of our scope.This approach would require indepth expertise related to all addressed topics and much broader access to the corresponding datasets (including the 'bad training data', which is traditionally seldomly reported).</p>
<p>Data dimension Vs publication year</p>
<p>Figure 2 displays the 'Dataset size' and the 'Initial N°of attributes' features as a function of the publication year.Corrosion has always been a multi-dimensional problem, which is reflected in the plot by the relatively constant 'Initial N°of attributes' (number of corrosion variables considered before data reduction) from 1999 to 2021.Nonetheless, from 2018 onwards, the growing trend in 'Dataset size' identified could be attributed to the 'Big Data Boom' 40 .In parallel to the Big Data Boom, the rise in popularity of ML is expected to reduce the contradiction of high-dimensional problems based on small sample sizes 21 .</p>
<p>PERFORMANCE OF THE ML MODELS</p>
<p>The effect of data dimension From Fig. 3, it could be seen that the higher the dataset size, the lower tend to be the mean percentage errors, either during training or testing.The associated mean R² values were, whenever possible, included next to the mean MAPE data points, indicating the good correlation between both metrics.Although not likely to confirm it without the corresponding mean R², the low mean  MAPE values obtained for dataset sizes smaller than 10 1 might result from overfitting.</p>
<p>The effect of the Time variable Figure 4 reveals that the models' performance (expressed by R 2 1-4,6-17,19 ) considerably increased when the Time was considered as an input (refer to the 'Selected features' and 'Time selected?' features in the ML for corrosion database (Supplementary information)).This trend generally held for both the training and testing datasets and was particularly remarkable for the ANN model type.It is interesting noting that Linear models are not suitable for predicting corrosion, which is essentially characterised by time-series data.</p>
<p>Performance per corrosion topic</p>
<p>The performance of the models (Machine learning for corrosion database 43 ) was evaluated either by the R 2 1-4,6,17,19 and/or by MAPE 3,5,[9][10][11]13,19 ). With he models' names and corresponding references, Figs. 5 and 6, respectively, display the achieved R² and MAPE values organised by corrosion topic.Moreover, the data points are subdivided by orientation strategy (Fig. 5) or by type of ML model (Fig. 6).These evaluation metrics derive from models with differences in structure/hyperparameters and represent optimum modelling conditions for each case.Therefore, the reader should be aware that the proposed performance comparisons refer to the modelling approaches in the broad sense (not the models solely).</p>
<p>As displayed in Figs. 5 and 6, atmospheric corrosion has been the most studied corrosion topic [1][2][3][4]6,9,11 . Marinecorrosion seems to be a straightforward research topic: not only relatively high predictive accuracies were achieved 8,18 , but the models demonstrated a high generalisation ability (low difference between training and testing MAPE values (Fig. 6)).On the contrary, the prediction of rebar corrosion has been more scattered, with the highest errors in cases where localised corrosion (pit) occurred (Fig. 6 18 ).</p>
<p>The 'Material &amp; environment' orientation strategy has been the most popular approach, encompassing corrosion-resistant alloys (CRAs) 7 , inhibitors 16 and atmospheric corrosion [1][2][3]6,9 investigations. Regrdless of the corrosion subject, Fig. 5 shows that diversifying types of variables leads to increased performances.For example, in the case of rebar corrosion, investigations simultaneously considering material, system-related and environmental descriptors 19 clearly outperformed both material 14 and environment-oriented 12,18 approaches.A system-orientated strategy has been required for pipeline corrosion (including geometrical pipeline characteristics 13 ), with increased goodness of fit when instrumental variables (e.g.operating pressures 10 ) were also considered.Atmospheric corrosion benefited the most when material features were also included in environmentoriented strategies [1][2][3]6,9 .</p>
<p>Concerning the types of ML models (Fig. 6), ANN (including BPNN (back propagation neural network), DNN (deep neural network) 3,[8][9][10] ) and tree-based (RF, cForest, etc. 3,9,10 ) have generally modelled atmospheric corrosion 3,9 , marine corrosion 8 and pipeline corrosion 10 with reasonable training errors (mostly below 30%).Comparatively, Kernel-based methods (SVR (support vector regression), SVMs) have generated higher prediction scattering across different corrosion topics 3,5,9,18 .Although only a few works employed Linear (logistic regression 3 , linear regression 18 ) or genetic algorithms 5 , these methods tend to produce high and low MAPE values, respectively.Overall, ensemble methods (combination of individual learners) have yielded the best predictive performances [8][9][10]19 , except when modelling the pitting of rebar corrosion 18 .</p>
<p>More details from each investigation, including a further description of the models employed, are disclosed in the corrosion topic sections hereafter.</p>
<p>REVIEWING ML PER CORROSION TOPIC Atmospheric corrosion</p>
<p>Atmospheric corrosion data, traditionally acquired by coupon exposure tests, is often associated with small sample sizes and high dimensionality defined by multiple corrosion-influencing factors.The complexity of the corrosive environment makes it highly challenging for traditional predictive models to make optimal decisions in short timescales 26 .</p>
<p>In 1999, in the pioneering work performed by Cai et al. 11 , a worldwide dataset on the atmospheric corrosion of steel and zinc was used to train and test neural networks.In contrast to previous works using a linear regression technique, the ANN seemed to be a promising modelling tool for addressing nonlinear/complex systems based on interpolation from past experience.Fig. 2 The "Data Boom" effect on the selected ML and corrosion references.The 'Dataset size' and the 'Initial number of attributes' (derived from the Machine learning for corrosion database) are presented Vs the publication year.</p>
<p>Fig. 3 The mean MAPE as a function of the 'Dataset size' (for both training and testing datasets).Corresponding mean R² were included whenever possible next to data points.This plot considered all corrosion topics from the ML for corrosion database 43 .The error bars represent the standard deviation of the mean.</p>
<p>Through sensitivity analysis, ANN could also demonstrate that the CRs of zinc were most likely affected by changes in corrosion products.As the corrosion rates slowed at high TOW (time of wetness), it was suggested that moisture inhibited corrosion due to the formation of protective carbonates.Meanwhile, corrosion significantly increased at high SO 2 concentrations due to sparingly soluble basic sulphates shifting towards soluble sulphates 11 .Concerning steel, knowledge mining showed that the relation between TOW, SO 2 concentration and atmospheric corrosion was almost linear 11 .</p>
<p>Regarding the prediction of corrosion depths, ANN achieved the following (testing) performances for steel and Zn, respectively: R² = 0.548 (MAPE = 39%) and R² = 0.608 (MAPE = 53%) 11 .These testing performance values are displayed in Figs. 6 and 7.</p>
<p>The high variances obtained were mainly due to ignorance of other important affecting variables and inherent scatter in the data from several sources.As the datasets were collected from multiple publications (42), more or less noise or bias is typically unavoidable 24 .</p>
<p>Although the ANN was not suitable to predict very long-term corrosion (lack of datasets), it was expected that its modelling capability could increase by considering more affecting factors and with the availability of more accurate data 11 .</p>
<p>Nearly a decade later, Kamrunnahar et al. 6 employed a neural network backpropagation method as a data mining tool to predict the CRs of carbon and alloy steels.According to the authors 6 , the trends that govern long-term behaviour are among the most critical challenges in corrosion studies.Notably, the effect of environmental variables on the outputs is often not well understood.</p>
<p>The ANN employed data organised according to the differences in the environmental conditions, including temperature, pH, etc. (each condition was unique).The supervised neural network could achieve a high prediction accuracy for long periods, despite being trained with short time period data only 6 .The achieved testing performance (R² = 0.987) is indicated by 'steels' and 'ANN (steels)' in Figs.7 and 5, respectively.</p>
<p>More recently, Zhi et al. 3 developed ML tools to forecast the outdoor atmospheric CR of low alloy steels (LAS).They also applied corrosion-knowledge mining by using a Random Forests (RF) algorithm.By applying this approach on corrosion data of 17 low alloy steels under 6 atmospheric corrosion test stations in China over 16 years 44 , the authors aimed at tackling the three main challenges with atmospheric corrosion datasets from multiple materials/environments: (1) their non-linearity, (2) their steepmanifold structure and ( 3) their (often) small sample size.</p>
<p>In their study, the methods of Logistic Regression (LR) and support vector regression (SVR) were not accurate (MAPE (testing) values of 45.63% and 41.35%) to deal with the steep-manifold structure of the data (at least for the number of samples considered).On the other hand, unstable classifiers (tree-based, ANN) produced acceptable performances using datasets with same sizes (MAPE (testing) = 22.12%, for ANN).In particular, RF was the least affected by the relatively small number of training samples (MAPE (testing) = 16.08%).The MAPE values 3 are indicated in Fig. 6, while the corresponding R² (training) values 3 are indicated by purple arrows in Fig. 7.</p>
<p>Furthermore, RF was applied separately to 5 sub-datasets with different exposures times: 1, 2, 4, 8, 16 years (the corresponding performances are present in the 'Sub-datasets with different times' feature in the ML for corrosion database (Supplementary Notes).</p>
<p>From knowledge mining applied to these sub-datasets, it was revealed that the environmental factor was more important than the material factor, with pH being the most important feature at the two corrosion stages (time split at Year 5).At the initial stage, the 'environment' importance was always greater than 80%.Notably, the SO 2 and Cl − concentrations had higher importance indices than the temperature (T) and the Relative Humidity (RH), while the rainfall was the second most important feature only in Year 1.At the stationary stage (more than 5 years), the corrosion products shielded the LAS from environments, decreasing the importance of the environment factor (the SO 2 importance was much less than Cl − , T and RH) 3 .</p>
<p>In another work, Zhi and co-authors 9 mentioned the current difficulty of making predictions of various materials in diverse and dynamic outdoor environments from modelling approaches based on indoor corrosion tests with just single materials (at least for the commonly used ML models, such as ANN, SVM, power-linear function, hidden Markov).Therefore, the authors proposed a new deep structure, called Densely Connected Cascade Forest-Weighted K-Nearest Neighbours (DCCF-WKNNs), to implement the modelling of LAS atmospheric corrosion from the same dataset previously used in ref. 3 .The different models employed in these two works 3,9 are not directly comparable because the latter 9 disposed of one more input (Fe element).The DCCF-WKNNs inherited the high generalisation ability (MAPE (testing) = 12.95%) Fig. 4 The mean R² as a function of the 'Type of ML model', depending whether the Time was selected as a feature or not.Both training and testing performances were considered for all references using R² as an evaluation metric [1][2][3][4][6][7][8][9][10][11][12][13][14][15][16][17]19 (ML for corrosion database 43 ). The erro bars represent the standard deviation of the mean.</p>
<p>from RF for modelling the small-size LAS outdoor atmospheric corrosion data, also demonstrating a better feature extraction ability as a representation learning algorithm with a deep structure.The testing performances (MAPE and R²) obtained with ANN, SVR, RF, RF-WKNNs, cForest (cascade forests), and DCCF-WKNNs 9 are highlighted in Fig. 6 and indicated by green arrows in Fig. 7.For more information on the developed ensemble model, the reader is referred to the 'Models description' column of the ML for corrosion database (Supplementary Notes).</p>
<p>In addition, knowledge mining could provide quantitative thresholds for the environmental variables; for instance, the CR decreased when pH was higher than ~6.3 or the rainfall was lower than ~320 mm per month; the CR increased when the SO 2 concentration was higher than ~0.067 mg cm −3 or the Cl − concentrations were higher than = 0.8 and 1.9 mg cm −3 ; and whether the electrolyte was continuous or not and whether the film was saturated or not (RH values equal to 67% and 86%, respectively) 9 .</p>
<p>In the same direction, Yan et al. 2 proposed a ML modelling method to simulate the atmospheric corrosion behaviour of LAS.While evaluating the correlations between material, environmental factors and CRs, the impact of rust layer formation as a function of the exposure periods was addressed.</p>
<p>The Pearson correlation coefficient (PCC) was used to evaluate the degree of correlation between multiple variables.Features with significant correlation were grouped into one same cluster and were considered multicollinear features.The dominating factors from each cluster were closely correlated with the output (CR) and independent.The achieved Pearson correlation map demonstrated a positive correlation for all the variables analysed (PCC &gt; 0), highlighting their interdependence (refer to the 'Attributes interdependence' feature in the ML for corrosion database 43 ).</p>
<p>The RF, GBDT (gradient boosted decision trees), and XGBoost models showed high predictive accuracy from the training set, with R² values of 0.94, 0.96 and 0.93, respectively 2 (points a, b and c in Fig. 7).Next, feature importance analysis revealed that the ELEMENTS (total content of alloying elements) feature was among the most significant during the whole exposure period (the SO 2 feature was selected based on domain knowledge).Concerning the environmental features, the CHLORIDE (chloride deposition rate) and PRECIPIT (precipitation) variables were the most significant ones in the first 3 years, while the RH_MIN (minimum relative humidity) became the most significant factor after 5 years 2 .</p>
<p>From this work, the main shortcoming of the RF, GBDT and XGBoost models was their low generalisation ability: R² values (testing) of 0.73, 0.69 and 0.77, respectively 2 (points a′, b′ and c′ in Fig. 7).The authors believed that the data amount was insufficient to reflect the impact of all factors fully.In particular, the low amount of data with high CR values generated a detrimental effect: the models were only accurate for samples with low CR values (limited extrapolation ability) 2 .</p>
<p>Traditional methods to predict atmospheric corrosion requires the accumulation of environmental data yearly.These annual averages could generate inaccurate predictions, especially in the short term 4 .</p>
<p>Based on this premise, Pei et al. 4 monitored the atmospheric corrosion of carbon steel by a Fe/Cu type galvanic corrosion sensor for 34 days.Upon application of RF for the ranking of feature importance, the T (temperature), RH and rainfall status were considered the most important features (pollutants were not significant due to their low concentrations).The authors recommend that the deposition of chlorides (monthly recording) be included as a feature in future works, especially for modelling longer-term corrosion in marine atmospheres 4 .[6][7][8][9][10][11][12][13][14][15][16][17]19 ), segmented by 'Corrosion topic' and organised by 'Orientation strategy'.R² values are distinguished for training ('O') and testing ('X') performances.The models' names of data points referred to in the text were included next to the respective 'X' points (other useful descriptors were also included whenever possible).</p>
<p>The sensor ended almost fully covered with corrosion products, which affected its response and thus the models' accuracy over time.This issue was dealt with by considering the rust formation on the sensor with the integral value of instantaneous corrosion current (Q ACM ) as an input parameter, resulting in improved prediction accuracy for all models (Q ACM was considered the most crucial factor in the second half of the test).Remarkably, the RF model with charge correction produced the highest accuracy, with a R² of 0.940, for both training/testing sets 4 (indicated as 'QACM' and 'RF-QACM' in Figs.7 and 5, respectively).</p>
<p>The application of CR prediction models is often limited to alloys with similar compositions to those used for training (inputs with a fixed number of elements content).Aiming at overcoming this limitation, Diao et al. 1 proposed a feature creation method to convert the chemical composition features from LAS into a set of atomic and physical property features.Thereby, these materialoriented features were used together with environmental factors as inputs, and RF was selected as the modelling algorithm.But firstly, feature reduction methods were applied to select the dominating factors on the data target (GBDT + Kendall provided the best results).</p>
<p>By applying the GBDT + Kendall method, the key factors influencing atmospheric corrosion were identified: Cr, C, Si, P, and S contents, O2_max (maximum dissolved oxygen content), S_max (maximum salinity value of the seawater), pH_min (minimum pH), T_mean (mean temperature).Next, the feature creation methods proposed an effective way to simulate the influence of elemental contents and their interactions with the steel corrosion resistance 1 .Although the feature creation methods (based on physical properties simulating elements) could extend the model's applicability to other alloys, it should be mentioned that modelling with the top 4 most important physical features produced lower performance than with the top 5 elements 1 .This difference in testing performance (R² equal to 0.90 or 0.92) 1 is depicted in Fig. 7 as 'elements' and 'phys.features'.</p>
<p>As summarised in Fig. 7, the same predictive tools have successfully modelled both I or CR; namely SVR [2][3][4]9 , RF 1-4,9 and ANN 3,9,11 .Although more extensive statistics would be needed to confirm this hypothesis, higher goodness of fit was generally observed having the I as data target (CR is an indirect measure often deriving from I).</p>
<p>Finally, Zhi et al. 5 combined a nonlinear grey Bernoulli model (NGBM(1,1)) with genetic algorithm (GA) for long-term prediction on a specific monotonic data series of atmospheric CR.The collected corrosion data of carbon steels exposed in various outdoor atmospheric environments was provided by the China Gateway to Corrosion and Protection 44 .NGBM(1,1) combined with GA had been previously to model small-sample datasets with high performance 45,46 .Nevertheless, the authors reported that when trying to apply GANGBM (1,1) to CR series data, the prediction accuracy was only high for historical data, but not for future data (model overfitting) 5 .</p>
<p>A new RGANGBM(1,1) (regularization genetic algorithm nonlinear grey Bernoulli model) was proposed for the long-term prediction of CR vs time series, from the 1st, 2nd, 4th, 8th and 16th year.Despite training the model with data from only one station while testing it on five other datasets, the mean prediction accuracy of this method was relatively high (for instance, MAPE (testing) = 9.15% (16th year)).Such an outcome was attributed to the overfitting optimisation via the regularisation parameter η (knowledge mining showed that η could reflect the corrosivity of the environment) 5 .</p>
<p>BPNN and SVR were shown to be unreliable when applied to comparable datasets (same sizes), yielding MAPE (testing) values of 28.02% and 83.55% (16th years), respectively-as indicated for ref. 5 in Fig. 6.</p>
<p>Corrosion-resistant alloys</p>
<p>Corrosion prediction is challenging for CRAs, as corrosion tests require considerable time periods for reaching steady states and appreciable weight losses 47 .Kamrunnahar et al. 7 proposed a data mining approach based on weight loss measurements of Alloy 22 in Basic Saturated Water at 60-105 °C (this environment intended to mimic the Yucca Mountain area of the United States, which was of great interest for high-level nuclear waste disposal and storage).The authors were able to predict the general corrosion behaviour of Alloy 22 (canister candidates for nuclear waste disposal) by employing ANN on the training set 7 .The achieved performance (R² = 0.8) 7 is indicated in Fig. 5 as 'ANN (Alloy 22)'.One of the main outcomes was the observed validity of the Arrhenius rule: the model would be applicable outside the ranges considered for the Arrhenius parameters, temperature and CR.This work 7 was elaborated before the Big Data Boom: more data points would be valuable to test the robustness of this ANN approach.</p>
<p>In their early Data mining approach 6 , Kamrunnahar et al. also employed ANN to investigate the general corrosion of metallic glasses with variable compositions.Their objective was to mimic polarisation curves to calculate corrosion potentials and polarisation resistances then.The developed ANN could learn the underlying functions in mapping corrosion variables, alloy characteristics, and environments (HCl, H 2 SO 4 ) to the different corrosion metrics.Although the train-test split procedure used was not specified, the model showed good agreement with experimental data as a function of the changing environment (average R² between 0.87 and 1, depending on the data target) 6 .The achieved performances, with corresponding targets (i, E, Rp) and solutions (HCl, H 2 SO 4 ), are indicated in Fig. 5 as a green 'ANN' 6 .</p>
<p>Marine corrosion</p>
<p>As an early example of ML work, Wen et al. 8 combined SVR with particle swarm optimisation (PSO) for predictive modelling of marine corrosion.Before 2008, Artificial Neural Networks were the main ML modelling tool employed for corrosion studies and had proven to be effective for predicting atmospheric corrosion of steel and zinc 11 .</p>
<p>Nonetheless, the weak generalisation ability and tendency to overfitting was already known for ANN modelling with smallsample datasets.For instance, this work 8 demonstrated that the higher the number of training samples (41 or 42 out of 46), the better the regression performance of BPNN (MAPE (testing) of 5.001% or 4.215%, respectively).]6,9,11 ).Data points were segmented by 'Targets' (current I, CR, depth) and by 'ML models' .R² values are distinguished for the training ('O') and testing ('X') performances.Meaningful entries from the following features were included in the plot: the 'Material' (Zn, steel 11 , steels 6 ); the 'Selected features' (elements, phys.features 1 ).Q ACM indicates the RF with charge correction 4 .The purple and green arrows, respectively, indicate the data points from refs. 3 and 9 (modelling on the same dataset).The difference between values a, b, c and a′, b′, c′ highlights a low generalisation ability 2 .</p>
<p>which resulted in MAPE (testing) values of 3.840%, 3.180% and 1.360% (for 41, and 45 (LOOCV) training samples, respectively).Nonetheless, from a goodness-of-fit point of view, it is worth noting that the SVR-PSO (LOOCV) produced the lowest R² (testing) value reported: 0.836.All reported metrics (MAPE and R² (testing)) related to the corresponding models' 8 are highlighted in Figs. 5 and 6.</p>
<p>Using sample datasets considered small by today's standards, SVR-PSO presented a high accuracy for predicting the CR of 3C steel under different seawater environments.Nonetheless, the model also showed a limited extrapolation ability.The collection of more experimental data (with larger data ranges) could enhance the model regression accuracy 8 .</p>
<p>More recently, using the same dataset as in ref. 8 , Chou et al. 18 also attempted the ML modelling of marine corrosion on carbon steel.The prediction included single and ensemble models constructed from four well-known machine learners, including SVR/SVMs, classification and regression tree (CART), and linear regression (LR).Various ML models are typically used to construct single classifiers, but ensemble systems compensate for errors made by the individual classifiers.The tiering ensemble models were shown to improve further the predictive accuracy of SVR (best individual model) 18 .</p>
<p>Nature-inspired metaheuristic optimisation algorithms such as the firefly algorithm (FA) have effectively solved difficult optimisation problems 48 .A hybrid model was recently implemented by integrating a smart firefly algorithm (SFA) with a least-squares SVR 49 .Notably, this hybrid SFA-LSSVR model was shown to be effective for modelling CRs of 3C steel, outperforming all other models 18 .The MAPE (testing) values achieved for SFA-LSSVR (1.26%) and for all other tested models (SVR, CART + LR, LR, CART + SVR + LR, SVMs +SVR, SVMs+CART) 18 are highlighted in Fig. 6.</p>
<p>Pipeline corrosion</p>
<p>Understanding and predicting the risk of pipeline corrosion is essential for maintaining oil operations healthy and safe.The first step in the Corrosion Risk Assessment of oil and gas companies is selecting the input parameters for estimating the corrosion defect depth amongst many parameters routinely measured 10 .</p>
<p>In a quest for estimating the defect depth growth of aged pipelines, Ossai et al. 10 implemented a data-driven ML approach relying on PSO, Feed-Forward Artificial Neural Network (FFANN), Gradient Boosting Machine (GBM), RF and Deep Neural Network (DNN).The influence of PCA-transformed (Principal Component Analysis) variables on the accuracy of the models was also conducted.</p>
<p>Before the application of the models mentioned above, a multivariate polynomial regression was used to fit the entire dataset coming from 60 wells (R² (training) = 0.9819, as included in Fig. 5 as 'MP' 10 ).The objective was to avoid data bias by having new datasets comprising variable scenarios of corrosion severity.Thus, the multivariate polynomial was used for data generation and provided a larger training dataset for the ML algorithms.</p>
<p>A PCA transformation thus highlighted the improvement in the prediction of future states of corrosion defect depth growth.For PCA non-transformed and transformed inputs (respectively), the PSO-FFANN, GBM, RF and DNN models produced training MAPE (%) values of 34.1329, 31.9266,32.4267, 23.647 and 7.8588, 6.0082, 7.7421, 6.6813 10 .All these models/metrics relationships 10 are displayed in Fig. 6.</p>
<p>Supported by the operating parameters of pipelines, this work contributed to understanding the time-dependent changes in the defect depth growth trajectories (over a 10 year period) 10 .</p>
<p>Since internal corrosion of pipelines results from an interaction of different mechanisms, a large degree of uncertainty is associated with the prediction of the damage evolution.</p>
<p>De Masi et al. 13 developed a predictive model to identify pipeline sections exposed to higher corrosion risks (existing approaches have not reproduced behaviours observed during gauging activity).The authors' premise was that combining data with different natures (geometrical profile of pipelines, fluid dynamic multiphase variables and deterministic models) could enormously improve the performance of predictive tasks 13 .</p>
<p>Thereby, by considering several network inputs, an ANN ensemble model could correctly identify the regions of pipelines where corrosion was most likely.This strategy improved not only the prediction performance obtained with deterministic models but also with single ANN models.For instance, the R² (testing) values achieved for the ANN and the ANN ensemble were respectively: 0.689 and 0.884 (for CR) or 0.336 and 0.672 (for volume loss).All these performance metrics are mapped in Fig. 5 13 .</p>
<p>Rebar corrosion</p>
<p>The highly nonlinear nature of embedded steel corrosion and the lack of theoretical basis for some corrosion phenomena render the predictive modelling in this topic difficult.In particular, the corrosion initiation of reinforced concrete is a crucial service life parameter, which depends upon the material, the environment, and the duration of exposure.The early detection of corrosion initiation of embedded steel could save cost and time.</p>
<p>To optimise the predictive modelling of corrosion initiation time, Salami et al. 14 compared the performances of different ML techniques with the corrosion potential (measured in 5% NaCl) as the data target.Before the regression modelling, various dataset transformations were applied, revealing no significant effect on the resulting performance (the raw dataset was considered) 14 .</p>
<p>This low sensitivity towards feature engineering techniques is aligned with the more recent models, such as deep learning (provided that the amount of training data is high enough) 14 .</p>
<p>This finding is in contraction with the results reported in ref. 10 , where the performance of the DNN model clearly increased with PCA transformation.</p>
<p>Next, RF was shown to combine high flexibility and could generalise with high accuracy the corrosion initiation times (R² (testing) = 0.897).The effect of split percentage on the performances of RF revealed that the model variance further reduced with an increase in the training dataset, with the highest performance achieved with an 85/15 dataset percentage split (R² (testing) = 0.974).These models and corresponding metrics are displayed in Fig. 5 14 .</p>
<p>The modelling of rebar corrosion is further complexified when localised corrosion (pitting) occurs, which is often the case in chloride-laden media.The chloride threshold (Clth) is defined as the chloride content necessary to sustain the breakdown of the passive film and is an essential parameter for assessing the service life of reinforced concrete 12 .The literature reports that the current lack of understanding of the Clth value of steel in concrete is due to its numerous factors affecting pitting corrosion (pH, E of the steel, physical condition of the steel/concrete interface) 12 .</p>
<p>Searching to establish a phenomenological model correlating the pitting risk of steel (characterised by Ecorr -Epit) and environmental factors, Shi et al. 12 applied a modified back propagation (BP) algorithm for ANN training with laboratory data from simulated concrete pore solutions.Only the training performance of the back propagation ANN was reported (R² = 0.8741), as indicated by 'BP ANN' in Fig. 5 12 .</p>
<p>From knowledge mining, the authors elaborated the following measures to enhance the Clth of rebar: the initial [Cl], as well as the DO, should be limited, while the percentage of bound Cl − and the pH of concrete should be maximised.However, they cautioned that only the overall trends were observed with independent variables maintained at specific levels 12 .</p>
<p>Six years after the publication of the 'pitting corrosion of steel rebar' dataset 12 , Chou et al. 18 derived this data for testing their advanced SFA-LSSVR model.Unfortunately, no performance comparison could be elaborated between both works 12,18 , as different evaluation metrics were used.</p>
<p>The SFA-LSSVR model presented a lower predictive performance for rebar pitting risk than the obtained for marine CR reported in the same work (shown in the Marine corrosion topic) 18 .Here, as illustrated in Fig. 6 as 'SFA-LSSVR (pit)', the model produced a MAPE (testing) value of 5.60% 18 .Such as for the marine corrosion case, although the tiering ensemble models outperformed all individual models, none of them reached reasonable percentage errors such as the one achieved by the hybrid model 18 .Further investigations would be envisaged for testing the prediction accuracy of SFA-LSSVR applied to different scenarios.</p>
<p>In 2021, Zhu et al. 19 combined ANN with Kohonen Self-Organized Mapping (KSOM) for modelling the chloride threshold (CT) in reinforced concrete from a sparse literature database.Their KSOM-ANN approach was first applied to find the most probable values for missing data, including primary (pH, corrosion potential, breakdown potential, temperature) and secondary independent variables (cement composition, concrete porosity, water/cement ratio) ('Attributes interdependence' feature in the ML for corrosion database 43 ).The trained KSOM-ANN was validated by comparing the predicted values with the experimental ones in the evaluation database for CR (%TotalCl/cem).Modelling a dataset of 1242 vectors yielded a high training performance (R² = 0.99, as indicated by 'K-ANN' in Fig. 5) 19 .</p>
<p>Next, the network revealed quantitative correlations between the major dependent (CT in three possible definitions) and the corresponding independent variables.For instance, it was found that CT was only poorly correlated with porosity, water/cement ratio, and the Al 2 O 3 , Fe 2 O 3 , MgO, K 2 O and SO 3 oxide contents of the cement.These findings are generally not supported by experimental investigations, thus claiming that CT is a highly scattered property and ambiguous in capturing all variables concerned.Particularly in the case of porosity, the weak correlation seemed to result from an interplay between the volume available to accommodate the same amount of Cl − and the migration/diffusion effect, which increases with porosity.Nonetheless, for a comprehensive understanding of the correlations obtained, one should consider that they depend on the definition of CT used.Indeed, a given definition of CT does not provide a unique measure of the aggressiveness of a particular concrete system because of simultaneous changes in pH and pKw (this issue was further addressed in Part II of the series 50 ).Interestingly, the CT was independent of the w/cem ratio in all three definitions, for which the lack of correlation was attributed to the weak effect of the w/cem ratio on the bound Cl − .</p>
<p>Crevice corrosion</p>
<p>Besides being effective when dealing with atmospheric and general corrosion, the ANN model developed by Kamrunnahar et al. 6 also proved to be efficient for modelling localised corrosion.Based on crevice corrosion data on Ti-2, the ANN predicted the alloy's penetration depth over much longer times than the timescale of the experimental data available.The ANN could perfectly fit the datasets for the 4 outputs considered 6 .The corresponding performance values (R² (training) = 1) are illustrated in Fig. 5 as 'ANN (Ti-2)' 6 .</p>
<p>The ANN model developed by Kamrunnahar et al. was not only able to predict the weight loss of the corrosion-resistant Alloy 22 (Nuclear corrosion topic) but also the alloy's localised behaviour 7 .Remarkably, the model mapped the environment (pH, [Cl − ]), the alloy condition, and the sample treatment to the crevice repassivation potential.Through ANN weighting, the input variable with the highest importance was the chloride concentration, which was a very realistic outcome based on domain knowledge.As only the average R squared value was provided (2-fold cross-validation (CV)) 7 , this was considered as a training (R²) performance point in Fig. 5 (indicated by 'ANN' 7 ).</p>
<p>Stress corrosion cracking</p>
<p>In 2014, Shi et al. 15 derived a database from the literature to train an ANN to predict the crack growth rate (CGR) in 304 SS.The primary motivation of the authors was to reduce the dispersion data (often higher than two orders of magnitude) associated with the modelling estimation of CGR from sensitised stainless steels.First, ANN sensitivity analysis was done to evaluate the contribution of each independent variable to the dependent variable.Next, the ANN-predicted CGR values were shown to be virtually identical to the ones obtained by the (deterministic) extended Coupled Environment Fracture Model (CEFM) (R² (training) = 0.95, as shown in Fig. 5 by 'ANN' 15 ).Moreover, both the AI model and the deterministic one predicted that CGR increased strongly with increased concentration in O 2 .</p>
<p>Corrosion inhibitors</p>
<p>Benign and efficient corrosion inhibitors are needed for overpassing the restrictions of toxic chromate-based technologies in the aerospace industry.</p>
<p>Winkler et al. 16 combined high throughput experiments with ML to determine the inhibition score (0-10) of corrosion inhibitors for aluminium alloys.The prediction of inhibition performance was conducted over an extensive library (100) of organic molecules tested on AA2024 and AA7075, at pH 4 and 10.</p>
<p>First, ML showed a negligible correlation between quantum chemical properties (calculated by DFT) and inhibition, suggesting that published structure-inhibition models available in the literature were incorrect (these were presumably based on minimum numbers of molecules).</p>
<p>Then, different robust models (including the BRANNGP (feed forward Bayesian regularised neural networks using a Gaussian prior)) were developed, linking molecular properties calculated by non-quantum chemical methods and inhibition.The BRANNGP model overperformed the MLREM model (multiple linear regressions), increasing the R² (training, 80/20 split) values from 0.79, 0.56, 0.75 to 0.82, 0.60, 0.82, for AA7075 (pH 4), AA7075 (pH 10), AA2024 (pH 4), respectively.The only exception was the AA2024 (pH 10) system, where the MLREM produced a higher R² (training, 80/20 split) than the BRANNGP (0.76 and 0.74, respectively) 16 .All these metric relationships are exhibited in Fig. 5 by the models' names (with respective alloy and solution) 16 .</p>
<p>In terms of the number and diversity of inhibitors, range of alloys and pHs, this work 16 stands out as one of the most comprehensive corrosion modelling studies.Besides, many descriptors (∼2000) were obtained, and the ones made available were employed in a subsequent ML work on the classification of inhibitors 51 .Nevertheless, the authors referred to the relatively opaque or arcane nature of the ensemble methods, which renders difficult the mechanistic interpretation of the phenomena 16 .</p>
<p>Conversion coatings</p>
<p>In a recent design-oriented work 17 , a new designing strategy, i.e. the ratio of the total acidity (TA) and pH value (TA/pH) was proposed to validate the chemical formulation of a phosphatebased conversion coating.The results indicated that ANN could not fit the corrosion performance solely with the pH or the TA predictor, presenting a relatively accurate prediction based on TA/pH 17 .</p>
<p>In Fig. 5, the average R squared obtained are presented as R² (training) values, with 0.19, 0.49 and 0.86 for pH, TA and TA/pH, respectively 17 .Furthermore, the corrosion performance of the phosphate coatings (PCC) increased with the decrease in TA/pH.However, it was impossible to produce a coating with good corrosion performance in pure water (TA/pH equal to 0).The authors explained that a critical value of TA/pH should be the boundary of the proposed theory of TA/pH.They also pointed out the complexity of decreasing TA/pH under the premise of maintaining the stability of the conversion bath and concluded that the validity of using TA/pH in large pH ranges should be further discussed 17 .</p>
<p>High-temperature oxidation</p>
<p>Although the data analysis conducted in this Review is entirely based on research papers focusing on electrochemical corrosion, two recent articles covering a correlated topic (ML applied to hightemperature oxidation) 52,53 are worth the assessment.</p>
<p>In the first of these two publications 52 , ML was used to predict the parabolic rate constant (k p ) for high-temperature oxidation of Ti alloys.Three different regression ML models (Gradient Boosting, Random Forest, k-Nearest Neighbours) were applied to a dataset of k p values (115 data points) built from experimental studies reported in the literature.Several descriptors (alloys' composition, constituent phase, temperature of oxidation, time for oxidation, O 2 content, moisture content, remaining atmosphere, mode of oxidation) were selected as independent variables.The gradient boosting model produced the highest achieved accuracy (R² = 0.92).The learning from this work could be extended to design novel Ti alloys with enhanced resistance against high-temperature oxidation 52 .</p>
<p>In the second publication 53 , 237 unique k p values were extracted from publications, calculated from corrosion product data and structured in a comprehensive database.The hightemperature oxidation dataset comprised entries from various environments (exposed temperatures between ~500 and 1700 °C) from 75 alloys, including low-and high-Cr ferritic/austenitic steels, nickel superalloys, aluminide materials.Several modelling strategies (including supervised ML) were implemented to explore the relationships between composition and oxidation kinetics.The modelling of materials based on their k p values presented the lowest errors achieved when supervised ML (logistic regression, linear regression, RF, decision tree, neural network) was employed.Furthermore, the dominant elements encountered to control the oxidation kinetics were Ni, Cr, Al and Fe (Mo and Co were also considered relevant descriptors) 53 .</p>
<p>MODELLING APPROACHES: CRITICAL ANALYSIS</p>
<p>One of the most commonly encountered findings against good practices in ML is the use of small training datasets, which potentially leads to overfitting.For instance, BPNN and SVR were unreliable when applied to datasets with low sizes 5 .In ref. 7 ('Crevice corrosion' section), the small sample dataset was the main drawback of the study.The small size of the training sample for the network modelling was also critical in ref. 13 .Conversely, the MP regression was most likely only efficient because dealing with such a large input dataset (8300 samples) 10 .Regrettably, the final data dimension upon application of PCA was not presented 10 .</p>
<p>Another issue with small datasets is that appropriate data splitting methods become less feasible.For example, due to the small sample size (only 8 samples), the data was not divided into training and testing sets in ref. 6 ('Crevice corrosion' section).The training-testing split method was unfortunately not clear 6 ('Atmospheric corrosion' section): only one type of steel seems to have been included in the testing set (the training performance was not presented).In ref. 7 ('Corrosion-resistant alloys' section), the same data was used for training-testing (the employed cross-validation method was not specified).</p>
<p>Not only the model's generalisation ability is essential, but also its extrapolation ability.Hence, to improve the prediction accuracy, more relevant data within appropriate ranges would be needed.In the case of ref. 2 , this would imply more samples with corrosion rates higher than 0.050 mm per year.As reported in ref. 13 , the prediction accuracy could be enhanced by considering larger datasets comprising several pipeline cases and flow conditions.In ref. 14 , tests were performed under laboratory conditions only: the validation of the RF method for the prediction of concrete corrosion would be recommended in in-field samples.Similarly, further study would be required to explore the broader applicability of the SFA-LSSVR 18 .Unfortunately, the electrochemical methods employed for data acquisition in ref. 8 are unknown.</p>
<p>In ref. 1 , features such as the flow velocity or microorganisms, also seriously influencing the corrosion rate of LAS in marine environments, were not explored.The investigation 3 lacks features describing the material microstructure.Unfortunately, the paper 9 did not discuss the effects of the composition or the microstructure.An illustrative example is the pitting risk of steel in simulated concrete pore solutions 12 : modelling from the referred predictors would be more complex than the initially conceived.Although the flow velocity was not included in this analysis 15 , theory indicates that this operational variable should be considered in SCC modelling.When assumptions are oversimplified, the model might be susceptible to underfitting.Increasing the data dimension with properly selected variables (based on domain knowledge) might improve further the model performance.</p>
<p>Finally, only one referenced paper 19 formally addressed the critical property of attributes interdependence.In there, as the corrosion potential (ECP) is also a function of T, pH and [Cl − ], the trends in CT with these independent variables must consider their interdependence with ECP 19 .Input independence leads to a more accurate prediction when there is enough information to describe data distribution in feature space.However, adding variables that depend on others and contain newer and richer information would improve the model accuracy and robustness.</p>
<p>PERFORMANCE OF THE ML MODELS: CONCLUSIONS</p>
<p>Not all articles used the same training, validation, and testing datasets, bringing extra uncertainty to comparing performances.As clearly visible in the plots dividing the training and testing performances, the testing performances are sometimes not reported, contrary to the good practices in the field.For the sake of easing comparisons, it would also be recommended to clearly report the number of learnable parameters/hyperparameters between models 54 .</p>
<p>Nonetheless, one could apprehend from Figs. 6 and 7 that the linear regression algorithms have difficulties in dealing with nonlinear datasets and/or with high dimensionality data.Kernelbased algorithms are effective when dealing with nonlinear and/ or sparse data but have a low training efficiency with large datasets 26,27 .The SVR models' performances are associated with points with relatively high scatter, reflecting their sensitivity to the Kernel selection (which could lead to training failure).</p>
<p>On the other hand, neural networks are more training expensive (vast number of tuning parameters) but provided there is enough data available, they might yield the best possible quality fitting 27 .This observation corresponds well with the performances observed for BPNN and/or ANN (Figs. 6 and 7).Neural networks were developed for modelling sequence data, and the recurrent method (most of the ANN models in the ML for corrosion database 43 ) is especially suitable for time series data (Fig. 4).For example, in Fig. 7, ANN presented a lower predictive performance on corrosion depth (static data) 11 than on CR (temporal data) 3,9 .</p>
<p>The Tree-based methods can handle missing data and datasets with multiple but can be prone to instabilities 24,26,40 .As explicit in Figs. 6 and 7, the considerable divergence between training and testing performances might reflect their overfitting characteristic.</p>
<p>Deep learning models (for example, ANN with multiple hidden layers) have high robustness, accuracy, and reliability when dealing with highly nonlinear and complex relationships between the input and output data 26,40 .The main drawback of deep learning, which requires a large amount of training data, is most likely to be surmounted as we enter the Big Data and the internet of things (IoT) era 40 .</p>
<p>The ensemble (hybrid) methods cited accomplished predictive tasks with superior performance by combining various weak learners.Worthy mentioning the regression trees (weak learner) was efficiently used to build models (GBDT, XGBoost) for predicting the weight loss of LAS 2 .</p>
<p>Modelling with ensemble methods (SVR-PSO, RF-WKNNs, PSO-FFANN, SFA-LSSVR, KSOM-ANN) or deep learning (cForest, DCCF-WKNNs, DNN, and the most ANNs here addressed) generally produced the highest observed performances.Both approaches could certainly solve possible contradictions between the high dimensionality and the small sample often observed in electrochemical data 21,40 .</p>
<p>CHALLENGES</p>
<p>A central challenge in machine learning is the conflict between the complexity and accuracy of the models 21 .This point is particularly true in the case of deep learning because these models usually have more complicated structures (structural designing becomes vital) 26 .Such as illustrated in Fig. 7, hybrid models with high complexity (XGBoost, RF-WKNNs, cForest, DCCF-WKNNs) could yield better performance than all the others.However, concerns related to their scalability exist, especially when non-parametric methods (tree-based, CARTs, SVMs, KNNs) are included 40 .</p>
<p>From a Review on ML approaches for energy systems 40 , the need to develop models that are generalisable to wider settings is claimed.authors also point out the lack of modelling details across a vast part of the reviewed literature.Notably, the number of times the models were trained are rarely reported 54 .</p>
<p>As it is complicated to translate the ML black box mechanics to formulas, many efforts have been devoted to developing more interpretable algorithms 24,55 , including the rule extraction (express the implied knowledge with patterns that are easy to understand) 21 and argument based machine learning (ABML), which improves the comprehensibility of the learned concepts 31 .</p>
<p>The learning achieved by ML frequently conflicts with domain expert knowledge.As much as for the batteries field, it is also imperative to establish AI approaches encompassing domain knowledge in the corrosion field 21 .For example, from this work on atmospheric corrosion 2 , each feature's significance to the CR was ranked based on the Pearson correlation coefficient and MIC (maximal information coefficient) methods.Although the SO 2 feature was not indicated as dominating factor, the authors decided to include it based on domain knowledge.</p>
<p>Although ML is a powerful tool for finding statistical patterns hidden behind multi-dimensional data, condensing the extracted knowledge into scientific laws for general cases is challenging 24 .When the expertise from the corrosion field is incorporated into the modelling already during the definition of problems, it often leads to the best results 31 .</p>
<p>Typical algorithms that could integrate domain knowledge and ML methods include Bayesian network, fuzzy learning 21 and argument based machine learning (ABML enables the knowledge to be articulated easily) 31 .</p>
<p>The availability of high-quality datasets is a primary challenge in ML for corrosion and is separately addressed in the Data sharing section.</p>
<p>GUIDELINES</p>
<p>The success of ML modelling most likely relies on the use of large datasets (Fig. 3), but even more on the proper selection of features 23,24 .Incorporating basic descriptors based on domain knowledge often simplifies the representation and improves the interpretability of machine learning modelling 21 .As highlighted in this Review (Fig. 4), the selection of temporal variables positively affects the overall models performance.Alternatively, ML could be applied to capture the remaining divergence between the target properties and the outputs from deterministic modelling 27 .</p>
<p>Such as in the case of this addressed study 13 , where data from different natures were considered (in-field measurements, software simulation and deterministic models), ML should be coupled more tightly with other approaches (experiments, numerical simulations, deterministic models) 26 .For instance, as previously described 6 , ANN could validate the high fidelity prediction of a deterministic model (CEFM) in capturing the electrochemical/ mechanical/microstructural phenomena of crack growth rates.</p>
<p>In a Review paper on energy materials published in 2021 26 , the authors emphasised that the application of ML should not be limited to the predictive tasks but should encompass all datarelated stages, including data-preprocessing and data mining.Text mining technologies, including full-text publisher application programming interfaces (APIs) and natural language processing (NLP) 56 , have been extensively used in materials science and chemistry 24 .</p>
<p>Moreover, ML could be an intermediate step for processing the collected datasets, thus reducing redundant experiments (or simulations) 26 .Ensemble learning strategies could be applied in the training phase to increase the model efficiency and robustness.</p>
<p>DATA SHARING: INITIATIVES AND RECOMMENDATIONS</p>
<p>Unlike traditional hard-coded modelling based on human expertise, ML approaches rely on available datasets for building reliable models.For accelerated progress of corrosion predictive modelling, collaborative culture of sharing of knowledge and resources (data, models, software) between the computer science and corrosion fields should be fostered 57 .</p>
<p>In the era of big materials data, considerable efforts have been made to collect and build materials properties databases 24,58 .In their review on machine learning for molecular and materials science, Butler et al. 59 listed the publicly accessible machine learning resources and tools.The available ML tools related to molecules and materials might be of great interest for corrosion research.The Materials Project and the Open Quantum Materials Database (OQMD) (referred to in ref. 27 ) also provides an ideal platform for machine learning.</p>
<p>The 'Data availability' feature of the Machine learning for corrosion database (Supplementary Notes) provides links to high quality publicly available datasets that can be downloaded for ML modelling.Atmospheric corrosion is the most studied topic, thanks to the good availability of atmospheric/climatic data obtained following standardised approaches.</p>
<p>Besides sharing datasets, researchers should ideally open their modelling codes and libraries as much as possible, thus providing a viable path for the transferability of their models 25,30 .Among the papers considered in the Machine learning for corrosion database 43 , only one investigation 16 made available related codes (see the 'Libraries' feature (Supplementary information)).</p>
<p>However, electrochemical data is often not shared in a systematic and machine-readable way 25,27 .The research community is also concerned with how to build/optimise such databases in more automated fashion.</p>
<p>Data standards and tools for automated organisation are needed to structure the data in a reusable fashion.Such initiatives have paved the way for innovation in battery technologies (through wider availability of high-quality databases) 25,27,30 .It would be recommended not to let corrosion data buried in figures only but also to present it within structured Tables that are readily accessible.In particular, reporting more failed data used during training and data from negative experiments would accelerate this process 24,27 .</p>
<p>RESEARCH EVOLUTION AND PERSPECTIVES</p>
<p>Training ML models with large datasets presenting comparable features across wide ranges of values is paramount for accurate prediction 2,24,26,54 .</p>
<p>In a Review paper on rechargeable batteries 21 , virtual sample generation (VSG) methods are cited as a solution for filling in data gaps.As a similar example from the selected papers on pipeline corrosion, the multivariate polynomial employed by Ossai et al. 10 generated defect depth values to complement their training dataset.</p>
<p>Another method for constructing training sets that might be particularly useful for corrosion studies based on small sample data is active learning (selecting effective samples by iterative sampling that ensures the highest possible accuracy 21 ).Active learning has been considered a promising approach for learning the high-dimensional data of battery materials 21 .Similarly, in a recent review paper on ML and energy storage, Gao et al. 26 refer to an unsupervised learning (generative adversarial network, GAN) capable of reconstructing/repairing datasets, thus enhancing their quality.The GAN approach might be beneficial for in-field corrosion measurements, where the quality and integrity of the data are often compromised.</p>
<p>Finally, transfer learning technology has been demonstrated to improve the applicable range of predictive models 23,26 .From the review on deep learning on materials degradation 39 , Nash et al. mentioned capability of transfer learning in fine-tuning models for tasks other than the ones they were trained on.</p>
<p>Although not the focus of this paper, machine learning has accelerated the discovery of new materials [21][22][23] .In the development of batteries, Attia et al. 52 employed a ML method that could reduce the time of performance tests by 98%.A similar approach would be instrumental in corrosion research because testing in simulated environments usually lasts weeks or even months (corrosion acceleration tests).This time-consuming aspect has become a limiting factor for the long-term study of corrosion, particularly atmospheric corrosion, where testing protocols often take years to complete.</p>
<p>Seeking at discovering the links between material composition, structure, properties and performance, scientists have input various property features to machine learning 21,28 .For example, ML methods have been applied to property prediction for energy conversion materials, potentially overcoming the shortcomings of DFT (high consumption of computational resources) 24 .For instance, ML of quantum-mechanical reference data has been used for fast and accurate interatomic potentials of battery materials 30 .ML has indeed the potential to bridge new synergies between experimental data and DFT modelling.</p>
<p>In their comprehensive study on the machine learning of corrosion inhibitors, Winkler et al. 16 assumed that molecular properties permitted more reliable models than quantum chemical properties of the individual compounds.In an ensuing investigation based on classification algorithms 51 , the structureproperty relationships in aluminium alloy inhibitors were further elucidated.Galvão et al. 51 employed new descriptors related to the self-association between inhibitors (dimerisation enthalpies and Gibbs energies), gaining further insights into the properties that distinguish these molecules.</p>
<p>This bibliometric data mining revealed not only the low number of ML works focusing on corrosion inhibitors (or other vital topics such as protective coatings or localised corrosion) but also identified several research gaps in which ML could be envisaged: EIS, local electrochemical techniques, microbial corrosion, corrosion of electronics, tribocorrosion.</p>
<p>To decrease the usage complexity of ML, automated (Auto) ML has attempted to limit human intervention in the model implementation 21 .In this context, meta-learning or 'learning to learn' methods have emerged and shown to be particularly useful in image recognition 24 .The task of hyperparameters' optimisation of nonlinear models (ANN, SVR) is complex and often relies on trial and error.Hyperparameter optimisation methods have been proposed to simplify these tuning processes 21 , including Auto ML 60 .From the selected papers, two investigations implemented distinct approaches to address this issue: the SFA was proven to be effective in dynamically optimise the LSSVR hyperparameters 18 , and the genetic algorithm NGBM (1,1) included a regularisation term η to avoid the overfitting problem 5 .</p>
<p>A variation of ensemble method called Temporal Ensemble Learning (TEL), in which temporal features portion the dataset for the forecast at specific time ranges 40 , might be a promising alternative for time series data in corrosion.</p>
<p>Although probabilistic (Gaussian processing regression) models have shown promising forecasting results in the energy and battery domains 26,40 , as far as the authors' knowledge on supervised learning goes, probabilistic regression tools have not yet been considered for corrosion research.All in all, hybrid models and holistic modelling approaches transcending time, length and mechanism scales point towards fruitful directions.</p>
<p>Unlike supervised and unsupervised learning, Reinforcement Learning (RL) can consider the trade-off between exploration and exploitation.RL is one of the most promising computational ML approaches by interacting with an unknown environment while explicitly focusing on goal-oriented learning 40 .</p>
<p>CONCLUSIONS</p>
<p>This data-driven review work depicts the current status of the emerging research on predictive machine learning applied to corrosion.</p>
<p>A bibliometric data mining approach led to creating a Machine learning for corrosion database, covering 34 works where relative metrics did the performance evaluation.Exploratory data analysis demonstrated the positive effects of increasing data dimension and including time as an input on the models performance.A comparative performance analysis was conducted, segmenting the references by corrosion topic, orientation strategy, type of ML model and data targets.In particular, expanding the types of variables (orientation strategies comprising data from multiple relevant sources) likely increases the models performance.The plots bridging the multi-dimensional data to the references serve as a roadmap for future regression modelling of corrosion.More studies focusing on the prediction of localised corrosion and inhibition efficiency should be considered in the future.</p>
<p>Accurate and reliable modelling requires large sets of training (and validation) data of high quality.Moreover, the process of labelling corrosion features should be based on the experience and intuition of domain researchers.Despite the challenge of establishing direct comparative analysis on the performances, this reviewing exercise allowed identifying research gaps and evaluating common practices in the field.For more systematic incorporation of ML within the corrosion community, concerted international efforts are needed to promote data sharing practices.Domain experts would benefit far more from the literature if the modelling datasets were made available alongside the related publications.</p>
<p>Fig. 1
1
Fig. 1 Visualization of the co-citation network of 'machine learning' and 'corrosion' publications.Citation relations from 2017 to 2020 (VOSviewer 41 ).</p>
<p>Fig. 6
6
Fig.6Performance of the ML models expressed by the MAPE (refs.3,5,[9][10][11]13,18 ), semented by 'Corrosion topic' and by 'Type of ML model'.MAPE values are distinguished for training ('O') and testing ('X') performances.The models' names were included right next to the respective 'X' points (other useful descriptors were also included whenever possible).Part of the results for the Ensemble models is magnified in the inset image (green borders).</p>
<p>Table 1 .
1
[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19]onmental variables) from the referenced papers[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19].
SpatialStation(Jiangjin, Wuhan)TemporaltttIncubation period,duration, durationof exposure, log(duration ofexposure)Aging time,exposure timetExposure timeSystemPS, PCO 2 , BSW,BOPD,BWPD, MMCFDElevation,inclination,concavity, conc./incl., dist_failure,flow regime,hold-up,ElectrochemicalElectrical quantity(Q ACM )CRs (1st, 2nd, 4th,8th year)Potential, dECorrosion type (generalor localized)Oxidation-reductionpotentialCR from deterministicmodels (de Waard,NORSOK)Atomic(physical)/chemicalV, λ, EN p , ΔH f b s , EN Κ, R m , R c ,Metallurgical/structuralSteel grade (A3,3C, 20, 08Al)Alloy 22treatment(welded orannealed)CompositionContent (LAS): Cr, C,Si, P, STotal content ofalloyingelements (LAS)Content (LAS): Mn, S, P,Si, Cr, Cu, NiContents: B, C, Cr, Cu,Fe, Mn, Mo, Ni, P, S, Si,Ti, V (carbon and alloysteel); Mo (x), Ni (14−x), (x + 1) (metallicglasses)Content (LAS): Mn, S, P,Si, Cr, Cu, Ni, FeClimateO2_max, S_max,pH_min, T_meanT_MAX, T_AVE,RH_MIN, PRECIPIT,SOLAR, Cl − , SO 2RH_mean, T_mean,Rainfall, SO 2 , pH of rain, Cl −T, RH, rainfallRH_mean, T_mean,Rainfall, SO 2 , pH of rain, Cl −SO 2 , Cl − ,temperature, TOW(time of wetness)Ref. Electrolytic1 a23456 HCl, H 2 SO 47 pH, Cl − , temperature8 Dissolved oxygen,salinity, pH,temperature910 pH, SO 4 , Cl, Fe,HCO 3 , Ca,temperature11TT (Cl − 12 Clconcentration),chloride binding, pH,DO (dissolvedoxygenconcentration)13</p>
<p>Table 1 continued
1SpatialTemporalExposureperiod (EXP)Systempressure, gasflow, total flow,liquid velocity,gas velocityElectrochemicalElectrochemicalpotentialCorrosion potentialElectrochemicalcorrosion potential -ECP (0.5 ppm, 1 ppm,5 ppm, 8 ppm [O2]),passivity breakdownpotential -EbAtomic(physical)/chemicalMoleculardescriptors cMetallurgical/structuralConcrete mixturedesignproportions:cement (CE),limestonepowder (LSP),coarse aggregate(CA), fineaggregate (FA),water (WA)Degree ofsensitization -DoS, stress-intensity factorKI (304 SS)AA alloy grade(2024, 7075)Water/cementratio, porosityCompositionSiO 2 , Al 2 O 2 O 3 , 3 , Fe2 O, 2 O, K CaO, MgO, NaSO 3 (cement)Ref. Electrolytic Climate1415 pH, conductivity, temperature16 pH17 pH, Total Acidity, TA/pH18 Total Cl − (Cl TT), Cl −binding, DO, salinity,pH, temperature19 pH, temperatureThese descriptors were extracted from the
'Selected features' attribute in the ML for corrosion database (Supplementary information).a Reference 1 also deals with 9 principal data components (variable with no physical meaning).b EN s = Sanderson electronegativity; K = Bulk modulus; R m = molecular single bond covalent radius; R c = covalent radius; V = molar volume; λ = thermal conductivity; EN p = Pauling electronegativity; ΔH f = enthalpy of fusion.c 1515 molecular descriptors were generated by DRAGON programme.Sparse feature selection (BioModeller) was applied to obtain the most relevant descriptors (number varied between 11 and 31).L.B. Coelho et al.</p>
<p>npj Materials Degradation (2022) 8Published in partnership with CSCP and USTB 1234567890():,;
Published in partnership with CSCP and USTB npj Materials Degradation (2022) 8
npj Materials Degradation (2022) 8Published in partnership with CSCP and USTB
ACKNOWLEDGEMENTSThe author L.B. Coelho is a Postdoctoral Researcher of the Fonds de la Recherche Scientifique -FNRS which is gratefully acknowledged.DATA AVAILABILITYThe processed data required to reproduce these findings are available to download Bertolucci Coelho, Leonardo (2021), 'Machine learning for corrosion database', Mendeley Data, V1, https://doi.org/10.17632/jfn8yhrphd.143, permanently stored at the repository via the link https://data.mendeley.com/datasets/jfn8yhrphd/1.CODE AVAILABILITYThe code required to reproduce these findings is available to download from GitHub: https://github.com/bcoelho-leonardo/Machine-learning-for-corrosion/blob/77c05253447d4bca737a126f678391e0f98108df/Machine%20learning%20for% 20corrosion%20database_codes.ipynb.AUTHOR CONTRIBUTIONSCOMPETING INTERESTSThe authors declare no competing interests.ADDITIONAL INFORMATION Supplementary informationThe online version contains supplementary material available at https://doi.org/10.1038/s41529-022-00218-4.Correspondence and requests for materials should be addressed to Leonardo Bertolucci Coelho.Reprints and permission information is available at http://www.nature.com/reprints Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Improvement of the machine learning-based corrosion rate prediction model through the optimization of input features. Y Diao, L Yan, K Gao, Mater. Des. 1981093262021</p>
<p>Corrosion rate prediction and influencing factors evaluation of low-alloy steels in marine atmosphere using machine learning approach. L Yan, Y Diao, Z Lang, K Gao, Sci. Technol. Adv. Mater. 212020</p>
<p>Prediction and knowledge mining of outdoor atmospheric corrosion rates of low alloy steels based on the random forests approach. Y Zhi, D Fu, D Zhang, T Yang, X Li, Metals. 93832019</p>
<p>Towards understanding and prediction of atmospheric corrosion of an Fe/Cu corrosion sensor via machine learning. Z Pei, Corros. Sci. 1701086972020</p>
<p>Long-term prediction on atmospheric corrosion data series of carbon steel in China based on NGBM(1,1) model and genetic algorithm. Y Zhi, Anti-Corros. Method M. 662017</p>
<p>Prediction of corrosion behavior using neural network as a data mining tool. M Kamrunnahar, M Urquidi-Macdonald, Corros. Sci. 522010</p>
<p>Prediction of corrosion behaviour of Alloy 22 using neural network as a data mining tool. M Kamrunnahar, M Urquidi-Macdonald, Corros. Sci. 532011</p>
<p>Corrosion rate prediction of 3C steel under different seawater environment by using support vector regression. Y F Wen, Corros. Sci. 512009</p>
<p>An improved deep forest model for forecast the outdoor atmospheric corrosion rate of low-alloy steels. Y Zhi, T Yang, D Fu, J. Mater. Sci. Technol. 492020</p>
<p>A data-driven machine learning approach for corrosion risk assessment -a comparative study. C I Ossai, Big Data Cogn. Comput. 3282019</p>
<p>Phenomenological modelling of atmospheric corrosion using an artificial neural network. J Cai, R A Cottis, S B Lyon, Corros. Sci. 412001-2030 (1999</p>
<p>A phenomenological model for the chloride threshold of pitting corrosion of steel in simulated concrete pore solutions. X Shi, T Anh Nguyen, P Kumar, Y Liu, Anti-Corros. Method M. 582011</p>
<p>Machine learning approach to corrosion assessment in subsea pipelines. G De Masi, M Gentile, R Vichi, R Bruschi, G Gabetta, 10.1109/OCEANS-Genova.2015.7271592OCEANS 2015 -Genova 1-6. IEEE2015</p>
<p>Ensemble machine learning model for corrosion initiation time estimation of embedded steel reinforced self-compacting concrete. B A Salami, S M Rahman, T A Oyehan, M Maslehuddin, S U Al Dulaijan, Measurement. 1651081412020</p>
<p>Prediction of crack growth rate in Type 304 stainless steel using artificial neural networks and the coupled environment fracture model. J Shi, J Wang, D D Macdonald, Corros. Sci. 892014</p>
<p>Using high throughput experimental data and in silico models to discover alternatives to toxic chromate corrosion inhibitors. D A Winkler, Corros. Sci. 1062016</p>
<p>Ratio of total acidity to pH value of coating bath: a new strategy towards phosphate conversion coatings with optimized corrosion resistance for magnesium alloys. Z Chunyan, Corros. Sci. 1502019</p>
<p>The use of artificial intelligence combiners for modeling steel pitting risk and corrosion rate. J Chou, N Ngo, W K Chong, Eng. Appl. Artif. Intell. 652017</p>
<p>Corrosion of rebar in concrete. Part III: Artificial Neural Network analysis of chloride threshold data. Y Zhu, D D Macdonald, J Qiu, M Urquidi-Macdonald, Corros. Sci. 1851094382021</p>
<p>. Materials Genome Initiative. 2021</p>
<p>Machine learning assisted materials design and discovery for rechargeable batteries. Y Liu, B Guo, X Zou, Y Li, S Shi, Energy Storage Mater. 312020</p>
<p>Future frontiers in corrosion science and engineering, part III: the next "Leap Ahead" in corrosion control may be enabled by data analytics and artificial intelligence. J R Scully, P V Balachandran, Corrosion. 752019</p>
<p>A survey of artificial intelligence techniques applied in energy storage materials R&amp;D. Z Luo, Front. Energy Res. 82020</p>
<p>Machine learning: accelerating materials development for energy storage and conversion. A Chen, X Zhang, Z Zhou, 20202</p>
<p>Machine learning for continuous innovation in battery technologies. M Aykol, P Herring, A Anapolsky, Nat. Rev. Mater. 52020</p>
<p>Machine learning toward advanced energy storage devices and systems. T Gao, W Lu, 202124</p>
<p>Predicting the state of charge and health of batteries using data-driven machine learning. M.-F Ng, J Zhao, Q Yan, G J Conduit, Z W Seh, Nat. Mach. Intell. 22020</p>
<p>Data mining to effect of key alloying elements on corrosion resistance of low alloy steels in Sanya seawater environmentAlloying Elements. X Wei, 10.1016/j.jmst.2020.01.040J. Mater. Sci. Technol. 2020</p>
<p>Lithium-ion battery modeling based on Big Data. S Li, J Li, H He, H Wang, Energy Procedia. 1592019</p>
<p>Modelling and understanding battery materials with machinelearning-driven atomistic simulations. V L Deringer, J. Phys. Energy. 2410032020</p>
<p>Fighting Knowledge Acquisition Bottleneck With Argument Based Machine Learning. M Mozina, M Guid, J Krivec, A Sadikov, I Bratko, 10.3233/978-1-58603-891-5-2342008</p>
<p>Atmospheric corrosion prediction: a review. Y Cai, Y Xu, Y Zhao, X Ma, Corros. Rev. 382020</p>
<p>Extrapolating short-term corrosion test results to field exposures in different environments. Y Cai, Y Xu, Y Zhao, X Ma, Corros. Sci. 1861094552021</p>
<p>The prediction of atmospheric corrosion from meteorological and pollution parameters-I. Annual corrosion. S Feliu, M Morcillo, S Feliu, Corros. Sci. 341993</p>
<p>V Chan, 10.31274/rtd-180813-12114Degradation-based reliability in outdoor environments. 2001Iowa State University</p>
<p>The classification system of ISO 9223 standard and the dose-response functions assessing the corrosivity of outdoor atmospheres. A A Mikhailov, J Tidblad, V Kucera, Prot. Met. 402004</p>
<p>Effect of environmental conditions on corrosion rates. D E Klinesmith, R H Mccuen, P Albrecht, J. Mater. Civ. Eng. 192007</p>
<p>Compensation effect in thermal aging investigated according to Eyring and Arrhenius models. P K David, G C Montanari, Eur. Trans. Electr. Power. 22007</p>
<p>A review of deep learning in the study of materials degradation. W Nash, T Drummond, N Birbilis, npj Mater. Degrad. 2372018</p>
<p>Artificial intelligence and machine learning approaches to energy demand-side response: a systematic review. I Antonopoulos, Renew. Sustain. Energy Rev. 1301098992020</p>
<p>Software survey: VOSviewer, a computer program for bibliometric mapping. N J Van Eck, L Waltman, Scientometrics. 842010</p>
<p>Bibliometric analysis of microbiologically influenced corrosion (MIC) of oil and gas engineering systems. S J Hashemi, Corrosion. 742018</p>
<p>Machine learning for corrosion database. L Bertolucci Coelho, 10.17632/jfn8yhrphd.1Mendeley Data. 2021</p>
<p>China Gateway to Corrosion and Protection. 2021</p>
<p>A genetic algorithm based nonlinear grey Bernoulli model for output forecasting in integrated circuit industry. L.-C Hsu, Expert Syst. Appl. 372010</p>
<p>Groundwater inflow prediction model of karst collapse pillar: a case study for mining-induced groundwater inrush risk. D Ma, H Bai, Nat. Hazards. 762015</p>
<p>Metallic glass-based materials in wearable energy storage devices. L Donaldson, Mater. Today. 3632020</p>
<p>Algorithms for Multimodal Optimization. X.-S Yang, Firefly, 10.1007/978-3-642-04944-6_142009</p>
<p>Smart artificial firefly colony algorithm-based support vector regression for enhanced forecasting in civil engineering. J.-S Chou, A.-D Pham, Comput. Civ. Infrastruct. Eng. 302015</p>
<p>Corrosion of rebar in concrete. Part II: Literature survey and statistical analysis of existing data on chloride threshold. Y Zhu, D D Macdonald, J Yang, J Qiu, G R Engelhardt, Corros. Sci. 1851094392021</p>
<p>Elucidating structure-property relationships in aluminum alloy corrosion inhibitors by machine learning. T L P Galvão, G Novell-Leruth, A Kuznetsova, J Tedim, J R B Gomes, J. Phys. Chem. C. 1242020</p>
<p>Closed-loop optimization of fast-charging protocols for batteries with machine learning. P M Attia, Nature. 5782020</p>
<p>Predicting the parabolic rate constants of high-temperature oxidation of Ti alloys using learning. S K Bhattacharya, R Sahara, T Narushima, Oxid. Met. 942020</p>
<p>Machine learning applied to electrified vehicle battery state of charge and state of health estimation: state-of-theart. C Vidal, P Malysz, P Kollmeyer, A Emadi, IEEE Access. 82020</p>
<p>Studying the explanatory capacity of artificial neural networks for understanding environmental chemical quantitative structure−activity relationship models. L Yang, P Wang, Y Jiang, J Chen, J. Chem. Inf. Model. 452005</p>
<p>Materials synthesis insights from scientific literature via text extraction and machine learning. E Kim, Chem. Mater. 292017</p>
<p>Materials science: share corrosion data. X Li, Nature. 5272015</p>
<p>An infrastructure with user-centered presentation data model for integrated management of materials data and services. S Liu, Comput. Mater. 72021</p>
<p>Machine learning for molecular and materials science. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, Nature. 5592018</p>
<p>Deep neural networks compression learning based on multiobjective evolutionary algorithms. J Huang, W Sun, L Huang, Neurocomputing. 3782020</p>            </div>
        </div>

    </div>
</body>
</html>