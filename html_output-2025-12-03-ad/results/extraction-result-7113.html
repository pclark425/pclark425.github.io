<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7113 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7113</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7113</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-e318c18e6f3faa5c514e6b85270b2211603fc419</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e318c18e6f3faa5c514e6b85270b2211603fc419" target="_blank">Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> The results show that most"state-of-the-art" molecular design algorithms fail to outperform their predecessors under a limited oracle budget allowing 10K queries and that no existing algorithm can efficiently solve certain molecular optimization problems in this setting.</p>
                <p><strong>Paper Abstract:</strong> Molecular optimization is a fundamental goal in the chemical sciences and is of central interest to drug and material design. In recent years, significant progress has been made in solving challenging problems across various aspects of computational molecular optimizations, emphasizing high validity, diversity, and, most recently, synthesizability. Despite this progress, many papers report results on trivial or self-designed tasks, bringing additional challenges to directly assessing the performance of new methods. Moreover, the sample efficiency of the optimization--the number of molecules evaluated by the oracle--is rarely discussed, despite being an essential consideration for realistic discovery applications. To fill this gap, we have created an open-source benchmark for practical molecular optimization, PMO, to facilitate the transparent and reproducible evaluation of algorithmic advances in molecular optimization. This paper thoroughly investigates the performance of 25 molecular design algorithms on 23 tasks with a particular focus on sample efficiency. Our results show that most"state-of-the-art"methods fail to outperform their predecessors under a limited oracle budget allowing 10K queries and that no existing algorithm can efficiently solve certain molecular optimization problems in this setting. We analyze the influence of the optimization algorithm choices, molecular assembly strategies, and oracle landscapes on the optimization performance to inform future algorithm development and benchmarking. PMO provides a standardized experimental setup to comprehensively evaluate and compare new molecule optimization methods with existing ones. All code can be found at https://github.com/wenhao-gao/mol_opt.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7113.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7113.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LM-seq (RNN/LSTM) methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sequence-based language models (RNN / LSTM) used for molecule generation (grouping REINVENT, SMILES-LSTM-HC, SELFIES-LSTM-HC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sequence-based neural language models (RNNs / LSTMs) are used to model molecular string distributions (SMILES or SELFIES), pretrain on a molecule corpus and then fine-tune or optimize via policy RL or hill-climbing to generate candidate molecules scored by oracles.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RNN/LSTM (as used in REINVENT, SMILES-LSTM-HC, SELFIES-LSTM-HC)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>sequence model; policy-based reinforcement learning (REINVENT) or fine-tuned LSTM (hill-climbing HC)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained on ZINC 250K when a database was required (PMO restricts pretraining / generative models to ZINC 250K); otherwise 'not reported' for individual model parameterization.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct sequence generation of molecular strings (SMILES or SELFIES) by sampling an RNN/LSTM; REINVENT uses policy-based RL to tune the RNN with property-based rewards; HC (hill-climbing) iteratively fine-tunes the LSTM by incorporating high‑scoring generated molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES or SELFIES (paper evaluates both SMILES and SELFIES variants head-to-head for sequence models)</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>De novo molecular optimization for drug-relevant properties: similarity-based MPOs, bioactivity prediction tasks (DRD2, GSK3β, JNK3), QED and other GuacaMol-style objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle-based reward; global experiment-level constraints: oracle-budget limit (10,000 oracle calls) and pretraining restricted to ZINC 250K; no additional universal synthetic-accessibility filter applied to these sequence methods in PMO unless the method is a synthesis-based variant.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses PMO oracles from Therapeutics Data Commons (TDC) as reward/evaluation; can be combined with surrogate predictors in model-based screening variants (MolPAL) but standard REINVENT runs treat oracles as black-box reward functions.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K (pretraining and database access restricted to this dataset in PMO for comparability).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Primary: AUC Top-10 (area under curve of top-10 average property vs number of oracle calls, limited to 10k calls). Secondary metrics reported in PMO: Top-1/Top-10/Top-100 averages, mean and standard deviation across 5 independent runs, and sum/rank across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Sequence-model family performed strongly: REINVENT (SMILES) ranked #1 by mean AUC Top-10 with summed mean = 14.196 across 23 oracles. Example per-task REINVENT AUC Top-10: drd2 0.945 ± 0.007, qed 0.941 ± 0.000, osimertinib_mpo 0.837 ± 0.009. SMILES-LSTM-HC (hill-climbing) ranked #6 overall (sum = 12.223) but required more oracle queries than REINVENT to reach similar performance. SELFIES-LSTM-HC and SELFIES-REINVENT are reported as SELFIES variants with slightly different task-level performance; REINVENT (SELFIES) listed with per-task values and overall rank #3 (sum = 13.471). (All AUC values are min-max scaled to [0,1] in PMO; reported means ± std over 5 runs.)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Sensitivity to hyperparameters (e.g., REINVENT's σ strongly affects performance and required re-tuning); sample-efficiency limitations on many tasks (many methods, including sequence models, cannot solve some objectives within hundreds of oracle calls); non-determinism / high run-to-run variance requiring multiple runs; no experimental (wet-lab) synthesis/assays of generated molecules reported in PMO; synthesizability and diversity not deeply evaluated for sequence-only methods in this benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7113.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>REINVENT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>REINVENT: Molecular de-novo design through deep reinforcement learning (RNN policy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A policy-based reinforcement learning approach that fine-tunes an RNN generative model to maximize molecular property rewards (originally trained to generate SMILES). In PMO, both SMILES- and SELFIES-based variants of REINVENT were benchmarked.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Molecular de-novo design through deep reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>REINVENT (RNN policy network)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>policy-based reinforcement learning tuning an RNN (sequence model); implemented as fine-tuning/guiding an RNN generator</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretraining/fine-tuning using molecules from ZINC 250K in PMO experimental setup (generative models pretrained on this dataset when required).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Generate SMILES (or SELFIES variant) sequences by sampling from the RNN policy; policy gradient updates the RNN parameters using oracle-derived rewards.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES (primary) and SELFIES (variant evaluated in PMO).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>De novo molecular optimization for drug-like properties, similarity-based MPOs and bioactivity prediction tasks (e.g., DRD2, GSK3β, JNK3), rediscovery and MPO tasks in GuacaMol/TDC.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle-driven reward shaping; PMO-wide constraint: total oracle budget limited to 10,000 calls; pretraining restricted to ZINC 250K.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses oracles from Therapeutics Data Commons (TDC) for reward signals; not integrated with docking or retrosynthesis in PMO runs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K (pretraining / reference database in PMO).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 (primary), Top-1/Top-10/Top-100 averages; reported mean and standard deviation over 5 independent runs.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Ranked #1 overall in PMO by mean AUC Top-10 (sum = 14.196 across 23 oracles). Representative per-task AUC Top-10 values: drd2 0.945 ± 0.007, qed 0.941 ± 0.000, osimertinib_mpo 0.837 ± 0.009, albuterol_similarity 0.882 ± 0.006. Performance sensitive to hyperparameter σ; best σ found in PMO larger than original paper's suggestion.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>High sensitivity to hyperparameters (σ); need for hyperparameter re-optimization when oracle budget is limited; does not guarantee synthesizability; performance can vary run-to-run (non-determinism).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7113.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SMILES-LSTM-HC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SMILES LSTM with hill-climbing (SMILES-LSTM-HC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LSTM sequence model trained on SMILES and optimized via a hill-climbing / cross-entropy-like procedure that iteratively fine-tunes the model using top-scoring generated molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GuacaMol: benchmarking models for de novo molecular design</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SMILES-LSTM-HC</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>sequence model (LSTM) with hill-climbing (iterative fine-tuning / cross-entropy method)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained on ZINC 250K in PMO experimental setup.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Generate SMILES sequences from LSTM; at each iteration incorporate top-scoring molecules into training data and fine-tune the LSTM (hill-climbing / cross-entropy variant).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>General-purpose molecular optimization tasks in PMO (GuacaMol-style MPOs, activity prediction tasks, QED).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle-based selection; PMO oracle budget limit (10,000 calls); no additional synthesizability constraints applied in PMO runs.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses TDC oracles for scoring; not explicitly combined with external docking or retrosynthesis tools in PMO.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 (primary), Top-K metrics and run-level statistics across 5 runs.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Ranked #6 overall by mean AUC Top-10 with summed mean = 12.223. Per-task examples: deco_hop 0.826 ± 0.017, drd2 0.919 ± 0.015, qed 0.939 ± 0.000. Requires more oracle queries than REINVENT to reach similar performance on several tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Less sample-efficient than REINVENT (needs more oracle calls); performance depends on hill-climbing schedule and selection thresholds; suffers from potential mode collapse / reduced diversity if overly exploitative.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7113.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SELFIES-REINVENT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>REINVENT variant using SELFIES instead of SMILES</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of REINVENT where the sequence representation is SELFIES rather than SMILES; evaluated to compare representation impact on optimization/sample efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Molecular de-novo design through deep reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SELFIES-REINVENT (RNN policy network with SELFIES tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>policy-based reinforcement learning over SELFIES sequences (RNN policy)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretraining / fine-tuning on ZINC 250K (SELFIES tokenization) as per PMO setup.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Generate SELFIES token sequences via RNN policy; policy gradients applied using oracle rewards.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SELFIES</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Same suite of PMO molecular optimization objectives: similarity MPOs, activity prediction oracles, QED, rediscovery, isomer tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle rewards and PMO experimental constraints (10,000 oracle calls, ZINC 250K pretraining); SELFIES aims to eliminate syntactic invalidity but PMO finds no systematic improvement in optimization/sample efficiency compared to SMILES in many tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses TDC oracles; no additional external tool integration reported for REINVENT-SELFIES in PMO.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K (SELFIES tokenization)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 primarily, Top-K metrics and run statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Ranked #3 overall by mean AUC Top-10 (sum = 13.471). Per-task example values: drd2 0.943 ± 0.005, qed 0.940 ± 0.000, albuterol_similarity 0.826 ± 0.030. PMO notes SELFIES variants did not consistently outperform SMILES variants for language-model-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Although SELFIES guarantees syntactic validity, PMO observed no consistent optimization advantage and sometimes lower sample efficiency versus SMILES variants; SELFIES tokenization can map many token combinations to a small set of molecules when truncated, limiting effective exploration if not carefully handled.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7113.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SMILES-VAE / SELFIES-VAE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Autoencoders for molecular generation (SMILES-VAE and SELFIES-VAE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Encoder-decoder VAEs learn continuous latent representations of molecules (from SMILES or SELFIES) enabling latent-space optimization and sampling; PMO evaluates vanilla VAE variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automatic chemical design using a data-driven continuous representation of molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SMILES-VAE and SELFIES-VAE</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>encoder-decoder variational autoencoder; latent-space molecular generator (BO in latent space sometimes used in prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained / pretrained on ZINC 250K in PMO; latent-space optimization variants in literature often use datasets like ZINC or MOSES, but PMO restricts to ZINC 250K.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Encode molecules to latent vectors and decode to SMILES/SELFIES; optimization performed by searching latent space (BO commonly used historically) or sampling from the learned distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES and SELFIES variants evaluated in PMO.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>De novo molecular generation for PMO objectives (similarity MPOs, activity predictors); used as baseline generative method class.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle-driven selection and PMO experiment-level constraints (10k oracle calls, ZINC 250K pretraining); no explicit synthesizability filtering for vanilla VAE in PMO.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses TDC oracles for evaluation; sometimes prior works combine latent BO with acquisition function optimizers but PMO included vanilla implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K (pretraining and fragment extraction when needed).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 primarily; VAEs ranked lower in PMO (SELFIES-VAE rank ~16–18 depending on metric).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>SELFIES-VAE and SMILES-VAE had overall lower summed mean AUC Top-10 (e.g., SMILES-VAE sum ~8.887–? depending on configuration; exact sums: SMILES-VAE listed among lower-ranked methods: rank ~18–19). Representative per-task values are provided in PMO tables (e.g., qed ~0.936–0.940 depending on variant).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>VAEs may struggle with validity or mapping smoothness; PMO reports older SMILES VAE versions had validity issues but later methods improved; VAEs in PMO were generally less sample-efficient under the 10k oracle budget and ranked lower than top sequence-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7113.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STONED</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>STONED: Superfast traversal, optimization, novelty, exploration and discovery algorithm using SELFIES</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A manipulation algorithm that directly alters SELFIES tokens to rapidly traverse chemical space (token-level edits) without training an explicit generative model; included in PMO as a SELFIES-based GA-like method.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>STONED (SELFIES token manipulator)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>nonparametric token-level manipulation algorithm (no large pretrained LM required)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not applicable (algorithmic manipulations rather than parametric LM)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>No training required; uses SELFIES token operations and optionally a corpus for initial seeds (PMO uses ZINC 250K as database when needed).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct SELFIES token modifications (mutations) to produce new molecules; rapid exploration via token edits.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SELFIES</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Molecular optimization tasks in PMO; particularly compared for isomer-type and similarity-based oracles.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Operates under PMO oracle budget (10k calls); SELFIES ensures syntactic validity by design.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses PMO oracles (TDC) for scoring; not integrated with retrosynthesis/docking in PMO runs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K used as seed/library in PMO experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10, Top-K averages; PMO reports STONED performed well in some isomer tasks and had varied rankings overall (ranked #5 among top-10 shown in Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>In Table 2 STONED (SELFIES) has per-task numbers like fexofenadine_mpo 0.797 ± 0.016, isomers_c7h8n2o2 0.899 ± 0.011, isomers_c9h10n2o2pf2cl 0.805 ± 0.031; overall sum for top methods shows STONED sum = 13.024 and rank #5 among top-10 shown.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Although syntax-valid by design, SELFIES token manipulations can map many token combinations to a small set of molecules when truncated; exploration can be constrained if token operations are not well designed; PMO notes that SELFIES advantages are not universal across model classes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7113.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GA+D</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Algorithm augmented with Deep neural networks (GA+D)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A SELFIES-based genetic algorithm enhanced by deep neural networks to guide mutation/crossover decisions; included in PMO as a hybrid between classical GA and learned models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting genetic algorithms with deep neural networks for exploring the chemical space</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GA+D (SELFIES based GA augmented by deep NN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>hybrid evolutionary algorithm with learned components (deep NN to guide GA operators)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>When used in PMO, GA+D is applied within the ZINC 250K-constrained setup; training details of the deep component not reported in PMO beyond citation to original work.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Genetic algorithm operations (mutation and/or crossover) on SELFIES sequences; a deep neural network component directs or ranks candidates to improve search efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SELFIES (SELFIES-based GA variant)</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>De novo molecular design objectives in PMO (similarity MPOs, isomer tasks, activity prediction tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle-based selection and PMO-wide constraints (10k oracle calls); being SELFIES-based, syntactic validity is enforced.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses PMO oracles (TDC) for evaluation; no explicit use of docking or retrosynthesis in PMO benchmarking.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 and Top-K metrics over 5 runs.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>GA+D appears in PMO results with mixed performance; overall rank around mid-field (GA+D rank ~23 in Table 3 when considering multiple metrics). Per-task values show high variance for some tasks; exact per-task numbers provided in PMO appendices.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Performance highly dependent on mutation/crossover rule design and on quality/effectiveness of the learned guidance network; GA-style exploration can be sample-inefficient and produce undesired candidates (unstable or unsynthesizable) that waste oracle budget.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7113.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pasithea</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pasithea: Deep molecular dreaming (gradient-based modification via learned surrogate)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A gradient-based method that trains a predictive MLP surrogate on SELFIES strings and backpropagates through the surrogate to propose token edits (i.e., uses surrogate gradients to propose molecules).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep molecular dreaming: Inverse machine learning for de-novo molecular design and interpretability with surjective representations.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pasithea (MLP surrogate with gradient-based token editing on SELFIES)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>gradient-ascent on surrogate predictions; surrogate is an MLP operating on SELFIES representations</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Surrogate model trained online as data are acquired during PMO optimization; initial data and pretraining sourced from ZINC 250K if required.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Estimate gradients of property via surrogate MLP then backpropagate to modify SELFIES tokens (gradient-based generation instead of sampling from a generative LM).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SELFIES</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Same PMO objective suite (MPOs, bioactivity predictors); used as a representative gradient-based approach.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Oracle-driven selection; PMO budget constraint of 10k oracle calls; no explicit synthesizability filters in Pasithea runs reported.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses PMO oracles (TDC) for evaluation; surrogate trained/updated online using the observed oracle outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K (for pretraining/initialization when applicable); online dataset collected during optimization counted toward oracle budget.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 primarily; Pasithea ranked ~19 in PMO across tasks by sum of AUC Top-10 values.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Pasithea's summed performance ranks lower (sum ~? listed in PMO tables as lower-tier; per-task examples: qed ~0.931 ± 0.002, some tasks like drd2 low ~0.255 ± 0.040) — full per-task numbers are in PMO appendices.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Surrogate accuracy limits optimization; gradient-based editing on discrete token spaces requires careful mapping/backpropagation strategies; PMO observed mixed performance and sensitivity to surrogate quality and online training schedule.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7113.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e7113.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Language-model representation comparison (SMILES vs SELFIES)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Comparison of SMILES and SELFIES string representations when used with language-model-like generators</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PMO compares SMILES and SELFIES variants of many sequence and string-based algorithms and finds no universal advantage for SELFIES across language-model-based methods; SELFIES shows benefit in some GA manipulation contexts but not consistently for pretrained sequence LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>representation comparison (SMILES vs SELFIES) applied to RNN/LSTM, GA, and other sequence-based methods</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>head-to-head representation study across multiple generative algorithm classes (sequence models, GAs, HC, RL)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not applicable</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Both representations tokenized from ZINC 250K for models that required pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Same generation algorithms run with either SMILES or SELFIES tokenization to assess representation effects (e.g., REINVENT SMILES vs REINVENT SELFIES, SMILES-LSTM-HC vs SELFIES-LSTM-HC).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES and SELFIES compared directly.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>All PMO objectives (similarity MPOs, isomer tasks, drug-target activity predictors).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>PMO experimental constraints (10k oracle calls, ZINC 250K pretraining).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses PMO oracles from TDC for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ZINC 250K for all pretraining / tokenization.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>AUC Top-10 per task and parity plots comparing SMILES vs SELFIES AUC Top-10 values across tasks (fraction of tasks where SELFIES outperforms SMILES reported).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>PMO finds SELFIES does not systematically improve optimization performance for language-model-based methods; fractions of tasks where SELFIES outperforms SMILES vary by method (plots in Figure 2a). SELFIES-based GA outperformed SMILES-based GA in PMO, but for sequence LMs SMILES variants often matched or outperformed SELFIES.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>SELFIES removes syntactic invalidity but does not guarantee better exploration or sample efficiency; SELFIES token combinatorics can map to a small number of molecules leading to exploration inefficiencies if token design/truncation is not handled carefully.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Molecular de-novo design through deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Automatic chemical design using a data-driven continuous representation of molecules. <em>(Rating: 2)</em></li>
                <li>GuacaMol: benchmarking models for de novo molecular design <em>(Rating: 2)</em></li>
                <li>Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation <em>(Rating: 2)</em></li>
                <li>Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES <em>(Rating: 2)</em></li>
                <li>Augmenting genetic algorithms with deep neural networks for exploring the chemical space <em>(Rating: 2)</em></li>
                <li>Deep molecular dreaming: Inverse machine learning for de-novo molecular design and interpretability with surjective representations. <em>(Rating: 2)</em></li>
                <li>Optimizing distributions over molecular space. an objective-reinforced generative adversarial network for inverse-design chemistry (ORGANIC). <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7113",
    "paper_id": "paper-e318c18e6f3faa5c514e6b85270b2211603fc419",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "LM-seq (RNN/LSTM) methods",
            "name_full": "Sequence-based language models (RNN / LSTM) used for molecule generation (grouping REINVENT, SMILES-LSTM-HC, SELFIES-LSTM-HC)",
            "brief_description": "Sequence-based neural language models (RNNs / LSTMs) are used to model molecular string distributions (SMILES or SELFIES), pretrain on a molecule corpus and then fine-tune or optimize via policy RL or hill-climbing to generate candidate molecules scored by oracles.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RNN/LSTM (as used in REINVENT, SMILES-LSTM-HC, SELFIES-LSTM-HC)",
            "model_type": "sequence model; policy-based reinforcement learning (REINVENT) or fine-tuned LSTM (hill-climbing HC)",
            "model_size": "not reported",
            "training_data_description": "Pretrained on ZINC 250K when a database was required (PMO restricts pretraining / generative models to ZINC 250K); otherwise 'not reported' for individual model parameterization.",
            "generation_method": "Direct sequence generation of molecular strings (SMILES or SELFIES) by sampling an RNN/LSTM; REINVENT uses policy-based RL to tune the RNN with property-based rewards; HC (hill-climbing) iteratively fine-tunes the LSTM by incorporating high‑scoring generated molecules.",
            "chemical_representation": "SMILES or SELFIES (paper evaluates both SMILES and SELFIES variants head-to-head for sequence models)",
            "target_application": "De novo molecular optimization for drug-relevant properties: similarity-based MPOs, bioactivity prediction tasks (DRD2, GSK3β, JNK3), QED and other GuacaMol-style objectives.",
            "constraints_used": "Oracle-based reward; global experiment-level constraints: oracle-budget limit (10,000 oracle calls) and pretraining restricted to ZINC 250K; no additional universal synthetic-accessibility filter applied to these sequence methods in PMO unless the method is a synthesis-based variant.",
            "integration_with_external_tools": "Uses PMO oracles from Therapeutics Data Commons (TDC) as reward/evaluation; can be combined with surrogate predictors in model-based screening variants (MolPAL) but standard REINVENT runs treat oracles as black-box reward functions.",
            "dataset_used": "ZINC 250K (pretraining and database access restricted to this dataset in PMO for comparability).",
            "evaluation_metrics": "Primary: AUC Top-10 (area under curve of top-10 average property vs number of oracle calls, limited to 10k calls). Secondary metrics reported in PMO: Top-1/Top-10/Top-100 averages, mean and standard deviation across 5 independent runs, and sum/rank across tasks.",
            "reported_results": "Sequence-model family performed strongly: REINVENT (SMILES) ranked #1 by mean AUC Top-10 with summed mean = 14.196 across 23 oracles. Example per-task REINVENT AUC Top-10: drd2 0.945 ± 0.007, qed 0.941 ± 0.000, osimertinib_mpo 0.837 ± 0.009. SMILES-LSTM-HC (hill-climbing) ranked #6 overall (sum = 12.223) but required more oracle queries than REINVENT to reach similar performance. SELFIES-LSTM-HC and SELFIES-REINVENT are reported as SELFIES variants with slightly different task-level performance; REINVENT (SELFIES) listed with per-task values and overall rank #3 (sum = 13.471). (All AUC values are min-max scaled to [0,1] in PMO; reported means ± std over 5 runs.)",
            "experimental_validation": false,
            "challenges_or_limitations": "Sensitivity to hyperparameters (e.g., REINVENT's σ strongly affects performance and required re-tuning); sample-efficiency limitations on many tasks (many methods, including sequence models, cannot solve some objectives within hundreds of oracle calls); non-determinism / high run-to-run variance requiring multiple runs; no experimental (wet-lab) synthesis/assays of generated molecules reported in PMO; synthesizability and diversity not deeply evaluated for sequence-only methods in this benchmark.",
            "uuid": "e7113.0",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "REINVENT",
            "name_full": "REINVENT: Molecular de-novo design through deep reinforcement learning (RNN policy)",
            "brief_description": "A policy-based reinforcement learning approach that fine-tunes an RNN generative model to maximize molecular property rewards (originally trained to generate SMILES). In PMO, both SMILES- and SELFIES-based variants of REINVENT were benchmarked.",
            "citation_title": "Molecular de-novo design through deep reinforcement learning",
            "mention_or_use": "use",
            "model_name": "REINVENT (RNN policy network)",
            "model_type": "policy-based reinforcement learning tuning an RNN (sequence model); implemented as fine-tuning/guiding an RNN generator",
            "model_size": "not reported",
            "training_data_description": "Pretraining/fine-tuning using molecules from ZINC 250K in PMO experimental setup (generative models pretrained on this dataset when required).",
            "generation_method": "Generate SMILES (or SELFIES variant) sequences by sampling from the RNN policy; policy gradient updates the RNN parameters using oracle-derived rewards.",
            "chemical_representation": "SMILES (primary) and SELFIES (variant evaluated in PMO).",
            "target_application": "De novo molecular optimization for drug-like properties, similarity-based MPOs and bioactivity prediction tasks (e.g., DRD2, GSK3β, JNK3), rediscovery and MPO tasks in GuacaMol/TDC.",
            "constraints_used": "Oracle-driven reward shaping; PMO-wide constraint: total oracle budget limited to 10,000 calls; pretraining restricted to ZINC 250K.",
            "integration_with_external_tools": "Uses oracles from Therapeutics Data Commons (TDC) for reward signals; not integrated with docking or retrosynthesis in PMO runs.",
            "dataset_used": "ZINC 250K (pretraining / reference database in PMO).",
            "evaluation_metrics": "AUC Top-10 (primary), Top-1/Top-10/Top-100 averages; reported mean and standard deviation over 5 independent runs.",
            "reported_results": "Ranked #1 overall in PMO by mean AUC Top-10 (sum = 14.196 across 23 oracles). Representative per-task AUC Top-10 values: drd2 0.945 ± 0.007, qed 0.941 ± 0.000, osimertinib_mpo 0.837 ± 0.009, albuterol_similarity 0.882 ± 0.006. Performance sensitive to hyperparameter σ; best σ found in PMO larger than original paper's suggestion.",
            "experimental_validation": false,
            "challenges_or_limitations": "High sensitivity to hyperparameters (σ); need for hyperparameter re-optimization when oracle budget is limited; does not guarantee synthesizability; performance can vary run-to-run (non-determinism).",
            "uuid": "e7113.1",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "SMILES-LSTM-HC",
            "name_full": "SMILES LSTM with hill-climbing (SMILES-LSTM-HC)",
            "brief_description": "An LSTM sequence model trained on SMILES and optimized via a hill-climbing / cross-entropy-like procedure that iteratively fine-tunes the model using top-scoring generated molecules.",
            "citation_title": "GuacaMol: benchmarking models for de novo molecular design",
            "mention_or_use": "use",
            "model_name": "SMILES-LSTM-HC",
            "model_type": "sequence model (LSTM) with hill-climbing (iterative fine-tuning / cross-entropy method)",
            "model_size": "not reported",
            "training_data_description": "Pretrained on ZINC 250K in PMO experimental setup.",
            "generation_method": "Generate SMILES sequences from LSTM; at each iteration incorporate top-scoring molecules into training data and fine-tune the LSTM (hill-climbing / cross-entropy variant).",
            "chemical_representation": "SMILES",
            "target_application": "General-purpose molecular optimization tasks in PMO (GuacaMol-style MPOs, activity prediction tasks, QED).",
            "constraints_used": "Oracle-based selection; PMO oracle budget limit (10,000 calls); no additional synthesizability constraints applied in PMO runs.",
            "integration_with_external_tools": "Uses TDC oracles for scoring; not explicitly combined with external docking or retrosynthesis tools in PMO.",
            "dataset_used": "ZINC 250K",
            "evaluation_metrics": "AUC Top-10 (primary), Top-K metrics and run-level statistics across 5 runs.",
            "reported_results": "Ranked #6 overall by mean AUC Top-10 with summed mean = 12.223. Per-task examples: deco_hop 0.826 ± 0.017, drd2 0.919 ± 0.015, qed 0.939 ± 0.000. Requires more oracle queries than REINVENT to reach similar performance on several tasks.",
            "experimental_validation": false,
            "challenges_or_limitations": "Less sample-efficient than REINVENT (needs more oracle calls); performance depends on hill-climbing schedule and selection thresholds; suffers from potential mode collapse / reduced diversity if overly exploitative.",
            "uuid": "e7113.2",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "SELFIES-REINVENT",
            "name_full": "REINVENT variant using SELFIES instead of SMILES",
            "brief_description": "A variant of REINVENT where the sequence representation is SELFIES rather than SMILES; evaluated to compare representation impact on optimization/sample efficiency.",
            "citation_title": "Molecular de-novo design through deep reinforcement learning",
            "mention_or_use": "use",
            "model_name": "SELFIES-REINVENT (RNN policy network with SELFIES tokens)",
            "model_type": "policy-based reinforcement learning over SELFIES sequences (RNN policy)",
            "model_size": "not reported",
            "training_data_description": "Pretraining / fine-tuning on ZINC 250K (SELFIES tokenization) as per PMO setup.",
            "generation_method": "Generate SELFIES token sequences via RNN policy; policy gradients applied using oracle rewards.",
            "chemical_representation": "SELFIES",
            "target_application": "Same suite of PMO molecular optimization objectives: similarity MPOs, activity prediction oracles, QED, rediscovery, isomer tasks.",
            "constraints_used": "Oracle rewards and PMO experimental constraints (10,000 oracle calls, ZINC 250K pretraining); SELFIES aims to eliminate syntactic invalidity but PMO finds no systematic improvement in optimization/sample efficiency compared to SMILES in many tasks.",
            "integration_with_external_tools": "Uses TDC oracles; no additional external tool integration reported for REINVENT-SELFIES in PMO.",
            "dataset_used": "ZINC 250K (SELFIES tokenization)",
            "evaluation_metrics": "AUC Top-10 primarily, Top-K metrics and run statistics.",
            "reported_results": "Ranked #3 overall by mean AUC Top-10 (sum = 13.471). Per-task example values: drd2 0.943 ± 0.005, qed 0.940 ± 0.000, albuterol_similarity 0.826 ± 0.030. PMO notes SELFIES variants did not consistently outperform SMILES variants for language-model-based methods.",
            "experimental_validation": false,
            "challenges_or_limitations": "Although SELFIES guarantees syntactic validity, PMO observed no consistent optimization advantage and sometimes lower sample efficiency versus SMILES variants; SELFIES tokenization can map many token combinations to a small set of molecules when truncated, limiting effective exploration if not carefully handled.",
            "uuid": "e7113.3",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "SMILES-VAE / SELFIES-VAE",
            "name_full": "Variational Autoencoders for molecular generation (SMILES-VAE and SELFIES-VAE)",
            "brief_description": "Encoder-decoder VAEs learn continuous latent representations of molecules (from SMILES or SELFIES) enabling latent-space optimization and sampling; PMO evaluates vanilla VAE variants.",
            "citation_title": "Automatic chemical design using a data-driven continuous representation of molecules.",
            "mention_or_use": "use",
            "model_name": "SMILES-VAE and SELFIES-VAE",
            "model_type": "encoder-decoder variational autoencoder; latent-space molecular generator (BO in latent space sometimes used in prior work)",
            "model_size": "not reported",
            "training_data_description": "Trained / pretrained on ZINC 250K in PMO; latent-space optimization variants in literature often use datasets like ZINC or MOSES, but PMO restricts to ZINC 250K.",
            "generation_method": "Encode molecules to latent vectors and decode to SMILES/SELFIES; optimization performed by searching latent space (BO commonly used historically) or sampling from the learned distribution.",
            "chemical_representation": "SMILES and SELFIES variants evaluated in PMO.",
            "target_application": "De novo molecular generation for PMO objectives (similarity MPOs, activity predictors); used as baseline generative method class.",
            "constraints_used": "Oracle-driven selection and PMO experiment-level constraints (10k oracle calls, ZINC 250K pretraining); no explicit synthesizability filtering for vanilla VAE in PMO.",
            "integration_with_external_tools": "Uses TDC oracles for evaluation; sometimes prior works combine latent BO with acquisition function optimizers but PMO included vanilla implementations.",
            "dataset_used": "ZINC 250K (pretraining and fragment extraction when needed).",
            "evaluation_metrics": "AUC Top-10 primarily; VAEs ranked lower in PMO (SELFIES-VAE rank ~16–18 depending on metric).",
            "reported_results": "SELFIES-VAE and SMILES-VAE had overall lower summed mean AUC Top-10 (e.g., SMILES-VAE sum ~8.887–? depending on configuration; exact sums: SMILES-VAE listed among lower-ranked methods: rank ~18–19). Representative per-task values are provided in PMO tables (e.g., qed ~0.936–0.940 depending on variant).",
            "experimental_validation": false,
            "challenges_or_limitations": "VAEs may struggle with validity or mapping smoothness; PMO reports older SMILES VAE versions had validity issues but later methods improved; VAEs in PMO were generally less sample-efficient under the 10k oracle budget and ranked lower than top sequence-based methods.",
            "uuid": "e7113.4",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "STONED",
            "name_full": "STONED: Superfast traversal, optimization, novelty, exploration and discovery algorithm using SELFIES",
            "brief_description": "A manipulation algorithm that directly alters SELFIES tokens to rapidly traverse chemical space (token-level edits) without training an explicit generative model; included in PMO as a SELFIES-based GA-like method.",
            "citation_title": "Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES",
            "mention_or_use": "use",
            "model_name": "STONED (SELFIES token manipulator)",
            "model_type": "nonparametric token-level manipulation algorithm (no large pretrained LM required)",
            "model_size": "not applicable (algorithmic manipulations rather than parametric LM)",
            "training_data_description": "No training required; uses SELFIES token operations and optionally a corpus for initial seeds (PMO uses ZINC 250K as database when needed).",
            "generation_method": "Direct SELFIES token modifications (mutations) to produce new molecules; rapid exploration via token edits.",
            "chemical_representation": "SELFIES",
            "target_application": "Molecular optimization tasks in PMO; particularly compared for isomer-type and similarity-based oracles.",
            "constraints_used": "Operates under PMO oracle budget (10k calls); SELFIES ensures syntactic validity by design.",
            "integration_with_external_tools": "Uses PMO oracles (TDC) for scoring; not integrated with retrosynthesis/docking in PMO runs.",
            "dataset_used": "ZINC 250K used as seed/library in PMO experiments.",
            "evaluation_metrics": "AUC Top-10, Top-K averages; PMO reports STONED performed well in some isomer tasks and had varied rankings overall (ranked #5 among top-10 shown in Table 2).",
            "reported_results": "In Table 2 STONED (SELFIES) has per-task numbers like fexofenadine_mpo 0.797 ± 0.016, isomers_c7h8n2o2 0.899 ± 0.011, isomers_c9h10n2o2pf2cl 0.805 ± 0.031; overall sum for top methods shows STONED sum = 13.024 and rank #5 among top-10 shown.",
            "experimental_validation": false,
            "challenges_or_limitations": "Although syntax-valid by design, SELFIES token manipulations can map many token combinations to a small set of molecules when truncated; exploration can be constrained if token operations are not well designed; PMO notes that SELFIES advantages are not universal across model classes.",
            "uuid": "e7113.5",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "GA+D",
            "name_full": "Genetic Algorithm augmented with Deep neural networks (GA+D)",
            "brief_description": "A SELFIES-based genetic algorithm enhanced by deep neural networks to guide mutation/crossover decisions; included in PMO as a hybrid between classical GA and learned models.",
            "citation_title": "Augmenting genetic algorithms with deep neural networks for exploring the chemical space",
            "mention_or_use": "use",
            "model_name": "GA+D (SELFIES based GA augmented by deep NN)",
            "model_type": "hybrid evolutionary algorithm with learned components (deep NN to guide GA operators)",
            "model_size": "not reported",
            "training_data_description": "When used in PMO, GA+D is applied within the ZINC 250K-constrained setup; training details of the deep component not reported in PMO beyond citation to original work.",
            "generation_method": "Genetic algorithm operations (mutation and/or crossover) on SELFIES sequences; a deep neural network component directs or ranks candidates to improve search efficiency.",
            "chemical_representation": "SELFIES (SELFIES-based GA variant)",
            "target_application": "De novo molecular design objectives in PMO (similarity MPOs, isomer tasks, activity prediction tasks).",
            "constraints_used": "Oracle-based selection and PMO-wide constraints (10k oracle calls); being SELFIES-based, syntactic validity is enforced.",
            "integration_with_external_tools": "Uses PMO oracles (TDC) for evaluation; no explicit use of docking or retrosynthesis in PMO benchmarking.",
            "dataset_used": "ZINC 250K",
            "evaluation_metrics": "AUC Top-10 and Top-K metrics over 5 runs.",
            "reported_results": "GA+D appears in PMO results with mixed performance; overall rank around mid-field (GA+D rank ~23 in Table 3 when considering multiple metrics). Per-task values show high variance for some tasks; exact per-task numbers provided in PMO appendices.",
            "experimental_validation": false,
            "challenges_or_limitations": "Performance highly dependent on mutation/crossover rule design and on quality/effectiveness of the learned guidance network; GA-style exploration can be sample-inefficient and produce undesired candidates (unstable or unsynthesizable) that waste oracle budget.",
            "uuid": "e7113.6",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Pasithea",
            "name_full": "Pasithea: Deep molecular dreaming (gradient-based modification via learned surrogate)",
            "brief_description": "A gradient-based method that trains a predictive MLP surrogate on SELFIES strings and backpropagates through the surrogate to propose token edits (i.e., uses surrogate gradients to propose molecules).",
            "citation_title": "Deep molecular dreaming: Inverse machine learning for de-novo molecular design and interpretability with surjective representations.",
            "mention_or_use": "use",
            "model_name": "Pasithea (MLP surrogate with gradient-based token editing on SELFIES)",
            "model_type": "gradient-ascent on surrogate predictions; surrogate is an MLP operating on SELFIES representations",
            "model_size": "not reported",
            "training_data_description": "Surrogate model trained online as data are acquired during PMO optimization; initial data and pretraining sourced from ZINC 250K if required.",
            "generation_method": "Estimate gradients of property via surrogate MLP then backpropagate to modify SELFIES tokens (gradient-based generation instead of sampling from a generative LM).",
            "chemical_representation": "SELFIES",
            "target_application": "Same PMO objective suite (MPOs, bioactivity predictors); used as a representative gradient-based approach.",
            "constraints_used": "Oracle-driven selection; PMO budget constraint of 10k oracle calls; no explicit synthesizability filters in Pasithea runs reported.",
            "integration_with_external_tools": "Uses PMO oracles (TDC) for evaluation; surrogate trained/updated online using the observed oracle outputs.",
            "dataset_used": "ZINC 250K (for pretraining/initialization when applicable); online dataset collected during optimization counted toward oracle budget.",
            "evaluation_metrics": "AUC Top-10 primarily; Pasithea ranked ~19 in PMO across tasks by sum of AUC Top-10 values.",
            "reported_results": "Pasithea's summed performance ranks lower (sum ~? listed in PMO tables as lower-tier; per-task examples: qed ~0.931 ± 0.002, some tasks like drd2 low ~0.255 ± 0.040) — full per-task numbers are in PMO appendices.",
            "experimental_validation": false,
            "challenges_or_limitations": "Surrogate accuracy limits optimization; gradient-based editing on discrete token spaces requires careful mapping/backpropagation strategies; PMO observed mixed performance and sensitivity to surrogate quality and online training schedule.",
            "uuid": "e7113.7",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Language-model representation comparison (SMILES vs SELFIES)",
            "name_full": "Comparison of SMILES and SELFIES string representations when used with language-model-like generators",
            "brief_description": "PMO compares SMILES and SELFIES variants of many sequence and string-based algorithms and finds no universal advantage for SELFIES across language-model-based methods; SELFIES shows benefit in some GA manipulation contexts but not consistently for pretrained sequence LMs.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "representation comparison (SMILES vs SELFIES) applied to RNN/LSTM, GA, and other sequence-based methods",
            "model_type": "head-to-head representation study across multiple generative algorithm classes (sequence models, GAs, HC, RL)",
            "model_size": "not applicable",
            "training_data_description": "Both representations tokenized from ZINC 250K for models that required pretraining.",
            "generation_method": "Same generation algorithms run with either SMILES or SELFIES tokenization to assess representation effects (e.g., REINVENT SMILES vs REINVENT SELFIES, SMILES-LSTM-HC vs SELFIES-LSTM-HC).",
            "chemical_representation": "SMILES and SELFIES compared directly.",
            "target_application": "All PMO objectives (similarity MPOs, isomer tasks, drug-target activity predictors).",
            "constraints_used": "PMO experimental constraints (10k oracle calls, ZINC 250K pretraining).",
            "integration_with_external_tools": "Uses PMO oracles from TDC for evaluation.",
            "dataset_used": "ZINC 250K for all pretraining / tokenization.",
            "evaluation_metrics": "AUC Top-10 per task and parity plots comparing SMILES vs SELFIES AUC Top-10 values across tasks (fraction of tasks where SELFIES outperforms SMILES reported).",
            "reported_results": "PMO finds SELFIES does not systematically improve optimization performance for language-model-based methods; fractions of tasks where SELFIES outperforms SMILES vary by method (plots in Figure 2a). SELFIES-based GA outperformed SMILES-based GA in PMO, but for sequence LMs SMILES variants often matched or outperformed SELFIES.",
            "experimental_validation": false,
            "challenges_or_limitations": "SELFIES removes syntactic invalidity but does not guarantee better exploration or sample efficiency; SELFIES token combinatorics can map to a small number of molecules leading to exploration inefficiencies if token design/truncation is not handled carefully.",
            "uuid": "e7113.8",
            "source_info": {
                "paper_title": "Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Molecular de-novo design through deep reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Automatic chemical design using a data-driven continuous representation of molecules.",
            "rating": 2
        },
        {
            "paper_title": "GuacaMol: benchmarking models for de novo molecular design",
            "rating": 2
        },
        {
            "paper_title": "Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation",
            "rating": 2
        },
        {
            "paper_title": "Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES",
            "rating": 2
        },
        {
            "paper_title": "Augmenting genetic algorithms with deep neural networks for exploring the chemical space",
            "rating": 2
        },
        {
            "paper_title": "Deep molecular dreaming: Inverse machine learning for de-novo molecular design and interpretability with surjective representations.",
            "rating": 2
        },
        {
            "paper_title": "Optimizing distributions over molecular space. an objective-reinforced generative adversarial network for inverse-design chemistry (ORGANIC).",
            "rating": 1
        }
    ],
    "cost": 0.023160999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization</h1>
<p>Wenhao Gao ${ }^{1 <em>}$, Tianfan $\mathbf{F u}^{2 </em>}$, Jimeng Sun ${ }^{3}$, Connor W. Coley ${ }^{1}$<br>${ }^{1}$ Massachusetts Institute of Technology, ${ }^{2}$ Georgia Institute of Technology<br>${ }^{3}$ University of Illinois at Urbana-Champaign<br>*Equal Contributions<br>{whgao, ccoley}@mit.edu, tfu42@gatech.edu, jimeng@illinois.edu</p>
<h4>Abstract</h4>
<p>Molecular optimization is a fundamental goal in the chemical sciences and is of central interest to drug and material design. In recent years, significant progress has been made in solving challenging problems across various aspects of computational molecular optimizations, emphasizing high validity, diversity, and, most recently, synthesizability. Despite this progress, many papers report results on trivial or selfdesigned tasks, bringing additional challenges to directly assessing the performance of new methods. Moreover, the sample efficiency of the optimization-the number of molecules evaluated by the oracle-is rarely discussed, despite being an essential consideration for realistic discovery applications. To fill this gap, we have created an open-source benchmark for practical molecular optimization, PMO, to facilitate the transparent and reproducible evaluation of algorithmic advances in molecular optimization. This paper thoroughly investigates the performance of 25 molecular design algorithms on 23 single-objective (scalar) optimization tasks with a particular focus on sample efficiency. Our results show that most "state-of-the-art" methods fail to outperform their predecessors under a limited oracle budget allowing 10 K queries and that no existing algorithm can efficiently solve certain molecular optimization problems in this setting. We analyze the influence of the optimization algorithm choices, molecular assembly strategies, and oracle landscapes on the optimization performance to inform future algorithm development and benchmarking. PMO provides a standardized experimental setup to comprehensively evaluate and compare new molecule optimization methods with existing ones. All code can be found at https://github.com/wenhao-gao/ mol_opt.</p>
<h2>1 Introduction</h2>
<p>Designing new functional molecules is a constrained multi-objective optimization problem that aims to find molecules with desired properties such as selective inhibition against a disease target, with additional desiderata and constraints to ensure the structures are stable and synthesizable. The importance of molecular design problems has attracted significant efforts to develop systematical molecular design methodologies instead of exhaustive searches, leveraging combinatorial optimization algorithms [1, 2], predictive machine learning models [3, 4], and generative models [5, 6]. Especially in recent years, we have witnessed significant progress in solving challenging problems across various aspects of computational molecular optimizations, such as achieving high validity [7, 8, 9], diversity [10], and, most recently, synthesizability [11, 12].</p>
<p>Despite the exciting progress in the field and the abundance of new methods proposed, how these algorithms compare against each other remains unclear. Most method development papers and existing benchmarks such as Guacamol [13], Therapeutics Data Commons (TDC) [14] and Tripp et al.'s [15] suffer from at least one of three problems: (1) Lack of consideration of the oracle budget: Many papers [16, 17, 18] do not report how many times the oracle function is called to achieve the reported results (i.e., how many candidate molecules were evaluated), except in rare cases [19, 20, 21, 22, 23], despite this range spanning orders of magnitude. As most valuable oracles—experiments or high-accuracy simulations—require substantial costs, it is vital to identify the desired compound with as few oracle calls as possible. (2) Trivial oracles: Some papers only report results on trivial oracles [17] like quantitative estimate of drug-likeness (QED) [24] or penalized octanol-water partition coefficient (LogP) ; other papers even introduce new self-designed tasks [18, 21], which obfuscates a comparison to prior work. (3) Randomness: Another complication is that many algorithms are not deterministic and exhibit significant run-to-run variation, so reporting results from several independent trials is essential. All of the existing benchmarks examined no more than five methods due to the significant variation between molecular optimization algorithms. Thus we still lack a unified benchmark to assess which methods are beneficial in a realistic discovery scenario.</p>
<p>This paper presents a new reproducible large-scale experimental study with a sound experimental protocol for molecular design, PMO. We have benchmarked 25 methods across 23 various widely-used oracle functions, with each of them tuned and run for multiple independent trials. To consider a combination of optimization ability and sample efficiency, we limit the number of maximum oracle calls up to 10,000 queries and measure model performance with the area under the curve (AUC) of the top-10 average performance versus oracle calls. Our results show that none of the existing molecular optimization algorithms are efficient enough to solve a de novo molecular optimization problem within a realistic oracle budget of hundreds of experiments, and "state-of-the-art" methods often fail to outperform their predecessors. We analyze the algorithmic contribution and the influence of oracle landscapes on optimization performance to inform future algorithm development and benchmarking. Our results highlight the necessity of standardized experimental reporting, including independent replicates and extensive hyperparameter tuning. We envision that the PMO benchmark will make molecular optimizations more accessible and reproducible, thereby facilitating algorithmic advances and, ultimately, the broader adoption of molecular optimization techniques in experimental drug and materials discovery workflows.</p>
<h1>2 Algorithms</h1>
<p>A molecular optimization method has two major components: (1) a molecular assembly strategy that defines the chemical space by assembling a digital representation of compounds, and (2) an optimization algorithm that navigates this chemical space. This section will first introduce common strategies to assemble molecules, then introduce the benchmarked molecular optimization methods based on the core optimization algorithms. Table 1 summarizes current molecular design methods categorized based on assembly strategy and optimization method, including but not limited to the methods included in our baseline. We emphasize that our goal is not to make an exhaustive list but to include a group of methods that are representative enough to obtain meaningful conclusions.</p>
<h3>2.1 Preliminaries</h3>
<p>In this paper, we limit our scope to general-purpose single-objective molecular optimization methods focusing on small organic molecules with scalar properties with some relevance to therapeutic design. Formally, we can formulate such a molecular design problem as an optimization problem:</p>
<p>$$
m^{*}=\arg \max _{m \in \mathcal{M}} \mathcal{O}(m)
$$</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 1: Representative molecule generation methods, categorised based on the molecular assembly strategies and the optimization algorithms. Columns are various molecular assembly strategies while rows are different optimization algorithms.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">SMILES</th>
<th style="text-align: center;">SELFIES</th>
<th style="text-align: center;">Graph (atom)</th>
<th style="text-align: center;">Graph (fragment)</th>
<th style="text-align: center;">Synthesis</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GA</td>
<td style="text-align: center;">SMILES-GA [13]</td>
<td style="text-align: center;">GA+D [17] <br> STONED [29]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">Graph-GA [1]</td>
<td style="text-align: center;">SynNet [12]</td>
</tr>
<tr>
<td style="text-align: center;">MCTS</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">Graph-MCTS [1]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">BO</td>
<td style="text-align: center;">BOSS [30]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">GPBO [15]</td>
<td style="text-align: center;">ChemBO [19]</td>
</tr>
<tr>
<td style="text-align: center;">VAE</td>
<td style="text-align: center;">SMILES-VAE [6]</td>
<td style="text-align: center;">SELFIES-VAE [22]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">JTVAE [8]</td>
<td style="text-align: center;">DoG-AE [11]</td>
</tr>
<tr>
<td style="text-align: center;">GAN</td>
<td style="text-align: center;">ORGAN [31]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">MolGAN [32]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">SBM</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">GFlowNet[10] <br> MARS[2]</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">HC</td>
<td style="text-align: center;">SMILES LSTM [13]</td>
<td style="text-align: center;">SELFIES LSTM</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">MIMOSA [33]</td>
<td style="text-align: center;">DoG-Gen [11]</td>
</tr>
<tr>
<td style="text-align: center;">RL</td>
<td style="text-align: center;">REINVENT [5]</td>
<td style="text-align: center;">SELFIES- <br> REINVENT</td>
<td style="text-align: center;">MolDQN [16] <br> GCPN [25]</td>
<td style="text-align: center;">RationaleRL[34] <br> FREED [35]</td>
<td style="text-align: center;">PGFS [18] <br> REACTOR [36]</td>
</tr>
<tr>
<td style="text-align: center;">GRAD</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">Pasithea [37]</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">DST [20]</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>where $m$ is a molecular structure, $\mathcal{M}$ denotes the design space called chemical space that comprises all possible candidate molecules. The size of $\mathcal{M}$ is impractically large, e.g., $10^{60}$ [26]. We assume we have access to the ground truth value of a property of interest denoted by $\mathcal{O}(m): \mathcal{M} \rightarrow \mathcal{R}$, where an oracle, $\mathcal{O}$, is a black-box function that evaluates certain chemical or biological properties of a molecule $m$ and returns the ground truth property $\mathcal{O}(m)$ as a scalar. Note that neither the analytic form of oracles nor the derivatives of the properties are accessible. The most practical oracles-experiments or high-accuracy simulations- typically require substantial costs. An algorithm able to optimize the oracle within a reasonable budget is thus necessary for automating the design of molecules to achieve high-level automated chemical design (ACD) [27] or function-oriented autonomous synthesis [28].</p>
<h1>2.2 Molecular assembly strategies</h1>
<p>String-based. String-based assembly strategies represent molecules as strings and explore chemical space by modifying strings directly: character-by-character, token-by-token, or through more complex transformations based on a specific grammar. We include two types of string representations: (1) Simplified Molecular-Input Line-Entry System (SMILES) [38], a linear notation describing the molecular structure using short ASCII strings based on a graph traversal algorithm; (2) SELFreferencIng Embedded Strings (SELFIES) [9], which avoids syntactical invalidity by enforcing the chemical validity rules in a formal grammar table.
Graph-based. Two-dimensional (2D) graphs can intuitively define molecular identities to a first approximation (ignoring stereochemistry ${ }^{3}$ ): the nodes and edges represent the atoms and bonds. There are two main assembling strategies for molecular graphs: (1) an atom-based assembly strategy [16] that adds or modifies atoms and bonds one at a time, which covers all valid chemical space; (2) a fragment-based assembling strategy [8] that summarizes common molecular fragments and operates one fragment at a time. Note that fragment-based strategy could also include atom-level operation.
Synthesis-based. Most of the above assembly strategies can cover a large chemical space, but an eventual goal of molecular design is to physically test the candidate; thus, a desideratum is to explore synthesizable candidates only. Designing molecules by assembling synthetic pathways from commercially-available starting materials and reliable chemical transformation adds a constraint of synthesizability to the search space. This class can be divided into template-free [11] and templatebased [12] based on how to define reliable chemical transformations, but we will not distinguish between them in this paper as synthesis-based strategy is relatively less explored in general.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>2.3 Optimization algorithms</h1>
<p>Screening (a.k.a. virtual screening) involves searching over a pre-enumerated library of molecules. We include Screening as a baseline, which randomly samples ZINC 250k [42]. Model-based screening $[43,44,45,46,3,47]$ instead trains a surrogate model and prioritizes molecules that are scored highly by the surrogate to accelerate screening. We adopt the implementation from the original paperof MolPAL [3] and treat it as a model-based version of screening.
Genetic Algorithm (GA) is a popular heuristic algorithm inspired by natural evolutionary processes. It combines mutation and/or crossover perturbing a mating pool to enable exploration in the design space. We include SMILES GA [48] that defines actions based on SMILES context-free grammar and a modified version of STONED [29] that directly manipulates tokens in SELFIES strings. Unlike the string-based GAs that only have mutation steps, Graph GA [1] derives crossover rules from graph matching and includes both atom- and fragment-level mutations. Finally, we include SynNet [12] as a synthesis-based example that applies a genetic algorithm on binary fingerprints and decodes to synthetic pathways. We adopt the implementation of SMILES GA and Graph GA from Guacamol [13], STONED, and SynNet from the original paper. We also include the original implementation of a deep learning enhanced version of SELFIES-based GA from [17] and label it as $\underline{\mathrm{GA}+\mathrm{D}}$.
Monte-Carlo Tree Search (MCTS) locally and randomly searches each branch of the current state (e.g., a molecule or partial molecule) and selects the most promising ones (those with highest property scores) for the next iteration. Graph MCTS [1] is an MCTS algorithm based on atom-level searching over molecular graphs. We adopt the implementation from Guacamol [13].
Bayesian optimization (BO) [49] is a large class of method that builds a surrogate for the objective function using a Bayesian machine learning technique, such as Gaussian process (GP) regression, then uses an acquisition function combining the surrogate and uncertainty to decide where to sample, which is naturally model-based. However, as BO usually leverages a non-parametric model, it scales poorly with sample size and feature dimension [50]. We included a string-based model, BO over String Space (BOSS) [30], and a synthesis-based model, ChemBO [19], but do not obtain meaningful results even with early stopping potentially due to the poor scaling of the string subsequence kernel (SSK) (see Section B. 3 for early stopping setting, and Section B. 33 for more analysis). Finally, we adopt Gaussian process Bayesian optimization (GP BO) [15] that optimizes the GP acquisition function with Graph GA methods in an inner loop. The implementation is from the original paper, and we treat it as a model-based version of Graph GA. Note that we categorize methods that apply BO to optimize molecules in latent space as a separate class below.
Variational autoencoders (VAEs) [51] are a class of generative method that maximize a lower bound of the likelihood (evidence lower bound (ELBO)) instead of estimating the likelihood directly. A VAE typically learns to map molecules to and from real space to enable the indirect optimization of molecules by numerically optimizing latent vectors, most commonly with BO [52]. SMILES-VAE [6] uses a VAE to model molecules represented as SMILES strings, and is implemented in MOSES [53]. We adopt the identical architecture to model SELFIES strings and denote it as SELFIES-VAE. JT-VAE [8] abstracts a molecular graph into a junction tree (i.e., a cycle-free structure), and design message passing network as the encoder and tree-RNN as the decoder. DoG-AE [11] uses Wasserstein autoencoder (WAE) to learn the distribution of synthetic pathways. Note that we include a set of vanilla methods for each kind while many variants have emerged, such as [23] and [22]. We leave the validation of variants for the future development of this benchmark.
Score-based modeling (SBM) formulates the problem of molecule design as a sampling problem where the target distribution is a function of the target property, featured by Markov-chain Monte Carlo (MCMC) methods that construct Markov chains with the desired distribution as their equilibrium distribution. MARkov molecular Sampling (MARS) [2] is such an example that leverages a graph neural network to propose action steps adaptively in an MCMC with an annealing scheme. Generative Flow Network (GFlowNet) [10] views the generative process as a flow network and trains it with a temporal difference-like loss function based on the conservation of flow. By matching the property of interest with the volume of the flow, generation can sample a distribution proportional to the target distribution.
Hill climbing (HC) is an iterative learning method that incorporates the generated high-scored molecules into the training data and fine-tunes the generative model for each iteration. It is a variant</p>
<p>of the cross-entropy method [54], and can also be seen as a variant of REINFORCE [55] with a particular reward shaping. We adopt SMILES-LSTM-HC from Guacamol [13] that leverages a LSTM to learn the molecular distribution represented in SMILES strings, and modifies it to a SELFIES version denoted as SELFIES-LSTM-HC. MultI-constraint MOlecule SAmpling (MIMOSA) [33] leverages a graph neural network to predict the identity of a masked fragment node and trains it with a HC algorithm. DoG-Gen [11] instead learn the distribution of synthetic pathways as Directed Acyclic Graph (DAGs) with an RNN generator.</p>
<p>Reinforcement Learning (RL) learns how intelligent agents take actions in an environment to maximize the cumulative reward by transitioning through different states. In molecular design, a state is usually a partially generated molecule; actions are manipulations at the level of graphs or strings; rewards are defined as the generated molecules' property of interest. REINVENT [5] adopts a policybased RL approach to tune RNNs to generate SMILES strings. We adopt the implementation from the original paper, and modify it to generate SELFIES strings, SELFIES-REINVENT. MolDQN [16] uses a deep Q-network to generate molecular graph in an atom-wise manner.</p>
<p>Gradient ascent (GRAD) methods learn to estimate the gradient direction based on the landscape of the molecular property over the chemical space, and back-propagate to optimize the molecules. Pasithea [37] exploits an MLP to predict properties from SELFIES strings, and back-propagate to modify tokens. Differentiable scaffolding tree (DST) [20] abstracts molecular graphs to scaffolding trees and leverages a graph neural network to estimate the gradient. We adopted the implementation from the original papers and modify them to update the surrogates online as data are acquired.</p>
<h1>3 Experiments</h1>
<h3>3.1 Benchmark setup</h3>
<p>This section introduces the setup of PMO benchmark. The main idea behind PMO is the pursuit of an ideal de novo molecular optimization algorithm that exhibits strong optimization ability, sample efficiency, generalizability to various optimization objectives, and robustness to hyperparameter selection and random seeds.</p>
<p>Oracle: To examine the generalizability of methods, we aim to include a broad range of pharmaceutically-relevant oracle functions. Systematic categorization of oracles based on their landscape is still challenging due to the complicated relationship between molecular structure and function. We have included the most commonly used oracles (see a recent discussion of commonlyused oracles in [56]). Several have been described as "trivial", but we assert this is only true when the number of oracle queries is not controlled. In total, PMO includes 23 oracle functions: QED [24], DRD2 [5], GSK3 $\beta$, JNK3 [57], and 19 oracles from Guacamol [13]. QED is a relatively simple heuristic function that estimates if a molecule is likely to be a drug based on if it contains some "red flags". DRD2, GSK3 $\beta$, and JNK3 are machine learning models (support vector machine (SVM), random forest (RF)) fit to experimental data to predict the bioactivities against their corresponding disease targets. Guacamol oracles are designed to mimic the drug discovery objectives based on multiple considerations, called multi-property objective (MPO), including similarity to target molecules, molecular weights, CLogP, etc. All oracle scores are normalized from 0 to 1 , where 1 is optimal. Recently, docking scores that estimate the binding affinity between ligands and proteins have been adopted as oracles [58, 14, 59]. However, as the simulations are more costly than above ones but are still coarse estimates that do not reflect true bioactivity, we leave it to future work.</p>
<p>Metrics: To consider the optimization ability and sample efficiency simultaneously, we report the area under the curve (AUC) of top- $K$ average property value versus the number of oracle calls ( $A U C$ top- $K$ ) as the primary metric to measure the performance. Unlike using top- $K$ average property, AUC rewards methods that reach high values with fewer oracle calls. We use $K=10$ in this paper as it is useful to identify a small number of distinct molecular candidates to progress to later stages of development. We limit the number of oracle calls to 10000, though we expect methods to optimize well within hundreds of calls when using experimental evaluations. The reported values of AUCs are min-max scaled to $[0,1]$.</p>
<p>Data: We restrict all our methods to using the ZINC 250K dataset only whenever a database is required, which contains around 250 K molecules sampled from the ZINC database [42] for its pharmaceutical relevance, moderate size, and popularity. Screening and MolPAL search over this</p>
<p>Table 2: Performance of ten best performing molecular optimization methods based on mean AUC Top-10. We report the mean and standard deviation of AUC Top-10 from 5 independent runs. The best model in each task is labeled bold. Full results are in the Appendix A.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>REINVENT</th>
<th>Graph GA</th>
<th>REINVENT</th>
<th>GP BO</th>
<th>STONED</th>
</tr>
</thead>
<tbody>
<tr>
<td>Assembly</td>
<td>SMILES</td>
<td>Fragments</td>
<td>SELFIES</td>
<td>Fragments</td>
<td>SELFIES</td>
</tr>
<tr>
<td>albuterol_similarity</td>
<td>$0.882 \pm 0.006$</td>
<td>$0.838 \pm 0.016$</td>
<td>$0.826 \pm 0.030$</td>
<td>$\mathbf{0 . 8 9 8} \pm \mathbf{0 . 0 1 4}$</td>
<td>$0.745 \pm 0.076$</td>
</tr>
<tr>
<td>amlodipine_mpo</td>
<td>$0.635 \pm 0.035$</td>
<td>$\mathbf{0 . 6 6 1} \pm \mathbf{0 . 0 2 0}$</td>
<td>$0.607 \pm 0.014$</td>
<td>$0.583 \pm 0.044$</td>
<td>$0.608 \pm 0.046$</td>
</tr>
<tr>
<td>celecoxib_rediscovery</td>
<td>$0.713 \pm 0.067$</td>
<td>$0.630 \pm 0.097$</td>
<td>$0.573 \pm 0.043$</td>
<td>$\mathbf{0 . 7 2 3} \pm \mathbf{0 . 0 5 3}$</td>
<td>$0.382 \pm 0.041$</td>
</tr>
<tr>
<td>deco_hop</td>
<td>$0.666 \pm 0.044$</td>
<td>$0.619 \pm 0.004$</td>
<td>$0.631 \pm 0.012$</td>
<td>$0.629 \pm 0.018$</td>
<td>$0.611 \pm 0.008$</td>
</tr>
<tr>
<td>drd2</td>
<td>$0.945 \pm 0.007$</td>
<td>$0.964 \pm 0.012$</td>
<td>$0.943 \pm 0.005$</td>
<td>$0.923 \pm 0.017$</td>
<td>$0.913 \pm 0.020$</td>
</tr>
<tr>
<td>fexofenadine_mpo</td>
<td>$0.784 \pm 0.006$</td>
<td>$0.760 \pm 0.011$</td>
<td>$0.741 \pm 0.002$</td>
<td>$0.722 \pm 0.005$</td>
<td>$\mathbf{0 . 7 9 7} \pm \mathbf{0 . 0 1 6}$</td>
</tr>
<tr>
<td>gsk3b</td>
<td>$\mathbf{0 . 8 6 5} \pm \mathbf{0 . 0 4 3}$</td>
<td>$0.788 \pm 0.070$</td>
<td>$0.780 \pm 0.037$</td>
<td>$0.851 \pm 0.041$</td>
<td>$0.668 \pm 0.049$</td>
</tr>
<tr>
<td>isomers_c7h8n2o2</td>
<td>$0.852 \pm 0.036$</td>
<td>$0.862 \pm 0.065$</td>
<td>$0.849 \pm 0.034$</td>
<td>$0.680 \pm 0.117$</td>
<td>$0.899 \pm 0.011$</td>
</tr>
<tr>
<td>isomers_c9h10n2o2pf2cl</td>
<td>$0.642 \pm 0.054$</td>
<td>$0.719 \pm 0.047$</td>
<td>$0.733 \pm 0.029$</td>
<td>$0.469 \pm 0.180$</td>
<td>$0.805 \pm 0.031$</td>
</tr>
<tr>
<td>jnk3</td>
<td>$\mathbf{0 . 7 8 3} \pm \mathbf{0 . 0 2 3}$</td>
<td>$0.553 \pm 0.136$</td>
<td>$0.631 \pm 0.064$</td>
<td>$0.564 \pm 0.155$</td>
<td>$0.523 \pm 0.092$</td>
</tr>
<tr>
<td>median1</td>
<td>$\mathbf{0 . 3 5 6} \pm \mathbf{0 . 0 0 9}$</td>
<td>$0.294 \pm 0.021$</td>
<td>$0.355 \pm 0.011$</td>
<td>$0.301 \pm 0.014$</td>
<td>$0.266 \pm 0.016$</td>
</tr>
<tr>
<td>median2</td>
<td>$0.276 \pm 0.008$</td>
<td>$0.273 \pm 0.009$</td>
<td>$0.255 \pm 0.005$</td>
<td>$\mathbf{0 . 2 9 7} \pm \mathbf{0 . 0 0 9}$</td>
<td>$0.245 \pm 0.032$</td>
</tr>
<tr>
<td>mestranol_similarity</td>
<td>$0.618 \pm 0.048$</td>
<td>$0.579 \pm 0.022$</td>
<td>$0.620 \pm 0.029$</td>
<td>$\mathbf{0 . 6 2 7} \pm \mathbf{0 . 0 8 9}$</td>
<td>$0.609 \pm 0.101$</td>
</tr>
<tr>
<td>osimertinib_mpo</td>
<td>$\mathbf{0 . 8 3 7} \pm \mathbf{0 . 0 0 9}$</td>
<td>$0.831 \pm 0.005$</td>
<td>$0.820 \pm 0.003$</td>
<td>$0.787 \pm 0.006$</td>
<td>$0.822 \pm 0.012$</td>
</tr>
<tr>
<td>perindopril_mpo</td>
<td>$0.537 \pm 0.016$</td>
<td>$0.538 \pm 0.009$</td>
<td>$0.517 \pm 0.021$</td>
<td>$0.493 \pm 0.011$</td>
<td>$0.488 \pm 0.011$</td>
</tr>
<tr>
<td>qed</td>
<td>$0.941 \pm 0.000$</td>
<td>$0.940 \pm 0.000$</td>
<td>$0.940 \pm 0.000$</td>
<td>$0.937 \pm 0.000$</td>
<td>$0.941 \pm 0.000$</td>
</tr>
<tr>
<td>ranolazine_mpo</td>
<td>$0.760 \pm 0.009$</td>
<td>$0.728 \pm 0.012$</td>
<td>$0.748 \pm 0.018$</td>
<td>$0.735 \pm 0.013$</td>
<td>$\mathbf{0 . 7 6 5} \pm \mathbf{0 . 0 2 9}$</td>
</tr>
<tr>
<td>scaffold_hop</td>
<td>$\mathbf{0 . 5 6 0} \pm \mathbf{0 . 0 1 9}$</td>
<td>$0.517 \pm 0.007$</td>
<td>$0.525 \pm 0.013$</td>
<td>$0.548 \pm 0.019$</td>
<td>$0.521 \pm 0.034$</td>
</tr>
<tr>
<td>sitagliptin_mpo</td>
<td>$0.021 \pm 0.003$</td>
<td>$\mathbf{0 . 4 3 3} \pm \mathbf{0 . 0 7 5}$</td>
<td>$0.194 \pm 0.121$</td>
<td>$0.186 \pm 0.055$</td>
<td>$0.393 \pm 0.083$</td>
</tr>
<tr>
<td>thiothisene_rediscovery</td>
<td>$0.534 \pm 0.013$</td>
<td>$0.479 \pm 0.025$</td>
<td>$0.495 \pm 0.040$</td>
<td>$\mathbf{0 . 5 5 9} \pm \mathbf{0 . 0 2 7}$</td>
<td>$0.367 \pm 0.027$</td>
</tr>
<tr>
<td>troglitazone_rediscovery</td>
<td>$\mathbf{0 . 4 4 1} \pm \mathbf{0 . 0 3 2}$</td>
<td>$0.390 \pm 0.016$</td>
<td>$0.348 \pm 0.012$</td>
<td>$0.410 \pm 0.015$</td>
<td>$0.320 \pm 0.018$</td>
</tr>
<tr>
<td>valsartan_smarts</td>
<td>$\mathbf{0 . 1 7 8} \pm \mathbf{0 . 3 5 8}$</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
</tr>
<tr>
<td>zaleplon_mpo</td>
<td>$\mathbf{0 . 3 5 8} \pm \mathbf{0 . 0 6 2}$</td>
<td>$0.346 \pm 0.032$</td>
<td>$0.333 \pm 0.026$</td>
<td>$0.221 \pm 0.072$</td>
<td>$0.325 \pm 0.027$</td>
</tr>
<tr>
<td>Sum</td>
<td>14.196</td>
<td>13.751</td>
<td>13.471</td>
<td>13.156</td>
<td>13.024</td>
</tr>
<tr>
<td>Rank</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>Method</td>
<td>LSTM HC</td>
<td>SMILES GA</td>
<td>SysNet</td>
<td>DoG-Gen</td>
<td>DST</td>
</tr>
<tr>
<td>Assembly</td>
<td>SMILES</td>
<td>SMILES</td>
<td>Synthesis</td>
<td>Synthesis</td>
<td>Fragments</td>
</tr>
<tr>
<td>albuterol_similarity</td>
<td>$0.719 \pm 0.018$</td>
<td>$0.661 \pm 0.066$</td>
<td>$0.584 \pm 0.039$</td>
<td>$0.676 \pm 0.013$</td>
<td>$0.619 \pm 0.020$</td>
</tr>
<tr>
<td>amlodipine_mpo</td>
<td>$0.593 \pm 0.016$</td>
<td>$0.549 \pm 0.009$</td>
<td>$0.565 \pm 0.007$</td>
<td>$0.536 \pm 0.003$</td>
<td>$0.516 \pm 0.007$</td>
</tr>
<tr>
<td>celecoxib_rediscovery</td>
<td>$0.539 \pm 0.018$</td>
<td>$0.344 \pm 0.027$</td>
<td>$0.441 \pm 0.027$</td>
<td>$0.464 \pm 0.009$</td>
<td>$0.380 \pm 0.006$</td>
</tr>
<tr>
<td>deco_hop</td>
<td>$\mathbf{0 . 8 2 6} \pm \mathbf{0 . 0 1 7}$</td>
<td>$0.611 \pm 0.006$</td>
<td>$0.613 \pm 0.009$</td>
<td>$0.800 \pm 0.007$</td>
<td>$0.608 \pm 0.008$</td>
</tr>
<tr>
<td>drd2</td>
<td>$0.919 \pm 0.015$</td>
<td>$0.908 \pm 0.019$</td>
<td>$\mathbf{0 . 9 6 9} \pm \mathbf{0 . 0 0 4}$</td>
<td>$0.948 \pm 0.001$</td>
<td>$0.820 \pm 0.014$</td>
</tr>
<tr>
<td>fexofenadine_mpo</td>
<td>$0.725 \pm 0.003$</td>
<td>$0.721 \pm 0.015$</td>
<td>$0.761 \pm 0.015$</td>
<td>$0.695 \pm 0.003$</td>
<td>$0.725 \pm 0.005$</td>
</tr>
<tr>
<td>gsk3b</td>
<td>$0.839 \pm 0.015$</td>
<td>$0.629 \pm 0.044$</td>
<td>$0.789 \pm 0.032$</td>
<td>$0.831 \pm 0.021$</td>
<td>$0.671 \pm 0.032$</td>
</tr>
<tr>
<td>isomers_c7h8n2o2</td>
<td>$0.485 \pm 0.045$</td>
<td>$\mathbf{0 . 9 1 3} \pm \mathbf{0 . 0 2 1}$</td>
<td>$0.455 \pm 0.031$</td>
<td>$0.465 \pm 0.018$</td>
<td>$0.548 \pm 0.069$</td>
</tr>
<tr>
<td>isomers_c9h10n2o2pf2cl</td>
<td>$0.342 \pm 0.027$</td>
<td>$\mathbf{0 . 8 6 0} \pm \mathbf{0 . 0 6 5}$</td>
<td>$0.241 \pm 0.064$</td>
<td>$0.199 \pm 0.016$</td>
<td>$0.458 \pm 0.063$</td>
</tr>
<tr>
<td>jnk3</td>
<td>$0.661 \pm 0.039$</td>
<td>$0.316 \pm 0.022$</td>
<td>$0.630 \pm 0.034$</td>
<td>$0.595 \pm 0.023$</td>
<td>$0.556 \pm 0.057$</td>
</tr>
<tr>
<td>median1</td>
<td>$0.255 \pm 0.010$</td>
<td>$0.192 \pm 0.012$</td>
<td>$0.218 \pm 0.008$</td>
<td>$0.217 \pm 0.001$</td>
<td>$0.232 \pm 0.009$</td>
</tr>
<tr>
<td>median2</td>
<td>$0.248 \pm 0.008$</td>
<td>$0.198 \pm 0.005$</td>
<td>$0.235 \pm 0.006$</td>
<td>$0.212 \pm 0.000$</td>
<td>$0.185 \pm 0.020$</td>
</tr>
<tr>
<td>mestranol_similarity</td>
<td>$0.526 \pm 0.032$</td>
<td>$0.469 \pm 0.029$</td>
<td>$0.399 \pm 0.021$</td>
<td>$0.437 \pm 0.007$</td>
<td>$0.450 \pm 0.027$</td>
</tr>
<tr>
<td>osimertinib_mpo</td>
<td>$0.796 \pm 0.002$</td>
<td>$0.817 \pm 0.011$</td>
<td>$0.796 \pm 0.003$</td>
<td>$0.774 \pm 0.002$</td>
<td>$0.785 \pm 0.004$</td>
</tr>
<tr>
<td>perindopril_mpo</td>
<td>$0.489 \pm 0.007$</td>
<td>$0.447 \pm 0.013$</td>
<td>$\mathbf{0 . 5 5 7} \pm \mathbf{0 . 0 1 1}$</td>
<td>$0.474 \pm 0.002$</td>
<td>$0.462 \pm 0.008$</td>
</tr>
<tr>
<td>qed</td>
<td>$0.939 \pm 0.000$</td>
<td>$0.940 \pm 0.000$</td>
<td>$\mathbf{0 . 9 4 1} \pm \mathbf{0 . 0 0 0}$</td>
<td>$0.934 \pm 0.000$</td>
<td>$0.938 \pm 0.000$</td>
</tr>
<tr>
<td>ranolazine_mpo</td>
<td>$0.714 \pm 0.008$</td>
<td>$0.699 \pm 0.026$</td>
<td>$0.741 \pm 0.010$</td>
<td>$0.711 \pm 0.006$</td>
<td>$0.632 \pm 0.054$</td>
</tr>
<tr>
<td>scaffold_hop</td>
<td>$0.533 \pm 0.012$</td>
<td>$0.494 \pm 0.011$</td>
<td>$0.502 \pm 0.012$</td>
<td>$0.515 \pm 0.005$</td>
<td>$0.497 \pm 0.004$</td>
</tr>
<tr>
<td>sitagliptin_mpo</td>
<td>$0.066 \pm 0.019$</td>
<td>$0.363 \pm 0.057$</td>
<td>$0.025 \pm 0.014$</td>
<td>$0.048 \pm 0.008$</td>
<td>$0.075 \pm 0.032$</td>
</tr>
<tr>
<td>thiothisene_rediscovery</td>
<td>$0.438 \pm 0.008$</td>
<td>$0.315 \pm 0.017$</td>
<td>$0.401 \pm 0.019$</td>
<td>$0.375 \pm 0.004$</td>
<td>$0.366 \pm 0.006$</td>
</tr>
<tr>
<td>troglitazone_rediscovery</td>
<td>$0.354 \pm 0.016$</td>
<td>$0.263 \pm 0.024$</td>
<td>$0.283 \pm 0.008$</td>
<td>$0.416 \pm 0.019$</td>
<td>$0.279 \pm 0.019$</td>
</tr>
<tr>
<td>valsartan_smarts</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
<td>$0.000 \pm 0.000$</td>
</tr>
<tr>
<td>zaleplon_mpo</td>
<td>$0.206 \pm 0.006$</td>
<td>$0.334 \pm 0.041$</td>
<td>$0.341 \pm 0.011$</td>
<td>$0.123 \pm 0.016$</td>
<td>$0.176 \pm 0.045$</td>
</tr>
<tr>
<td>Sum</td>
<td>12.223</td>
<td>12.054</td>
<td>11.498</td>
<td>11.456</td>
<td>10.989</td>
</tr>
<tr>
<td>Rank</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>database; generative models such as VAEs, LSTMs are pretrained on this database; fragments required for JT-VAE, MIMOSA, DST are extracted from this database.</p>
<p>Other details: We tuned hyperparameters for most methods on the average AUC Top-10 from 3 independent runs of two Guacamol tasks: zaleplon_mpo and perindopril_mpo. Reported results are from 5 independent runs with various random seeds. All data, oracle functions, and metric evaluations are taken from the Therapeutic Data Commons (TDC) [14] (https://tdcommons.ai) and more details are described in Appendix. Note that the implementation of sitagliptin_mpo and zaleplon_mpo are different from the ones in Guacamol [13].</p>
<p>Table 3: The ranking of each methods based on different metrics.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">AUC Top-1</th>
<th style="text-align: center;">AUC <br> Top-10</th>
<th style="text-align: center;">AUC <br> Top-100</th>
<th style="text-align: center;">Top-1</th>
<th style="text-align: center;">Top-10</th>
<th style="text-align: center;">Top-100</th>
<th style="text-align: center;">Mean</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">REINVENT</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">Graph GA</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2.33</td>
</tr>
<tr>
<td style="text-align: center;">SELFIES-REINVENT</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3.16</td>
</tr>
<tr>
<td style="text-align: center;">SMILES-LSTM-HC</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4.66</td>
</tr>
<tr>
<td style="text-align: center;">GP BO</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4.83</td>
</tr>
<tr>
<td style="text-align: center;">STONED</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">5.66</td>
</tr>
<tr>
<td style="text-align: center;">DoG-GEN</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">7.5</td>
</tr>
<tr>
<td style="text-align: center;">SMILES GA</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
</tr>
<tr>
<td style="text-align: center;">DST</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">9.66</td>
</tr>
<tr>
<td style="text-align: center;">SynNet</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">10</td>
</tr>
<tr>
<td style="text-align: center;">SELFIES-LSTM-HC</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">11.33</td>
</tr>
<tr>
<td style="text-align: center;">MIMOSA</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">12</td>
</tr>
<tr>
<td style="text-align: center;">MARS</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">12.16</td>
</tr>
<tr>
<td style="text-align: center;">MolPAL</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">13.66</td>
</tr>
<tr>
<td style="text-align: center;">GA+D</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">15.83</td>
</tr>
<tr>
<td style="text-align: center;">DoG-AE</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">16.33</td>
</tr>
<tr>
<td style="text-align: center;">GFlowNet</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">17</td>
</tr>
<tr>
<td style="text-align: center;">SELFIES-VAE</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">18.33</td>
</tr>
<tr>
<td style="text-align: center;">Screening</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">18.5</td>
</tr>
<tr>
<td style="text-align: center;">SMILES-VAE</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">19.66</td>
</tr>
<tr>
<td style="text-align: center;">GFlowNet-AL</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">20.66</td>
</tr>
<tr>
<td style="text-align: center;">Pasithca</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">21.33</td>
</tr>
<tr>
<td style="text-align: center;">JT-VAE</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">22.33</td>
</tr>
<tr>
<td style="text-align: center;">Graph MCTS</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td style="text-align: center;">MolDQN</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">25</td>
</tr>
</tbody>
</table>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The optimization curves of top-10 average on optimizing isomer_c9h10n2o2pf2cl and celecoxib_rediscovery, as the representation of isomer-type and similarity-type oracles. Only 8 methods are displayed for clarity and full results are in the Appendix A.</p>
<h1>3.2 Results \&amp; Analysis</h1>
<p>The primary results are summarized in Table 2 and 3. For clarity, we only show the ten bestperforming models in the table. We show a selective set of optimization curves in Figure 1. The remaining results are in the Appendix A and D.</p>
<p>Sample efficiency matters. A first observation from the results is that none of the methods we implemented can optimize the simple toy objectives within hundreds of oracle calls under our experimental settings, except some trivial ones like QED, DRD2, and osimertinib_mpo, which emphasize the need for more efficient molecular optimization algorithms. By comparing the ranking of AUC Top-10 and Top-10, we notice some methods have significantly different relative performances. For example, SMILES LSTM HC, which used to be seen as comparable to Graph GA, actually requires more oracle queries to achieve the same level of performance, while a related algorithm, REINVENT, requires far fewer (see Figure 1). These differences indicate the training algorithm of REINVENT is more efficient than HC, emphasizing the importance of AUC Top-10 as an evaluation metric. In addition, methods that assemble molecules either token-by-token or atom-by-atom from a single start point, such as GA+D, MolDQN, and Graph MCTS, are most data-inefficient. Those methods potentially cover broader chemical space and include many undesired candidates, such as unstable or unsynthesizable ones, which wastes a significant portion of the oracle budget and also imposes a strong requirement on the oracles' quality.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" />
(a) Comparison between SMILES- and SELFIES-based methods. Note GA is not a head-to-head comparison.
(b) Comparison between model-free and corresponding model-based methods.</p>
<p>Figure 2: Each point represents the AUC Top-10 of one task, with x-axis the SMILES variant and y-axis the SELFIES variant of the same method. Colors are labeled by the optimization algorithms. The fractions of the tasks above the parity line are in parentheses.</p>
<p>Older algorithms are still powerful. As shown in Table 2 and 3, the best-performing algorithms are REINVENT and Graph GA among all the compared methods, despite both of them being released several years ago. However, we rarely see model development papers list these two methods as baselines. The absence of a thorough benchmark has obfuscated the fact that newer models published in top AI conferences do not seem to offer an improvement in performance by our metrics. Of course, we should acknowledge that some of the methods are developed to solve other problems in molecular optimization, such as strings' validity or synthesizability, and some might have opened new avenues to tackle the problem that could potentially be more efficient when mature. Still, some of the field's efforts and resources might be wasted due to a lack of a thorough and standardized benchmark.</p>
<p>There are no obvious shortcomings of SMILES. SELFIES was designed as a substitute of SMILES to solve the syntactical invalidity problem met in SMILES representation and has been adopted by a number of recent studies. However, our head-to-head comparison of string-based methods, especially the ones leveraging language models, shows that most SELFIES variants cannot outperform their corresponding SMILES-based methods in terms of optimization ability and sample efficiency (Figure 2a). We do observe some early methods like the initial version of SMILES VAE [6] (2016) and ORGAN [31] (2017) struggle to propose valid SMILES strings, but this is not an issue for more recent methods. We believe this is partially because current language models are better able to learn the grammar of SMILES strings, which has flattened the advantage of SELFIES. Further, as shown in Appendix D.1, more combinations of SELFIES tokens don't necessarily explore larger chemical space but might map to a small number of valid molecules that can be represented by truncated SELFIES strings, which implies that there are still syntax requirements in generating SELFIES strings to achieve effective exploration.</p>
<p>On the other hand, we observe a clear advantage of SELFIES-based GA compared to SMILES-based one, which indicates that SELFIES has an advantage over SMILES when we need to design the rules to manipulate the sequence. However, we should note that the comparison is not head-tohead, as GAs' performances highly depend on the mutation and crossover rule design, but not the representation. Graph GA's mutation rules are also encoded in SMARTS strings and operate on SMILES strings, which can also be seen as SMILES modification steps. Overall, when we need to design the generative action manually, the assembly strategy that could derive desired transformation more intuitively should be preferred.</p>
<p>Model-based methods are potentially more efficient but need careful design. It is widely recognized in the RL community that model-based optimization methods that explicitly leverage a predictive model ("world model") are more sample efficient than the model-free ones [60]. Our results on MolPAL and screening verify the principle that training a predictive model is beneficial compared to random sampling (see Figure 2b). However, the results of Graph GA (model-based variant: GP BO) and GFlowNet (model-based variant: GFlowNet-AL) indicate that simply adding a predictive model might not necessarily be helpful. GP BO outperformed Graph GA in 12 tasks among 23, but Graph GA outperformed GP BO in the summation. GFlowNet outperformed GFlowNet-AL in almost every task. From the step-wise increment behavior (see Figure 1) and hyper-parameter</p>
<p>Figure 3: The heatmap and the clustering of oracles based on relative AUC Top-10. Relative AUC Top-10 is computed by normalizing AUC Top-10 values to a range from the lowest and the highest value within the task. The zaleplon_mpo and sitagliptin_mpo are multi-objective versions of isomer functions [13], while all other MPOs are based on similarity. Clear patterns emerge between a large cluster of similarity-based oracles, four isomer-based oracles, and other non-clustered ones. Different types of landscape are more suitable for different kinds of methods to explore. The cluster tree was calculated with unweighted pair group method with arithmetic mean (UPGMA) using Euclidean distance.
<img alt="img-2.jpeg" src="img-2.jpeg" />
tuning of GP BO (Appendix D.2), we conclude that the performance bottleneck is mainly the quality of the predictive model. Further, GFlowNet-AL adopts a relatively naive model-based strategy that may suppress exploitation, especially when the model is not well-trained. Overall, we observe that model-based optimization algorithms have the potential to be more sample efficient but require careful design of the inner- and outer-loop optimization algorithms so the model does not lead the search astray.</p>
<p>Different types of methods are more suitable for different kinds of landscapes. As shown from Figure 3 and Table 2, we find that there are some clear clusters of oracles based on the relative performance of methods. One clear pattern is that string-based GAs, such as SMILES GA and STONED, reach superior relative performance in tasks involving isomer functions, including isomer_c7h8n2o2, isomer_c9h10n2o2pf2cl, sitagliptin_mpo, and zaleplon_mpo. Isomer-type oracles are summations of atomic contribution, while all other MPOs are mainly based on similarity measured by fingerprints, and they generally have closer relative performance. Among similarity-based oracles, the ones including $\log \mathrm{P}$ and TPSA, such as fexofenadine_mpo and osimertinib_mpo, are clustered together against more naive similarities such as the rediscovery and median ones. The machine learning oracles predicting bioactivities belong to the same cluster of similarity-based oracles. While QED is too trivial that almost all methods reach very close values, deco_hop, valsartan_smarts, scaffold_hop that are designed based on whether a molecule contains a substructure have varied performance. The results suggest that different types of landscape are better explored by different kinds of methods, such as string-based GA on isomer-type oracles. It is not evident which type of oracle is closest to a "true" pharmaceutical design objective, which is likely more complex and challenging to optimize; we leave further investigation on oracle landscapes and their influence on optimization to future work.</p>
<p>Hyperparameter reoptimization and multiple runs are required when reporting results. We also observed that the optimal set of hyper-parameters is always not the default ones suggested by a method's original paper (see Appendix D.2). For example, REINVENT's performance is highly dependent on $\sigma$; we found the best-performing value to be much larger than the values suggested in the original paper (see Figure 15 and 14) [5]. We conclude that this is due to unique demands of our setting of limited oracle budget, which was not a goal of the original study, and thus suggest reoptimizing the hyper-parameters whenever the testing environment is changed. Another challenge is the non-determinism of most algorithms. For example, Graph GA suffers from a relatively</p>
<p>large variance due to its random-walk-like exploration, as does GP BO. If the oracle were a costly experimental evaluation, we might consider the worst-case performance as an endpoint to reduce the risk rather than the average performance, highlighting the importance of running multiple independent runs and reporting the distribution of outcomes.</p>
<h1>4 Conclusions</h1>
<p>This paper proposes PMO: a standardized molecular design benchmark focusing on sample efficiency as a key impediment to experimental adoption. We conduct a thorough investigation across 25 methods and 23 objectives to determine the current state-of-the-art, investigate problems, and draw insights for future studies. Our primary observations are that (1) methods considered to be strong baselines, like LSTM HC, may be inefficient in data usage; (2) several older methods, like REINVENT and Graph GA, outperform more recent ones; (3) SELFIES does not seem to offer an immediate benefit in optimization performance compared to SMILES except in GA; (4) model-based methods have the potential to be more sample efficient but require careful design of the inner-loop, outer-loop, and the predictive model; and (5) different optimization algorithms may excel at different tasks, determined by the landscapes of oracle functions; which algorithm to select is still dependent on the use case and the type of tasks.</p>
<p>We acknowledge several limitations of the current study: we cannot exhaustively explore every method and thoroughly tune every hyperparameter, the representative methods we implement might not be the best-in-class among all possible variants, our conclusion might be biased toward similarity-based oracles, and we are not thoroughly investigating other important quantities such as synthesizability [61] and diversity [14]. We also emphasize that our experiments consider the number of oracle calls from scratch, i.e., the data used to train the surrogate models in model-based methods are counted in the total budget. If a dataset has been collected previously, it may be prudent to train a surrogate model on this information and use a model-based method as illustrated by Tripp et al. [15]. We will support the continued development of this benchmark to minimize the wasted effort caused by non-reproducibility and poor baselines to boost the field's growth toward solving practical molecular design problems.
We would like to conclude with recommendations for subsequent studies: (1) When comparing baselines, it is important to run algorithms under the same oracle budgets; (2) For general-purpose molecular design algorithms, one should test on multiple types of oracles; (3) Conducting multiple independent runs and reporting the distribution of outcomes is critical for non-deterministic methods; (4) Whenever the tasks and testing environment are changed, hyperparameter tuning is necessary.</p>
<h2>Acknowledgments and Disclosure of Funding</h2>
<p>This research was supported by the Office of Naval Research under grant number N00014-21-1-2195 and the Machine Learning for Pharmaceutical Discovery and Synthesis consortium. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Office of Naval Research. W.G. received additional funding from MIT-Takeda fellowship. T.F. and J.S. were supported by NSF award SCH-2205289, SCH-2014438, IIS-1838042, NIH award R01 1R01NS107291-01. We thank Samuel Goldman and John Bradshaw for commenting on the manuscript.</p>
<h2>Reproducibility Statement</h2>
<p>All code, parameters, and releasable data can be found at https://github.com/wenhao-gao/ mol_opt, including instructions in a README file. All results generated in this experiment can be found at https://figshare.com/articles/dataset/Results_for_practical_ molecular_optimization_PMO_benchmark/20123453. Appendix B describe the experimental setup, implementation details, datasets used, and hardware configuration.</p>
<h1>References</h1>
<p>[1] Jan H Jensen. A graph-based genetic algorithm and generative model/monte carlo tree search for the exploration of chemical space. Chemical science, 10(12):3567-3572, 2019.
[2] Yutong Xie, Chence Shi, Hao Zhou, Yuwei Yang, Weinan Zhang, Yong Yu, and Lei Li. MARS: Markov molecular sampling for multi-objective drug discovery. In ICLR, 2021.
[3] David E Graff, Eugene I Shakhnovich, and Connor W Coley. Accelerating high-throughput virtual screening through molecular pool-based active learning. Chemical science, 12(22):78667881, 2021.
[4] Francesco Gentile, Jean Charle Yaacoub, James Gleave, Michael Fernandez, Anh-Tien Ton, Fuqiang Ban, Abraham Stern, and Artem Cherkasov. Artificial intelligence-enabled virtual screening of ultra-large chemical libraries with deep docking. Nature Protocols, pages 1-26, 2022.
[5] Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen. Molecular de-novo design through deep reinforcement learning. Journal of cheminformatics, 9(1):1-14, 2017.
[6] Rafael Gómez-Bombarelli, Jennifer N Wei, David Duvenaud, José Miguel Hernández-Lobato, Benjamín Sánchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Alán Aspuru-Guzik. Automatic chemical design using a data-driven continuous representation of molecules. ACS central science, 2018.
[7] Matt J Kusner, Brooks Paige, and José Miguel Hernández-Lobato. Grammar variational autoencoder. In International Conference on Machine Learning, pages 1945-1954. PMLR, 2017.
[8] Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Junction tree variational autoencoder for molecular graph generation. ICML, 2018.
[9] Mario Krenn, Florian Häse, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. Self-referencing embedded strings (SELFIES): A 100\% robust molecular string representation. Machine Learning: Science and Technology, 1(4):045024, 2020.
[10] Yoshua Bengio, Tristan Deleu, Edward J. Hu, Salem Lahlou, Mo Tiwari, and Emmanuel Bengio. GFlowNet foundations. CoRR, abs/2111.09266, 2021.
[11] John Bradshaw, Brooks Paige, Matt J Kusner, Marwin Segler, and José Miguel HernándezLobato. Barking up the right tree: an approach to search over molecule synthesis dags. Advances in Neural Information Processing Systems, 33:6852-6866, 2020.
[12] Wenhao Gao, Rocío Mercado, and Connor W Coley. Amortized tree generation for bottom-up synthesis planning and synthesizable molecular design. International Conference on Learning Representations, 2022.
[13] Nathan Brown, Marco Fiscato, Marwin HS Segler, and Alain C Vaucher. GuacaMol: benchmarking models for de novo molecular design. Journal of chemical information and modeling, 59(3):1096-1108, 2019.
[14] Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec, Connor W Coley, Cao Xiao, Jimeng Sun, and Marinka Zitnik. Therapeutics data commons: Machine learning datasets and tasks for therapeutics. NeurIPS Track Datasets and Benchmarks, 2021.
[15] Austin Tripp, Gregor NC Simm, and José Miguel Hernández-Lobato. A fresh look at de novo molecular design benchmarks. In NeurIPS 2021 AI for Science Workshop, 2021.
[16] Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N Zare, and Patrick Riley. Optimization of molecules via deep reinforcement learning. Scientific reports, 9(1):1-10, 2019.
[17] AkshatKumar Nigam, Pascal Friederich, Mario Krenn, and Alán Aspuru-Guzik. Augmenting genetic algorithms with deep neural networks for exploring the chemical space. In ICLR, 2020.</p>
<p>[18] Sai Krishna Gottipati, Boris Sattarov, Sufeng Niu, Yashaswi Pathak, Haoran Wei, Shengchao Liu, Simon Blackburn, Karam Thomas, Connor Coley, Jian Tang, et al. Learning to navigate the synthetically accessible chemical space using reinforcement learning. In International Conference on Machine Learning, pages 3668-3679. PMLR, 2020.
[19] Ksenia Korovina, Sailun Xu, Kirthevasan Kandasamy, Willie Neiswanger, Barnabas Poczos, Jeff Schneider, and Eric Xing. ChemBO: Bayesian optimization of small organic molecules with synthesizable recommendations. In International Conference on Artificial Intelligence and Statistics, pages 3393-3403. PMLR, 2020.
[20] Tianfan Fu, Wenhao Gao, Cao Xiao, Jacob Yasonik, Connor W Coley, and Jimeng Sun. Differentiable scaffolding tree for molecular optimization. International Conference on Learning Representations, 2022.
[21] Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow network based generative models for non-iterative diverse candidate generation. Advances in Neural Information Processing Systems, 34, 2021.
[22] Natalie Maus, Haydn T Jones, Juston S Moore, Matt J Kusner, John Bradshaw, and Jacob R Gardner. Local latent space bayesian optimization over structured inputs. arXiv preprint arXiv:2201.11872, 2022.
[23] Antoine Grosnit, Rasul Tutunov, Alexandre Max Maraval, Ryan-Rhys Griffiths, Alexander I Cowen-Rivers, Lin Yang, Lin Zhu, Wenlong Lyu, Zhitang Chen, Jun Wang, et al. Highdimensional Bayesian optimisation with variational autoencoders and deep metric learning. arXiv preprint arXiv:2106.03609, 2021.
[24] G Richard Bickerton, Gaia V Paolini, Jérémy Besnard, Sorel Muresan, and Andrew L Hopkins. Quantifying the chemical beauty of drugs. Nature chemistry, 4(2):90, 2012.
[25] Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec. Graph convolutional policy network for goal-directed molecular graph generation. Advances in neural information processing systems, 31, 2018.
[26] Regine S Bohacek, Colin McMartin, and Wayne C Guida. The art and practice of structurebased drug design: a molecular modeling perspective. Medicinal research reviews, 16(1):3-50, 1996.
[27] Brian Goldman, Steven Kearnes, Trevor Kramer, Patrick Riley, and W Patrick Walters. Defining levels of automated chemical design. Journal of Medicinal Chemistry, 2022.
[28] Wenhao Gao, Priyanka Raghavan, and Connor W Coley. Autonomous platforms for data-driven organic synthesis. Nature Communications, 13(1):1-4, 2022.
[29] AkshatKumar Nigam, Robert Pollice, Mario Krenn, Gabriel dos Passos Gomes, and Alan Aspuru-Guzik. Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES. Chemical science, 12(20):7079-7090, 2021.
[30] Henry Moss, David Leslie, Daniel Beck, Javier Gonzalez, and Paul Rayson. BOSS: Bayesian optimization over string spaces. Advances in neural information processing systems, 33:1547615486, 2020.
[31] Benjamin Sanchez-Lengeling, Carlos Outeiral, Gabriel L Guimaraes, and Alan Aspuru-Guzik. Optimizing distributions over molecular space. an objective-reinforced generative adversarial network for inverse-design chemistry (ORGANIC). 2017.
[32] Nicola De Cao and Thomas Kipf. MolGAN: An implicit generative model for small molecular graphs. arXiv preprint arXiv:1805.11973, 2018.
[33] Tianfan Fu, Cao Xiao, Xinhao Li, Lucas M Glass, and Jimeng Sun. MIMOSA: Multi-constraint molecule sampling for molecule optimization. AAAI, 2021.</p>
<p>[34] Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Multi-objective molecule generation using interpretable substructures. In International Conference on Machine Learning, pages 4849-4859. PMLR, 2020.
[35] Soojung Yang, Doyeong Hwang, Seul Lee, Seongok Ryu, and Sung Ju Hwang. Hit and lead discovery with explorative RL and fragment-based molecule generation. Advances in Neural Information Processing Systems, 34, 2021.
[36] Julien Horwood and Emmanuel Noutahi. Molecular design in synthetically accessible chemical space via deep reinforcement learning. ACS omega, 5(51):32984-32994, 2020.
[37] Cynthia Shen, Mario Krenn, Sagi Eppel, and Alan Aspuru-Guzik. Deep molecular dreaming: Inverse machine learning for de-novo molecular design and interpretability with surjective representations. Machine Learning: Science and Technology, 2021.
[38] David Weininger. SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. Journal of chemical information and computer sciences, 28(1):31-36, 1988.
[39] Jakob Lykke Andersen, Christoph Flamm, Daniel Merkle, and Peter F Stadler. Chemical graph transformation with stereo-information. In International Conference on Graph Transformation, pages 54-69. Springer, 2017.
[40] Lagnajit Pattanaik, Octavian-Eugen Ganea, Ian Coley, Klavs F Jensen, William H Green, and Connor W Coley. Message passing networks for molecules with tetrahedral chirality. arXiv preprint arXiv:2012.00094, 2020.
[41] Keir Adams, Lagnajit Pattanaik, and Connor W Coley. Learning 3D representations of molecular chirality with invariance to bond rotations. International Conference on Learning Representations, 2022.
[42] Teague Sterling and John J Irwin. ZINC 15-ligand discovery for everyone. Journal of chemical information and modeling, 55(11):2324-2337, 2015.
[43] Fredrik Svensson, Ulf Norinder, and Andreas Bender. Improving screening efficiency through iterative screening using docking and conformal prediction. Journal of chemical information and modeling, 57(3):439-444, 2017.
[44] José Miguel Hernández-Lobato, James Requeima, Edward O Pyzer-Knapp, and Alán AspuruGuzik. Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical space. In International conference on machine learning, pages 1470-1479. PMLR, 2017.
[45] Laeeq Ahmed, Valentin Georgiev, Marco Capuccini, Salman Toor, Wesley Schaal, Erwin Laure, and Ola Spjuth. Efficient iterative virtual screening with Apache Spark and conformal prediction. Journal of cheminformatics, 10(1):1-8, 2018.
[46] Francesco Gentile, Vibudh Agrawal, Michael Hsing, Anh-Tien Ton, Fuqiang Ban, Ulf Norinder, Martin E Gleave, and Artem Cherkasov. Deep docking: A deep learning platform for augmentation of structure based drug discovery. ACS central science, 6(6):939-949, 2020.
[47] David E Graff, Matteo Aldeghi, Joseph A Morrone, Kirk E Jordan, Edward O Pyzer-Knapp, and Connor W Coley. Self-focusing virtual screening with active design space pruning. arXiv preprint arXiv:2205.01753, 2022.
[48] Naruki Yoshikawa, Kei Terayama, Masato Sumita, Teruki Homma, Kenta Oono, and Koji Tsuda. Population-based de novo molecule generation, using grammatical evolution. Chemistry Letters, 47(11):1431-1434, 2018.
[49] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE, 104(1):148-175, 2015.</p>
<p>[50] Marc Deisenroth and Jun Wei Ng. Distributed Gaussian processes. In International Conference on Machine Learning, pages 1481-1490. PMLR, 2015.
[51] Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. International Conference on Learning Representations (ICLR), 2014.
[52] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. Advances in neural information processing systems, 33, 2020.
[53] Daniil Polykovskiy, Alexander Zhebrak, Benjamin Sanchez-Lengeling, Sergey Golovanov, Oktai Tatanov, Stanislav Belyaev, Rauf Kurbanov, Aleksey Artamonov, Vladimir Aladinskiy, Mark Veselov, et al. Molecular sets (MOSES): A benchmarking platform for molecular generation models. Frontiers in pharmacology, 2020.
[54] Pieter-Tjerk De Boer, Dirk P Kroese, Shie Mannor, and Reuven Y Rubinstein. A tutorial on the cross-entropy method. Annals of operations research, 134(1):19-67, 2005.
[55] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3):229-256, 1992.
[56] Austin Tripp, Wenlin Chen, and José Miguel Hernández-Lobato. An evaluation framework for the objective functions of de novo drug design benchmarks. In ICLR2022 Machine Learning for Drug Discovery, 2022.
[57] Yibo Li, Liangren Zhang, and Zhenming Liu. Multi-objective de novo drug design with conditional graph generative model. Journal of cheminformatics, 10(1):1-24, 2018.
[58] Tobiasz Cieplinski, Tomasz Danel, Sabina Podlewska, and Stanislaw Jastrzebski. We should at least be able to design molecules that dock well. arXiv preprint arXiv:2006.16955, 2020.
[59] Miguel García-Ortegón, Gregor NC Simm, Austin J Tripp, José Miguel Hernández-Lobato, Andreas Bender, and Sergio Bacallado. DOCKSTRING: Easy molecular docking yields better benchmarks for ligand design. Journal of Chemical Information and Modeling, 2021.
[60] Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, and Jimmy Ba. Benchmarking model-based reinforcement learning. arXiv preprint arXiv:1907.02057, 2019.
[61] Wenhao Gao and Connor W Coley. The synthesizability of molecules proposed by generative models. Journal of chemical information and modeling, 60(12):5714-5723, 2020.
[62] Michalis Titsias. Variational learning of inducing variables in sparse Gaussian processes. In Artificial intelligence and statistics, pages 567-574. PMLR, 2009.
[63] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. PyTorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019.
[64] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. International Conference on Learning Representations, 2014.
[65] Aditya R Thawani, Ryan-Rhys Griffiths, Arian Jamasb, Anthony Bourached, Penelope Jones, William McCorkindale, Alexander A Aldrick, and Alpha A Lee. The photoswitch dataset: a molecular machine learning benchmark for the advancement of synthetic chemistry. arXiv preprint arXiv:2008.03226, 2020.
[66] Alice Capecchi, Daniel Probst, and Jean-Louis Reymond. One molecular fingerprint to rule them all: drugs, biomolecules, and the metabolome. Journal of cheminformatics, 12(1):1-15, 2020.
[67] Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A Hunter, Costas Bekas, and Alpha A Lee. Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction. ACS central science, 5(9):1572-1583, 2019.</p>
<p>[68] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.
[69] Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Carlos Outeiral, Pedro Luis Cunha Farias, and Alán Aspuru-Guzik. Objective-reinforced generative adversarial networks (ORGAN) for sequence generation models. arXiv preprint arXiv:1705.10843, 2017.
[70] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical Bayesian optimization of machine learning algorithms. Advances in neural information processing systems, 25, 2012.
[71] Choon Hui Teo and S.V.N. Vishwanathan. Fast and space efficient string kernels using suffix arrays. In Proceedings of the 23rd international conference on Machine learning, pages 929-936, 2006.
[72] Lukas Biewald. Experiment tracking with weights and biases, 2020. Software available from wandb.com.</p>
<h1>Checklist</h1>
<ol>
<li>For all authors...
(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]
(b) Did you describe the limitations of your work? [Yes] See Section 4.
(c) Did you discuss any potential negative societal impacts of your work? [N/A]
(d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]</li>
<li>If you are including theoretical results...
(a) Did you state the full set of assumptions of all theoretical results? [N/A]
(b) Did you include complete proofs of all theoretical results? [N/A]</li>
<li>If you ran experiments (e.g. for benchmarks)...
(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] All code, parameters, and releasable data can be found at https://github.com/wenhao-gao/ mol_opt, including instructions in a README file. Appendix B describe the experimental setup, implementation details, datasets used, and hardware configuration.
(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] Please see Section B.
(c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes] Please see Table 2.
(d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] Please see Section C.2.</li>
<li>
<p>If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
(a) If your work uses existing assets, did you cite the creators? [Yes]
(b) Did you mention the license of the assets? [Yes] Please see Section C. 3 for details.
(c) Did you include any new assets either in the supplemental material or as a URL? [Yes] We release the code repository at https://github.com/wenhao-gao/mol_opt, including instructions in a README file. Appendix B and C describe the experimental setup, implementation details, datasets used, and hardware configuration.
(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] All the data/codes we use are publicly available. Please see Section B for details.
(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes] Our paper does not involve human subjects research. It also does not contain any personally identifiable information or offensive content.</p>
</li>
<li>
<p>If you used crowdsourcing or conducted research with human subjects...
(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A]
(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A]
(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]</p>
</li>
</ol>
<h1>A Main Results</h1>
<h2>A. 1 AUC Top-10 Table</h2>
<p>Table 4: We report the mean and standard deviation of AUC Top-10 from 5 independent runs. We ranked the methods by the summation of mean AUC Top-10 of all tasks. (Continued)</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">REINVENT</th>
<th style="text-align: center;">Graph GA</th>
<th style="text-align: center;">REINVENT <br> SELFIES</th>
<th style="text-align: center;">GP BO</th>
<th style="text-align: center;">STONED</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Assembly</td>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">Fragments</td>
<td style="text-align: center;">SELFIES</td>
<td style="text-align: center;">Fragments</td>
<td style="text-align: center;">SELFIES</td>
</tr>
<tr>
<td style="text-align: center;">albuterol_similarity</td>
<td style="text-align: center;">$0.882 \pm 0.006$</td>
<td style="text-align: center;">$0.838 \pm 0.016$</td>
<td style="text-align: center;">$0.826 \pm 0.030$</td>
<td style="text-align: center;">0.890 $\pm 0.014$</td>
<td style="text-align: center;">$0.745 \pm 0.076$</td>
</tr>
<tr>
<td style="text-align: center;">amlodipine_mpo</td>
<td style="text-align: center;">$0.635 \pm 0.035$</td>
<td style="text-align: center;">$0.661 \pm 0.020$</td>
<td style="text-align: center;">$0.607 \pm 0.014$</td>
<td style="text-align: center;">$0.583 \pm 0.044$</td>
<td style="text-align: center;">$0.608 \pm 0.046$</td>
</tr>
<tr>
<td style="text-align: center;">celecoxib_rediscovery</td>
<td style="text-align: center;">$0.713 \pm 0.067$</td>
<td style="text-align: center;">$0.630 \pm 0.097$</td>
<td style="text-align: center;">$0.573 \pm 0.043$</td>
<td style="text-align: center;">$0.723 \pm 0.053$</td>
<td style="text-align: center;">$0.382 \pm 0.041$</td>
</tr>
<tr>
<td style="text-align: center;">deco_hop</td>
<td style="text-align: center;">$0.666 \pm 0.044$</td>
<td style="text-align: center;">$0.619 \pm 0.004$</td>
<td style="text-align: center;">$0.631 \pm 0.012$</td>
<td style="text-align: center;">$0.629 \pm 0.018$</td>
<td style="text-align: center;">$0.611 \pm 0.008$</td>
</tr>
<tr>
<td style="text-align: center;">dsd2</td>
<td style="text-align: center;">$0.945 \pm 0.007$</td>
<td style="text-align: center;">$0.964 \pm 0.012$</td>
<td style="text-align: center;">$0.943 \pm 0.005$</td>
<td style="text-align: center;">$0.923 \pm 0.017$</td>
<td style="text-align: center;">$0.913 \pm 0.020$</td>
</tr>
<tr>
<td style="text-align: center;">fexofenadine_mpo</td>
<td style="text-align: center;">$0.784 \pm 0.006$</td>
<td style="text-align: center;">$0.760 \pm 0.011$</td>
<td style="text-align: center;">$0.741 \pm 0.002$</td>
<td style="text-align: center;">$0.722 \pm 0.005$</td>
<td style="text-align: center;">$0.797 \pm 0.016$</td>
</tr>
<tr>
<td style="text-align: center;">gsk3b</td>
<td style="text-align: center;">$0.865 \pm 0.043$</td>
<td style="text-align: center;">$0.788 \pm 0.070$</td>
<td style="text-align: center;">$0.780 \pm 0.037$</td>
<td style="text-align: center;">$0.851 \pm 0.041$</td>
<td style="text-align: center;">$0.668 \pm 0.049$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c7h8n2o2</td>
<td style="text-align: center;">$0.852 \pm 0.036$</td>
<td style="text-align: center;">$0.862 \pm 0.065$</td>
<td style="text-align: center;">$0.849 \pm 0.034$</td>
<td style="text-align: center;">$0.680 \pm 0.117$</td>
<td style="text-align: center;">$0.899 \pm 0.011$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c9h10n2o2pf2cl</td>
<td style="text-align: center;">$0.642 \pm 0.054$</td>
<td style="text-align: center;">$0.719 \pm 0.047$</td>
<td style="text-align: center;">$0.733 \pm 0.029$</td>
<td style="text-align: center;">$0.469 \pm 0.180$</td>
<td style="text-align: center;">$0.805 \pm 0.031$</td>
</tr>
<tr>
<td style="text-align: center;">jnk3</td>
<td style="text-align: center;">$0.783 \pm 0.023$</td>
<td style="text-align: center;">$0.553 \pm 0.136$</td>
<td style="text-align: center;">$0.631 \pm 0.064$</td>
<td style="text-align: center;">$0.564 \pm 0.155$</td>
<td style="text-align: center;">$0.523 \pm 0.092$</td>
</tr>
<tr>
<td style="text-align: center;">median1</td>
<td style="text-align: center;">$0.356 \pm 0.009$</td>
<td style="text-align: center;">$0.294 \pm 0.021$</td>
<td style="text-align: center;">$0.355 \pm 0.011$</td>
<td style="text-align: center;">$0.301 \pm 0.014$</td>
<td style="text-align: center;">$0.266 \pm 0.016$</td>
</tr>
<tr>
<td style="text-align: center;">median2</td>
<td style="text-align: center;">$0.276 \pm 0.008$</td>
<td style="text-align: center;">$0.273 \pm 0.009$</td>
<td style="text-align: center;">$0.255 \pm 0.005$</td>
<td style="text-align: center;">$0.297 \pm 0.009$</td>
<td style="text-align: center;">$0.245 \pm 0.032$</td>
</tr>
<tr>
<td style="text-align: center;">mestranol_similarity</td>
<td style="text-align: center;">$0.618 \pm 0.048$</td>
<td style="text-align: center;">$0.579 \pm 0.022$</td>
<td style="text-align: center;">$0.620 \pm 0.029$</td>
<td style="text-align: center;">$0.627 \pm 0.089$</td>
<td style="text-align: center;">$0.609 \pm 0.101$</td>
</tr>
<tr>
<td style="text-align: center;">osimertinib_mpo</td>
<td style="text-align: center;">$0.837 \pm 0.009$</td>
<td style="text-align: center;">$0.831 \pm 0.005$</td>
<td style="text-align: center;">$0.820 \pm 0.003$</td>
<td style="text-align: center;">$0.787 \pm 0.006$</td>
<td style="text-align: center;">$0.822 \pm 0.012$</td>
</tr>
<tr>
<td style="text-align: center;">perindopril_mpo</td>
<td style="text-align: center;">$0.537 \pm 0.016$</td>
<td style="text-align: center;">$0.538 \pm 0.009$</td>
<td style="text-align: center;">$0.517 \pm 0.021$</td>
<td style="text-align: center;">$0.493 \pm 0.011$</td>
<td style="text-align: center;">$0.488 \pm 0.011$</td>
</tr>
<tr>
<td style="text-align: center;">qed</td>
<td style="text-align: center;">$0.941 \pm 0.000$</td>
<td style="text-align: center;">$0.940 \pm 0.000$</td>
<td style="text-align: center;">$0.940 \pm 0.000$</td>
<td style="text-align: center;">$0.937 \pm 0.000$</td>
<td style="text-align: center;">$0.941 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">ranolazine_mpo</td>
<td style="text-align: center;">$0.760 \pm 0.009$</td>
<td style="text-align: center;">$0.728 \pm 0.012$</td>
<td style="text-align: center;">$0.748 \pm 0.018$</td>
<td style="text-align: center;">$0.735 \pm 0.013$</td>
<td style="text-align: center;">$0.765 \pm 0.029$</td>
</tr>
<tr>
<td style="text-align: center;">scaffold_hop</td>
<td style="text-align: center;">$0.560 \pm 0.019$</td>
<td style="text-align: center;">$0.517 \pm 0.007$</td>
<td style="text-align: center;">$0.525 \pm 0.013$</td>
<td style="text-align: center;">$0.548 \pm 0.019$</td>
<td style="text-align: center;">$0.521 \pm 0.034$</td>
</tr>
<tr>
<td style="text-align: center;">sitagliptin_mpo</td>
<td style="text-align: center;">$0.021 \pm 0.003$</td>
<td style="text-align: center;">$0.433 \pm 0.075$</td>
<td style="text-align: center;">$0.194 \pm 0.121$</td>
<td style="text-align: center;">$0.186 \pm 0.055$</td>
<td style="text-align: center;">$0.393 \pm 0.083$</td>
</tr>
<tr>
<td style="text-align: center;">thiothixene_rediscovery</td>
<td style="text-align: center;">$0.534 \pm 0.013$</td>
<td style="text-align: center;">$0.479 \pm 0.025$</td>
<td style="text-align: center;">$0.495 \pm 0.040$</td>
<td style="text-align: center;">$0.559 \pm 0.027$</td>
<td style="text-align: center;">$0.367 \pm 0.027$</td>
</tr>
<tr>
<td style="text-align: center;">troglitazone_rediscovery</td>
<td style="text-align: center;">$0.441 \pm 0.032$</td>
<td style="text-align: center;">$0.390 \pm 0.016$</td>
<td style="text-align: center;">$0.348 \pm 0.012$</td>
<td style="text-align: center;">$0.410 \pm 0.015$</td>
<td style="text-align: center;">$0.320 \pm 0.018$</td>
</tr>
<tr>
<td style="text-align: center;">valsartan_smarin</td>
<td style="text-align: center;">$0.179 \pm 0.358$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">zaleplon_mpo</td>
<td style="text-align: center;">$0.358 \pm 0.062$</td>
<td style="text-align: center;">$0.346 \pm 0.032$</td>
<td style="text-align: center;">$0.333 \pm 0.026$</td>
<td style="text-align: center;">$0.221 \pm 0.072$</td>
<td style="text-align: center;">$0.325 \pm 0.027$</td>
</tr>
<tr>
<td style="text-align: center;">Sum</td>
<td style="text-align: center;">14.196</td>
<td style="text-align: center;">13.751</td>
<td style="text-align: center;">13.471</td>
<td style="text-align: center;">13.156</td>
<td style="text-align: center;">13.024</td>
</tr>
<tr>
<td style="text-align: center;">Rank</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">Method</td>
<td style="text-align: center;">LSTM HC</td>
<td style="text-align: center;">SMILES GA</td>
<td style="text-align: center;">SysNet</td>
<td style="text-align: center;">DoG-Gen</td>
<td style="text-align: center;">DST</td>
</tr>
<tr>
<td style="text-align: center;">Assembly</td>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">Synthesis</td>
<td style="text-align: center;">Synthesis</td>
<td style="text-align: center;">Fragments</td>
</tr>
<tr>
<td style="text-align: center;">albuterol_similarity</td>
<td style="text-align: center;">$0.719 \pm 0.018$</td>
<td style="text-align: center;">$0.661 \pm 0.066$</td>
<td style="text-align: center;">$0.584 \pm 0.039$</td>
<td style="text-align: center;">$0.676 \pm 0.013$</td>
<td style="text-align: center;">$0.619 \pm 0.020$</td>
</tr>
<tr>
<td style="text-align: center;">amlodipine_mpo</td>
<td style="text-align: center;">$0.593 \pm 0.016$</td>
<td style="text-align: center;">$0.549 \pm 0.009$</td>
<td style="text-align: center;">$0.565 \pm 0.007$</td>
<td style="text-align: center;">$0.536 \pm 0.003$</td>
<td style="text-align: center;">$0.516 \pm 0.007$</td>
</tr>
<tr>
<td style="text-align: center;">celecoxib_rediscovery</td>
<td style="text-align: center;">$0.539 \pm 0.018$</td>
<td style="text-align: center;">$0.344 \pm 0.027$</td>
<td style="text-align: center;">$0.441 \pm 0.027$</td>
<td style="text-align: center;">$0.464 \pm 0.009$</td>
<td style="text-align: center;">$0.380 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">deco_hop</td>
<td style="text-align: center;">$0.826 \pm 0.017$</td>
<td style="text-align: center;">$0.611 \pm 0.006$</td>
<td style="text-align: center;">$0.613 \pm 0.009$</td>
<td style="text-align: center;">$0.800 \pm 0.007$</td>
<td style="text-align: center;">$0.608 \pm 0.008$</td>
</tr>
<tr>
<td style="text-align: center;">dsd2</td>
<td style="text-align: center;">$0.919 \pm 0.015$</td>
<td style="text-align: center;">$0.908 \pm 0.019$</td>
<td style="text-align: center;">$0.969 \pm 0.004$</td>
<td style="text-align: center;">$0.948 \pm 0.001$</td>
<td style="text-align: center;">$0.820 \pm 0.014$</td>
</tr>
<tr>
<td style="text-align: center;">fexofenadine_mpo</td>
<td style="text-align: center;">$0.725 \pm 0.003$</td>
<td style="text-align: center;">$0.721 \pm 0.015$</td>
<td style="text-align: center;">$0.761 \pm 0.015$</td>
<td style="text-align: center;">$0.695 \pm 0.003$</td>
<td style="text-align: center;">$0.725 \pm 0.005$</td>
</tr>
<tr>
<td style="text-align: center;">gsk3b</td>
<td style="text-align: center;">$0.839 \pm 0.015$</td>
<td style="text-align: center;">$0.629 \pm 0.044$</td>
<td style="text-align: center;">$0.789 \pm 0.032$</td>
<td style="text-align: center;">$0.831 \pm 0.021$</td>
<td style="text-align: center;">$0.671 \pm 0.032$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c7h8n2o2</td>
<td style="text-align: center;">$0.485 \pm 0.045$</td>
<td style="text-align: center;">$0.913 \pm 0.021$</td>
<td style="text-align: center;">$0.455 \pm 0.031$</td>
<td style="text-align: center;">$0.465 \pm 0.018$</td>
<td style="text-align: center;">$0.548 \pm 0.069$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c9h10n2o2pf2cl</td>
<td style="text-align: center;">$0.342 \pm 0.027$</td>
<td style="text-align: center;">$0.860 \pm 0.065$</td>
<td style="text-align: center;">$0.241 \pm 0.064$</td>
<td style="text-align: center;">$0.199 \pm 0.016$</td>
<td style="text-align: center;">$0.458 \pm 0.063$</td>
</tr>
<tr>
<td style="text-align: center;">jnk3</td>
<td style="text-align: center;">$0.661 \pm 0.039$</td>
<td style="text-align: center;">$0.316 \pm 0.022$</td>
<td style="text-align: center;">$0.630 \pm 0.034$</td>
<td style="text-align: center;">$0.595 \pm 0.023$</td>
<td style="text-align: center;">$0.556 \pm 0.057$</td>
</tr>
<tr>
<td style="text-align: center;">median1</td>
<td style="text-align: center;">$0.255 \pm 0.010$</td>
<td style="text-align: center;">$0.192 \pm 0.012$</td>
<td style="text-align: center;">$0.218 \pm 0.008$</td>
<td style="text-align: center;">$0.217 \pm 0.001$</td>
<td style="text-align: center;">$0.232 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;">median2</td>
<td style="text-align: center;">$0.248 \pm 0.008$</td>
<td style="text-align: center;">$0.198 \pm 0.005$</td>
<td style="text-align: center;">$0.235 \pm 0.006$</td>
<td style="text-align: center;">$0.212 \pm 0.000$</td>
<td style="text-align: center;">$0.185 \pm 0.020$</td>
</tr>
<tr>
<td style="text-align: center;">mestranol_similarity</td>
<td style="text-align: center;">$0.526 \pm 0.032$</td>
<td style="text-align: center;">$0.469 \pm 0.029$</td>
<td style="text-align: center;">$0.399 \pm 0.021$</td>
<td style="text-align: center;">$0.437 \pm 0.007$</td>
<td style="text-align: center;">$0.450 \pm 0.027$</td>
</tr>
<tr>
<td style="text-align: center;">osimertinib_mpo</td>
<td style="text-align: center;">$0.796 \pm 0.002$</td>
<td style="text-align: center;">$0.817 \pm 0.011$</td>
<td style="text-align: center;">$0.796 \pm 0.003$</td>
<td style="text-align: center;">$0.774 \pm 0.002$</td>
<td style="text-align: center;">$0.785 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">perindopril_mpo</td>
<td style="text-align: center;">$0.489 \pm 0.007$</td>
<td style="text-align: center;">$0.447 \pm 0.013$</td>
<td style="text-align: center;">$0.557 \pm 0.011$</td>
<td style="text-align: center;">$0.474 \pm 0.002$</td>
<td style="text-align: center;">$0.462 \pm 0.008$</td>
</tr>
<tr>
<td style="text-align: center;">qed</td>
<td style="text-align: center;">$0.939 \pm 0.000$</td>
<td style="text-align: center;">$0.940 \pm 0.000$</td>
<td style="text-align: center;">$0.941 \pm 0.000$</td>
<td style="text-align: center;">$0.934 \pm 0.000$</td>
<td style="text-align: center;">$0.938 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">ranolazine_mpo</td>
<td style="text-align: center;">$0.714 \pm 0.008$</td>
<td style="text-align: center;">$0.699 \pm 0.026$</td>
<td style="text-align: center;">$0.741 \pm 0.010$</td>
<td style="text-align: center;">$0.711 \pm 0.006$</td>
<td style="text-align: center;">$0.632 \pm 0.054$</td>
</tr>
<tr>
<td style="text-align: center;">scaffold_hop</td>
<td style="text-align: center;">$0.533 \pm 0.012$</td>
<td style="text-align: center;">$0.494 \pm 0.011$</td>
<td style="text-align: center;">$0.502 \pm 0.012$</td>
<td style="text-align: center;">$0.515 \pm 0.005$</td>
<td style="text-align: center;">$0.497 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">sitagliptin_mpo</td>
<td style="text-align: center;">$0.066 \pm 0.019$</td>
<td style="text-align: center;">$0.363 \pm 0.057$</td>
<td style="text-align: center;">$0.025 \pm 0.014$</td>
<td style="text-align: center;">$0.048 \pm 0.008$</td>
<td style="text-align: center;">$0.075 \pm 0.032$</td>
</tr>
<tr>
<td style="text-align: center;">thiothixene_rediscovery</td>
<td style="text-align: center;">$0.438 \pm 0.008$</td>
<td style="text-align: center;">$0.315 \pm 0.017$</td>
<td style="text-align: center;">$0.401 \pm 0.019$</td>
<td style="text-align: center;">$0.375 \pm 0.004$</td>
<td style="text-align: center;">$0.366 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">troglitazone_rediscovery</td>
<td style="text-align: center;">$0.354 \pm 0.016$</td>
<td style="text-align: center;">$0.263 \pm 0.024$</td>
<td style="text-align: center;">$0.283 \pm 0.008$</td>
<td style="text-align: center;">$0.416 \pm 0.019$</td>
<td style="text-align: center;">$0.279 \pm 0.019$</td>
</tr>
<tr>
<td style="text-align: center;">valsartan_smarin</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">zaleplon_mpo</td>
<td style="text-align: center;">$0.206 \pm 0.006$</td>
<td style="text-align: center;">$0.334 \pm 0.041$</td>
<td style="text-align: center;">$0.341 \pm 0.011$</td>
<td style="text-align: center;">$0.123 \pm 0.016$</td>
<td style="text-align: center;">$0.176 \pm 0.045$</td>
</tr>
<tr>
<td style="text-align: center;">Sum</td>
<td style="text-align: center;">12.223</td>
<td style="text-align: center;">12.054</td>
<td style="text-align: center;">11.498</td>
<td style="text-align: center;">11.456</td>
<td style="text-align: center;">10.989</td>
</tr>
<tr>
<td style="text-align: center;">Rank</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">10</td>
</tr>
</tbody>
</table>
<p>Table 5: (Continued)</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method <br> Assembly</th>
<th style="text-align: center;">MARS <br> Fragments</th>
<th style="text-align: center;">MIMOSA <br> Fragments</th>
<th style="text-align: center;">MolPal</th>
<th style="text-align: center;">LSTM HC <br> SELFIES <br> SELFIES</th>
<th style="text-align: center;">DoG-AE <br> Synthesis</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">albuterol_similarity</td>
<td style="text-align: center;">$0.597 \pm 0.124$</td>
<td style="text-align: center;">$0.618 \pm 0.017$</td>
<td style="text-align: center;">$0.609 \pm 0.002$</td>
<td style="text-align: center;">$0.664 \pm 0.030$</td>
<td style="text-align: center;">$0.533 \pm 0.034$</td>
</tr>
<tr>
<td style="text-align: center;">amlodipine_mpo</td>
<td style="text-align: center;">$0.504 \pm 0.016$</td>
<td style="text-align: center;">$0.543 \pm 0.003$</td>
<td style="text-align: center;">$0.582 \pm 0.008$</td>
<td style="text-align: center;">$0.532 \pm 0.004$</td>
<td style="text-align: center;">$0.507 \pm 0.005$</td>
</tr>
<tr>
<td style="text-align: center;">celecoxib_rediscovery</td>
<td style="text-align: center;">$0.379 \pm 0.060$</td>
<td style="text-align: center;">$0.393 \pm 0.010$</td>
<td style="text-align: center;">$0.415 \pm 0.001$</td>
<td style="text-align: center;">$0.385 \pm 0.008$</td>
<td style="text-align: center;">$0.355 \pm 0.012$</td>
</tr>
<tr>
<td style="text-align: center;">deco_hop</td>
<td style="text-align: center;">$0.589 \pm 0.003$</td>
<td style="text-align: center;">$0.619 \pm 0.003$</td>
<td style="text-align: center;">$0.643 \pm 0.005$</td>
<td style="text-align: center;">$0.590 \pm 0.001$</td>
<td style="text-align: center;">$0.765 \pm 0.055$</td>
</tr>
<tr>
<td style="text-align: center;">drd2</td>
<td style="text-align: center;">$0.891 \pm 0.020$</td>
<td style="text-align: center;">$0.799 \pm 0.017$</td>
<td style="text-align: center;">$0.783 \pm 0.009$</td>
<td style="text-align: center;">$0.729 \pm 0.034$</td>
<td style="text-align: center;">$0.943 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;">fexofenadine_mpo</td>
<td style="text-align: center;">$0.711 \pm 0.006$</td>
<td style="text-align: center;">$0.706 \pm 0.011$</td>
<td style="text-align: center;">$0.685 \pm 0.000$</td>
<td style="text-align: center;">$0.693 \pm 0.004$</td>
<td style="text-align: center;">$0.679 \pm 0.017$</td>
</tr>
<tr>
<td style="text-align: center;">gsk3b</td>
<td style="text-align: center;">$0.552 \pm 0.037$</td>
<td style="text-align: center;">$0.554 \pm 0.042$</td>
<td style="text-align: center;">$0.555 \pm 0.011$</td>
<td style="text-align: center;">$0.423 \pm 0.018$</td>
<td style="text-align: center;">$0.601 \pm 0.091$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c7h8n2o2</td>
<td style="text-align: center;">$0.728 \pm 0.027$</td>
<td style="text-align: center;">$0.564 \pm 0.046$</td>
<td style="text-align: center;">$0.484 \pm 0.006$</td>
<td style="text-align: center;">$0.587 \pm 0.031$</td>
<td style="text-align: center;">$0.239 \pm 0.077$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c9h10n2o2pf2cl</td>
<td style="text-align: center;">$0.581 \pm 0.013$</td>
<td style="text-align: center;">$0.303 \pm 0.046$</td>
<td style="text-align: center;">$0.164 \pm 0.003$</td>
<td style="text-align: center;">$0.352 \pm 0.019$</td>
<td style="text-align: center;">$0.049 \pm 0.015$</td>
</tr>
<tr>
<td style="text-align: center;">jnk3</td>
<td style="text-align: center;">$0.489 \pm 0.095$</td>
<td style="text-align: center;">$0.360 \pm 0.063$</td>
<td style="text-align: center;">$0.339 \pm 0.009$</td>
<td style="text-align: center;">$0.207 \pm 0.013$</td>
<td style="text-align: center;">$0.469 \pm 0.138$</td>
</tr>
<tr>
<td style="text-align: center;">median1</td>
<td style="text-align: center;">$0.207 \pm 0.011$</td>
<td style="text-align: center;">$0.243 \pm 0.005$</td>
<td style="text-align: center;">$0.249 \pm 0.001$</td>
<td style="text-align: center;">$0.239 \pm 0.009$</td>
<td style="text-align: center;">$0.171 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;">median2</td>
<td style="text-align: center;">$0.181 \pm 0.011$</td>
<td style="text-align: center;">$0.214 \pm 0.002$</td>
<td style="text-align: center;">$0.230 \pm 0.000$</td>
<td style="text-align: center;">$0.205 \pm 0.005$</td>
<td style="text-align: center;">$0.182 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">mestranol_similarity</td>
<td style="text-align: center;">$0.388 \pm 0.026$</td>
<td style="text-align: center;">$0.438 \pm 0.015$</td>
<td style="text-align: center;">$0.564 \pm 0.004$</td>
<td style="text-align: center;">$0.446 \pm 0.009$</td>
<td style="text-align: center;">$0.370 \pm 0.014$</td>
</tr>
<tr>
<td style="text-align: center;">osimertinib_mpo</td>
<td style="text-align: center;">$0.777 \pm 0.006$</td>
<td style="text-align: center;">$0.788 \pm 0.014$</td>
<td style="text-align: center;">$0.779 \pm 0.000$</td>
<td style="text-align: center;">$0.780 \pm 0.005$</td>
<td style="text-align: center;">$0.750 \pm 0.012$</td>
</tr>
<tr>
<td style="text-align: center;">perindopril_mpo</td>
<td style="text-align: center;">$0.462 \pm 0.006$</td>
<td style="text-align: center;">$0.490 \pm 0.011$</td>
<td style="text-align: center;">$0.467 \pm 0.002$</td>
<td style="text-align: center;">$0.448 \pm 0.006$</td>
<td style="text-align: center;">$0.432 \pm 0.013$</td>
</tr>
<tr>
<td style="text-align: center;">qed</td>
<td style="text-align: center;">$0.930 \pm 0.003$</td>
<td style="text-align: center;">$0.939 \pm 0.000$</td>
<td style="text-align: center;">$0.940 \pm 0.000$</td>
<td style="text-align: center;">$0.938 \pm 0.000$</td>
<td style="text-align: center;">$0.926 \pm 0.003$</td>
</tr>
<tr>
<td style="text-align: center;">ranolazine_mpo</td>
<td style="text-align: center;">$0.740 \pm 0.010$</td>
<td style="text-align: center;">$0.640 \pm 0.015$</td>
<td style="text-align: center;">$0.457 \pm 0.005$</td>
<td style="text-align: center;">$0.614 \pm 0.010$</td>
<td style="text-align: center;">$0.689 \pm 0.015$</td>
</tr>
<tr>
<td style="text-align: center;">scaffold_hop</td>
<td style="text-align: center;">$0.469 \pm 0.004$</td>
<td style="text-align: center;">$0.507 \pm 0.015$</td>
<td style="text-align: center;">$0.494 \pm 0.000$</td>
<td style="text-align: center;">$0.472 \pm 0.002$</td>
<td style="text-align: center;">$0.489 \pm 0.010$</td>
</tr>
<tr>
<td style="text-align: center;">sitagliptin_mpo</td>
<td style="text-align: center;">$0.016 \pm 0.003$</td>
<td style="text-align: center;">$0.102 \pm 0.023$</td>
<td style="text-align: center;">$0.043 \pm 0.001$</td>
<td style="text-align: center;">$0.116 \pm 0.012$</td>
<td style="text-align: center;">$0.009 \pm 0.005$</td>
</tr>
<tr>
<td style="text-align: center;">thiothixene_rediscovery</td>
<td style="text-align: center;">$0.344 \pm 0.022$</td>
<td style="text-align: center;">$0.347 \pm 0.018$</td>
<td style="text-align: center;">$0.339 \pm 0.001$</td>
<td style="text-align: center;">$0.339 \pm 0.009$</td>
<td style="text-align: center;">$0.314 \pm 0.015$</td>
</tr>
<tr>
<td style="text-align: center;">troglitazone_rediscovery</td>
<td style="text-align: center;">$0.256 \pm 0.016$</td>
<td style="text-align: center;">$0.299 \pm 0.009$</td>
<td style="text-align: center;">$0.268 \pm 0.000$</td>
<td style="text-align: center;">$0.257 \pm 0.002$</td>
<td style="text-align: center;">$0.259 \pm 0.016$</td>
</tr>
<tr>
<td style="text-align: center;">valsartan_smarts</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">zaleplon_mpo</td>
<td style="text-align: center;">$0.187 \pm 0.046$</td>
<td style="text-align: center;">$0.172 \pm 0.036$</td>
<td style="text-align: center;">$0.168 \pm 0.003$</td>
<td style="text-align: center;">$0.218 \pm 0.020$</td>
<td style="text-align: center;">$0.049 \pm 0.027$</td>
</tr>
<tr>
<td style="text-align: center;">Sum</td>
<td style="text-align: center;">10.989</td>
<td style="text-align: center;">10.651</td>
<td style="text-align: center;">10.268</td>
<td style="text-align: center;">10.246</td>
<td style="text-align: center;">9.790</td>
</tr>
<tr>
<td style="text-align: center;">Rank</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">15</td>
</tr>
<tr>
<td style="text-align: center;">Method</td>
<td style="text-align: center;">GFlowNet</td>
<td style="text-align: center;">GA+D</td>
<td style="text-align: center;">VAE BO</td>
<td style="text-align: center;">Screening</td>
<td style="text-align: center;">VAE BO</td>
</tr>
<tr>
<td style="text-align: center;">Assembly</td>
<td style="text-align: center;">Fragments</td>
<td style="text-align: center;">SELFIES</td>
<td style="text-align: center;">SELFIES</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">SMILES</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">SELFIES</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">SMILES</td>
</tr>
<tr>
<td style="text-align: center;">albuterol_similarity</td>
<td style="text-align: center;">$0.447 \pm 0.012$</td>
<td style="text-align: center;">$0.495 \pm 0.025$</td>
<td style="text-align: center;">$0.494 \pm 0.012$</td>
<td style="text-align: center;">$0.483 \pm 0.006$</td>
<td style="text-align: center;">$0.489 \pm 0.007$</td>
</tr>
<tr>
<td style="text-align: center;">amlodipine_mpo</td>
<td style="text-align: center;">$0.444 \pm 0.004$</td>
<td style="text-align: center;">$0.400 \pm 0.032$</td>
<td style="text-align: center;">$0.516 \pm 0.005$</td>
<td style="text-align: center;">$0.535 \pm 0.001$</td>
<td style="text-align: center;">$0.533 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;">celecoxib_rediscovery</td>
<td style="text-align: center;">$0.327 \pm 0.004$</td>
<td style="text-align: center;">$0.223 \pm 0.025$</td>
<td style="text-align: center;">$0.326 \pm 0.007$</td>
<td style="text-align: center;">$0.351 \pm 0.005$</td>
<td style="text-align: center;">$0.354 \pm 0.002$</td>
</tr>
<tr>
<td style="text-align: center;">deco_hop</td>
<td style="text-align: center;">$0.583 \pm 0.002$</td>
<td style="text-align: center;">$0.550 \pm 0.005$</td>
<td style="text-align: center;">$0.579 \pm 0.001$</td>
<td style="text-align: center;">$0.590 \pm 0.001$</td>
<td style="text-align: center;">$0.589 \pm 0.001$</td>
</tr>
<tr>
<td style="text-align: center;">drd2</td>
<td style="text-align: center;">$0.590 \pm 0.070$</td>
<td style="text-align: center;">$0.382 \pm 0.205$</td>
<td style="text-align: center;">$0.569 \pm 0.039$</td>
<td style="text-align: center;">$0.545 \pm 0.015$</td>
<td style="text-align: center;">$0.555 \pm 0.043$</td>
</tr>
<tr>
<td style="text-align: center;">fexofenadine_mpo</td>
<td style="text-align: center;">$0.693 \pm 0.006$</td>
<td style="text-align: center;">$0.587 \pm 0.007$</td>
<td style="text-align: center;">$0.670 \pm 0.004$</td>
<td style="text-align: center;">$0.666 \pm 0.004$</td>
<td style="text-align: center;">$0.671 \pm 0.003$</td>
</tr>
<tr>
<td style="text-align: center;">gsk3b</td>
<td style="text-align: center;">$0.651 \pm 0.026$</td>
<td style="text-align: center;">$0.342 \pm 0.019$</td>
<td style="text-align: center;">$0.350 \pm 0.034$</td>
<td style="text-align: center;">$0.438 \pm 0.034$</td>
<td style="text-align: center;">$0.386 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c7h8n2o2</td>
<td style="text-align: center;">$0.366 \pm 0.043$</td>
<td style="text-align: center;">$0.854 \pm 0.015$</td>
<td style="text-align: center;">$0.325 \pm 0.028$</td>
<td style="text-align: center;">$0.168 \pm 0.034$</td>
<td style="text-align: center;">$0.161 \pm 0.017$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c9h10n2o2pf2cl</td>
<td style="text-align: center;">$0.110 \pm 0.031$</td>
<td style="text-align: center;">$0.657 \pm 0.020$</td>
<td style="text-align: center;">$0.200 \pm 0.030$</td>
<td style="text-align: center;">$0.106 \pm 0.021$</td>
<td style="text-align: center;">$0.084 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;">jnk3</td>
<td style="text-align: center;">$0.440 \pm 0.022$</td>
<td style="text-align: center;">$0.219 \pm 0.021$</td>
<td style="text-align: center;">$0.208 \pm 0.022$</td>
<td style="text-align: center;">$0.238 \pm 0.024$</td>
<td style="text-align: center;">$0.241 \pm 0.026$</td>
</tr>
<tr>
<td style="text-align: center;">median1</td>
<td style="text-align: center;">$0.202 \pm 0.004$</td>
<td style="text-align: center;">$0.180 \pm 0.009$</td>
<td style="text-align: center;">$0.201 \pm 0.003$</td>
<td style="text-align: center;">$0.205 \pm 0.005$</td>
<td style="text-align: center;">$0.202 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">median2</td>
<td style="text-align: center;">$0.180 \pm 0.000$</td>
<td style="text-align: center;">$0.121 \pm 0.005$</td>
<td style="text-align: center;">$0.185 \pm 0.001$</td>
<td style="text-align: center;">$0.200 \pm 0.004$</td>
<td style="text-align: center;">$0.195 \pm 0.001$</td>
</tr>
<tr>
<td style="text-align: center;">mestranol_similarity</td>
<td style="text-align: center;">$0.322 \pm 0.007$</td>
<td style="text-align: center;">$0.371 \pm 0.016$</td>
<td style="text-align: center;">$0.386 \pm 0.009$</td>
<td style="text-align: center;">$0.409 \pm 0.019$</td>
<td style="text-align: center;">$0.399 \pm 0.005$</td>
</tr>
<tr>
<td style="text-align: center;">osimertinib_mpo</td>
<td style="text-align: center;">$0.784 \pm 0.001$</td>
<td style="text-align: center;">$0.672 \pm 0.027$</td>
<td style="text-align: center;">$0.765 \pm 0.002$</td>
<td style="text-align: center;">$0.764 \pm 0.001$</td>
<td style="text-align: center;">$0.771 \pm 0.002$</td>
</tr>
<tr>
<td style="text-align: center;">perindopril_mpo</td>
<td style="text-align: center;">$0.430 \pm 0.010$</td>
<td style="text-align: center;">$0.172 \pm 0.088$</td>
<td style="text-align: center;">$0.429 \pm 0.003$</td>
<td style="text-align: center;">$0.445 \pm 0.004$</td>
<td style="text-align: center;">$0.442 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">qed</td>
<td style="text-align: center;">$0.921 \pm 0.004$</td>
<td style="text-align: center;">$0.860 \pm 0.014$</td>
<td style="text-align: center;">$0.936 \pm 0.001$</td>
<td style="text-align: center;">$0.938 \pm 0.000$</td>
<td style="text-align: center;">$0.938 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">ranolazine_mpo</td>
<td style="text-align: center;">$0.652 \pm 0.002$</td>
<td style="text-align: center;">$0.555 \pm 0.015$</td>
<td style="text-align: center;">$0.452 \pm 0.025$</td>
<td style="text-align: center;">$0.411 \pm 0.010$</td>
<td style="text-align: center;">$0.457 \pm 0.012$</td>
</tr>
<tr>
<td style="text-align: center;">scaffold_hop</td>
<td style="text-align: center;">$0.463 \pm 0.002$</td>
<td style="text-align: center;">$0.413 \pm 0.009$</td>
<td style="text-align: center;">$0.455 \pm 0.004$</td>
<td style="text-align: center;">$0.471 \pm 0.002$</td>
<td style="text-align: center;">$0.470 \pm 0.003$</td>
</tr>
<tr>
<td style="text-align: center;">sitagliptin_mpo</td>
<td style="text-align: center;">$0.008 \pm 0.003$</td>
<td style="text-align: center;">$0.281 \pm 0.022$</td>
<td style="text-align: center;">$0.084 \pm 0.015$</td>
<td style="text-align: center;">$0.022 \pm 0.003$</td>
<td style="text-align: center;">$0.023 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">thiothixene_rediscovery</td>
<td style="text-align: center;">$0.285 \pm 0.012$</td>
<td style="text-align: center;">$0.223 \pm 0.029$</td>
<td style="text-align: center;">$0.297 \pm 0.004$</td>
<td style="text-align: center;">$0.317 \pm 0.003$</td>
<td style="text-align: center;">$0.317 \pm 0.007$</td>
</tr>
<tr>
<td style="text-align: center;">troglitazone_rediscovery</td>
<td style="text-align: center;">$0.188 \pm 0.001$</td>
<td style="text-align: center;">$0.152 \pm 0.013$</td>
<td style="text-align: center;">$0.243 \pm 0.004$</td>
<td style="text-align: center;">$0.249 \pm 0.003$</td>
<td style="text-align: center;">$0.257 \pm 0.003$</td>
</tr>
<tr>
<td style="text-align: center;">valsartan_smarts</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.002 \pm 0.003$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.002 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">zaleplon_mpo</td>
<td style="text-align: center;">$0.035 \pm 0.030$</td>
<td style="text-align: center;">$0.244 \pm 0.015$</td>
<td style="text-align: center;">$0.206 \pm 0.015$</td>
<td style="text-align: center;">$0.072 \pm 0.014$</td>
<td style="text-align: center;">$0.039 \pm 0.012$</td>
</tr>
<tr>
<td style="text-align: center;">Sum</td>
<td style="text-align: center;">9.131</td>
<td style="text-align: center;">8.964</td>
<td style="text-align: center;">8.887</td>
<td style="text-align: center;">8.635</td>
<td style="text-align: center;">8.587</td>
</tr>
<tr>
<td style="text-align: center;">Rank</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">20</td>
</tr>
</tbody>
</table>
<p>Table 6: (Continued)</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method <br> Assembly</th>
<th style="text-align: center;">Pasithea <br> SELFIES</th>
<th style="text-align: center;">GFlowNet-AL <br> Fragments</th>
<th style="text-align: center;">JT-VAE BO <br> Fragments</th>
<th style="text-align: center;">Graph MCTS <br> Atoms</th>
<th style="text-align: center;">MolDQN <br> Atoms</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">albuterol_similarity</td>
<td style="text-align: center;">$0.447 \pm 0.007$</td>
<td style="text-align: center;">$0.390 \pm 0.008$</td>
<td style="text-align: center;">$0.485 \pm 0.029$</td>
<td style="text-align: center;">$0.580 \pm 0.023$</td>
<td style="text-align: center;">$0.320 \pm 0.015$</td>
</tr>
<tr>
<td style="text-align: center;">amlodipine_mpo</td>
<td style="text-align: center;">$0.504 \pm 0.003$</td>
<td style="text-align: center;">$0.428 \pm 0.002$</td>
<td style="text-align: center;">$0.519 \pm 0.009$</td>
<td style="text-align: center;">$0.447 \pm 0.008$</td>
<td style="text-align: center;">$0.311 \pm 0.008$</td>
</tr>
<tr>
<td style="text-align: center;">celecoxib_rediscovery</td>
<td style="text-align: center;">$0.312 \pm 0.007$</td>
<td style="text-align: center;">$0.257 \pm 0.003$</td>
<td style="text-align: center;">$0.299 \pm 0.009$</td>
<td style="text-align: center;">$0.264 \pm 0.013$</td>
<td style="text-align: center;">0.099 \pm 0.005</td>
</tr>
<tr>
<td style="text-align: center;">deco_hop</td>
<td style="text-align: center;">$0.579 \pm 0.001$</td>
<td style="text-align: center;">$0.583 \pm 0.001$</td>
<td style="text-align: center;">$0.585 \pm 0.002$</td>
<td style="text-align: center;">$0.554 \pm 0.002$</td>
<td style="text-align: center;">$0.546 \pm 0.001$</td>
</tr>
<tr>
<td style="text-align: center;">drd2</td>
<td style="text-align: center;">$0.255 \pm 0.040$</td>
<td style="text-align: center;">$0.468 \pm 0.046$</td>
<td style="text-align: center;">$0.506 \pm 0.136$</td>
<td style="text-align: center;">$0.300 \pm 0.050$</td>
<td style="text-align: center;">$0.025 \pm 0.001$</td>
</tr>
<tr>
<td style="text-align: center;">fexofenadine_mpo</td>
<td style="text-align: center;">$0.660 \pm 0.015$</td>
<td style="text-align: center;">$0.688 \pm 0.002$</td>
<td style="text-align: center;">$0.667 \pm 0.010$</td>
<td style="text-align: center;">$0.574 \pm 0.009$</td>
<td style="text-align: center;">$0.478 \pm 0.012$</td>
</tr>
<tr>
<td style="text-align: center;">gsk3b</td>
<td style="text-align: center;">$0.281 \pm 0.038$</td>
<td style="text-align: center;">$0.588 \pm 0.015$</td>
<td style="text-align: center;">$0.350 \pm 0.051$</td>
<td style="text-align: center;">$0.281 \pm 0.022$</td>
<td style="text-align: center;">$0.241 \pm 0.008$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c7h8n2o2</td>
<td style="text-align: center;">$0.673 \pm 0.030$</td>
<td style="text-align: center;">$0.241 \pm 0.055$</td>
<td style="text-align: center;">$0.103 \pm 0.016$</td>
<td style="text-align: center;">$0.530 \pm 0.035$</td>
<td style="text-align: center;">$0.431 \pm 0.035$</td>
</tr>
<tr>
<td style="text-align: center;">isomers_c9h10n2o2pf2cl</td>
<td style="text-align: center;">$0.345 \pm 0.145$</td>
<td style="text-align: center;">$0.064 \pm 0.012$</td>
<td style="text-align: center;">$0.090 \pm 0.035$</td>
<td style="text-align: center;">$0.454 \pm 0.067$</td>
<td style="text-align: center;">$0.342 \pm 0.026$</td>
</tr>
<tr>
<td style="text-align: center;">jnk3</td>
<td style="text-align: center;">$0.154 \pm 0.018$</td>
<td style="text-align: center;">$0.362 \pm 0.021$</td>
<td style="text-align: center;">$0.222 \pm 0.009$</td>
<td style="text-align: center;">$0.110 \pm 0.019$</td>
<td style="text-align: center;">$0.111 \pm 0.008$</td>
</tr>
<tr>
<td style="text-align: center;">median1</td>
<td style="text-align: center;">$0.178 \pm 0.009$</td>
<td style="text-align: center;">$0.190 \pm 0.002$</td>
<td style="text-align: center;">$0.179 \pm 0.003$</td>
<td style="text-align: center;">$0.195 \pm 0.005$</td>
<td style="text-align: center;">$0.122 \pm 0.007$</td>
</tr>
<tr>
<td style="text-align: center;">median2</td>
<td style="text-align: center;">$0.179 \pm 0.004$</td>
<td style="text-align: center;">$0.173 \pm 0.001$</td>
<td style="text-align: center;">$0.180 \pm 0.003$</td>
<td style="text-align: center;">$0.132 \pm 0.002$</td>
<td style="text-align: center;">$0.088 \pm 0.003$</td>
</tr>
<tr>
<td style="text-align: center;">mestranol_similarity</td>
<td style="text-align: center;">$0.361 \pm 0.016$</td>
<td style="text-align: center;">$0.295 \pm 0.004$</td>
<td style="text-align: center;">$0.356 \pm 0.013$</td>
<td style="text-align: center;">$0.281 \pm 0.008$</td>
<td style="text-align: center;">$0.188 \pm 0.007$</td>
</tr>
<tr>
<td style="text-align: center;">osimertinib_mpo</td>
<td style="text-align: center;">$0.749 \pm 0.007$</td>
<td style="text-align: center;">$0.787 \pm 0.003$</td>
<td style="text-align: center;">$0.775 \pm 0.004$</td>
<td style="text-align: center;">$0.700 \pm 0.004$</td>
<td style="text-align: center;">$0.674 \pm 0.006$</td>
</tr>
<tr>
<td style="text-align: center;">perindopril_mpo</td>
<td style="text-align: center;">$0.421 \pm 0.008$</td>
<td style="text-align: center;">$0.421 \pm 0.002$</td>
<td style="text-align: center;">$0.430 \pm 0.009$</td>
<td style="text-align: center;">$0.277 \pm 0.013$</td>
<td style="text-align: center;">$0.213 \pm 0.043$</td>
</tr>
<tr>
<td style="text-align: center;">qed</td>
<td style="text-align: center;">$0.931 \pm 0.002$</td>
<td style="text-align: center;">$0.902 \pm 0.005$</td>
<td style="text-align: center;">$0.934 \pm 0.002$</td>
<td style="text-align: center;">$0.892 \pm 0.006$</td>
<td style="text-align: center;">$0.731 \pm 0.018$</td>
</tr>
<tr>
<td style="text-align: center;">ranolazine_mpo</td>
<td style="text-align: center;">$0.347 \pm 0.012$</td>
<td style="text-align: center;">$0.632 \pm 0.007$</td>
<td style="text-align: center;">$0.508 \pm 0.055$</td>
<td style="text-align: center;">$0.239 \pm 0.027$</td>
<td style="text-align: center;">$0.051 \pm 0.020$</td>
</tr>
<tr>
<td style="text-align: center;">scaffold_hop</td>
<td style="text-align: center;">$0.456 \pm 0.003$</td>
<td style="text-align: center;">$0.460 \pm 0.002$</td>
<td style="text-align: center;">$0.470 \pm 0.005$</td>
<td style="text-align: center;">$0.412 \pm 0.003$</td>
<td style="text-align: center;">$0.405 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">sitagliptin_mpo</td>
<td style="text-align: center;">$0.088 \pm 0.013$</td>
<td style="text-align: center;">$0.006 \pm 0.001$</td>
<td style="text-align: center;">$0.046 \pm 0.027$</td>
<td style="text-align: center;">$0.056 \pm 0.012$</td>
<td style="text-align: center;">$0.003 \pm 0.002$</td>
</tr>
<tr>
<td style="text-align: center;">thiothixene_rediscovery</td>
<td style="text-align: center;">$0.288 \pm 0.006$</td>
<td style="text-align: center;">$0.266 \pm 0.005$</td>
<td style="text-align: center;">$0.282 \pm 0.008$</td>
<td style="text-align: center;">$0.231 \pm 0.004$</td>
<td style="text-align: center;">0.099 \pm 0.007</td>
</tr>
<tr>
<td style="text-align: center;">troglitazone_rediscovery</td>
<td style="text-align: center;">$0.240 \pm 0.002$</td>
<td style="text-align: center;">$0.186 \pm 0.003$</td>
<td style="text-align: center;">$0.237 \pm 0.005$</td>
<td style="text-align: center;">$0.224 \pm 0.009$</td>
<td style="text-align: center;">$0.122 \pm 0.004$</td>
</tr>
<tr>
<td style="text-align: center;">valsarian_smarts</td>
<td style="text-align: center;">$0.006 \pm 0.012$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
<td style="text-align: center;">$0.000 \pm 0.000$</td>
</tr>
<tr>
<td style="text-align: center;">zaleplon_mpo</td>
<td style="text-align: center;">$0.091 \pm 0.013$</td>
<td style="text-align: center;">$0.010 \pm 0.001$</td>
<td style="text-align: center;">$0.125 \pm 0.038$</td>
<td style="text-align: center;">$0.058 \pm 0.019$</td>
<td style="text-align: center;">$0.010 \pm 0.005$</td>
</tr>
<tr>
<td style="text-align: center;">Sum</td>
<td style="text-align: center;">8.556</td>
<td style="text-align: center;">8.406</td>
<td style="text-align: center;">8.358</td>
<td style="text-align: center;">7.803</td>
<td style="text-align: center;">5.620</td>
</tr>
<tr>
<td style="text-align: center;">Rank</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">25</td>
</tr>
</tbody>
</table>
<h1>A. 2 Optimization Curves</h1>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The optimization curves of top-10 average on optimizing similarity-based oracles.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The optimization curves of top-10 average on optimizing similarity-based MPO oracles.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: The optimization curves of top-10 average on optimizing isomer-based oracles.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ Incorporating certain stereochemical information in 2D molecular graphs is possible through various approaches $[39,40,41]$.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>