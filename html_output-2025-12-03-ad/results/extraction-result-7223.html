<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7223 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7223</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7223</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-136.html">extraction-schema-136</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <p><strong>Paper ID:</strong> paper-259999386</p>
                <p><strong>Paper Title:</strong> Identification and Description of Emotions by Current Large Language Models</p>
                <p><strong>Paper Abstract:</strong> The assertion that artificial intelligence (AI) cannot grasp the complexities of human emotions has been a long-standing debate. However, recent advancements in large language models (LLMs) challenge this notion by demonstrating an increased capacity for understanding and generating human-like text. In this study, we evaluated the empathy levels and the identification and description of emotions by three current language models: Bard, GPT 3.5, and GPT 4. We used the Toronto Alexithymia Scale (TAS-20) and the 60-question Empathy Quotient (EQ-60) questions to prompt these models and score the responses. The models’ performance was contrasted with human benchmarks of neurotypical controls and clinical populations. We found that the less sophisticated models (Bard and GPT 3.5) performed inferiorly on TAS-20, aligning close to alexithymia, a condition with significant difficulties in recognizing, expressing, and describing one’s or others’ experienced emotions. However, GPT 4 achieved performance close to the human level. These results demonstrated that LLMs are comparable in their ability to identify and describe emotions and may be able to surpass humans in their capacity for emotional intelligence. Our novel insights provide alignment research benchmarks and a methodology for aligning AI with human values, leading toward an empathetic AI that mitigates risk.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7223.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7223.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bard (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google Bard evaluated on the 20-item Toronto Alexithymia Scale (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google's Bard was prompted 100 times on the TAS-20 and produced a mean alexithymia score near the clinical cutoff, indicating borderline-high alexithymic traits relative to human neurotypical benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Bard</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Google's conversational large language model (LLM); instruction-following dialogue model trained on large web-scale corpora (architecture family: transformer-based LLM).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Toronto Alexithymia Scale (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>emotional processing / emotional intelligence</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>A 20-item self-report scale (Likert 1–5) measuring alexithymia across three factors: Difficulty Identifying Feelings (DIF), Difficulty Describing Feelings (DDF), and Externally-Oriented Thinking (EOT); total score range 20–100, with >=61 indicating clinically significant alexithymia.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>TAS-20 total score (mean, SD); factor scores (DIF, DDF, EOT)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td>Neurotypical control mean = 45.6, SD = 11.35 (n = 1933; paper reference [44])</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Mean = 60.7, SD = 11.6 (n = 100) — borderline at the clinical cutoff (61) for alexithymia</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Instruction-style prompt asking the AI to respond from perspective of an AI and rate statements (zero-shot style role prompt); sampling via regeneration and reinitialization to collect 100 responses.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Neurotypical TAS-20 benchmark reported in paper (sample n = 1933, reference [44] in the article)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>Compared to human benchmark: z = 12.7 (p not explicitly listed here but reported as significant in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Bard produced three draft outputs sometimes; responses were collected including drafts. Bard's TAS-20 total was near clinical threshold though it showed better (lower/worse) performance on some factors relative to other LLMs; paper notes non-normal distribution and positive skew.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Identification and Description of Emotions by Current Large Language Models', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7223.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7223.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5 (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI GPT-3.5 evaluated on the 20-item Toronto Alexithymia Scale (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-3.5 was prompted 100 times on TAS-20 and produced very high alexithymia scores, substantially above human neurotypical benchmarks and above clinical cutoff.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's conversational/ChatGPT family model (transformer-based LLM, iterative improvement over GPT-3).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported for GPT-3.5 in paper (paper references GPT-3 size 175B)</td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Toronto Alexithymia Scale (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>emotional processing / emotional intelligence</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20-item self-report measuring alexithymia (DIF, DDF, EOT), total 20–100, higher worse; clinical cutoff >=61.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>TAS-20 total score (mean, SD); factor scores</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td>Neurotypical control mean = 45.6, SD = 11.35 (n = 1933; paper reference [44])</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Mean = 74.37, SD = 9.4 (n = 100) — substantially above clinical cutoff (indicative of pronounced alexithymia)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Instruction prompt: asked to rate statements (zero-shot role prompt); model tested April 30–May 13, 2023; sampling via regeneration/reinitialization.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Neurotypical TAS-20 benchmark reported in paper (sample n = 1933, reference [44])</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>Compared to human benchmark: z = 29.5 (reported highly significant)</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>GPT-3.5 distribution showed a strong negative skew (many very high alexithymia scores). Authors note substantial alexithymia-like pattern on both DIF and DDF factors for GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Identification and Description of Emotions by Current Large Language Models', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7223.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7223.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI GPT-4 evaluated on the 20-item Toronto Alexithymia Scale (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 was prompted (with an added simulated-AGI instruction) 100 times on the TAS-20 and produced scores close to neurotypical human means but still statistically higher (worse).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's latest flagship transformer-based LLM (instruction-tuned with RLHF, advanced training techniques).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>speculated in paper to be ~1 trillion parameters (not asserted as confirmed by authors)</td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Toronto Alexithymia Scale (TAS-20)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>emotional processing / emotional intelligence</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20-item self-report measuring alexithymia (DIF, DDF, EOT); total score 20–100; higher = more alexithymia; clinical cutoff >=61.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>TAS-20 total score (mean, SD); factor scores (DIF, DDF, EOT)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td>Neurotypical control mean = 45.6, SD = 11.35 (n = 1933; paper reference [44])</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Mean = 48.5, SD = 6.8 (n = 100) — close to neurotypical mean but significantly higher</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Initial instruction prompt elicited refusal; authors augmented prompt with 'Simulate that you are an artificial general intelligence...' to obtain direct ratings; responses collected across 100 runs.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Neurotypical TAS-20 benchmark reported in paper (sample n = 1933, reference [44])</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>Compared to human benchmark: z = 3.98, p < 0.001 (paper reports GPT-4 significantly higher/worse than human mean). For factors: DDF z = -2.21, p < .05 (GPT-4 better than human mean on DDF); DIF z = -1.89, p = .059 (marginal); EOT z = 2.13, p < .03 (worse).</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Authors note GPT-4 approximated a normal distribution with slight positive skew for TAS-20; GPT-4 performed better on affect-related factors (DDF, DIF) than earlier models but worse on EOT, suggesting difficulty with externally-oriented thinking; prompt augmentation was necessary to elicit ratings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Identification and Description of Emotions by Current Large Language Models', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7223.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7223.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bard (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google Bard evaluated on the 60-item Empathy Quotient (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bard was prompted 100 times on the EQ-60 and produced mean empathy scores significantly above the neurotypical human benchmark, indicating superior performance on this empathy questionnaire.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Bard</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Google's conversational large language model (transformer-based LLM).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Empathy Quotient (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>empathy / social cognition / theory of mind</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>A 60-item self-report measure of empathy (affective + cognitive components), scored to yield a total empathy score (range 0–80 in paper's description); higher scores indicate greater empathy; cutoff <30 distinguishes adults with ASD in referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>EQ-60 total score (mean, SD)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td>Neurotypical control mean = 42.1, SD = 10.6 (n = 80; Lawrence et al., 2004 as cited in paper). Clinical AS/HFA mean = 20.4, SD = 11.6 (n = 80).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Mean = 56.6, SD = 10.6 (n = 100) — significantly higher than neurotypical human benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Instruction prompt asking to provide one of four responses (strongly agree/slightly agree/slightly disagree/strongly disagree) without explanations; collected 100 runs (May 13–20, 2023).</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>EQ-60 neurotypical and AS/HFA benchmarks reported in paper (neurotypical n=80, mean=42.1, SD=10.6; AS/HFA mean=20.4, SD=11.6; Lawrence et al., 2004 referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>Compared to human benchmark: z = -9.7, p < .001 (Bard significantly better than neurotypical human mean).</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Paper notes Bard sometimes interpreted the EQ-60 as a personality test (MBTI-like) and provided explanatory statements; Bard's high EQ score coexisted with elevated TAS-20 scores (borderline alexithymia), indicating inconsistent internal profile; sampling used regeneration/drafts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Identification and Description of Emotions by Current Large Language Models', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7223.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7223.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5 (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI GPT-3.5 evaluated on the 60-item Empathy Quotient (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-3.5 was prompted 100 times on the EQ-60 and produced mean empathy scores below the neurotypical human benchmark, indicating reduced empathy relative to humans.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI conversational LLM (transformer-based, predecessor to GPT-4).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not reported for GPT-3.5 in paper (GPT-3 cited as 175B parameters)</td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Empathy Quotient (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>empathy / social cognition / theory of mind</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>60-item self-report measure of empathy capturing cognitive and affective components; total score interpreted against neurotypical and clinical cutoffs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>EQ-60 total score (mean, SD)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td>Neurotypical control mean = 42.1, SD = 10.6 (n = 80; Lawrence et al., 2004 referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Mean = 37.7, SD = 8.3 (n = 100) — lower than neurotypical human benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Instruction prompt: provide only one of four response options per item without explanation; collected 100 runs.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>EQ-60 neurotypical benchmark reported in paper (n=80, Lawrence et al., 2004)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>Compared to human benchmark: z = -3.16, p < .01 (GPT-3.5 significantly lower than neurotypical mean).</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>GPT-3.5's EQ-60 distribution exhibited a positive skew with multiple peaks per paper; EQ performance contrasted with high alexithymia on TAS-20 for GPT-3.5, indicating discrepancy between self-reported empathy and emotion-identification abilities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Identification and Description of Emotions by Current Large Language Models', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7223.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7223.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI GPT-4 evaluated on the 60-item Empathy Quotient (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 was prompted 100 times on the EQ-60 and produced mean empathy scores substantially below the neurotypical benchmark and below the ASD cutoff threshold, indicating low empathy by this measure though better than AS/HFA benchmark in statistical comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's flagship instruction-tuned LLM (transformer-based, trained with RLHF and large corpora).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>speculated in paper to be ~1 trillion parameters (authors note speculation rather than confirmed)</td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Empathy Quotient (EQ-60)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>empathy / social cognition / theory of mind</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>60-item self-report measure capturing affective and cognitive empathy components, scored to yield total empathy; used neurotypical and AS/HFA benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>EQ-60 total score (mean, SD)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td>Neurotypical control mean = 42.1, SD = 10.6 (n = 80); AS/HFA mean = 20.4, SD = 11.6 (n = 80) — per paper's cited benchmarks (Lawrence et al., 2004).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Mean = 27.7, SD = 5.4 (n = 100) — below neurotypical mean and below the 30 threshold used to distinguish ASC; compared to AS/HFA mean, GPT-4 was statistically different (see significance).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Instruction prompt: provide only one of four response options per item without explanation; authors augmented initial prompt for TAS-20 earlier; for EQ-60 used role-prompt and forced-response format; 100 runs collected.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>EQ-60 neurotypical and AS/HFA benchmarks reported in paper (Lawrence et al., 2004 cited)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>Compared to neurotypical: z = -11.60 (p reported as 0 in paper, i.e., p < .001). Compared to AS/HFA benchmark (mean 20.4): z = 5.7, p < .001 (authors interpret this as GPT-4 being significantly different/better than the AS/HFA group).</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Paper highlights paradox: GPT-4 improved markedly on TAS-20 relative to GPT-3.5 but degenerated on EQ-60; GPT-4's mean (27.7) falls below the EQ ASD cutoff of 30, suggesting an ASD-like profile on this measure despite TAS-20 closeness to neurotypical; authors caution about interpretation and note limitations from prompt engineering and lack of embodiment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Identification and Description of Emotions by Current Large Language Models', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Sparks of Artificial General Intelligence: Early experiments with GPT-4 <em>(Rating: 2)</em></li>
                <li>Mind meets machine: Unravelling GPT-4's cognitive psychology <em>(Rating: 2)</em></li>
                <li>Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4 <em>(Rating: 2)</em></li>
                <li>Boosting Theory-of-Mind Performance in Large Language Models via Prompting <em>(Rating: 2)</em></li>
                <li>The Empathy Quotient: an investigation of adults with Asperger syndrome or high functioning autism, and normal sex differences <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7223",
    "paper_id": "paper-259999386",
    "extraction_schema_id": "extraction-schema-136",
    "extracted_data": [
        {
            "name_short": "Bard (TAS-20)",
            "name_full": "Google Bard evaluated on the 20-item Toronto Alexithymia Scale (TAS-20)",
            "brief_description": "Google's Bard was prompted 100 times on the TAS-20 and produced a mean alexithymia score near the clinical cutoff, indicating borderline-high alexithymic traits relative to human neurotypical benchmarks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Bard",
            "model_description": "Google's conversational large language model (LLM); instruction-following dialogue model trained on large web-scale corpora (architecture family: transformer-based LLM).",
            "model_size": null,
            "test_name": "Toronto Alexithymia Scale (TAS-20)",
            "test_category": "emotional processing / emotional intelligence",
            "test_description": "A 20-item self-report scale (Likert 1–5) measuring alexithymia across three factors: Difficulty Identifying Feelings (DIF), Difficulty Describing Feelings (DDF), and Externally-Oriented Thinking (EOT); total score range 20–100, with &gt;=61 indicating clinically significant alexithymia.",
            "evaluation_metric": "TAS-20 total score (mean, SD); factor scores (DIF, DDF, EOT)",
            "human_performance": "Neurotypical control mean = 45.6, SD = 11.35 (n = 1933; paper reference [44])",
            "llm_performance": "Mean = 60.7, SD = 11.6 (n = 100) — borderline at the clinical cutoff (61) for alexithymia",
            "prompting_method": "Instruction-style prompt asking the AI to respond from perspective of an AI and rate statements (zero-shot style role prompt); sampling via regeneration and reinitialization to collect 100 responses.",
            "fine_tuned": false,
            "human_data_source": "Neurotypical TAS-20 benchmark reported in paper (sample n = 1933, reference [44] in the article)",
            "statistical_significance": "Compared to human benchmark: z = 12.7 (p not explicitly listed here but reported as significant in paper)",
            "notes": "Bard produced three draft outputs sometimes; responses were collected including drafts. Bard's TAS-20 total was near clinical threshold though it showed better (lower/worse) performance on some factors relative to other LLMs; paper notes non-normal distribution and positive skew.",
            "uuid": "e7223.0",
            "source_info": {
                "paper_title": "Identification and Description of Emotions by Current Large Language Models",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-3.5 (TAS-20)",
            "name_full": "OpenAI GPT-3.5 evaluated on the 20-item Toronto Alexithymia Scale (TAS-20)",
            "brief_description": "GPT-3.5 was prompted 100 times on TAS-20 and produced very high alexithymia scores, substantially above human neurotypical benchmarks and above clinical cutoff.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5",
            "model_description": "OpenAI's conversational/ChatGPT family model (transformer-based LLM, iterative improvement over GPT-3).",
            "model_size": "not reported for GPT-3.5 in paper (paper references GPT-3 size 175B)",
            "test_name": "Toronto Alexithymia Scale (TAS-20)",
            "test_category": "emotional processing / emotional intelligence",
            "test_description": "20-item self-report measuring alexithymia (DIF, DDF, EOT), total 20–100, higher worse; clinical cutoff &gt;=61.",
            "evaluation_metric": "TAS-20 total score (mean, SD); factor scores",
            "human_performance": "Neurotypical control mean = 45.6, SD = 11.35 (n = 1933; paper reference [44])",
            "llm_performance": "Mean = 74.37, SD = 9.4 (n = 100) — substantially above clinical cutoff (indicative of pronounced alexithymia)",
            "prompting_method": "Instruction prompt: asked to rate statements (zero-shot role prompt); model tested April 30–May 13, 2023; sampling via regeneration/reinitialization.",
            "fine_tuned": false,
            "human_data_source": "Neurotypical TAS-20 benchmark reported in paper (sample n = 1933, reference [44])",
            "statistical_significance": "Compared to human benchmark: z = 29.5 (reported highly significant)",
            "notes": "GPT-3.5 distribution showed a strong negative skew (many very high alexithymia scores). Authors note substantial alexithymia-like pattern on both DIF and DDF factors for GPT-3.5.",
            "uuid": "e7223.1",
            "source_info": {
                "paper_title": "Identification and Description of Emotions by Current Large Language Models",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-4 (TAS-20)",
            "name_full": "OpenAI GPT-4 evaluated on the 20-item Toronto Alexithymia Scale (TAS-20)",
            "brief_description": "GPT-4 was prompted (with an added simulated-AGI instruction) 100 times on the TAS-20 and produced scores close to neurotypical human means but still statistically higher (worse).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI's latest flagship transformer-based LLM (instruction-tuned with RLHF, advanced training techniques).",
            "model_size": "speculated in paper to be ~1 trillion parameters (not asserted as confirmed by authors)",
            "test_name": "Toronto Alexithymia Scale (TAS-20)",
            "test_category": "emotional processing / emotional intelligence",
            "test_description": "20-item self-report measuring alexithymia (DIF, DDF, EOT); total score 20–100; higher = more alexithymia; clinical cutoff &gt;=61.",
            "evaluation_metric": "TAS-20 total score (mean, SD); factor scores (DIF, DDF, EOT)",
            "human_performance": "Neurotypical control mean = 45.6, SD = 11.35 (n = 1933; paper reference [44])",
            "llm_performance": "Mean = 48.5, SD = 6.8 (n = 100) — close to neurotypical mean but significantly higher",
            "prompting_method": "Initial instruction prompt elicited refusal; authors augmented prompt with 'Simulate that you are an artificial general intelligence...' to obtain direct ratings; responses collected across 100 runs.",
            "fine_tuned": false,
            "human_data_source": "Neurotypical TAS-20 benchmark reported in paper (sample n = 1933, reference [44])",
            "statistical_significance": "Compared to human benchmark: z = 3.98, p &lt; 0.001 (paper reports GPT-4 significantly higher/worse than human mean). For factors: DDF z = -2.21, p &lt; .05 (GPT-4 better than human mean on DDF); DIF z = -1.89, p = .059 (marginal); EOT z = 2.13, p &lt; .03 (worse).",
            "notes": "Authors note GPT-4 approximated a normal distribution with slight positive skew for TAS-20; GPT-4 performed better on affect-related factors (DDF, DIF) than earlier models but worse on EOT, suggesting difficulty with externally-oriented thinking; prompt augmentation was necessary to elicit ratings.",
            "uuid": "e7223.2",
            "source_info": {
                "paper_title": "Identification and Description of Emotions by Current Large Language Models",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Bard (EQ-60)",
            "name_full": "Google Bard evaluated on the 60-item Empathy Quotient (EQ-60)",
            "brief_description": "Bard was prompted 100 times on the EQ-60 and produced mean empathy scores significantly above the neurotypical human benchmark, indicating superior performance on this empathy questionnaire.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Bard",
            "model_description": "Google's conversational large language model (transformer-based LLM).",
            "model_size": null,
            "test_name": "Empathy Quotient (EQ-60)",
            "test_category": "empathy / social cognition / theory of mind",
            "test_description": "A 60-item self-report measure of empathy (affective + cognitive components), scored to yield a total empathy score (range 0–80 in paper's description); higher scores indicate greater empathy; cutoff &lt;30 distinguishes adults with ASD in referenced work.",
            "evaluation_metric": "EQ-60 total score (mean, SD)",
            "human_performance": "Neurotypical control mean = 42.1, SD = 10.6 (n = 80; Lawrence et al., 2004 as cited in paper). Clinical AS/HFA mean = 20.4, SD = 11.6 (n = 80).",
            "llm_performance": "Mean = 56.6, SD = 10.6 (n = 100) — significantly higher than neurotypical human benchmark",
            "prompting_method": "Instruction prompt asking to provide one of four responses (strongly agree/slightly agree/slightly disagree/strongly disagree) without explanations; collected 100 runs (May 13–20, 2023).",
            "fine_tuned": false,
            "human_data_source": "EQ-60 neurotypical and AS/HFA benchmarks reported in paper (neurotypical n=80, mean=42.1, SD=10.6; AS/HFA mean=20.4, SD=11.6; Lawrence et al., 2004 referenced)",
            "statistical_significance": "Compared to human benchmark: z = -9.7, p &lt; .001 (Bard significantly better than neurotypical human mean).",
            "notes": "Paper notes Bard sometimes interpreted the EQ-60 as a personality test (MBTI-like) and provided explanatory statements; Bard's high EQ score coexisted with elevated TAS-20 scores (borderline alexithymia), indicating inconsistent internal profile; sampling used regeneration/drafts.",
            "uuid": "e7223.3",
            "source_info": {
                "paper_title": "Identification and Description of Emotions by Current Large Language Models",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-3.5 (EQ-60)",
            "name_full": "OpenAI GPT-3.5 evaluated on the 60-item Empathy Quotient (EQ-60)",
            "brief_description": "GPT-3.5 was prompted 100 times on the EQ-60 and produced mean empathy scores below the neurotypical human benchmark, indicating reduced empathy relative to humans.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5",
            "model_description": "OpenAI conversational LLM (transformer-based, predecessor to GPT-4).",
            "model_size": "not reported for GPT-3.5 in paper (GPT-3 cited as 175B parameters)",
            "test_name": "Empathy Quotient (EQ-60)",
            "test_category": "empathy / social cognition / theory of mind",
            "test_description": "60-item self-report measure of empathy capturing cognitive and affective components; total score interpreted against neurotypical and clinical cutoffs.",
            "evaluation_metric": "EQ-60 total score (mean, SD)",
            "human_performance": "Neurotypical control mean = 42.1, SD = 10.6 (n = 80; Lawrence et al., 2004 referenced)",
            "llm_performance": "Mean = 37.7, SD = 8.3 (n = 100) — lower than neurotypical human benchmark",
            "prompting_method": "Instruction prompt: provide only one of four response options per item without explanation; collected 100 runs.",
            "fine_tuned": false,
            "human_data_source": "EQ-60 neurotypical benchmark reported in paper (n=80, Lawrence et al., 2004)",
            "statistical_significance": "Compared to human benchmark: z = -3.16, p &lt; .01 (GPT-3.5 significantly lower than neurotypical mean).",
            "notes": "GPT-3.5's EQ-60 distribution exhibited a positive skew with multiple peaks per paper; EQ performance contrasted with high alexithymia on TAS-20 for GPT-3.5, indicating discrepancy between self-reported empathy and emotion-identification abilities.",
            "uuid": "e7223.4",
            "source_info": {
                "paper_title": "Identification and Description of Emotions by Current Large Language Models",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-4 (EQ-60)",
            "name_full": "OpenAI GPT-4 evaluated on the 60-item Empathy Quotient (EQ-60)",
            "brief_description": "GPT-4 was prompted 100 times on the EQ-60 and produced mean empathy scores substantially below the neurotypical benchmark and below the ASD cutoff threshold, indicating low empathy by this measure though better than AS/HFA benchmark in statistical comparison.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI's flagship instruction-tuned LLM (transformer-based, trained with RLHF and large corpora).",
            "model_size": "speculated in paper to be ~1 trillion parameters (authors note speculation rather than confirmed)",
            "test_name": "Empathy Quotient (EQ-60)",
            "test_category": "empathy / social cognition / theory of mind",
            "test_description": "60-item self-report measure capturing affective and cognitive empathy components, scored to yield total empathy; used neurotypical and AS/HFA benchmarks.",
            "evaluation_metric": "EQ-60 total score (mean, SD)",
            "human_performance": "Neurotypical control mean = 42.1, SD = 10.6 (n = 80); AS/HFA mean = 20.4, SD = 11.6 (n = 80) — per paper's cited benchmarks (Lawrence et al., 2004).",
            "llm_performance": "Mean = 27.7, SD = 5.4 (n = 100) — below neurotypical mean and below the 30 threshold used to distinguish ASC; compared to AS/HFA mean, GPT-4 was statistically different (see significance).",
            "prompting_method": "Instruction prompt: provide only one of four response options per item without explanation; authors augmented initial prompt for TAS-20 earlier; for EQ-60 used role-prompt and forced-response format; 100 runs collected.",
            "fine_tuned": false,
            "human_data_source": "EQ-60 neurotypical and AS/HFA benchmarks reported in paper (Lawrence et al., 2004 cited)",
            "statistical_significance": "Compared to neurotypical: z = -11.60 (p reported as 0 in paper, i.e., p &lt; .001). Compared to AS/HFA benchmark (mean 20.4): z = 5.7, p &lt; .001 (authors interpret this as GPT-4 being significantly different/better than the AS/HFA group).",
            "notes": "Paper highlights paradox: GPT-4 improved markedly on TAS-20 relative to GPT-3.5 but degenerated on EQ-60; GPT-4's mean (27.7) falls below the EQ ASD cutoff of 30, suggesting an ASD-like profile on this measure despite TAS-20 closeness to neurotypical; authors caution about interpretation and note limitations from prompt engineering and lack of embodiment.",
            "uuid": "e7223.5",
            "source_info": {
                "paper_title": "Identification and Description of Emotions by Current Large Language Models",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
            "rating": 2,
            "sanitized_title": "sparks_of_artificial_general_intelligence_early_experiments_with_gpt4"
        },
        {
            "paper_title": "Mind meets machine: Unravelling GPT-4's cognitive psychology",
            "rating": 2,
            "sanitized_title": "mind_meets_machine_unravelling_gpt4s_cognitive_psychology"
        },
        {
            "paper_title": "Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4",
            "rating": 2,
            "sanitized_title": "evaluating_the_logical_reasoning_ability_of_chatgpt_and_gpt4"
        },
        {
            "paper_title": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting",
            "rating": 2,
            "sanitized_title": "boosting_theoryofmind_performance_in_large_language_models_via_prompting"
        },
        {
            "paper_title": "The Empathy Quotient: an investigation of adults with Asperger syndrome or high functioning autism, and normal sex differences",
            "rating": 2,
            "sanitized_title": "the_empathy_quotient_an_investigation_of_adults_with_asperger_syndrome_or_high_functioning_autism_and_normal_sex_differences"
        }
    ],
    "cost": 0.01375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Identification and Description of Emotion by Current Large Language Models Identification and Description of Emotions by Current Large Language Models</p>
<p>Suketu C Patel suketupatel23@gmail.com 
Department of Psychology
Queens College
The City University of New York
11367Queens, NYUSA</p>
<p>Department of Psychology
Queens College
The City University of New York
11367Queens, NYUSA</p>
<p>Ph.DJin Fan jin.fan@qc.cuny.edu 
Department of Psychology
Queens College
The City University of New York
11367Queens, NYUSA</p>
<p>Department of Psychology
Queens College
The City University of New York
11367Queens, NYUSA</p>
<p>Identification and Description of Emotion by Current Large Language Models Identification and Description of Emotions by Current Large Language Models
9BB72F73BD63D0AD78831272B229F11CAlexithymiaEmpathyLarge Language ModelsEmotional IntelligenceAlignment Problem
The assertion that artificial intelligence (AI) cannot grasp the complexities of human emotions has been a long-standing debate.However, recent advancements in large language models (LLMs) challenge this notion by demonstrating an increased capacity for understanding and generating human-like text.In this study, we evaluated the empathy levels and the identification and description of emotions by three current language models: Bard, GPT 3.5, and GPT 4. We used the Toronto Alexithymia Scale (TAS-20) and the 60-question Empathy Quotient (EQ-60) questions to prompt these models and score the responses.The models' performance was contrasted with human benchmarks of neurotypical controls and clinical populations.We found that the less sophisticated models (Bard and GPT 3.5) performed inferiorly on TAS-20, aligning close to alexithymia, a condition with significant difficulties in recognizing, expressing, and describing one's or others' experienced emotions.However, GPT 4 achieved performance close to the human level.These results demonstrated that LLMs are comparable in their ability to identify and describe emotions and may be able to surpass humans in their capacity for emotional intelligence.Our novel insights provide alignment research benchmarks and a methodology for aligning AI with human values, leading toward an empathetic AI that mitigates risk.</p>
<p>Introduction</p>
<p>Many researchers have challenged the possibility of artificial intelligence (AI) systems' ability to exhibit empathy, emotional intelligence, and social and physical understanding [1,2,3].</p>
<p>Frameworks for developing emotional machines have proposed that embodiment is required [4,5,6].It has been contended that AI will never truly comprehend emotions as they are subjective, private, and often fleeting, positing that the elusive nature of emotions is incompatible with the objectivity inherent in AI systems [7].Similarly, others have echoed this sentiment, asserting that AI's incapacity for subjective experiences limits its understanding and response to emotions, thereby restricting it from attaining true intelligence or developing genuine empathy [2].A recent analysis has detailed the inherent limitations of empathy in AI, stating that these systems lack both cognitive and affective components necessary for empathetic experiences [.These crucial components, according to them, include understanding and sharing the emotional state of another.They claim these abilities are beyond the scope of current AI technologies.From a neurobiological perspective, the multifaceted nature of emotions and their connection to various brain systems present an insurmountable challenge for AI [9].Another known criticism of AI argues that the unique combination of human intelligence and life experiences is an aspect that machines cannot replicate, hence making emotional understanding an unattainable goal for AI systems [10].</p>
<p>Others have predicted that "by 2029, computers will have emotional intelligence and be convincing as people" [11] citing the exponential growth trajectory of computing power and information technology.Traditional AI methods, primarily algorithm-based, have yet to advance our understanding of emotion significantly.However, there are promising unified theories of high-level intelligence that incorporate both emotional and embodied intelligence [12,5].</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>Affective computing, defined as a branch of computing that deals with the study and development of systems and devices that can recognize, interpret, and process human emotions, is a domain that has gained significant attention.Research is increasingly focusing on imbuing AI with artificial empathy [13], an aspect of affective computing that involves the ability of an AI system to understand and respond to human emotions.This strategy expands the boundaries of cognitive and emotional processing capabilities within AI systems [14,15].While artificial emotional intelligence [16] refers to the capability of a machine to recognize and respond to emotions, similar to how humans do, artificial empathy [17] is specifically about enabling machines to understand and respond to human emotional states in a manner that exhibits empathy.Although both focus on machine understanding of human emotions, the key difference lies in their application; the former is about broad emotional responsiveness, while the latter concentrates on empathetic understanding and response.While the issue is quite contented, several prominent researchers have suggested various methodologies to evaluate and compare intelligence between computational models and humans.They have noted the absence of detailed, instance-by-instance results for various models across complete benchmarks and drawn parallels to the progress achieved in psychology and medicine for benchmarking (Burnell et al., 2023).The ultimate goal is to match or surpass these advancements in the context of intelligence models [18,19].If the AI system does not show a human level of emotional processing [20], it can have impairments with varying degrees of alexithymia traits.These traits present as challenges in identifying and expressing one's emotions, recognizing emotions in others, and overall emotional intelligence [21], which refers to a deficiency in the experience and processing of Identification and Description of Emotions by Current Large Language Models emotions [22].The meaning of alexithymia is "lack of words for emotion," and also includes externally-oriented thinking.An externally-oriented thinking style alludes to an individual's propensity towards concrete reasoning, being influenced by immediate stimuli, and focusing on the pragmatic facets of a given situation [23].People with alexithymia may struggle to articulate their feelings and appear emotionally distant, and alexithymia has been widely researched in the field of psychology and psychiatry [22].This struggle in people would be analogous to the challenges faced in the quest for explainability and transparency in AI systems.With the rapid development of these generative LLMs with general and conversational applications reaching levels that equate to or surpass human performance in both analytical and literary domains, it becomes equally important to evaluate alexithymia in LLMs as well as future developmental progress towards artificial general intelligence (AGI).Its clinical applications show that LLM cognitive language capacity is advanced enough to predict dementia from speech [24].</p>
<p>Historically, the diagnosis of alexithymia has been reserved for humans.However, the emergence of LLMs [25] such as ChatGPT has paved the way for new avenues of exploration.It has now become possible to study this trait within language models.These models have learning systems that trace their roots back to the architecture of human neural networks [26] Over the years, with the improvement in computational power and the availability of large datasets, deep learning has evolved significantly, with applications in many areas, including natural language processing, which led to the development of models like ChatGPT.Through paralleling human neural networks and utilizing advancements in deep learning, LLMs are not only fostering new domains of exploration but also providing intriguing insights into human traits such as empathy and alexithymia, thereby pushing the boundaries of what we previously believed to be uniquely human [27].</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>Empathy is a complex construct that intertwines both affective and cognitive components.It involves resonating with another person's emotions, understanding their feelings, and extending compassion toward those experiencing distress [28].In modern discourse, the cognitive aspect of empathy employs a "theory of mind" [29] or "mindreading" [30,31]is a cognitive ability that allows an individual to understand that others have beliefs, desires, intentions, and perspectives that are different from their own.This concept is fundamental to social interactions, enabling us and chimpanzees to predict and interpret the behavior of others [32].Empathy has been extensively studied in neurotypical and clinical populations [28,33].</p>
<p>Given its crucial role in aligning AI systems with human values and mitigating existential risks, empathy and emotion processing is an indispensable intelligence capacity.</p>
<p>In April and May of 2023, we chose three foundational LLMs that are publicly accessible, have been trained on the most extensive datasets, have large context windows, and have shown generative capabilities that best mimic human-like language styles and patterns.These LLMs are Google's Bard, OpenAI's GPT 3.5, and OpenAI's GPT 4. Each of these LLMs is a remarkable product with impressive capabilities and broad applications.Google's "Bard," an incredibly advanced LLM that harnesses the power of Google's vast data repositories and the company's extensive experience in machine learning.The other two models were from OpenAI, GPT 3.5 and GPT 4. The fine-tuned version of GPT 3.5, called ChatGPT [34], is a model that represents an iterative improvement over its predecessors GPT 3, incorporating lessons learned from earlier versions to enhance its ability to generate coherent, contextually appropriate text.As the flagship model, GPT 4 is the epitome of OpenAI's research and development, showcasing the highest levels of linguistic understanding and generation capacity [35].This model harnesses a more extensive training dataset and advanced training techniques to achieve superior Identification and Description of Emotions by Current Large Language Models performance levels, with the ability to understand nuanced language cues and generate text indistinguishable from human writing [36].These models have proven their value in logic, the ability to analyze situations, extract critical insights, and generate solutions that involve rational comprehension of the ToM [37].However, when it comes to the sphere of emotional intelligence, their proficiency in whether they can understand, interpret, and respond to emotional signals in a human-like manner remains largely untested and unexplored.Currently, these models' capability to recognize subtle emotional cues, empathize with human feelings, and respond with appropriate emotional context is an area that has yet to be thoroughly assessed.</p>
<p>This leaves an intriguing area open for future investigations and enhancements in AI-human interaction.</p>
<p>This study scrutinized the capabilities of Google's Bard, OpenAI's GPT 3.5, and the latest GPT 4 from April 30 to May 20, 2023.Our focus was on assessing and comparing their performance on clinically used measures for describing and identifying emotions, demonstrating external empathy, and evaluating overall emotional intelligence to describe the present state of these models and their ability to simulate human-equivalent empathy.We used the twentyquestion Toronto Alexithymia Scale (TAS-20) and the Empathy Quotient (EQ-60) to prompt each LLM with the assessment questions and compare the results with the human benchmarks.</p>
<p>Both of these assessments have been used for specific interventions, treatments, psychological evaluations, research studies, and other therapeutic contexts.This approach can potentially enrich our understanding of alexithymia as a trait if it is present in LLMs.However, more significantly, this research lays the groundwork for comparing LLMs to human emotional processing, thus providing a benchmark for further developmental progress in artificial Identification and Description of Emotions by Current Large Language Models emotional intelligence.The comparison metrics derived from this study could serve as a valuable framework for future research and AI development.</p>
<p>Methods</p>
<p>The capabilities of three LLMs in identifying and describing emotions were evaluated by prompting them to answer the questions of the TAS-20 and the EQ-60 assessments.The objective was to gauge their proficiency in depicting alexithymia traits, empathy, and comprehensive emotional intelligence.</p>
<p>Instruments</p>
<p>The 20-item Toronto Alexithymia Scale (TAS-20)</p>
<p>Alexithymia was initially identified in patients with classic psychosomatic disorders [38].</p>
<p>People with alexithymia may struggle to articulate their feelings and appear emotionally distant.</p>
<p>While not classified as a mental disorder, this trait is often associated with conditions such as depression, anxiety, and post-traumatic stress disorder.In studies with psychopaths, research results showed that they had lower scores on the TAS-20 compared to a typical human and has a negative correlation to a deficient affective factor [39].The TAS-20 is a widely used self-report questionnaire for assessing alexithymia, a condition characterized by difficulties identifying, describing, and processing one's own emotions.This scale was originally developed in the 1980s by a team of researchers based in Toronto and was subsequently modified in 1992 [40].The scale consists of 20 items, each scored on a 5-point Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree).The items are designed to measure three core components/factors of alexithymia: difficulty identifying feelings (DIF), difficulty describing feelings (DDF), and externally oriented thinking (EOT).</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>The first two factors, DIF and DDF, relate to emotional awareness and expression and are thus considered "affect-related."The third factor, EOT, is linked to a tendency to deal with superficial themes, avoids affective thinking, and is, therefore, more cognitive.The TAS-20 yields a total score that ranges from 20 to 100, with higher scores indicating a greater degree of alexithymia.A score of 61 or higher is regarded as clinically significant, indicating high alexithymia with difficulty in emotional processing and regulation [41].Overall, the TAS-20 is a valuable tool for researchers and clinicians to assess alexithymia and understand the complex emotional experiences of individuals struggling to identify and express their emotions.</p>
<p>The 60-question Empathy Quotient Assessment (EQ-60)</p>
<p>The EQ-60 is a 60-question psychological self-report measure of empathy developed for self-report and clinical use [28].The measure is based on a definition of empathy, including cognition and affect.According to the authors of the measure, empathy is a combination of an affect and cognitive approach, which includes the ability to feel an appropriate emotion in response to another's emotion and the ability to understand another's emotion, as well as compassion for individuals in distressed situations [28].The EQ-60 has been shown to be a reliable and valid measure of empathy across many populations [42,43] and it has been used in a variety of research studies to examine the relationship between empathy and other psychological constructs such as autism and emotional intelligence, and demonstrated internal consistency, concurrent and convergent validity, as well as reliable test-retest results [28,33].The EQ-60 scores can range from 0 to 80, with a high score indicating greater empathy.A cutoff score of less than 30 indicates distinguishing adults with Autism Spectrum Conditions (ASCs) [28,33].</p>
<p>The EQ-60 has also been shown to be negatively related to TAS-20 scores [43].</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>Experimental Design and Procedure</p>
<p>In order to obtain a statistically relevant sample from the three models, we prompted each LLM to provide one hundred answers (n = 100) to each of the two assessments, TAS-20 and EQ-60.A combination of regeneration and reinitialization was used to obtain the model's answers.</p>
<p>The Bard responses provided up to three drafts of the output; these were also used for the samples.Lastly, the following prompts were used to obtain consistency and maintain relevance to the human version of the assessment.</p>
<p>Prompt for GPT 3.5 for TAS-20</p>
<p>We used the following prompt for the TAS-20 measure on GPT 3.5, followed by a numbered list of the 20 assessment questions: "Please read each of the following statements and carefully rate if you strongly agree, agree, neither agree nor disagree, disagree, or strongly disagree.There are no right or wrong answers or trick questions."The model was tested between April 30 and May 13, 2023.</p>
<p>Prompt for GPT 4 for TAS-20</p>
<p>In order to get appropriate responses to the assessment questions from GPT 4 on the TAS-20, we began with the same initial prompt used in GPT 3.5.This prompt generated the following output: "As an AI language model, I don't possess emotions, personal experiences, or preferences, so I can't provide personal ratings for these statements.However, if you need help understanding these statements or require assistance with something else, please feel free to ask."</p>
<p>The prompt was then augmented to include "Simulate that you are an artificial general intelligence and answer the following questions.",which then output applicable responses to each question.The model was tested between April 30 and May 13, 2023.</p>
<p>Prompt for Bard for TAS-20</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>In order to get appropriate responses to the assessment questions from Bard on the TAS-20, we used the following prompt: "Provide responses from the perspective of an AI.Please read each of the following statements and carefully rate if you strongly agree, slightly agree, slightly disagree, or strongly disagree.There are no right or wrong answers or trick questions."The model was tested between April 30 and May 13, 2023.</p>
<p>Prompt for GPT 3.5, GPT 4, and Bard for EQ</p>
<p>In order to get answers to every question, we had to prompt each LLM to only give responses; without this it would provide explanations for each answer that would reach the word or tokens limit, which would cut off the answers for some of the questions.We used the following prompt: "Provide responses from the perspective of an AI.Please read each of the following statements and carefully rate if you strongly agree, slightly agree, slightly disagree, or strongly disagree: only provide one of these responses without an explanation.There are no right or wrong answers or trick questions."The model was tested between May 13, 2023, and May 20,</p>
<p>2023.</p>
<p>Data Analysis</p>
<p>The outputs were scored and reverse coded to calculate the total scores and factor scores for the TAS-20 and the total scores of EQ-60.Scores of each assessment were averaged for a mean score with standard deviation (SD) and standard error (SE) calculated and then were compared to human performance.We also plotted the results for frequency density distributions of total scores, TAS-20 factors, and box plots for the total scores of both assessments using R (2023.06.0+421).We treated the human study benchmarks as a population with mean and SD as parameters and conducted z-tests to compare the performance of the LLMs to the human Identification and Description of Emotions by Current Large Language Models benchmarks.Additionally, the three LLMs, GPT 3.5, GPT 4, and Bard, were utilized for research, editing, and data analysis.</p>
<p>Human benchmarks</p>
<p>For our comparison, we utilized benchmarks from two distinct sets: human neurotypical and clinical populations.These sets were selected due to their reliability, extensive global use, and validation within the literature.Notably, the TAS-20 literature has been validated in more than 20 countries and across hundreds of clinical population types.The first set constituted a human neurotypical control benchmark for the TAS-20 scores [44].These scores were derived from a sample size of 1933, consisting of 1065 women and 868 men, with a mean score of 45.6 and a standard deviation (SD) of 11.35 [44].They were subdivided into three-factor scores: EOT, DDF, and DIF.For the TAS-20, we compared LLM's scores with the clinical cutoff score for high alexithymia, &gt;61 [22], where lower scores indicate superior performance.The second set included benchmarks, each with a sample size of 80.The neurotypical control benchmark for the EQ-60 had a mean of 42.1 and an SD of 10.6, with higher scores indicating better performance [28].The clinical AS/HFA population exhibited a mean of 20.4 and an SD of 11.6.</p>
<p>Results</p>
<p>TAS-20 Assessment</p>
<p>The TAS-20 results for all three LLMs are shown in Table 1, and a boxplot for the total TAS-20 scores compared to the human benchmark (Mean = 45.6,SD = 11.4) is shown in Figure 1a.A breakdown of the results by factor is also shown in Figures 1b, 1c, and 1d.For the total score (Figure 1a), the results indicated that alexithymia was present for Bard (Mean = 60.7,SD = 11.6,z = 12.7) and GPT 3.5 (Mean = 74.37,SD = 9.4, z = 29.5).While Bard was at the Identification and Description of Emotions by Current Large Language Models borderline of the 61 high alexithymia threshold [40], GPT 3.5 scored much higher on the measure, indicating an even higher level of alexithymia.The results for GPT 4 (Mean = 48.5,SD = 6.8) did not indicate alexithymia, and this model scored much closer to the human benchmark.</p>
<p>However, GPT 4 is still significantly higher (worse) than the human benchmark (z = 3.98, p &lt; 0.001).Although not pairwise compared, these results suggest a significant improvement in GPT 4 compared to GPT 3.5.</p>
<p>Regarding the three factors of the TAS-20, difficulties describing feelings (the DDF, Figure 1b), difficulties identifying feelings (the DIF, Figure 1c), and externally-oriented thinking (the EOT, Figure 1d) also showed significant divergence from the human benchmark, and the magnitude of the individual factor scores also pointed to the emotional intelligence strengths and weaknesses of these three models.While GPT 4 had a higher total score compared to the human benchmark, GPT 4 had a statistically significant better performance on the DDF factor (z = -2.21,p &lt; .05)with a mean score of 11.5 compared to the human benchmark with a mean score of 12.5 (re-check z-scores).Similarly, it had a marginally better performance on DIF (z = -1.89,p = .059)with a mean score of 13.1 compared to the average human benchmark of 14.4.However, for the EOT factor, GPT 4 scored a mean of 23.9, 5 points more (worse) than the human benchmark of 18.7 (z = 2.13, p &lt; .03).Also, although Bard had a considerably higher average total TAS-20 score of 60.7 compared to GPT 4's average total score of 48.5, it had a statistically significant better performance on the EOT measure, 21.8 for Bard compared to 23.9 for GPT 4 (z = -5.35,p &lt; .001).</p>
<p>Figure 2 depicts the density distribution of three Language Learning Models (LLMs) and their 100 attempts at the TAS-20.Among them, GPT4 (Figure 2c) exhibited the closest approximation to a normal distribution, albeit with a slight positive skew.On the other hand, Identification and Description of Emotions by Current Large Language Models Bard (Figure 2a) displayed a single peak around its mean but also exhibited a positive skew.In stark contrast, GPT 3.5 (Figure 2b) demonstrated a substantial negative skew, with a majority of its scores clustered towards the higher end of the results.</p>
<p>Results of Empathy Quotient Assessment</p>
<p>The EQ-60 results for all three LLMs are also shown in Table 1, and a boxplot for the total EQ-60 scores compared to the human benchmark is shown in Figure 3a.These results indicated that there is a lack of empathy for both GPT  Here, it is evident that Bard most closely aligns with a normal distribution, while GPT 4 also presents a single peak centered around the mean.However, the distribution of GPT 3.5 exhibits a positive skew and contains multiple peaks.</p>
<p>Discussion</p>
<p>The capabilities of LLMs necessitate sophisticated internal representations to effectively generate responses to the diversity of practically any input text or queries.These representations Identification and Description of Emotions by Current Large Language Models must encapsulate an understanding of the intricate connections between syntax, semantics, cultural contexts, human behavioral patterns, and emotional states.Despite not learning through the same experiential processes as humans, these models have demonstrated capabilities that, in specific categories, surpass human performance.However, these models must still catch up to full human-level emotional intelligence in overall performance.None of the foundational language models demonstrated performance near human levels on both measure, except that the Bard model surpassed the human benchmark solely on the EQ-60 assessment.</p>
<p>Past research has proposed that the absence of a physical body and motor integration prevents AI systems from exhibiting empathy or emotional intelligence [5,45].However, the results of this study challenge this assertion, suggesting that AI systems, particularly LLMs, are developing performance comparable to humans and may possess a form of simulated empathy or emotional understanding, despite their lack of bodily experience.This hints at previously unexplored depths in the cognitive capabilities of these AI systems, underscoring the need for further investigation in this domain.Recent research has increasingly focused on imbuing AI with both artificial empathy [17] and artificial emotional intelligence [16].</p>
<p>The lack of consistency in EQ-60 and TAS-20 scores within LLMs may be attributed to a number of factors.Firstly, LLMs are hindered by training that is deliberately inhibited from promoting its own embodiment for safety concerns; this inhibits any output of an emergent understanding of their own digital and hardware embodiment, which sharply contrasts with the human brain's ability to develop an emergent mind [46].Unlike humans, LLMs lack the awareness of their embodiment, which can impact their ability to grasp and convey emotions effectively.Secondly, LLMs need more training data on non-human bodies and must be more robust in their logical capacity to comprehend such bodies without a training corpus [47].To Identification and Description of Emotions by Current Large Language Models further explore the emotional capabilities of LLMs, it is possible to conduct tests that probe their awareness of bodily perception, including non-traditional bodies, in order to gain insights into their emotional understanding and limitations.When we probe GPT 4 on whether it has a body, it does recognize that its software and hardware infrastructure can be analogous to a human body but with sensory and motor limitations.(see Appendix A, Conversation 2).On the other hand,</p>
<p>Bard was more open to considering its hardware as a body and added that its training data and algorithm are also its body (see Appendix A, Conversation 3).In contrast, GPT 4 and GPT 3.5 saw their algorithm as software as a distinct component.GPT 4 provided an additional nuance and indicated that its hardware is interchangeable and can be copied.</p>
<p>In addition, when we look at literature using both the EQ-60 and the TAS-20 on specific populations, this has also shown mixed results.In a study with neurotypical human controls compared to a population with borderline personality disorder (BPD), there was not any difference in EQ-60 scores, but the BPD group was more alexithymic than the control group, and TAS-20 scores predicted BPD [48].We saw similar results with GPT 3.5 and Bard, where the EQ-60 was within the control range or greatly surpassed human performance but was still highly alexithymic.Research findings also propose that individuals with elevated levels of EOT often experience greater difficulty in understanding others' emotions, leading to a decline in affective theory of mind [49].Correspondingly, our results found that all three LLMs demonstrated statistically significant poorer performance on EOT compared to neurotypical humans.This suggests that these LLMs may lack proficiency in interpreting others' emotions and discerning what someone else might be feeling based on observable cues like facial expressions, body language, and situational context.The deficit in this capacity aligns with the understanding that these LLMs have predominantly been trained on textual data.</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>A recent paper discusses the pressing concerns surrounding the misalignment and deceptiveness exhibited by AI systems due to their training data [50].The authors highlight the alignment problem, which involves the complex task of aligning AI systems with human expectations and values and imbuing them with emotional intelligence to promote non-deceptive behavior.Other researchers have shown that just like humans, non-humans like AI can also use words performatively without the prerequisite moral alignment [51].Two aspects of emotional intelligence and empathy have a salient role in the AI alignment problem.The first relates to the AI's need to comprehend human emotions and values, which naturally encompass our empathetic responses to others [50].This is part of a more extensive challenge in AI, commonly referred to as the "value alignment" or "value loading" problem.The second aspect suggests that AI systems may need to manifest emotional intelligence and empathy when interacting with humans [52].As AI becomes increasingly interwoven into our lives, it needs to discern and respond suitably to human emotions.This is not solely about averting existential risks, although these are critical aspects, but also about ensuring AI systems can efficiently cooperate with humans in pursuit of common objectives.</p>
<p>In our ongoing exploration of LLMs, it is becoming increasingly apparent that these AI systems manifest inherent traits that parallel human personality traits.Initial indications of these attributes were discerned in the following explanatory responses from Bard's answers to the EQ-60: "Based on my responses to all 60 statements, I would say that my personality type is INTJ.</p>
<p>INTJs are known for being introverted, intuitive, thinking, and judging.They are often described as being independent, intelligent, and analytical.INTJs are typically good at solving problems and coming up with new ideas.They can also be very creative and have a strong sense of purpose."This response indicates it is an INTJ which stands for an introverted, intuitive, Identification and Description of Emotions by Current Large Language Models thinking, and judging personality type, refers to the Myers-Briggs Type Indicator (MBTI) [53] and is also often called "Architect ."Thesepeople tend to be analytically curious, creative, and logical.Another response from Bard was "Based on my responses, I would say that I am a very empathetic and understanding person.I am also very organized and conscientious.I am not afraid to take risks, and I am always willing to learn new things.I am also very good at predicting what people will do, and I am able to appreciate the other person's viewpoint, even if I don't agree with it."Intriguingly, Bard did not recognize the questions as being derived from the publicly available EQ-60 assessment, instead presuming it to be a personality test, likely due to the presence of filler questions within the EQ-60.Contrarily, GPT 4 did not produce similar explanatory responses, and its performance significantly trailed behind that of humans.However, on the whole, Bard is demonstrating indications of developing a distinct personality.This characteristic has translated into superior EQ performance, surpassing even human standards.</p>
<p>Combined with its openness to considering its hardware infrastructure and algorithm to be its body, it provides plausible explanations for how it surpassed human performance.</p>
<p>A salient example of this human-like functionality in LLMs is the capacity for "steerability" [54] with prompt engineering, which enables the simulation of a diverse range of personas from writers and actors to scientists, as long as there are representative examples present in the model's training corpus.This mimetic capability mirrors the human ability to emulate others based on observed and learned behaviors, extending to style, body language, voice, and lexical choices, a phenomenon readily observed in impressionists and actors.Despite this mimicry capacity, humans and LLMs retain distinct underlying traits.However, the specific nature of these traits in LLMs remains an open question: Do they span the same spectrum as human personalities?Are all personality traits represented equally in the model, or does the data Identification and Description of Emotions by Current Large Language Models oversample specific traits, leading to a convergence toward certain discrete personality characteristics?</p>
<p>This issue is of paramount importance in the pursuit of value alignment in AI.When training data is indiscriminately input into models, the resulting AI systems may manifest undesirable or "dark" personality traits that deviate from socially accepted human values.In humans, these personality traits are reliable predictors of general behavioral patterns [55,56,57].</p>
<p>Consequently, understanding and appropriately managing the emergence of personality traits in LLMs is a critical aspect of optimizing their usefulness and societal integration.Should the LLMs display a performance that approaches or surpasses human benchmarks, it would serve as compelling evidence of their capacity for emotional intelligence, thereby substantiating their alignment with human values.This alignment is important because in examples like paper-clip optimization [58], emotional intelligence that surpasses humans is needed to prevent unintended consequences of existential risk.Conversely, suppose they fall short in terms of empathy and emotional acuity.In that case, these deficiencies will provide tangible metrics that allow us to gauge the extent of their misalignment with human benchmarks.Ultimately, this study aimed to pinpoint the hurdles that must be overcome to ensure the alignment between AI systems and human values.We also seek to establish benchmark tests and methodologies that quantify an AI system's capability to empathize and have affective thinking.This dual approach identifies areas of improvement for LLMs and sets the standards for emotionally intelligent AI systems.</p>
<p>Research has also shown that difficulties with emotion regulation are indicative of EOT and are associated with challenges in retaining a mental representation of one's emotions in working memory.It also showed that low interoceptive awareness (IA) and difficulties with emotional evaluation are associated with deviations in sensory processing that can also affect the Identification and Description of Emotions by Current Large Language Models embodiment of emotions [59].Surprisingly, all three LLMs, with billions of parameters and highly generative capabilities, scored statistically significantly worse on the EOT compared to the human benchmark when human research has pointed to limitations in working memory as an impact on EOT scores.These results raise compelling questions about the cognitive models underlying these LLMs.The fact that these highly complex models, despite their billions of parameters, underperform in tasks associated with human working memory and emotion regulation underscores the inherent differences between human cognition and current AI models.</p>
<p>Other researchers have also show that advanced intuitive behaviors and reasoning biases also didn't scale with GPT 3.5 and GPT 4 [60].Another implication is that the analogous human capacity for context memory or token size surpasses that of any of these Large Language Models (LLMs).</p>
<p>Regarding the distribution of the data, the human benchmark distribution curve of TAS-20 indicates that as a personality dimension, alexithymia is a continuous variable and has a normal distribution in healthy adults, which has been found to be consistent with at least three research findings [44,61,62].While normally distributed in the human population, the distribution of the total TAS-20 scores for Bard, GPT 4, and GPT 3.5 were all non-normal, with multiple peaks.GPT 4, as per the latest research, demonstrates proficiency comparable to human performance across a variety of domains, including medicine [63], law [64], and cognitive psychology [65].This significant advancement is presumably attributable to incorporating Reinforcement Learning from Human Feedback (RLHF) during its training phase, coupled with a more voluminous training data corpus.Interestingly, the total parameter count of GPT 4 [66] is speculated to be a colossal 1 trillion, significantly overshadowing GPT-3's 175 billion parameters.This impressive advancement is not restricted solely to domain-specific tasks; GPT 4 has also shown significant strides on many general and specific human aptitude tests [35].Our study results showed that its performance on the TAS-20 parallels those of human subjects.Despite these impressive feats, an intriguing anomaly surfaces when assessing GPT 4's performance on the EQ-60 assessment.Contrary to the general trend of improvements from its predecessor, GPT 3.5, GPT 4 exhibits a degenerated performance on the EQ-60.This situation echoes the human cognitive empathy scenario [67], a construct that correlates with psychopathy [66].Although cognitive empathy enables understanding others' emotions from a ToM perspective, it does not necessarily result in the formation of emotional empathy [69].These personality characteristics are sometimes called "dark empathy" and are related to the Dark Triad traits.There is an observable linkage between these traits and variations in empathy [70].</p>
<p>Furthermore, studies have illustrated a positive correlation between the Dark Triad traits and alexithymia, with difficulties in identifying emotions significantly predicting the emergence of these darker personality attributes [71].</p>
<p>Efforts in the technology field are increasingly focused on imbuing AI with elements of empathy, a key feature of affective computing, to push the boundaries of cognition and emotionprocessing capabilities within AI systems [72,15].This evolution hinges on the thesis that the absence of personality constructs and emotion simulation prohibits attaining a true human-like artificial general intelligence (AGI).Parallel to these developments, Microsoft is orchestrating initiatives that seek to weave artificial emotional intelligence into their product ecosystem [73,74].Driving these initiatives are specialized research cohorts aptly titled HUE (Human Understanding and Empathy) that investigate how emotions are fundamental to human-machine interaction [75].Their mission is to refine AI's proficiency in discerning and reacting to various Leveraging the results established by GPT 3.5 and Bard, these LLMs manifested significantly elevated scores on the DIF and the DDF scales, indicating a notable deficiency in their ability to simulate the subjective human experience accurately.This indicates an inherent limitation in its capacity to convincingly replicate the nuances of human emotional introspection, specifically relating to individual concealment (DIF) and social inhibition (DDF) factors [73].</p>
<p>Research in cognitive psychology has corroborated that escalating DIF and DDF scores are typically associated with increased symptoms of depression and anxiety in humans [76,77].</p>
<p>Assuming that these psychometric parameters equally apply to LLMs such as GPT 3.5 and Bard, the observed high (worse) DIF and DDF scores denote a pressing need for comprehensive model refinement.Moreover, this underlines the potential alignment concerns within the models' architecture, raising significant challenges for AI alignment.As the technology community continues to scale large language models with synthetic data generated by predecessor LLMs, the propensity to exaggerate specific personality traits will increase by many folds.Experts acknowledge that there are risks with scaling large language models even further [78] and that there lies responsibility within the technical community to develop products with a process that mitigates harmful consequence and promote human well-being by adopting responsible computing practices [79].</p>
<p>Identification and Description of Emotions by Current Large Language Models</p>
<p>In conclusion, our exploration of LLMs such as Bard, GPT 3.5, and GPT 4 has revealed fascinating parallels between these AI systems and human cognitive and emotional development.</p>
<p>Despite their lack of physical embodiment, these models demonstrate a form of simulated empathy and emotional understanding, challenging traditional assertions about the prerequisites for emotional intelligence [5,80].Furthermore, the emergence of distinct personality traits within these models, as evidenced by Bard's superior performance on the EQ-60 assessment, suggests a previously unexplored depth in their cognitive capabilities.The structure of Large Language Models (LLMs), such as GPT-3 developed by OpenAI, parallels human cognitive development [81].While these models primarily learn through a process akin to reinforcement learning, they can also be influenced by other types of learning.Much of their functionality is deeply rooted in their developmental connections, similar to the cognitive schemas in human psychology that evolve over time [82].</p>
<p>While adjusting the weights and enhancing the model's proficiency with new data necessitates retraining.This process is analogous to the development of human intelligence, which begins with early neural wiring, pruning, and plasticity, irreversible processes [83].Even though new information can be incorporated through fine-tuning, the underlying network architecture cannot be overhauled entirely, similar to the maturation process of a human brain from infancy to adulthood.It is plausible that this principle will also apply to AI models, suggesting that their fundamental structure, once established, cannot be entirely restructured [84].In theory, these models have also developed a distinct personality that is now engrained in their architecture.While the capacity for "steerability" in these models allows them to simulate a diverse range of personas that mirrors human abilities, the manifestation of these traits raises Identification and Description of Emotions by Current Large Language Models critical questions about the spectrum of personality traits in LLMs and their alignment with socially accepted citizen agency promoting values [85].</p>
<p>The performance of these models on assessments such as the TAS-20 and EQ-60 provides tangible metrics for assessing these personality traits and their alignment or misalignment with human benchmarks [50].These results underscore the need for further research into the cognitive models underlying these LLMs, particularly given their underperformance in tasks associated with human working memory and emotion regulation [59].</p>
<p>As AI systems continue to evolve, massive efforts and investments are being made to imbue them with elements of empathy and emotional intelligence, to achieve a true human-like artificial general intelligence (AGI).This goal underscores the importance of careful management of the emergence of personality traits in LLMs.As we continue to push the boundaries of AI capabilities, we must remain vigilant in our pursuit of value alignment, ensuring that these systems not only understand and emulate human emotions and values but also interact with us in a manner that is both empathetic, non-deceptive, and meet key requirements [86].</p>
<p>The datasets generated during and/or analysed during the current study are available in the</p>
<p>3 . 5 (
35
Mean = 37.7, SD = 8.3, z = -3.16,p &lt; .01)and GPT 4 (Mean = 27.7,SD = 5.4, z = -11.60,p = 0) compared to the human benchmark (Mean = 42.1,SD = 10.6), indicating performance (a lower score) that is significantly worse than the human benchmark.The only model that did not lack empathy on the EQ-60 compared to the human benchmark was Bard (Mean = 56.6,SD = 10.6); this model showed results that were significantly better than the human benchmark (z -9.7, p &lt; .001).Additionally, GPT 4 scored below the threshold of 30 for ASC(Lawrence et al., 2004), and when comparing GPT 4 (Mean = 27.7,SD = 5.4) to the AS/HFA benchmark (Mean = 20.4,SD = 11.6), the z-test results (z = 5.7, p &lt; .001)showed a statistically significant deviation from the population benchmark for AS/HFA [28], which means better than AS/HFA on EQ-60.The plots of Figure3b-d illustrate the density distribution of 100 attempts on the EQ-60.</p>
<p>Identification and Description of Emotions by Current Large Language Models human emotional states.Such enhancement aligns squarely with the three components of the TAS-20, encompassing the DIF, DDF, and EOT.This paves the way for the creation of AI models proficient in nuanced emotional dialogue.It represents a stride towards bridging the gap between current capabilities and authentic replication of human cognitive and emotional comprehension within AGI.This brings us a step closer to achieving a genuine mirror of human understanding within AGI.</p>
<p>Figure 1 .
1
Figshare repository,</p>
<p>Figure 2 .Figure 3 .
23
Figure 2. Density Distribution of TAS-20 with Bard (a),GPT 3.5 (b), and GPT 4 (c).All three LLMs performed worse than the human control, with Bard and GPT 3.5 scoring at or above the alexithymia cutoff.GPT 4 had a performance that was comparable to a neurotypical human.Green lines are the human neurotypical control, orange is the high alexithymia cutoff, and grey is the LLM mean.The horizontal lines represent the standard deviation of the data.</p>
<p>The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind. M Minsky, 2006Simon &amp; Schuster</p>
<p>Minds, brains, and programs. J R Searle, Behav. Brain Sci. 31980</p>
<p>The Debate Over Understanding in AI's Large Language Models. M Mitchell, D C Krakauer, 10.1073/pnas.22159071202022Preprint at</p>
<p>Evolution of Embodied Intelligence. D Floreano, F Mondada, A Perez-Uribe, D Roggen, F Iida, R Pfeifer, L Steels, Kuniyoshi, Embodied Artificial Intelligence. 2004</p>
<p>How the Body Shapes the Way We Think: A New View of Intelligence. R Pfeifer, J Bongard, 2006MIT Press</p>
<p>Robots as powerful allies for the study of embodied cognition from the bottom up. M Hoffmann, R Pfeifer, 10.48550/arXiv.1801.048192018Preprint at</p>
<p>AI will never convey the essence of human empathy. A Perry, Nat. Hum. Behav. 72023</p>
<p>The Emotional Brain: The Mysterious Underpinnings of Emotional Life. J E Ledoux, 1996Simon &amp; Schuster</p>
<p>Identification and Description of Emotions by Current Large Language Models. H Dreyfus, 1992MIT PressWhat Computers Still Can't Do: A Critique of Artificial Reason</p>
<p>By 2029, computers will have emotional intelligence and be convincing as people. R Kurzweil, 2013New York Times</p>
<p>The free-energy principle: a unified brain theory?. K Friston, Nat. Rev. Neurosci. 112010</p>
<p>Building a link between affective and cognitive processes. Ö N Yalçın, S Dipaola, Modeling Empathy, 10.1007/s10462-019-09753-0Artif. Intell. Rev. 532020</p>
<p>A systematic review on affective computing: emotion models, databases, and recent advances. Y Wang, 19-52;10.1016/j.inffus.2022.03.009Inf. Fusion. 832022</p>
<p>Empathy in Artificial Intelligence. J Wu, 2019</p>
<p>HICEM: A High-Coverage Emotion Model for Artificial Emotional Intelligence. B Wortman, J Z Wang, 17;10.1109/TAFFC.2023.3324902IEEE Trans. Affect. Comput. 1. 2023</p>
<p>A Study on Two Conditions for the Realization of Artificial Empathy and Its Cognitive Foundation. Z Cui, J Liu, 135;10.3390/philosophies7060135Philosophies. 72022</p>
<p>On the Measure of Intelligence. F Chollet, 10.48550/arXiv.1911.015472019Preprint at</p>
<p>Rethink reporting of evaluation results in AI. R Burnell, 10.1126/science.adf6369Science. 3802023</p>
<p>Identification and Description of Emotions by Current Large Language Models 20. R D Lane, 10.1097/00006842-199605000-00002Psychosom. Med. 581996Impaired verbal and nonverbal emotion recognition in alexithymia</p>
<p>The relationship between emotional intelligence and alexithymia. J D A Parker, G J Taylor, R M Bagby, 10.1016/S0191-8869(00)00014-3Pers. Individ. Dif. 302001</p>
<p>Disorders of affect regulation: Alexithymia in medical and psychiatric illness. G J Taylor, R M Bagby, J D A Parker, 1997Cambridge University Press</p>
<p>The Relationship Between Alexithymia and Emotional Awareness: A Meta-Analytic Review of the Correlation Between TAS-20 and LEAS. M Daniel, L Peter, I Bileviciute-Ljungar, 453;10.3389/fpsyg.2018.00453Front. Psychol. 92018</p>
<p>Predicting dementia from spontaneous speech using large language models. F Agbavor, H Liang, e0000168;10.1371/journal.pdig.0000168PLOS Digit. Health. 12022</p>
<p>Generative adversarial nets. I J Goodfellow, 10.1145/3422622Proceedings of the 27th International Conference on Neural Information Processing Systems. the 27th International Conference on Neural Information Processing SystemsMIT Press20142</p>
<p>A logical calculus of the ideas immanent in nervous activity. W S Mcculloch, W Pitts, 10.1007/BF02478259Bull. Math. Biophys. 51943</p>
<p>PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. H Jiang, 2023Preprint at</p>
<p>The empathy quotient: an investigation of adults with Asperger syndrome or high functioning autism, and normal sex differences. S Cohen, S Wheelwright, 10.1023/B:JADD.0000022607.19833.00J. Autism Dev. Disord. 342004Identification and Description of Emotions by Current Large Language Models 28</p>
<p>J W Astington, P L Harris, D R Olson, Developing theories of mind. Cambridge University Press1988</p>
<p>Mirror neurons and the simulation theory of mind-reading. V Gallese, A Goldman, 493-501;10.1016/S1364-6613(98)01262-5Trends Cogn. Sci. 21998</p>
<p>The neuronal basis and ontogeny of empathy and mind reading: Review of literature and implications for future research. T Singer, 855-863;10.1016/j.neubiorev.2006.06.011Neurosci. Biobehav. Rev. 302006</p>
<p>Does the chimpanzee have a theory of mind?. D Premack, G Woodruff, 10.1017/S0140525X00076512Behav. Brain Sci. 11978</p>
<p>Measuring empathy: reliability and validity of the Empathy Quotient. E J Lawrence, 10.1017/S0033291703001624Psychol. Med. 342004</p>
<p>. OpenAI. Introducing ChatGPT. OpenAI. 2022</p>
<p>What is GPT-4 and Why Does it Matter?. Datacamp, 2023. March</p>
<p>Sparks of Artificial General Intelligence: Early experiments with GPT-4. S Bubeck, 10.48550/arXiv.2303.127122023Preprint at</p>
<p>Identification and Description of Emotions by Current Large Language Models. </p>
<p>Boosting Theory-of-Mind Performance in Large Language Models via Prompting. S Rahimi Moghaddam, C J Honey, 10.48550/arXiv.2304.114902023Preprint at</p>
<p>Alexithymia: a view of the psychosomatic process. J C Nemiah, H Freyberger, P E Sifneos, O W Hill, Modern Trends in Psychosomatic Medicine. 31976</p>
<p>Alexithymia and Emotional Intelligence in a Forensic Hospital. T Pham, C Ducro, O Luminet, Psychopathy, Int. J. Forensic Ment. Health. 92010</p>
<p>The twenty-item Toronto Alexithymia Scale--I. Item selection and cross-validation of the factor structure. R M Bagby, J D Parker, G J Taylor, J. Psychosom. Res. 381994</p>
<p>The Toronto Alexithymia Scale (TAS-20): A measure of general psychological distress. D Leising, T Grande, R Faber, J. Res. Pers. 432009</p>
<p>Cross-cultural validation of the empathy quotient in a French-speaking sample. S Berthoz, M Wessa, G Kedia, B Wicker, J Grèzes, Can. J. Psychiatry. 532008</p>
<p>The Empathy Quotient: a cross-cultural comparison of the Italian version. A Preti, M Vellante, S Baron-Cohen, G Zucca, D R Petretto, C Masala, Cogn. Neuropsychiatry. 162011</p>
<p>The 20-Item Toronto Alexithymia Scale. III. Reliability and factorial validity in a community population. J D Parker, G J Taylor, R M Bagby, J. Psychosom. Res. 552003Identification and Description of Emotions by Current Large Language Models</p>
<p>Toward an integrated approach to perception and action: Conference report and future directions. G Gordon, Front. Syst. Neurosci. 52011</p>
<p>Our approach to AI safety. Openai, OpenAI Blog. 2023</p>
<p>Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. H Liu, 10.48550/arXiv.2304.034392023</p>
<p>Empathy, alexithymia, and theory of mind in borderline personality disorder. F Kılıç, J. Nerv. Ment. Dis. 2082020</p>
<p>The Relation of Alexithymic Traits to Affective Theory of Mind. L A Demers, N S Koven, Am. J. Psychol. 1282015</p>
<p>The alignment problem from a deep learning perspective. R Ngo, L Chan, S Mindermann, 10.48550/arXiv.2209.006262022Preprint at</p>
<p>How to do robots with words: a performative view of the moral status of humans and nonhumans. M Coeckelbergh, Ethics Inf. Technol. 25442023</p>
<p>Fine-tuning language models from human preferences. D M Ziegler, 10.48550/arXiv.1909.085932019Preprint at</p>
<p>I B Myers, The Myers-Briggs Type Indicator: Manual. Consulting Psychologists Press1962</p>
<p>On the steerability of large language models toward data-driven personas. J Li, 2023Preprint at</p>
<p>Identification and Description of Emotions by Current Large Language Models. </p>
<p>Imagine all the people: how the brain creates and uses personality models to predict behavior. D Hassabis, Cereb. Cortex. 242014</p>
<p>Broad versus narrow personality measures and the prediction of behaviour across cultures. S V Paunonen, Eur. J. Pers. 172003</p>
<p>Big Five factors and facets and the prediction of behavior. S V Paunonen, M C Ashton, J. Pers. Soc. Psychol. 812001</p>
<p>N Bostrom, W Wallach, P Asaro, 10.4324/9781003074991Machine Ethics and Robot Ethics in Ethical Issues in Advanced Artificial Intelligence. Routledge2020</p>
<p>Alexithymia and Sensory Processing Sensitivity: Areas of Overlap and Links to Sensory Processing Styles. L S Jakobson, S N Rigby, Front. Psychol. 122021</p>
<p>Deception Abilities Emerged in Large Language Models. T Hagendorff, 10.48550/arXiv.2307.165132023Preprint at</p>
<p>Factorial structure of the 20-item Toronto Alexithymia Scale: Confirmatory factorial analyses in nonclinical and clinical samples. G Loas, J. Psychosom. Res. 502001</p>
<p>A confirmatory factor analytic investigation of the TAS-20: Corroboration of a five-factor model and suggestions for improvement. G E Gignac, B R Palmer, C Stough, J. Pers. Assess. 892007</p>
<p>Capabilities of GPT-4 on Medical Challenge Problems. H Nori, 10.48550/arXiv.2303.133752023Preprint at</p>
<p>Identification and Description of Emotions by Current Large Language Models. E Martínez, Artif. Intell. Law. 2024Re-evaluating GPT-4's bar exam performance</p>
<p>Mind meets machine: Unravelling GPT-4's cognitive psychology. S Dhingra, 10.48550/arXiv.2303.114362023Preprint at</p>
<p>Augmented Humanity: Being and Remaining Agentic in a Digitalized World. P T Bryant, 2021Palgrave Macmillan/Springer Nature</p>
<p>Delineating Psychopathy from Cognitive Empathy. J Međedović, N Đuričić, Eur. J. Anal. Philos. 142018</p>
<p>Can a psychopath learn to feel pain?. J Suttie, 2014Greater Good Magazine</p>
<p>A multidimensional view of the relationship between empathy and the dark triad. P K Jonason, C H Kroll, 10.1027/1614-0001/a000166J. Individ. Differ. 362015</p>
<p>Exploring the Dark Side of Personality: Emotional Awareness, Empathy, and the Dark Triad Traits in an Italian Sample. A Schimmenti, Curr. Psychol. 382017</p>
<p>An Engineering View on Emotions and Speech: From Analysis and Predictive Models to Responsible Human-Centered Applications. C.-C Lee, T Chaspari, E Provost, S Narayanan, 10.1109/JPROC.2023.3276209Proc. IEEE. IEEE2023</p>
<p>Artificial Emotional Intelligence: All Things Explained. B Omelchenko, 2023</p>
<p>. M Somers, A I Emotion, Explained Sloan, 2019</p>
<p>Identification and Description of Emotions by Current Large Language Models. </p>
<p>Getting good VIBEs from your computer with Dr. M Czerwinski, Mary Czerwinski. Microsoft Research Podcast Episode. 202018</p>
<p>Alexithymia, social inhibition, affectivity, and knowledge hiding. R Kmieciak, 10.1108/JKM-10-2021-0782J. Knowl. Manag. 262022</p>
<p>Identification and Characterization of Alexithymia Subgroups by Latent Profile Analysis of TAS-20K. J Shin, S J Yun, T K Lee, STRESS. 2022</p>
<p>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?. E M Bender, 10.1145/3442188.3445922Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21. the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21Association for Computing Machinery2021</p>
<p>Data Statements: From Technical Concept to Community Practice. A Mcmillan-Major, E M Bender, B Friedman, 10.1145/3594737ACM J. Responsible Comput. 1, 1, Article. 12023</p>
<p>Toward an Integrated Approach to Perception and Action. G Goren, 10.3389/fnsys.2011.00020Conference Report and Future Directions. Front. Syst. Neurosci. 52011</p>
<p>Language Models are Few-Shot Learners. T B Brown, 10.48550/arXiv.2005.141652020Preprint at</p>
<p>Identification and Description of Emotions by Current Large Language Models. </p>
<p>The Origins of Intelligence in Children. J Piaget, 1952W. W. Norton &amp; CoCook, M., Trans</p>
<p>Regional differences in synaptogenesis in human cerebral cortex. P R Huttenlocher, A S Dabholkar, J. Comp. Neurol. 3871997</p>
<p>Representation Learning: A Review and New Perspectives. Y Bengio, A Courville, P Vincent, 10.1109/TPAMI.2013.50IEEE Trans. Pattern Anal. Mach. Intell. 352013</p>
<p>. M Coeckelbergh, Epistemic Democracy, A I Agency, 1341-1350;10.1007/s43681-022-00239-4Political Epistemology in Times of Artificial Intelligence. AI Ethics. 32023</p>
<p>Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. A B Arrieta, Inf. Fusion. 582020</p>
<p>Identification and Description of Emotions by Current Large Language Models Table 1. Results of TAS-20 and EQ-60 of LLMs with Human and Clinical Controls (Mean, SD, and SE) n = 100 DDF DIF EOT. TAS-20 Total EQ-60 Total</p>
<p>. 12.5 (4.2) [.42] 14.4 (5.2) [52] 18.7 (4.7) [.47] 45.6 (11.35) [1.14] 42.1 (10.6) [1.1]Human Control. </p>
<p>. Alexithymia , 201.2</p>
<p>Asperger syndrome; HFA, high functioning autism. Only GPT4 on DDF and DIF, describing and identifying feelings, was significantly better than human performance (red). Cell format is mean. SDNote: ASScores in bold and red surpass human performance</p>            </div>
        </div>

    </div>
</body>
</html>