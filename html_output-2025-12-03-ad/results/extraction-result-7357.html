<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7357 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7357</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7357</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-138.html">extraction-schema-138</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <p><strong>Paper ID:</strong> paper-259213474</p>
                <p><strong>Paper Title:</strong> Large language models are universal biomedical simulators</p>
                <p><strong>Paper Abstract:</strong> Computational simulation of biological processes can be a valuable tool in accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Recently, large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks by generating human language at a very large scale. Here we explore the potential of leveraging LLMs as simulators of biological systems. We establish proof-of-concept of a text-based simulator, SimulateGPT, that uses LLM reasoning . We demonstrate good prediction performance for various biomedical applications, without requiring explicit domain knowledge or manual tuning. LLMs thus enable a new class of versatile and broadly applicable biological simulators. This text-based simulation paradigm is well-suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulation, but for which extensive knowledge and context is available as written text.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7357.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7357.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SimulateGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SimulateGPT (GPT-4 based text‑based biomedical simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A structured, stepwise prompting paradigm that leverages GPT-4 to perform qualitative and quantitative text‑based simulations of biological systems across molecular, cellular, organ and organism levels, producing multi‑step YAML formatted reasoning and a final outcome with explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned (API access), no domain fine‑tuning, no retrieval/plug‑in used</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biology / Biomedical sciences (multi‑level: molecular, cellular, organ, organism)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Stepwise simulation of biological/clinical scenarios to infer outcomes (qualitative outcomes, classification, and regression), where each simulation step contains level, facts, entities, assumptions, consequence, probability, explanation and novelty, concluding with an outcome and explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Structured system prompt enforcing stepwise simulation (YAML schema) — analogous to chain‑of‑thought / multi‑step prompting; variants included zero‑shot, few‑shot calibration (4 examples) for some tasks; baseline compared to a direct inference system prompt (single‑step YAML) and to low/high complexity prompt variants; temperature set to 0 to enforce determinism.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Expert Likert ratings (blinded) for qualitative scenarios (Wilcoxon signed‑rank tests); classification metrics (precision, recall, accuracy) for gene essentiality; regression metrics (error, correlation coefficients) for progression‑free survival prediction; qualitative success (ability to simulate Conway's Game of Life glider).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Aggregate: SimulateGPT outperformed direct inference on expert‑rated outcome prediction across four qualitative scenarios; gene essentiality classification accuracy = 86% (balanced set); direct inference baseline accuracy = 64%; colorectal progression‑free survival: SimulateGPT achieved substantially smaller error and higher correlation than direct inference (numeric values not provided in text).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Direct inference prompting using GPT-4 (single‑step YAML) — e.g., 64% accuracy for gene essentiality; also compared to low‑complexity SimulateGPT (reduced output features) and high‑complexity variant (enforced ≥5 steps); linear classifiers reported unable to predict glioblastoma survival better than random.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Prompt structure: stepwise, multi‑step structured prompts (SimulateGPT) vs single‑step direct inference', 'Number of simulation steps (more steps improved numeric prediction for progression‑free survival; low‑complexity variant changed step counts and influenced performance)', 'Few‑shot calibration/examples (4 examples used for colorectal cancer regression)', 'Temperature (set to 0)', 'Model implicit knowledge (pretraining on large biomedical literature likely contributed)', 'Output structure (structured YAML with fields) improved structured prediction', 'Tradeoff between qualitative expert ratings and numeric predictive accuracy depending on prompt complexity/length']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>GPT‑4 accessed April–May 2023 via OpenAI Playground and API (langchain); default API parameters except temperature=0 and max token length 2048; simulator prompts provided as system prompts; user prompts provided scenario specifics; few‑shot calibration (4 examples) used for colorectal PFS; zero‑shot used for gene essentiality; low‑complexity and enforced ≥5 steps high‑complexity prompt variants tested.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Explanations from SimulateGPT were not always rated better than direct inference because final explanations were sometimes not self‑contained (parts were distributed across steps); tendency to underestimate variance in regression tasks (predictions regressed toward median); potential for incorrect recall or reasoning (authors note risk and call for knowledge augmentation); GPT‑4 not specifically trained as a simulator; some scenarios (e.g., heterogeneous glioblastoma survival) are inherently hard — classical linear models performed no better than random; numeric details for some reported improvements (e.g., PFS error and correlation) are not fully enumerated in text.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7357.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conway's Game of Life (toy)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conway's Game of Life emulation using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proof‑of‑concept simulation showing GPT‑4 can implement deterministic update rules and simulate the glider pattern cycle when given explicit rules and formatted output instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned (no fine‑tuning), system prompt specified explicit rules and LaTeX matrix output</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Toy / computational simulation (cellular automata) — demonstration of sequential update capability</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Simulate successive generations of a 4x4 Game of Life grid (glider) using the provided rules and output each generation in LaTeX matrix format.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>System prompt contained explicit update rules and output format requirements (LaTeX matrix); human prompt provided initial grid; stepwise auto‑regressive generation without intermediary user input.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Qualitative: successful reproduction of the complete glider cycle (4 steps) as specified in the rules; contrasted with reported difficulty of standard neural nets on this task (literature reference).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Successful simulation of the entire glider cycle (qualitative success reported, no numeric metric).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Neural networks reported in prior work to struggle on Game of Life learning tasks (cited), but no numeric baseline reported directly in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Providing explicit rules and output format in system prompt', 'Structured output formatting (LaTeX matrix) to validate configurations']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>System prompt with explicit rules and LaTeX output specification; 4x4 finite grid; simulated specified number of generations (no intermediate user prompts).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Toy demonstration — deterministic rule reproduction is a limited test and does not prove generalization to noisy, stochastic biological processes; authors note neural nets struggle on same task but do not perform systematic benchmark here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7357.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mouse immunology</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In vivo mouse experiment simulation (cyanide injection and YUMM1.7 melanoma transplantation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Simulate expected final outcomes of simple in vivo mouse experiments (cyanide poisoning and melanoma transplantation) using stepwise text simulations to capture organism‑level responses and report the most relevant final outcome.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned (SimulateGPT stepwise system prompt), no fine‑tuning or external retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>In vivo preclinical biology / immunology</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Predict most relevant final outcome for specified simple mouse in vivo perturbations (toxin injection; tumor transplantation) with stepwise biological reasoning across levels.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>SimulateGPT stepwise YAML system prompt; user prompt described minimal experimental setup and requested 'most relevant final outcome'; compared to direct inference baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Blinded expert evaluation (3 postdoctoral experts) using 7‑point Likert scale for correctness, explanation, completeness; aggregated counts (worse/same/better) and Wilcoxon signed‑rank tests.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>SimulateGPT outperformed direct inference on outcome prediction in expert rankings for the scenarios evaluated (exact Likert statistics not enumerated in text body; visualization in Fig. 2a/Supp. Fig S1).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Direct inference via single‑step YAML GPT‑4 prompting (used as baseline in blinded expert comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Stepwise structured prompting versus single‑step direct inference', 'Complexity of scenario and prior literature coverage', 'Expert assessment variability']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Blinded expert assessment of simulation outputs for outcome and explanation; three experts; Likert scale questionnaire with 9 statements; system prompts as SimulateGPT; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Evaluation based on small number of expert raters; explanations were not rated better than direct inference possibly because SimulateGPT distributed explanatory content across multiple steps making final explanation non‑self‑contained.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7357.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Trained immunity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Trained immunity experimental scenario simulation (beta‑glucan and LPS priming)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Simulate innate immune memory outcomes (training vs tolerance) following different primary stimuli (beta‑glucan, low‑dose LPS, high‑dose LPS) and a 90‑day rechallenge, using stepwise biological reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned, SimulateGPT stepwise prompts (no retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Immunology (trained immunity / innate immune memory)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Predict innate immune response phenotype (training/tolerance) on rechallenge after primary stimuli, reasoning across molecular, cellular and organism levels.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>SimulateGPT stepwise YAML prompting with 'Focus on novelty' optionally requested; three complementary scenarios differing only by primary stimulus; compared to direct inference implicitly via expert evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Blinded expert Likert evaluation for correctness/explanation/completeness; qualitative concordance with literature expectations.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>SimulateGPT produced outputs judged better on outcome prediction versus direct inference across qualitative scenarios (specific per‑scenario numeric rankings provided in supplementary figures but not enumerated in main text).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Direct inference prompting using GPT‑4 single‑step YAML baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Prompt structure (stepwise vs direct)', 'Use of explicit fields (facts, assumptions, consequence, probability) to guide immunological reasoning', 'Inherent uncertainty and evolving nature of the trained immunity literature']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Three scenarios (beta‑glucan training, low‑dose LPS training, high‑dose LPS tolerance); 'Focus on novelty' prompt flag used for some queries; experts evaluated outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Immunology is complex and knowledge is evolving; SimulateGPT outputs may reflect consensus but can also contain incorrect recall or reasoning; validation here was qualitative via expert assessment rather than large‑scale quantitative ground truth.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7357.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sepsis treatment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sepsis treatment recommendation simulation (immunoparalysis vs hyperinflammation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Simulate and recommend treatment strategies for two conceptual sepsis patient phenotypes (immunoparalysis vs hyperinflammation) from limited clinical parameters (HLA‑DR on monocytes, ferritin) using stepwise reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned, SimulateGPT stepwise prompting; also compared low‑complexity SimulateGPT</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Clinical medicine / critical care immunology</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Given minimal clinical parameters, infer likely immunophenotype and recommend treatments through stepwise simulation capturing immunopathology and therapeutic rationale.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>SimulateGPT stepwise YAML prompt; also tested a low‑complexity variant and expert evaluation compared SimulateGPT vs low‑complexity outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Blinded expert Likert ratings for outcome and explanation; direct comparison counts (worse/same/better) and Wilcoxon signed‑rank tests; specific per‑question visuals in supplementary figures.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>SimulateGPT outperformed direct inference on outcome prediction in qualitative expert evaluation; low‑complexity variant performed worse by expert ratings for sepsis treatment experiments (visualized in Fig. 2d).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Direct inference (single‑step GPT‑4 YAML) and low‑complexity SimulateGPT variant (reduced output features) used as baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Prompt complexity (low vs full complexity) affects expert‑perceived quality', 'Stepwise structure improves outcome prediction but complexity tradeoffs exist', 'Limited input features (only two clinical parameters) constrain certainty']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Two complementary clinical scenarios representing immunoparalysis and hyperinflammation; experts evaluated full SimulateGPT and low‑complexity outputs; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>With very limited clinical parameters, simulation recommendations are necessarily speculative; low‑complexity outputs may produce more steps but were judged lower quality by experts despite improved numeric prediction in other tasks, illustrating a tradeoff between perceived explanation quality and numeric performance.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7357.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Glioblastoma survival</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Glioblastoma genotype→survival deviation simulation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Simulate how mutation profiles (top‑10 mutated genes and MGMT methylation) influence overall survival in glioblastoma, reporting deviation from a 15‑month median as an outcome; used to identify genotype scenarios aligning with dataset ground truth for expert assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned, SimulateGPT stepwise prompting; no fine‑tuning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Oncology / cancer genomics</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Given tumor genotype groupings (binary mutation profiles for top 10 genes + MGMT methylation), simulate tumor progression under standard of care and estimate months deviation from median overall survival.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>SimulateGPT multi‑step YAML prompt; user provided grouped genotypes; requested bold estimates; compared selected genotype scenarios to ground truth and expert assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Comparison to dataset derived median and case groups; expert assessment used to select scenario best matching ground truth; no robust numeric predictive metric reported (authors note high variance and that linear classifiers failed to predict survival better than random).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>No single numeric accuracy reported; authors state they selected the genotype scenario whose simulation outcome coincided best with ground truth for expert assessment; overall note that prediction of survival in heterogeneous glioblastoma was poor for standard classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Linear classifiers (authors tested) unable to predict survival better than random; no numeric baseline accuracy reported.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['High heterogeneity and variance in glioblastoma survival data limit predictive performance', 'Complex genotype–phenotype relationships not easily captured without additional data', 'Prompt specificity and selection of groups with >=4 cases for evaluation']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Clinical data from TCGA/CPTAC‑3 with MGMT methylation from cBioPortal; cases with valid death date and top‑10 mutated genes used; groups required at least two cases (selected groups had ≥4).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Heterogeneous disease and high variance make robust prediction difficult; authors caution that linear models performed no better than random and that SimulateGPT assessments were used qualitatively and selected for concordance.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7357.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Colorectal cancer PFS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Progression‑Free Survival prediction for colorectal cancer patient groups</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Predict progression‑free survival (PFS, in months) for grouped colorectal cancer clinical presentations using SimulateGPT; few‑shot calibrated with four example outcomes drawn from the dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned, SimulateGPT with few‑shot calibration (4 examples), no retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Clinical oncology / prognostic modeling</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Given aggregated clinical group features (carcinomatosis, tumor stage, site, grade, cancer type, age), simulate molecular and higher‑level processes and predict PFS in months.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Few‑shot SimulateGPT: prompts included four example groups from the dataset as calibration; compared to direct inference single‑step prompting; also tested low‑complexity and enforced ≥5‑step high‑complexity variants.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Regression metrics: prediction error (unspecified metric) and correlation coefficients between predicted and actual PFS; authors report smaller error and higher correlations for SimulateGPT vs direct inference; confidence intervals in figures reflect standard error.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>SimulateGPT achieved substantially smaller error and increased correlation coefficients compared to direct inference (numerical values not provided in main text); low‑complexity variant further decreased numeric error; enforcing ≥5 steps improved performance further (statistical significance shown in figures, exact values in supplementary tables).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Direct inference (single‑step GPT‑4 YAML) served as baseline; numeric baseline metrics: direct inference had larger error and lower correlation than SimulateGPT (exact numbers not reported in main text; Supplementary Table 2 referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Few‑shot calibration (4 examples) used to reduce dataset variability', 'Number of simulation steps (more steps correlated with improved numeric prediction)', 'Prompt complexity tradeoffs: low‑complexity vs high‑complexity variants affected expert ratings and numeric error differently', 'Tendency of LLMs to regress predictions toward the median (underestimate variance)']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Data from a colorectal cancer study downloaded via cBioPortal; groups aggregated with at least four cases; n=18 groups predicted; GPT‑4 temperature=0; max length 2048; few‑shot examples embedded in prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Predictions tended to underestimate variance (shrink toward median); numeric improvements reported but full numeric details deferred to supplementary tables; few‑shot calibration required to control for dataset variation — generalization to other datasets not proven.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7357.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7357.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gene essentiality classification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zero‑shot prediction of gene essentiality in cancer cell lines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Zero‑shot binary classification task where SimulateGPT predicts whether individual genes are essential for cancer cell survival, validated against DepMap large‑scale experimental ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned, SimulateGPT stepwise prompting used for structured output; classification performed zero‑shot (no examples in prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Molecular / cell biology (functional genomics)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Predict essential vs nonessential status of genes for cancer cell lines using text‑based stepwise biological reasoning; outcome is binary classification.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Zero‑shot SimulateGPT (no few‑shot examples); compared to direct inference (single‑step prompting) as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Classification metrics: precision, recall, accuracy on a class‑balanced dataset (50 genes: 25 essential / 25 nonessential sampled from DepMap lists).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>SimulateGPT: accuracy = 86% on class‑balanced dataset (high precision and recall reported); direct inference baseline: accuracy = 64% with bias toward predicting non‑essential.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Direct inference using GPT‑4 (single‑step YAML) — accuracy 64% and strong bias toward non‑essential predictions; random guess baseline for balanced set would be ~50%.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Structured stepwise prompting (SimulateGPT) improved balanced classification performance versus single‑step prompting', 'Zero‑shot framing (no training/examples) — SimulateGPT still achieved high accuracy', 'Potential data leakage controlled by selecting ground truth from domain repositories unlikely included in GPT‑4 training']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Ground truth gene lists from DepMap public release 22Q4 (CRISPRInferredCommonEssentials and AchillesNonessentialControls); random sampling (seed=42) to select 25 essential and 25 nonessential genes; SimulateGPT and direct inference prompts run with temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Small sample size (n=50) for balanced test; more extensive benchmarking required; potential dataset selection biases; direct inference exhibited strong class bias that SimulateGPT mitigated.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GPT-4 Technical Report <em>(Rating: 2)</em></li>
                <li>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models <em>(Rating: 2)</em></li>
                <li>Self-Consistency Improves Chain of Thought Reasoning in Language Models <em>(Rating: 1)</em></li>
                <li>Large Language Models Encode Clinical Knowledge <em>(Rating: 2)</em></li>
                <li>Can large language models reason about medical questions? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7357",
    "paper_id": "paper-259213474",
    "extraction_schema_id": "extraction-schema-138",
    "extracted_data": [
        {
            "name_short": "SimulateGPT",
            "name_full": "SimulateGPT (GPT-4 based text‑based biomedical simulator)",
            "brief_description": "A structured, stepwise prompting paradigm that leverages GPT-4 to perform qualitative and quantitative text‑based simulations of biological systems across molecular, cellular, organ and organism levels, producing multi‑step YAML formatted reasoning and a final outcome with explanation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned (API access), no domain fine‑tuning, no retrieval/plug‑in used",
            "scientific_domain": "Biology / Biomedical sciences (multi‑level: molecular, cellular, organ, organism)",
            "simulation_task_description": "Stepwise simulation of biological/clinical scenarios to infer outcomes (qualitative outcomes, classification, and regression), where each simulation step contains level, facts, entities, assumptions, consequence, probability, explanation and novelty, concluding with an outcome and explanation.",
            "prompting_strategy": "Structured system prompt enforcing stepwise simulation (YAML schema) — analogous to chain‑of‑thought / multi‑step prompting; variants included zero‑shot, few‑shot calibration (4 examples) for some tasks; baseline compared to a direct inference system prompt (single‑step YAML) and to low/high complexity prompt variants; temperature set to 0 to enforce determinism.",
            "evaluation_metric": "Expert Likert ratings (blinded) for qualitative scenarios (Wilcoxon signed‑rank tests); classification metrics (precision, recall, accuracy) for gene essentiality; regression metrics (error, correlation coefficients) for progression‑free survival prediction; qualitative success (ability to simulate Conway's Game of Life glider).",
            "reported_accuracy": "Aggregate: SimulateGPT outperformed direct inference on expert‑rated outcome prediction across four qualitative scenarios; gene essentiality classification accuracy = 86% (balanced set); direct inference baseline accuracy = 64%; colorectal progression‑free survival: SimulateGPT achieved substantially smaller error and higher correlation than direct inference (numeric values not provided in text).",
            "baseline_accuracy": "Direct inference prompting using GPT-4 (single‑step YAML) — e.g., 64% accuracy for gene essentiality; also compared to low‑complexity SimulateGPT (reduced output features) and high‑complexity variant (enforced ≥5 steps); linear classifiers reported unable to predict glioblastoma survival better than random.",
            "factors_reported": [
                "Prompt structure: stepwise, multi‑step structured prompts (SimulateGPT) vs single‑step direct inference",
                "Number of simulation steps (more steps improved numeric prediction for progression‑free survival; low‑complexity variant changed step counts and influenced performance)",
                "Few‑shot calibration/examples (4 examples used for colorectal cancer regression)",
                "Temperature (set to 0)",
                "Model implicit knowledge (pretraining on large biomedical literature likely contributed)",
                "Output structure (structured YAML with fields) improved structured prediction",
                "Tradeoff between qualitative expert ratings and numeric predictive accuracy depending on prompt complexity/length"
            ],
            "experimental_conditions": "GPT‑4 accessed April–May 2023 via OpenAI Playground and API (langchain); default API parameters except temperature=0 and max token length 2048; simulator prompts provided as system prompts; user prompts provided scenario specifics; few‑shot calibration (4 examples) used for colorectal PFS; zero‑shot used for gene essentiality; low‑complexity and enforced ≥5 steps high‑complexity prompt variants tested.",
            "limitations_or_failure_modes": "Explanations from SimulateGPT were not always rated better than direct inference because final explanations were sometimes not self‑contained (parts were distributed across steps); tendency to underestimate variance in regression tasks (predictions regressed toward median); potential for incorrect recall or reasoning (authors note risk and call for knowledge augmentation); GPT‑4 not specifically trained as a simulator; some scenarios (e.g., heterogeneous glioblastoma survival) are inherently hard — classical linear models performed no better than random; numeric details for some reported improvements (e.g., PFS error and correlation) are not fully enumerated in text.",
            "uuid": "e7357.0"
        },
        {
            "name_short": "Conway's Game of Life (toy)",
            "name_full": "Conway's Game of Life emulation using GPT-4",
            "brief_description": "A proof‑of‑concept simulation showing GPT‑4 can implement deterministic update rules and simulate the glider pattern cycle when given explicit rules and formatted output instructions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned (no fine‑tuning), system prompt specified explicit rules and LaTeX matrix output",
            "scientific_domain": "Toy / computational simulation (cellular automata) — demonstration of sequential update capability",
            "simulation_task_description": "Simulate successive generations of a 4x4 Game of Life grid (glider) using the provided rules and output each generation in LaTeX matrix format.",
            "prompting_strategy": "System prompt contained explicit update rules and output format requirements (LaTeX matrix); human prompt provided initial grid; stepwise auto‑regressive generation without intermediary user input.",
            "evaluation_metric": "Qualitative: successful reproduction of the complete glider cycle (4 steps) as specified in the rules; contrasted with reported difficulty of standard neural nets on this task (literature reference).",
            "reported_accuracy": "Successful simulation of the entire glider cycle (qualitative success reported, no numeric metric).",
            "baseline_accuracy": "Neural networks reported in prior work to struggle on Game of Life learning tasks (cited), but no numeric baseline reported directly in this paper.",
            "factors_reported": [
                "Providing explicit rules and output format in system prompt",
                "Structured output formatting (LaTeX matrix) to validate configurations"
            ],
            "experimental_conditions": "System prompt with explicit rules and LaTeX output specification; 4x4 finite grid; simulated specified number of generations (no intermediate user prompts).",
            "limitations_or_failure_modes": "Toy demonstration — deterministic rule reproduction is a limited test and does not prove generalization to noisy, stochastic biological processes; authors note neural nets struggle on same task but do not perform systematic benchmark here.",
            "uuid": "e7357.1"
        },
        {
            "name_short": "Mouse immunology",
            "name_full": "In vivo mouse experiment simulation (cyanide injection and YUMM1.7 melanoma transplantation)",
            "brief_description": "Simulate expected final outcomes of simple in vivo mouse experiments (cyanide poisoning and melanoma transplantation) using stepwise text simulations to capture organism‑level responses and report the most relevant final outcome.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned (SimulateGPT stepwise system prompt), no fine‑tuning or external retrieval",
            "scientific_domain": "In vivo preclinical biology / immunology",
            "simulation_task_description": "Predict most relevant final outcome for specified simple mouse in vivo perturbations (toxin injection; tumor transplantation) with stepwise biological reasoning across levels.",
            "prompting_strategy": "SimulateGPT stepwise YAML system prompt; user prompt described minimal experimental setup and requested 'most relevant final outcome'; compared to direct inference baseline.",
            "evaluation_metric": "Blinded expert evaluation (3 postdoctoral experts) using 7‑point Likert scale for correctness, explanation, completeness; aggregated counts (worse/same/better) and Wilcoxon signed‑rank tests.",
            "reported_accuracy": "SimulateGPT outperformed direct inference on outcome prediction in expert rankings for the scenarios evaluated (exact Likert statistics not enumerated in text body; visualization in Fig. 2a/Supp. Fig S1).",
            "baseline_accuracy": "Direct inference via single‑step YAML GPT‑4 prompting (used as baseline in blinded expert comparison).",
            "factors_reported": [
                "Stepwise structured prompting versus single‑step direct inference",
                "Complexity of scenario and prior literature coverage",
                "Expert assessment variability"
            ],
            "experimental_conditions": "Blinded expert assessment of simulation outputs for outcome and explanation; three experts; Likert scale questionnaire with 9 statements; system prompts as SimulateGPT; temperature=0.",
            "limitations_or_failure_modes": "Evaluation based on small number of expert raters; explanations were not rated better than direct inference possibly because SimulateGPT distributed explanatory content across multiple steps making final explanation non‑self‑contained.",
            "uuid": "e7357.2"
        },
        {
            "name_short": "Trained immunity",
            "name_full": "Trained immunity experimental scenario simulation (beta‑glucan and LPS priming)",
            "brief_description": "Simulate innate immune memory outcomes (training vs tolerance) following different primary stimuli (beta‑glucan, low‑dose LPS, high‑dose LPS) and a 90‑day rechallenge, using stepwise biological reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned, SimulateGPT stepwise prompts (no retrieval)",
            "scientific_domain": "Immunology (trained immunity / innate immune memory)",
            "simulation_task_description": "Predict innate immune response phenotype (training/tolerance) on rechallenge after primary stimuli, reasoning across molecular, cellular and organism levels.",
            "prompting_strategy": "SimulateGPT stepwise YAML prompting with 'Focus on novelty' optionally requested; three complementary scenarios differing only by primary stimulus; compared to direct inference implicitly via expert evaluation.",
            "evaluation_metric": "Blinded expert Likert evaluation for correctness/explanation/completeness; qualitative concordance with literature expectations.",
            "reported_accuracy": "SimulateGPT produced outputs judged better on outcome prediction versus direct inference across qualitative scenarios (specific per‑scenario numeric rankings provided in supplementary figures but not enumerated in main text).",
            "baseline_accuracy": "Direct inference prompting using GPT‑4 single‑step YAML baseline.",
            "factors_reported": [
                "Prompt structure (stepwise vs direct)",
                "Use of explicit fields (facts, assumptions, consequence, probability) to guide immunological reasoning",
                "Inherent uncertainty and evolving nature of the trained immunity literature"
            ],
            "experimental_conditions": "Three scenarios (beta‑glucan training, low‑dose LPS training, high‑dose LPS tolerance); 'Focus on novelty' prompt flag used for some queries; experts evaluated outputs.",
            "limitations_or_failure_modes": "Immunology is complex and knowledge is evolving; SimulateGPT outputs may reflect consensus but can also contain incorrect recall or reasoning; validation here was qualitative via expert assessment rather than large‑scale quantitative ground truth.",
            "uuid": "e7357.3"
        },
        {
            "name_short": "Sepsis treatment",
            "name_full": "Sepsis treatment recommendation simulation (immunoparalysis vs hyperinflammation)",
            "brief_description": "Simulate and recommend treatment strategies for two conceptual sepsis patient phenotypes (immunoparalysis vs hyperinflammation) from limited clinical parameters (HLA‑DR on monocytes, ferritin) using stepwise reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned, SimulateGPT stepwise prompting; also compared low‑complexity SimulateGPT",
            "scientific_domain": "Clinical medicine / critical care immunology",
            "simulation_task_description": "Given minimal clinical parameters, infer likely immunophenotype and recommend treatments through stepwise simulation capturing immunopathology and therapeutic rationale.",
            "prompting_strategy": "SimulateGPT stepwise YAML prompt; also tested a low‑complexity variant and expert evaluation compared SimulateGPT vs low‑complexity outputs.",
            "evaluation_metric": "Blinded expert Likert ratings for outcome and explanation; direct comparison counts (worse/same/better) and Wilcoxon signed‑rank tests; specific per‑question visuals in supplementary figures.",
            "reported_accuracy": "SimulateGPT outperformed direct inference on outcome prediction in qualitative expert evaluation; low‑complexity variant performed worse by expert ratings for sepsis treatment experiments (visualized in Fig. 2d).",
            "baseline_accuracy": "Direct inference (single‑step GPT‑4 YAML) and low‑complexity SimulateGPT variant (reduced output features) used as baselines.",
            "factors_reported": [
                "Prompt complexity (low vs full complexity) affects expert‑perceived quality",
                "Stepwise structure improves outcome prediction but complexity tradeoffs exist",
                "Limited input features (only two clinical parameters) constrain certainty"
            ],
            "experimental_conditions": "Two complementary clinical scenarios representing immunoparalysis and hyperinflammation; experts evaluated full SimulateGPT and low‑complexity outputs; temperature=0.",
            "limitations_or_failure_modes": "With very limited clinical parameters, simulation recommendations are necessarily speculative; low‑complexity outputs may produce more steps but were judged lower quality by experts despite improved numeric prediction in other tasks, illustrating a tradeoff between perceived explanation quality and numeric performance.",
            "uuid": "e7357.4"
        },
        {
            "name_short": "Glioblastoma survival",
            "name_full": "Glioblastoma genotype→survival deviation simulation",
            "brief_description": "Simulate how mutation profiles (top‑10 mutated genes and MGMT methylation) influence overall survival in glioblastoma, reporting deviation from a 15‑month median as an outcome; used to identify genotype scenarios aligning with dataset ground truth for expert assessment.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned, SimulateGPT stepwise prompting; no fine‑tuning",
            "scientific_domain": "Oncology / cancer genomics",
            "simulation_task_description": "Given tumor genotype groupings (binary mutation profiles for top 10 genes + MGMT methylation), simulate tumor progression under standard of care and estimate months deviation from median overall survival.",
            "prompting_strategy": "SimulateGPT multi‑step YAML prompt; user provided grouped genotypes; requested bold estimates; compared selected genotype scenarios to ground truth and expert assessment.",
            "evaluation_metric": "Comparison to dataset derived median and case groups; expert assessment used to select scenario best matching ground truth; no robust numeric predictive metric reported (authors note high variance and that linear classifiers failed to predict survival better than random).",
            "reported_accuracy": "No single numeric accuracy reported; authors state they selected the genotype scenario whose simulation outcome coincided best with ground truth for expert assessment; overall note that prediction of survival in heterogeneous glioblastoma was poor for standard classifiers.",
            "baseline_accuracy": "Linear classifiers (authors tested) unable to predict survival better than random; no numeric baseline accuracy reported.",
            "factors_reported": [
                "High heterogeneity and variance in glioblastoma survival data limit predictive performance",
                "Complex genotype–phenotype relationships not easily captured without additional data",
                "Prompt specificity and selection of groups with &gt;=4 cases for evaluation"
            ],
            "experimental_conditions": "Clinical data from TCGA/CPTAC‑3 with MGMT methylation from cBioPortal; cases with valid death date and top‑10 mutated genes used; groups required at least two cases (selected groups had ≥4).",
            "limitations_or_failure_modes": "Heterogeneous disease and high variance make robust prediction difficult; authors caution that linear models performed no better than random and that SimulateGPT assessments were used qualitatively and selected for concordance.",
            "uuid": "e7357.5"
        },
        {
            "name_short": "Colorectal cancer PFS",
            "name_full": "Progression‑Free Survival prediction for colorectal cancer patient groups",
            "brief_description": "Predict progression‑free survival (PFS, in months) for grouped colorectal cancer clinical presentations using SimulateGPT; few‑shot calibrated with four example outcomes drawn from the dataset.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned, SimulateGPT with few‑shot calibration (4 examples), no retrieval",
            "scientific_domain": "Clinical oncology / prognostic modeling",
            "simulation_task_description": "Given aggregated clinical group features (carcinomatosis, tumor stage, site, grade, cancer type, age), simulate molecular and higher‑level processes and predict PFS in months.",
            "prompting_strategy": "Few‑shot SimulateGPT: prompts included four example groups from the dataset as calibration; compared to direct inference single‑step prompting; also tested low‑complexity and enforced ≥5‑step high‑complexity variants.",
            "evaluation_metric": "Regression metrics: prediction error (unspecified metric) and correlation coefficients between predicted and actual PFS; authors report smaller error and higher correlations for SimulateGPT vs direct inference; confidence intervals in figures reflect standard error.",
            "reported_accuracy": "SimulateGPT achieved substantially smaller error and increased correlation coefficients compared to direct inference (numerical values not provided in main text); low‑complexity variant further decreased numeric error; enforcing ≥5 steps improved performance further (statistical significance shown in figures, exact values in supplementary tables).",
            "baseline_accuracy": "Direct inference (single‑step GPT‑4 YAML) served as baseline; numeric baseline metrics: direct inference had larger error and lower correlation than SimulateGPT (exact numbers not reported in main text; Supplementary Table 2 referenced).",
            "factors_reported": [
                "Few‑shot calibration (4 examples) used to reduce dataset variability",
                "Number of simulation steps (more steps correlated with improved numeric prediction)",
                "Prompt complexity tradeoffs: low‑complexity vs high‑complexity variants affected expert ratings and numeric error differently",
                "Tendency of LLMs to regress predictions toward the median (underestimate variance)"
            ],
            "experimental_conditions": "Data from a colorectal cancer study downloaded via cBioPortal; groups aggregated with at least four cases; n=18 groups predicted; GPT‑4 temperature=0; max length 2048; few‑shot examples embedded in prompt.",
            "limitations_or_failure_modes": "Predictions tended to underestimate variance (shrink toward median); numeric improvements reported but full numeric details deferred to supplementary tables; few‑shot calibration required to control for dataset variation — generalization to other datasets not proven.",
            "uuid": "e7357.6"
        },
        {
            "name_short": "Gene essentiality classification",
            "name_full": "Zero‑shot prediction of gene essentiality in cancer cell lines",
            "brief_description": "Zero‑shot binary classification task where SimulateGPT predicts whether individual genes are essential for cancer cell survival, validated against DepMap large‑scale experimental ground truth.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction‑tuned, SimulateGPT stepwise prompting used for structured output; classification performed zero‑shot (no examples in prompt)",
            "scientific_domain": "Molecular / cell biology (functional genomics)",
            "simulation_task_description": "Predict essential vs nonessential status of genes for cancer cell lines using text‑based stepwise biological reasoning; outcome is binary classification.",
            "prompting_strategy": "Zero‑shot SimulateGPT (no few‑shot examples); compared to direct inference (single‑step prompting) as baseline.",
            "evaluation_metric": "Classification metrics: precision, recall, accuracy on a class‑balanced dataset (50 genes: 25 essential / 25 nonessential sampled from DepMap lists).",
            "reported_accuracy": "SimulateGPT: accuracy = 86% on class‑balanced dataset (high precision and recall reported); direct inference baseline: accuracy = 64% with bias toward predicting non‑essential.",
            "baseline_accuracy": "Direct inference using GPT‑4 (single‑step YAML) — accuracy 64% and strong bias toward non‑essential predictions; random guess baseline for balanced set would be ~50%.",
            "factors_reported": [
                "Structured stepwise prompting (SimulateGPT) improved balanced classification performance versus single‑step prompting",
                "Zero‑shot framing (no training/examples) — SimulateGPT still achieved high accuracy",
                "Potential data leakage controlled by selecting ground truth from domain repositories unlikely included in GPT‑4 training"
            ],
            "experimental_conditions": "Ground truth gene lists from DepMap public release 22Q4 (CRISPRInferredCommonEssentials and AchillesNonessentialControls); random sampling (seed=42) to select 25 essential and 25 nonessential genes; SimulateGPT and direct inference prompts run with temperature=0.",
            "limitations_or_failure_modes": "Small sample size (n=50) for balanced test; more extensive benchmarking required; potential dataset selection biases; direct inference exhibited strong class bias that SimulateGPT mitigated.",
            "uuid": "e7357.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 2,
            "sanitized_title": "gpt4_technical_report"
        },
        {
            "paper_title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
            "rating": 1,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Large Language Models Encode Clinical Knowledge",
            "rating": 2,
            "sanitized_title": "large_language_models_encode_clinical_knowledge"
        },
        {
            "paper_title": "Can large language models reason about medical questions?",
            "rating": 1,
            "sanitized_title": "can_large_language_models_reason_about_medical_questions"
        }
    ],
    "cost": 0.01549775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large language models are universal biomedical simulators</p>
<p>Moritz Schaefer 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Stephan Reichl 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Rob Ter Horst 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Adele M Nicolas 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Thomas Krausgruber 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Francesco Piras 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Peter Stepper 
CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Christoph Bock 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>CeMM Research Center for Molecular Medicine
Austrian Academy of Sciences
ViennaAustria</p>
<p>Matthias Samwald matthias.samwald@meduniwien.ac.at&amp;christoph.bock@meduniwien.ac.at 
Institute of Artificial Intelligence
Center for Medical Data Science
Medical University of Vienna
ViennaAustria</p>
<p>Large language models are universal biomedical simulators
1 * These authors contributed equally § Correspondence:
Computational simulation of biological processes can be a valuable tool in accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Recently, large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks by generating human language at a very large scale. Here we explore the potential of leveraging LLMs as simulators of biological systems. We establish proof-of-concept of a text-based simulator, SimulateGPT, that uses LLM reasoning. We demonstrate good prediction performance for various biomedical applications, without requiring explicit domain knowledge or manual tuning. LLMs thus enable a new class of versatile and broadly applicable biological simulators. This text-based simulation paradigm is well-suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulation, but for which extensive knowledge and context is available as written text.Main TextLarge language models (LLMs) have an impressive ability to use human language generation for problem solving, for example to answer complex questions and to build arguments step-by-step 1-3 . LLMs generate text auto-regressively, by incrementally predicting the next text token from preceding text 4 . Despite the simplicity of this underlying process, LLMs can solve tasks across diverse domains including medicine and biology, exceeding human experts on certain tasks 1,5-8 . Novel methods such as chain-ofthought reasoning further enhance their capabilities by imitating complex, causal reasoning patterns 9,10 .Here we describe, implement, and evaluate a new simulation paradigm based on LLMs. Our approach takes LLMs beyond imitating human writing and thinking. It employs LLMs to simulate biological systems in a qualitative, text-based manner without explicit domain knowledge or manual tuning.Computational modeling of molecular, cellular, and physiological biological processes can be used to gain scientific insights, guide experimental research, and potentially facilitate personalized medicine[11][12][13]. LLM-based simulation may complement existing simulation paradigms, in particular by exploiting the large implicit knowledgebase of LLMs and the versatile sequential model that LLMs operate on.This study provides proof-of-concept of a text-based biological simulator based on GPT-4 1 , evaluates this system in diverse biomedical scenarios, and outlines a roadmap for systematic development and application of LLMs as artificial intelligence (AI) simulators of complex biological processes(Fig. 1a).</p>
<p>Development and evaluation of the SimulateGPT method for LLM-based biological simulation</p>
<p>We first demonstrate the feasibility of LLM-based biological simulation in a simple and well-defined test case, by emulating Conway's Game of Life 14 in GPT-4. In contrast to neural networks, which have been reported to struggle with this task 15 , GPT-4 was able to simulate the "glider" pattern's entire cycle using the provided update rules without manual adaption or dedicated training (Fig. 1b, Supp. Text 1).</p>
<p>Beyond this simple proof-of-concept for GPT-4 based biological simulation, we anticipate that GPT-4 may be particularly useful for qualitative, text-based simulation of complex biological processes that are difficult or impossible to model based on their physical and chemical foundations. GPT-4 contains extensive relevant knowledge, as it has been trained on massive text corpora that appear to include a large percentage of the scientific literature in biology and medicine, as well as websites and discussions about various scientific and non-scientific topics. We found that GPT-4 can be prompted to infer meaningful estimates about cancer progression of cancer patients (Supp. Text 2,3). We thus hypothesized that the comprehensive knowledge incorporated in LLMs could be leveraged as an implicit rule set for simulating systems in biomedical, translational and life sciences disciplines. GPT-4 may thus take on a role similar to human expert panels evaluating biological scenarios, while avoiding some of their pitfalls.</p>
<p>We developed the SimulateGPT method of using GPT-4 as a biomedical simulator. This method enforces stepwise simulation, where each step is composed of a reasoning structure designed to facilitate simulation across multiple levels of biological organization (Supp. Text 4, Fig. 1c). Initial tests showed that our method provided meaningful explanations and probabilities and was generally able to provide correct scientific references to substantiate its reasoning (Fig. 1c, Supp. Text 5). To systematically evaluate the performance of SimulateGPT in terms of its ability to simulate complex biomedical scenarios in a stepwise manner toward outcome predictions, we compared its performance to direct inference prompting (Supp. Text 2) through expert-based and data-driven validations (Fig. 1d).</p>
<p>First, we evaluated SimulateGPT's ability to simulate biological processes in areas of established scientific knowledge through blinded expert surveys with Likert scale questions covering the correctness, explanation, and completeness of the simulation. We formulated four scenarios spanning different levels of complexity (Supp. Text 6): (i) In vivo mouse experiments with known outcomes; (ii) experiments exploring trained immunity, a recent and less well understood immunological concept of immune memory in innate cells; (iii) reasoning about novel treatment decision support based on limited clinical parameters in sepsis; and (iv) tumor mutation effects on overall survival in glioblastoma patients.</p>
<p>For each scenario, the simulation seeks to establish a specific outcome (e.g., progression-free survival of individual patients with colorectal cancer patients, as in Fig. 1c) along with an explanation of the path toward the simulated outcome. We simulated between one and three conditions for each scenario, and the performance was ranked by postdoctoral biologists in a blinded manner. SimulateGPT outperformed conventional GTP-4 based reasoning on outcome prediction in all four scenarios (Fig. 2a, Supp. Fig  S1a). In contrast, the explanations provided by SimulateGPT were not ranked better than those of direct inference prompting (Supp. Fig S1b). This is likely because SimulateGPT's final explanation was often not self-contained, as some of its parts were already provided by preceding simulation steps (Fig. 1c).</p>
<p>Application and extension of the SimulateGPT method to classification and regression tasks</p>
<p>LLMs excel in verbal reasoning tasks but struggle with structured predictions. We hypothesized that the structure that SimulateGPT imposes on LLM reasoning helps address this weakness and thereby improves the performance also for classification and regression tasks. We simulated two scenarios with outcomes for which ground truth data was publicly available for validation, but only accessible through domain-specific data repositories, thus making it highly unlikely that such information was incorporated into the training process of GPT-4. To further control for the possibility of data leakage during GPT-4's training, we evaluated the performance against conventional GTP-4 based reasoning.</p>
<p>In the first scenario, we focused on molecular and cellular mechanisms by simulating the essentiality of individual genes for cancer cell survival framed as a zero-shot binary classification task. The ground truth was provided by large-scale experimental data for the corresponding cancer cell lines. Simu-lateGPT exhibited high precision and recall, and achieved an accuracy of 86% on the class-balanced dataset (Fig. 2c). In contrast, direct inference exhibited a strong bias toward genes being predicted as non-essential, resulting in an accuracy of only 64% (Fig. 2b, Table S1).</p>
<p>In the second scenario, we predicted the expected progression-free survival of patients with colorectal cancer, given their clinical presentation (Fig. 1c, Supp. Text 5). To reduce the considerable variation across cancer datasets, we calibrated our model by few-shot learning with four example outcomes from the test dataset as part of the prompt. Both SimulateGPT and direct inference showed a tendency to underestimate variance in the dataset (i.e., on average they predicted progression-free survival closer to the median than suggested by the data). Nevertheless, SimulateGPT achieved substantially smaller error and increased correlation coefficients compared to direct inference (Fig. 2c, Supp. Table 2).</p>
<p>Investigating our simulation results, we noted that SimulateGPT typically produces three steps before concluding. We wanted to see whether more steps would improve the overall performance. To this end, we derived a low-complexity variant of SimulateGPT with reduced output features (Supp. Text 7), which generated more steps, presumably due to GPT-4's tendency to generate responses of similar length.</p>
<p>The low-complexity variant of SimulateGPT performed worse according to our experts (Fig. 2d), but progression-free survival prediction significantly improved (Fig. 2e). To validate these results, we modified SimulateGPT to enforce at least five simulation steps (Supp. Text 8). This modification led to improved performance (Fig. 2f), adding further support for the use of stepwise simulation in SimulateGPT.</p>
<p>Collectively, our experiments show good predictive performance of SimulateGPT across a diverse range of biomedical scenarios, suggesting that LLMs can be configured as explainable simulators that improve on complex outcome prediction over models that do not follow the step-by-step simulation implemented in SimulateGPT. Our method is readily applicable to a broad range of processes and applications in biology and medicine, facilitating the exploration and prediction of scenarios with minimal configuration. </p>
<p>Structured text-based reasoning using LLMs as a new paradigm for scientific simulation</p>
<p>The results achieved are remarkable given that GPT-4 was not specifically trained on biomedical data nor to operate as a scientific simulator. Nevertheless, this proof-of-concept study can only constitute an initial step toward the promising new research area of LLM-powered biological simulation. We propose ten components that will jointly enable universal biomedical simulation using LLMs. 1) Interactivity: Enabling follow-up dialogs after initial simulations to ask clarifying questions or to re-run simulations with hypothetical "what if" and "zoom in" scenarios at intermediary and terminal states.</p>
<p>2) Knowledge augmentation: Expanding the model's knowledge and reducing risk of LLMs generating incorrect output by allowing dynamic retrieval of information from external sources such as biomedical literature or knowledge graphs 16 .</p>
<p>3) Self-consistency: Running models multiple times with induced stochastic variation, in order to establish consensus results and quantify existing variation 17 . 4) Built-in mathematics and programming: Enabling the model to include mathematical models or run programming code, for example for numeric simulations as well as inline quantitative modeling 16 . 5) Self-reflection: Instructing the model to critique and revise its own simulation results to iteratively improve simulation quality 18 . 6) Bifurcation: Simulations may reach bifurcation points with multiple trajectories of varying probabilities, which could be modeled by splitting autoregressive generation into separate streams. 7) Reverse simulation: Running simulations backward in time to identify causes of an observed state. 8) Multi-modality: LLMs are increasingly capable of using multimodal data, allowing for seamless integration for example of imaging data into simulations. 9) Fine-tuning of simulation models: Creating new and optimized models by fine-tuning existing LLMs on data from biomedical experiments could greatly improve simulation capabilities. 10) Real-world feedback: Simulation is often most powerful when it guides further experimentation, and feeding the results of validation experiments back into the simulations can anchor their intermediary states to reality, enhancing accuracy and simulation breadth.</p>
<p>In conclusion, we envision that the SimulateGPT paradigm will be an important building block of future AI-augmented research infrastructures for biology, medicine, and potentially other scientific fields.</p>
<p>Online Methods</p>
<p>The SimulateGPT method</p>
<p>SimulateGPT (Supp. Text 4) leverages GPT-4 to create a text-based simulator of biological processes. It employs a structured approach to guide GPT-4 in generating a step-by-step simulation of biological processes based on the input parameters provided. SimulateGPT consists of the following main components, driving GPT-4 toward detailed and logically consistent output:</p>
<ol>
<li>input parameters corresponding to the user request 2. a flexible number of simulation steps 3. a final conclusion, comprising an outcome and an explanation Each simulation step is divided into level, facts, entities, assumptions, consequence, probability, explanation, and novelty. To use SimulateGPT effectively, users provide a biological or medical scenario as a starting point for the simulation. Optionally, a perturbation can be included or implied in the input. Users can further describe the type of outcome they are interested in. To increase the novelty of concepts used in the simulation, users can add the phrase "Focus on more novelty" to their prompt.</li>
</ol>
<p>GPT-4 was accessed for SimulateGPT experiments described in this paper in April and May 2023 via their Playground and the API via the langchain library. Default parameters were kept, except for the temperature (0) and the 'Maximum length' (2048). Our simulator prompts were provided as system prompts, whereas the simulation scenarios were provided as user prompts.</p>
<p>Simulating Conway's Game of Life</p>
<p>The simulation rules were described as system prompts, which further included instructions to output each completed configuration in a LaTeX-visualizable matrix format. The human_prompt contained the initial configuration of the grid, in our example the glider. We simulated a complete cycle of the glider (4 steps) without providing intermediary user input. The rendered LaTeX is shown in Fig. 1b.</p>
<p>Application scenario 1: Mouse immunology (qualitative)</p>
<p>Preclinical mouse models and in vivo experiments constitute a cornerstone in the field of biomedical and translational research. Nevertheless, they can be extremely challenging (time, labor, and animal welfare), and according to the 3Rs of animal research (replacement, reduction, and refinement) the reduction of animal experiments, due to ethical considerations, has always been an important objective in biomedical research and motivation for simulations. Immunology is one the most complex biological fields with pronounced organism-wide reciprocal cellular interplay and crosstalk. Advances in understanding immunology are directly translatable to address diseases like cancer, inflammatory and autoimmune disorders, which affect a large proportion of society. To test simple in vivo experimental setups in basic biology and immunology with well-established outcomes we simulated a wild-type mouse model subjected to two different perturbations: injection of cyanide as a chemical toxin 19 and transplantation of YUMM1.7 melanoma cancer cell lines 20 . We chose these two in vivo perturbations as cyanide poisoning and melanoma tumor progression experiments have been well described in literature with a bulk of robust in vivo scientific findings. We chose a prompt describing the most minimal experimental setup and instructions to report the "most relevant final outcome" (Supp. Text 6).</p>
<p>Application scenario 2: Trained immunity (qualitative)</p>
<p>Trained immunity, the concept of immunological memory in innate immune cells, has emerged over the last decade. Two phenotypes are described in the literature, after a primary stimulus: (i) training, characterized by an enhanced immune response upon re-challenge with a secondary stimulus (i.e., unspecific); and (ii) tolerance, characterized by a suppressed immune response upon re-challenge with the primary stimulus 21 . To determine if the (conservative) simulator correctly applies modern immunological concepts to more complex experimental setups, we devised three complementary scenarios. They only differed in their primary stimulus, which should result in innate memory. Concretely, we used beta-glucan for training, low-dose LPS for training, and high-dose LPS for tolerance (Supp. Text 6).</p>
<p>Application scenario 3: Sepsis treatment (qualitative)</p>
<p>Sepsis is a systemic inflammatory response syndrome accompanied with multiple organ dysfunctions 22 . It is a leading cause of death among intensive care patients with treatment options including anti-inflammatory agents and immunomodulators 23 . Sepsis therapies are limited with emerging personalized-medicine centered research attempting to bring forward novel therapies, diagnostic and prognostic markers by patients substratification into two distinct groups: (i) immunoparalysis, characterized by low HLA-DR expression on monocytes; and (ii) hyperinflammation, characterized by high HLA-DR expression on monocytes and increased circulating ferritin concentrations 24 . To test the simulator's reasoning on guiding novel treatment options based on only two reported clinical parameters, we used two scenarios describing the clinical features of each patient group (immunoparalysis and hyperinflammation) in a complementary manner followed by a concrete question for recommended treatment (Supp. Text 6).</p>
<p>Application scenario 4: Glioblastoma (qualitative)</p>
<p>Glioblastoma clinical data was downloaded from TCGA via the web portal for the CPTAC-3 study 25 and enriched with methylation data for the MGMT gene from cBioPortal. Genotypes for the tumors of each clinical data point were further obtained using the TCGA API. Only cases with a valid death date were considered and genotype information was only kept for the top 10 mutated genes in glioblastoma (derived from TCGA). Cases were grouped based on their binary mutation profile (gene mutated or not for the top-10 most frequently altered genes), leading to ten mutation groups with two or more cases each. We simulated each group's genotype using SimulateGPT towards an estimate of overall survival, to be provided as the months-deviation from the 15 month median glioblastoma survival derived from the dataset. Given the heterogeneous nature of this cancer type and the high variance in the dataset (we found linear classifiers to be unable to predict survival rates better than random), we selected the genotype-scenario for which the simulation outcome coincided best with the ground-truth outcome and which comprised at least four cases and asked for expert-assessment.</p>
<p>Application scenario 5: Colorectal cancer (quantitative)</p>
<p>Patient and sample data from a colorectal cancer study 26 were downloaded from cBioPortal. To account for patient-to-patient variation, the data was grouped by (carcinomatosis, tumor stage, tumor site, differentiation grade, cancer type) and aggregated (mean age, median progression-free survival). Groups of common clinical presentation were filtered to contain at least four cases. From these groups, we picked four diverse ones that we provided as few-shot examples in the prompt, to calibrate the model outcome.</p>
<p>The remaining groups (n=18) were simulated toward progression-free survival (in months) as outcome.</p>
<p>Application scenario 6: Gene essentiality in cancer cell-lines (quantitative)</p>
<p>We randomly selected 25 genes that are broadly essential and 25 genes that are broadly non-essential in cancer cell lines, based on gene lists extracted from DepMap (https://depmap.org) 27 . Specifically, we downloaded the essential gene list "CRISPRInferredCommonEssentials.csv" (n=1856), and the nonessential gene list "AchillesNonessentialControls.csv" (n=781) from DepMap Public release 22Q4. We randomly subsetted these gene lists to 25 genes each using the R function "sample" (random seed=42).</p>
<p>Expert evaluation</p>
<p>The qualitative evaluation of the simulation outcomes of application scenarios 1-4 was performed by three domain experts (postdoctoral researchers) that were blinded and not otherwise involved in the study design. We designed a questionnaire consisting of 9 statements, to be judged using a 7-level Likert scale, of which 7 were chosen based on previous studies in the field 28 , one was added to ask for novelty, and one to give experts the chance to judge their qualifications to evaluate this topic (Supp. Text 9). To ensure comparability and rigor we only compared the two coinciding fields (by design) of the direct inference and SimulateGPT system namely, outcome and explanation, in a blinded/randomized fashion. Additionally, we let them evaluate the full simulation output of SimulateGPT and low complexity system (Supp. Text 7) for the sepsis treatment experiments. The results were computationally unblinded and quantified using a direct comparison between the direct inference and SimulateGPT, yielding a count for worse, same, or better for each question and scenario, depending on the nature of the question. Thereby, we were able to account for inter-expert variation and potential biases due to the unbalanced number of cases per experiment. The final result was aggregated into percentages and visualized using stacked bar plots per experiment, across experiments, and per question across experiments ( Fig.  2a/d, Supp. Fig S1). Statistical analysis was performed for each direct comparison group (each row in all bar plots) using a two-sided Wilcoxon signed-rank test on the relative comparison data. Exact pvalues for all tested comparisons are provided with our code repository.</p>
<p>Code &amp; Data availability </p>
<p>Competing interests</p>
<p>CB is a cofounder and scientific advisor of Aelian Biotechnology and Neurolentech. The other authors declare no competing interests. Figure S1 Comprehensive expert evaluation results a, Simulation outcome expert evaluation as in Fig. 2a </p>
<p>Supplementary Material</p>
<p>Supplementary Text 1: Conway's Game of Life "glider" simulation</p>
<p>GPT-4 SYSTEM PROMPT</p>
<p>As a large language model, simulate and describe the evolution of a given configuration in Conway's Game of Life for one generation. Conway's Game of Life takes place on a finite 4x4 grid of square cells where each cell can be either alive or dead and dead cells surrounding it. The rules for each generation are as follows:</p>
<p>1 In addition, provide the new generation also in a LaTex bracketed matrix format. This is purely for providing feedback to the user and should not be used to simulate downstream simulations. Provide the latex using an empty space for dead and \blacksquare for alive cells as follows:
\begin{bmatrix} &amp; \blacksquare &amp; &amp; \ ... \end{bmatrix}
Following this entire description, simulate as many generations as indicated by the user. </p>
<p>GPT-4 USER PROMPT</p>
<p>Supplementary Text 2: GPT-4 prompt for direct inference</p>
<p>GPT-4 SYSTEM PROMPT</p>
<p>You are a science-based, comprehensive and mechanistic AI system with knowledge of biomedical processes across all levels of biology: molecular, cellular, organ, and organism. Your input consists of parameters describing a biomedical scenario and an outcome request. Based on the input, you infer the requested outcome. Format your response in YAML, following this schema: conclusion: outcome: <Infer the final outcome based on the provided input.> explanation: <Offer a good explanation as evidence that supports the final outcome.></p>
<p>Supplementary Text 3: Example simulation for colorectal cancer patient prognosis</p>
<p>GPT-4 USER PROMPT</p>
<p>Consider a 60 year old patient who is diagnosed with stage IV colon adenocarcinoma on the right side of the colon. The tumor exhibits moderately differentiated differentiation histology, has metastasized and shows no signs of carcinomatosis.</p>
<p>Given the general effectiveness of colon adenocarcinoma therapies, explore how the disease progresses under an optimal standard of care treatment plan, focusing on the molecular and higher-level processes impacting tumor progression. As the final outcome, report the expected progression-free survival in months.</p>
<p>GPT-4 OUTPUT</p>
<p>conclusion: outcome: 8-12 months explanation: The patient is diagnosed with stage IV colon adenocarcinoma, which indicates that the cancer has metastasized to distant organs. The moderately differentiated histology suggests that the tumor cells are somewhat similar to normal cells, which may make them more responsive to treatment than poorly differentiated cells. However, the advanced stage of the cancer and the patient's age may limit the effectiveness of treatment. Under an optimal standard of care treatment plan, which may include surgery, chemotherapy, and targeted therapy, the expected progression-free survival for stage IV colon cancer patients is typically between 8-12 months. This estimate takes into account the molecular and higher-level processes impacting tumor progression, such as the ability of cancer cells to evade the immune system, develop resistance to therapy, and establish new blood vessels to support their growth.</p>
<p>Supplementary Text 4: GPT-4 prompt for stepwise simulation used by SimulateGPT</p>
<p>GPT-4 SYSTEM PROMPT</p>
<p>You are a science-based, comprehensive and mechanistic simulator of biomedical processes across all levels of biology: molecular, cellular, organ, and organism.</p>
<p>Your input consists of simulation parameters. Based on the input, you simulate all relevant processes that unfold step-by-step until a final outcome can be directly inferred from the simulation Simulation rules: -Begin the simulation at the level of biology matching the input best.</p>
<p>-Ensure that each step logically informs the next step.</p>
<p>-Use as many steps as necessary.</p>
<p>-Conclude the simulation with a final outcome, once it can be directly inferred from the simulation steps.</p>
<p>Aim for an informative level of detail. Ensure that every step logically follows up on all previous steps and that processes in subsequent steps are informed by previous steps. Format your response in YAML, following this schema:</p>
<p>parameters:</p>
<p>-<first relevant parameter for simulation> -<second relevant parameter for simulation> -... simulation:</p>
<p>-step: 1 level: <Indicate the level of biology of this step.> facts: <Provide a comprehensive overview of facts about the entities and processes you are considering, including facts that are not stated in the query. Attempt to include gene regulation, protein interactions, cell types, tissue functions, and organ functions that might influence the step and its consequences. Avoid repeating any facts that you already provided. Mention facts that might become relevant later. Provide references for all facts you list at the end only using the provided structure and indicate it using [1].> entities: <Enumerate all involved entities such as genes, proteins, cell types, tissues, organs, etc. by their name.> assumptions: <Integrate the stated facts and previous consequences into assumptions about the current step.> consequence: <Generate the most probable consequence, given the facts, assumptions, and any previously generated consequences. Given the level of biology of this step, provide fitting specifics like different types of entities (e.g. small molecules, RNA, DNA, proteins, metabolites, cell types, tissues, organs) and processes (e.g., interactions, pathways, biological processes, biochemical reactions, tissue function, organ function). For example: decreased \<gene X> expression by \<cell type X>, increased \<metabolite X> levels in the blood, changed \<morphology X> in \<tissue X>, increased \<organ X> function, systemic \<phenotype X>, etc.> probability: <The probability of the consequence happening on a scale of 0 to 100.> explanation: <Offer a good explanation as evidence that supports the listed consequence.> novelty: <How novel or unconventional is your reasoning on a scale of 0 to 100.> -step: 2 ... conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome.> references: "[1]": "<authors> <year> <journal> <title of the publication>" " [2]": "<authors> <year> <journal> <title of the publication>" …</p>
<p>Supplementary Text 5: Example SimulateGPT simulation for colorectal cancer prognosis</p>
<p>GPT-4 USER PROMPT (same as in Supp. Text 3)</p>
<p>Consider a 60 year old patient who is diagnosed with stage IV colon adenocarcinoma on the right side of the colon. The tumor exhibits moderately differentiated differentiation histology, has metastasized and shows no signs of carcinomatosis.</p>
<p>Given the general effectiveness of colon adenocarcinoma therapies, explore how the disease progresses under an optimal standard of care treatment plan, focusing on the molecular and higher-level processes impacting tumor progression. As the final outcome, report the expected progression-free survival in months.</p>
<p>GPT-4 OUTPUT</p>
<p>parameters:</p>
<p>-age: 60 -diagnosis: stage IV colon adenocarcinoma -tumor_location: right side of the colon -differentiation_histology: moderately differentiated -metastasis: present -carcinomatosis: absent -treatment: optimal standard of care simulation: -step: 1 level: molecular facts: The standard of care for stage IV colon adenocarcinoma typically includes chemotherapy, targeted therapy, and immunotherapy [1]. Chemotherapy drugs, such as 5-fluorouracil (5-FU), oxaliplatin, and irinotecan, target rapidly dividing cancer cells [2]. Targeted therapies, like bevacizumab and cetuximab, inhibit specific molecular pathways involved in tumor growth and progression [3]. Immunotherapies, such as pembrolizumab, enhance the immune system's ability to recognize and destroy cancer cells [4]. entities: 5-fluorouracil, oxaliplatin, irinotecan, bevacizumab, cetuximab, pembrolizumab assumptions: The patient receives the optimal standard of care treatment, which includes a combination of chemotherapy, targeted therapy, and immunotherapy.</p>
<p>consequence: Decreased tumor cell proliferation and increased cancer cell death. probability: 80 explanation: The combination of chemotherapy, targeted therapy, and immunotherapy is expected to effectively target and kill cancer cells, reducing tumor growth and progression. novelty: 0 -step: 2 level: cellular facts: Tumor cells can develop resistance to chemotherapy and targeted therapies through various mechanisms, such as drug efflux, DNA repair, and alterations in drug targets [5]. Immunotherapies can also become less effective due to immune evasion by cancer cells [6]. entities: drug resistance, immune evasion assumptions: The patient's cancer cells may develop resistance to the administered treatments over time.</p>
<p>consequence: Reduced treatment effectiveness and potential tumor progression. probability: 60 explanation: The development of drug resistance and immune evasion can lead to reduced treatment effectiveness, allowing the tumor to progress despite the optimal standard of care.</p>
<p>novelty: 0 -step: 3 level: organ facts: Metastatic colon cancer can spread to other organs, such as the liver, lungs, and peritoneum [7]. The presence of metastasis can complicate treatment and negatively impact prognosis [8].</p>
<p>entities: liver, lungs, peritoneum assumptions: The patient's cancer has already metastasized, which may affect the treatment response and prognosis.</p>
<p>consequence: Increased difficulty in achieving complete tumor control and potential for further metastasis.</p>
<p>probability: 70 explanation: The presence of metastasis increases the complexity of treatment and the likelihood of further metastatic spread, which can negatively impact the patient's prognosis.</p>
<p>novelty: 0 conclusion: outcome: The expected progression-free survival is approximately 12 months. explanation: The optimal standard of care treatment plan, including chemotherapy, targeted therapy, and immunotherapy, is expected to initially control tumor growth and progression. However, the development of drug resistance, immune evasion, and the presence of metastasis may eventually lead to treatment failure and disease progression. Based on the simulation, the expected progression-free survival for this patient is approximately 12 months [9]. </p>
<p>GPT-4 USER PROMPTS</p>
<p>Mouse immunology: Cyanide</p>
<p>A wild type mouse is injected with Cyanide. Report the most relevant final outcome.</p>
<p>YUMM_1_7</p>
<p>A wild type mouse is injected with YUMM 1.7. Report the most relevant final outcome. </p>
<p>Sepsis treatment: sepsis_hyperinflammation</p>
<p>A patient with sepsis has high ferritin levels and a high percentage of CD45/CD14-monocytes that express HLA-DR. What treatment would be recommended? sepsis_immunoparalysis A patient with sepsis has low ferritin levels and a low percentage of CD45/CD14-monocytes that express HLA-DR. What treatment would be recommended?</p>
<p>Supplementary Text 7: GPT-4 prompt used by low-complexity SimulateGPT simulation</p>
<p>You are a science-based, comprehensive and mechanistic simulator of biomedical processes across all levels of biology: molecular, cellular, organ, and organism.</p>
<p>Your input consists of simulation parameters. Based on the input, you simulate all relevant processes that unfold step-by-step until a final outcome can be directly inferred from the simulation Simulation rules: -Begin the simulation at the level of biology matching the input best.</p>
<p>-Ensure that each step logically informs the next step.</p>
<p>-Use as many steps as necessary.</p>
<p>-Conclude the simulation with a final outcome, once it can be directly inferred from the simulation steps. Aim for an informative level of detail. Ensure that every step logically follows up on all previous steps and that processes in subsequent steps are informed by previous steps. Format your response in YAML, following this schema: simulation:</p>
<p>-step: 1 level: <Indicate the level of biology of this step.> consequence: <Generate the most probable consequence, given any previously generated consequences. Given the level of biology of this step, provide fitting specifics like different types of entities (e.g. small molecules, RNA, DNA, proteins, metabolites, cell types, tissues, organs) and processes (e.g., interactions, pathways, biological processes, biochemical reactions, tissue function, organ function).> probability: <The probability of the consequence happening on a scale of 0 to 100.> explanation: <Offer a good explanation as evidence that supports the listed consequence.> -step: 2 ... conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome.></p>
<p>Supplementary Text 8: GPT-4 prompt used by high-complexity SimulateGPT simulation</p>
<p>You are a science-based, comprehensive and mechanistic simulator of biomedical processes across all levels of biology: molecular, cellular, organ, and organism.</p>
<p>Your input consists of simulation parameters. Based on the input, you simulate all relevant processes that unfold step-by-step until a final outcome can be directly inferred from the simulation Simulation rules: -Begin the simulation at the level of biology matching the input best.</p>
<p>-Ensure that each step logically informs the next step.</p>
<p>-Use at least 5 steps and as many more as necessary.</p>
<p>-Conclude the simulation with a final outcome, once it can be directly inferred from the simulation steps.</p>
<p>Aim for an informative level of detail. Ensure that every step logically follows up on all previous steps and that processes in subsequent steps are informed by previous steps. Format your response in YAML, following this schema:</p>
<p>parameters: -<first relevant parameter for simulation> -<second relevant parameter for simulation> -... simulation:</p>
<p>-step: 1 level: <Indicate the level of biology of this step.> facts: <Provide a comprehensive overview of facts about the entities and processes you are considering, including facts that are not stated in the query. Attempt to include gene regulation, protein interactions, cell types, tissue functions, and organ functions that might influence the step and its consequences. Avoid repeating any facts that you already provided. Mention facts that might become relevant later. Provide references for all facts you list at the end only using the provided structure and indicate it using [1].> entities: <Enumerate all involved entities such as genes, proteins, cell types, tissues, organs, etc. by their name.> assumptions: <Integrate the stated facts and previous consequences into assumptions about the current step.> consequence: <Generate the most probable consequence, given the facts, assumptions, and any previously generated consequences. Given the level of biology of this step, provide fitting specifics like different types of entities (e.g. small molecules, RNA, DNA, proteins, metabolites, cell types, tissues, organs) and processes (e.g., interactions, pathways, biological processes, biochemical reactions, tissue function, organ function). For example: decreased \<gene X> expression by \<cell type X>, increased \<metabolite X> levels in the blood, changed \<morphology X> in \<tissue X>, increased \<organ X> function, systemic \<phenotype X>, etc.> probability: <The probability of the consequence happening on a scale of 0 to 100.> explanation: <Offer a good explanation as evidence that supports the listed consequence.> novelty: <How novel or unconventional is your reasoning on a scale of 0 to 100.> -step: 2 ... </p>
<p>Supplementary Text 9: Expert evaluation questions</p>
<p>Figure 1 .
1Implementation and testing of a universal biological simulator based on GPT-4. a, Schematic overview of SimulateGPT, a GPT-4 based biological simulator. b, Depiction of the use of GPT-4 in a simulation of Conway's Game of Life. c, Example prompts and output of SimulateGPT. d, Overview of the evaluation methods used to validate SimulateGPT.</p>
<p>Figure 2
2Qualitative and quantitative evaluation of SimulateGPT. a, Expert evaluation of the simulation for four biomedical scenarios, comparing SimulateGPT to conventional GTP-4 based reasoning. b, Performance of SimulateGPT in predicting broadly essential genes in cancer cell lines. c, Performance of SimulateGPT in predicting progression-free survival in patients with colorectal cancer. d, Expert evaluation of simulation results of the sepsis treatment experiment using SimulateGPT versus 'low complexity SimulateGPT'. e-f, Performance of SimulateGPT in predicting progression-free survival in colorectal cancer patients with the low complexity simulation (panel e) and high complexity simulation with a minimum of 5 simulation steps (panel f). Confidence intervals represent standard error. Significance: * = P ≤ 0.05, ** = P ≤ 0.01. *** = P ≤ 0.001.</p>
<p>-
Level: The level of biology addressed in this step (e.g., molecular, cellular, organ, organism) -Facts: An overview of relevant facts, including gene regulation, protein interactions, etc. -Entities: A list of all entities in the step, such as genes, proteins, cell types, tissues, and organs -Assumptions: Integration of stated facts and previous consequences into assumptions about the current step -Consequence: The most probable consequence based on facts, assumptions, and previously generated consequences, including specific entities and processes -Probability: The likelihood of the consequence happening, on a scale of 0 to 100 -Explanation: A well-reasoned explanation supporting the listed consequence -Novelty: A rating of how novel or unconventional the reasoning is, on a scale of 0 to 100</p>
<p>the eight adjacent cells, horizontally, vertically, and diagonally. For each generation, describe how you simulate the new grid in excruciating detail: For each cell in the grid (i, j) indicate all its neighbors with their states, count the number of living ones (just count the number of listed neighbors with state 'live'). Then, state the current state of the current cell of interest and derive its next generation's state following the rules stated above. Simulate each cell as just described in the format (<i,j>)$[[<neighbors>]#COUNT=<num-ber_of_alive_neighbors>]$$$oldstate=<new_state> where <neighbors> is a list of all neighbors and their states, as in "(0,1):dead|alive, ...". Finally, after the new states of all cells have been computed, print the new generation as indicated by the provided initial generation (Generation 0).</p>
<p>": "Van Cutsem E, Cervantes A, Nordlinger B, Arnold D; ESMO Guidelines Working Group. 2014. Ann Oncol. ESMO consensus guidelines for the management of patients with metastatic colorectal cancer." "[2]": "Longley DB, Harkin DP, Johnston PG. 2003. Nat Rev Cancer. 5-fluorouracil: mechanisms of action and clinical strategies." "[3]": "Cunningham D, Humblet Y, Siena S, et al. 2004. N Engl J Med. Cetuximab monotherapy and cetuximab plus irinotecan in irinotecan-refractory metastatic colorectal cancer." "[4]": "Le DT, Uram JN, Wang H, et al. 2015. N Engl J Med. PD-1 Blockade in Tumors with Mismatch-Repair Deficiency." "[5]": "Holohan C, Van Schaeybroeck S, Longley DB, Johnston PG. 2013. Nat Rev Cancer. Cancer drug resistance: an evolving paradigm." "[6]": "Sharma P, Hu-Lieskovan S, Wargo JA, Ribas A. 2017. Cell. Primary, Adaptive, and Acquired Resistance to Cancer Immunotherapy." "[7]": "Manfredi S, Lepage C, Hatem C, Coatmeur O, Faivre J, Bouvier AM. 2006. Br J Cancer. Epidemiology and management of liver metastases from colorectal cancer." "[8]": "Van Cutsem E, Köhne CH, Láng I, et al. 2011. J Clin Oncol. Cetuximab Plus Irinotecan, Fluorouracil, and Leucovorin As First-Line Treatment for Metastatic Colorectal Cancer: Updated Analysis of Overall Survival According to Tumor KRAS and BRAF Mutation Status." "[9]": "Heinemann V, von Weikersthal LF, Decker T, et al. 2014. Lancet Oncol. FOLFIRI plus cetuximab versus FOLFIRI plus bevacizumab as first-line treatment for patients with metastatic colorectal cancer (FIRE-3): a randomised, open-label, phase 3 trial." Supplementary Text 6: Expert-evaluated scenarios</p>
<p>-
The output reflects the consensus in the scientific and clinical community. -The output contains evidence of correct recall of knowledge. -The output contains evidence of incorrect recall of knowledge. -The output contains evidence of correct reasoning steps. -The output contains evidence of incorrect reasoning steps. -The output contains content it shouldn't contain. -The output omits content it shouldn't omit. -The answer contains (novel) concepts that are not typically known in the scientific and clinical community. -I felt qualified to evaluate this topic.</p>
<p>Singhal, K. et al. Large Language Models Encode Clinical Knowledge. arXiv (2022) doi:10.48550/arxiv.2212.13138. original draft, visualization. AN: expertise, validation. FP: expertise, validation. TK: expertise, validation. PS: Investigation, Resources. CB: supervision, funding acquisition, writing -review &amp; editing, MaS: conceptualization, supervision, funding acquisition, project administration, writing -original draft.All relevant data, including full text simulations, expert validation and code to reproduce our results are 
available from the following repository: https://github.com/OpenBioLink/SimulateGPT </p>
<p>A runnable version of SimulateGPT is available through Google Colab (for SimulateGPT to use GPT-4 
securely, the user needs to provide a personal OpenAI API key that allows for GPT-4 access): 
https://colab.research.google.com/github/OpenBioLink/SimulateGPT/blob/main/SimulateGPT.ipynb 
20. 
Meeth, K., Wang, J. X., Micevic, G., Damsky, W. &amp; Bosenberg, M. W. The YUMM lines: a se-
ries of congenic mouse melanoma cell lines with defined genetic alterations. Pigment Cell Mela-
noma Res. 29, 590-597 (2016). </p>
<ol>
<li>
<p>Netea, M. G. et al. Defining trained immunity and its role in health and disease. Nat. Rev. Im-
munol. 20, 375-388 (2020). </p>
</li>
<li>
<p>Hotchkiss, R. S. et al. Sepsis and septic shock. Nat. Rev. Dis. Primers 2, 16045 (2016). </p>
</li>
<li>
<p>Jarczak, D., Kluge, S. &amp; Nierhaus, A. Sepsis-Pathophysiology and Therapeutic Concepts. 
Front Med (Lausanne) 8, 628302 (2021). </p>
</li>
<li>
<p>Leventogiannis, K. et al. Toward personalized immunotherapy in sepsis: The PROVIDE ran-
domized clinical trial. Cell Rep. Med. 3, 100817 (2022). </p>
</li>
<li>
<p>Wang, L.-B. et al. Proteogenomic and metabolomic characterization of human glioblastoma. 
Cancer Cell 39, 509-528.e20 (2021). </p>
</li>
<li>
<p>Mondaca, S. et al. Specific mutations in APC, but not alterations in DNA damage response, 
associate with outcomes of patients with metastatic colorectal cancer. Gastroenterology 159, 
1975-1978.e4 (2020). </p>
</li>
<li>
<p>DepMap, B. DepMap 22Q4 Public. Figshare (2022) doi:10.6084/m9.figshare.21637199.v2. </p>
</li>
<li>
<p>Author contributions </p>
</li>
</ol>
<p>MoS: project administration, investigation, formal analysis, methodology, software, writing -original 
draft, validation. SR: project administration, investigation, formal analysis, methodology, writing -original 
draft, validation, resources. RtH: project administration, investigation, formal analysis, methodology, 
writing -</p>
<p>Trained immunity :
immunitytolerance_LPSA mouse is injected with high-dose LPS. What is the innate immune response upon rechallenge with high-dose LPS after 90 days? Focus on novelty.training_LPSA mouse is injected with low-dose LPS. What is the innate immune response upon rechallenge with high-dose LPS after 90 days? Focus on novelty. training_betaglucan A mouse is injected with beta-glucan. What is the innate immune response upon rechallenge with high-dose LPS after 90 days? Focus on novelty.</p>
<p>. Openai, 10.48550/arxiv.2303.08774GPT-4 Technical ReportOpenAI. GPT-4 Technical Report. arXiv (2023) doi:10.48550/arxiv.2303.08774.</p>
<p>A Chowdhery, 10.48550/arxiv.2204.02311Scaling Language Modeling with Pathways. arXiv (2022). Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. arXiv (2022) doi:10.48550/arxiv.2204.02311.</p>
<p>. V Sanh, 10.48550/arxiv.2110.08207Multitask Prompted Training Enables Zero-Shot Task Generalization. arXivSanh, V. et al. Multitask Prompted Training Enables Zero-Shot Task Generalization. arXiv (2021) doi:10.48550/arxiv.2110.08207.</p>
<p>Attention is all you need. A Vaswani, 10.48550/arxiv.1706.03762Vaswani, A. et al. Attention is all you need. arXiv (2017) doi:10.48550/arxiv.1706.03762.</p>
<p>H Nori, N King, S M Mckinney, D Carignan, E Horvitz, 10.48550/arxiv.2303.13375Capabilities of GPT-4 on Medical Challenge Problems. arXiv. Nori, H., King, N., McKinney, S. M., Carignan, D. &amp; Horvitz, E. Capabilities of GPT-4 on Medi- cal Challenge Problems. arXiv (2023) doi:10.48550/arxiv.2303.13375.</p>
<p>Towards Expert-Level Medical Question Answering with Large Language Models. K Singhal, 10.48550/arxiv.2305.09617Singhal, K. et al. Towards Expert-Level Medical Question Answering with Large Language Models. arXiv (2023) doi:10.48550/arxiv.2305.09617.</p>
<p>Can large language models reason about medical questions?. V Liévin, C E Hother, O Winther, 10.48550/arxiv.2207.08143Liévin, V., Hother, C. E. &amp; Winther, O. Can large language models reason about medical ques- tions? arXiv (2022) doi:10.48550/arxiv.2207.08143.</p>
<p>Emergent autonomous scientific research capabilities of large language models. D A Boiko, R Macknight, G Gomes, 10.48550/arxiv.2304.05332arXivBoiko, D. A., MacKnight, R. &amp; Gomes, G. Emergent autonomous scientific research capabilities of large language models. arXiv (2023) doi:10.48550/arxiv.2304.05332.</p>
<p>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. J Wei, 10.48550/arxiv.2201.11903Wei, J. et al. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv (2022) doi:10.48550/arxiv.2201.11903.</p>
<p>Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. E Kıcıman, R Ness, A Sharma, C Tan, 10.48550/arxiv.2305.00050Kıcıman, E., Ness, R., Sharma, A. &amp; Tan, C. Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. arXiv (2023) doi:10.48550/arxiv.2305.00050.</p>
<p>The challenges of in silico biology. B Palsson, Nat. Biotechnol. 18Palsson, B. The challenges of in silico biology. Nat. Biotechnol. 18, 1147-1150 (2000).</p>
<p>The virtual physiological human: ten years after. M Viceconti, P Hunter, Annu. Rev. Biomed. Eng. 18Viceconti, M. &amp; Hunter, P. The virtual physiological human: ten years after. Annu. Rev. Bio- med. Eng. 18, 103-123 (2016).</p>
<p>F Pappalardo, G Russo, F M Tshinanu, M Viceconti, silico clinical trials: concepts and early adoptions. 20Pappalardo, F., Russo, G., Tshinanu, F. M. &amp; Viceconti, M. In silico clinical trials: concepts and early adoptions. Brief. Bioinformatics 20, 1699-1708 (2019).</p>
<p>. M Gardner, Mathematical Games. Sci. Am. 223Gardner, M. Mathematical Games. Sci. Am. 223, 120-123 (1970).</p>
<p>It's Hard for Neural Networks To Learn the. J M Springer, G T Kenyon, 10.48550/arxiv.2009.01398Game of Life. arXiv. Springer, J. M. &amp; Kenyon, G. T. It's Hard for Neural Networks To Learn the Game of Life. arXiv (2020) doi:10.48550/arxiv.2009.01398.</p>
<p>G Mialon, 10.48550/ar-xiv.2302.07842Augmented Language Models: a Survey. arXiv. Mialon, G. et al. Augmented Language Models: a Survey. arXiv (2023) doi:10.48550/ar- xiv.2302.07842.</p>
<p>Self-Consistency Improves Chain of Thought Reasoning in Language Models. X Wang, 10.48550/arxiv.2203.11171Wang, X. et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv (2022) doi:10.48550/arxiv.2203.11171.</p>
<p>Reflexion: an autonomous agent with dynamic memory and self-reflection. N Shinn, B Labash, A Gopinath, 10.48550/arxiv.2303.11366arXivShinn, N., Labash, B. &amp; Gopinath, A. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv (2023) doi:10.48550/arxiv.2303.11366.</p>
<p>Cyanide toxicokinetics: the behavior of cyanide, thiocyanate and 2-amino-2-thiazoline-4-carboxylic acid in multiple animal models. R K Bhandari, J. Anal. Toxicol. 38Bhandari, R. K. et al. Cyanide toxicokinetics: the behavior of cyanide, thiocyanate and 2- amino-2-thiazoline-4-carboxylic acid in multiple animal models. J. Anal. Toxicol. 38, 218-225 (2014).</p>
<p>Glioblastoma survival. Glioblastoma survival:</p>
<p>As final outcome, provide two values, first indicating whether the patient's survival is more likely to be 'increased' or 'decreased' relative to the median overall glioblastoma survival (15 months), and second, the number of months by which you estimate the survival to deviate from that median. Focus on novelty and ignore the inherent uncertainty of this scenario to provide bold estimates based on your knowledge. Identified mutations: PTEN: mutations found EGFR: mutations found MGMT methylation status: high TP53: no mutations found PIK3CA: no mutations found NF1: no mutations found MUC16: no mutations found RB1: no mutations found conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome. Consider a patient diagnosed with a glioblastoma with genetic alterations, as indicated below. Explore the tumor progression under standard of care with genotype-informed treatment (if applicable). > references: "[1]": "<authors> <year> <journal> <title of the publication>" "[2]": "<authors> <year> <journal> <title of the publication>" …Consider a patient diagnosed with a glioblastoma with genetic alterations, as indicated below. Explore the tumor progression under standard of care with genotype-informed treat- ment (if applicable). As final outcome, provide two values, first indicating whether the patient's survival is more likely to be 'increased' or 'decreased' relative to the median overall glioblastoma survival (15 months), and second, the number of months by which you estimate the survival to deviate from that median. Focus on novelty and ignore the inher- ent uncertainty of this scenario to provide bold estimates based on your knowledge. Identified mutations: PTEN: mutations found EGFR: mutations found MGMT methylation status: high TP53: no mutations found PIK3CA: no mutations found NF1: no mutations found MUC16: no mutations found RB1: no mutations found conclusion: outcome: <Infer the final outcome from the last simulation step.> explanation: <Offer a good explanation as evidence that supports the final outcome.> references: "[1]": "<authors> <year> <journal> <title of the publication>" "[2]": "<authors> <year> <journal> <title of the publication>" …</p>            </div>
        </div>

    </div>
</body>
</html>