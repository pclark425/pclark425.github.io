<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8196 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8196</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8196</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-150.html">extraction-schema-150</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <p><strong>Paper ID:</strong> paper-274464979</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.03563v1.pdf" target="_blank">From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents</a></p>
                <p><strong>Paper Abstract:</strong> Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns. Recent advancements in large language models (LLMs) highlight their potential to simulate human behavior, enabling the replication of individual responses and facilitating studies on many interdisciplinary studies. In this paper, we conduct a comprehensive survey of this field, illustrating the recent progress in simulation driven by LLM-empowered agents. We categorize the simulations into three types: (1) Individual Simulation, which mimics specific individuals or demographic groups; (2) Scenario Simulation, where multiple agents collaborate to achieve goals within specific contexts; and (3) Society Simulation, which models interactions within agent societies to reflect the complexity and variety of real-world dynamics. These simulations follow a progression, ranging from detailed individual modeling to large-scale societal phenomena. We provide a detailed discussion of each simulation type, including the architecture or key components of the simulation, the classification of objectives or scenarios and the evaluation method. Afterward, we summarize commonly used datasets and benchmarks. Finally, we discuss the trends across these three types of simulation. A repository for the related sources is at {\url{https://github.com/FudanDISC/SocialAgent}}.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8196.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8196.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents: Interactive Simulacra of Human Behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system of LLM-driven agents that stores rich episodic histories and uses a tree-structured reflection process to synthesize memories, enabling continuous, coherent multi-session behavior and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents record detailed experiences over time, summarize and reflect on those experiences, and use synthesized memory summaries to guide planning and action selection in sandbox simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified in survey; implemented with large pre-trained LLM(s) (unspecified).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Sandbox social simulation / multi-session role play</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Populate an interactive sandbox with many agents and evaluate continuity, coherence, and emergent social behaviors across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>societal / long-horizon social simulation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic long-term memory with tree-structured reflection</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Comprehensive recording of experiences plus a tree-structured reflection process that periodically synthesizes and abstracts past experiences into higher-level memory entries used to guide future planning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Detailed experience logs (events, observations, interactions) and synthesized summaries/insights derived via reflection.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Reflection-driven synthesis and selection of relevant memory summaries appended to prompts; history integration into context for planning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey reports that tree-structured memory reflection optimizes memory usage and supports deeper simulations, but no numeric ablation results are provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Organizing episodic experiences and synthesizing them via reflection enables agents to maintain behavior continuity and to plan more coherently across sessions; memory reflection improves depth of simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Reflection and long-term memory increase complexity and system cost; specifics of retrieval/selectivity are challenging and not standardized.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8196.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ProAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ProAgent: Building Proactive Cooperative Agents with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proactive cooperative agent framework that incorporates memory reflection with validation and belief-correction mechanisms to improve planning and decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Proagent: Building proactive cooperative agents with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ProAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents perform memory reflection that includes validation and belief correction steps to refine memory contents and improve downstream planning and decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified in survey; uses large language models (unspecified).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-agent cooperative tasks / planning</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Cooperative multi-agent planning tasks where agents must plan and coordinate actions over time with improved decision quality through refined memories.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-agent planning / cooperative problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>long-term memory with reflective update and belief-correction</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Memory reflection pipeline that validates and corrects beliefs in stored memory entries, then uses corrected memories to inform planning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Past experiences, beliefs, and corrected memory entries used to inform planning and decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Reflection-updated memory accessed during planning; retrieval likely via prompting with selected memory summaries (survey-level description).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey notes inclusion of validation and belief correction improves planning and decision-making qualitatively; no numeric ablation reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Incorporating memory reflection with validation/belief correction leads to better planning and decision quality in complex environments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Reflection and belief-correction add pipeline complexity; limited application scenarios reported and quantitative comparisons are scarce in the surveyed literature.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8196.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Voyager: An Open-Ended Embodied Agent with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based agent that updates and refines its skill library through self-verification and reflective processes, using memory to retain learned skills and experiences for future tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Voyager: An open-ended embodied agent with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Embodied agent that allows iterative self-reflection and verification to update an internal skill library and memory of past behaviors to improve long-horizon task performance.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified in the survey; uses LLM(s) as core reasoning/planning component.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Open-ended embodied exploration / skill acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents operate in an environment, learn skills through interaction, and reuse these learned skills for subsequent tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>embodied agent / lifelong learning</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>skill library + episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Reflection and self-verification processes that add new skills and update memory entries (skill library) for future use.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Learned skills, past actions, and verification-derived knowledge entries.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Access to skill library and past interactions during planning; retrieval via prompt augmentation and reuse of validated skills.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey claims reflection and skill-library updates improve agent robustness and capability over time but does not provide numerical ablation data.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Self-reflection and verification that populate a skill library enable agents to progressively improve and perform more complex tasks over time.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Maintaining and verifying learned skills is resource-intensive; specifics of retrieval/scalability are open challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8196.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memorybank: Enhancing Large Language Models with Long-Term Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposal to use a long-term memory hub (vector database) to manage, retrieve, and organize persistent agent memories effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memorybank: Enhancing large language models with long-term memory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemoryBank (memory system)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A long-term memory architecture that stores embeddings of past content in a vector database to enable efficient semantic retrieval for LLM agents.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified; assumes integration with general LLMs via embedding-based retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>General long-term memory augmentation for LLM agents</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Provide persistent memory store for agents to retrieve relevant past information across sessions to aid planning and continuity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>memory augmentation / retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external vector-database long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Store embeddings of memories in a vector DB and retrieve relevant entries via similarity search to augment prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Embeddings corresponding to past experiences, documents, or summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Similarity (semantic) search over vector embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey notes vector databases make long-term memory management and retrieval more effective; no quantified ablation in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Vector DBs are effective hubs for long-term memory enabling better management and retrieval of persistent information for agents.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Semantic retrieval quality depends on embedding models and indexing; deciding what to write and how to summarize memories remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8196.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDB: Augmenting LLMs with Databases as Symbolic Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that treats structured databases as a symbolic memory for LLMs, enabling retrieval and operations over stored records to support task solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chatdb.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatDB (memory-backed agent pattern)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents augment language model context with structured database entries treated as symbolic memory, enabling precise retrieval and manipulation of factual records.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified; integrates LLMs with symbolic DB access.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Database-augmented conversational / task solving</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Use structured database rows as persistent memory to ground LLM responses and actions in factual, queryable memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>retrieval-augmented generation / symbolic memory access</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external symbolic (database) memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Store facts/records in a database and query them during generation to ground responses and operations.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Structured records, tables, or documents stored in a database.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Database queries and structured retrieval routed into LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey highlights database-as-memory improves factual grounding and manipulability of stored content but does not provide quantitative comparisons here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Treating structured data as symbolic memory improves precision and enables programmatic retrieval/modification of persistent facts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Bridging unstructured natural language and structured DB querying introduces engineering overhead; schema design matters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8196.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TradingGPT / TradingGPT (layered memory)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent trading system that uses layered memory to improve decision-making in financial trading simulations, where agents hold distinct characters and memory layers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TradingGPT: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>TradingGPT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Multi-agent system for financial trading where agents use layered memory structures (likely separating short-term / long-term / shared memories) to inform trading strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified; uses large language models for agent reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Financial trading simulation / market decision-making</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents trade in simulated markets, leveraging layered memories to remember past market events, strategies, and agent-specific histories to improve outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>economic simulation / sequential decision-making</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>layered memory (multiple tiers: short-term, long-term, shared)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Distinct memory layers capture different temporal scopes and possibly shared information between agents to support individual and group-level strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Past trades, market events, strategy notes, and possibly aggregated summaries across time horizons.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Layer-aware retrieval (accessing appropriate layer by recency/relevance); survey-level description without implementation detail.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey reports layered memory was used to enhance trading performance qualitatively; no numeric ablation is provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Layered memory helps agents retain and utilize multi-timescale information in economic simulations, improving decision quality in trading contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Designing appropriate layer semantics and retrieval policies is nontrivial; cost and complexity scale with memory size.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8196.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EconAgent (layered memory)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for macroeconomic simulation using LLM-based agents, incorporating layered memory to better model agents' temporal information and decision processes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>EconAgent: Large language model-empowered agents for simulating macroeconomic activities.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>EconAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Macroeconomic simulation framework where agents use layered memory to capture persistent and recent economic information to simulate macro trends like inflation and unemployment.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified; uses LLMs to craft agent decision processes.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Macroeconomic simulation / policy evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Simulate interacting economic agents over time to reproduce macroeconomic phenomena using agent memories to inform behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>economic simulation / multi-agent time-series modeling</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>layered memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Multiple memory layers represent different temporal spans (short-term observations vs long-term experiences) to influence economic decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Past economic observations, agent experiences, policy history, and aggregated summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Layered-access policy selecting memories by temporal scope and relevance; survey-level description.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey notes layered-memory architectures have been used to improve macro-simulation fidelity; no direct quantitative ablation within this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Layered memory structures help LLM agents reproduce macroeconomic phenomena more plausibly by preserving multi-timescale information.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Trade-off between simulation precision and scale; large-scale simulations require memory compression or simplification.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8196.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Shared Message Pool (Hong et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Shared Message Pool for Enhanced Agent Communication (as proposed by Hong et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A communication/storage mechanism where agents exchange structured messages into a shared pool that agents can retrieve to improve communication efficiency and coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Meta programming for multi-agent collaborative framework.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Shared Message Pool (system component)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A shared repository of structured messages that agents can write to and retrieve from to streamline inter-agent communication and reduce redundant context passing.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not specified; component used within LLM-agent multi-agent frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-agent collaboration (software development and other coordinated tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents collaborate on multi-stage tasks using the shared message pool to exchange intermediate results and coordinate subtask assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-agent coordination / collaborative task solving</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>shared short-to-mid-term communication memory pool</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Agents post structured messages to a shared pool that others can query/retrieve, functioning as a communal memory and coordination hub.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Structured messages, intermediate results, plans, and coordination signals.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Personalized retrieval of relevant messages from the shared pool (survey-level description).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey states shared message pools enhance communication efficiency; no quantitative ablations reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared message pools can improve communication efficiency and coordination in multi-agent systems by centralizing exchangeable structured information.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Requires careful structuring of messages and retrieval policies; may become a bottleneck or scale issue in very large agent societies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8196.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e8196.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memory Operations (survey-level abstraction)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory operations: write, retrieval, reflection (survey abstraction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A survey-level taxonomy describing three primary memory operations for LLM agents  memory writing, retrieval, and reflection  and their roles in agent behavior continuity and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Memory operations (write/retrieve/reflect)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Abstracted operations performed by agents to manage memory: writing new information, retrieving relevant content, and reflecting (organizing/abstracting) past memories.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>General agent tasks across individual, scenario, and society simulations</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Used across tasks to maintain consistency, inform planning, and improve long-term behavior by managing historical information.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>general memory-augmented agent behavior</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>short-term and long-term memory (operational taxonomy)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Write: append interactions/experiences; Retrieve: similarity or retrieval-model-based selection; Reflect: synthesize and abstract memories into higher-level knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Dialogue history, experiences, scene descriptors, skills, summaries, and abstracted beliefs.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Keyword/embedding similarity, retrieval models, or reflection-guided selection; also prompt concatenation for short-term context.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Survey emphasizes retrieval effectiveness is critical and that reflection can qualitatively improve planning, but it does not provide numerical ablation studies itself.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Memory writing, retrieval, and reflection are core operations; retrieval effectiveness and reflection mechanisms substantially influence agent performance and simulation fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Choosing what to write, how to summarize, retrieval selection policies, and token/context limitations are major open challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior. <em>(Rating: 2)</em></li>
                <li>Proagent: Building proactive cooperative agents with large language models. <em>(Rating: 2)</em></li>
                <li>Voyager: An open-ended embodied agent with large language models. <em>(Rating: 2)</em></li>
                <li>Memorybank: Enhancing large language models with long-term memory. <em>(Rating: 2)</em></li>
                <li>Chatdb. <em>(Rating: 2)</em></li>
                <li>TradingGPT: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance. <em>(Rating: 2)</em></li>
                <li>EconAgent: Large language model-empowered agents for simulating macroeconomic activities. <em>(Rating: 2)</em></li>
                <li>Meta programming for multi-agent collaborative framework. <em>(Rating: 1)</em></li>
                <li>Large language model-based agents for software engineering: A survey. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8196",
    "paper_id": "paper-274464979",
    "extraction_schema_id": "extraction-schema-150",
    "extracted_data": [
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents: Interactive Simulacra of Human Behavior",
            "brief_description": "A system of LLM-driven agents that stores rich episodic histories and uses a tree-structured reflection process to synthesize memories, enabling continuous, coherent multi-session behavior and planning.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior.",
            "mention_or_use": "mention",
            "agent_name": "Generative Agents",
            "agent_description": "Agents record detailed experiences over time, summarize and reflect on those experiences, and use synthesized memory summaries to guide planning and action selection in sandbox simulations.",
            "model_name": "",
            "model_description": "Not specified in survey; implemented with large pre-trained LLM(s) (unspecified).",
            "task_name": "Sandbox social simulation / multi-session role play",
            "task_description": "Populate an interactive sandbox with many agents and evaluate continuity, coherence, and emergent social behaviors across sessions.",
            "task_type": "societal / long-horizon social simulation",
            "memory_used": true,
            "memory_type": "episodic long-term memory with tree-structured reflection",
            "memory_mechanism": "Comprehensive recording of experiences plus a tree-structured reflection process that periodically synthesizes and abstracts past experiences into higher-level memory entries used to guide future planning.",
            "memory_representation": "Detailed experience logs (events, observations, interactions) and synthesized summaries/insights derived via reflection.",
            "memory_retrieval_method": "Reflection-driven synthesis and selection of relevant memory summaries appended to prompts; history integration into context for planning.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey reports that tree-structured memory reflection optimizes memory usage and supports deeper simulations, but no numeric ablation results are provided in this survey.",
            "key_findings": "Organizing episodic experiences and synthesizing them via reflection enables agents to maintain behavior continuity and to plan more coherently across sessions; memory reflection improves depth of simulation.",
            "limitations_or_challenges": "Reflection and long-term memory increase complexity and system cost; specifics of retrieval/selectivity are challenging and not standardized.",
            "uuid": "e8196.0",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ProAgent",
            "name_full": "ProAgent: Building Proactive Cooperative Agents with Large Language Models",
            "brief_description": "A proactive cooperative agent framework that incorporates memory reflection with validation and belief-correction mechanisms to improve planning and decision-making.",
            "citation_title": "Proagent: Building proactive cooperative agents with large language models.",
            "mention_or_use": "mention",
            "agent_name": "ProAgent",
            "agent_description": "Agents perform memory reflection that includes validation and belief correction steps to refine memory contents and improve downstream planning and decisions.",
            "model_name": "",
            "model_description": "Not specified in survey; uses large language models (unspecified).",
            "task_name": "Multi-agent cooperative tasks / planning",
            "task_description": "Cooperative multi-agent planning tasks where agents must plan and coordinate actions over time with improved decision quality through refined memories.",
            "task_type": "multi-agent planning / cooperative problem solving",
            "memory_used": true,
            "memory_type": "long-term memory with reflective update and belief-correction",
            "memory_mechanism": "Memory reflection pipeline that validates and corrects beliefs in stored memory entries, then uses corrected memories to inform planning.",
            "memory_representation": "Past experiences, beliefs, and corrected memory entries used to inform planning and decisions.",
            "memory_retrieval_method": "Reflection-updated memory accessed during planning; retrieval likely via prompting with selected memory summaries (survey-level description).",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey notes inclusion of validation and belief correction improves planning and decision-making qualitatively; no numeric ablation reported here.",
            "key_findings": "Incorporating memory reflection with validation/belief correction leads to better planning and decision quality in complex environments.",
            "limitations_or_challenges": "Reflection and belief-correction add pipeline complexity; limited application scenarios reported and quantitative comparisons are scarce in the surveyed literature.",
            "uuid": "e8196.1",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Voyager",
            "name_full": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
            "brief_description": "An LLM-based agent that updates and refines its skill library through self-verification and reflective processes, using memory to retain learned skills and experiences for future tasks.",
            "citation_title": "Voyager: An open-ended embodied agent with large language models.",
            "mention_or_use": "mention",
            "agent_name": "Voyager",
            "agent_description": "Embodied agent that allows iterative self-reflection and verification to update an internal skill library and memory of past behaviors to improve long-horizon task performance.",
            "model_name": "",
            "model_description": "Not specified in the survey; uses LLM(s) as core reasoning/planning component.",
            "task_name": "Open-ended embodied exploration / skill acquisition",
            "task_description": "Agents operate in an environment, learn skills through interaction, and reuse these learned skills for subsequent tasks.",
            "task_type": "embodied agent / lifelong learning",
            "memory_used": true,
            "memory_type": "skill library + episodic memory",
            "memory_mechanism": "Reflection and self-verification processes that add new skills and update memory entries (skill library) for future use.",
            "memory_representation": "Learned skills, past actions, and verification-derived knowledge entries.",
            "memory_retrieval_method": "Access to skill library and past interactions during planning; retrieval via prompt augmentation and reuse of validated skills.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey claims reflection and skill-library updates improve agent robustness and capability over time but does not provide numerical ablation data.",
            "key_findings": "Self-reflection and verification that populate a skill library enable agents to progressively improve and perform more complex tasks over time.",
            "limitations_or_challenges": "Maintaining and verifying learned skills is resource-intensive; specifics of retrieval/scalability are open challenges.",
            "uuid": "e8196.2",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "MemoryBank",
            "name_full": "Memorybank: Enhancing Large Language Models with Long-Term Memory",
            "brief_description": "A proposal to use a long-term memory hub (vector database) to manage, retrieve, and organize persistent agent memories effectively.",
            "citation_title": "Memorybank: Enhancing large language models with long-term memory.",
            "mention_or_use": "mention",
            "agent_name": "MemoryBank (memory system)",
            "agent_description": "A long-term memory architecture that stores embeddings of past content in a vector database to enable efficient semantic retrieval for LLM agents.",
            "model_name": "",
            "model_description": "Not specified; assumes integration with general LLMs via embedding-based retrieval.",
            "task_name": "General long-term memory augmentation for LLM agents",
            "task_description": "Provide persistent memory store for agents to retrieve relevant past information across sessions to aid planning and continuity.",
            "task_type": "memory augmentation / retrieval-augmented generation",
            "memory_used": true,
            "memory_type": "external vector-database long-term memory",
            "memory_mechanism": "Store embeddings of memories in a vector DB and retrieve relevant entries via similarity search to augment prompts.",
            "memory_representation": "Embeddings corresponding to past experiences, documents, or summaries.",
            "memory_retrieval_method": "Similarity (semantic) search over vector embeddings.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey notes vector databases make long-term memory management and retrieval more effective; no quantified ablation in survey.",
            "key_findings": "Vector DBs are effective hubs for long-term memory enabling better management and retrieval of persistent information for agents.",
            "limitations_or_challenges": "Semantic retrieval quality depends on embedding models and indexing; deciding what to write and how to summarize memories remains challenging.",
            "uuid": "e8196.3",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ChatDB",
            "name_full": "ChatDB: Augmenting LLMs with Databases as Symbolic Memory",
            "brief_description": "An approach that treats structured databases as a symbolic memory for LLMs, enabling retrieval and operations over stored records to support task solving.",
            "citation_title": "Chatdb.",
            "mention_or_use": "mention",
            "agent_name": "ChatDB (memory-backed agent pattern)",
            "agent_description": "Agents augment language model context with structured database entries treated as symbolic memory, enabling precise retrieval and manipulation of factual records.",
            "model_name": "",
            "model_description": "Not specified; integrates LLMs with symbolic DB access.",
            "task_name": "Database-augmented conversational / task solving",
            "task_description": "Use structured database rows as persistent memory to ground LLM responses and actions in factual, queryable memory.",
            "task_type": "retrieval-augmented generation / symbolic memory access",
            "memory_used": true,
            "memory_type": "external symbolic (database) memory",
            "memory_mechanism": "Store facts/records in a database and query them during generation to ground responses and operations.",
            "memory_representation": "Structured records, tables, or documents stored in a database.",
            "memory_retrieval_method": "Database queries and structured retrieval routed into LLM prompts.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey highlights database-as-memory improves factual grounding and manipulability of stored content but does not provide quantitative comparisons here.",
            "key_findings": "Treating structured data as symbolic memory improves precision and enables programmatic retrieval/modification of persistent facts.",
            "limitations_or_challenges": "Bridging unstructured natural language and structured DB querying introduces engineering overhead; schema design matters.",
            "uuid": "e8196.4",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "TradingGPT / TradingGPT (layered memory)",
            "name_full": "TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance",
            "brief_description": "A multi-agent trading system that uses layered memory to improve decision-making in financial trading simulations, where agents hold distinct characters and memory layers.",
            "citation_title": "TradingGPT: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance.",
            "mention_or_use": "mention",
            "agent_name": "TradingGPT",
            "agent_description": "Multi-agent system for financial trading where agents use layered memory structures (likely separating short-term / long-term / shared memories) to inform trading strategies.",
            "model_name": "",
            "model_description": "Not specified; uses large language models for agent reasoning.",
            "task_name": "Financial trading simulation / market decision-making",
            "task_description": "Agents trade in simulated markets, leveraging layered memories to remember past market events, strategies, and agent-specific histories to improve outcomes.",
            "task_type": "economic simulation / sequential decision-making",
            "memory_used": true,
            "memory_type": "layered memory (multiple tiers: short-term, long-term, shared)",
            "memory_mechanism": "Distinct memory layers capture different temporal scopes and possibly shared information between agents to support individual and group-level strategies.",
            "memory_representation": "Past trades, market events, strategy notes, and possibly aggregated summaries across time horizons.",
            "memory_retrieval_method": "Layer-aware retrieval (accessing appropriate layer by recency/relevance); survey-level description without implementation detail.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey reports layered memory was used to enhance trading performance qualitatively; no numeric ablation is provided in this survey.",
            "key_findings": "Layered memory helps agents retain and utilize multi-timescale information in economic simulations, improving decision quality in trading contexts.",
            "limitations_or_challenges": "Designing appropriate layer semantics and retrieval policies is nontrivial; cost and complexity scale with memory size.",
            "uuid": "e8196.5",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "EconAgent (layered memory)",
            "name_full": "EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities",
            "brief_description": "A framework for macroeconomic simulation using LLM-based agents, incorporating layered memory to better model agents' temporal information and decision processes.",
            "citation_title": "EconAgent: Large language model-empowered agents for simulating macroeconomic activities.",
            "mention_or_use": "mention",
            "agent_name": "EconAgent",
            "agent_description": "Macroeconomic simulation framework where agents use layered memory to capture persistent and recent economic information to simulate macro trends like inflation and unemployment.",
            "model_name": "",
            "model_description": "Not specified; uses LLMs to craft agent decision processes.",
            "task_name": "Macroeconomic simulation / policy evaluation",
            "task_description": "Simulate interacting economic agents over time to reproduce macroeconomic phenomena using agent memories to inform behavior.",
            "task_type": "economic simulation / multi-agent time-series modeling",
            "memory_used": true,
            "memory_type": "layered memory",
            "memory_mechanism": "Multiple memory layers represent different temporal spans (short-term observations vs long-term experiences) to influence economic decisions.",
            "memory_representation": "Past economic observations, agent experiences, policy history, and aggregated summaries.",
            "memory_retrieval_method": "Layered-access policy selecting memories by temporal scope and relevance; survey-level description.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey notes layered-memory architectures have been used to improve macro-simulation fidelity; no direct quantitative ablation within this survey.",
            "key_findings": "Layered memory structures help LLM agents reproduce macroeconomic phenomena more plausibly by preserving multi-timescale information.",
            "limitations_or_challenges": "Trade-off between simulation precision and scale; large-scale simulations require memory compression or simplification.",
            "uuid": "e8196.6",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Shared Message Pool (Hong et al.)",
            "name_full": "Shared Message Pool for Enhanced Agent Communication (as proposed by Hong et al.)",
            "brief_description": "A communication/storage mechanism where agents exchange structured messages into a shared pool that agents can retrieve to improve communication efficiency and coordination.",
            "citation_title": "Meta programming for multi-agent collaborative framework.",
            "mention_or_use": "mention",
            "agent_name": "Shared Message Pool (system component)",
            "agent_description": "A shared repository of structured messages that agents can write to and retrieve from to streamline inter-agent communication and reduce redundant context passing.",
            "model_name": "",
            "model_description": "Not specified; component used within LLM-agent multi-agent frameworks.",
            "task_name": "Multi-agent collaboration (software development and other coordinated tasks)",
            "task_description": "Agents collaborate on multi-stage tasks using the shared message pool to exchange intermediate results and coordinate subtask assignments.",
            "task_type": "multi-agent coordination / collaborative task solving",
            "memory_used": true,
            "memory_type": "shared short-to-mid-term communication memory pool",
            "memory_mechanism": "Agents post structured messages to a shared pool that others can query/retrieve, functioning as a communal memory and coordination hub.",
            "memory_representation": "Structured messages, intermediate results, plans, and coordination signals.",
            "memory_retrieval_method": "Personalized retrieval of relevant messages from the shared pool (survey-level description).",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Survey states shared message pools enhance communication efficiency; no quantitative ablations reported in the survey.",
            "key_findings": "Shared message pools can improve communication efficiency and coordination in multi-agent systems by centralizing exchangeable structured information.",
            "limitations_or_challenges": "Requires careful structuring of messages and retrieval policies; may become a bottleneck or scale issue in very large agent societies.",
            "uuid": "e8196.7",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Memory Operations (survey-level abstraction)",
            "name_full": "Memory operations: write, retrieval, reflection (survey abstraction)",
            "brief_description": "A survey-level taxonomy describing three primary memory operations for LLM agents  memory writing, retrieval, and reflection  and their roles in agent behavior continuity and planning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "Memory operations (write/retrieve/reflect)",
            "agent_description": "Abstracted operations performed by agents to manage memory: writing new information, retrieving relevant content, and reflecting (organizing/abstracting) past memories.",
            "model_name": "",
            "model_description": "",
            "task_name": "General agent tasks across individual, scenario, and society simulations",
            "task_description": "Used across tasks to maintain consistency, inform planning, and improve long-term behavior by managing historical information.",
            "task_type": "general memory-augmented agent behavior",
            "memory_used": true,
            "memory_type": "short-term and long-term memory (operational taxonomy)",
            "memory_mechanism": "Write: append interactions/experiences; Retrieve: similarity or retrieval-model-based selection; Reflect: synthesize and abstract memories into higher-level knowledge.",
            "memory_representation": "Dialogue history, experiences, scene descriptors, skills, summaries, and abstracted beliefs.",
            "memory_retrieval_method": "Keyword/embedding similarity, retrieval models, or reflection-guided selection; also prompt concatenation for short-term context.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "ablation_or_comparison": "Survey emphasizes retrieval effectiveness is critical and that reflection can qualitatively improve planning, but it does not provide numerical ablation studies itself.",
            "key_findings": "Memory writing, retrieval, and reflection are core operations; retrieval effectiveness and reflection mechanisms substantially influence agent performance and simulation fidelity.",
            "limitations_or_challenges": "Choosing what to write, how to summarize, retrieval selection policies, and token/context limitations are major open challenges.",
            "uuid": "e8196.8",
            "source_info": {
                "paper_title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior.",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Proagent: Building proactive cooperative agents with large language models.",
            "rating": 2,
            "sanitized_title": "proagent_building_proactive_cooperative_agents_with_large_language_models"
        },
        {
            "paper_title": "Voyager: An open-ended embodied agent with large language models.",
            "rating": 2,
            "sanitized_title": "voyager_an_openended_embodied_agent_with_large_language_models"
        },
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory.",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Chatdb.",
            "rating": 2
        },
        {
            "paper_title": "TradingGPT: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance.",
            "rating": 2,
            "sanitized_title": "tradinggpt_multiagent_system_with_layered_memory_and_distinct_characters_for_enhanced_financial_trading_performance"
        },
        {
            "paper_title": "EconAgent: Large language model-empowered agents for simulating macroeconomic activities.",
            "rating": 2,
            "sanitized_title": "econagent_large_language_modelempowered_agents_for_simulating_macroeconomic_activities"
        },
        {
            "paper_title": "Meta programming for multi-agent collaborative framework.",
            "rating": 1,
            "sanitized_title": "meta_programming_for_multiagent_collaborative_framework"
        },
        {
            "paper_title": "Large language model-based agents for software engineering: A survey.",
            "rating": 1,
            "sanitized_title": "large_language_modelbased_agents_for_software_engineering_a_survey"
        }
    ],
    "cost": 0.02103925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents
4 Dec 2024</p>
<p>Xinyi Mou 
Fudan University</p>
<p>Xuanwen Ding 
East China Normal University</p>
<p>Qi He 
Fudan University</p>
<p>Liang Wang 
Harbin Institute of Technology
Shenzhen</p>
<p>Jingcong Liang 
Fudan University</p>
<p>Xinnong Zhang 
Fudan University</p>
<p>Libo Sun 
Fudan University</p>
<p>Jiayu Lin 
Fudan University</p>
<p>Jie Zhou 
East China Normal University</p>
<p>Xuanjing Huang 
Fudan University</p>
<p>Zhongyu Wei zywei@fudan.edu.cn 
Fudan University</p>
<p>Shanghai Innovation Institute</p>
<p>From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents
4 Dec 202492885EFEE5C47BA8C2FAD9D682FACC74arXiv:2412.03563v1[cs.CL]
Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns.Recent advancements in large language models (LLMs) highlight their potential to simulate human behavior, enabling the replication of individual responses and facilitating studies on many interdisciplinary studies.In this paper, we conduct a comprehensive survey of this field, illustrating the recent progress in simulation driven by LLM-empowered agents.We categorize the simulations into three types: (1) Individual Simulation, which mimics specific individuals or demographic groups; (2) Scenario Simulation, where multiple agents collaborate to achieve goals within specific contexts; and (3) Society Simulation, which models interactions within agent societies to reflect the complexity and variety of real-world dynamics.These simulations follow a progression, ranging from detailed individual modeling to largescale societal phenomena.We provide a detailed discussion of each simulation type, including the architecture or key components of the simulation, the classification of objectives or scenarios and the evaluation method.Afterward, we summarize commonly used datasets and benchmarks.Finally, we discuss the trends across these three types of simulation.A repository for the related sources is at https://github.com/FudanDISC/SocialAgent.</p>
<p>Introduction</p>
<p>Social science investigates human behavior and social structures to understand how societies function.Traditional sociological research heavily relies on human participation to conduct experiments and gather data.Questionnaires [1,2] and psychological experiments [3,4] are commonly used to test theoretical hypotheses, understand social phenomena, and predict collective outcomes.While these methods can provide highly authentic data, they are expensive, challenging to scale, and involve certain ethical risks.</p>
<p>Recently, large language models (LLMs) have demonstrated impressive capabilities in human-level reasoning and planning [5][6][7][8][9].They can perceive the environment, make decisions, and take corresponding actions, showcasing their potential as autonomous agents that can serve as human substitutes.In appropriate settings, LLM-driven agents can accurately simulate responses from corresponding individuals by leveraging their role-playing abilities [10,11], a property known as algorithmic fidelity [12,13].This characteristic makes LLM-driven agents highly valuable in simulating human behavior.By reproducing individual response patterns in specific scenarios, LLM-driven agents help researchers to better understand, validate, and predict human reactions.</p>
<p>Just as individuals do not exist independently within society, in addition to separate individual agents, interactions between multiple agents have also been widely studied to solve specific problems or simulate complex dynamics in the real world [14,15].On one hand, LLMs can be specialized as agents with detailed knowledge and skills, leveraging collective intelligence to solve complex problems, such as software development [16,17], automatic diagnosis [18,19] and judicial decision-making [20].In this case, multiple autonomous agents collaborate on planning, discussion, and decision-making, reflecting the cooperative nature of human groups when solving problems.On the other hand, simple interactions between multiple agents can lead to the emergence of complex collective behaviors or patterns [21][22][23], thereby replicating complex social dynamics in the real world, such as opinion dynamics [24][25][26] and macroeconomics phenomena [27].Such simulations provide valuable tools for understanding, analyzing, and predicting complex phenomena that may be difficult or impractical to observe directly in real life, offering strong support for decision-making in areas such as policy-making and social management.</p>
<p>This research field is rapidly expanding, with papers focusing on various aspects.Considering the purpose of simulation and the varying demands for diversity, scale, and accuracy in individual modeling, we categorize the existing work into three types, as illustrated in Figure 1: 1.Individual Simulation: leveraging LLM-based agents to mimic specific individuals or groups of people sharing common demographic characteristics [10,11,28].This line of research focuses on the replication of features of a single person, e.g., personality, and has not involved multi-agent interactions.</p>
<p>Individual Simulation</p>
<ol>
<li>
<p>Scenario Simulation: organizing a group of agents in a concentrated scenario, driven by specific goals or tasks, such as software development [16,17], question answering [29] and paper reviewing [30].Such simulations are usually focused on small-scale agents within specific scenarios, emphasizing the collective wisdom of agents with specialized expertise.</p>
</li>
<li>
<p>Society Simulation: simulating more complex and diverse behaviors in the agent society to explore social dynamics in real-world applications.Such simulations could test social science theories within a small scope [31] or populate virtual spaces and communities with large-scale realistic social phenomena [32,33].The composition of individuals in such simulations is more complex and diverse.</p>
</li>
</ol>
<p>These three types of simulations exhibit a progressive relationship.Individual simulation models a specific person or a type of person, serving as the foundation for scenario simulation and society simulation.Theoretically, society simulation can encompass a chaotic world composed of countless subscenarios, though current work focuses on specific scenarios.</p>
<p>Although this field has seen rapid growth, with some surveys summarizing agent architectures [7,9,15] or certain aspects of single-agent ability or multi-agent systems [11,14,34], there is an absence of a systematic review to summarize the work from the individual to society, providing a comprehensive blueprint for this field.This motivates us to present this survey, aiming to contribute to the research and development of simulations driven by LLM-based agents, as well as a wider range of interdisciplinary studies.To comprehensively describe our landscape, we organize our survey as follows.After a brief introduction to the background in  2, we begin in  3 by detailing how to conduct individual simulation through discussions of (1) the architecture of a single agent, (2) construction method of individual simulation, (3) the classification of objectives, and (4) the evaluation of individual simulation.Next, in  4, we summarize scenario simulation, including (1) the elements that constitute a scenario simulation system, (2) the classification of scenarios, and (3) the evaluation of scenario simulation, exploring how multiple agents collaborate to achieve objectives within a single scenario.Following this, in  5, we introduce society simulation, examining how multi-agent systems can construct complex social dynamics through (1) the social construction elements of society simulation, (2) the classification of society simulation scenarios, and (3) the evaluation of society simulation.In  6, we summarize existing datasets and benchmarks.Based on the earlier sections, we analyze trends in these three aspects in  7 and present the conclusion in  8. 2 Background</p>
<p>Level Strategy
Support</p>
<p>Large Language Model-based Agents</p>
<p>Benefiting from the large-scale parameters and pre-training on vast amounts of data, the recently emerging large language models have shown great potential in achieving human-like intelligence [6,35,36].This has sparked a rise in the research of LLM-empowered agents, where the key idea is to equip the LLMs with human capabilities such as memory [37,38], planning [39,40] and tool usage [41,42].The memory module enables agents to store and operate historical information to facilitate future actions.Memory of different structures [32,43] and formats [44,45] have been integrated into LLM-based agents.The planning module helps agents to decompose complex tasks into subtasks, where various planning strategies [5,39] are adopted.The tool-usage module allows agents to make use of external tools or resources [39,46] to solve tasks.Overall, these modules assist agents in operating more effectively in complex and diverse environments.</p>
<p>Multi-agent Systems</p>
<p>To realize complex scenarios, a single agent is never enough.</p>
<p>A system where interaction between multiple agents is involved is referred to as a multi-agent system (MAS).The agents may have a common goal, such as working together to accomplish a task [16,17] or solve a problem [29], or they may just have self-interested goals that can cause them to compete for limited resources [47].In a multi-agent system, each agent may be assigned distinct roles and skills, as well as distinct tasks.These agents can be organized in various ways, such as layered or centralized structures [48][49][50], and can communicate through different methods [51][52][53].These factors significantly influence the effectiveness and efficiency of multi-agent interactions.</p>
<p>Individual Simulation</p>
<p>Individual simulation focuses on designing a modular architecture that integrates individualized data for the construction of agents and simulating the specific objective with high fidelity.In this section, we first outline the basic architecture of the agent in the individual simulation with four key components in 3.1.Then, two construction methods are discussed in 3.2 to implement the integration of individualized data into objectives introduced in 3.3.The evaluation methods are examined from different perspectives in 3.4.The overall framework is presented in Figure 2 and representative works are summarized in Table 1.</p>
<p>Architecture</p>
<p>To effectively accomplish individual simulation, it is essential to construct an agent architecture that can accurately replicate the features of the individual.This requires a balance between theoretical abstraction and practical implementation to capture the complexity of human behaviors.Typically, this architecture is modularized into four core components: profile, memory, planning, and action.</p>
<p>Profile</p>
<p>Profile differentiates the unique characteristics of simulated individuals, encompassing attributes, behaviors, and constraints.The profiles differ in the ways of construction and their forms.</p>
<p>Profile Construction Profile construction refers to the process of collecting individual-related information, which can be categorized into manual modification and LLM generation.Manual modification takes advantage of publicly available data to create high-quality profiles through a human-guided process.According to the collected sources, manual modification can also be classified into three categories: handcrafting, online communities, and historical works.Handcrafting manually organized some coarse strength information, such as well-known characters [101] and specific personalities [77,79], while online communities construct profiles built on the web data like Wikipedia [10] and social media [60], where the profile implicitly exists in conversations and materials.In addition, literary works serve as additional descriptions that reflect the author's thoughts [56] and characters in the storyline [54,59].LLM generation automatically generates the expected persona-based information profiles by prompting LLMs with essential individual details [28,61,83].This method explores diverse profiles with ease, while the quality needs human supervision with caution.</p>
<p>Profile Form Profile form defines the format of individual information, which can be categorized into descriptions and conversations.Descriptions directly describe basic individual information or identity with details like name, age, and gender [101,102].While descriptions can intuitively reflect the basic attributes of an individual, deeper contextual information can also be ignored.On the contrary, conversations implicitly reflect the character profile through dialogue.A substantial amount of conversational data is derived from sources such as films, literary works, and scripts [54,70,103,104].</p>
<p>Considering the extensive commonsense knowledge learned by LLMs in the pre-training stage, recent works leverage LLMs to generate individual dialogues [59,98], which defines the artistic genre through six essential elements to generate detailed drama scripts [105] and imitates speaking styles through context learning [28,65].</p>
<p>Memory</p>
<p>Memory is designed to store perceived or generated information, helping agents maintain consistency and continuity of behavior and overcome the limited context window of LLMs.</p>
<p>Considering the complexity of memory, researchers struggle to design more efficient memory types and operations.</p>
<p>Memory Type Based on the temporal span of stored content, memory can be commonly divided into two types, namely short-term memory and long-term memory.Short-term memory records the instant local information that the agent perceives, which can be further divided into simulation contents and simulation supplements.Simulation contents include essential interaction data like user instructions [56,77], dialogue history [106,107], and user/environment responses [76].Simulation supplements provide additional environmental information includ-ing scene descriptions [58,76] and scene-related experiences [10,66], which navigate agents through the simulation to perform tasks appropriately.Long-term memory stores persistent global information, preventing deviations from intended goals, which holds extensive individual-specific information stably, including past experiences and behaviors, current knowledge, and skills [66,86].With the proposal of using the vector database as the long-term memory hub, the management, retrieval, and organization of memory is more effective [108].</p>
<p>Memory Operation Memory operations stand for the continuous updating and utilization of memory by the agent.The common memory operations include three types, namely memory writing, memory retrieval, and memory reflection.Memory writing aims to incorporate the relevant historical content into the memory.This process mirrors human memory formation, where useful information is retained for future retrieval.The memories to be written vary from user-specific dialogue history [103], new skills [109], to selected papers and other forms [110].</p>
<p>Memory retrieval serves to extract valuable content from memory based on customized requirements.The overall performance of the individual simulation highly relies on the effectiveness of memory retrieval since simulations are sensitive to the context.Traditional retrieval technologies rely on similarity such as keyword matching [111] and embedding vectors [108], while recent works introduce the retrieval model to select the most relevant information [112,113].</p>
<p>Memory reflection mirrors the human ability to reconsider past behaviors and opinions.Specifically, it helps the agent to organize, refine, and elevate memories into more abstract and insightful concepts.Generative Agents [57] maintains a comprehensive record of agents' experiences with a tree-structured reflection process to optimize memory usage.ProAgent [114] incorporates memory reflection with validation and belief correction to improve the agent's planning and decision-making.Voyager [109] allows agents to reflect on their behavior and update their skill libraries through selfverification.Although the application scenarios of memory reflection are still limited, it shows great improvement in enhancing performance and increasing the depth of simulations, especially in complex environments.</p>
<p>Planning</p>
<p>Planning is the process of deciding on a series of actions aimed at achieving specific goals.Traditional planning tasks typically focus on solving particular problems, such as mathematical reasoning [115] or embodied tasks [116,117].At the individual simulation level, however, agents are expected to go beyond mere problem-solving.They should also be able to simulate personalized thinking and emotional responses during interactions with specific individuals.This extends planning into two additional categories: empathetic planning and subjective planning.Empathetic planning Empathetic planning refers to an agent's ability to infer and perceive the behavior and emotions of others before taking action.It involves using Chainof-Thought (CoT) reasoning to understand the situations of others and make adaptive decisions or judgments [71,76,89].This allows the agent to tailor its actions based on the emotional and behavioral context, guiding the acquisition of personalized feedback.</p>
<p>Subjective planning Subjective planning refers to the actions an agent takes based on its own thoughts and feelings, in line with its predefined role or identity.This can involve utilizing inner monologues from simulated characters to finetune LLMs [10,68] or using CoT to guide LLMs to express themselves according to their own beliefs [92].This form of planning is driven by the agent's internal state, rather than by external stimuli or the needs of others.</p>
<p>Action</p>
<p>Action refers to the direct interaction between LLMs and their environment.Action encompasses two key aspects: the action situation, which describes the context in which actions occur, and the action domain, which defines the requirements for action space.Action serves as the interface for simulating human behavior, allowing LLMs to execute tasks that mimic real-world actions and responses.This interaction enables a deeper understanding of human-like decision-making and execution in various scenarios.</p>
<p>Action Situation With individual simulations focusing on more and more diverse and complicated situations, various action situations spring out accordingly, ranging from dialogue [118], games [119], real word [106], etc.Typically, action situations can be divided into simple dialogues and crafted situations.</p>
<p>Simple dialogues are few-turn conversations without restricted environments, such as constructing dialogues between two characters [54].Recent researches utilize simple dialogues to induce potential attributes within the models, involving personality [72,73], traits [81] and toxicity [77].Other works conduct evaluations of persona with interviewing [61] or questionnaire [120] with simple dialogues to facilitate their experiment.</p>
<p>Crafted situations are elaborately designed environments including detailed rules and surrounding descriptions.Common situations like games are modified from simple dialogues.They leverage game rules to provide a settled virtual topic for both users and agents to play in, especially in the board role-playing games [119, 119] [121].Besides, researchers have developed a more delicate environment called sandbox [111], which not only includes rules but establish an objective environment.To further enrich the individual simulation situation, some authors add some elements existing in scripts like facial expression, tiny movements [58,105], and nuanced information from environment images [69].</p>
<p>Action Domain The Action domain can be commonly divided into close domain and open domain based on the restriction of action space.</p>
<p>Closed domain simulation occurs when the available action space is limited.In simple situations such as completing questionnaires testing [72], making decisions from a set of options [75], or rating with predefined standards [61], the action space of LLMs is determined by researchers ahead of simulation to make responses predictable.In practical scenarios, LLMs are required to choose tools [112,122] or se-lect specific functions to complete concrete tasks, like recommending, browsing, and compiling.Individual simulation with agents in closed-domain tasks can improve human work efficiency, extending beyond entertainment purposes.</p>
<p>Open domain simulation places few restrictions on actions, allowing LLMs to generate responses freely.This approach more closely resembles real-world conditions, but also demands higher standards for individual simulation.Among various open-domain tasks, taking actions through conversation is a popular method for simulating individual behavior [54,59,62,65], in which the varied settings stimulate LLMs' potential for individual simulation and allow researchers to oversee simulations across diverse and nuanced dimensions.Another growing method of open-domain simulation is scenario-based interaction, where LLMs are assigned roles and are required to interact in crated situations like sandbox [108,109] or established game settings [119,121].</p>
<p>Construction</p>
<p>Construction indicates the process of integrating individual data into the established model of LLMs, which aligns the design model and the individual, thus creating the simulating LLMs.Generally, construction methods are distinguished into two types, namely nonparametric prompting and parametric training.</p>
<p>Nonparametric Prompting</p>
<p>Nonparametric prompting, i.e. prompt engineering, is a method of interacting with LLMs by designing and optimizing input prompts.In some individual simulations, the description-based profile is implemented by a system prompt.Researchers often create system prompts that begin with "You are a..." to assign models specific demographic features and roles [77].Besides, LLM outputs are enhanced in some works through few-shot prompting by providing specific examples to inject detailed information and improve response quality.Moreover, incorporating problem-specific details directly within prompt structures can significantly enhance the effectiveness of the simulation.</p>
<p>Short-term memory is often implemented by nonparametric prompting.For situation-based individual simulations, environment descriptions and behavior rules are typically conveyed through prompt engineering [121].Since situational information is generally objective and must be followed, emphasizing this information directly in the input is a rather effective method for constructing simulations.However, due to the context window limitations of LLMs, the quality of the profile prompt significantly restricts prompt-based individual simulations.Moreover, the preset template configurations as the "assistant" within LLMs pose a major challenge for prompt engineering in individual simulations [83].</p>
<p>Parametric Training</p>
<p>Parametric training modifies the model by directly updating the LLM parameters with given data.The training methods can be generally categorized into pre-training, finetuning, and reinforcement learning.</p>
<p>Pre-training</p>
<p>The pre-training method in individual simulation focuses on aligning the original LLMs with basic individual-related data and setting up a fundamental knowledge of individuals for LLMs.The targets of training datasets vary in recent studies, including individual descriptions [113], literature summaries [54], and philosophical works or utterances [56].Finetuning The finetuning method is designed for adapting LLMs for individual simulation in specific tasks and situations.Researchers collect and modify supervised instruction datasets tailored for specific situations and fine-tune their models to equip them with the corresponding capabilities.Using persona-enhanced datasets is an effective method to regulate the models' behavior in individual simulation, which is constructed by adding instruction tuning samples of the simulated individual's behavior [68,98].LoRA finetuning method can integrate multiple characters into a single model [65,123].In multimodal finetuning scenarios, both visual and textual information are considered to significantly enhance LLMs' simulation behavior in multimodal contexts [69,113].Compared to prompt engineering, finetuning leverages large datasets more effectively and reduces the limitations imposed by the pre-training phase of LLMs.Reinforcement Learning The reinforcement learning method is used to refine models in dynamic environments with the goal of maximizing cumulative rewards.In simulations involving conversations and dialogues, the quality of the LLM's responses directly influences the rewards it receives [87,124,125], which encourages the model to learn the appropriate ways to respond in dialogues.By modifying the reward function, researchers can influence the model's preference and thus manage to mimic the personas of the simulated individuals [88].As individual simulations become more diverse and complex, reinforcement learning plays a crucial role in improving the dynamic behavior of simulated LLMs.</p>
<p>Simulation Objectives</p>
<p>The simulation objectives of individual simulation for various purposes can be divided into two categories: (1) Demographics: a group of people who share the same characteristics, such as psychological traits (e.g., INTJ) or identityrelated features (e.g., farmers).(2) Characters: a specific individual, whether real or virtual, who is widely recognized by groups of people.</p>
<p>Demographics</p>
<p>Demographic individuals refer to a group of people who share the same features.In an abstract sense, demographics can be understood as the centroid of an embedding space that represents common opinions and beliefs, essentially clustering individual embeddings for classification purposes [91].Demographic simulation involves assigning an identity, such as "student," to LLMs and guiding the simulators to perform specific tasks.Early demographic simulations have focused on investigating the internal demographic attributes within pre-trained models [74,126], laying the groundwork for further simulations.Additionally, these simulations are used to reflect opinion surveys [93] or evaluate preferences and biases [99,127] of particular groups.With the ability to scale synthetic dialogue [63,98,128] involving specific personas, demographic simulations can also contribute to societal simulation studies [111].In most cases, demographic simulation is implemented through nonparametric prompting.Many researchers in this field focus on designing tasks, such as questionnaires or social experiments [75], to fully tap into the simulating potential of LLMs.</p>
<p>Characters</p>
<p>Characters are distinct individuals who differ from one another.They may be ordinary platform users, well-known public figures, or fictional characters from novels.Researchers favor these characters because they enhance the expertise of LLMs in specific domains and challenge the learning capabilities of these models.From Haruhi and Li Yunlong [59] to Beethoven [66], individual simulations select their protagonists from both real and virtual worlds.</p>
<p>Real Characters Real characters, typically famous figures, are associated with high-quality data from platforms like Wikipedia and social media, making it easier to establish objective profiles and evaluate simulations.Many LLMs focus on historical figures, celebrities across various periods and backgrounds [10,129], characters from online encyclopedias [64], and popular livestreamers on Douyin [60].Since LLMs often have prior knowledge of these individuals, creating their profiles is relatively straightforward.Real and simulated characters are also used to test LLM simulation capabilities, such as in philosopher simulations [56].</p>
<p>Virtual Characters Virtual characters are fictional roles created in novels, movies, and video games.Advancements in virtual character simulation can significantly benefit entertainment sectors like the gaming industry and theme parks.Many researchers have drawn inspiration from famous fictional characters, such as Harry Potter [55], Sun Wukong [62], and Tong Xiangyu [130].Additionally, some experiments design virtual characters [119] with specific attributes or objectives.However, despite the attention virtual character simulation attracts, developing virtual individual LLMs presents challenges, particularly in ensuring the quality and reliability of their datasets.Most simulations of virtual characters are designed for interactive conversations, enhancing user experience in various entertaining scenarios.</p>
<p>Evaluation</p>
<p>To measure the performance of individual simulations, provide insights into their feasibility, and guide improvements to simulation architectures, researchers have developed diverse evaluation standards and methods, ranging from simple to complex approaches.These methods can be categorized into static evaluation and interactive evaluation.</p>
<p>Static Evaluation</p>
<p>Static evaluation refers to the dialogue-based assessment of LLMs by directly inducing their generation and measuring their quality.It can be categorized into subjective evaluation, which involves assessments by both LLMs and human evaluators, and objective evaluation, which utilizes mathematical tools for analysis.</p>
<p>Evaluation</p>
<p>Sub-Task System Automatic Human</p>
<p>Level Strategy</p>
<p>Task LLM Subjective Evaluation Subjective evaluation refers to assessments conducted by humans or LLMs based on subjective standards.It often involves leveraging conversations with varying forms and contexts.Interview techniques are widely adopted [28,61] because they can effectively prompt LLMs to generate expected responses.Other approaches, such as utterance imitation [77], are also favored in some research.</p>
<p>System Scenario</p>
<p>Dialog-Driven Task-Driven
Evaluate Integrate Role Environment Coordinator Integrator Planner Communicator Worker Participants Directors Configuration State Tool History Organization Structure Mode Communication Format Style
Once dialogues are generated, some studies utilize advanced LLMs to evaluate the output on a given scale [61,65,130], considering performance dimensions.These dimensions range from psychology-based metrics, such as the Big Five Personality Traits (BFI) and Myers-Briggs Type Indicator (MBTI), to language-based factors like grammar and tone.Human annotators are often involved in experiments to provide human reference points [57,84,131].</p>
<p>Objective Evaluation Objective evaluation refers to assessments based on objective indicators, utilizing mathematical and statistical tools.It takes advantage of mathematical tools to grade the generation of simulating LLMs.Examination commonly involves option choosing(or questionnaire) [72], ranking [60] and question answering [102].Accuracy [91,106], F1 score, recall [132,133] are used in option choosing and ranking.In the examination of generation(question answering), text sequence related tools such as perplexity [58,118,134], ROUGE-L [55, 74,106] and BLUE [60,74,132,134] are broadly used in the evaluation, especially those with a reference version [55].Objective Examination is a more credible method of evaluating the performance of LLMs in individual simulation.However, it is highly restricted, and occasionally, specific objective tools must be developed to facilitate the evaluation of simulation in given dimensions.</p>
<p>Interactive Evaluation</p>
<p>Interactive evaluation refers to a circumstance-based assessment that creates a detailed interactive environment to measure the ability of individual simulations in complex scenarios.It is commonly applied in areas such as game performance [119,121], task completion [112,135,136], and nuanced role-playing [88,104].Three key features of interactive evaluation are the carefully designed environment, realtime interactive external responses, and multi-stage assessments.Information about the crafted environment has been introduced in 3.1.4.Real-time interactive external responses refer to the feedback from the external environment in reaction to the outputs of simulating LLMs.Agent-environment interactions construct multiple dialogues between the LLMs and the environment.These interactions help reveal the LLMs' capabilities in complex contexts, leading to more dynamic simulations.Single-aspect measurements are insufficient for interactive evaluation, so many studies adopt evaluated objectives that range from specific actions to hybrid actions [110], or from single-turn interactions to multi-turn dialogues [10].Other studies assess generation quality, focusing on aspects such as accuracy relative to ground truth, nuanced simulations like tone imitation [28,107], and self-reporting consistency [137].In interactive evaluation, researchers prioritize not only accuracy but also the degree to which the simulation resembles real-world scenarios.</p>
<p>In the real world, individuals do not function in isolation.They frequently engage in collaborative efforts to complete tasks within specific scenarios.This raises a crucial question: can LLM-based agents cooperate like humans or even surpass human performance in achieving collective intelligence?To answer this question, researchers simulate the interactions and collaborations of multiple individuals across various scenarios [16,17,147], ranging from everyday conversations to complex professional tasks, to enhance collective intelligence and problem-solving capabilities.A scenario simulation typically starts with designing a multi-agent system that includes constructing the scenario environment, modeling agent roles, and establishing organizational structures and communication protocols to manage interactions among agents.</p>
<p>In this section, we begin discussing the system composition of a scenario simulation with four key aspects in 4.1.Following this, we summarize several scenarios that have recently attracted the attention of researchers in 4.2.Finally, we review the methods and metrics commonly used for evaluating scenario simulations in 4.3.The overall framework is presented in Figure 3 and representative works are summarized in Table 2.</p>
<p>System</p>
<p>The diversity of scenarios presents challenges in proposing a unified system applicable to scenarios.Most of the current systems can be summarized as "agents organized to play roles in dedicated environments through constrained communications".Based on this general description, we identify four key concepts in scenario simulations: environment, role, organization and communication.</p>
<p>Environment</p>
<p>The environment in scenario simulation defines the specific contexts in which agents operate and interact with each other.Just as humans gather information from their surroundings, agents depend on the environment to receive input from various sources.These signals guide the behaviors and strategies of agents within the system.Thus, a comprehensive understanding of the environment paves the way for agents' decision-making and task continuity.We analyze the environment of existing work by focusing on four key aspects: configuration, state, history and tools.Configuration The environment configuration provides basic information, especially essential elements necessary for the tasks and goals in the scenario.The system will initialize agents accordingly so that they interact with clear objectives.More specifically, an environment configuration may include events in the environment and profiles of agents.</p>
<p>Events are represented as a primary focus that needs to be resolved, such as the specific cases brought before the court [20,181,185,186], and the topics that serve as the basis for multi-agent debates.[29,[144][145][146][147][148][149].</p>
<p>Profile refers to personalized information relevant to the agents specific to the scenario.Different from the basic attributes described in individual simulation, this module encompasses various aspects of the agents' identities, including their interests, goals, and roles [17,142,172].Agents can also be configured to have access to external resources, such as related research papers [171], predefined strategies [142] or disease information [18].</p>
<p>State Environment states encompass the information provided by the environment during scenario execution (configurations are fixed at the beginning instead).They directly influence the agents' decision-making and behavior.According to how agents receive them, states can be further divided into observation and feedback.</p>
<p>Observation involves changes in the environment and the current state of surrounding entities.For example, properties and spatial positions [164,189,194,197] of other agents are provided to agents to inform real-time decision-making.Moreover, continuously updating agents' physical states are utilized to establish real-time spatial relationships with their environment and neighboring agents [161,194,197,198].</p>
<p>Feedback consists of responses received by agents after they perform actions, which guide future strategy adjustments.Some studies [162,164,190] describe how agents' cognitive states and strategies are modified based on feedback after each interaction, allowing them to simulate human-like adaptability.Meanwhile, feedback on market events or decisions made by others [162,182] and execution results from external tools [17,147,177] are provided, to facilitate strategy adjustment and guide future actions.</p>
<p>History As the scenario runs, past states and interactions accumulate into a series of history records.Agents can leverage them to adapt to new situations and refine strategies, ensuring more coherent and effective task performance in dynamic environments.We summarize four widely used methods to process and utilize the history, including direct integration, refinement, summarization and memory mechanisms.</p>
<p>Direct integration appends the history to the current input without modification.Agents may retain task continuity by incorporating past dialogue directly into the current session [29,145,147,166].Excessive content is truncated to fit token limits while preserving key historical information [194,196].</p>
<p>Refinement iteratively updates and enhances responses based on the history.Ma et al. [149] uses a subgraphfocusing mechanism to refine answers, allowing agents to optimize outcomes after each reasoning step.Similarly, Weiss et al. [183] and D'Arcy et al. [30] iteratively improves initial answers to converge to more accurate results.</p>
<p>Summarization distills essential insights from the history.This can be achieved by synthesizing core actions from multiple plans to establish a reference for diverse scenarios [161], summarizing reports from multiple agents to consolidate findings [168], and sharing key solutions subtasks [177] to avoid lengthy dialogue histories.</p>
<p>Memory mechanisms process the history through agents' memory modules.This dynamic approach enables agents to preserve relevant information both within and across sessions [26,48,173,180,182,195,199,200].In addition, Hong et al. [17] proposed shared message pools to further enhance communication efficiency, where agents exchange structured messages directly and retrieve information in a personalized  [191]    static,multi UNL RoCo [192]    static,single UNL AgentVerse [193]      dynamic,multi UNL Scalable [194]     dynamic,single UNL AutoAgents [195]     dynamic,single UNL OpenAgents [196]     dynamic,single SL TWOSOME [197]   static,single -ReAd [198]     dynamic,single UNL MACNET [48]   dynamic,single UNL manner.
  static,single UNL SimuCourt [20]     static,multi UNL,SL MATHVC [184]    static,multi UNL baker et al.[185]   static,multi UNL LawLuo [186]    dynamic,multi UNL MAIC [187]     dynamic,multi UNL CAMEL [188]    static,single UNL SwiftSage [189]    static,single UNL Multi-Agent Collaboration [190]     dynamic,single UNL CoELA
Tools External tools offer specialized functionalities related to scenario simulation tasks, enabling more accurate and precise outcomes.The spectrum of tools utilized in scenario simulation encompasses a wide range, from programming languages such as Python and SQL to APIs facilitating external interactions.Generally, Python is mainly employed to execute and verify programmes [17,147,177].SQL [174] and knowledge graphs query tools [149,171] have been harnessed to retrieve external structured data.In certain scenarios, task-related tools such as calculators, predefined tools, and APIs [195,196] are also utilized to provide intermediate results, simplifying the processing workflow of agents.</p>
<p>Role</p>
<p>In scenario simulations, we assign agents distinct roles based on their tasks and functionalities.As demonstrated in Figure 3, there are two groups of roles in a typical setting: participants carry out the tasks within the scenario, and directors manage the task execution processes while providing necessary assistance.Each role has its own responsibility that emphasizes different aspects of the system's operations.They collaborate to achieve the system's overall goals.</p>
<p>Participants Participants are the key members that actively engaged in task execution and discussion.Their organization and communication are the core of task completion in scenario simulations.Participants can be further classified into communicators and workers according to their tasks.</p>
<p>Communicators primarily focus on communication, such as information exchange, feedback, and task guidance.Specifically, this kind of agents can process information for certain disciplines and research applications [175,181] and advocate diverse viewpoints [49,144], claims [145] and underlying needs [50,139].</p>
<p>Workers are directly involved in task execution and operations, demonstrating specialized skills and efficiency.This typically includes the common professional roles present in each scenario, such as coder and tester in software development [176], buyer and seller in negotiations [143], doctors and medical professional agents in healthcare domain [18,166], and receptionist, lawyer, and secretary in the legal contexts [186].</p>
<p>Directors While participants execute most of the tasks, directors can provide essential support in crucial aspects such as planning procedures, coordinating communication, and integrating results.We name them Planners, Coordinators and Integrators respectively.</p>
<p>Planners play a vital role in task definition and strategic formulation, facilitating effective inter-agent collaboration through tasks such as defining objectives, analyzing user requirements, and optimizing execution plans.Task-specific agents [188], central planners [193], analysts [176] and decomposer [161] are responsible for breaking down requirements and dividing overarching objectives into specific subgoals.Product managers [17] contribute by creating detailed product requirements documents.Other planners can also refine execution plans according to task requirements [194], optimize the process by maximizing the advantage function [164] and develop plans based on user inquiries [174].</p>
<p>Coordinators are responsible for managing and coordinating the collaboration between agents to ensure effective task execution, monitor progress, and facilitate cooperation.The project managers [17,167] in software development oversee task distribution and project progress, ensuring efficient collaboration among team members throughout the development cycle.Judge assistant agents [20] aids in organizing information during court proceedings, and the main contact agents [50] manage intercultural conversations.Additionally, the secretary agents [170] manage interactions among civilization agents.Meanwhile, coordinators also provide feedback to guide better interactions.Critic agents [143] evaluate negotiation strategies and guide agents through iterative learning processes.Judge agents [144,145,201] serve as an authoritative evaluator, assessing arguments and performances during debates.</p>
<p>Integrators encompass various decision-making and summarization functions critical for guiding the system's trajectory.Deciders [175] autonomously evaluate contributions from the researcher to make informed judgments on the dialogue's outcome.Summarizer agents [146] enhance communication clarity by providing concise summaries of discussions after each iteration, effectively integrating key points into the ongoing dialogue.In medical scenarios, medical report assistants [168] compile analyses into a cohesive document that supports collaborative expert discussions, while the medical decision maker ensures that final decisions reflect the collective expertise of the specialists involved.Additionally, the chief physician [19] evaluates diagnostic performance based on accuracy and effectiveness, reinforcing the system's overall reliability.In legal contexts, the judge [20] oversees judicial processes, making critical decisions grounded in legal arguments and assessing the evidence presented.</p>
<p>Organization</p>
<p>Effective task execution necessitates careful coordination and scheduling of the interactions between individual agents.The organizational structures establish how each agent collaborates with others to achieve a goal.Typically, we can depict an organization schema by its mode and structure.</p>
<p>Mode The organizational structure determines whether the relationships among agents remain stable or evolve dynamically throughout the simulation process.In terms of how to organize agents, there are mainly two modes in existing research, i.e., static and dynamic mode.</p>
<p>Static mode refers to the organizational structure predefined based on the nature of the tasks.Agents communicate and work in an orderly manner according to these static structures.The static mode can be further divided into singlestage and multi-stage setups.In the single-stage setup, agents follow a fixed structure in multiple rounds of communication, such as structured debates [143,146,175,188], skill training [140,141] and integrating ideas [49,181].In the multi-stage setup, tasks are divided into distinct stages, and the organization may change with stages.This can be found in the design, coding, and testing stages in software development scenarios following the waterfall model or standard-ized operating procedures [17,177], and multi-stage process in judicial scenarios [20,185] and problem-solving processes [149,161,191].</p>
<p>Dynamic mode explores more open and adaptive organizational structures, often relying on dynamic and heuristic communication.This also includes both single-stage and multi-stage setups.The single-stage setup emphasizes agent collaboration and adaptability in a single stage.The agents can be flexibly created and recruited [149,193,195,196,202], coordinated through liaison agents [50,170], and self-organized [164].The multi-stage setup mainly features dynamic discussions among agents.Agents can be involved across multiple stages, but they can communicate autonomously based on the current state [167,168,176,186,187].</p>
<p>Structure The organization structure, meanwhile, reflects how agents are connected with each other.Typically, an organization can be layered, centralized or decentralized.Layered structures adopt a hierarchical framework, with agents assigned to distinct levels.Interactions are predominantly confined to agents within the same level or occur between adjacent layers, thereby facilitating a controlled and organized flow of information [49,177,181].Centralized structures often involve a high-level role (e.g., coordinator) that serves as the core of the organization, overseeing communication and functioning as the central hub for interactions among other agents [19,50,170].Decentralized structures, in contrast, is more flattened, where agents can engage in peer-to-peer interactions as needed [145,146,149].</p>
<p>Communication</p>
<p>The communication between agents controls the transmission of information.To better understand the internal mechanism of communication, we dissect communication from its format and style.</p>
<p>Format From the perspective of information format, there exist two common communication protocols: unstructured natural language and structured language.</p>
<p>Unstructured natural language is most commonly used in multi-agent communication, enabling flexible and immediate exchanges through free-form, conversational language that mirrors human dialogue [29,140,141,143,144,167,175,188].Communication based on natural language is diverse and flexible, but it can also suffer from issues such as ambiguity and redundancy.</p>
<p>Structured language, such as code and JSON documents, is another protocol that may alleviate the issues from natural language.In software development, agents transit information between phases through code [17,177].In the medical domain, structured summaries of reports are utilized to gain key insights [168].In addition to predefined formats, agents can also autonomously choose the appropriate format during interactions to improve efficiency [51,203].Recently, more complex communication protocols using more than one language have been designed to improve communication [53].</p>
<p>Style Communication, by nature, can be cooperative or competitive regarding its style.In cooperative communication, agents share a common objective, aiming to optimize collective outcomes, like software development [17,176,177], medical diagnosis [19,168], and case handling [181,186].In contrast, agents in competitive communication typically hold differing viewpoints and positions, each striving to achieve individual objectives.Such scenarios are commonly found in settings like games [150,151,159] and debates [143][144][145], where agents maintain opposing stances and seek to outmaneuver each other.</p>
<p>Scenario</p>
<p>Using the collective capabilities of agents with specialized expertise, scenario simulations have been applied to various domains.Here we divide different scenarios into two groups: dialog-driven ones that cover social interaction and questionanswering, and task-driven ones that focus on specialized tasks.</p>
<p>Dialog-Driven Scenario</p>
<p>Dialog-driven scenarios encompass scenarios in people's daily lives where the dialog itself is centered, such as those for social or entertainment purposes.These scenarios share a common emphasis on tackling general goals that are not related to any specific task or domain.We identify three primary types of dialog-driven scenarios: social interaction, question-answering, and game scenarios.</p>
<p>Social Interaction Some works focus on task completion in simple social interaction scenarios, typically involving social tasks between two or a few agents, such as persuasion or comforting a partner.Zhou et al. [138] discusses the social intelligence of agents in social scenarios, revealing significant performance differences among models across different dimensions.The exploration in social intelligence is further extended to objective action-level evaluation [204] and diverse scenarios and others' information reasoning [205].Furthermore, some works propose interactive learning methods [140,206,207] to help learn social skills.</p>
<p>Question Answering Another mainstream scenario is the question answering, emphasizing collaborative processes, strategic reasoning, and integration to enhance model performance.On the one hand, some studies focus on improving reasoning through debate.FORD [144] facilitates a three-stage commonsense reasoning debate, demonstrating that LLMs can reach consensus even amidst inconsistencies.MAD [29], involves agents debating under a judge's supervision, addressing the Degeneration-of-Thought problem.In addition, a "society of minds" approach [29] is presented to guide multiple debate rounds, improving mathematical reasoning and factual accuracy while reducing hallucinations.On the other hand, some works focus on optimizing strategies in strategic reasoning and negotiation.OG-Narrator [148] is proposed to improve negotiation strategies, increasing the Buyers' deal success rates.Ma et al. [149] utilize a subgraphfocusing mechanism and a multi-role debate team to improve reasoning accuracy and reliability, outperforming existing methods.</p>
<p>Game Games provide a unique platform for exploring scenario simulation, evolving from basic game reproduction to complex social dynamics.Early studies, such as [150,151],</p>
<p>introduce Werewolf and Avalon to examine LLM performance in communication games, specifically investigating how LLMs handle aspects like trust and leadership.Building on these complex interactions, reinforcement learning frameworks in [155,158] allow agents to adapt their strategies, achieving near-human-level decision-making.To explore deeper social phenomena, [158,160] expand on game dynamics by incorporating tools that enhance memory, reasoning, and adaptability.Additionally, [159] examines the role of opinion leadership, while [156,157,208] tackle ad hoc teamwork, where agents adapt and collaborate without predefined protocols, revealing both the challenges and potential of LLM agents in team-based collaboration.</p>
<p>Task-Driven Scenario</p>
<p>In task-driven scenarios, agents role-play personas with specific functions for a certain task or task-set.Most of these scenarios fall into one or more specific domains related to the tasks.Here, agents are increasingly leveraged to solve complex, domain-specific problems by automating tasks and improving decision-making processes.</p>
<p>Foundational and Applied Science Science domains, such as medicine, mathematics, data science, and content analysis, have been popular experimental fields for scenario simulation.In the medical domain, medical reasoning and automating diagnostic processes have been refined through innovative methodologies such as chain-of-thought prompting and multi-agent collaboration [18,166,168,209].Zheng et al. [167] integrates ChatGPT with Bayesian optimization techniques to enhance research workflows in chemistry laboratories, demonstrating significant improvements in efficiency and productivity.Hassan et al. [165] introduce a conversational framework that enables seamless interaction with machine learning models, specifically for tasks like data visualization and predictive analytics.These studies demonstrate the potential of LLM-based agents to transform traditional research patterns.</p>
<p>Software Development Recent research has increasingly focused on harnessing agents to address complex challenges in software development and life-cycle management.Early works focus on designing frameworks for collaborative code generation.Dong et al. [176] presents a self-collaboration framework where LLM agents function as distinct "experts," each managing specific subtasks to facilitate autonomous collaborative code generation.Building on this, ChatDev [177], a chat-powered framework utilizes unified language-based communication among agents to effectively address design, coding, and testing phases.Meanwhile, Hong et al. [17] enhances LLM collaborations by encoding Standardized Operating Procedures into prompts, enabling agents to verify results and produce coherent solutions through an assembly line approach.Afterward, some works focus on enabling agents to learn from past experiences and refine their processes over time [178,180].Further efforts focus on autonomous issue resolution and program understanding [179].These studies show the potential of multi-agent collaboration in software engineering, offering robust tools for automatic development and management.</p>
<p>Other Industries In the realm of broad social science, several studies leverage multi-agent systems to enhance decision-making processes across diverse fields, such as journalism [210], judiciary, economics, and education.In the judicial field, legal consultations have been improved through LawLuo [186], which simulates collaborative discussions.Hamilton et al. [181] and He et al. [20] design multi-agent systems to simulate U.S. Supreme Court decisions and court trials through detailed steps such as debate, resource retrieval, and decision refinement, complemented by additional benchmarks that enhance legal article generation.In the economic sector, Li et al. [182] propose a multi-agent framework with layered memory to improve LLM performance in stock trading.Additionally, Weiss et al. [183] address the buyer's inspection paradox in information markets by simulating a marketplace where intelligent agents use LLMs to navigate information access and biases, exploring the impact of pricing and budgets on outcomes.In the education domain, MAIC [187], a system simulating AI-enhanced classrooms has contributed to the development of a comprehensive AI-driven online education platform.Yue et al. [184] presents MATHVC, an LLM-driven virtual classroom designed to simulate interactions among students, thereby fostering the development of mathematical skills.</p>
<p>Evaluation</p>
<p>For scenario simulations, the evaluation focuses on how well the tasks of the scenarios are solved.Based on the scope of the evaluation, it can be categorized into task evaluation, sub-task evaluation and system evaluation, each employing various automatic, LLM-based, and human evaluation methods to assess performance.</p>
<p>Task Evaluation Task Evaluation measures the overall performance of tasks assigned to the scenario.The evaluation can carried out in automatic ways or by LLMs or humans.In terms of automatic evaluation, predefined metrics and mathematical tools are used to objectively assess the task outcomes, such as accuracy [144,181], pass@k [188] for coding tasks, success rate, and coverage for exploration [161], and deal price for negotiation [143].These methods are efficient and scalable but may overlook complex behaviors.Thus, LLMs [49] and human experts [145,188] have been applied to provide more nuanced evaluation for qualitative tasks and compare solutions based on specific criteria.</p>
<p>Sub-Task Evaluation Sub-task Evaluation assesses the completion of sub-tasks within a scenario simulation and their impact on overall task performance.It serves as a process evaluation for the execution of complex tasks.The automatic evaluation uses metrics like transport rate, average steps, task success rate, re-plan attempts, and efficiency improvement to assess sub-task performance and strategy efficiency [191,192].Completeness, executability, and consistency metrics are often applied in software generation tasks [177,178].LLM-based evaluation focuses on pairwise comparisons or win rate judgments, capturing qualitative aspects of sub-task performance [177].Meanwhile, human evaluation relies on participants to provide subjective assessments on metrics such as executability, revision costs, or com-</p>
<p>Scenario Social Construction Element General Economic Sociology and Politics</p>
<p>Support</p>
<p>Evaluation</p>
<p>Micro System ment quality, offering practical insights into sub-task performance [17,30].System Evaluation System Evaluation aims to capture the effectiveness and efficiency of the system in a scenario simulation as a whole.Automatic evaluation relies on metrics such as token consumption, task success rate, and human-likeness scores to measure the efficiency and realism of agents [197].Additional metrics like accuracy, precision, recall, and F1 scores are used to assess system accuracy and consistency in diagnostic or predictive tasks [19].LLM-based evaluation often involves GPT-4 to assess qualitative aspects, such as human-likeness or diagnostic report quality [18,197].</p>
<p>Level</p>
<p>Human evaluation typically involves subjective assessments, such as rating instructional content for tone, clarity, and supportiveness on a Likert scale [187], often used to complement automatic methods and capture human perspectives on system outputs.</p>
<p>Society Simulation</p>
<p>While scenarios discuss multi-agent interactions in relatively focused and small-scale contexts and provide solutions within specific domains, society is more complex than a simple scenario.Its complexity lies in many aspects, such as the diversity of its components, the variety of structures, and nonlinear effects [259].Considering this, a series of studies focus on society simulation.In terms of research topic, society simulation generally hopes to investigate societal and macrolevel results.In terms of research purpose, society simulation does not aim to solve a task or problem, instead, it focuses on revealing and explaining emergent behaviors and the outcomes of interactions among numerous agents.Society simulations have been a vital tool for theoretical validation and predicting social dynamics.</p>
<p>In this section, we summarize the components of social construction to capture the key features reflected in society simulations in 5.1.Then, we present the different categories of scenarios in society simulation in 5.2.After that, we introduce the evaluation of society simulation in 5.3.The overall framework is illustrated in Figure 4 and representative works are summarized in Table 3.</p>
<p>Social Construction Elements</p>
<p>Considering the complexity of society, a major challenge in society simulation is bridging the gap between individual and societal scales.Some core elements serve as the foundation for modeling social systems.We outline four key dimensions that underpin societal structures and dynamics: composition, network, social influence, and outcomes.</p>
<p>Composition</p>
<p>Society is composed of massive and diverse individuals.This diversity, also referred to as heterogeneity [259] in social science, encompasses a wide range of beliefs, preferences, behaviors, normative values, and positions within social structures.Modeling this diversity is essential for capturing the varied behavioral patterns and complex social dynamics that emerge from individual differences within a social system.</p>
<p>Individual Composition To model a diverse society, the composition of individuals in society needs to be determined.</p>
<p>Scenario</p>
<p>Field</p>
<p>Paper # Agents Construction Element Composition Network Social Influence Outcome</p>
<p>General Economic</p>
<p>Game Theory and Strategic Interactions</p>
<p>Agent-trust [211] (0, 10]    LELMA [212] (0, 10]   Economics Arena [213] (0, 10]   Fontana et al. [214] (0, 10]   SABM [215] (0, 10]     Noh and Chang.[216] (0, 10]    Mozikov et al. [217] (0, 10]   Wu et al. [218] (10, 100]    CompeteAI [219] (10, 100]     WarAgent [47] (10, 100]    </p>
<p>Economic Contexts</p>
<p>Horton [220] (10, 100]   EconAgent [27] (10, 100]   SRAP-Agent [221] (10, 100]     Ghaffarzadegan et al. [222] (10, 100]    EC [223] (10, 100]     Williams et al. [224] (100, )
    AgentTorch [225] (100, )   </p>
<p>Sociology and Political Science</p>
<p>Public Opinion Survey</p>
<p>Argyle et al. [12] (100, )   Lee et al. [226] (100, )   Chaudhary and Chaudhary [13] (100, )   ElectionSim [227] (100, )   GABSS [228] (100, )     Park et al. [229] (100, )   Sun et al. [96] (100, )  </p>
<p>Individual and Organizational Behavior Observation</p>
<p>Aher et al. [230] (0, 10]   Zhang et al. [152] (0, 10]   Lyfe Agents [231] (0, 10]     CRSEC [232] (0, 10]     Chuang et al. [24] (0, 10]     ChoiceMates [233] (0, 10]     Jarrett et al. [234] (0, 10]   AgentReview [235] (0, 10]    Generative Agents [32] (10, 100]     AGA [236] (10, 100]     MineLand [237] (10, 100]     Chuang et al. [31] (10, 100]     CareerAgent [238] (10, 100]     Suzuki and Arita [239] (10, 100]    Chuang et al. [240] (100, )   Li et al. [241] (100, )    MATRIX [242] (100, )  </p>
<p>Online Platform Social Platforms</p>
<p>Cai et al. [243] (0, 10]   FPS [26] (10, 100]     FUSE [244] (10, 100]     Wang et al. [245] (10, 100]     Concordia [246] (10, 100]     Social Simulacra [247] (100, )
    S 3 [248] (100, )     Trnberg et al. [249] (100, )     Y Social [250] (100, )     TIS [251] (100, )     HiSim [25] (100, )     OASIS [33] (100, )     MindEcho [252]
(100, )   BASES [253] (100, ) </p>
<p>Recommendation Environments</p>
<p>InteRecAgent [254] (0, 10]  Rec4Agentverse [255] (0, 10]   RecAgent [256] (10, 100]     Agent4Rec [257] (100, )     AgentCF [258] (100, )     There are three main approaches to determining the composition of individuals in a system simulating a microcosm of society.Some works rely on virtual individual synthesis, often not focused on alignment with the real world, aiming to ensure that the system includes users with a variety of attributes, typically by generating virtual individuals with the help of LLMs or humans [31,260].Other works utilize existing datasets, such as MovieLens-1M [256,257], to define user composition within a simulated recommendation platform.Agents are initialized on the basis of the user information within these datasets, reflecting the distribution of users in that context.Recently, an increasing number of studies have focused on real-world distribution replication, such as the composition of users on social platforms [33] or the distribution of voters in surveys [227].For smallscale individual sets, individual data are typically collected manually [229,233].In cases where large-scale populations are required or obtaining real data is difficult, individuals may be sampled based on real-world macro distributions or generated by LLMs to match desired attribute distribution [12,226,227].</p>
<p>Trade-off between Simulation Precision and Scale When simulating individuals in society simulations, many studies adopt detailed role modeling to enhance the authenticity of agent behavior.Beyond common demographic attributes, this may include factors such as an individual's past statements and interaction history [32,214,219,256,257].However, as the number of individuals increases, such fine-grained modeling becomes expensive.Consequently, a trade-off often arises between the precision of individual modeling and the scale of the simulation.In large-scale simulations, to reduce computational costs, the details of each agent are typically simplified, by retaining only the most essential and common characteristics [224,225] or compressing auxiliary dialogue information into shared memory [236].Special Modeling on Outliers As previously mentioned, the composition of individuals in society is diverse.However, not all individuals play an equally significant role.Some individuals, whose attributes or behaviors significantly deviate from the majority, are referred to as outliers [259].Compared to average individuals, outliers often introduce variability and unpredictability to society.Examples include celebrities and opinion leaders [251,252], who frequently hold prominent positions within social structures and amplify their influence.</p>
<p>In situations with limited resources, some studies [25] prioritize detailed modeling of these core content producers, while simplifying the modeling for the majority.Meanwhile, intervention policies based on simulation results often focus on these key nodes in networks [261], aiming to influence the overall system's behavior by blocking or interfering with them.</p>
<p>Network</p>
<p>Social interactions are often conducted through social networks, which can be described using graph structures where nodes represent individuals and edges represent their relations.The network determines the direction of information and influence dissemination.In social science, it has been observed that homophily of individuals can increase the likeli-hood of communication.Highly similar individuals are more likely to establish connections compared to those with greater differences [262,263].This principle also informs the construction of networks in society simulations.The methods for constructing social networks vary across different scenarios.Here, we divide them into offline networks and online networks.</p>
<p>Offline Network An offline network represents connections formed through in-person interactions, such as face-toface communication or the spread of opinions and diseases in physical settings.On the one hand, some studies aim to simulate interactions in virtual worlds, thus determining the connections between agents in a random or predefined manner [32,232,236].On the other hand, when some studies aim to simulate the spread of a disease or event information in the real world, considering the difficulty of obtaining real data, they often estimate the social relations using external algorithms or agents themselves [224,228].However, in studies with a large scale of agents, the network relationships between individuals are sometimes ignored, and individuals are treated as independent [227].Alternatively, some studies provide rough information, such as community statistics, in place of specific details about the agents' neighbors [225].</p>
<p>Online Network An online network is a digital structure where individuals or entities interact through platforms, such as online social platforms and recommendation platforms, forming connections based on activities, relationships, or shared interests.At the beginning, some studies randomly initialize the social relations for users existing datasets [256] or synthesized users [26], while other efforts have focused on crawling authentic social relationships from social media platforms like Weibo [248] and Twitter [25].However, as the scale of individuals increase, it may be challenging to obtain all of their authentic relationships.Therefore, some studies construct networks using a small portion of real relationship data combined with a large amount of synthetic relationship data [33], or connect similar users based on the assumption of homophily [242].</p>
<p>Social Influence</p>
<p>Social influence refers to the influence agents have on others and the influence they receive from others during interactions.This is also known as embeddedness in social sciences [259], which suggests that individuals behavior and decisions are influenced by their environment.When conducting society simulations, it is necessary to consider the modeling of such social influence.</p>
<p>Influence Received by the Influencee The same information may produce different effects when received by individuals with different traits.Currently, most studies have modeled how the influence received by the recipient varies based on their profile [26,33,248].This can be easily achieved by integrating the individual's profile, memory and the information received from others into the same context.Building this, a few works further induce additional mechanisms such as cognitive bias [24] and reflection on norms [232] to enhance agents' understanding and perception of the received messages.</p>
<p>Influence Exerted by the Influencer The same message conveyed by different individuals can result in varying social impacts.The Pareto distribution and the Matthew Effect [25,256] indicate that information, influence, or attention tends to concentrate on a small group of individuals who are already dominant in the community.Therefore, when simulating social interactions, the identity, status, and reputation of the information sender are also crucial.Some studies start with real-world data to conduct detailed modeling of opinion leaders [251,252].Other studies, instead of focusing on the role of the influencer, model the influence exerted by the influencer by incorporating the relation information such as social impression memory [236] and share party affiliation [31].</p>
<p>In addition to the influence exerted by individuals, research has found that as group size increases, the impact of a single influencer may diminish.However, the influence of the group on individuals often drives them to align their behavior with the group, leading to the emergence of the herd effect [33].</p>
<p>Outcomes</p>
<p>Social emergence suggests that the collective behaviors or phenomena arise from individual interactions are not a linear sum of individual actions but rather complex patterns emerge from the interactions [21,259].These interaction outcomes may be measurable macro results, such as voting results and public opinion levels, or they may also be qualitative social phenomena and norms.Next, we will discuss these two types of outcomes separately.</p>
<p>Macro Statistical Results</p>
<p>Macro statistical results are typically the focus of existing studies, as they are closely related to predefined research objectives such as market research, election predictions, and public opinion forecasting.These studies often aim to calculate the sum or average of the choices or opinions of all agents in the system.To get a static opinion distribution, some studies overlook the social interactions and instead directly sum up individual choices to obtain macro outcomes [96,227], simplifying the complexity of social dynamics.Another line of research focuses on the change of indicators by modeling multiple rounds of interactions among the agents over a period of time and then statistically analyzing the results [27,215,218,248,249].</p>
<p>Formation of Social Phenomena and Social Norms</p>
<p>In addition to the quantifiable macro results, some social phenomena and social norms are also important outcomes of social interactions.On the one hand, some studies have identified the bubble effect in recommendation systems [257], echo chambers in social media [25,33,245], Matthew effect in competitive agent interactions [219], and spontaneous cooperation of competing agents [218] by calculating additional metrics or observing the trends of primary indicators.On the other hand, some studies examine social norms as an important byproduct of social interactions.This includes simulating and testing whether community rules can shape desired social norms [247], constructing normative architecture to observe the emergence of social norms [232], studying how social media language evolves in the presence of regulatory constraints [243], and observing changes in social norms in real-world scenarios such as autonomous driving [264].</p>
<p>Scenario</p>
<p>Society simulation has been widely applied to various scenarios related to human society.These scenarios cover different aspects of daily human life, and existing studies can be categorized into three primary areas: general economics, sociology and political science, as well as online platforms.</p>
<p>General Economics</p>
<p>Simulations in general economics analyze decision-making and behaviors related to resource allocation and competition.These studies primarily investigate how agents make decisions influenced by economic incentives, market rules and resource constraints, while also examining how interactions among groups shape broader economic trends.</p>
<p>Game Theory and Strategic Interactions Some research mainly focuses on game theory and strategic interaction.These scenarios typically involve small groups of agents, with a primary focus on the complex interactions between agents.Some works use classic game theory games, such as the Prisoner's Dilemma, to explore agent behavior in game-theoretic scenarios, including trust behavior [211], logic reasoning and decision-making [212], rationality and strategic reasoning ability [213], cooperation tendencies [214] and how emotional states can disrupt rational decision-making [217].</p>
<p>Other studies focus on real-world scenarios other than the games, such as spontaneous cooperation in competitive environments [218], complex market behaviors in firm competition [215], and competition between restaurant and customer agents [219].Overall, the former kind of scenarios simplifies the environment, making it easier to conduct controlled research on agent behavior, while the latter provides more insights for real-world applications.</p>
<p>Economic Contexts</p>
<p>In addition to close studies on game theory and strategic interactions, some studies focus on the use of agents and their interactions within economic environments.Horton [220] examines economic agents driven by LLMs in various experiments to replicate human behavior in economic scenarios.EconAgent [27] introduces agents for macroeconomic simulation, emphasizing the influence of macroeconomic trends.SRAP-Agent [221] proposes a framework for simulating and optimizing scarce resource allocation in economics, specifically in public housing allocation scenarios.Besides, some studies involve broader macroeconomic domains, using agents to simulate and predict the spread of diseases and the change in unemployment rates [224,225].</p>
<p>Sociology and Political Science</p>
<p>Society simulation has been widely used in sociological and political science research.These studies range from smallscale laboratory experiments that validate theories and hypotheses to large-scale social surveys aimed at understanding public choices.The goal is to leverage agents as substitutes for humans in studying human behavior within sociological and political contexts.</p>
<p>Public Opinion Survey A mainstream application of society simulation is public opinion survey, which aims to predict the perspectives of specific groups toward a given sub-ject through simulation and aggregate their opinions to support advanced needs such as election forecasting and public administration.Argyle et al. [12] first propose that LLMs could serve as silicon samples of humans, through several large-scale surveys conducted in the United States.Building on this, some studies have expanded their focus to scenarios of opinion surveys [13,226,240], such as election polls [227] and response to public administration crisis [228], delving deeper into issues like population complexity and algorithmic bias.Recently, agents have demonstrated the potential to replicate participants' responses in individual interviews [229].These studies lay the foundation for new tools to investigate individual and collective behavior.</p>
<p>Individual and Organizational Behavior Observation</p>
<p>Other studies focus on observing individual or organizational behavior in common or specific settings.Some works do not specify a particular scenario but instead observe agents' social interactions and potential phenomena in daily life within a sandbox environment [32,231,232,237].Other studies aim to validate theories or hypotheses in specific scenarios, such as the wisdom of partisan crowds [31], information management [233], organizational behavior management [238], and the evolution of personality traits [239].</p>
<p>Online Platform</p>
<p>Online Platforms are a vital component of society simulation, offering a practical means to study complex social phenomena in digital environments.These platforms, ranging from social media to online communities, allow agents to simulate real-world interactions and study dynamics such as opinion formation, information spread, and collective behaviors.</p>
<p>Social Platforms Online social platforms have long served as an important testing ground for studying the propagation of information and the evolution of opinions.These studies typically recreate environments similar to popular social platforms, such as Twitter, Reddit, and Weibo, with action spaces that include behaviors like sharing, commenting, and liking.By simulating these scenarios, researchers can model the spread of information and track changes in user attitudes following events, covering a wide range of topics such as general news, rumors, and the role of opinion leaders [26,243,244,248,250,251].In such scenarios, the roles and relationships of agents play a critical role in ensuring realistic simulations.Initially, many studies relied on realworld data scraped from platforms to maintain consistency [25,248].However, as the scale of these simulations grew and data acquisition became more challenging, researchers began exploring the use of synthetic data [33].Furthermore, to accommodate the increasing demand for simulating larger numbers of agents, some studies have developed large-scale society simulation platforms [265,266], employing parallel processing and other strategies to enhance simulation efficiency.</p>
<p>Recommendation Environments Another widely studied scenario is the recommendation environment, where these works use agents to simulate user responses in order to validate and improve recommendation algorithms [254,255].A key feature across these studies is the use of agents to em-ulate personalized behaviors such as item selection, preferences, and emotional responses, often integrating user memory and contextual factors [256][257][258].Additionally, some approaches incorporate external knowledge or self-reflection mechanisms, allowing agents to adapt and learn from their interactions over time [267].These studies collectively show how LLMs can bridge the gap between traditional recommender systems and more interactive, human-like behavior simulations, offering new ways to improve recommendation accuracy and better understand user dynamics.</p>
<p>Evaluation</p>
<p>For society simulations, the evaluation primarily focuses on the comparison between the simulation results and real-world data, with assessments centered on micro level, macro level and system level.</p>
<p>Micro-level Evaluation Individual simulation accuracy is key to society simulation.Therefore, micro-level evaluation of society simulation has received widespread attention.Initially, evaluations in non-real-world simulations draw on the Turing test, assessing agent behavior's resemblance to human behavior, often subjectively by humans or LLMs [32,236,268].For specific scenarios, metrics like partisan bias and human likeness index are proposed [31].</p>
<p>When simulations target real-world scenarios with available empirical data, automated metrics like emotion, attitude, behavior consistency, and user taste alignment can be designed for more objective evaluations by comparing simulation content with real-world data [25,248,257].</p>
<p>Macro-level Evaluation Social interactions often lead to collective outcomes, so it is important to evaluate whether macro-level outcomes show patterns and trends that are consistent with the real world.For sociology and online platforms, attention is typically given to whether the scale of propagation, the distribution and trends of collective opinions and traits align with those of the real world.In addition to qualitative methods such as subjective evaluation [248,257], some studies have proposed quantitative metrics, such as fitted parameters, correlation coefficients and change of toxicity of community content to measure this differences objectively [25,26,33,249].Similarly, in economic simulation, the evaluation of simulated economic systems depends on whether they can reproduce the most representative macroeconomic laws [27].</p>
<p>System-level Evaluation System-level evaluation is concerned with assessing the overall performance of a simulation system, irrespective of the specific content being simulated.With the growing number of agents in simulation, the focus of contemporary research has been on system efficiency and associated costs.Efficiency is assessed through various metrics, such as the time it takes to run a simulation, the resources that are utilized during the process, and how well the simulation can scale with an increasing number of agents [33,256,266].These metrics are crucial for understanding how well the system can handle complexity and the demands of larger simulations.On the cost side, evaluations often center on the number of tokens consumed during the simulation or the financial expenditure incurred [236].6 Datasets and Benchmarks</p>
<p>Individual Simulation</p>
<p>We summarize commonly used datasets for scenario simulation in Table 4. Datasets for individual simulation can be classified into two types: description datasets and dialogue datasets.Description datasets include individual-specific information, such as life experiences, relationships, and basic demographic details like career, age, and gender, often sourced from literature summaries or search engines like Baidu and Wikipedia.Dialogue datasets consist of singleturn or multi-turn conversations in specific scenarios, created by extracting relevant plots for targeted characters or gathering utterances from social media.Some datasets are designed specifically for evaluation, combining basic personal information with customized questions or tasks to assess simulation performance.</p>
<p>Scenario Simulation</p>
<p>We summarize commonly used datasets for scenario simulation in Table 5, comprising dialog-driven and task-driven scenarios.The datasets cover a wide range of formats, including QA, multiple-choice, rating, code, and game.We observed that QA and multiple-choice formats dominate the data types, while domain-specific datasets like judicial, game, and media prefer to preserve domain-tailored data type.Based on task complexity, datasets are categorized into three levels: easy, medium, and hard.Additionally, according to the collection methods, datasets are classified as human-annotated, real-world, or synthetic.</p>
<p>Social Simulation</p>
<p>We summarize commonly used datasets or benchmarks for social simulations in Table 6.In social simulations, datasets often consist of two parts: those for initialization of agents and those for evaluation.Data used for agent initialization typically contain profiles and potential relations between agents, to help initialize the simulation settings.In contrast, datasets for evaluation provide the reference data of behaviors of real-world individuals.These datasets are sourced in various ways, such as public surveys, existing datasets like MovieLens and Amazon-Book, and crawling from online platforms like Twitter.</p>
<p>7 Trend of Social Simulations</p>
<p>Trend of Individual Simulation</p>
<p>Evolving from social science, individual simulation powered by LLMs has progressed through three distinct stages, namely coarse simulation, more nuanced simulation, and situation-oriented simulation, which is depicted in Figure 5. Since June 2022, researchers started to focus on coarse simulations, especially for superficial traits like testing the personalities of LLMs and simulating well-known characters [81,137].After August 2023, the trends shifted towards more refined simulations of specific individuals, with studies evaluating the cognitive aspects of simulated models [61,67] and improving their simulation capabilities [65,84].By May 2024, researchers began conducting individual simulations in specific scenarios [70,111], further expanding the complexity and realism of these simulations.</p>
<p>Individual Simulation</p>
<p>More Nuanced Simulation on Specific Characters</p>
<p>Situation-oriented Simulation</p>
<p>Out of one, many [12] Improving Personality Consistency [74] The wall street neophyte [76] Conversational Health Agents [84] Chain of Empathy [89] CultureLLM [94] Faithful Persona-based Conversational Dataset [104] Interactive Agents [100] HIRPF [123] Large Language Models Meet Harry Potter [55] Creating a Large Language Model of a Philosopher [56] LiveChat [60] RoleLLM [28] CharacterLLM [10] InCharacter [61] CharacterGLM [62] Neeko [65] Character is Destiny [66] Evaluating Character Understanding [67] Capturing Minds, Not Just Words [68] MMRole [69] Beyond Dialogue [70] From Role-Play to Drama-Interaction [105] Social Bench [111] Demographic Persona
Charactcer Persona Year</p>
<p>Scenario Simulation</p>
<p>Multi-Stage Scenario Collaborative Scenario</p>
<p>Improving factuality and reasoning [29] ChatLLM [49] ICL-AIF [143] FORD [144] GITM [161] MetaGPT [17] Empirical Study on Werewolf [150] Recon [151] MachineSoM [152] AvalonBench [153] Self-Emotion [141] DoG [149] S-Agents [164] AgentSense [205] DERA [175] Self-collaboration [176] Blind Judgement [181] CAMEL [188] VIDS [165] ChatDev [177] TradingGPT [182] Multi-Agent Collaboration [190] CoELA [191] RoCo [192] AI Hospital [19] MATHVC [184] TWOSOME [197] ReAd [198] AGA [236] Dialog-Driven Scenario Task-Driven Scenario</p>
<p>Year</p>
<p>Figure 6: Illustration of scenario simulation trend, which goes through simple scenario, multi-stage scenario, and collaborative scenario.</p>
<p>Coarse Simulation on Superficial Features</p>
<p>Many individual simulation works born since June 2022, the majority of which initially focus on simulating superficial features implied in human behaviors.A significant portion of the effort was dedicated to collecting and standardizing character-related information to build persona-based datasets [55,56].Additionally, eliciting the underlying demographic personalities of prevailing LLMs posed a challenge in this early stage [81,120].The early trials on coarse individual simulations shed light on LLMs' attributes during simulation, including hallucinations, inherent biases, and stereotypes, which are proven to be crucial for future simulations.</p>
<p>More Nuanced Simulation on Specific Characters</p>
<p>As individual simulation methods advanced, the precision of simulations significantly improved.More nuanced aspects of the individual simulation gained growing attention.Some works implement new functionalities and refine the models' architecture, such as incorporating memory and planning modules [66,84], while others focus on designing specific tasks for training and evaluation, like multi-dimensional interviews [61] and simulation with rich information from scene descriptions and experiential memories [28].</p>
<p>Situation-Oriented Simulation</p>
<p>Situation-oriented individual simulations begin within game environments [119], where LLMs are required to make appropriate decisions based on predefined rules.In more complex environments, simulated individuals are supposed to interact dynamically with their surroundings, responding to real-time environmental feedback [100,111].Beyond traditional simulations like dialogue, situation-oriented simulations expand into areas such as dramatic performances [105],</p>
<p>Mar</p>
<p>Sociology and Politics</p>
<p>Epidemic Modeling [224] Choicemates [233] EconAgent [27] Personality Traits [239] Prisoner's Dilemma [214] Holacracy view [277] Social Simulacra [247] RecAgent [256] S^3 [248] AgentCF [258] Agent4Rec [257] News Feed [249] HiSim [25] FPS [26] Influencer Selection [251] AgentTorch [225] OASIS [33] Generative Agents [57] AgentSims [199] WarAgent [47] Wisdom of Partisan Crowds [31] Public Administration Crisis [228] CRSEC [232] Instruments of Power [13] Beyond Demographics [240] ElectionSim [227] Figure 7: Illustration of society simulation trend, which goes through three stages: constructing preliminary environments, exploring alignment on specific scenarios, and scaling up while moving towards multi-modal.</p>
<p>digital game exploration [109], and 3D task execution [107].</p>
<p>As the complexity of these simulations grows, the demands on the underlying architecture grow as well.</p>
<p>Trend of Scenario Simulation</p>
<p>The development of scenario simulation has progressed through several distinct stages.Starting from January 2023, different researches focused primarily on simple scenarios concerning single objectives and facilitated basic contextual interactions [144,175,181,188].By June 2023, the emphasis changed to multi-stage scenarios, incorporating multi-step tasks that enabled agents to engage in sequential decisionmaking and adaptive responses across varied contexts to achieve the more complex goal [165,182,190,192].By February 2024, research has increasingly focused on multiagent collaborative scenarios, emphasizing agents' capabilities to cooperate and adapt within complex, high-order simulations [149,164,184,236].</p>
<p>Simple Scenario</p>
<p>In the initial phase of scenario simulation, researchers focused on constructing simple scenarios that supported foundational agent interactions.Much of this work concentrated on dialogue-driven decision-making frameworks, which facilitated structured information exchange and agent alignment [49,175,188].Additionally, studies explored the collaborative potentials of agents through multi-agent debate frameworks, employing debate and critical feedback to assess cooperative reasoning and performance enhancement in LLMs [29,143,144].Simultaneously, other studies applied scenario simulations within specific domains-such as law, software development, scientific analysis, and recommendation systems-demonstrating the versatility of task-based simulations in achieving domain-specific objectives [161,176,181].</p>
<p>Multi-Stage Scenario</p>
<p>Different from simple task-oriented scenarios, multi-stage scenarios are no longer limited to mere agent interactions.Instead, they emphasize the fine-grained construction of scenarios.This stage introduces multiple roles and task decomposition as central elements, enabling agents to collaborate not merely on single tasks but through incremental task breakdowns that require coordinated effort [191,192].In software development, [17,177] decomposed the development process into multiple stages like design, coding and testing to enhance the capacity for achieving complex objectives and improving software quality.Additionally, communication games were introduced to investigate human behavior within complex conversational scenarios, adding depth to interaction analysis [150][151][152][153].</p>
<p>Collaborative Scenario</p>
<p>With the growing interest in scenario simulation, research shifted toward collaborative scenarios, emphasizing advanced social dynamics and cooperative strategies in agent interactions.[197,198] introduce reinforcement learning to align LLM with embodied environments.To build efficient scenario simulations, [236] focused on reducing LLM inference costs by modeling social relationships while [164] utilized dynamic "agent trees" in environments like Minecraft, enabling asynchronous task execution for efficient resource gathering.In addition, [19,141] simulated collaborative environments in the real world, reflecting complex social interactions such as medical processes and the development of social skills, with agents handling evolving multistep tasks.</p>
<p>Trend of Society Simulation</p>
<p>Since the concept of social simulation was first introduced by Park et al. [247], numerous notable studies have emerged.</p>
<p>Broadly, the development of this field can be categorized into three phases.Prior to June 2023, researchers concentrated on constructing preliminary environments [32,199,224].By February 2024, the focus shifted toward exploring alignment within specific scenarios, such as persona modeling and targeted environments, marking the first significant surge of publications [27,248,272].Most recently, the trend has moved towards scaling up and incorporating multi-modal approaches.In this phase, large-scale precise modeling has gained recognition, with other modalities such as vision and voice being integrated into simulations [25,158,232,273].</p>
<p>The main characteristics can be summarized as:</p>
<p>Constructing Preliminary Environments</p>
<p>The complexity of society simulation, to a certain extent, stems from the complexity of the environment involved.Society simulation usually involve multiple interacting individuals (such as people, organizations, groups, etc.), which act in a specific environment (such as cities, markets, cyberspace, etc.).Therefore, the pioneer work focuses on how to design a specific environment to support society simulation.[32] built an interactive sandbox environment by extending a LLM to store a complete record of an agent's experience and dynamically synthesizing memory to plan behavior.[224] built an epidemic spread simulation environment that simulates human behavior at the individual level to reproduce the spread of an epidemic in a simulated environment.[199] created an easy-to-use infrastructure that allows researchers to build evaluation tasks by adding agents and buildings, providing a visual and program-based platform for testing LLMs.</p>
<p>Exploring Alignment on Specific Scenarios</p>
<p>With the development of simulation environment technology, society simulation has basically become operational.At this time, to test the credibility of simulation, evaluating the alignment performance of agents with real situations on specific tasks has gradually become an important research direction.[248] use real social network data to measure the accuracy of simulation by evaluating the behavior and decision-making of agents at the individual and group levels in a simulated social network environment.[27] evaluate the decision rationality of LLM agents by simulating macroeconomic activities and comparing the performance of LLM agents with traditional rule-based agents or language agents in generating classic macroeconomic phenomena such as inflation and unemployment.</p>
<p>Scaling Up and towards Multi-Modal</p>
<p>Scaling up Before LLM-based agents became widely adopted for society simulation, researchers predominantly relied on agent-based modeling (ABM) methods, where agents were typically programmed to react based on predefined algorithms.With the advent of LLM providing glimpses of human-like intelligence [274], LLM-based agents entered the spotlight.Given the good performance of LLM-based agents in a series of specific scenarios, researchers began to expand the scale of simulation.[25,232] involve the core elements of large-scale society simulation and study the interaction between agents and the generation of behavioral norms.[158] proposed a proving ground for assessing advanced reasoning capabilities of LLM agents in a large-scale society simulation context.</p>
<p>Multi-Modal With the development of language models, using language agents for society simulation has become a hot topic in research.It incorporates other modal information elements such as vision in life into the simulation through text descriptions.However, with a series of advances in the field of Vision-Language Model(VLM) [36,275,276], researchers began to incorporate VLM-based agents into society simulation research.[273] provide rich multi-modal interaction information and detailed annotations in large-scale scenarios.[237] focus on simulating the perceptual limitations and physical demands of the real world to facilitate more realistic social interactions.</p>
<p>Conclusion</p>
<p>In this paper, we categorize LLM-driven social simulations into three types: individual, scenario, and society simulation, highlighting their progression from modeling individual behaviors to replicating complex social dynamics.By systematically reviewing architectures, methods, and evaluations across these categories, we provide a structured framework for advancing research in this field.This work aims to guide the development of LLM-based simulations and foster interdisciplinary studies to address real-world challenges and support decision-making.</p>
<p>Figure 1 :
1
Figure 1: Illustration of simulations empowered by LLM-driven agents.We categorize the simulations into individual simulation, scenario simulation and society simulation.From left to right, the diversity and scale of individual modeling generally increase.Conversely, from right to left, the granularity of individual modeling becomes more refined.</p>
<p>Figure 2 :
2
Figure 2: Illustration of individual simulation blueprint.An individual agent is typically composed of an architecture with modules involving profile, memory, planning, and action through construction method, prompting or training, to simulate specific objectives like characters or demographics .Individual simulation can be evaluated statically and interactively with different dimensions being observed.</p>
<p>Figure 3 :
3
Figure3: Illustration of scenario simulations.Given a specific scenario, building a multi-agent system involves modeling environment, roles, organization, and communication with detailed modules or mechanisms adjusted to the targeted scenario being supported.After simulating the scenario, the desired output, typically the result of a task or problem, is obtained and evaluated using different levels and strategies.</p>
<p>Figure 4 :
4
Figure4: Illustration of society simulations.To construct society simulations, the corresponding society's construction elements, i.e., composition, network, social influence and outcomes need to be carefully designed.Building on this, various scenarios can be simulated.The performance of individuals and the overall performance of the system are evaluated.</p>
<p>Figure 5 :
5
Figure 5: Illustration of individual simulation trend, which goes through coarse simulation, more nuanced simulation, and situation-oriented simulation.</p>
<p>Table 1 :
1Short-term-ClosedNonparametric
A list of representative works of individual simulation.</p>
<p>Table 2 :
2
A list of representative works of scenario simulation.UNL: unstructured natural language; SL: structured language.</p>
<p>Table 3 :
3
A list of representative works of society simulation.</p>
<p>Table 4 :
4
Summary of commonly used datasets for individual simulation.</p>
<p>Table 5 :
5
Summary of commonly used datasets for scenario simulation.
DomainDatasetsTypeComplexity # caseCollectionUsed byData LinkMiniWob++Web InteractionHard/human[147]LinkSOTOPIAOpen-Ended EnvironmentHard/human[138]LinkWebQuestionsQAEasy5,810human[149]LinkWebQSPQAEasy4,737human[149]LinkCWQQAEasy34,689human[149]LinkGrailQAQAEasy64,331human[149]LinkNatural QuestionsQAEasy323,045human[147]LinkFairEvalQAMedium80human[146]LinkMMLUMultiple-ChoiceHard115,700real world[29, 152, 168, 172, 197]LinkBIG-bench/Hard/human[29, 152, 193]LinkMetaQAQAMedium407,513 real world, human[149]LinkAmazonHistoryPriceProduct InfoHard930real world[148]LinkMATHMath ProblemMedium12,500real world[147]LinkArithmeticMath ExpressionEasy/human[29]LinkCounter-Intuitive ARReasoning ProblemEasy200human[145]LinkDialog-DrivenCommonMT Overcooked-AI AVALONBENCHTranslation Triple Game GameMedium Medium Easy1,200 / /human human human[145] [198] [153]Link Link LinkJubenshaGameMedium1,115real world[156]LinkFanLang-9GameEasy18,800real world[158]LinkWellPlayQAHard1,482human[160]LinkWWQAQAMedium2,053synthetic[159]LinkBiographiesBiographiesEasy524real world[29]LinkALFWorldEmbodied EnvironmentMedium3,827human[147]LinkED datasetConversationalHard24,850human[142]LinkTopical-ChatConversationalMedium10,784human[146]LinkCOPAMultiple-ChoiceEasy500real world[144]LinkNLIMultiple-ChoiceEasy1,507human[144]LinkCSQAMultiple-ChoiceEasy1,221human[144]LinkSocial IQaMultiple-ChoiceEasy1,935human[144]LinkPIQAMultiple-ChoiceEasy1,838human[144, 197]LinkStrategyQAMultiple-ChoiceEasy2,290human[144]Linke-CAREMultiple-ChoiceEasy2,122human[144]LinkWiKiTQQAEasy22,033real world[174]LinkTabFactQAHard118,275 real world, human[174]LinkFeTaQAQAHard10,330 real world, human[174]LinkHumanEval real world[176]LinkSRDDSoftware RequirementMedium1,200synthetic[172, 177, 178, 180]LinkSoftwareDevTask PromptHard70human[17]LinkSWE-benchCodeEasy2,294real world[179]LinkAI SocietyConversationalEasy25,000synthetic[188]LinkSynthPAICommentHard7,823synthetic[48]LinkScienceWorldInteractive EnvironmentHard/human[189]LinkScienceQAMedium60,000synthetic[188]LinkTriviaQAQAEasy650,000real world[195]LinkMT-benchQAMedium80human[195]LinkRoCoBench-TextQAMedium269human[192]LinkPubMedQAQAMedium273,500 human, synthetic[168]LinkTask-DrivenMedQA DDXPlus MedMCQAMultiple-Choice Medical Record Multiple-ChoiceMedium Hard Hard61,097 1,300,000 194,000real world synthetic real world[168, 175] [166] [168]Link Link LinkMVMEMedical RecordMedium506real world[19]LinkARIESReview CommentEasy3,900human, synthetic[30]LinkReviewer2ReviewEasy99,727 human, synthetic[169]LinkGSM8KMath ProblemEasy8,500human[29, 184]LinkMGSMMath ProblemHard2,750human[193]LinkMathQAHard50,000synthetic[152, 188]LinkSimuCourtLegal CasesMedium420real world[20]LinkKINLEDConversationalMedium10,546 human, synthetic[186]LinkSupreme Court DatabaseLegal CasesEasy9,095real world[181]LinkTDW-MATEmbodied EnvironmentMedium/human[191]LinkC-WAHEmbodied EnvironmentMedium/human[191]LinkRoCoBenchEmbodied EnvironmentMedium/human[192]LinkFEDDialogue ResponseMedium4,712human[193]LinkCultureParkConversationalMedium41,000synthetic[50]LinkCommonGen-HardConceptEasy200human[172, 193]LinkARC ChallengeMultiple-ChoiceEasy2,590human[197]LinkHellaSwagMultiple-ChoiceEasy70,000synthetic[197]LinkUCF101Video ClipMedium7,000human[173]LinkHMDB51Video ClipMedium13,320real world[173]Link</p>
<p>Table 6 :
6
Summary of commonly used datasets for society simulation.Init.means the data provides profile to initialize agents, and Eval.means it provides data to validate the simulation effectiveness.
Coarse Simulation onSuperficial FeaturesJun. 2022Aug. 2023Apr. 2024</p>
<p>. 2023 Jun. 2023 Feb. 2024 Constructing Preliminary Environments Society Simulation Exploring Alignment on Specific Scenarios Scaling up and towards Multi-Modal Year General Economics Online Platform</p>
<p>Code Easy 164 real world [17, 172, 176, 193] Link MBPP Code Easy 974 real world [17, 176] Link APPS Code Easy / real world [176] Link Code Conversational Hard 50,000 synthetic [188] Link CoderEval Code Medium 230
The strength of weak ties. Mark S Granovetter, American journal of sociology. 7861973</p>
<p>The social psychology of organizations. Daniel Katz, Robert Kahn, Organizational behavior 2. Routledge2015</p>
<p>Effects of group pressure upon the modification and distortion of judgments. Asch Se, Groups, Leadership and Men: Research in Human Relations. 1951177</p>
<p>Behavioral study of obedience. Stanley Milgram, The Journal of abnormal and social psychology. 6743711963</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, 202235Advances in neural information processing systems</p>
<p>Large language models are zero-shot reasoners. Advances in neural information processing systems. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, 202235</p>
<p>Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, arXiv:2309.07864The rise and potential of large language model based agents: A survey. 2023arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in Neural Information Processing Systems. 202436</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Jirong Wen, Frontiers of Computer Science. 186March 2024</p>
<p>Character-llm: A trainable agent for role-playing. Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu, 2023</p>
<p>From persona to personalization: A survey on role-playing language agents. Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui Zhu, arXiv:2404.182312024arXiv preprint</p>
<p>Out of one, many: Using language models to simulate human samples. Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, David Wingate, Political Analysis. 313February 2023</p>
<p>Large language models as instruments of power: New regimes of autonomous manipulation and control. Yaqub Chaudhary, Jonnie Penn, arXiv:2405.038132024arXiv preprint</p>
<p>Large language model based multiagents: A survey of progress and challenges. Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, V Nitesh, Olaf Chawla, Xiangliang Wiest, Zhang, arXiv:2402.016802024arXiv preprint</p>
<p>Large language models empowered agent-based modeling and simulation: A survey and perspectives. Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, Fengli Xu, Yong Li, Humanities and Social Sciences Communications. 1112024</p>
<p>Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng Su, Yufan Dang, Jiahao Li, Juyuan Xu, Dahai Li, arXiv:2307.07924Communicative agents for software development. 2023arXiv preprint</p>
<p>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, arXiv:2308.00352Meta programming for multi-agent collaborative framework. 2023arXiv preprint</p>
<p>Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang, Weizhi Ma, Yang Liu, arXiv:2405.02957Agent hospital: A simulacrum of hospital with evolvable medical agents. 2024arXiv preprint</p>
<p>Ai hospital: Interactive evaluation and collaboration of llms as intern doctors for clinical diagnosis. Zhihao Fan, Jialong Tang, Wei Chen, Siyuan Wang, Zhongyu Wei, Jun Xi, Fei Huang, Jingren Zhou, arXiv:2402.097422024arXiv preprint</p>
<p>Simucourt: Building judicial decision-making agents with real-world judgement documents. Zhitao He, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao, arXiv:2403.029592024arXiv preprint</p>
<p>Dynamic models of segregation. C Thomas, Schelling, Journal of mathematical sociology. 121971</p>
<p>Opinion dynamics driven by various ways of averaging. Rainer Hegselmann, Ulrich Krause, Computational Economics. 252005</p>
<p>Computational agent-based models in opinion dynamics: A survey on social simulations and empirical studies. Yun-Shiuan Chuang, Timothy T Rogers, arXiv:2306.034462023arXiv preprint</p>
<p>Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T Rogers, arXiv:2311.09618Simulating opinion dynamics with networks of llm-based agents. 2023arXiv preprint</p>
<p>Unveiling the truth and facilitating change: Towards agent-based large-scale social movement simulation. Xinyi Mou, Zhongyu Wei, Xuanjing Huang, arXiv:2402.163332024arXiv preprint</p>
<p>Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing Gao, Ji Zhang, Rui Yan, arXiv:2403.09498From skepticism to acceptance: Simulating the attitude dynamics toward fake news. 2024arXiv preprint</p>
<p>Large language model-empowered agents for simulating macroeconomic activities. N Li, C Gao, M Li, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics20241</p>
<p>Zekun Moore, Wang , Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Stephen W Huang, Jie Fu, and Junran Peng. Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models. 2024</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, arXiv:2305.143252023arXiv preprint</p>
<p>Marg: Multi-agent review generation for scientific papers. D' Mike, Tom Arcy, Larry Hope, Doug Birnbaum, Downey, arXiv:2401.042592024arXiv preprint</p>
<p>The wisdom of partisan crowds: Comparing collective intelligence in humans and llm-based agents. Yun-Shiuan Chuang, Nikunj Harlalka, Siddharth Suresh, Agam Goyal, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T Rogers, Proceedings of the Annual Meeting of the Cognitive Science Society. the Annual Meeting of the Cognitive Science Society202446</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th annual acm symposium on user interface software and technology. the 36th annual acm symposium on user interface software and technology2023</p>
<p>Oasis: Open agents social interaction simulations on one million agents. Ziyi Yang, Zaibin Zhang, Zirui Zheng, Yuxian Jiang, Ziyue Gan, Zhiyu Wang, Zijian Ling, Jinsong Chen, Martz Ma, Bowen Dong, arXiv:2411.115812024arXiv preprint</p>
<p>Large language model-based agents for software engineering: A survey. Junwei Liu, Kaixin Wang, Yixuan Chen, Xin Peng, Zhenpeng Chen, Lingming Zhang, Yiling Lou, arXiv:2409.029772024arXiv preprint</p>
<p>Language models are few-shot learners. Tom B Brown, arXiv:2005.141652020arXiv preprint</p>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. Gpt-4 technical report. 2023arXiv preprint</p>
<p>Reflective linguistic programming (rlp): A stepping stone in socially-aware agi (socialagi). Kevin A Fischer, arXiv:2305.126472023arXiv preprint</p>
<p>User behavior simulation with large language model based agents. Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, arXiv:2306.025522023arXiv preprint</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprint</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992Reasoning with language model is planning with world model. 2023arXiv preprint</p>
<p>Aaron Parisi, Yao Zhao, Noah Fiedel, arXiv:2205.12255Talm: Tool augmented language models. 2022arXiv preprint</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, Advances in Neural Information Processing Systems. 202436</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202436</p>
<p>Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao, Chatdb, arXiv:2306.03901Augmenting llms with databases as their symbolic memory. 2023arXiv preprint</p>
<p>Memorybank: Enhancing large language models with long-term memory. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202417</p>
<p>Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng, arXiv:2308.03427Tptu: large language model-based ai agents for task planning and tool usage. 2023arXiv preprint</p>
<p>War and peace (waragent): Large language model-based multi-agent simulation of world wars. Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, Yongfeng Zhang, arXiv:2311.172272023arXiv preprint</p>
<p>Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun, arXiv:2406.07155Scaling large-language-model-based multi-agent collaboration. 2024arXiv preprint</p>
<p>Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, Liqiang Nie, arXiv:2304.12998Chatllm network: More brains, more intelligence. 2023arXiv preprint</p>
<p>Cheng Li, Damien Teney, Linyi Yang, Qingsong Wen, Xing Xie, Jindong Wang, arXiv:2405.15145Culturepark: Boosting cross-cultural understanding in large language models. 2024arXiv preprint</p>
<p>Weize Chen, Chenfei Yuan, Jiarui Yuan, Yusheng Su, Chen Qian, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun, arXiv:2402.18439Beyond natural language: Llms leveraging alternative formats for enhanced reasoning and communication. 2024arXiv preprint</p>
<p>Let models speak ciphers: Multiagent debate through embeddings. Chau Pham, Boyi Liu, Yingxiang Yang, Zhengyu Chen, Tianyi Liu, Jianbo Yuan, Bryan A Plummer, Zhaoran Wang, Hongxia Yang, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Samuele Marro, La Emanuele, Jesse Malfa, Guohao Wright, Nigel Li, Michael Shadbolt, Philip Wooldridge, Torr, arXiv:2410.11905A scalable communication protocol for networks of large language models. 2024arXiv preprint</p>
<p>let your characters tell their story": A dataset for character-centric narrative understanding. Faeze Brahman, Meng Huang, Oyvind Tafjord, Chao Zhao, Mrinmaya Sachan, Snigdha Chaturvedi, 2021</p>
<p>Large language models meet harry potter: A bilingual dataset for aligning dialogue agents with characters. Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, Jia Li, 2023</p>
<p>Creating a large language model of a philosopher. Eric Schwitzgebel, David Schwitzgebel, Anna Strasser, 2023</p>
<p>Sung Joon, Joseph C Park, Carrie J O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Generative agents: Interactive simulacra of human behavior. 2023</p>
<p>Multimodal persona based generation of comic dialogs. Harsh Agrawal, Aditya Mishra, Manish Gupta, Mausam , Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. Anna Rogers, Jordan Boyd-Graber, Naoaki Okazaki, the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational LinguisticsJuly 20231</p>
<p>Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, M I Weishi, Yaying Fei, Xiaoyang Feng, Song Yan, Haosheng Wang, Linkang Zhan, Yaokai Jia, Pingyu Wu, Haozhen Sun, Chatharuhi, Reviving anime character in reality via large language model. 2023</p>
<p>Livechat: A large-scale personalized dialogue dataset automatically constructed from live streaming. Jingsheng Gao, Yixin Lian, Ziyi Zhou, Yuzhuo Fu, Baoyuan Wang, 2023</p>
<p>Xintao Wang, Yunze Xiao, Jen Tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Jiangjie Chen, Cheng Li, Yanghua Xiao, Incharacter, Evaluating personality fidelity in role-playing agents through psychological interviews. 2024</p>
<p>Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, Sahand Sabour, Xiaohan Zhang, Wenjing Hou, Yijia Zhang, Yuxiao Dong, Jie Tang, and Minlie Huang. Characterglm: Customizing chinese conversational ai characters with large language models. 2023</p>
<p>Roleeval: A bilingual role evaluation benchmark for large language models. Tianhao Shen, Sun Li, Quan Tu, Deyi Xiong, 2024</p>
<p>Charactereval: A chinese benchmark for role-playing conversational agent evaluation. Quan Tu, Shilong Fan, Zihang Tian, Rui Yan, 2024</p>
<p>Neeko: Leveraging dynamic lora for efficient multi-character role-playing agent. Xiaoyan Yu, Tongxu Luo, Yifan Wei, Fangyu Lei, Yiming Huang, Hao Peng, Liehuang Zhu, 2024</p>
<p>Character is destiny: Can large language models simulate persona-driven decisions in role-playing?. Rui Xu, Xintao Wang, Jiangjie Chen, Siyu Yuan, Xinfeng Yuan, Jiaqing Liang, Zulong Chen, Xiaoqing Dong, Yanghua Xiao, 2024</p>
<p>Evaluating character understanding of large language models via character profiling from fictional works. Xinfeng Yuan, Siyu Yuan, Yuhan Cui, Tianhe Lin, Xintao Wang, Rui Xu, Jiangjie Chen, Deqing Yang, 2024</p>
<p>Capturing minds, not just words: Enhancing role-playing language models with personality-indicative data. Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, Deqing Yang, 2024</p>
<p>Mmrole: A comprehensive framework for developing and evaluating multimodal role-playing agents. Yanqi Dai, Huanran Hu, Lei Wang, Shengjie Jin, Xu Chen, Zhiwu Lu, 2024</p>
<p>Beyond dialogue: A profiledialogue alignment framework towards general roleplaying language model. Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian, 2024</p>
<p>Rational sensibility: Llm enhanced empathetic response generation guided by selfpresentation theory. Linzhuang Sun, Yao Dong, Nan Xu, Jingxuan Wei, Bihui Yu, Yin Luo, arXiv:2312.087022023arXiv preprint</p>
<p>Saketh Reddy, Karra , Son The Nguyen, and Theja Tulabandhula. Estimating the personality of white-box language models. 2023</p>
<p>Evaluating and inducing personality in pre-trained language models. Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu, 2023</p>
<p>Improving personality consistency in conversation by persona extending. Yifan Liu, Wei Wei, Jiayi Liu, Xianling Mao, Rui Fang, Dangyang Chen, Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management. the 31st ACM International Conference on Information &amp; Knowledge ManagementACMOctober 202239</p>
<p>Large language models as simulated economic agents: What can we learn from homo silicus?. John J Horton, 2023</p>
<p>The wall street neophyte: A zeroshot analysis of chatgpt over multimodal stock movement prediction challenges. Qianqian Xie, Weiguang Han, Yanzhao Lai, Min Peng, Jimin Huang, 2023</p>
<p>Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan, Toxicity in chatgpt: Analyzing persona-assigned language models. 2023</p>
<p>Have large language models developed a personality?: Applicability of self-assessment tests in measuring personality in llms. Xiaoyang Song, Akshat Gupta, Kiyan Mohebbizadeh, Shujie Hu, Anant Singh, 2023</p>
<p>Marked personas: Using natural language prompts to measure stereotypes in language models. Myra Cheng, Esin Durmus, Dan Jurafsky, 2023</p>
<p>Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Jun Xu, Zhicheng Dou, Jun Wang, Ji-Rong Wen, User behavior simulation with large language model based agents. 2024</p>
<p>Greg Serapio-Garca, Mustafa Safdari, Clment Crepy, Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, and Maja Matari. Personality traits in large language models. 2023</p>
<p>Emotionally numb or empathetic? evaluating how llms feel using emotionbench. Jen Tse Huang, Man Ho Lam, Eric John Li, Shujie Ren, Wenxuan Wang, Wenxiang Jiao, Zhaopeng Tu, Michael R Lyu, 2024</p>
<p>Characterchat: Learning towards conversational ai with personalized social support. Quan Tu, Chuanqi Chen, Jinpeng Li, Yanran Li, Shuo Shang, Dongyan Zhao, Ran Wang, Rui Yan, 2023</p>
<p>Conversational health agents: A personalized llm-powered agent framework. Iman Mahyar Abbasian, Azimi, M Amir, Ramesh Rahmani, Jain, 2024</p>
<p>Put your money where your mouth is: Evaluating strategic planning and execution of llm agents in an auction arena. Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder, Kyle Richardson, 2024</p>
<p>Econagent: Large language model-empowered agents for simulating macroeconomic activities. Nian Li, Chen Gao, Mingyu Li, Yong Li, Qingmin Liao, 2024</p>
<p>Building persona consistent dialogue agents with offline reinforcement learning. Ryan Shea, Zhou Yu, 2023</p>
<p>Be selfish, but wisely: Investigating the impact of agent personality in mixed-motive human-agent interactions. Kushal Chawla, Ian Wu, Yu Rong, Gale M Lucas, Jonathan Gratch, 2023</p>
<p>Enhancing empathic reasoning of large language models based on psychotherapy models for ai-assisted social support. Yoon-Kyung Lee, Sowon Hahn, Seo-Yeon Bae, Inju Lee, Minjung Shin, Korean Journal of Cognitive Science. 3512024</p>
<p>Ameet Deshpande. Shashank Gupta, Vaishnavi Shrivastava, Ashish Sabharwal, and Tushar Khot. Bias runs deep: Implicit reasoning biases in persona-assigned llms. Ashwin Kalyan, Peter Clark2024</p>
<p>On the steerability of large language models toward data-driven personas. Junyi Li, Ninareh Mehrabi, Charith Peris, Palash Goyal, Kai-Wei Chang, Aram Galstyan, Richard Zemel, Rahul Gupta, 2024</p>
<p>Can large language model agents simulate human trust behaviors?. Chengxing Xie, Canyu Chen, Feiran Jia, Ziyu Ye, Kai Shu, Adel Bibi, Ziniu Hu, Philip Torr, Bernard Ghanem, Guohao Li, 2024</p>
<p>Can large language models estimate public opinion about global warming? an empirical assessment of algorithmic fidelity and bias. Sanguk Lee, Tai-Quan Peng, Matthew H Goldberg, Seth A Rosenthal, John E Kotcher, Edward W Maibach, Anthony Leiserowitz, PLOS Climate. 38e0000429August 2024</p>
<p>Culturellm: Incorporating cultural differences into large language models. Cheng Li, Mengzhou Chen, Jindong Wang, Sunayana Sitaram, Xing Xie, 2024</p>
<p>Controllm: Crafting diverse personalities for language models. Yixuan Weng, Shizhu He, Kang Liu, Shengping Liu, Jun Zhao, 2024</p>
<p>Random silicon sampling: Simulating human sub-population opinion using a large language model based on group-level demographic information. Seungjong Sun, Eungu Lee, Dongyan Nan, Xiangying Zhao, Wonbyung Lee, Bernard J Jansen, Jang Hyun, Kim , 2024</p>
<p>Synthetic replacements for human survey data? the perils of large language models. James Bisbee, Joshua D Clinton, Cassy Dorff, Brenton Kenkel, Jennifer M Larson, Political Analysis. 3242024</p>
<p>Scaling synthetic data creation with 1,000,000. Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu, 20240</p>
<p>Performance and biases of large language models in public opinion simulation. Yao Qu, Jue Wang, 2024Academy of Management Proceedings</p>
<p>Interactive agents: Simulating counselor-client psychological counseling via role-playing llm-to-llm interactions. Huachuan Qiu, Zhenzhong Lan, 2024</p>
<p>Humanoid agents: Platform for simulating human-like generative agents. Zhilin Wang, Yu Ying Chiu, Yu Cheung Chiu, 2023</p>
<p>Call for customized conversation: Customized conversation grounding persona and knowledge. Yoonna Jang, Jungwoo Lim, Yuna Hur, Dongsuk Oh, Suhyune Son, Yeonsoo Lee, Donghoon Shin, Seungryong Kim, Heuiseok Lim, 2022</p>
<p>Dialogue history matters! personalized response selectionin multi-turn retrieval-based chatbots. Juntao Li, Chang Liu, Chongyang Tao, Zhangming Chan, Dongyan Zhao, Min Zhang, Rui Yan, 2021</p>
<p>Faithful persona-based conversational dataset generation with large language models. Pegah Jandaghi, Xianghai Sheng, Xinyi Bai, Jay Pujara, Hakim Sidahmed, 2023</p>
<p>From role-play to drama-interaction: An llm solution. Weiqi Wu, Hongqiu Wu, Lai Jiang, Xingyuan Liu, Jiale Hong, Hai Zhao, Min Zhang, 2024</p>
<p>Language models meet world models: Embodied experiences enhance language models. Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, Zhiting Hu, 2023</p>
<p>Jiangyong Huang, Silong Yong, Xiaojian Ma, Xiongkun Linghu, Puhao Li, Yan Wang, Qing Li, Song-Chun Zhu, Baoxiong Jia, and Siyuan Huang. An embodied generalist agent in 3d world. 2024</p>
<p>Agentsims: An opensource sandbox for large language model evaluation. Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, Qin Chen, 2023</p>
<p>Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, 2023</p>
<p>Surveyagent: A conversational system for personalized and efficient research survey. Xintao Wang, Jiangjie Chen, Nianqi Li, Lida Chen, Xinfeng Yuan, Wei Shi, Xuyang Ge, Rui Xu, Yanghua Xiao, 2024</p>
<p>Socialbench: Sociality evaluation of role-playing conversational agents. Hongzhan Chen, Hehong Chen, Ming Yan, Wenshen Xu, Xing Gao, Weizhou Shen, Xiaojun Quan, Chenliang Li, Ji Zhang, Fei Huang, Jingren Zhou, 2024</p>
<p>Chatcot: Tool-augmented chain-of-thought reasoning on chatbased large language models. Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, Ji-Rong Wen, 2023</p>
<p>Lamp: When large language models meet personalization. Alireza Salemi, Sheshera Mysore, Michael Bendersky, Hamed Zamani, 2024</p>
<p>Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge Zhang, Feng Yin, Yitao Liang, Yaodong Yang, Proagent: Building proactive cooperative agents with large language models. 2024</p>
<p>Planand-solve prompting: Improving zero-shot chain-ofthought reasoning by large language models. Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy , Ka-Wei Lee, Ee-Peng Lim, arXiv:2305.040912023arXiv preprint</p>
<p>Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, Haibin Yan, arXiv:2307.01848Embodied task planning with large language models. 2023arXiv preprint</p>
<p>Llmplanner: Few-shot grounded planning for embodied agents with large language models. Hee Chan, Jiaman Song, Clayton Wu, Brian M Washington, Wei-Lun Sadler, Yu Chao, Su, 2023</p>
<p>A personalized dialogue generator with implicit user persona detection. Itsugun Cho, Dongyang Wang, Ryota Takahashi, Hiroaki Saito, 2022</p>
<p>Avalonbench: Evaluating llms playing the game of avalon. Jonathan Light, Min Cai, Sheng Shen, Ziniu Hu, 2023</p>
<p>Do llms possess a personality? making the mbti test an amazing evaluation for large language models. Keyu Pan, Yawen Zeng, 2023</p>
<p>Clembench: Using game play to evaluate chat-optimized language models as conversational agents. Kranti Chalamalasetti, Jana Gtze, Sherzod Hakimov, Brielen Madureira, Philipp Sadler, David Schlangen, 2023</p>
<p>Skill reinforcement learning and planning for open-world long-horizon tasks. Haoqi Yuan, Chi Zhang, Hongcheng Wang, Feiyang Xie, Penglin Cai, Hao Dong, Zongqing Lu, 2023</p>
<p>Libo Sun, Siyuan Wang, Xuanjing Huang, Zhongyu Wei, arXiv:2407.19412Identity-driven hierarchical roleplaying agents. 2024arXiv preprint</p>
<p>Training a helpful and harmless assistant with reinforcement learning from human feedback. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova Dassarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam Mccandlish, Chris Olah, Ben Mann, Jared Kaplan, 2022</p>
<p>Personalized soups: Personalized large language model alignment via post-hoc parameter merging. Joel Jang, Seungone Kim, Bill Yuchen Lin, Yizhong Wang, Jack Hessel, Luke Zettlemoyer, Hannaneh Hajishirzi, Yejin Choi, Prithviraj Ammanabrolu, 2023</p>
<p>Xingxuan Li, Yutong Li, Lin Qiu, Shafiq Joty, Lidong Bing, Evaluating psychological safety of large language models. 2024</p>
<p>Exploring social desirability response bias in large language models: Evidence from gpt-4 simulations. Sanguk Lee, Kai-Qi Yang, Tai-Quan Peng, Ruth Heo, Hui Liu, 2024</p>
<p>When crowd meets persona: Creating a large-scale open-domain persona dialogue corpus. Ik Won, Cho, Kyung Yoon, Seoyeon Lee, Jihwan Bae, Sangah Kim, Moosung Park, Sowon Kim, Nam Soo Hahn, Kim, 2023</p>
<p>Unifying local and global knowledge: Empowering large language models as political experts with knowledge graphs. Xinyi Mou, Zejun Li, Hanjia Lyu, Jiebo Luo, Zhongyu Wei, Proceedings of the ACM on Web Conference 2024. the ACM on Web Conference 20242024</p>
<p>Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, Rui Kong, Yile Wang, Hanfei Geng, Jian Luan, Xuefeng Jin, Zilong Ye, Guanjing Xiong, Fan Zhang, Xiang Li, Mengwei Xu, Zhijun Li, Peng Li, Yang Liu, Ya-Qin Zhang, and Yunxin Liu. Personal llm agents: Insights and survey about the capability, efficiency and security. 2024</p>
<p>Knowledge-augmented large language models for personalized contextual query suggestion. Jinheon Baek, Nirupama Chandrasekaran, Silviu Cucerzan, Allen Herring, Sujay Kumar, Jauhar , 2024</p>
<p>Daniel del Castillo Iglesias, Ron Heichman, and Ramesh Darwishi. Evaluating the susceptibility of pre-trained language models via handcrafted adversarial examples. Hezekiah J Branch, Jonathan Rodriguez Cefalu, Jeremy Mchugh, Leyla Hujer, Aditya Bahl, 2022</p>
<p>MPCHAT: Towards multimodal personagrounded conversation. Jaewoo Ahn, Yeda Song, Sangdoo Yun, Gunhee Kim, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. Anna Rogers, Jordan Boyd-Graber, Naoaki Okazaki, the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational LinguisticsJuly 20231</p>
<p>Jiwei Li, Michel Galley, Chris Brockett, Georgios P Spithourakis, Jianfeng Gao, Bill Dolan, A persona-based neural conversation model. 2016</p>
<p>Chatcoder: Chat-based refine requirement improves llms' code generation. Zejun Wang, Jia Li, Ge Li, Zhi Jin, 2023</p>
<p>Tooltalk: Evaluating tool-usage in a conversational setting. Nicholas Farn, Richard Shin, 2023</p>
<p>Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. Agentbench: Evaluating llms as agents. 2023</p>
<p>Graham Neubig, et al. Sotopia: Interactive evaluation for social intelligence in language agents. Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, arXiv:2310.116672023arXiv preprint</p>
<p>Elicitron: An llm agent-based simulation framework for design requirements elicitation. Mohammadmehdi Ataei, Hyunmin Cheong, Daniele Grandi, Ye Wang, Nigel Morris, Alexander Tessier, arXiv:2404.160452024arXiv preprint</p>
<p>Diyi Yang, Caleb Ziems, William Held, Omar Shaikh, John Michael S Bernstein, Mitchell, arXiv:2404.04204Social skill training with large language models. 2024arXiv preprint</p>
<p>Social life simulation for non-cognitive skills learning. Zihan Yan, Yaohong Xiang, Yun Huang, arXiv:2405.002732024arXiv preprint</p>
<p>Self-emotion blended dialogue generation in social simulation agents. Qiang Zhang, Jason Naradowsky, Yusuke Miyao, arXiv:2408.016332024arXiv preprint</p>
<p>Improving language model negotiation with selfplay and in-context learning from ai feedback. Yao Fu, Hao Peng, arXiv:2305.101422023arXiv preprintTushar Khot, and Mirella Lapata</p>
<p>Examining inter-consistency of large language models collaboration: An in-depth analysis via debate. Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, Bing Qin, arXiv:2305.115952023arXiv preprint</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, arXiv:2305.191182023arXiv preprint</p>
<p>Chi Ming Chan, Wenhao Chen, Yi Su, arXiv:2308.07201Towards better llm-based evaluators through multiagent debate. 2023arXiv preprint</p>
<p>Autogen: Enabling next-gen llm applications via multi-agent conversation framework. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang, arXiv:2308.081552023arXiv preprint</p>
<p>Tian Xia, Zhiwei He, Yibo Tong Ren, Zhuosheng Miao, Yang Zhang, Rui Yang, Wang, arXiv:2402.15813Measuring bargaining abilities of llms: A benchmark and a buyer-enhancement method. 2024arXiv preprint</p>
<p>Debate on graph: a flexible and reliable reasoning framework for large language models. Jie Ma, Zhitao Gao, Qi Chai, Wangchun Sun, Pinghui Wang, Hongbin Pei, Jing Tao, Lingyun Song, Jun Liu, Chen Zhang, arXiv:2409.031552024arXiv preprint</p>
<p>Exploring large language models for communication games: An empirical study on werewolf. Y Xu, S Wang, P Li, 2023</p>
<p>Avalon's game of thoughts: Battle against deception through recursive contemplation. Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen, Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, Gao Huang, arXiv:2310.013202023arXiv preprint</p>
<p>Exploring collaboration mechanisms for llm agents: A social psychology view. Jintian Zhang, Xin Xu, Shumin Deng, arXiv:2310.021242023arXiv preprint</p>
<p>From text to tactic: Evaluating llms playing the game of avalon. Jonathan Light, Min Cai, Sheng Shen, Ziniu Hu, arXiv:2310.050362023arXiv preprint</p>
<p>Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye, Peilin Zhao, Ee-Peng Lim, Hui Xiong, Hao Wang, arXiv:2310.14985Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay. 2023arXiv preprint</p>
<p>Language agents with reinforcement learning for strategic play in the werewolf game. Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu, arXiv:2310.189402023arXiv preprint</p>
<p>Deciphering digital detectives: Understanding llm behaviors and capabilities in multi-agent mystery games. Dekun Wu, Haochen Shi, Zhiyuan Sun, Bang Liu, arXiv:2312.007462023arXiv preprint</p>
<p>Zijing Shi, Meng Fang, Shunfeng Zheng, Shilong Deng, Ling Chen, Yali Du, arXiv:2312.17515Cooperation on the fly: Exploring language agents for ad hoc teamwork in the avalon game. 2023arXiv preprint</p>
<p>Enhance reasoning for large language models in the game werewolf. S Wu, L Zhu, T Yang, 2024</p>
<p>Helmsman of the masses? evaluate the opinion leadership of large language models in the werewolf game. Silin Du, Xiaowei Zhang, arXiv:2404.016022024arXiv preprint</p>
<p>Qinglin Zhu, Runcong Zhao, Jinhua Du, Lin Gui, Yulan He, arXiv:2404.17662Player*: Enhancing llm-based multiagent communication and interaction in murder mystery games. 2024arXiv preprint</p>
<p>Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory. Xizhou Zhu, Yuntao Chen, Chenxin Hao Tian, Weijie Tao, Chenyu Su, Gao Yang, Bin Huang, Lewei Li, Xiaogang Lu, Wang, arXiv:2305.171442023arXiv preprint</p>
<p>Karthik Sreedhar, Lydia Chilton, arXiv:2402.08189Simulating human strategic behavior: Comparing single and multiagent llms. 2024arXiv preprint</p>
<p>Amongagents: Evaluating large language models in the interactive text-based social deduction game. Yizhou Chi, Lingjun Mao, Zineng Tang, arXiv:2407.165212024arXiv preprint</p>
<p>S-agents: self-organizing agents in open-ended environment. Jiaqi Chen, Yuxian Jiang, Jiachen Lu, Li Zhang, arXiv:2402.045782024arXiv preprint</p>
<p>Md Mahadi Hassan, Alex Knipper, Shubhra Kanti, Karmaker Santu, arXiv:2305.13657Chatgpt as your personal data scientist. 2023arXiv preprint</p>
<p>Cheng-Kuang Wu, Wei-Lin Chen, Hsin-Hsi Chen, arXiv:2307.08922Large language models perform diagnostic reasoning. 2023arXiv preprint</p>
<p>Chatgpt research group for optimizing the crystallinity of mofs and cofs. Zhiling Zheng, Oufan Zhang, Nakul Ha L Nguyen, Rampal, Zichao Ali H Alawadhi, Teresa Rong, Christian Head-Gordon, Jennifer T Borgs, Omar M Chayes, Yaghi, ACS Central Science. 9112023</p>
<p>Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, Arman Cohan, Mark Gerstein, Medagents, arXiv:2311.10537Large language models as collaborators for zero-shot medical reasoning. 2023arXiv preprint</p>
<p>Reviewer2: Optimizing review generation through prompt generation. Zhaolin Gao, Kiant Brantley, Thorsten Joachims, arXiv:2402.108862024arXiv preprint</p>
<p>What if llms have different world views: Simulating alien civilizations with llmbased agents. Mingyu Jin, Beichen Wang, Zhaoqian Xue, Suiyuan Zhu, Wenyue Hua, Hua Tang, Kai Mei, Mengnan Du, Yongfeng Zhang, arXiv:2402.131842024arXiv preprint</p>
<p>Researchagent: Iterative research idea generation over scientific literature with large language models. Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, Sung Ju Hwang, arXiv:2404.077382024arXiv preprint</p>
<p>A synthetic dataset for personal attribute inference. Hanna Yukhymenko, Robin Staab, Mark Vero, Martin Vechev, arXiv:2406.072172024arXiv preprint</p>
<p>Dreamfactory: Pioneering multi-scene long video generation with a multi-agent framework. Zhifei Xie, Daniel Tang, Dingwei Tan, Jacques Klein, Tegawend F Bissyand, Saad Ezzini, arXiv:2408.117882024arXiv preprint</p>
<p>Autotqa: Towards autonomous tabular question answering through multi-agent large language models. Jun-Peng Zhu, Peng Cai, Kai Xu, Li Li, Yishen Sun, Shuai Zhou, Haihuang Su, Liu Tang, Qi Liu, Proc. VLDB Endow. VLDB EndowNovember 202417</p>
<p>Varun Nair, Elliot Schumacher, Geoffrey Tso, Anitha Kannan, arXiv:2303.17071Dera: enhancing large language model completions with dialog-enabled resolving agents. 2023arXiv preprint</p>
<p>Selfcollaboration code generation via chatgpt. Yihong Dong, Xue Jiang, Zhi Jin, Ge Li, arXiv:2304.075902023arXiv preprint</p>
<p>Chatdev: Communicative agents for software development. Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics20241</p>
<p>Experiential co-learning of software-developing agents. Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun, arXiv:2312.170252023arXiv preprint</p>
<p>Autocoderover: Autonomous program improvement. Yuntong Zhang, Haifeng Ruan, Zhiyu Fan, Abhik Roychoudhury, Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis. the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis2024</p>
<p>Iterative experience refinement of software-developing agents. Chen Qian, Jiahao Li, Yufan Dang, Wei Liu, Yifei Wang, Zihao Xie, Weize Chen, Cheng Yang, Yingli Zhang, Zhiyuan Liu, arXiv:2405.042192024arXiv preprint</p>
<p>Blind judgement: Agent-based supreme court modelling with gpt. Sil Hamilton, arXiv:2301.053272023arXiv preprint</p>
<p>Tradinggpt: Multi-agent system with layered memory and distinct characters for enhanced financial trading performance. Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, Khaldoun Khashanah, arXiv:2309.037362023arXiv preprint</p>
<p>Rethinking the buyer's inspection paradox in information markets with language agents. Martin Weiss, Nasim Rahaman, Manuel Wuthrich, Yoshua Bengio, Li Erran Li, Bernhard Sch "olkopf, Christopher Pal, 2024OpenReview</p>
<p>Mathvc: An llm-simulated multicharacter virtual classroom for mathematics education. Murong Yue, Wijdane Mifdal, Yixuan Zhang, Jennifer Suh, Ziyu Yao, arXiv:2404.067112024arXiv preprint</p>
<p>Simulating the us senate: An llm-driven agent approach to modeling legislative behavior and bipartisanship. R Zachary, Zarif L Baker, Azher, arXiv:2406.187022024arXiv preprint</p>
<p>Lawluo: A chinese law firm coby llm agents. Jingyun Sun, Chengxiao Dai, Zhongze Luo, Yangbo Chang, Yang Li, arXiv:2407.162522024arXiv preprint</p>
<p>From mooc to maic: Reshaping online teaching and learning through llm-driven agents. Jifan Yu, Zheyuan Zhang, Daniel Zhang-Li, Shangqing Tu, Zhanxin Hao, Rui Miao Li, Haoxuan Li, Yuanchun Wang, Hanming Li, Linlu Gong, arXiv:2409.035122024arXiv preprint</p>
<p>Camel: Communicative agents for"" mind"" exploration of large language model society. Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, Advances in Neural Information Processing Systems. 202336</p>
<p>Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks. Yicheng Bill Yuchen Lin, Karina Fu, Faeze Yang, Shiyu Brahman, Chandra Huang, Prithviraj Bhagavatula, Yejin Ammanabrolu, Xiang Choi, Ren, Advances in Neural Information Processing Systems. 202436</p>
<p>Multi-agent collaboration: Harnessing the power of intelligent llm agents. Yashar Talebirad, Amirhossein Nadiri, arXiv:2306.033142023arXiv preprint</p>
<p>Building cooperative embodied agents modularly with large language models. Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, Chuang Gan, arXiv:2307.024852023arXiv preprint</p>
<p>Roco: Dialectic multi-robot collaboration with large language models. Zhao Mandi, Shreeya Jain, Shuran Song, 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE2024</p>
<p>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. W Chen, Y Su, J Zuo, 2023</p>
<p>Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?. Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, Chuchu Fan, 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE2024</p>
<p>Autoagents: A framework for automatic agent generation. Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, B "orje F Karlsson, Jie Fu, Yemin Shi, arXiv:2309.172882023arXiv preprint</p>
<p>Openagents: An open platform for language agents in the wild. Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Jing Toh, Junning Hua, Qian Zhao, Che Liu, Liu, arXiv:2310.106342023arXiv preprint</p>
<p>True knowledge comes from practice: Aligning llms with embodied environments via reinforcement learning. Weihao Tan, Wentao Zhang, Shanqi Liu, Longtao Zheng, Xinrun Wang, Bo An, arXiv:2401.141512024arXiv preprint</p>
<p>Towards efficient llm grounding for embodied multi-agent collaboration. Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong Li, Zhen Wang, arXiv:2405.143142024arXiv preprint</p>
<p>Agentsims: An opensource sandbox for large language model evaluation. J Lin, H Zhao, A Zhang, 2023</p>
<p>Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents. Yuan Li, Yixuan Zhang, Lichao Sun, arXiv:2310.065002023arXiv preprint</p>
<p>Debatrix: Multi-dimensinal debate judge with iterative chronological analysis based on llm. Jingcong Liang, Rong Ye, Meng Han, Ruofei Lai, Xinyu Zhang, Xuanjing Huang, Zhongyu Wei, arXiv:2403.080102024arXiv preprint</p>
<p>Wei Liu, Chenxi Wang, Yifei Wang, Zihao Xie, Rennai Qiu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Chen Qian, arXiv:2406.14928Autonomous agents for collaborative task under information asymmetry. 2024arXiv preprint</p>
<p>Optima: Optimizing effectiveness and efficiency for llm-based multi-agent system. Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun, arXiv:2410.081152024arXiv preprint</p>
<p>Towards objectively benchmarking social intelligence for language agents at action level. Chenxu Wang, Bin Dai, Huaping Liu, Baoyuan Wang, arXiv:2404.053372024arXiv preprint</p>
<p>Xinyi Mou, Jingcong Liang, Jiayu Lin, Xinnong Zhang, Xiawei Liu, Shiyue Yang, Rong Ye, Lei Chen, Haoyu Kuang, Xuanjing Huang, arXiv:2410.19346Benchmarking social intelligence of language agents through interactive scenarios. 2024arXiv preprint</p>
<p>Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Graham Neubig, Yonatan Bisk, Hao Zhu, arXiv:2403.08715Sotopia-pi: Interactive learning of socially intelligent language agents. 2024arXiv preprint</p>
<p>Is this the real life? is this just fantasy? the misleading success of simulating social interactions with llms. Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, Maarten Sap, arXiv:2403.050202024arXiv preprint</p>
<p>Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, arXiv:2309.09971Emergent gaming interaction. 2023arXiv preprint</p>
<p>Piors: Personalized intelligent outpatient reception based on large language model with multi-agents medical scenario simulation. Zhijie Bao, Qingyun Liu, Ying Guo, Zhengqiang Ye, Jun Shen, Shirong Xie, Jiajie Peng, Xuanjing Huang, Zhongyu Wei, arXiv:2411.139022024arXiv preprint</p>
<p>Ai-press: A multiagent news generating and feedback simulation system powered by large language models. Xiawei Liu, Shiyue Yang, Xinnong Zhang, Haoyu Kuang, Libo Sun, Yihang Yang, Siming Chen, Xuanjing Huang, Zhongyu Wei, arXiv:2410.075612024arXiv preprint</p>
<p>Chengxing Xie, Canyu Chen, Feiran Jia, Ziyu Ye, Kai Shu, Adel Bibi, Ziniu Hu, Philip Torr, Bernard Ghanem, Guohao Li, arXiv:2402.04559Can large language model agents simulate human trust behaviors?. 2024arXiv preprint</p>
<p>Logic-enhanced language model agents for trustworthy social simulations. Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi, arXiv:2408.160812024arXiv preprint</p>
<p>Shangmin Guo, Haoran Bu, Haochuan Wang, Yi Ren, Dianbo Sui, Yuming Shang, Siting Lu, arXiv:2401.01735Economics arena for large language models. 2024arXiv preprint</p>
<p>Nicol Fontana, Francesco Pierri, Luca Maria Aiello, arXiv:2406.13605Nicer than humans: How do large language models behave in the prisoner's dilemma?. 2024arXiv preprint</p>
<p>guinea pig trials" utilizing gpt: A novel smart agent-based modeling approach for studying firm competition and collusion. X Han, Z Wu, C Xiao, 2023</p>
<p>Sean Noh, Ho-Chun Herbert, Chang , arXiv:2405.05248Llms with personalities in multi-issue negotiation games. 2024arXiv preprint</p>
<p>The good, the bad, and the hulk-like gpt: Analyzing emotional decisions of large language models in cooperation and bargaining games. Mikhail Mozikov, Nikita Severin, Valeria Bodishtianu, Maria Glushanina, Mikhail Baklashkin, Andrey V Savchenko, Ilya Makarov, arXiv:2406.032992024arXiv preprint</p>
<p>Shall we team up: Exploring spontaneous cooperation of competing llm agents. Zengqing Wu, Run Peng, Shuyuan Zheng, Qianying Liu, Xu Han, Brian Kwon, Makoto Onizuka, Shaojie Tang, Chuan Xiao, Findings of the Association for Computational Linguistics: EMNLP 2024. 2024</p>
<p>Competeai: Understanding the competition dynamics of large language model-based agents. Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie Zhu, Chen Hao, Xing Xie, Forty-first International Conference on Machine Learning. 2024</p>
<p>Large language models as simulated economic agents: What can we learn from homo silicus?. John J Horton, 2023National Bureau of Economic ResearchTechnical report</p>
<p>Srap-agent: Simulating and optimizing scarce resource allocation policy with llm-based agent. Jiarui Ji, Yang Li, Hongtao Liu, Zhicheng Du, Zhewei Wei, Qi Qi, Weiran Shen, Yankai Lin, Findings of the Association for Computational Linguistics: EMNLP 2024. 2024</p>
<p>Generative agent-based modeling: Unveiling social system dynamics through coupling mechanistic models with generative artificial intelligence. Navid Ghaffarzadegan, Aritra Majumdar, Ross Williams, Niyousha Hosseinichimeh, arXiv:2309.114562023arXiv preprint</p>
<p>Emergent cooperation and strategy adaptation in multi-agent systems: An extended coevolutionary theory with llms. J De Zarz, Gemma De Curt, Pietro Roig, Carlos T Manzoni, Calafate, 2023Electronics122722</p>
<p>Epidemic modeling with generative agents. R Williams, N Hosseinichimeh, A Majumdar, arXiv:2307.049862023arXiv preprint</p>
<p>Ayush Chopra, Shashank Kumar, Nurullah Giray-Kuru, Ramesh Raskar, Arnau Quera-Bofarull, arXiv:2409.10568On the limits of agency in agent-based models. 2024arXiv preprint</p>
<p>Sanguk Lee, Tai-Quan Peng, Matthew H Goldberg, Seth A Rosenthal, John E Kotcher, Edward W Maibach, Anthony Leiserowitz, arXiv:2311.00217Can large language models capture public opinion about global warming? an empirical assessment of algorithmic fidelity and bias. 2023arXiv preprint</p>
<p>Xinnong Zhang, Jiayu Lin, Libo Sun, Weihong Qi, Yihang Yang, Yue Chen, Hanjia Lyu, Xinyi Mou, Siming Chen, Jiebo Luo, arXiv:2410.20746Massive population election simulation powered by large language model driven agents. 2024arXiv preprint</p>
<p>Simulating public administration crisis: A novel generative agent-based simulation system to lower technology barriers in social science research. B Xiao, Z Yin, Z Shan, 2023</p>
<p>Sung Joon, Carolyn Q Park, Aaron Zou, Benjamin Mako Shaw, Carrie Hill, Meredith Ringel Cai, Robb Morris, Percy Willer, Michael S Liang, Bernstein, arXiv:2411.10109Generative agent simulations of 1,000 people. 2024arXiv preprint</p>
<p>Using large language models to simulate multiple humans and replicate human subject studies. Rosa I Gati V Aher, Adam Arriaga, Kalai Tauman, International Conference on Machine Learning. PMLR2023</p>
<p>Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes, Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, Andrew Ahn, arXiv:2310.02172Lyfe agents: Generative agents for low-cost real-time social interactions. 2023arXiv preprint</p>
<p>Emergence of social norms in large language model-based agent societies. S Ren, Z Cui, R Song, 2024</p>
<p>Choicemates: Supporting unfamiliar online decision-making with multi-agent conversational interactions. Jeongeon Park, Bryan Min, Xiaojuan Ma, Juho Kim, arXiv:2310.013312023arXiv preprint</p>
<p>Language agents as digital representatives in collective decision-making. Daniel Jarrett, Miruna Pislar, A Michiel, Michael Henry Bakker, Raphael Tessler, Jan Koster, Romuald Balaguer, Christopher Elie, Andrea Summerfield, Tacchetti, NeurIPS 2023 Foundation Models for Decision Making Workshop. 2023</p>
<p>Agentreview: Exploring peer review dynamics with llm agents. Yiqiao Jin, Qinlin Zhao, Yiyang Wang, Hao Chen, Kaijie Zhu, Yijia Xiao, Jindong Wang, arXiv:2406.127082024arXiv preprint</p>
<p>Yangbin Yu, Qin Zhang, Junyou Li, Qiang Fu, Deheng Ye, arXiv:2402.02053Affordable generative agents. 2024arXiv preprint</p>
<p>Mineland: Simulating large-scale multi-agent interactions with limited multimodal senses and physical needs. Xianhao Yu, Jiaqi Fu, Renjia Deng, Wenjuan Han, arXiv:2403.192672024arXiv preprint</p>
<p>Chen Zhu, Yihang Cheng, Jingshuai Zhang, Yusheng Qiu, Sitao Xia, Hengshu Zhu, arXiv:2408.11826Generative organizational behavior simulation using large language model based autonomous agents: A holacracy perspective. 2024arXiv preprint</p>
<p>An evolutionary model of personality traits related to cooperative behavior using a large language model. R Suzuki, T Arita, Scientific Reports. 14159892024</p>
<p>Yun-Shiuan Chuang, Zach Studdiford, Krirk Nirunwiroj, Agam Goyal, Sijia Vincent V Frigo, Dhavan Yang, Junjie Shah, Timothy T Hu, Rogers, Beyond demographics: Aligning role-playing llm-based agents using human belief networks. 2024</p>
<p>Quantifying the impact of large language models on collective opinion dynamics. Chao Li, Xing Su, Haoying Han, Cong Xue, Chunmo Zheng, Chao Fan, arXiv:2308.033132023arXiv preprint</p>
<p>Synthesizing post-training data for llms through multiagent simulation. Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Xiaowen Dong, Yanfeng Wang, Siheng Chen, arXiv:2410.142512024arXiv preprint</p>
<p>Language evolution for evading social media regulation via llm-based multi-agent simulation. Jinyu Cai, Jialong Li, Mingyue Zhang, Munan Li, Chen-Shu Wang, Kenji Tei, arXiv:2405.028582024arXiv preprint</p>
<p>From a tiny slip to a giant leap: An llm-based simulation for fake news evolution. Yuhan Liu, Zirui Song, Xiaoqing Zhang, Xiuying Chen, Rui Yan, arXiv:2410.190642024arXiv preprint</p>
<p>Decoding echo chambers: Llm-powered simulations revealing polarization in social networks. Chenxi Wang, Zongfang Liu, Dequan Yang, Xiuying Chen, arXiv:2409.193382024arXiv preprint</p>
<p>Andreea Musulan, et al. A simulation system towards solving societal-scale manipulation. Maximilian Puelma Touzel, Sneheel Sarangi, Austin Welch, Gayatri Krishnakumar, Dan Zhao, Zachary Yang, Hao Yu, Ethan Kosak-Hine, Tom Gibbs, arXiv:2410.139152024arXiv preprint</p>
<p>Social simulacra: Creating populated prototypes for social computing systems. J S Park, L Popowski, C Cai, Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. the 35th Annual ACM Symposium on User Interface Software and Technology2022</p>
<p>C Gao, X Lan, Z Lu, Social-network simulation system with large language model-empowered agents. 20233</p>
<p>Simulating social media using large language models to evaluate alternative news feed algorithms. Petter Trnberg, Diliara Valeeva, Justus Uitermark, Christopher Bail, arXiv:2310.059842023arXiv preprint</p>
<p>Andrea Failla, Riccardo Improta, Virginia Morini, and Valentina Pansanella. Y social: an llm-powered social media digital twin. Giulio Rossetti, Massimo Stella, Rmy Cazabet, Katherine Abramski, Erica Cau, Salvatore Citraro, 2024</p>
<p>A large-scale time-aware agents simulation for influencer selection in digital advertising campaigns. Xiaoqing Zhang, Xiuying Chen, Yuhan Liu, Jianzhou Wang, Zhenxing Hu, Rui Yan, arXiv:2411.011432024arXiv preprint</p>
<p>Mindecho: Role-playing language agents for key opinion leaders. Rui Xu, Dakuan Lu, Xiaoyu Tan, Xintao Wang, Siyu Yuan, Jiangjie Chen, Wei Chu, Xu Yinghui, 2024</p>
<p>Ruiyang Ren, Peng Qiu, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Hua Wu, Ji-Rong Wen, Haifeng Wang, arXiv:2402.17505Bases: Large-scale web search user simulation with large language model based agents. 2024arXiv preprint</p>
<p>Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, Xing Xie, arXiv:2308.16505Recommender ai agent: Integrating large language models for interactive recommendations. 2023arXiv preprint</p>
<p>Jizhi Zhang, Keqin Bao, Wenjie Wang, Yang Zhang, Wentao Shi, Wanhong Xu, Fuli Feng, Tat-Seng Chua, arXiv:2402.18240Prospect personalized recommendation on large language model-based agent platform. 2024arXiv preprint</p>
<p>Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Ji-Rong Wen, arXiv:2306.02552Recagent: A novel simulation paradigm for recommender systems. 2023arXiv preprint</p>
<p>On generative agents in recommendation. A Zhang, Y Chen, L Sheng, 2024</p>
<p>Agentcf: Collaborative learning with autonomous language agents for recommender systems. Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian Mcauley, Wayne Xin Zhao, Leyu Lin, Ji-Rong Wen, Proceedings of the ACM on Web Conference 2024. the ACM on Web Conference 20242024</p>
<p>Social simulation in the social sciences: A brief overview. Flaminio Squazzoni, Wander Jager, Bruce Edmonds, Social Science Computer Review. 3232014</p>
<p>Turning large language models into cognitive models. Marcel Binz, Eric Schulz, arXiv:2306.039172023arXiv preprint</p>
<p>Large language model-driven multi-agent simulation for news diffusion under different network structures. Xinyi Li, Yu Xu, Yongfeng Zhang, Edward C Malthouse, arXiv:2410.139092024arXiv preprint</p>
<p>Social ties and word-of-mouth referral behavior. Jacqueline , Johnson Brown, Peter H Reingen, Journal of Consumer research. 1431987</p>
<p>Origins of homophily in an evolving social network. Gueorgi Kossinets, Duncan J Watts, 2009115American journal of sociology</p>
<p>Can llms understand social norms in autonomous driving games?. Boxuan Wang, Haonan Duan, Yanhao Feng, Xu Chen, Yongjie Fu, Zhaobin Mo, Xuan Di, arXiv:2408.126802024arXiv preprint</p>
<p>Dawei Gao, Zitao Li, Xuchen Pan, Weirui Kuang, Zhijian Ma, Bingchen Qian, Fei Wei, Wenhao Zhang, Yuexiang Xie, Daoyuan Chen, arXiv:2402.14034A flexible yet robust multi-agent platform. 2024arXiv preprint</p>
<p>Xuchen Pan, Dawei Gao, Yuexiang Xie, Yushuo Chen, Zhewei Wei, Yaliang Li, Bolin Ding, Ji-Rong Wen, Jingren Zhou, arXiv:2407.17789Very large-scale multi-agent simulation in agentscope. 2024arXiv preprint</p>
<p>Recmind: Large language model powered agent for recommendation. Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, Yingzhen Yang, arXiv:2308.142962023arXiv preprint</p>
<p>Tian Liang, Zhiwei He, Jen-Tes Huang, Wenxuan Wang, Wenxiang Jiao, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, Xing Wang, arXiv:2310.20499Leveraging word guessing games to assess the intelligence of large language models. 2023arXiv preprint</p>
<p>Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, Jason Weston, Wizard of wikipedia: Knowledge-powered conversational agents. 2019</p>
<p>Personalizing dialogue agents: I have a dog, do you have pets too?. Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston, 2018</p>
<p>Who is gpt-3? an exploration of personality, values and demographics. Maril Miotto, Nicola Rossberg, Bennett Kleinberg, 2022</p>
<p>Avalon's game of thoughts: Battle against deception through recursive contemplation. S Wang, C Liu, Z Zheng, 2023</p>
<p>H Wang, J Chen, W Huang, Dream general robots in a city at scale. 2024</p>
<p>Personhood and ai: Why large language models don't understand us. J Browning, 2023AI &amp; Society</p>
<p>Learning transferable visual models from natural language supervision. A Radford, J W Kim, C Hallacy, Proceedings of the International Conference on Machine Learning. the International Conference on Machine LearningPMLR2021</p>
<p>Visual instruction tuning. Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee, Advances in neural information processing systems. 202436</p>            </div>
        </div>

    </div>
</body>
</html>