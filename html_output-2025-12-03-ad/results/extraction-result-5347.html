<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5347 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5347</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5347</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-111.html">extraction-schema-111</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for converting graphs into text for language model training, including details of the representation, properties, evaluation tasks, performance, and comparisons to other methods.</div>
                <p><strong>Paper ID:</strong> paper-e147cc46b7f441a68706ca53549d45e9a9843fb6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e147cc46b7f441a68706ca53549d45e9a9843fb6" target="_blank">GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks</a></p>
                <p><strong>Paper Venue:</strong> The Web Conference</p>
                <p><strong>Paper TL;DR:</strong> GraphPrompt is proposed, a novel pre- training and prompting framework on graphs that unifies pre-training and downstream tasks into a common task template, but also employs a learnable prompt to assist a downstream task in locating the most relevant knowledge from the pre-trained model in a task-specific manner.</p>
                <p><strong>Paper Abstract:</strong> Graphs can model complex relationships between objects, enabling a myriad of Web applications such as online page/article classification and social recommendation. While graph neural networks (GNNs) have emerged as a powerful tool for graph representation learning, in an end-to-end supervised setting, their performance heavily relies on a large amount of task-specific supervision. To reduce labeling requirement, the “pre-train, fine-tune” and “pre-train, prompt” paradigms have become increasingly common. In particular, prompting is a popular alternative to fine-tuning in natural language processing, which is designed to narrow the gap between pre-training and downstream objectives in a task-specific manner. However, existing study of prompting on graphs is still limited, lacking a universal treatment to appeal to different downstream tasks. In this paper, we propose GraphPrompt, a novel pre-training and prompting framework on graphs. GraphPrompt not only unifies pre-training and downstream tasks into a common task template, but also employs a learnable prompt to assist a downstream task in locating the most relevant knowledge from the pre-trained model in a task-specific manner. Finally, we conduct extensive experiments on five public datasets to evaluate and analyze GraphPrompt.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5347.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5347.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for converting graphs into text for language model training, including details of the representation, properties, evaluation tasks, performance, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GraphPrompt (biomedical, Zhang et al. 2021)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method (cited in this paper) that uses a relational graph to assist generation of text prompt templates which are consumed by masked-language-model (MLM) style text prompts for biomedical entity normalization; in that work the graph is auxiliary to a text-prompting pipeline rather than being converted into standalone natural language sequences for LM pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>graph-based text prompt templates</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Relational graph information is used to generate or guide textual prompt templates which are then used in a standard masked language modeling prompt framework; the approach keeps the core LM input as text (templates with mask tokens) while using the graph to form or select those templates (i.e., the graph is an auxiliary component that helps create text prompts rather than producing long textual serializations of the graph). The paper's mention states the method "employs the standard text prompt unified by masked language modeling, assisted by a relational graph to generate text templates."</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>relational graph (graph used as auxiliary to generate text templates)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_properties</strong></td>
                            <td>As described in this paper: the representation keeps language-model inputs in standard MLM text-prompt format (thus leveraging existing LM pretraining), treats the graph as auxiliary (not primary input), and is distinct from approaches that directly encode graphs into textual sequences; no detailed claims here about faithfulness, compression, or expressivity are given in this paper's mention.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_task</strong></td>
                            <td>Biomedical entity normalization (an NLP entity normalization task, as cited for that external work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_representations</strong></td>
                            <td>This paper states the approach (ref. [54]) is distinct from the authors' GraphPrompt: the cited GraphPrompt uses standard text prompts + MLM with graph assistance, whereas the present paper focuses on unifying GNN pretraining and graph prompting (graph-native prompting). No quantitative comparisons or benchmark results are provided in this paper's mention.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Mentioned limitations in this paper: the graph-based text-prompt approach treats the graph as auxiliary (i.e., not the primary input modality), and so it is conceptually different from graph-native prompting/pretraining; this paper does not report detailed limitations or empirical challenges of the cited approach (no metrics or failure modes provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5347.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5347.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for converting graphs into text for language model training, including details of the representation, properties, evaluation tasks, performance, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MLM text prompting (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Standard text prompt unified by masked language modeling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The general prompting paradigm in NLP where downstream tasks are cast into masked language modeling via handcrafted or learnable text templates (prompts) so that a pre-trained language model can be queried without full fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models are few-shot learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>text prompt templates (MLM)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Tasks are rewritten as textual templates containing mask tokens; the LM predicts masked tokens and the predicted tokens map to labels. This is a text-only representation (not a graph-to-text algorithm per se) but is referenced as the canonical way to align pretraining and downstream tasks in language models and as the template that graph-assisted methods (e.g., the cited GraphPrompt [54]) use to feed LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>not applicable (text prompt paradigm; graphs only enter if used to generate/select templates)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_properties</strong></td>
                            <td>Properties noted in this paper: narrows gap between pretraining and downstream objectives when applicable; can be handcrafted or learnable; learnable prompts lower engineering cost; reduces need to fine-tune large LM weights. No graph-faithfulness properties discussed here because this is a text-only paradigm.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_task</strong></td>
                            <td>General NLP few-shot tasks (the paper references the paradigm conceptually; specific downstream benchmarks are not given in this paper's discussion beyond the general reference).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_representations</strong></td>
                            <td>In this paper the MLM text-prompt paradigm is contrasted conceptually with graph-native prompting approaches: text prompting is the established method in NLP, while graph prompting must be adapted because graph structures are not natural language; no empirical comparison numbers are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Handcrafted prompts incur high engineering cost; need for learnable prompts to reduce manual effort; standard text prompts do not directly encode graph topology, so when graphs are involved additional machinery (e.g., graph-to-text conversion or graph-assisted template generation) is required — specifics not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates <em>(Rating: 2)</em></li>
                <li>Language models are few-shot learners <em>(Rating: 1)</em></li>
                <li>The Power of Scale for Parameter-Efficient Prompt Tuning <em>(Rating: 1)</em></li>
                <li>GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5347",
    "paper_id": "paper-e147cc46b7f441a68706ca53549d45e9a9843fb6",
    "extraction_schema_id": "extraction-schema-111",
    "extracted_data": [
        {
            "name_short": "GraphPrompt (biomedical, Zhang et al. 2021)",
            "name_full": "GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates",
            "brief_description": "A method (cited in this paper) that uses a relational graph to assist generation of text prompt templates which are consumed by masked-language-model (MLM) style text prompts for biomedical entity normalization; in that work the graph is auxiliary to a text-prompting pipeline rather than being converted into standalone natural language sequences for LM pretraining.",
            "citation_title": "GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates",
            "mention_or_use": "mention",
            "representation_name": "graph-based text prompt templates",
            "representation_description": "Relational graph information is used to generate or guide textual prompt templates which are then used in a standard masked language modeling prompt framework; the approach keeps the core LM input as text (templates with mask tokens) while using the graph to form or select those templates (i.e., the graph is an auxiliary component that helps create text prompts rather than producing long textual serializations of the graph). The paper's mention states the method \"employs the standard text prompt unified by masked language modeling, assisted by a relational graph to generate text templates.\"",
            "graph_type": "relational graph (graph used as auxiliary to generate text templates)",
            "representation_properties": "As described in this paper: the representation keeps language-model inputs in standard MLM text-prompt format (thus leveraging existing LM pretraining), treats the graph as auxiliary (not primary input), and is distinct from approaches that directly encode graphs into textual sequences; no detailed claims here about faithfulness, compression, or expressivity are given in this paper's mention.",
            "evaluation_task": "Biomedical entity normalization (an NLP entity normalization task, as cited for that external work)",
            "performance_metrics": null,
            "comparison_to_other_representations": "This paper states the approach (ref. [54]) is distinct from the authors' GraphPrompt: the cited GraphPrompt uses standard text prompts + MLM with graph assistance, whereas the present paper focuses on unifying GNN pretraining and graph prompting (graph-native prompting). No quantitative comparisons or benchmark results are provided in this paper's mention.",
            "limitations_or_challenges": "Mentioned limitations in this paper: the graph-based text-prompt approach treats the graph as auxiliary (i.e., not the primary input modality), and so it is conceptually different from graph-native prompting/pretraining; this paper does not report detailed limitations or empirical challenges of the cited approach (no metrics or failure modes provided here).",
            "uuid": "e5347.0",
            "source_info": {
                "paper_title": "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "MLM text prompting (general)",
            "name_full": "Standard text prompt unified by masked language modeling",
            "brief_description": "The general prompting paradigm in NLP where downstream tasks are cast into masked language modeling via handcrafted or learnable text templates (prompts) so that a pre-trained language model can be queried without full fine-tuning.",
            "citation_title": "Language models are few-shot learners",
            "mention_or_use": "mention",
            "representation_name": "text prompt templates (MLM)",
            "representation_description": "Tasks are rewritten as textual templates containing mask tokens; the LM predicts masked tokens and the predicted tokens map to labels. This is a text-only representation (not a graph-to-text algorithm per se) but is referenced as the canonical way to align pretraining and downstream tasks in language models and as the template that graph-assisted methods (e.g., the cited GraphPrompt [54]) use to feed LMs.",
            "graph_type": "not applicable (text prompt paradigm; graphs only enter if used to generate/select templates)",
            "representation_properties": "Properties noted in this paper: narrows gap between pretraining and downstream objectives when applicable; can be handcrafted or learnable; learnable prompts lower engineering cost; reduces need to fine-tune large LM weights. No graph-faithfulness properties discussed here because this is a text-only paradigm.",
            "evaluation_task": "General NLP few-shot tasks (the paper references the paradigm conceptually; specific downstream benchmarks are not given in this paper's discussion beyond the general reference).",
            "performance_metrics": null,
            "comparison_to_other_representations": "In this paper the MLM text-prompt paradigm is contrasted conceptually with graph-native prompting approaches: text prompting is the established method in NLP, while graph prompting must be adapted because graph structures are not natural language; no empirical comparison numbers are provided here.",
            "limitations_or_challenges": "Handcrafted prompts incur high engineering cost; need for learnable prompts to reduce manual effort; standard text prompts do not directly encode graph topology, so when graphs are involved additional machinery (e.g., graph-to-text conversion or graph-assisted template generation) is required — specifics not detailed in this paper.",
            "uuid": "e5347.1",
            "source_info": {
                "paper_title": "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks",
                "publication_date_yy_mm": "2023-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates",
            "rating": 2
        },
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 1
        },
        {
            "paper_title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
            "rating": 1
        },
        {
            "paper_title": "GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks",
            "rating": 1
        }
    ],
    "cost": 0.011498999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks</h1>
<p>Zemin Liu ${ }^{1 *}$<br>${ }^{1}$ National University of Singapore<br>Singapore<br>zeminliu@nus.edu.sg<br>Yuan Fang ${ }^{3 \dagger}$<br>${ }^{3}$ Singapore Management University<br>Singapore<br>yfang@smu.edu.sg</p>
<h4>Abstract</h4>
<p>Graphs can model complex relationships between objects, enabling a myriad of Web applications such as online page/article classification and social recommendation. While graph neural networks (GNNs) have emerged as a powerful tool for graph representation learning, in an end-to-end supervised setting, their performance heavily relies on a large amount of task-specific supervision. To reduce labeling requirement, the "pre-train, fine-tune" and "pre-train, prompt" paradigms have become increasingly common. In particular, prompting is a popular alternative to fine-tuning in natural language processing, which is designed to narrow the gap between pre-training and downstream objectives in a task-specific manner. However, existing study of prompting on graphs is still limited, lacking a universal treatment to appeal to different downstream tasks. In this paper, we propose GraphPrompt, a novel pre-training and prompting framework on graphs. GraphPrompt not only unifies pre-training and downstream tasks into a common task template, but also employs a learnable prompt to assist a downstream task in locating the most relevant knowledge from the pre-trained model in a task-specific manner. Finally, we conduct extensive experiments on five public datasets to evaluate and analyze GraphPrompt.</p>
<h2>CCS CONCEPTS</h2>
<ul>
<li>Computing methodologies $\rightarrow$ Learning latent representations; $\cdot$ Information systems $\rightarrow$ Data mining.</li>
</ul>
<h2>KEYWORDS</h2>
<p>Graph neural networks, pre-training, prompt, few-shot learning.</p>
<h2>ACM Reference Format:</h2>
<p>Zemin Liu ${ }^{1 <em>}$, Xingtong $\mathrm{Yu}^{2 </em>}$, Yuan Fang ${ }^{3 \dagger}$, and Xinming Zhang ${ }^{2 \dagger}$. 2023. GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Xingtong $\mathrm{Yu}^{2 *}$ <br> ${ }^{2}$ University of Science and Technology of China <br> China <br> yxt95@mail.ustc.edu.cn</h2>
<p>Xinming Zhang ${ }^{2 \dagger}$<br>${ }^{2}$ University of Science and Technology of China<br>China<br>xinming@ustc.edu.cn</p>
<p>Neural Networks. In Proceedings of the ACM Web Conference 2023 (WWW '23), May 1-5, 2023, Austin, TX, USA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3543507.3583386</p>
<h2>1 INTRODUCTION</h2>
<p>The ubiquitous Web is becoming the ultimate data repository, capable of linking a broad spectrum of objects to form gigantic and complex graphs. The prevalence of graph data enables a series of downstream tasks for Web applications, ranging from online page/article classification to friend recommendation in social networks. Modern approaches for graph analysis generally resort to graph representation learning including graph embedding and graph neural networks (GNNs). Earlier graph embedding approaches [12, 33, 41] usually embed nodes on the graph into a low-dimensional space, in which the structural information such as the proximity between nodes can be captured [5]. More recently, GNNs [13, 20, 43, 50] have emerged as the state of the art for graph representation learning. Their key idea boils down to a message-passing framework, in which each node derives its representation by receiving and aggregating messages from its neighboring nodes recursively [48].
Graph pre-training. Typically, GNNs work in an end-to-end manner, and their performance depends heavily on the availability of large-scale, task-specific labeled data as supervision. This supervised paradigm presents two problems. First, task-specific supervision is often difficult or costly to obtain. Second, to deal with a new task, the weights of GNN models need to be retrained from scratch, even if the task is on the same graph. To address these issues, pretraining GNNs $[15,16,30,34]$ has become increasingly popular, inspired by pre-training techniques in language and vision applications [1, 7]. The pre-training of GNNs leverages self-supervised learning on more readily available label-free graphs (i.e., graphs without task-specific labels), and learns intrinsic graph properties that intend to be general across tasks and graphs in a domain. In other words, the pre-training extracts a task-agnostic prior, and can be used to initialize model weights for a new task. Subsequently, the initial weights can be quickly updated through a lightweight fine-tuning step on a smaller number of task-specific labels.</p>
<p>However, the "pre-train, fine-tune" paradigm suffers from the problem of inconsistent objectives between pre-training and downstream tasks, resulting in suboptimal performance [23]. On one hand, the pre-training step aims to preserve various intrinsic graph</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Illustration of the motivation. (a) Pre-training on graphs. (b/c) Downstream node/graph classification.
properties such as node/edge features [15, 16], node connectivity/links [13, 16, 30], and local/global patterns [15, 30, 34]. On the other hand, the fine-tuning step aims to reduce the task loss, i.e., to fit the ground truth of the downstream task. The discrepancy between the two steps can be quite large. For example, pre-training may focus on learning the connectivity pattern between two nodes (i.e., related to link prediction), whereas fine-tuning could be dealing with a node or graph property (i.e., node classification or graph classification task).
Prior work. To narrow the gap between pre-training and downstream tasks, prompting [4] has first been proposed for language models, which is a natural language instruction designed for a specific downstream task to "prompt out" the semantic relevance between the task and the language model. Meanwhile, the parameters of the pre-trained language model are frozen without any finetuning, as the prompt can "pull" the task toward the pre-trained model. Thus, prompting is also more efficient than fine-tuning, especially when the pre-trained model is huge. Recently, prompting has also been introduced to graph pre-training in the GPPT approach [39]. While the pioneering work has proposed a sophisticated design of pre-training and prompting, it can only be employed for the node classification task, lacking a universal treatment that appeals to different downstream tasks such as both node classification and graph classification.
Research problem and challenges. To address the divergence between graph pre-training and various downstream tasks, in this paper we investigate the design of pre-training and prompting for graph neural networks. In particular, we aim for a unified design that can suit different downstream tasks flexibly. This problem is non-trivial due to the following two challenges.</p>
<p>Firstly, to enable effective knowledge transfer from the pretraining to a downstream task, it is desirable that the pre-training step preserves graph properties that are compatible with the given task. However, since different downstream tasks often have different objectives, how do we unify pre-training with various downstream
tasks on graphs, so that a single pre-trained model can universally support different tasks? That is, we try to convert the pre-training task and downstream tasks to follow the same "template". Using pretrained language models as an analogy, both their pre-training and downstream tasks can be formulated as masked language modeling.</p>
<p>Secondly, under the unification framework, it is still important to identify the distinction between different downstream tasks, in order to attain task-specific optima. For pre-trained language models, prompts in the form of natural language tokens or learnable word vectors have been designed to give different hints to different tasks, but it is less apparent what form prompts on graphs should take. Hence, how do we design prompts on graphs, so that they can guide different downstream tasks to effectively make use of the pre-trained model?
Present work. To address these challenges, we propose a novel graph pre-training and prompting framework, called GraphPrompt, aiming to unify the pre-training and downstream tasks for GNNs. Drawing inspiration from the prompting strategy for pre-trained language models, GraphPrompt capitalizes on a unified template to define the objectives for both pre-training and downstream tasks, thus bridging their gap. We further equip GraphPrompt with taskspecific learnable prompts, which guides the downstream task to exploit relevant knowledge from the pre-trained GNN model. The unified approach endows GraphPrompt with the ability of working on limited supervision such as few-shot learning tasks.</p>
<p>More specifically, to address the first challenge of unification, we focus on graph topology, which is a key enabler of graph models. In particular, subgraph is a universal structure that can be leveraged for both node- and graph-level tasks. At the node level, the information of a node can be enriched and represented by its contextual subgraph, i.e., a subgraph where the node resides in [17, 55]; at the graph level, the information of a graph is naturally represented by the maximum subgraph (i.e., the graph itself). Consequently, we unify both the node- and graph-level tasks, whether in pre-training or downstream, into the same template: the similarity calculation of (sub)graph ${ }^{1}$ representations. In this work, we adopt link prediction as the self-supervised pre-training task, given that links are readily available in any graph without additional annotation cost. Meanwhile, we focus on the popular node classification and graph classification as downstream tasks, which are node- and graphlevel tasks, respectively. All these tasks can be cast as instances of learning subgraph similarity. On one hand, the link prediction task in pre-training boils down to the similarity between the contextual subgraphs of two nodes, as shown in Fig. 1(a). On the other hand, the downstream node or graph classification task boils down to the similarity between the target instance (a node's contextual subgraph or the whole graph, resp.) and the class prototypical subgraphs constructed from labeled data, as illustrated in Figs. 1(b) and (c). The unified template bridges the gap between the pre-training and different downstream tasks.</p>
<p>Toward the second challenge, we distinguish different downstream tasks by way of the ReadOut operation on subgraphs. The ReadOut operation is essentially an aggregation function to fuse</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>node representations in the subgraph into a single subgraph representation. For instance, sum pooling, which sums the representations of all nodes in the subgraph, is a practical and popular scheme for READOut. However, different downstream tasks can benefit from different aggregation schemes for their READOut. In particular, node classification tends to focus on features that can contribute to the representation of the target node, while graph classification tends to focus on features associated with the graph class. Motivated by such differences, we propose a novel task-specific learnable prompt to guide the READOut operation of each downstream task with an appropriate aggregation scheme. As shown in Fig. 1, the learnable prompt serves as the parameters of the READOut operation of downstream tasks, and thus enables different aggregation functions on the subgraphs of different tasks. Hence, GraphPrompt not only unifies the pre-training and downstream tasks into the same template based on subgraph similarity, but also recognizes the differences between various downstream tasks to guide taskspecific objectives.
Contributions. To summarize, our contributions are three-fold. (1) We recognize the gap between graph pre-training and downstream tasks, and propose a unification framework GraphPrompt based on subgraph similarity for both pre-training and downstream tasks, including both node and graph classification tasks. (2) We propose a novel prompting strategy for GraphPrompt, hinging on a learnable prompt to actively guide downstream tasks using task-specific aggregation in READOut, in order to drive the downstream tasks to exploit the pre-trained model in a task-specific manner. (3) We conduct extensive experiments on five public datasets, and the results demonstrate the superior performance of GraphPrompt in comparison to the state-of-the-art approaches.</p>
<h2>2 RELATED WORK</h2>
<p>Graph representation learning. The rise of graph representation learning, including earlier graph embedding [12, 33, 41] and recent GNNs [13, 20, 43, 50], opens up great opportunities for various downstream tasks at node and graph levels. Note that learning graph-level representations requires an additional READOut operation which summarizes the global information of a graph by aggregating node representations through a flat $[8,11,50,56]$ or hierarchical [10, 21, 31, 51] pooling algorithm. We refer the readers to two comprehensive surveys [5, 48] for more details.
Graph pre-training. Inspired by the application of pre-training models in language [2, 7] and vision [1, 29] domains, graph pretraining [49] emerges as a powerful paradigm that leverages selfsupervision on label-free graphs to learn intrinsic graph properties. While the pre-training learns a task-agnostic prior, a relatively light-weight fine-tuning step is further employed to update the pre-trained weights to fit a given downstream task. Different pretraining approaches design different self-supervised tasks based on various graph properties such as node features [15, 16], links [13, 16, 19, 30], local or global patterns [15, 30, 34], local-global consistency [14, 32, 37, 44], and their combinations [40, 52, 53].</p>
<p>However, the above approaches do not consider the gap between pre-training and downstream objectives, which limits their generalization ability to handle different tasks. Some recent studies recognize the importance of narrowing this gap. L2P-GNN [30]
capitalizes on meta-learning [9] to simulate the fine-tuning step during pre-training. However, since the downstream tasks can still differ from the simulation task, the problem is not fundamentally addressed. In other fields, as an alternative to fine-tuning, researchers turn to prompting [4], in which a task-specific prompt is used to cue the downstream tasks. Prompts can be either handcrafted [4] or learnable [22, 24]. On graph data, the study of prompting is still limited. One recent work called GPPT [39] capitalizes on a sophisticated design of learnable prompts on graphs, but it only works with node classification, lacking a unification effort to accommodate other downstream tasks like graph classification. Besides, there is a model also named as GraphPrompt [54], but it considers an NLP task (biomedical entity normalization) on text data, where graph is only auxiliary. It employs the standard text prompt unified by masked language modeling, assisted by a relational graph to generate text templates, which is distinct from our work.
Comparison to other settings. Our few-shot setting is different from other paradigms that also deal with label scarcity, including semi-supervised learning [20] and meta-learning [9]. In particular, semi-supervised learning cannot cope with novel classes not seen in training, while meta-learning requires a large volume of labeled data in their base classes for a meta-training phase, before they can handle few-shot tasks in testing.</p>
<h2>3 PRELIMINARIES</h2>
<p>In this section, we give the problem definition and introduce the background of GNNs.</p>
<h3>3.1 Problem Definition</h3>
<p>Graph. A graph can be defined as $G=(V, E)$, where $V$ is the set of nodes and $E$ is the set of edges. We also assume an input feature matrix of the nodes, $\mathbf{X} \in \mathbb{R}^{|V| \times d}$, is available. Let $\mathbf{x}<em i="i">{i} \in \mathbb{R}^{d}$ denote the feature vector of node $v</em>\right}$.
Problem. In this paper, we investigate the problem of graph pretraining and prompting. For the downstream tasks, we consider the popular node classification and graph classification tasks. For node classification on a graph $G=(V, E)$, let $C$ be the set of node classes with $t_{i} \in C$ denoting the class label of node $v_{i} \in V$. For graph classification on a set of graphs $\mathcal{G}$, let $\mathcal{C}$ be the set of graph labels with $L_{i} \in \mathcal{C}$ denoting the class label of graph $G_{i} \in \mathcal{G}$.} \in V$. In addition, we denote a set of graphs as $\mathcal{G}=\left{G_{1}, G_{2}, \ldots, G_{N</p>
<p>In particular, the downstream tasks are given limited supervision in a few-shot setting: for each class in the two tasks, only $k$ labeled samples (i.e., nodes or graphs) are provided, known as $k$-shot classification.</p>
<h3>3.2 Graph Neural Networks</h3>
<p>The success of GNNs boils down to the message-passing mechanism [48], in which each node receives and aggregates messages (i.e., features or embeddings) from its neighboring nodes to generate its own representation. This operation of neighborhood aggregation can be stacked in multiple layers to enable recursive message passing. Formally, in the $l$-th GNN layer, the embedding of node $v$, denoted by $\mathbf{h}_{v}^{l}$, is calculated based on the embeddings in the</p>
<p>previous layer, as follows.</p>
<p>$$
\mathbf{h}<em v="v">{v}^{l}=\operatorname{AGGR}\left(\mathbf{h}</em>}^{l-1},\left{\mathbf{h<em v="v">{v}^{l-1}: u \in \mathcal{N}</em>\right)
$$}\right} ; \theta^{l</p>
<p>where $\mathcal{N}<em v="v">{v}$ is the set of neighboring nodes of $v, \theta^{l}$ is the learnable GNN parameters in layer $l$. AGGR $(\cdot)$ is the neighborhood aggregation function and can take various forms, ranging from the simple mean pooling $[13,20]$ to advanced neural networks such as neural attention [43] or multi-layer perceptrons [50]. Note that in the first layer, the input node embedding $\mathbf{h}</em>$.}^{0}$ can be initialized as the node features in $\mathbf{X}$. The total learnable GNN parameters can be denoted as $\Theta=\left{\theta^{1}, \theta^{2}, \ldots\right}$. For brevity, we simply denote the output node representations of the last layer as $\mathbf{h}_{v</p>
<h2>4 PROPOSED APPROACH</h2>
<p>In this section, we present our proposed approach GraphPrompt.</p>
<h3>4.1 Unification Framework</h3>
<p>We first introduce the overall framework of GraphPrompt in Fig. 2. Our framework is deployed on a set of label-free graphs shown in Fig. 2(a), for pre-training in Fig. 2(b). The pre-training adopts a link prediction task, which is self-supervised without requiring extra annotation. Afterward, in Fig. 2(c), we capitalize on a learnable prompt to guide each downstream task, namely, node classification or graph classification, for task-specific exploitation of the pretrained model. In the following, we explain how the framework supports a unified view of pre-training and downstream tasks.
Instances as subgraphs. The key to the unification of pre-training and downstream tasks lies in finding a common template for the tasks. The task-specific prompt can then be further fused with the template of each downstream task, to distinguish the varying characteristics of different tasks.</p>
<p>In comparison to other fields such as visual and language processing, graph learning is uniquely characterized by the exploitation of graph topology. In particular, subgraph is a universal structure capable of expressing both node- and graph-level instances. On one hand, at the node level, every node resides in a local neighborhood, which in turn contextualizes the node [25, 27, 28]. The local neighborhood of a node $v$ on a graph $G=(V, E)$ is usually defined by a contextual subgraph $S_{v}=\left(V\left(S_{v}\right), E\left(S_{v}\right)\right)$, where its set of nodes and edges are respectively given by</p>
<p>$$
\begin{aligned}
&amp; V\left(S_{v}\right)={d(u, v) \leq \delta \mid u \in V}, \text { and } \
&amp; E\left(S_{v}\right)=\left{\left(u, u^{\prime}\right) \in E \mid u \in V\left(S_{v}\right), u^{\prime} \in V\left(S_{v}\right)\right}
\end{aligned}
$$</p>
<p>where $d(u, v)$ gives the shortest distance between nodes $u$ and $v$ on the graph $G$, and $\delta$ is a predetermined threshold. That is, $S_{v}$ consists of nodes within $\delta$ hops from the node $v$, and the edges between those nodes. Thus, the contextual subgraph $S_{v}$ embodies not only the self-information of the node $v$, but also rich contextual information to complement the self-information [17, 55]. On the other hand, at the graph level, the maximum subgraph of a graph $G$, denoted $S_{G}$, is the graph itself, i.e., $S_{G}=G$. The maximum subgraph $S_{G}$ spontaneously embodies all information of $G$. In summary, subgraphs can be used to represent both node- and graph-level instances: Given an instance $x$ which can either be a node or a graph (e.g., $x=v$ or $x=G$ ), the subgraph $S_{x}$ offers a unified access to the information associated with $x$.</p>
<p>Unified task template. Based on the above subgraph definitions for both node- and graph-level instances, we are ready to unify different tasks to follow a common template. Specifically, the link prediction task in pre-training and the downstream node and graph classification tasks can all be redefined as subgraph similarity learning. Let $\mathbf{s}<em x="x">{x}$ be the vector representation of the subgraph $S</em>(\cdot, \cdot)$ be the cosine similarity function. As illustrated in Figs. 2(b) and (c), the three tasks can be mapped to the computation of subgraph similarity, which is formalized below.}$, and $\operatorname{sim</p>
<ul>
<li>Link prediction: This is a node-level task. Given a graph $G=$ $(V, E)$ and a triplet of nodes $(v, a, b)$ such that $(v, a) \in E$ and $(v, b) \notin E$, we shall have</li>
</ul>
<p>$$
\operatorname{sim}\left(\mathbf{s}<em a="a">{v}, \mathbf{s}</em>}\right)&gt;\operatorname{sim}\left(\mathbf{s<em b="b">{v}, \mathbf{s}</em>\right)
$$</p>
<p>Intuitively, the contextual subgraph of $v$ shall be more similar to that of a node linked to $v$ than that of another unlinked node.</p>
<ul>
<li>Node classification: This is also a node-level task. Consider a graph $G=(V, E)$ with a set of node classes $C$, and a set of labeled nodes $D=\left{\left(v_{1}, t_{1}\right),\left(v_{2}, t_{2}\right), \ldots\right}$ where $v_{i} \in V$ and $t_{i}$ is the corresponding label of $v_{i}$. As we adopt a $k$-shot setting, there are exactly $k$ pairs of $\left(v_{i}, t_{i}=c\right) \in D$ for every class $c \in C$. For each class $c \in C$, further define a node class prototypical subgraph represented by a vector $\tilde{\mathbf{s}}_{c}$, given by</li>
</ul>
<p>$$
\tilde{\mathbf{s}}<em _left_v__i="\left(v_{i">{c}=\frac{1}{k} \sum</em>}, t_{i}\right) \in D, t_{i}=c} \mathbf{s<em i="i">{v</em>
$$}</p>
<p>Note that the class prototypical subgraph is a "virtual" subgraph with a latent representation in the same embedding space as the node contextual subgraphs. Basically, it is constructed as the mean representation of the contextual subgraphs of labeled nodes in a given class. Then, given a node $v_{j}$ not in the labeled set $D$, its class label $\ell_{j}$ shall be</p>
<p>$$
\ell_{j}=\arg \max <em v__j="v_{j">{c \in C} \operatorname{sim}\left(\mathbf{s}</em>\right)
$$}}, \tilde{\mathbf{s}}_{c</p>
<p>Intuitively, a node shall belong to the class whose prototypical subgraph is the most similar to the node's contextual subgraph.</p>
<ul>
<li>Graph classification: This is a graph-level task. Consider a set of graphs $\mathcal{G}$ with a set of graph classes $\mathcal{C}$, and a set of labeled graphs $\mathcal{D}=\left{\left(G_{1}, L_{1}\right),\left(G_{2}, L_{2}\right), \ldots\right}$ where $G_{i} \in \mathcal{G}$ and $L_{i}$ is the corresponding label of $G_{i}$. In the $k$-shot setting, there are exactly $k$ pairs of $\left(G_{i}, L_{i}=c\right) \in \mathcal{D}$ for every class $c \in \mathcal{C}$. Similar to node classification, for each class $c \in \mathcal{C}$, we define a graph class prototypical subgraph, also represented by the mean embedding vector of the (sub)graphs in $c$ :</li>
</ul>
<p>$$
\tilde{\mathbf{s}}<em _left_G__i="\left(G_{i">{c}=\frac{1}{k} \sum</em>}, L_{i}\right) \in \mathcal{D}, L_{i}=c} \mathbf{s<em i="i">{G</em>
$$}</p>
<p>Then, given a graph $G_{j}$ not in the labeled set $\mathcal{D}$, its class label $L_{j}$ shall be</p>
<p>$$
L_{j}=\arg \max <em G__j="G_{j">{c \in \mathcal{C}} \operatorname{sim}\left(\mathbf{s}</em>\right)
$$}}, \tilde{\mathbf{s}}_{c</p>
<p>Intuitively, a graph shall belong to the class whose prototypical subgraph is the most similar to itself.
It is worth noting that node and graph classification can be further condensed into a single set of notations. Let $(x, y)$ be an</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Overall framework of GraphPrompt.</p>
<p>annotated instance of graph data, i.e., $x$ is either a node or a graph, and $y \in Y$ is the class label of $x$ among the set of classes $Y$. Then,</p>
<p>$$
y=\arg \max <em x="x">{c \in Y} \operatorname{sim}\left(\mathbf{s}</em>\right)
$$}, \hat{\mathbf{s}}_{c</p>
<p>Finally, to materialize the common task template, we discuss how to learn the subgraph embedding vector $\mathbf{s}<em x="x">{x}$ for the subgraph $S</em>}$. Given node representations $\mathbf{h<em x="x">{v}$ generated by a GNN (see Sect. 3.2), a standard approach of computing $\mathbf{s}</em>$. That is,}$ is to employ a READOut operation that aggregates the representations of nodes in the subgraph $S_{x</p>
<p>$$
\mathbf{s}<em v="v">{x}=\operatorname{READOUT}\left(\left{\mathbf{h}</em>\right)\right}\right)
$$}: v \in V\left(S_{x</p>
<p>The choice of the aggregation scheme for READOut is flexible, including sum pooling and more advanced techniques [50, 51]. In our implementation, we simply use sum pooling.</p>
<p>In summary, the unification framework is enabled by the common task template of subgraph similarity learning, which lays the foundation of our pre-training and prompting strategies as we will introduce in the following parts.</p>
<h3>4.2 Pre-Training Phase</h3>
<p>As discussed earlier, our pre-training phase employs the link prediction task. Using link prediction/generation is a popular and natural way [13, 16, 18, 30], as a vast number of links are readily available on large-scale graph data without extra annotation. In other words, the link prediction objective can be optimized on label-free graphs, such as those shown in Fig. 2(a), in a self-supervised manner.</p>
<p>Based on the common template defined in Sect. 4.1, the link prediction task is anchored on the similarity of the contextual subgraphs of two candidate nodes. Generally, the subgraphs of two positive (i.e., linked) candidates shall be more similar than those of negative (i.e., non-linked) candidates, as illustrated in Fig. 2(b). Subsequently, the pre-trained prior on subgraph similarity can be naturally transferred to node classification downstream, which shares a similar intuition: the subgraphs of nodes in the same class shall be more similar than those of nodes from different classes. On the other hand, the prior can also support graph classification
downstream, as graph similarity is consistent with subgraph similarity not only in letter (as a graph is technically always a subgraph of itself), but also in spirit. The "spirit" here refers to the tendency that graphs sharing similar subgraphs are likely to be similar themselves, which means graph similarity can be translated into the similarity of the containing subgraphs [36, 42, 56].</p>
<p>Formally, given a node $v$ on graph $G$, we randomly sample one positive node $a$ from $v$ 's neighbors, and a negative node $b$ from the graph that does not link to $v$, forming a triplet $(v, a, b)$. Our objective is to increase the similarity between the contextual subgraphs $S_{v}$ and $S_{a}$, while decreasing that between $S_{v}$ and $S_{b}$. More generally, on a set of label-free graphs $\mathcal{G}$, we sample a number of triplets from each graph to construct an overall training set $\mathcal{T}_{\text {pre }}$. Then, we define the following pre-training loss.</p>
<p>$$
\mathcal{L}<em T__mathrm_pre="T_{\mathrm{pre" _in="\in" _v_="(v," a_="a," b_="b)">{\mathrm{pre}}(\Theta)=-\sum</em>}}} \ln \frac{\exp \left(\operatorname{sim}\left(\mathbf{s<em a="a">{v}, \mathbf{s}</em>}\right) / \tau\right)}{\sum_{u \in{a, b}} \exp \left(\operatorname{sim}\left(\mathbf{s<em u="u">{v}, \mathbf{s}</em>
$$}\right) / \tau\right)</p>
<p>where $\tau$ is a temperature hyperparameter to control the shape of the output distribution. Note that the loss is parameterized by $\Theta$, which represents the GNN model weights.</p>
<p>The output of the pre-training phase is the optimal model parameters $\Theta_{0}=\arg \min <em _pre="{pre" _text="\text">{\Theta} \mathcal{L}</em>$ can be used to initialize the GNN weights for downstream tasks, thus enabling the transfer of prior knowledge downstream.}}(\Theta) . \Theta_{0</p>
<h3>4.3 Prompting for Downstream Tasks</h3>
<p>The unification of pre-training and downstream tasks enables more effective knowledge transfer as the tasks in the two phases are made more compatible by following a common template. However, it is still important to distinguish different downstream tasks, in order to capture task individuality and achieve task-specific optimum.</p>
<p>To cope with this challenge, we propose a novel task-specific learnable prompt on graphs, inspired by prompting in natural language processing [4]. In language contexts, a prompt is initially a handcrafted instruction to guide the downstream task, which provides task-specific cues to extract relevant prior knowledge</p>
<p>through a unified task template (typically, pre-training and downstream tasks are all mapped to masked language modeling). More recently, learnable prompts [22, 24] have been proposed as an alternative to handcrafted prompts, to alleviate the high engineering cost of the latter.
Prompt design. Nevertheless, our proposal is distinctive from language-based prompting for two reasons. Firstly, we have a different task template from masked language modeling. Secondly, since our prompts are designed for graph structures, they are more abstract and cannot take the form of language-based instructions. Thus, they are virtually impossible to be handcrafted. Instead, they should be topology related to align with the core of graph learning. In particular, under the same task template of subgraph similarity learning, the ReadOut operation (used to generate the subgraph representation) can be "prompted" differently for different downstream tasks. Intuitively, different tasks can benefit from different aggregation schemes for their ReadOut. For instance, node classification pays more attention to features that are topically more relevant to the target node. In contrast, graph classification tends to focus on features that are correlated to the graph class. Moreover, the important features may also vary given different sets of instances or classes in a task.</p>
<p>Formally, let $\mathbf{p}<em x="x">{t}$ denote a learnable prompt vector for a downstream task $t$, as shown in Fig. 2(c). The prompt-assisted ReadOut operation on a subgraph $S</em>$ for task $t$ is</p>
<p>$$
\mathbf{s}<em t="t">{t, x}=\operatorname{ReadOut}\left(\left{\mathbf{p}</em>} \odot \mathbf{h<em x="x">{v}: v \in V\left(S</em>\right)\right}\right)
$$</p>
<p>where $\mathbf{s}<em t="t">{t, x}$ is the task $t$-specific subgraph representation, and $\odot$ denotes the element-wise multiplication. That is, we perform a feature weighted summation of the node representations from the subgraph, where the prompt vector $\mathbf{p}</em>$ is a dimension-wise reweighting in order to extract the most relevant prior knowledge for the task $t$.</p>
<p>Note that other prompt designs are also possible. For example, we could consider a learnable prompt matrix $\mathbf{P}_{t}$, which applies a linear transformation to the node representations:</p>
<p>$$
\mathbf{s}<em t="t">{t, x}=\operatorname{ReadOut}\left(\left{\mathbf{P}</em>} \mathbf{h<em x="x">{v}: v \in V\left(S</em>\right)\right}\right)
$$</p>
<p>More complex prompts such as an attention layer is another alternative. However, one of the main motivation of prompting instead of fine-tuning is to reduce reliance on labeled data. In few-shot settings, given very limited supervision, prompts with fewer parameters are preferred to mitigate the risk of overfitting. Hence, the feature weighting scheme in Eq. (12) is adopted for our prompting as the prompt is a single vector of the same length as the node representation, which is typically a small number (e.g., 128).
Prompt tuning. To optimize the learnable prompt, also known as prompt tuning, we formulate the loss based on the common template of subgraph similarity, using the prompt-assisted taskspecific subgraph representations.</p>
<p>Formally, consider a task $t$ with a labeled training set $\mathcal{T}<em 1="1">{t}=$ $\left{\left(x</em>$ among the set of classes $Y$. The loss for prompt tuning is defined as}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots\right}$, where $x_{i}$ is an instance (i.e., a node or a graph), and $y_{i} \in Y$ is the class label of $x_{i</p>
<p>$$
\mathcal{L}<em t="t">{\text {prompt }}\left(\mathbf{p}</em>}\right)=-\sum_{\left(x_{i}, y_{i}\right) \in \mathcal{T<em t_="t," x__i="x_{i">{t}} \ln \frac{\exp \left(\operatorname{sim}\left(\mathbf{s}</em>}}, \hat{\mathbf{s}<em i="i">{t, y</em>}}\right) / \tau\right)}{\sum_{c \in Y} \exp \left(\operatorname{sim}\left(\mathbf{s<em i="i">{t, x</em>
$$}}, \hat{\mathbf{s}}_{t, c}\right) / \tau\right)</p>
<p>Table 1: Summary of datasets.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Graphs</th>
<th style="text-align: center;">Graph <br> classes</th>
<th style="text-align: center;">Avg. <br> nodes</th>
<th style="text-align: center;">Avg. <br> edges</th>
<th style="text-align: center;">Node <br> features</th>
<th style="text-align: center;">Node <br> classes</th>
<th style="text-align: center;">Task <br> (N/G)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Flickr</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">89,250</td>
<td style="text-align: center;">899,756</td>
<td style="text-align: center;">500</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">N</td>
</tr>
<tr>
<td style="text-align: left;">PROTEINS</td>
<td style="text-align: center;">1,113</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">39.06</td>
<td style="text-align: center;">72.82</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">N, G</td>
</tr>
<tr>
<td style="text-align: left;">COX2</td>
<td style="text-align: center;">467</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">41.22</td>
<td style="text-align: center;">43.45</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">G</td>
</tr>
<tr>
<td style="text-align: left;">ENZYMES</td>
<td style="text-align: center;">600</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">32.63</td>
<td style="text-align: center;">62.14</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">N, G</td>
</tr>
<tr>
<td style="text-align: left;">BZR</td>
<td style="text-align: center;">405</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">35.75</td>
<td style="text-align: center;">38.36</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">G</td>
</tr>
</tbody>
</table>
<p>where the class prototypical subgraph for class $c$ is represented by $\hat{\mathbf{s}}_{t, c}$, which is also generated by the prompt-assisted, task-specific READOut.</p>
<p>Note that, the prompt tuning loss is only parameterized by the learnable prompt vector $\mathbf{p}<em 0="0">{t}$, without the GNN weights. Instead, the pre-trained GNN weights $\Theta</em>$ are frozen for downstream tasks, as no fine-tuning is necessary. This significantly decreases the number of parameters to be updated downstream, thus not only improving the computational efficiency of task learning and inference, but also reducing the reliance on labeled data.</p>
<h2>5 EXPERIMENTS</h2>
<p>In this section, we conduct extensive experiments including node classification and graph classification as downstream tasks on five benchmark datasets to evaluate the proposed GraphPrompt.</p>
<h3>5.1 Experimental Setup</h3>
<p>Datasets. We employ five benchmark datasets for evaluation. (1) Flickr [47] is an image sharing network. (2) PROTEINS [3] is a collection of protein graphs which include the amino acid sequence, conformation, structure, and features such as active sites of the proteins. (3) COX2 [35] is a dataset of molecular structures including 467 cyclooxygenase-2 inhibitors. (4) ENZYMES [46] is a dataset of 600 enzymes collected from the BRENDA enzyme database. (5) BZR [35] is a collection of 405 ligands for benzodiazepine receptor.</p>
<p>We summarize these datasets in Table 1, and present further details in Appendix B. Note that the "Task" column indicates the type of downstream task performed on each dataset: "N" for node classification and "G" for graph classification.
Baselines. We evaluate GraphPrompt against the state-of-the-art approaches from three main categories, as follows. (1) End-to-end graph neural networks: GCN [20], GraphSAGE [13], GAT [43] and GIN [50]. They capitalize on the key operation of neighborhood aggregation to recursively aggregate messages from the neighbors, and work in an end-to-end manner. (2) Graph pre-training models: DGI [44], InfoGraph [38], and GraphCL [53]. They work in the "pretrain, fine-tune" paradigm. In particular, they pre-train the GNN models to preserve the intrinsic graph properties, and fine-tune the pre-trained weights on downstream tasks to fit task labels. (3) Graph prompt models: GPPT [39]. GPPT utilizes a link prediction task for pre-training, and resorts to a learnable prompt for the node classification task, which is mapped to a link prediction task.</p>
<p>Note that other few-shot learning methods on graphs, such as Meta-GNN [57] and RALE [26], adopt a meta-learning paradigm [9]. Thus, they cannot be used in our setting, as they require labeled data</p>
<p>in their base classes for the meta-training phase. In our approach, only label-free graphs are utilized for pre-training.
Settings and parameters. To evaluate the goal of our GraphPrompt in realizing a unified design that can suit different downstream tasks flexibly, we consider two typical types of downstream tasks, i.e., node classification and graph classification. In particular, for the datasets which are suitable for both of these two tasks, i.e., PROTEINS and ENZYMES, we only pre-train the GNN model once on each dataset, and utilize the same pre-trained model for the two downstream tasks with their task-specific prompting.</p>
<p>The downstream tasks follow a $k$-shot classification setting. For each type of downstream task, we construct a series of $k$-shot classification tasks. The details of task construction will be elaborated later when reporting the results in Sect. 5.2. For task evaluation, as the $k$-shot tasks are balanced classification, we employ accuracy as the evaluation metric following earlier work [26, 45].</p>
<p>For all the baselines, based on the authors' code and default settings, we further tune their hyper-parameters to optimize their performance. We present more implementation details of the baselines and our GraphPrompt in Appendix D.</p>
<h3>5.2 Performance Evaluation</h3>
<p>As discussed, we perform two types of downstream task different from the link prediction task in pre-training, namely, node classification and graph classification in few-shot settings. We first evaluate on a fixed-shot setting, and then vary the shot numbers to see the performance trend.
Few-shot node classification. We conduct this node-level task on three datasets, i.e., Flickr, PROTEINS, and ENZYMES. Following a typical $k$-shot setup [26, 45, 57], we generate a series of few-shot tasks for model training and validation. In particular, for PROTEINS and ENZYMES, on each graph we randomly generate ten 1-shot node classification tasks (i.e., in each task, we randomly sample 1 node per class) for training and validation, respectively. Each training task is paired with a validation task, and the remaining nodes not sampled by the pair of training and validation tasks will be used for testing. For Flickr, as it contains a large number of very sparse node features, selecting very few shots for training may result in inferior performance for all the methods. Therefore, we randomly generate ten 50 -shot node classification tasks, for training and validation, respectively. On Flickr, 50 shots are still considered few, accounting for less than $0.06 \%$ of all nodes on the graph.</p>
<p>Table 2 illustrates the results of few-shot node classification. We have the following observations. First, our proposed GraphPrompt outperforms all the baselines across the three datasets, demonstrating the effectiveness of GraphPrompt in transferring knowledge from the pre-training to downstream tasks. In particular, by virtue of the unification framework and prompt-based task-specific aggregation in ReadOut function, GraphPrompt is able to narrow the gap between pre-training and downstream tasks, and guide the downstream tasks to exploit the pre-trained model in a task-specific manner. Second, compared to graph pre-training models, end-toend GNN models can sometimes achieve comparable or even better performance. This implies that the discrepancy between the pretraining and downstream tasks in these pre-training approaches obstructs the knowledge transfer from the former to the latter. In</p>
<p>Table 2: Accuracy evaluation on node classification.
All tabular results are in percent, with best bolded and runner-up underlined.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: center;">Flickr <br> 50 -shot</th>
<th style="text-align: center;">PROTEINS <br> 1-shot</th>
<th style="text-align: center;">ENZYMES <br> 1-shot</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GCN</td>
<td style="text-align: center;">$9.22 \pm 9.49$</td>
<td style="text-align: center;">$59.60 \pm 12.44$</td>
<td style="text-align: center;">$61.49 \pm 12.87$</td>
</tr>
<tr>
<td style="text-align: left;">GraphSAGE</td>
<td style="text-align: center;">$13.52 \pm 11.28$</td>
<td style="text-align: center;">$59.12 \pm 12.14$</td>
<td style="text-align: center;">$61.81 \pm 13.19$</td>
</tr>
<tr>
<td style="text-align: left;">GAT</td>
<td style="text-align: center;">$16.02 \pm 12.72$</td>
<td style="text-align: center;">$58.14 \pm 12.05$</td>
<td style="text-align: center;">$60.77 \pm 13.21$</td>
</tr>
<tr>
<td style="text-align: left;">GIN</td>
<td style="text-align: center;">$10.18 \pm 5.41$</td>
<td style="text-align: center;">$\underline{60.53} \pm 12.19$</td>
<td style="text-align: center;">$\underline{63.81} \pm 11.28$</td>
</tr>
<tr>
<td style="text-align: left;">DGI</td>
<td style="text-align: center;">$17.71 \pm 1.09$</td>
<td style="text-align: center;">$54.92 \pm 18.46$</td>
<td style="text-align: center;">$63.33 \pm 18.13$</td>
</tr>
<tr>
<td style="text-align: left;">GraphCL</td>
<td style="text-align: center;">$18.37 \pm 1.72$</td>
<td style="text-align: center;">$52.00 \pm 15.83$</td>
<td style="text-align: center;">$58.73 \pm 16.47$</td>
</tr>
<tr>
<td style="text-align: left;">GPPT</td>
<td style="text-align: center;">$\underline{18.95} \pm 1.92$</td>
<td style="text-align: center;">$50.83 \pm 16.56$</td>
<td style="text-align: center;">$53.79 \pm 17.46$</td>
</tr>
<tr>
<td style="text-align: left;">GraphPrompt</td>
<td style="text-align: center;">$\mathbf{2 0 . 2 1} \pm 11.52$</td>
<td style="text-align: center;">$\mathbf{6 3 . 0 3} \pm 12.14$</td>
<td style="text-align: center;">$\mathbf{6 7 . 0 4} \pm 11.48$</td>
</tr>
</tbody>
</table>
<p>Table 3: Accuracy evaluation on graph classification.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: center;">PROTEINS <br> 5 -shot</th>
<th style="text-align: center;">COX2 <br> 5 -shot</th>
<th style="text-align: center;">ENZYMES <br> 5 -shot</th>
<th style="text-align: center;">BZR <br> 5 -shot</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GCN</td>
<td style="text-align: center;">$54.87 \pm 11.20$</td>
<td style="text-align: center;">$51.37 \pm 11.06$</td>
<td style="text-align: center;">$20.37 \pm 5.24$</td>
<td style="text-align: center;">$56.16 \pm 11.07$</td>
</tr>
<tr>
<td style="text-align: left;">GraphSAGE</td>
<td style="text-align: center;">$52.99 \pm 10.57$</td>
<td style="text-align: center;">$52.87 \pm 11.46$</td>
<td style="text-align: center;">$18.31 \pm 6.22$</td>
<td style="text-align: center;">$57.23 \pm 10.95$</td>
</tr>
<tr>
<td style="text-align: left;">GAT</td>
<td style="text-align: center;">$48.78 \pm 18.46$</td>
<td style="text-align: center;">$51.20 \pm 27.93$</td>
<td style="text-align: center;">$15.90 \pm 4.13$</td>
<td style="text-align: center;">$53.19 \pm 20.61$</td>
</tr>
<tr>
<td style="text-align: left;">GIN</td>
<td style="text-align: center;">$\underline{58.17} \pm 8.58$</td>
<td style="text-align: center;">$51.89 \pm 8.71$</td>
<td style="text-align: center;">$20.34 \pm 5.01$</td>
<td style="text-align: center;">$57.45 \pm 10.54$</td>
</tr>
<tr>
<td style="text-align: left;">InfoGraph</td>
<td style="text-align: center;">$54.12 \pm 8.20$</td>
<td style="text-align: center;">$54.04 \pm 9.45$</td>
<td style="text-align: center;">$20.90 \pm 3.32$</td>
<td style="text-align: center;">$57.57 \pm 9.93$</td>
</tr>
<tr>
<td style="text-align: left;">GraphCL</td>
<td style="text-align: center;">$56.38 \pm 7.24$</td>
<td style="text-align: center;">$\underline{55.40} \pm 12.04$</td>
<td style="text-align: center;">$\underline{28.11} \pm 4.00$</td>
<td style="text-align: center;">$\underline{59.22} \pm 7.42$</td>
</tr>
<tr>
<td style="text-align: left;">GraphPrompt</td>
<td style="text-align: center;">$\mathbf{6 4 . 4 2} \pm 4.37$</td>
<td style="text-align: center;">$\mathbf{5 9 . 2 1} \pm 6.82$</td>
<td style="text-align: center;">$\mathbf{3 1 . 4 5} \pm 4.32$</td>
<td style="text-align: center;">$\mathbf{6 1 . 6 3} \pm 7.68$</td>
</tr>
</tbody>
</table>
<p>such a case, even with sophisticated pre-training, they cannot effectively promote the performance of downstream tasks. Third, the graph prompt model GPPT is only comparable to or even worse than the other baselines, despite also using prompts. A potential reason is that GPPT requires much more learnable parameters in their prompts than ours, which may not work well given very few shots (e.g., 1-shot).
Few-shot graph classification. We further conduct few-shot graph classification on four datasets, i.e., PROTEINS, COX2, ENZYMES, and BZR. For each dataset, we randomly generate 1005 -shot classification tasks for training and validation, following a similar process for node classification tasks.</p>
<p>We illustrate the results of few-shot graph classification in Table 3, and have the following observations. First, our proposed GraphPrompt significantly outperforms the baselines on these four datasets. This again demonstrates the necessity of unification for pre-training and downstream tasks, and the effectiveness of prompt-assisted task-specific aggregation for ReadOut. Second, as both node and graph classification tasks share the same pre-trained model on PROTEINS and ENZYMES, the superior performance of GraphPrompt on both types of task further demonstrates that, the gap between different tasks is well addressed by virtue of our unification framework. Third, the graph pre-training models generally achieve better performance than the end-to-end GNN models. This is because both InfoGraph and GraphCL capitalize on graph-level tasks for pre-training, which are naturally closer to the downstream graph classification.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Impact of shots on few-shot node classification.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Impact of shots on few-shot graph classification.</p>
<p>Performance with different shots. We study the impact of number of shots on the PROTEINS and ENZYMES datasets. For node classification, we vary the number of shots between 1 and 10, and compare with several competitive baselines (i.e., GIN, DGI, GraphCL, and GPPT) in Fig. 3. For few-shot graph classification, we vary the number of shots between 1 and 30, and compare with competitive baselines (i.e., GIN, InfoGraph, and GraphCL) in Fig. 4. The task settings are identical to those stated earlier.</p>
<p>In general, our proposed GraphPrompt consistently outperforms the baselines especially with lower shots. For node classification, as the number of nodes in each graph is relatively small, 10 shots per class might be sufficient for semi-supervised node classification. Nevertheless, GraphPrompt is competitive even with 10 shots. For graph classification, GraphPrompt can be surpassed by some baselines when given more shots (e.g., 20 or more), especially on ENZYMES. On this dataset, 30 shots per class implies $30 \%$ of the 600 graphs are used for training, which is not our target scenario.</p>
<h3>5.3 Model Analysis</h3>
<p>We further analyse several aspects of our model. Due to space constraint, we only report the ablation and parameter efficiency study, and leave the rest to Appendix E.
Ablation study. To evaluate the contribution of each component, we conduct an ablation study by comparing GraphPrompt with different prompting strategies: (1) no prompt: for downstream tasks,
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Ablation study.</p>
<p>Table 4: Study of parameter efficiency on node classification.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Methods</th>
<th style="text-align: center;">Flickr</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">PROTEINS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ENZYMES</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Params</td>
<td style="text-align: center;">FLOPs</td>
<td style="text-align: center;">Params</td>
<td style="text-align: center;">FLOPs</td>
<td style="text-align: center;">Params</td>
<td style="text-align: center;">FLOPs</td>
</tr>
<tr>
<td style="text-align: center;">GIN</td>
<td style="text-align: center;">22,183</td>
<td style="text-align: center;">240,100</td>
<td style="text-align: center;">5,730</td>
<td style="text-align: center;">12,380</td>
<td style="text-align: center;">6,280</td>
<td style="text-align: center;">11,030</td>
</tr>
<tr>
<td style="text-align: center;">GPPT</td>
<td style="text-align: center;">4,096</td>
<td style="text-align: center;">4,582</td>
<td style="text-align: center;">1,536</td>
<td style="text-align: center;">1,659</td>
<td style="text-align: center;">1,536</td>
<td style="text-align: center;">1,659</td>
</tr>
<tr>
<td style="text-align: center;">GraphPrompt</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">96</td>
</tr>
<tr>
<td style="text-align: center;">GraphPrompt-ft</td>
<td style="text-align: center;">21,600</td>
<td style="text-align: center;">235,200</td>
<td style="text-align: center;">6,176</td>
<td style="text-align: center;">13,440</td>
<td style="text-align: center;">6,176</td>
<td style="text-align: center;">10,944</td>
</tr>
</tbody>
</table>
<p>we remove the prompt vector, and conduct classification by employing a classifier on the subgraph representations obtained by a direct sum-based ReadOut. (2) lin. prompt: we replace the prompt vector with a linear transformation matrix in Eq. (13).</p>
<p>We conduct the ablation study on three datasets for node classification (Flickr, PROTEINS, and ENZYMES) and graph classification (COX2, ENZYMES, and BZR), respectively, and illustrate the comparison in Fig. 5. We have the following observations. (1) Without the prompt vector, no prompt usually performs the worst among the variants, showing the necessity of prompting the ReadOut operation differently for different downstream tasks. (2) Converting the prompt vector into a linear transformation matrix also hurts the performance, as the matrix involves more parameters thus increasing the reliance on labeled data.
Parameter efficiency. We also compare the number of parameters that needs to be updated in a downstream node classification task for a few representative models, as well as their number of floating point operations (FLOPs), in Table 4.</p>
<p>In particular, as GIN works in an end-to-end manner, it is obvious that it involves the largest number of parameters for updating. For GPPT, it requires a separate learnable vector for each class as its representation, and an attention module to weigh the neighbors for aggregation in the structure token generation. Therefore, GPPT needs to update more parameters than GraphPrompt, which is one factor that impairs its performance in downstream tasks. For our proposed GraphPrompt, it not only outperforms the baselines GIN and GPPT as we have seen earlier, but also requires the least parameters and FLOPs for downstream tasks. For illustration, in addition to prompt tuning, if we also fine-tune the pre-trained weights instead of freezing them (denoted GraphPrompt+ft), there will be significantly more parameters to update.</p>
<h2>6 CONCLUSIONS</h2>
<p>In this paper, we studied the research problem of prompting on graphs and proposed GraphPrompt, in order to overcome the limitations of graph neural networks in the supervised or "pre-train, fine-tune" paradigms. In particular, to narrow the gap between pretraining and downstream objectives on graphs, we introduced a unification framework by mapping different tasks to a common task template. Moreover, to distinguish task individuality and achieve task-specific optima, we proposed a learnable task-specific prompt vector that guides each downstream task to make full of the pretrained model. Finally, we conduct extensive experiments on five public datasets, and show that GraphPrompt significantly outperforms various state-of-the-art baselines.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>This research / project is supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 2 (MOE-T2EP20122-0041). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of the Ministry of Education, Singapore.</p>
<h2>REFERENCES</h2>
<p>[1] Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei. 2022. BEiT: BERT PreTraining of Image Transformers. In International Conference on Learning Representations.
[2] Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A Pretrained Language Model for Scientific Text. In Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing. $3615-3620$.
[3] Karsten M Borgwardt, Cheng Soon Ong, Stefan Schönauer, SVN Vishwanathan, Alex J Smola, and Hans-Peter Kriegel. 2005. Protein function prediction via graph kernels. Bioinformatics 21, suppl_1 (2005), i47-i56.
[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in Neural Information Processing Systems 33 (2020), 1877-1901.
[5] Hongyun Cai, Vincent W Zheng, and Kevin Chen-Chuan Chang. 2018. A comprehensive survey of graph embedding: Problems, techniques, and applications. IEEE Transactions on Knowledge and Data Engineering 30, 9 (2018), 1616-1637.
[6] Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. 2020. Measuring and relieving the over-smoothing problem for graph neural networks from the topological view. In AAAI Conference on Artificial Intelligence. 3438-3445.
[7] Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hou. 2019. Unified language model pretraining for natural language understanding and generation. Advances in Neural Information Processing Systems 32 (2019).
[8] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. Advances in Neural Information Processing Systems 28 (2015).
[9] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic metalearning for fast adaptation of deep networks. In International Conference on Machine Learning. 1126-1135.
[10] Hongyang Gao and Shuiwang Ji. 2019. Graph u-nets. In International Conference on Machine Learning. 2083-2092.
[11] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In International Conference on Machine Learning. 1263-1272.
[12] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 855-864.
[13] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. Advances in neural information processing systems 30 (2017), 1025-1035.
[14] Kaveh Hassani and Amir Hosein Khasahmadi. 2020. Contrastive multi-view representation learning on graphs. In International Conference on Machine Learning. $4116-4126$.
[15] Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. 2020. Strategies for Pre-training Graph Neural Networks. In International Conference on Learning Representations.
[16] Zinix Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, and Yizhou Sun. 2020. GPT-GNN: Generative pre-training of graph neural networks. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1857-1867.
[17] Kevin Huang and Marinka Zitnik. 2020. Graph meta learning via local subgraphs. Advances in Neural Information Processing Systems 33 (2020), 5862-5874.
[18] Dasol Hwang, Jinyoung Park, Sunyoung Kwon, KyungMin Kim, Jung-Woo Ha, and Hyunwoo J Kim. 2020. Self-supervised auxiliary learning with meta-paths for heterogeneous graphs. Advances in Neural Information Processing Systems 33 (2020), 10294-10305.
[19] Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. In Bayesian Deep Learning Workshop.
[20] Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations.
[21] Junhyun Lee, Inyeop Lee, and Jaewoo Kang. 2019. Self-attention graph pooling. In International Conference on Machine Learning. 3734-3743.
[22] Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. In Conference on Empirical Methods in Natural Language Processing. 3045-3059.
[23] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586 (2021).
[24] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. GPT understands, too. arXiv preprint arXiv:2103.10385 (2021).
[25] Zemin Liu, Yuan Fang, Chenghao Liu, and Steven C.H. Hoi. 2021. Node-wise Localization of Graph Neural Networks. In International Joint Conference on Artificial Intelligence. 1520-1526.</p>
<p>[26] Zemin Liu, Yuan Fang, Chenghao Liu, and Steven CH Hoi. 2021. Relative and absolute location embedding for few-shot node classification on graph. In AAAI Conference on Artificial Intelligence. 4267-4275.
[27] Zemin Liu, Trung-Kien Nguyen, and Yuan Fang. 2021. Tail-GNN: Tail-Node Graph Neural Networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 1109-1119.
[28] Zemin Liu, Wentao Zhang, Yuan Fang, Xinming Zhang, and Steven C. H. Hoi. 2020. Towards Locality-Aware Meta-Learning of Tail Node Embeddings on Networks. In Conference on Information and Knowledge Management. 975-984.
[29] Jiaxen Lu, Dheuv Batra, Devi Parikh, and Stefan Lee. 2019. ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Advances in Neural Information Processing Systems 32 (2019).
[30] Yuanfu Lu, Xunqiang Jiang, Yuan Fang, and Chuan Shi. 2021. Learning to pre-train graph neural networks. In AAAI Conference on Artificial Intelligence. 4276-4284.
[31] Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph convolutional networks with eigenpooling. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 723-731.
[32] Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang Xu, and Junzhou Huang. 2020. Graph representation learning via graphical mutual information maximization. In The Web Conference. 259-270.
[33] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: Online learning of social representations. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 701-710.
[34] Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, and Jie Tang. 2020. GCC: Graph contrastive coding for graph neural network pre-training. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1150-1160.
[35] Ryan A. Rossi and Nesreen K. Ahmed. [n. d.]. The Network Data Repository with Interactive Graph Analytics and Visualization. In AAAI Conference on Artificial Intelligence. 4292-4293.
[36] Nino Shervashidze, Pascal Schweitzer, Erik Jan Van Leeuwen, Kurt Mehlhorn, and Karsten M Borgwardt. 2011. Weisfeiler-lehman graph kernels. Journal of Machine Learning Research 12, 9 (2011).
[37] Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. 2020. InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. In International Conference on Learning Representations.
[38] Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang. 2020. InfoGraph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization. In International Conference on Learning Representations.
[39] Mingchen Sun, Kaixiong Zhou, Xin He, Ying Wang, and Xin Wang. 2022. GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 1717-1727.
[40] Susheel Suresh, Pan Li, Cong Hao, and Jennifer Neville. 2021. Adversarial graph augmentation to improve graph contrastive learning. Advances in Neural Information Processing Systems 34 (2021), 15920-15933.
[41] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale information network embedding. In The Web Conference. $1067-1077$.
[42] Matteo Togninalli, Elisabetta Ghisu, Felipe Llinares-López, Bastian Rieck, and Karsten Borgwardt. 2019. Wasserstein weisfreler-lehman graph kernels. Advances in Neural Information Processing Systems 32 (2019).
[43] Petar Velicković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In International Conference on Learning Representations.
[44] Petar Velickovic, William Fedus, William I, Hamilton, Pietro Liò, Yoshua Bengio, and R Devon Hjelm. 2019. Deep Graph Infomas. In International Conference on Learning Representations.
[45] Ning Wang, Minnan Luo, Kaize Ding, Lingling Zhang, Jundong Li, and Qinghua Zheng. 2020. Graph few-shot learning with attribute matching. In ACM International Conference on Information and Knowledge Management. 1545-1554.
[46] Song Wang, Yushun Dong, Xiao Huang, Chen Chen, and Jundong Li. 2022. FATH: Few-Shot Graph Classification with Hierarchical Task Graphs. In International Joint Conference on Artificial Intelligence.
[47] Zhihao Wen, Yuan Fang, and Zemin Liu. 2021. Meta-inductive node classification across graphs. In International ACM SIGIR Conference on Research and Development in Information Retrieval. 1219-1228.
[48] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE Transactions on Neural Networks and Learning Systems 32, 1 (2020), 4-24.
[49] Jun Xia, Yamjiao Zhu, Yuanqi Du, and Stan Z Li. 2022. A survey of pretraining on graphs: Taxonomy, methods, and applications. arXiv preprint arXiv:2202.07893 (2022).
[50] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How powerful are graph neural networks?. In International Conference on Learning Representations.
[51] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. Advances in Neural Information Processing Systems 31 (2018), 4805-4815.
[52] Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. 2021. Graph contrastive learning automated. In International Conference on Machine Learning. $12121-12132$.
[53] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. 2020. Graph contrastive learning with augmentations. Advances in Neural Information Processing Systems 33 (2020), 5812-5823.
[54] Jiayou Zhang, Zhirui Wang, Shizhuo Zhang, Megh Manoj Bhalerao, Yucong Liu, Dawei Zhu, and Sheng Wang. 2021. GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates. arXiv preprint arXiv:2112.05002 (2021).
[55] Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. Advances in Neural Information Processing Systems 31 (2018).
[56] Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An end-to-end deep learning architecture for graph classification. In AAAI conference on artificial intelligence, Vol. 32.
[57] Fan Zhou, Chengtai Cao, Kunpeng Zhang, Goce Trajcevski, Ting Zhong, and Ji Geng. 2019. Meta-GNN: On few-shot node classification in graph meta-learning. In ACM International Conference on Information and Knowledge Management. $2357-2360$.</p>
<h2>APPENDICES</h2>
<h2>A Algorithm and Complexity Analysis</h2>
<p>Algorithm. We present the algorithm for prompt design and tuning of GraphPrompt in Alg. 1. In line 1, we initialize the prompt vector and the objective $\mathcal{L}<em _prompt="{prompt" _text="\text">{\text {prompt }}$. In lines 2-3, we obtain the node embeddings of input graphs based on the pre-trained GNN. In lines 5-13, we accumulate the loss for the given tuning samples. In particular, in lines 5-6, we design the prompt for the specific task $t$. In lines 7-8, we calculate the subgraph representation for each class prototype. Then, in lines 9-13, we calculate and accumulate the loss and get the overall objective. Finally, in line 14 we optimize the prompt vector by minimizing the objective $\mathcal{L}</em>$.}</p>
<div class="codehilite"><pre><span></span><code>Algorithm <span class="mi">1</span> Prompt Design <span class="ow">and</span> Tuning
Input<span class="p">:</span> Graphs set <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathcal<span class="p">{</span>G<span class="p">}</span><span class="o">=</span><span class="err">\</span>left<span class="err">\</span><span class="p">{</span>G_<span class="p">{</span>j<span class="p">}</span> <span class="err">\</span>mid <span class="ss">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="err">\</span>ldots<span class="err">\</span>right<span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">),</span> task <span class="err">\</span><span class="p">(</span>t<span class="err">\</span><span class="p">)</span><span class="o">-</span>specific subgraphs set
    <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathcal<span class="p">{</span>S<span class="p">}</span><span class="o">=</span><span class="err">\</span>left<span class="err">\</span><span class="p">{</span>S_<span class="p">{</span>t<span class="p">,</span> x<span class="p">}</span> <span class="err">\</span>mid <span class="ss">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="err">\</span>ldots<span class="err">\</span>right<span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">),</span> labeled set <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathcal<span class="p">{</span>D<span class="p">}</span><span class="o">=</span><span class="err">\</span>left<span class="err">\</span><span class="p">{</span><span class="err">\</span>left<span class="p">(</span>x_<span class="p">{</span>i<span class="p">},</span> y_<span class="p">{</span>i<span class="p">}</span><span class="err">\</span>right<span class="p">)</span> <span class="err">\</span>mid <span class="ss">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="err">\</span>ldots<span class="err">\</span>right<span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">),</span> class
    set <span class="err">\</span><span class="p">(</span>Y<span class="err">\</span><span class="p">),</span> pre-trained GNN model <span class="err">\</span><span class="p">(</span>f_<span class="p">{</span><span class="err">\</span>mathrm<span class="p">{</span>th<span class="p">}</span>_<span class="p">{</span><span class="mi">0</span><span class="p">}}</span><span class="err">\</span><span class="p">)</span> which takes <span class="k">in</span> a graph <span class="ow">and</span> outputs
    its node embedding vectors<span class="o">.</span>
Output<span class="p">:</span> Prompt vector <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>p<span class="p">}</span>_<span class="p">{</span>t<span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="o">.</span>
    <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>p<span class="p">}</span>_<span class="p">{</span>t<span class="p">}</span> <span class="err">\</span>leftarrow<span class="err">\</span><span class="p">)</span> prompt vector initialization<span class="p">,</span> <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathcal<span class="p">{</span>L<span class="p">}</span>_<span class="p">{</span><span class="err">\</span>text <span class="p">{</span>prompt <span class="p">}}</span> <span class="err">\</span>leftarrow <span class="mi">0</span><span class="err">\</span><span class="p">);</span>
    for each graph <span class="err">\</span><span class="p">(</span>G_<span class="p">{</span>j<span class="p">}</span> <span class="err">\</span><span class="k">in</span> <span class="err">\</span>mathcal<span class="p">{</span>G<span class="p">}</span><span class="err">\</span><span class="p">)</span> do <span class="err">\</span><span class="p">(</span><span class="err">\</span>quad <span class="err">\</span>triangleright<span class="err">\</span><span class="p">)</span> Load pre-trained GNN
        <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathrm<span class="p">{</span>H<span class="p">}</span>_<span class="p">{</span>j<span class="p">}</span> <span class="err">\</span>leftarrow f_<span class="p">{</span><span class="err">\</span>mathrm<span class="p">{</span>th<span class="p">}</span>_<span class="p">{</span><span class="mi">0</span><span class="p">}}</span><span class="err">\</span>left<span class="p">(</span>G_<span class="p">{</span>j<span class="p">}</span><span class="err">\</span>right<span class="p">)</span><span class="err">\</span><span class="p">)</span>
    while not converged do <span class="err">\</span><span class="p">(</span><span class="err">\</span>quad <span class="err">\</span>triangleright<span class="err">\</span><span class="p">)</span> Tuning iteration
        for each subgraph <span class="err">\</span><span class="p">(</span>s_<span class="p">{</span>t <span class="err">\</span>times x<span class="p">}</span> <span class="err">\</span><span class="k">in</span> <span class="err">\</span>mathcal<span class="p">{</span>S<span class="p">}</span><span class="err">\</span><span class="p">)</span> do <span class="err">\</span><span class="p">(</span><span class="err">\</span>quad <span class="err">\</span>triangleright<span class="err">\</span><span class="p">)</span> Prompt design<span class="p">,</span> Eq<span class="o">.</span> <span class="p">(</span><span class="mi">12</span><span class="p">)</span>
            <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>s<span class="p">}</span>_<span class="p">{</span>t <span class="err">\</span>times x<span class="p">}</span> <span class="err">\</span>leftarrow <span class="err">\</span>operatorname<span class="p">{</span>READOUT<span class="p">}</span><span class="err">\</span>left<span class="p">(</span><span class="err">\</span>left<span class="err">\</span><span class="p">{</span><span class="err">\</span>mathbf<span class="p">{</span>p<span class="p">}</span>_<span class="p">{</span>t<span class="p">}</span> <span class="err">\</span>odot <span class="err">\</span>mathbf<span class="p">{</span>h<span class="p">}</span>_<span class="p">{</span>v<span class="p">}:</span> v <span class="err">\</span><span class="k">in</span> V<span class="err">\</span>left<span class="p">(</span>S_<span class="p">{</span>x<span class="p">}</span><span class="err">\</span>right<span class="p">)</span><span class="err">\</span>right<span class="err">\</span><span class="p">}</span><span class="err">\</span>right<span class="p">)</span><span class="err">\</span><span class="p">)</span>
        for each class <span class="err">\</span><span class="p">(</span>c <span class="err">\</span><span class="k">in</span> Y<span class="err">\</span><span class="p">)</span> do <span class="err">\</span><span class="p">(</span><span class="err">\</span>quad <span class="err">\</span>triangleright<span class="err">\</span><span class="p">)</span> Class prototypical subgraph
            <span class="err">\</span><span class="p">(</span><span class="err">\</span>hat<span class="p">{</span><span class="err">\</span>mathbf<span class="p">{</span>s<span class="p">}}</span>_<span class="p">{</span>t<span class="p">,</span> c<span class="p">}</span> <span class="err">\</span>leftarrow<span class="err">\</span><span class="p">)</span> Mean of <span class="l">node/graph</span> embedding vectors
        for each labeled pair <span class="err">\</span><span class="p">(</span><span class="err">\</span>left<span class="p">(</span>x_<span class="p">{</span>i<span class="p">},</span> y_<span class="p">{</span>i<span class="p">}</span><span class="err">\</span>right<span class="p">)</span> <span class="err">\</span><span class="k">in</span> <span class="err">\</span>mathcal<span class="p">{</span>D<span class="p">}</span><span class="err">\</span><span class="p">)</span> do <span class="err">\</span><span class="p">(</span><span class="err">\</span>triangleright<span class="err">\</span><span class="p">)</span> Accumulate loss<span class="p">,</span> Eq<span class="o">.</span> <span class="p">(</span><span class="mi">14</span><span class="p">)</span>
            <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathrm<span class="p">{</span>Z<span class="p">}</span>_<span class="p">{</span>i<span class="p">}</span> <span class="err">\</span>leftarrow <span class="mi">0</span><span class="err">\</span><span class="p">)</span>
            for each class <span class="err">\</span><span class="p">(</span>c <span class="err">\</span><span class="k">in</span> Y<span class="err">\</span><span class="p">)</span> do
                <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathrm<span class="p">{</span>Z<span class="p">}</span>_<span class="p">{</span>i<span class="p">}</span><span class="o">=</span><span class="err">\</span>exp <span class="err">\</span>left<span class="p">(</span><span class="err">\</span>operatorname<span class="p">{</span>sim<span class="p">}</span><span class="err">\</span>left<span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>s<span class="p">}</span>_<span class="p">{</span>t<span class="p">,</span> x_<span class="p">{</span>i<span class="p">}},</span> <span class="err">\</span>hat<span class="p">{</span><span class="err">\</span>mathbf<span class="p">{</span>s<span class="p">}}</span>_<span class="p">{</span>t<span class="p">,</span> c<span class="p">}</span><span class="err">\</span>right<span class="p">)</span> <span class="o">/</span> <span class="err">\</span>tau<span class="err">\</span>right<span class="p">)</span><span class="o">+</span><span class="err">\</span>mathrm<span class="p">{</span>Z<span class="p">}</span>_<span class="p">{</span>i<span class="p">}</span><span class="err">\</span><span class="p">)</span>
            <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathcal<span class="p">{</span>L<span class="p">}</span>_<span class="p">{</span><span class="err">\</span>text <span class="p">{</span>prompt <span class="p">}}</span><span class="o">=</span><span class="err">\</span>mathcal<span class="p">{</span>L<span class="p">}</span>_<span class="p">{</span><span class="err">\</span>text <span class="p">{</span>prompt <span class="p">}}</span><span class="o">-</span><span class="err">\</span>ln <span class="err">\</span>left<span class="p">(</span><span class="err">\</span>exp <span class="err">\</span>left<span class="p">(</span><span class="err">\</span>operatorname<span class="p">{</span>sim<span class="p">}</span><span class="err">\</span>left<span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>s<span class="p">}</span>_<span class="p">{</span>t<span class="p">,</span> x_<span class="p">{</span>i<span class="p">}},</span> <span class="err">\</span>hat<span class="p">{</span><span class="err">\</span>mathbf<span class="p">{</span>s<span class="p">}}</span>_<span class="p">{</span>t<span class="p">,</span> y_<span class="p">{</span>i<span class="p">}}</span><span class="err">\</span>right<span class="p">)</span> <span class="o">/</span> <span class="err">\</span>tau<span class="err">\</span>right<span class="p">)</span> <span class="o">/</span> <span class="err">\</span>mathrm<span class="p">{</span>Z<span class="p">}</span>_<span class="p">{</span>i<span class="p">}</span><span class="err">\</span>right<span class="p">)</span><span class="err">\</span><span class="p">)</span>
            Update <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>p<span class="p">}</span>_<span class="p">{</span>t<span class="p">}</span><span class="err">\</span><span class="p">)</span> by minimize <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathcal<span class="p">{</span>L<span class="p">}</span>_<span class="p">{</span><span class="err">\</span>text <span class="p">{</span>prompt <span class="p">}}</span><span class="err">\</span><span class="p">);</span>
    return <span class="err">\</span><span class="p">(</span><span class="err">\</span>mathbf<span class="p">{</span>p<span class="p">}</span>_<span class="p">{</span>t<span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="o">.</span>
</code></pre></div>

<p>Complexity analysis. For a node $v$, with average degree $\bar{d}, k$ GNN layers, $\delta$ hops for subgraph extraction, $D$ hidden dimensions, the complexity of GNN-based embedding calculation is $O\left(D \cdot \bar{d}^{k}\right)$, and the complexity of subgraph extraction is $O\left(\bar{d}^{\delta}\right)$. Thus, the embedding calculation of $v$ 's subgraph with READOut is $O\left(D \cdot \bar{d}^{k} \cdot \bar{d}^{\delta}\right)$, where $k, \delta$ are small constants. Furthermore, if some neighborhood sampling [13] is adopted during GNN aggregation, $\bar{d}$ is a relatively small constant too.</p>
<h2>B Further Descriptions of Datasets</h2>
<p>We provide further details of the datasets.
(1) Flickr [47] is an image sharing network, which is collected by SNAP ${ }^{2}$. In particular, each node is an image, and there exists an edge between two images if they share some common properties, such as commented by the same user, or from the same location. Each image belongs to one of the 7 categories.
(2) PROTEINS [3] is a collection of protein graphs which include the amino acid sequence, conformation, structure, and features such</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>as active sites of the proteins. The nodes represent the secondary structures, and each edge depicts the neighboring relation in the amino-acid sequence or in 3D space. The nodes belong to three categories, and the graphs belong to two classes.
(3) COX2 [35] is a dataset of molecular structures including 467 cyclooxygenase-2 inhibitors, in which each node is an atom, and each edge represents the chemical bond between atoms, such as single, double, triple or aromatic. All the molecules belong to two categories.
(4) ENZYMES [46] is a dataset of 600 enzymes collected from the BRENDA enzyme database. These enzymes are labeled into 6 categories according to their top-level EC enzyme.
(5) BZR [35] is a collection of 405 ligands for benzodiazepine receptor, in which each ligand is represented by a graph. All these ligands belong to 2 categories.</p>
<p>Note that we conduct node classification on Flickr, PROTEINS and ENZYMES, since their node labels generally appear on all the graphs, which is suitable for the setting of few-shot node classification on each graph. Note that, we only choose the graphs which consist of more than 50 nodes for the downstream node classification, to ensure there exist sufficient labeled nodes for testing. Additionally, graph classification is conducted on PROTEINS, COX2, ENXYMES and BZR. We use the given node features in the cited datasets to initialize input feature vectors, without additional processing.</p>
<h2>C Further Descriptions of Baselines</h2>
<p>In this section, we present more details for the baselines, which are chosen from three main categories.
(1) End-to-end graph neural networks.</p>
<ul>
<li>GCN [20]: GCN resorts to mean-pooling based neighborhood aggregation to receive messages from the neighboring nodes for node representation learning in an end-to-end manner.</li>
<li>GraphSage [13]: GraphSAGE has a similar neighborhood aggregation mechanism with GCN, while it focuses more on the information from the node itself.</li>
<li>GAT [43] : GAT also depends on neighborhood aggregation for node representation learning in an end-to-end manner, while it can assign different weights to neighbors to reweigh their contributions.</li>
<li>GIN [50]: GIN employs a sum-based aggregator to replace the mean-pooling method in GCN, which is more powerful in expressing the graph structures.
(2) Graph pre-training models.</li>
<li>DGI [44]: DGI capitalizes on a self-supervised method for pretraining, which is based on the concept of mutual information (MI). It maximizes the MI between the local augmented instances and the global representation.</li>
<li>InfoGraph [38]: InfoGraph learns a graph-level representation, which maximizes the MI between the graph-level representation and substructure representations at various scales.</li>
<li>
<p>GraphCL [53]: GraphCL applies different graph augmentations to exploit the structural information on the graphs, and aims to maximize the agreement between different augmentations for graph pre-training.
(3) Graph prompt models.</p>
</li>
<li>
<p>GPPT [39]. GPPT pre-trains a GNN model based on the link prediction task, and employs a learnable prompt to reformulate the downstream node classification task into the same format as link prediction.</p>
</li>
</ul>
<h2>D Further Implementation Details</h2>
<p>For baseline GCN [20], we employ a 3-layer architecture, and set the hidden dimension as 32. For GraphSAGE [13], we utilize the mean aggregator, and employ a 3-layer architecture. The hidden dimension is also set to 32. For GAT [43], we employ a 2-layer architecture and set the hidden dimension as 32. Besides, we apply 4 attention heads in the first GAT layer. Similarly, for GIN [50], we also employ a 3-layer architecture and set the hidden dimension as 32. For the pre-training and prompting approaches, we use the backbones in their original paper. Specifically, for DGI [44], we use a 1-layer GCN as the backbone, and set the hidden dimension as 512. Besides, we utilize PReLU as the activation function. For InfoGraph [38], we use a 3-layer GIN as the backbone, and set its hidden dimension as 32. For GraphCL [53], we also employ a 3-layer GIN as its backbone, and set the hidden dimension as 32. In particular, we choose the augmentations of node dropping and subgraph, with a default augmentation ratio of 0.2 . For GPPT [39], we utilize a 2-layer GraphSAGE as its backbone, set its hidden dimension as 128, and utilize the mean aggregator. For our proposed GraphPrompt, we employ a 3-layer GIN as the backbone, and set the hidden dimensions as 32 . In addition, we set $\delta=1$ to construct 1-hop subgraphs for the nodes.</p>
<h2>E Further Experimental Results</h2>
<p>Scalability study. We investigate the scalability of GraphPrompt on the dataset PROTEINS for graph classification. We divide the graphs into six groups based on their size (i.e., number of nodes). The size of graphs in each group is approximately $50,60, \ldots, 100$ nodes. We sample 10 graphs from each group, and record the prompt tuning time on the 10 graphs in each epoch. The results are presented in Fig. 6. Note that we also report the tuning time for Graph-Prompt-ft, a variant of GraphPrompt, which fine-tunes all the parameters including the pre-trained GNN weights. We first observe that the tuning time of our GraphPrompt increases linearly as the graph size increases, demonstrating the scalability of GraphPrompt on larger graphs. In addition, compared to GraphPrompt, GraphPrompt-ft needs more tuning time, showing the inefficiency of the fine-tuning paradigm.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Scalability study.</p>
<p>Parameter sensitivity. We evaluate the sensitivity of two important hyperparameters in GraphPrompt, and show the impact in Figs. 7 and 8 for node classification and graph classification, respectively.</p>
<p>For the number of hops ( $\delta$ ) in subgraph construction, the performance on node classification gradually decreases as the number of hops increases. This is because a larger subgraph tends to bring in irrelevant information for the target node, and may suffer from the over-smoothing issue [6]. On the other hand, for graph classification, the number of hops only affects the pre-training stage as the whole graph is used in downstream classification. In this case, the number of hops does not show a clear trend, implying less impact on graph classification since both small and large subgraphs are helpful in capturing substructure information at different scales.</p>
<p>For the hidden dimension, a smaller dimension is better for node classification, such as 32 and 64 . For graph classification, a slightly larger dimension might be better, such as 64 and 128 . Overall, 32 or 64 appears to be robust for both node and graph classification.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Parameter sensitivity on node classification.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Parameter sensitivity on graph classification.</p>
<h2>F Data Ethics Statement</h2>
<p>To evaluate the efficacy of this work, we conducted experiments which only use publicly available datasets, namely, Flickr ${ }^{3}$, PROTEINS, COX2, ENZYMES and BZR ${ }^{4}$, in accordance to their usage terms and conditions if any. We further declare that no personally identifiable information was used, and no human or animal subject was involved in this research.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://snap.stanford.edu/data/web-flickr.html
${ }^{4}$ https://chrsmrrs.github.io/datasets/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>