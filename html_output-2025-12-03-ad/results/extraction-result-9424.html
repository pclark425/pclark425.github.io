<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9424 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9424</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9424</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-87dde6e5f221bf697d79b74f2efafaca9da220fd</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/87dde6e5f221bf697d79b74f2efafaca9da220fd" target="_blank">RAGLog: Log Anomaly Detection using Retrieval Augmented Generation</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This research work explores the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs and the experimental results show much promise.</p>
                <p><strong>Paper Abstract:</strong> The ability to detect log anomalies from system logs is a vital activity needed to ensure cyber resiliency of systems. It is applied for fault identification or facilitate cyber investigation and digital forensics. However, as logs belonging to different systems and components differ significantly, the challenge to perform such analysis is humanly challenging from the volume, variety and velocity of logs. This is further complicated by the lack or unavailability of anomalous log entries to develop trained machine learning or artificial intelligence models for such purposes. In this research work, we explore the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs. We used a Question and Answer configuration pipeline. To the best of our knowledge, our experiment which we called RAGLog is a novel one and the experimental results show much promise.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9424.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9424.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAGLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval Augmented Generation for Log Anomaly Detection (RAGLog)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that stores representative normal log entries in a vector database, retrieves nearest normal examples for a queried log entry, and uses a large language model in a zero-shot Q&A prompt to label the entry as 'normal' or 'abnormal'.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (autoregressive LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual system logs (sequenced/time-series log entries)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System/HPC/cloud application logs (BGL and Thunderbird datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log entries / outlier/error events in logs</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot Q&A prompting inside a Retrieval-Augmented-Generation (RAG) loop: encode log entries with a pre-trained OpenAI embedding model, store vectors of only normal log entries in a vector DB, retrieve nearest normal samples (dense inner-product similarity via LangChain retriever), decode retrieved vectors to text and include them in a prompt plus the query log entry, instruct GPT-3.5 to output 'normal' or 'abnormal' (temperature=0.1). Two strategies to populate the DB were tested: random sampling of normal entries and sampling representative normal entries via k-means clustering (elbow method to pick k).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared directly against LogPrompt (zero-shot prompt engineering approach). Paper also references conventional supervised and unsupervised ML/deep learning log-anomaly methods but does not reimplement them as baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 score (binary classification metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>RAGLog (zero-shot): Precision = 0.91, Recall = 0.88, F1 = 0.89. Experiments used vector DBs sized by sampling (BGL: 50,000 entries for clustered/random at 5 clusters × 10,000 each; Thunderbird: 40,000 entries at 4 clusters × 10,000 each). Evaluation run on a random sample of 20% of test sets due to cost.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Substantially better than the cited LogPrompt zero-shot results (LogPrompt: Precision 0.25, Recall 0.83, F1 0.38); RAGLog showed much higher precision and F1 while maintaining high recall.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High compute/resource consumption and inference latency because LLM inference is performed per log entry; cost constraints limited evaluation sampling; general LLM limits noted (token capacity, recall limits, potential for hallucination) — though in these experiments responses were constrained to 'normal'/'abnormal' and no hallucinations were observed; dependence on representativeness of stored normal samples (quality of clustering/random sampling matters); current pipeline analyzes one log entry at a time which harms throughput for large volumes.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Storing only representative normal examples in a vector DB and using retrieval to provide local context enables effective zero-shot anomaly classification with an LLM; selecting normal examples via k-means clustering improved performance for datasets with wide log-pattern distributions (BGL) compared to random sampling; constraining the LLM output format to fixed labels greatly reduces hallucination risk in this operational classification setting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9424.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9424.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI GPT-3.5 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autoregressive transformer LLM used as the generative/semantic classifier in the RAGLog pipeline; prompted in zero-shot Q&A form to return 'normal' or 'abnormal' for queried log entries together with retrieved normal examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (autoregressive LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual log entry strings (sequence of log tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (BGL, Thunderbird)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log entries / outliers</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot prompting: compose a prompt that includes several retrieved normal log entries and the queried entry, and ask GPT-3.5 to classify as 'normal' or 'abnormal' (temperature set to 0.1).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Used within RAGLog and compared to LogPrompt (as a baseline method from prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 (reported at the system level for RAGLog)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>As the LLM component of RAGLog, contributed to system metrics: Precision 0.91, Recall 0.88, F1 0.89 (RAGLog overall).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>When used inside RAGLog (with retrieval of normal examples), outperformed LogPrompt zero-shot prompt method reported in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Subject to token-length limits and potential hallucinations in general; inference cost and latency are non-trivial when run per log entry; no model fine-tuning was performed so all classification was zero-shot and reliant on prompt engineering and retrieved context.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Constrained single-label outputs and retrieval of normal exemplars can turn a general-purpose LLM into an effective zero-shot anomaly detector for logs, achieving high precision and F1 in the evaluated datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9424.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9424.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenAI Embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI pre-trained embedding model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pre-trained embedding encoder/decoder used to convert log entries to dense vectors for nearest-neighbor retrieval and to decode retrieved vectors back to textual log examples for inclusion in prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI embedding model (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based dense vector embedding</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual log entries</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System/HPC logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Not directly detecting anomalies; used to represent normal log examples for retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Encode log entries into dense vectors stored in a vector DB; compute inner-product similarity between a query's embedding and stored embeddings to retrieve top normal examples; decoded retrieved embeddings back to original text for prompt construction.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not separately measured in paper (component-level retrieval quality not reported numerically).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No direct baseline for embeddings reported; paper uses dense-vector retrieval as the retrieval strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Retrieval performance depends on embedding quality and representativeness of stored normal samples; decoding step described but performance/accuracy of decoding not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Using dense embeddings of only normal samples simplifies the retrieval store and enables a zero-shot LLM to reason semantically about deviations relative to known-normal examples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9424.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9424.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogPrompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior work that explored prompt engineering for zero-shot log analysis with LLMs; evaluated several prompt formats and numbers of provided examples, but reported low precision for zero-shot anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM (unspecified in citation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log entries (text)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log entries / rare/error events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot prompting with different prompt formats (self-prompt, chain-of-thought prompts, in-context prompts) and varying numbers of provided samples for the LLM to analyze logs without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 (as reported in the cited comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported zero-shot results cited in this paper: Precision = 0.25, Recall = 0.83, F1 = 0.38.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>RAGLog reported much higher precision and F1 compared to LogPrompt's zero-shot numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Very low precision indicates many false positives, making the method less suitable for operations without further improvements; prompt/window tuning non-trivial.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Shows that naive zero-shot prompting of LLMs for anomaly detection can yield high recall but poor precision, motivating retrieval-augmentation and exemplar selection strategies like those used in RAGLog.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9424.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9424.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogGPT / ChatGPT (Qi et al., Mudgal et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection; assessments of ChatGPT on log data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior exploratory works using ChatGPT for log parsing and anomaly detection; reported sensitivity to prompt design, token/window size limitations, and high false positive rates in anomaly detection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (OpenAI, unspecified variant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based conversational LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual log entries and windows/sequences of log records</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log entries / rare events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prompting ChatGPT with windows of log entries and various prompt constructs to perform parsing and anomaly detection; experimental exploration of prompt design and input window sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not exhaustively reported in this paper; Qi et al. reported high false positive rates and non-trivial prompt/window selection.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Summarized findings: prompt choice and window size materially affect performance; ChatGPT experiments showed non-trivial optimization and high false positives for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Used as motivation for retrieval-augmentation; these exploratory findings motivated the RAG approach due to ChatGPT limitations on window size and precision.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Prompt sensitivity, token-window limits, high false positive rates, and hallucination risk noted as practical challenges for direct LLM application to log anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>These prior studies highlight that direct application of large conversational LLMs without retrieval/context management tends to produce unreliable anomaly-detection performance, motivating architectures that augment LLMs with retrieval of representative context.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9424.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9424.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LangChain retriever</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LangChain dense-vector retriever</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval component (used by RAGLog) that computes dense-vector similarity (inner-product) between query embeddings and stored vectors to return top-k relevant normal log entries from the vector DB.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LangChain retriever</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Dense-vector retrieval (library/component)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Vectorized textual embeddings of log entries</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>N/A (retrieval component)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute inner-product similarity between the query embedding (from OpenAI embedding model) and stored embeddings of normal examples; return highest-scoring items to include in the LLM prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not separately reported (component-level retrieval metrics not given).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Retrieval quality dependent on embedding model and the representativeness of stored normal examples; tuning of retrieval thresholds and number of retrieved items not exhaustively reported.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Dense retrieval of normal exemplars is an effective way to ground LLM zero-shot decisions for anomaly detection in logs, improving precision compared to pure prompt-only zero-shot approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis <em>(Rating: 2)</em></li>
                <li>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection <em>(Rating: 2)</em></li>
                <li>An Assessment of ChatGPT on Log Data <em>(Rating: 2)</em></li>
                <li>Log-based Anomaly Detection without Log Parsing <em>(Rating: 1)</em></li>
                <li>OneLog: Towards End-to-End Training in Software Log Anomaly Detection <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9424",
    "paper_id": "paper-87dde6e5f221bf697d79b74f2efafaca9da220fd",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "RAGLog",
            "name_full": "Retrieval Augmented Generation for Log Anomaly Detection (RAGLog)",
            "brief_description": "A pipeline that stores representative normal log entries in a vector database, retrieves nearest normal examples for a queried log entry, and uses a large language model in a zero-shot Q&A prompt to label the entry as 'normal' or 'abnormal'.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (Davinci)",
            "model_type": "Transformer (autoregressive LLM)",
            "model_size": null,
            "data_type": "Textual system logs (sequenced/time-series log entries)",
            "data_domain": "System/HPC/cloud application logs (BGL and Thunderbird datasets)",
            "anomaly_type": "Anomalous log entries / outlier/error events in logs",
            "method_description": "Zero-shot Q&A prompting inside a Retrieval-Augmented-Generation (RAG) loop: encode log entries with a pre-trained OpenAI embedding model, store vectors of only normal log entries in a vector DB, retrieve nearest normal samples (dense inner-product similarity via LangChain retriever), decode retrieved vectors to text and include them in a prompt plus the query log entry, instruct GPT-3.5 to output 'normal' or 'abnormal' (temperature=0.1). Two strategies to populate the DB were tested: random sampling of normal entries and sampling representative normal entries via k-means clustering (elbow method to pick k).",
            "baseline_methods": "Compared directly against LogPrompt (zero-shot prompt engineering approach). Paper also references conventional supervised and unsupervised ML/deep learning log-anomaly methods but does not reimplement them as baselines.",
            "performance_metrics": "Precision, Recall, F1 score (binary classification metrics)",
            "performance_results": "RAGLog (zero-shot): Precision = 0.91, Recall = 0.88, F1 = 0.89. Experiments used vector DBs sized by sampling (BGL: 50,000 entries for clustered/random at 5 clusters × 10,000 each; Thunderbird: 40,000 entries at 4 clusters × 10,000 each). Evaluation run on a random sample of 20% of test sets due to cost.",
            "comparison_to_baseline": "Substantially better than the cited LogPrompt zero-shot results (LogPrompt: Precision 0.25, Recall 0.83, F1 0.38); RAGLog showed much higher precision and F1 while maintaining high recall.",
            "limitations_or_failure_cases": "High compute/resource consumption and inference latency because LLM inference is performed per log entry; cost constraints limited evaluation sampling; general LLM limits noted (token capacity, recall limits, potential for hallucination) — though in these experiments responses were constrained to 'normal'/'abnormal' and no hallucinations were observed; dependence on representativeness of stored normal samples (quality of clustering/random sampling matters); current pipeline analyzes one log entry at a time which harms throughput for large volumes.",
            "unique_insights": "Storing only representative normal examples in a vector DB and using retrieval to provide local context enables effective zero-shot anomaly classification with an LLM; selecting normal examples via k-means clustering improved performance for datasets with wide log-pattern distributions (BGL) compared to random sampling; constraining the LLM output format to fixed labels greatly reduces hallucination risk in this operational classification setting.",
            "uuid": "e9424.0",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "GPT-3.5 (Davinci)",
            "name_full": "OpenAI GPT-3.5 (Davinci)",
            "brief_description": "An autoregressive transformer LLM used as the generative/semantic classifier in the RAGLog pipeline; prompted in zero-shot Q&A form to return 'normal' or 'abnormal' for queried log entries together with retrieved normal examples.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (Davinci)",
            "model_type": "Transformer (autoregressive LLM)",
            "model_size": null,
            "data_type": "Textual log entry strings (sequence of log tokens)",
            "data_domain": "System logs (BGL, Thunderbird)",
            "anomaly_type": "Anomalous log entries / outliers",
            "method_description": "Zero-shot prompting: compose a prompt that includes several retrieved normal log entries and the queried entry, and ask GPT-3.5 to classify as 'normal' or 'abnormal' (temperature set to 0.1).",
            "baseline_methods": "Used within RAGLog and compared to LogPrompt (as a baseline method from prior work).",
            "performance_metrics": "Precision, Recall, F1 (reported at the system level for RAGLog)",
            "performance_results": "As the LLM component of RAGLog, contributed to system metrics: Precision 0.91, Recall 0.88, F1 0.89 (RAGLog overall).",
            "comparison_to_baseline": "When used inside RAGLog (with retrieval of normal examples), outperformed LogPrompt zero-shot prompt method reported in prior work.",
            "limitations_or_failure_cases": "Subject to token-length limits and potential hallucinations in general; inference cost and latency are non-trivial when run per log entry; no model fine-tuning was performed so all classification was zero-shot and reliant on prompt engineering and retrieved context.",
            "unique_insights": "Constrained single-label outputs and retrieval of normal exemplars can turn a general-purpose LLM into an effective zero-shot anomaly detector for logs, achieving high precision and F1 in the evaluated datasets.",
            "uuid": "e9424.1",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "OpenAI Embeddings",
            "name_full": "OpenAI pre-trained embedding model",
            "brief_description": "A pre-trained embedding encoder/decoder used to convert log entries to dense vectors for nearest-neighbor retrieval and to decode retrieved vectors back to textual log examples for inclusion in prompts.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "OpenAI embedding model (unspecified)",
            "model_type": "Transformer-based dense vector embedding",
            "model_size": null,
            "data_type": "Textual log entries",
            "data_domain": "System/HPC logs",
            "anomaly_type": "Not directly detecting anomalies; used to represent normal log examples for retrieval",
            "method_description": "Encode log entries into dense vectors stored in a vector DB; compute inner-product similarity between a query's embedding and stored embeddings to retrieve top normal examples; decoded retrieved embeddings back to original text for prompt construction.",
            "baseline_methods": "",
            "performance_metrics": "Not separately measured in paper (component-level retrieval quality not reported numerically).",
            "performance_results": "",
            "comparison_to_baseline": "No direct baseline for embeddings reported; paper uses dense-vector retrieval as the retrieval strategy.",
            "limitations_or_failure_cases": "Retrieval performance depends on embedding quality and representativeness of stored normal samples; decoding step described but performance/accuracy of decoding not quantified.",
            "unique_insights": "Using dense embeddings of only normal samples simplifies the retrieval store and enables a zero-shot LLM to reason semantically about deviations relative to known-normal examples.",
            "uuid": "e9424.2",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LogPrompt",
            "name_full": "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis",
            "brief_description": "A prior work that explored prompt engineering for zero-shot log analysis with LLMs; evaluated several prompt formats and numbers of provided examples, but reported low precision for zero-shot anomaly detection.",
            "citation_title": "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis",
            "mention_or_use": "mention",
            "model_name": "LLM (unspecified in citation)",
            "model_type": "Transformer (LLM)",
            "model_size": null,
            "data_type": "Log entries (text)",
            "data_domain": "System logs",
            "anomaly_type": "Anomalous log entries / rare/error events",
            "method_description": "Zero-shot prompting with different prompt formats (self-prompt, chain-of-thought prompts, in-context prompts) and varying numbers of provided samples for the LLM to analyze logs without fine-tuning.",
            "baseline_methods": "",
            "performance_metrics": "Precision, Recall, F1 (as reported in the cited comparison)",
            "performance_results": "Reported zero-shot results cited in this paper: Precision = 0.25, Recall = 0.83, F1 = 0.38.",
            "comparison_to_baseline": "RAGLog reported much higher precision and F1 compared to LogPrompt's zero-shot numbers.",
            "limitations_or_failure_cases": "Very low precision indicates many false positives, making the method less suitable for operations without further improvements; prompt/window tuning non-trivial.",
            "unique_insights": "Shows that naive zero-shot prompting of LLMs for anomaly detection can yield high recall but poor precision, motivating retrieval-augmentation and exemplar selection strategies like those used in RAGLog.",
            "uuid": "e9424.3",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LogGPT / ChatGPT (Qi et al., Mudgal et al.)",
            "name_full": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection; assessments of ChatGPT on log data",
            "brief_description": "Prior exploratory works using ChatGPT for log parsing and anomaly detection; reported sensitivity to prompt design, token/window size limitations, and high false positive rates in anomaly detection tasks.",
            "citation_title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "mention_or_use": "mention",
            "model_name": "ChatGPT (OpenAI, unspecified variant)",
            "model_type": "Transformer-based conversational LLM",
            "model_size": null,
            "data_type": "Textual log entries and windows/sequences of log records",
            "data_domain": "System logs",
            "anomaly_type": "Anomalous log entries / rare events",
            "method_description": "Prompting ChatGPT with windows of log entries and various prompt constructs to perform parsing and anomaly detection; experimental exploration of prompt design and input window sizes.",
            "baseline_methods": "",
            "performance_metrics": "Not exhaustively reported in this paper; Qi et al. reported high false positive rates and non-trivial prompt/window selection.",
            "performance_results": "Summarized findings: prompt choice and window size materially affect performance; ChatGPT experiments showed non-trivial optimization and high false positives for anomaly detection.",
            "comparison_to_baseline": "Used as motivation for retrieval-augmentation; these exploratory findings motivated the RAG approach due to ChatGPT limitations on window size and precision.",
            "limitations_or_failure_cases": "Prompt sensitivity, token-window limits, high false positive rates, and hallucination risk noted as practical challenges for direct LLM application to log anomaly detection.",
            "unique_insights": "These prior studies highlight that direct application of large conversational LLMs without retrieval/context management tends to produce unreliable anomaly-detection performance, motivating architectures that augment LLMs with retrieval of representative context.",
            "uuid": "e9424.4",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LangChain retriever",
            "name_full": "LangChain dense-vector retriever",
            "brief_description": "A retrieval component (used by RAGLog) that computes dense-vector similarity (inner-product) between query embeddings and stored vectors to return top-k relevant normal log entries from the vector DB.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LangChain retriever",
            "model_type": "Dense-vector retrieval (library/component)",
            "model_size": null,
            "data_type": "Vectorized textual embeddings of log entries",
            "data_domain": "System logs",
            "anomaly_type": "N/A (retrieval component)",
            "method_description": "Compute inner-product similarity between the query embedding (from OpenAI embedding model) and stored embeddings of normal examples; return highest-scoring items to include in the LLM prompt.",
            "baseline_methods": "",
            "performance_metrics": "Not separately reported (component-level retrieval metrics not given).",
            "performance_results": "",
            "comparison_to_baseline": "",
            "limitations_or_failure_cases": "Retrieval quality dependent on embedding model and the representativeness of stored normal examples; tuning of retrieval thresholds and number of retrieved items not exhaustively reported.",
            "unique_insights": "Dense retrieval of normal exemplars is an effective way to ground LLM zero-shot decisions for anomaly detection in logs, improving precision compared to pure prompt-only zero-shot approaches.",
            "uuid": "e9424.5",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis",
            "rating": 2
        },
        {
            "paper_title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "rating": 2
        },
        {
            "paper_title": "An Assessment of ChatGPT on Log Data",
            "rating": 2
        },
        {
            "paper_title": "Log-based Anomaly Detection without Log Parsing",
            "rating": 1
        },
        {
            "paper_title": "OneLog: Towards End-to-End Training in Software Log Anomaly Detection",
            "rating": 1
        }
    ],
    "cost": 0.014584999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>RAGLog: Log Anomaly Detection using Retrieval Augmented Generation</h1>
<p>Jonathan Pan, Swee Liang Wong, Yidi Yuan<br>Home Team Science and Technology Agency, Singapore<br>Jonathan_Pan@htx.gov.sg, Wong_Swee_Liang@htx.gov.sg, Yuan_Yidi@htx.gov.sg</p>
<h4>Abstract</h4>
<p>The ability to detect log anomalies from system logs is a vital activity needed to ensure cyber resiliency of systems. It is applied for fault identification or facilitate cyber investigation and digital forensics. However, as logs belonging to different systems and components differ significantly, the challenge to perform such analysis is humanly challenging from the volume, variety and velocity of logs. This is further complicated by the lack or unavailability of anomalous log entries to develop trained machine learning or artificial intelligence models for such purposes. In this research work, we explore the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs. We used a Question and Answer configuration pipeline. To the best of our knowledge, our experiment which we called RAGLog is a novel one and the experimental results show much promise.</p>
<p>Keywords- Log analysis; Retrieval Augmented Generation, Large Language Model</p>
<h2>I. INTRODUCTION</h2>
<p>The analysis of logs to detect anomalies is an important research topic with practical importance in the field of failure identification [1], [2] and security threat detection [3], [4]. Logs are generated by systems or applications that are codified and configured to report relevant information about the state of the applications or software while running. Here, the application may refer to any software running to perform specific task or tasks. It could be a mobile application, operating system running inside an Internet of Things (IoTs) device or a cloud compute node performing computational tasks. It could also be an environment of compute nodes working collectively on multiple tasks. Such logs and their log entries are generated based on its current configuration at the time of the log generation. These entries are also affected by the state of the application during its execution and its dependent factors that may originate from within the operating environment and executing platform of the application. It would be affected by external factors like users or external systems interacting with the application.</p>
<p>These internal and external factors affecting the log generation may change abruptly and progressively over time resulting in corresponding log entries being included into the log generation process. These factors may originate from planned changes like planned maintenance tasks. They may also originate from unplanned activities. Additionally, these changes may be induced by benign or malicious intent. For the latter,
with the intent to evade detection, even if the logs are not tampered, its entries will be elusive to classical detection techniques. These further complicates the composition of logs to be analyzed.</p>
<p>The objective of performing analysis on logs is done to facilitate the detection of anomalous activities so that immediate or corresponding remediation may be done to contain or remediate the issue recorded in the logs. This is part of the attempt to enhance system resiliency against system faults, degradation and intentionally induced cyber physical attacks. It is also used to facilitate the investigation or analysis of what may have induced the occurrence of such anomalous activities. The scope of this research work is on the detection of such anomalous activities from the logs. However, due to the characteristics of logs, namely being voluminous, varied, and contextual, regular log analysis is difficult, warranting the need for automation. While rule or signature-based automation solution helps, the contextual or semantic complexity of logs limits its efficacy [16].</p>
<p>There is many research work done to develop AI algorithms to detect anomalies from logs. However, log analysis using AI algorithms require extensive preparation and data requirements to train the models [6][7]. The capability of log analysis using AI algorithms to detect anomalies has several challenges and constraints to deal with before it contributes significantly to its intended objectives of keeping system resilient. For supervised models, there is the challenge of acquiring sufficient anomalous data points to train such models. For unsupervised models, it will be the ability to detect the variety and variations of anomalies in logs. Recent research work to apply Large Language Models (LLMs) to log analysis processes have shown promising results but are constrained by model limits such as token capacity, ability to remember and hallucinations. Also, there is limited evaluation on its efficacy.</p>
<p>In our research work, we seek to address these constraints using a Retrieval Augmented Generation approach with a vector database and evaluate its performance in detecting log anomalies. Our novel log anomaly detection solution termed RAGLog uses a Retrieval Augmented Generation construct with a vector database to store subset of normal log entries and a Large Language Model to perform zero shot semantic analysis of the queried log entry. Our pipeline process requires minimal</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>data preprocessing and does not require log parsing. It uses unsupervised clustering to enhance log anomaly detection.</p>
<p>In the next section, we will cover the challenges and complexity of performing log analysis. This is followed by a review of current log analysis algorithms including Large Language Models. A coverage of our RAG construct is described in the section that follows with the details of the experimental setup and its evaluation. This paper concludes with a summary of this work and potential future research direction.</p>
<h2>II. BACKGROUND INFORMATION</h2>
<p>In this section, we articulate the background information related to the need for the analysis of logs, its complexity, and challenges with current log analysis algorithms.</p>
<h2>A. Need for Analysis of Logs</h2>
<p>Logs are generated by software driven applications running on systems or devices to provide information to aid developers and system engineers with their analysis of system's state and condition. It is also used as a form of audit trail to log the occurrences of events in chronological manner. The analysis of logs is also done to facilitate investigation after the occurrence of an incident related to the system that generates the logs. This incident could be in the form of system defect and a malicious or unintended breach of the system. With investigation, the log could provide the means to reconstruct the occurrence of the incident. With such forms of analysis, an investigator or system engineer would attempt to identify the occurrence of anomalous events through the logs. However, to identify such anomalies, one would need to know how to spot such anomalies from voluminous entries posted into the log files.</p>
<h2>B. Challenges with Log Analysis</h2>
<p>The form for logs is typically unique to how the software has been developed or configured to post entries into these textual files. Also, each system or software component may adopt its own logging format and information lexicon representation that details the state of the run-time system when logs are posted. Such information within the logs is highly context specific to the environment which the system resides in [16]. For example, information like the IP addresses or hostnames or resource identities. Entries in the logs are dependent also on the configuration surrounding the involved system and their own respective environmental conditions. In addition to the contextual settings, the log entries are sequenced by its chronological occurrence of events or state. Hence such log entries have a time dimension.</p>
<p>Hence, the analysis of such log datasets requires contextual understanding of the system or component that generates such logs. Also, the analysis requires the means to classify or distinguish what is a normal log entry and what is not a normal log entry. For the latter, such information of recognizing an abnormal entry would be constrained to what may be conceivable based on the engineering design of the system involved or known instances of events that could cause an anomalous event like a cyber security breach attempt. However,
there will be instances where such information or knowledge is only acquired through the occurrence of the event that in turn induces the anomalous log entries. Hence the challenges with log analysis are the need for semantic comprehension [15][16] to perform good log analysis and the challenge of having limitedly available information about the form of anomalies that could occur.</p>
<h2>C. Challenges with Large Language Models</h2>
<p>Current Large Language Models (or Generative Artificial Intelligence) have inherent limitations that includes limits to the size of the tokens that they can handle which in turns limits how much contextual information LLMs can take in or recall as well as potential for hallucinations [17]. Solutions are being researched upon to address such limitations with information retrieval techniques that will be described in subsequent sections.</p>
<h2>III. Related Work</h2>
<p>In this section, we review the current log analysis algorithmic development and their strengths and limitations.</p>
<h2>A. Multi-staged Log Processing</h2>
<p>The current log analysis algorithmic designs typically involve multiple stages of log processing before analysis is applied. It typically starts with log parsing that converts raw logs into structured data features. These extracted features would undergo further transformation as they are typically represented as textual features and would be converted to numerical forms. Log partitioning typically follows that involves converting the contiguous $\log$ into associative partitions to improve anomaly classification. This may involve the use of time-based partitions, partitions organized by windows of similar or compatible operations or identifier-based divisions of log entries. Finally, the anomaly detection algorithm would then be applied after these pre-processing.</p>
<p>Thus far, there are very few developmental attempts to develop an integrated model that could ingest raw log data for immediate model training and inference. Based on our survey, one by Hashemi and Mäntylä [5] and Le and Zhang [15] ingress logs without log parsers. Le and Zhang observed that log parsers could cause inaccurate log parsing due to misinterpretation of the semantic meaning of the log analysis and not handle Out-ofvocabulary (OOV) words well. Our approach removes the need for log parsing, allowing inferences on raw log data inputs.</p>
<h2>B. Algorithms to detect Anomalous Events from Logs</h2>
<p>Many of the log analysis algorithms focused on the key area of detecting anomalous events from logs. From the survey work done by He et al. [6] and Chen et al. [7], the algorithms are either supervised or unsupervised machine learning algorithms. These algorithms may be based on classical machine learning algorithms or deep learning algorithms. Supervised learning algorithms are constrained by the availability of anomalous data with labels within the training datasets. Additionally, even with the availability of anomalous data within the log datasets, the class imbalance could pose a significant challenge to the training</p>
<p>of the model. Also, these models may need to undergo retraining or be reconstructed to internalize the new knowledge. With unsupervised learning algorithms [12][13] for log analysis, their challenge is the efficiency of the algorithms to detect the variety and variations of anomalies captured in log entries as such anomalies may occur and vary significantly over a prolonged period of time. When new anomalies are discovered, these unsupervised models will require retraining. Our approach uses the vector database to store only small samples of normal log entries. The LLM will do anomaly detection without any samples of anomalous log entries. Hence it is a zero shot classifier.</p>
<h2>C. LLM for Log Analysis</h2>
<p>There were recent attempts to apply Large Language models to perform log analysis. Qi et al. [18] proposed a framework for log-based anomaly detection using ChatGPT using varied prompt constructs, window sizes and input sequences. Their work showed the non-triviality of an optimal prompt, window size limitations as well as high false positive rates. Mudgal et al. [19] designed specific prompts with ChatGPT for log parsing that had excellent performance. However, with other areas of log analysis like anomaly detection and log summarization, the LLM exhibited limitations that warrant further research. Liu et al. [20] tested their LogPrompt model in zero-shot scenarios with varying number of provided log samples and different prompt formats (self-prompt, CoT prompts and In-context Prompt). The zero-shot test results showed promise when compared with our log analysis algorithms and other Deep Learning architectures. However, it had very low precision scores which is not optimal if applied to log analysis for operations and maintenance activities to support resiliency.</p>
<p>These preliminary experimentations demonstrate the necessity for further research in applying LLM for log analysis, especially in detecting anomalies in logs, forming the basis of this research work.</p>
<h2>IV. MODEL</h2>
<p>Our construct uses the Retrieval Augmented Generative (RAG) model [22] to analyze log entries by querying its store of samples of normal log entries. In our work, the store is a vector database. The Large Language Model would need to perform semantic analysis between the retrieved log samples from the database and the queried log entry.</p>
<p>This creates an end-to-end model construct that is simple to use and adept for any log source, unlike many other similarly purposed algorithms mentioned in our previous section for log analysis which require the use of multi-stage log processing pipeline.</p>
<h2>A. Formulation for RAG</h2>
<p>The RAG operates in two stages. The first is the retrieval of contextually relevant information. The second involves using the retrieved information to generate the corresponding response. This can be formulated with $x$ as the provided input, which is the queried log entry, $z$ as the set of relevant log entries
from the vector database and $y$ as the generated output from the LLM $f$. This can be expressed in the form.</p>
<p>$$
y=f(x, z)
$$</p>
<p>Our model construct uses dense-vector retrieval approach [23] that encodes the log entries into vector embedding representations using a pre-trained Embedding model from OpenAI. The retrieval score is computed through inner products between the queried vector from the provided log entry against vectors stored in the vector database that contains provided samples of normal log entries. When the retrieval score matches the criteria like highest similarity score or minimal threshold score, the vector database will return the resultant vectors. The retriever that we used is from LangChain [24].</p>
<h2>B. LLM for Semantic Analysis</h2>
<p>With the retrieved vectors, the vector embedding will be decoded using the corresponding decoder by Embedding model. This turns the vector back to the original log entry representation. We frame the log anomaly detection as a Question and Answer [23], using a Question and Answer prompt template to include the best matched retrieved normal log entries to analyze whether a queried log entry is normal or abnormal. The prompt is fed to the Language Large Model.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. RAGLog Architecture</p>
<h2>V. Methodology and Analysis</h2>
<p>In our experiment setup, we designed our experiment to address our research question whether Retrieval Augmented Generation in LLM could perform log anomaly detection.</p>
<h2>A. Log Datasets</h2>
<p>For our log datasets, we used BGL [9] and Thunderbird [21]. These are two popular datasets typically used by researchers to evaluate their log models [7].</p>
<p>The BGL are open real-world datasets from HPC from a BlueGene/L supercomputer at Lawrence Livermore National Labs. This dataset has an important characteristic associated with their appearance of many new log messages in the timeline of the data, that is, the systems change over time. The Thunderbird open dataset of logs was collected by Sandia National Lab. It contains alert and non-alert messages. Both</p>
<p>datasets are labelled with sizeable imbalance for the anomaly class.</p>
<h2>B. Evaluation Metrics</h2>
<p>As the dataset used had binary classification labels, we used Precision to measure the accuracy of the model against type I error (true positive) and Recall to measure the accuracy of the models against type II error (true negative). Finally, we used F1 score to measure the harmonic mean of precision and recall.</p>
<p>$$
\begin{gathered}
\text { Precision }=\frac{T P}{T P+F P} \
\text { Recall }=\frac{T P}{T P+F N} \
F 1 \text { score }=2 \times \frac{\text { Precision } \times \text { Recall }}{\text { Precision }+ \text { Recall }}
\end{gathered}
$$</p>
<p>TP (True Positive) represents the number of correctly classified anomalies, TN (True Negative) represents normal log entries and FP (False Positive) is the number of incorrect anomaly classification. FN (False Negative) is the number of incorrect classifications of log entries as normal while the label or ground truth states overwise.</p>
<h2>C. Experimentation Preparation and Evaluation</h2>
<p>We populated the vector database using two approaches. The first approach was to populate the database with randomly selected samples from the log datasets that contain only normal log entries. The second approach was to populate the database with selected samples of the log database with normal log entries. For this selection, we first applied unsupervised k-means clustering to the dataset and populated the database from random sampling from the cluster classes. We used the elbow approach to select the number of cluster classes. For both approaches, to facilitate our evaluation, we kept the same number of records persisted in the vector databases.</p>
<p>While we applied the same evaluation techniques for both log datasets, we observed notable differences in the distribution of log patterns for both: namely, BGL has a wider distribution surface compared to Thunderbird. The following are the kmeans clustering visualizations of both datasets.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Chart 1. BGL Cluster Visualization Map
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Chart 2. Thunderbird Cluster Visualization Map
For our experiment, we configured the sample size of 10,000 log entries for each cluster class and cluster classes of 5 for BGL dataset. For random sampling, that would be $50,000 \log$ entries that are randomly selected. For Thunderbird, we used the same sample size of 10,000 from each of the 4 classes for the clustered approach and 40,000 for random selection.</p>
<p>After selecting log entries samples, they were then populated into the vector database. Using one predefined prompt template from a Question and Answer pipeline, we will assess the efficacy of our solution to detect log anomalies. In our prompt template, we explicitly directed GPT 3.5 (Davinci) with temperature of 0.1 to generate answers in the form of 'normal' or 'abnormal' to facilitate our evaluation. Due to cost constraints of using GPT 3.5, we randomly sampled from the $20 \%$ of both log datasets that has been set aside for testing.</p>
<h2>D. Results and Analysis</h2>
<p>From our experiment test results shown below in Chart 3, we observed that the clustering approach yielded better results for BGL log datasets as compared to random selection.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Chart 3. Evaluation performance comparison between clustered approach and random selection for both datasets.</p>
<p>The Thunderbird log dataset generally performed well with both randomized and clustering approach. This could be due to concentration of the log pattern distribution for this dataset.</p>
<p>We further evaluated our results with others who had applied zero shot classification using LLM [20]. Also the output from the LLM had either normal or abnormal returns with no other textual hallucination noted.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F1 score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LogPrompt [20]</td>
<td style="text-align: left;">0.25</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">0.38</td>
</tr>
<tr>
<td style="text-align: left;">RAGLog (Ours)</td>
<td style="text-align: left;">0.91</td>
<td style="text-align: left;">0.88</td>
<td style="text-align: left;">0.89</td>
</tr>
</tbody>
</table>
<p>Table 1. Evaluation Comparison for Zero-Shot Classification</p>
<h2>VI. CONCLUSION AND Future DireCTIONS</h2>
<p>Our research work explored the use of Retrieval Augmented Generation model as log anomaly detector (RAGLog). The model's vector database only contained samples of normal log entries that were selected using unsupervised k-means clustering. It achieved good F1 scores when analyzing log entries using zero shot approach for anomalies, with the LLM being given only normal log entries for semantic analysis.</p>
<p>The constraints posed by this approach is the high resource consumption and execution latency for running the LLM and performing log analysis one log entry at a time. Hence, our next step will be to further optimize our RAG model approach to analyze logs faster with larger volumes.</p>
<h2>REFERENCES</h2>
<p>[1] A. Pecchia, D. Cotroneo, Z. Kalbarczyk, and R.K. Iyer, "Improving logbased field failure data analysis of multi-node computing systems", DSN'11: Proc. of the 41st IEEE/IFIP International Conference on Dependable Systems and Networks, pages 97-108. IEEE, 2011.
[2] W. Xu, L. Huang, A. Fox, D. Patterson, and M.I. Jordon, "Detecting large-scale system problems by mining console logs", SOSP'09: Proc. of the ACM Symposium on Operating Systems Principles, 2009.
[3] A. Brandao and P. Georgieva, "Log Files Analysis For Network Intrusion Detection," 2020 IEEE 10th International Conference on Intelligent Systems (IS), 2020, pp. 328-333, doi: 10.1109/IS48319.2020.9199976.
[4] M. Moh, S. Pininti, S. Doddapaneni and T. Moh, "Detecting Web Attacks Using Multi-stage Log Analysis," 2016 IEEE 6th International Conference on Advanced Computing (IACC), 2016, pp. 733-738, doi: 10.1109/IACC.2016.141.
[5] S. Hashemi and M. Mäntylä, "OneLog: Towards End-to-End Training in Software Log Anomaly Detection", arXiv, arXiv:2104.07324, https://doi.org/10.48550/arXiv.2104.07324.
[6] S. He, J. Zhu, P. He and M. R. Lyu, "Experience Report: System Log Analysis for Anomaly Detection," 2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE), 2016, pp. 207218, doi: 10.1109/ISSRE.2016.21.
[7] Z. Chen, J. Liu, W. Gu, Y. Su, and M. R. Lyu, "Experience Report: Deep Learning-based System Log Analysis for Anomaly Detection,", arXiv, arXiv:2107.05908, https://doi.org/10.48550/arXiv.2107.05908.
[8] J. Snell, K. Swersky, and R. S. Zemel, "Prototypical networks for fewshot learning", Neural Information Processing Systems, 2017.
[9] A. Oliner and J. Stearley, "What supercomputers say: A study of five system logs", 37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07). IEEE, pp 575-584, 2007.
[10] V. H. Le and H. Zhang, "Log-based Anomaly Detection without Log Parsing", 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), Nov 2021.
[11] M. Du, F. Li, G. Zheng, and V. Srikumar, "Deeplog: Anomaly detection and diagnosis from system logs through deep learning", Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, 1285-1298, 2017.
[12] A. Farzad and T. A. Gulliver, "Unsupervised log message anomaly detection", ICT Express 6, 3, 229-237, 2020.
[13] D. Biplob, M. Solaimani, M. A. G. Gulzar, N. Arora, C. Lumezanu, J. Xu, B. Zong, H. Zhang, G. Jiang and L. Khan, "LogLens: A real- time log analysis system." In 2018 IEEE 38th international conference on distributed computing systems (ICDCS), pp. 1052-1062. IEEE, 2018.
[14] J. P. Poh, J. Y. C. Lee, K. X. Tan, and E. Tan, "Physical access log analysis: An unsupervised clustering approach for anomaly detection." In Proceedings of the 3rd International Conference on Data Science and Information Technology, pp. 12-18. 2020.
[15] V. H. Le and H. Zhang, "Log-based Anomaly Detection without Log Parsing", 2021 36 $6^{\text {th }}$ IEEE/ACM International Conference on Automated Software Engineering (ASE), Nov 2021.
[16] A. Ekelhart, E. Kiesling and K. Kurniawan, "Taming the logs Vocabularies for semantic security analysis", SEMANTiCS 2028 - $14^{\text {th }}$ International Conference on Semantic Systems, Science Direct, Procedia Comput Science 137, pp. 109-119, 2018.
[17] R. Zhao, H. Chen, W. Wang, F. Jiao, X.L. Do, C Qin, B. Ding, X. Guo, M. Li, X. Li and S. Joty, "Retrieving Multimodal Information for Augmented Generaion: A Survey, arXiv:2303.10868v2, 2023.
[18] J. Qi, S. Huang, Z. Luan, C. Fung, H. Yang and D. Qian, "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection", arXiv:2309.01189v1, 2023.
[19] P. Mudgal and R. Wouhaybi, "An Assessment of ChatGPT on Log Data", arXiv:2309.07938v1, 2023.
[20] Y. Liu, S. Tao, W. Meng, J. Wang, W. Ma, Y. Zhao, Y. Chen, H. Yang, Y. Jiang and X. Chen, "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis", arXiv:2308.07610v1, 2023.
[21] A. Oliner and J. Stearley, "What supercomputers say: A study of five system logs," in DSN, 2007.
[22] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis,W. Yih, T. Rocktäschel, et al., "Retrieval-augmented generation for knowledge-intensive nlp tasks", Advances in Neural Information Processing Systems, 33:9459-9474, 2020.
[23] K. Lee, M. W. Chang, and K. Toutanov, "Latent retrieval for weakly supervised open domain question answering", arXiv:1906.00300, 2019.
[24] H. Chase, LangChain, langchain.com.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>(C) 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other users for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>