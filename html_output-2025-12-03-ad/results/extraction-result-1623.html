<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1623 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1623</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1623</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-18112188</p>
                <p><strong>Paper Title:</strong> <a href="http://www.mdpi.com/1996-1073/8/11/12361/pdf" target="_blank">A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting</a></p>
                <p><strong>Paper Abstract:</strong> : Data mining has become an essential tool during the last decade to analyze large sets of data. The variety of techniques it includes and the successful results obtained in many application ﬁelds, make this family of approaches powerful and widely used. In particular, this work explores the application of these techniques to time series forecasting. Although classical statistical-based methods provides reasonably good results, the result of the application of data mining outperforms those of classical ones. Hence, this work faces two main challenges: (i) to provide a compact mathematical formulation of the mainly used techniques; (ii) to review the latest works of time series forecasting and, as case study, those related to electricity price and demand markets.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1623.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1623.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A population-based stochastic search inspired by biological evolution that applies selection, crossover and mutation operators to candidate solutions to optimize a fitness function.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Algorithm (GA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Population-based evolutionary optimizer that maintains a population of candidate solutions and iteratively applies selection (fitness-based sampling), crossover (recombination of parent genomes with probability p_c) and mutation (random perturbation of genes) to produce new generations, with the goal of finding high-fitness solutions in complex, multimodal search spaces. The paper describes GA as a generic search paradigm and summarizes the common operators and their roles (selection to exploit, crossover to recombine, mutation to introduce novelty).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>numeric parameter vectors / candidate solution encodings</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Generic recombination: two parent individuals are mated with crossover probability p_c; segments/genes from parents are recombined to create offspring (the survey describes the operator conceptually but does not specify a concrete encoding or recombination scheme used in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Generic random perturbation: one or more genes of an individual are randomly changed to introduce new alleles and prevent premature convergence (survey gives conceptual description without specific mutation operators or rates).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Parameter estimation and optimization in time-series models and electricity forecasting tasks (e.g., ARIMA parameter estimation, scheduling problems, model selection).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Classical optimization/estimation methods such as least squares (LS), maximum likelihood (ML), and deterministic optimization; as well as other metaheuristics (PSO, simulated annealing) and statistical baselines (ARIMA, ANN) referenced in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The survey states that evolutionary algorithms (including GAs) are popular for parameter estimation and model selection, often outperforming classical local optimization (LS, ML) because they better explore nonlinear, multimodal likelihood surfaces and avoid local maxima; the paper provides conceptual descriptions of selection, crossover and mutation but does not report quantitative measures of novelty, diversity, executability or functionality for GA runs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1623.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1623.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary method that evolves computer programs (typically tree-structured) using genetic operators analogous to GA (selection, subtree crossover, point/subtree mutation) to produce programs that perform a computational task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Programming (GP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A specialization of genetic algorithms where individuals are executable programs (often represented as syntax trees). GP evolves populations of programs by repeatedly evaluating program fitness on the target task, selecting fitter programs, and producing offspring via program-level crossover (recombining subtrees) and mutation (randomly replacing subtrees or nodes). The survey explains GP fundamentals and outlines the canonical GP cycle (random initial population; evaluate; selection; reproduction via copy, crossover, mutation; iterate).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / tree-structured symbolic expressions (models, forecasting expressions)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Tree-structured crossover: recombination of two parent program trees by selecting crossover points (subtrees) in each parent and exchanging them to form offspring (described conceptually in the GP fundamentals section of the survey).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Tree mutation: random modification of program trees, e.g., replacing a randomly chosen subtree or node with a newly generated subtree or terminal to introduce variation (survey provides conceptual description, not implementation details).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>implicit program fitness (task-specific accuracy/error metrics such as MAE, MAPE, RMSE) — the survey indicates GP fitness is assigned according to program performance on forecasting tasks but does not define separate executability/validity metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Evolving forecasting models/expressions for electricity demand and price prediction (program synthesis for time-series models).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>ANN, neuro-fuzzy systems (EFuNN), RBF networks, ARIMA and other statistical or machine-learning models used in referenced empirical comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The survey reports GP has been applied successfully to electricity demand and price forecasting; variants (linear GP, MGGP, semantic-aware GP) have been tried and in some cases outperformed ANN and other baselines in accuracy or computational cost. The paper emphasizes GP's nature of evolving executable programs (hence using crossover and mutation on program structures) but does not report any explicit metrics for novelty, diversity, or executability beyond task performance (MAE/MAPE/RMSE).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1623.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1623.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EA-ARIMA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary Algorithms for ARIMA Parameter Estimation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of evolutionary/metaheuristic algorithms (including genetic algorithms) to estimate ARIMA model parameters by optimizing error or likelihood objectives, intended to avoid convergence to local optima common in classical methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Evolutionary parameter estimation (GA/other metaheuristics) for ARIMA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Evolutionary approaches search the ARIMA parameter space (orders p,d,q and their coefficients) using population-based stochastic operators. The objective is typically to minimize forecast error (e.g., MSE) or maximize likelihood; evolutionary search helps overcome nonlinearity and multiple local optima in the likelihood surface where classical gradient or closed-form methods may fail.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>numeric model parameters (AR/MA coefficients, differencing order) and model structures</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Parameter recombination: numerical crossover between numeric parameter vectors (e.g., exchanging coefficient subsets between two parent parameter vectors) described generically; the survey notes GAs are applied but does not give algorithmic specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Parameter perturbation: random modification of parameter values (small additive noise or replacement of parameter genes) to introduce exploration; survey describes mutation role conceptually without implementation detail.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>model fitness via forecasting error metrics (e.g., MSE, MAE) or likelihood; the paper cites comparisons using these metrics but does not report specialized executability/validity metrics for generated parameter sets.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>ARIMA model identification and parameter estimation for time-series forecasting (electricity markets and other temporal datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Least squares (LS), maximum likelihood (ML), autocorrelation-based methods; the survey reports evolutionary methods often outperform or are recommended over classical methods in difficult/noisy settings.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey highlights that evolutionary algorithms often yield better parameter estimates for ARIMA in practice because the likelihood surface is highly nonlinear and classical methods can get trapped in local maxima; evolutionary methods are recommended especially as model order increases. No measurements of novelty/diversity/executability beyond forecast-error comparisons are reported.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1623.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1623.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MGGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Gene Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic programming variant where individuals are composed of multiple gene trees whose outputs are linearly combined to form the model output, used to improve modelling flexibility and accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-Gene Genetic Programming (MGGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MGGP represents each individual as a set (linear combination) of GP trees (genes). Each gene is a program/tree and the combined output is a weighted sum of gene outputs, where weights can be learned (e.g., by least squares). The survey cites MGGP as an applied variant for short-term load forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / symbolic expression trees (multiple genes per individual)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>GP-like subtree crossover applied to gene trees and/or exchange of entire genes between individuals; the survey mentions MGGP but does not provide specific crossover mechanics beyond standard GP recombination at tree/gene level.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>GP-like mutation at the subtree or gene level (random subtree replacement or random change of a gene), described only conceptually in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>task fitness (e.g., MAPE, RMSE) used to evaluate evolved multi-gene models; no explicit executability or code-validity metric reported.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Short-term load forecasting (electricity demand), symbolic regression for time-series models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>RBF networks, standard genetic programming, and conventional forecasting models (as reported in cited empirical studies).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MGGP is reported as a useful GP variant applied to load forecasting (cited application to Egypt); the survey notes MGGP was compared with other methods in related work but provides no quantitative novelty/diversity/executability measures in the survey itself.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1623.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1623.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantic-Aware Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GP variant that incorporates semantic information (program behavior/output) into genetic operators or selection to improve search effectiveness and generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Semantic-aware Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An extension of GP that augments operators (crossover/mutation) or selection with semantics (e.g., program outputs on inputs) so that offspring preserve or meaningfully modify behavior; the survey cites an application of semantic-aware GP that improved short-term load forecasting performance over standard GP.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / symbolic expressions (tree-structured), with emphasis on program semantics/behavior</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Semantic-aware subtree crossover: recombination that takes into account program outputs/semantics to guide selection of subtrees to swap, described at a high level in the cited literature and summarized in the survey (survey does not give operator details).</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Semantics-aware mutation: modifications chosen considering their effect on program behavior rather than purely syntactic substitutions; survey mentions the variant but gives no implementation-level detail.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>evaluated by forecasting performance metrics (MAE/MAPE/MSE) in cited studies; the survey reports improved accuracy but does not provide separate executability metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Short-term electricity load forecasting (South Italy case) where semantic-aware GP was applied and compared to standard GP and other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard genetic programming and other machine learning methods (as cited in the related work references).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The survey notes that incorporating semantic awareness into GP improved short-term load forecasting accuracy relative to standard GP and some other ML methods (cited study), but the survey does not report explicit novelty/diversity/executability metrics or quantitative tradeoff analyses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Genetic Programming: On the Programming of Computers by Means of Natural Selection <em>(Rating: 2)</em></li>
                <li>A Linear Genetic Programming Approach for modelling Electricity Demand Prediction in Victoria <em>(Rating: 2)</em></li>
                <li>Day-Ahead Price Forecasting of Electricity Markets by Mutual Information and Cascaded Neuro-Evolutionary Algorithm <em>(Rating: 2)</em></li>
                <li>Turkey's Electricity Consumption Forecasting Using Genetic Programming <em>(Rating: 2)</em></li>
                <li>Multi-Gene Genetic Programming for Short Term Load Forecasting <em>(Rating: 2)</em></li>
                <li>Forecasting short-term electricity consumption using a semantics-based genetic programming framework: The South Italy case <em>(Rating: 2)</em></li>
                <li>Maximum Likelihood Parameter Estimation of F-ARIMA Processes Using the Genetic Algorithm in the Frequency Domain <em>(Rating: 1)</em></li>
                <li>A new genetic fuzzy system approach for parameter estimation of ARIMA model <em>(Rating: 1)</em></li>
                <li>Using genetic algorithms to parameters (d; r) estimation for threshold autoregressive models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1623",
    "paper_id": "paper-18112188",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "GA",
            "name_full": "Genetic Algorithm",
            "brief_description": "A population-based stochastic search inspired by biological evolution that applies selection, crossover and mutation operators to candidate solutions to optimize a fitness function.",
            "citation_title": "A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting",
            "mention_or_use": "mention",
            "system_name": "Genetic Algorithm (GA)",
            "system_description": "Population-based evolutionary optimizer that maintains a population of candidate solutions and iteratively applies selection (fitness-based sampling), crossover (recombination of parent genomes with probability p_c) and mutation (random perturbation of genes) to produce new generations, with the goal of finding high-fitness solutions in complex, multimodal search spaces. The paper describes GA as a generic search paradigm and summarizes the common operators and their roles (selection to exploit, crossover to recombine, mutation to introduce novelty).",
            "input_type": "numeric parameter vectors / candidate solution encodings",
            "crossover_operation": "Generic recombination: two parent individuals are mated with crossover probability p_c; segments/genes from parents are recombined to create offspring (the survey describes the operator conceptually but does not specify a concrete encoding or recombination scheme used in experiments).",
            "mutation_operation": "Generic random perturbation: one or more genes of an individual are randomly changed to introduce new alleles and prevent premature convergence (survey gives conceptual description without specific mutation operators or rates).",
            "uses_literature": false,
            "uses_code": null,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Parameter estimation and optimization in time-series models and electricity forecasting tasks (e.g., ARIMA parameter estimation, scheduling problems, model selection).",
            "comparison_baseline": "Classical optimization/estimation methods such as least squares (LS), maximum likelihood (ML), and deterministic optimization; as well as other metaheuristics (PSO, simulated annealing) and statistical baselines (ARIMA, ANN) referenced in comparisons.",
            "key_findings": "The survey states that evolutionary algorithms (including GAs) are popular for parameter estimation and model selection, often outperforming classical local optimization (LS, ML) because they better explore nonlinear, multimodal likelihood surfaces and avoid local maxima; the paper provides conceptual descriptions of selection, crossover and mutation but does not report quantitative measures of novelty, diversity, executability or functionality for GA runs.",
            "uuid": "e1623.0"
        },
        {
            "name_short": "GP",
            "name_full": "Genetic Programming",
            "brief_description": "An evolutionary method that evolves computer programs (typically tree-structured) using genetic operators analogous to GA (selection, subtree crossover, point/subtree mutation) to produce programs that perform a computational task.",
            "citation_title": "A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting",
            "mention_or_use": "mention",
            "system_name": "Genetic Programming (GP)",
            "system_description": "A specialization of genetic algorithms where individuals are executable programs (often represented as syntax trees). GP evolves populations of programs by repeatedly evaluating program fitness on the target task, selecting fitter programs, and producing offspring via program-level crossover (recombining subtrees) and mutation (randomly replacing subtrees or nodes). The survey explains GP fundamentals and outlines the canonical GP cycle (random initial population; evaluate; selection; reproduction via copy, crossover, mutation; iterate).",
            "input_type": "programs / tree-structured symbolic expressions (models, forecasting expressions)",
            "crossover_operation": "Tree-structured crossover: recombination of two parent program trees by selecting crossover points (subtrees) in each parent and exchanging them to form offspring (described conceptually in the GP fundamentals section of the survey).",
            "mutation_operation": "Tree mutation: random modification of program trees, e.g., replacing a randomly chosen subtree or node with a newly generated subtree or terminal to introduce variation (survey provides conceptual description, not implementation details).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "implicit program fitness (task-specific accuracy/error metrics such as MAE, MAPE, RMSE) — the survey indicates GP fitness is assigned according to program performance on forecasting tasks but does not define separate executability/validity metrics.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Evolving forecasting models/expressions for electricity demand and price prediction (program synthesis for time-series models).",
            "comparison_baseline": "ANN, neuro-fuzzy systems (EFuNN), RBF networks, ARIMA and other statistical or machine-learning models used in referenced empirical comparisons.",
            "key_findings": "The survey reports GP has been applied successfully to electricity demand and price forecasting; variants (linear GP, MGGP, semantic-aware GP) have been tried and in some cases outperformed ANN and other baselines in accuracy or computational cost. The paper emphasizes GP's nature of evolving executable programs (hence using crossover and mutation on program structures) but does not report any explicit metrics for novelty, diversity, or executability beyond task performance (MAE/MAPE/RMSE).",
            "uuid": "e1623.1"
        },
        {
            "name_short": "EA-ARIMA",
            "name_full": "Evolutionary Algorithms for ARIMA Parameter Estimation",
            "brief_description": "Use of evolutionary/metaheuristic algorithms (including genetic algorithms) to estimate ARIMA model parameters by optimizing error or likelihood objectives, intended to avoid convergence to local optima common in classical methods.",
            "citation_title": "A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting",
            "mention_or_use": "mention",
            "system_name": "Evolutionary parameter estimation (GA/other metaheuristics) for ARIMA",
            "system_description": "Evolutionary approaches search the ARIMA parameter space (orders p,d,q and their coefficients) using population-based stochastic operators. The objective is typically to minimize forecast error (e.g., MSE) or maximize likelihood; evolutionary search helps overcome nonlinearity and multiple local optima in the likelihood surface where classical gradient or closed-form methods may fail.",
            "input_type": "numeric model parameters (AR/MA coefficients, differencing order) and model structures",
            "crossover_operation": "Parameter recombination: numerical crossover between numeric parameter vectors (e.g., exchanging coefficient subsets between two parent parameter vectors) described generically; the survey notes GAs are applied but does not give algorithmic specifics.",
            "mutation_operation": "Parameter perturbation: random modification of parameter values (small additive noise or replacement of parameter genes) to introduce exploration; survey describes mutation role conceptually without implementation detail.",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "model fitness via forecasting error metrics (e.g., MSE, MAE) or likelihood; the paper cites comparisons using these metrics but does not report specialized executability/validity metrics for generated parameter sets.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "ARIMA model identification and parameter estimation for time-series forecasting (electricity markets and other temporal datasets).",
            "comparison_baseline": "Least squares (LS), maximum likelihood (ML), autocorrelation-based methods; the survey reports evolutionary methods often outperform or are recommended over classical methods in difficult/noisy settings.",
            "key_findings": "Survey highlights that evolutionary algorithms often yield better parameter estimates for ARIMA in practice because the likelihood surface is highly nonlinear and classical methods can get trapped in local maxima; evolutionary methods are recommended especially as model order increases. No measurements of novelty/diversity/executability beyond forecast-error comparisons are reported.",
            "uuid": "e1623.2"
        },
        {
            "name_short": "MGGP",
            "name_full": "Multi-Gene Genetic Programming",
            "brief_description": "A genetic programming variant where individuals are composed of multiple gene trees whose outputs are linearly combined to form the model output, used to improve modelling flexibility and accuracy.",
            "citation_title": "A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting",
            "mention_or_use": "mention",
            "system_name": "Multi-Gene Genetic Programming (MGGP)",
            "system_description": "MGGP represents each individual as a set (linear combination) of GP trees (genes). Each gene is a program/tree and the combined output is a weighted sum of gene outputs, where weights can be learned (e.g., by least squares). The survey cites MGGP as an applied variant for short-term load forecasting.",
            "input_type": "programs / symbolic expression trees (multiple genes per individual)",
            "crossover_operation": "GP-like subtree crossover applied to gene trees and/or exchange of entire genes between individuals; the survey mentions MGGP but does not provide specific crossover mechanics beyond standard GP recombination at tree/gene level.",
            "mutation_operation": "GP-like mutation at the subtree or gene level (random subtree replacement or random change of a gene), described only conceptually in the survey.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "task fitness (e.g., MAPE, RMSE) used to evaluate evolved multi-gene models; no explicit executability or code-validity metric reported.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Short-term load forecasting (electricity demand), symbolic regression for time-series models.",
            "comparison_baseline": "RBF networks, standard genetic programming, and conventional forecasting models (as reported in cited empirical studies).",
            "key_findings": "MGGP is reported as a useful GP variant applied to load forecasting (cited application to Egypt); the survey notes MGGP was compared with other methods in related work but provides no quantitative novelty/diversity/executability measures in the survey itself.",
            "uuid": "e1623.3"
        },
        {
            "name_short": "Semantic GP",
            "name_full": "Semantic-Aware Genetic Programming",
            "brief_description": "A GP variant that incorporates semantic information (program behavior/output) into genetic operators or selection to improve search effectiveness and generalization.",
            "citation_title": "A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting",
            "mention_or_use": "mention",
            "system_name": "Semantic-aware Genetic Programming",
            "system_description": "An extension of GP that augments operators (crossover/mutation) or selection with semantics (e.g., program outputs on inputs) so that offspring preserve or meaningfully modify behavior; the survey cites an application of semantic-aware GP that improved short-term load forecasting performance over standard GP.",
            "input_type": "programs / symbolic expressions (tree-structured), with emphasis on program semantics/behavior",
            "crossover_operation": "Semantic-aware subtree crossover: recombination that takes into account program outputs/semantics to guide selection of subtrees to swap, described at a high level in the cited literature and summarized in the survey (survey does not give operator details).",
            "mutation_operation": "Semantics-aware mutation: modifications chosen considering their effect on program behavior rather than purely syntactic substitutions; survey mentions the variant but gives no implementation-level detail.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "evaluated by forecasting performance metrics (MAE/MAPE/MSE) in cited studies; the survey reports improved accuracy but does not provide separate executability metrics.",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Short-term electricity load forecasting (South Italy case) where semantic-aware GP was applied and compared to standard GP and other methods.",
            "comparison_baseline": "Standard genetic programming and other machine learning methods (as cited in the related work references).",
            "key_findings": "The survey notes that incorporating semantic awareness into GP improved short-term load forecasting accuracy relative to standard GP and some other ML methods (cited study), but the survey does not report explicit novelty/diversity/executability metrics or quantitative tradeoff analyses.",
            "uuid": "e1623.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection",
            "rating": 2,
            "sanitized_title": "genetic_programming_on_the_programming_of_computers_by_means_of_natural_selection"
        },
        {
            "paper_title": "A Linear Genetic Programming Approach for modelling Electricity Demand Prediction in Victoria",
            "rating": 2,
            "sanitized_title": "a_linear_genetic_programming_approach_for_modelling_electricity_demand_prediction_in_victoria"
        },
        {
            "paper_title": "Day-Ahead Price Forecasting of Electricity Markets by Mutual Information and Cascaded Neuro-Evolutionary Algorithm",
            "rating": 2,
            "sanitized_title": "dayahead_price_forecasting_of_electricity_markets_by_mutual_information_and_cascaded_neuroevolutionary_algorithm"
        },
        {
            "paper_title": "Turkey's Electricity Consumption Forecasting Using Genetic Programming",
            "rating": 2,
            "sanitized_title": "turkeys_electricity_consumption_forecasting_using_genetic_programming"
        },
        {
            "paper_title": "Multi-Gene Genetic Programming for Short Term Load Forecasting",
            "rating": 2,
            "sanitized_title": "multigene_genetic_programming_for_short_term_load_forecasting"
        },
        {
            "paper_title": "Forecasting short-term electricity consumption using a semantics-based genetic programming framework: The South Italy case",
            "rating": 2,
            "sanitized_title": "forecasting_shortterm_electricity_consumption_using_a_semanticsbased_genetic_programming_framework_the_south_italy_case"
        },
        {
            "paper_title": "Maximum Likelihood Parameter Estimation of F-ARIMA Processes Using the Genetic Algorithm in the Frequency Domain",
            "rating": 1,
            "sanitized_title": "maximum_likelihood_parameter_estimation_of_farima_processes_using_the_genetic_algorithm_in_the_frequency_domain"
        },
        {
            "paper_title": "A new genetic fuzzy system approach for parameter estimation of ARIMA model",
            "rating": 1,
            "sanitized_title": "a_new_genetic_fuzzy_system_approach_for_parameter_estimation_of_arima_model"
        },
        {
            "paper_title": "Using genetic algorithms to parameters (d; r) estimation for threshold autoregressive models",
            "rating": 1,
            "sanitized_title": "using_genetic_algorithms_to_parameters_d_r_estimation_for_threshold_autoregressive_models"
        }
    ],
    "cost": 0.0158685,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting
19 November 2015</p>
<p>Francisco Martínez-Álvarez 
Division of Computer Science
Universidad Pablo de Olavide
ES-41013SevilleSpain</p>
<p>Alicia Troncoso 
Division of Computer Science
Universidad Pablo de Olavide
ES-41013SevilleSpain</p>
<p>Gualberto Asencio-Cortés 
Division of Computer Science
Universidad Pablo de Olavide
ES-41013SevilleSpain</p>
<p>José C Riquelme riquelme@us.es 
Department of Computer Science
University of Seville
41012SevilleSpain</p>
<p>A Survey on Data Mining Techniques Applied to Electricity-Related Time Series Forecasting
19 November 20159B3A7578BFF19E62056E0031E6B1BBC810.3390/en81112361Received: 16 July 2015 ; Accepted: 6 November 2015 ;energytime seriesforecastingdata mining
Data mining has become an essential tool during the last decade to analyze large sets of data.The variety of techniques it includes and the successful results obtained in many application fields, make this family of approaches powerful and widely used.In particular, this work explores the application of these techniques to time series forecasting.Although classical statistical-based methods provides reasonably good results, the result of the application of data mining outperforms those of classical ones.Hence, this work faces two main challenges: (i) to provide a compact mathematical formulation of the mainly used techniques; (ii) to review the latest works of time series forecasting and, as case study, those related to electricity price and demand markets.</p>
<p>Introduction</p>
<p>The prediction of the future has fascinated the human being since its early existence.Actually, many of these efforts can be noticed in everyday events such as energy management [1], telecommunications [2], pollution [3], bioinformatics [4], earthquakes [5], and so forth.Accurate predictions are essential in economical activities as remarkable forecasting errors in certain areas may involve large loss of money.</p>
<p>Given this situation, the successful analysis of temporal data has been a challenging task for many researchers during the last decades and, indeed, it is difficult to figure out any scientific branch with no time-dependant variables.</p>
<p>A thorough review of the existing techniques devoted to forecast time series is provided in this survey.Although a description of classical Box-Jenkins methodology is also discussed, this text is particularly focused on those methodologies that make use of data mining techniques.Moreover, a family of energy-related time series are examined due to the scientific relevance exhibited during the last decade: electricity price and demand time series.These series have been chosen since they present some peculiarities such as nonconstant mean and variance, high volatility or presence of outliers, that turns the forecasting process into a particularly difficult task to fulfil.</p>
<p>Actually, the electric power markets have become competitive markets due to the deregulation carried out in the last years, allowing the participation of all buyers, producers, investors or traders.Thus, the price of the electricity is determined on the basis of this buying/selling system.Consequently, electricity-producer companies need to develop methods for optimal bidding [6].</p>
<p>On the other hand, load forecasting or demand forecasting consists in forecasting the amount of required electricity for a particular period of time.The demand forecasting plays an important role for electricity power suppliers because both excess and insufficient energy production may lead to large costs and significative reduction of benefits.Some works have already reviewed electricity price time series forecasting techniques.For instance, [7] collates a massive review of artificial neural networks, but it barely reviews other data mining techniques.Also, Weron [8] presented an excellent review, describing many different approaches for several markets.However, none of them are focused on the whole data mining paradigm.Moreover, they do not provide mathematical foundations for all the methods they evaluated.Indeed, this is maybe the most significative strength of the paper, since information relating to underlying mathematics is provided, as well as an exhaustive description of the measures typically used to evaluate the performance.In short, this survey is to provide the reader with a general overview of current data mining techniques used in time series analysis and to highlight all the skills these techniques are exhibiting nowadays.As case study, their application to a real-world energy-related set of series is reported.</p>
<p>As it will be shown in subsequent sections, the majority of the techniques have been applied to Pennsylvania-New Jersey-Maryland (PJM) [9], New York (NYSIO) [10] and Spain (OMEL) [11] electricity markets.By contrast, both Australian National Electricity Market (ANEM) [12] and Ontario [13] follow a single settlement real-time structure and few researchers have dealt with such markets.ANEM is also well-known for its volatility and its frequent appearance of outliers, turning this market into a perfect target for robust forecasting.Additionally, the Californian electricity market (CAISO) [14] has also been widely analyzed because of the well-known problems that it experienced in the second half of 2000's.Some other markets appear in this work, given the relevance of the model applied.Such are the cases for the UK, India, Malaysia, Finland, Turkey, Egypt, Nord Pool, Brazil, Jordan, China, Taiwan or Greece.Note that most of them provide public access to data.</p>
<p>The remainder of this work is structured as follows.Section 2 provides a formal description of a time series and describes its main features.</p>
<p>Section 3 describes statistical indicators and errors typically used in this field.Also, the concept of persistence model and forecasting skill is here described.</p>
<p>In particular, Section 4 describes the approaches based on linear methods.Classical Box and Jenkins-based methods such as AR, MA, ARMA, ARIMA, ARCH, GARCH or VAR are thus reviewed.Note that from this section on, all sections consist of a brief mathematical description of the technique analyzed and a review of the most representative works.</p>
<p>As for Section 5, it is a compendium of the non-linear forecasting techniques currently in use in the data mining domain.In particular, these methods are divided into global (neural networks, support vector machines, genetic programming) and local (nearest neighbors).</p>
<p>In Section 6, rule-based forecasting methods are analyzed, providing a brief explanation of what a decision rule is, and revisiting the latest and most relevant works in this domain.</p>
<p>The use of wavelets, as relevant method for hybridization, is detailed in Section 7 as well as discussing the most relevant improvements achieved by means of these techniques.</p>
<p>A compilation of several works that cannot be classified in none of the aforementioned groups is described in Section 8. Thus, forecasting approaches based on Markov processes, on Grey models, on Pattern-Sequence similarity or on manifold dimensionality reduction, are there detailed.</p>
<p>Due to the large amount of ensemble models that are being used nowadays, Section 9 is devoted to cover these methods.</p>
<p>Finally, the conclusions drawn from the exploration of all existing techniques are summarized in Section 10.</p>
<p>Time Series Description</p>
<p>This section is to describe temporal data features as well as to provide mathematical description for such a kind of data.Thus, a time series can be understood as a sequence of values observed over time and chronologically ordered.Time is a continuous variable, however, samples are recorded at Energies 2015, 8, 13162-13193 constant intervals in practice.When the time is considered as a continuous variable, the discipline is commonly referred as functional data analysis [15].The description of this category is out of scope in this survey.</p>
<p>Let y t , t = 1, 2, ..., T be the historical data of a given time series.This series is thus formed by T samples, where each y i represents the recorded value of the variable y at time i.Therefore, the forecasting process consists in estimating the value of y T+1 ( ŷT+1 ) and, the goal, to minimize the error, which is typically represented as a function of y T+1 − ŷT+1 .This estimation can be extended when the horizon of prediction is greater than one, that is, when the objective is to predict a sample at a time T + h ( ŷT+h ).In this situation, the best prediction is reached when a function of ∑ h i=1 (y T+i − ŷT+i ) is minimized.</p>
<p>Time series can be graphically represented.In particular, the x-axis identifies the time (t = 1, 2, ..., T) whereas the y-axis the values recorded at punctual time stamps (y t ).This representation allows the visual detection of the most highlighting features of a series, such as oscillations amplitude, existing seasons and cycles or the existence of anomalous data or outliers.Figure 1 illustrates, as example, the price evolution for a particular period of 2006 in the Spanish electricity market.An usual strategy to analyze time series is to decompose them in three main components [16,17]: trend, seasonality and irregular components, also known as residuals.</p>
<ol>
<li>Trend.It is the general movement that the variable exhibits during the observation period, without considering seasonality and irregulars.Some authors prefer to refer the trend as the long-term movement that a time series shows.Trends can present different profiles such as linear, exponential or parabolic.2. Seasonality.This component typically represents periodical fluctuations of the variable subjected to analysis.It consists of the effects reasonably stable along with the time, magnitude and direction.It can arise from several factors such as weather conditions, economical cycles or holidays.3. Residuals.Once the trend and cyclic oscillations have been calculated and removed, some residual values remain.These values can be, sometimes, high enough to mask the trend and the seasonality.In this case, the term outlier is used to refer these residuals, and robust statistics are usually applied to cope with them [18].These fluctuations can be of diverse origin, which makes the prediction almost impossible.However, if by any chance, this origin can be detected or modeled, they can be thought of precursors in trend changes.Obviously, real-world time series present a meaningful irregular component, which makes their prediction a especially hard task to fulfil.Some forecasting techniques are focused on detecting trend and seasonality (especially traditional classical methods), however, residuals are the most challenging component to be predicted.The effectiveness of one technique or another is assessed according to its capability of forecasting this particular component.It is for the analysis of this component where data mining-based techniques has been shown to be particularly powerful, as this survey will attempt to show in next sections.</li>
</ol>
<p>Accuracy Measures</p>
<p>The purpose of error measures is to obtain a clear and robust summary of the error distribution.It is common practice to calculate error measures by first calculating a loss function (usually eliminating the sign of the single errors) and then computing an average.Let in the following y t be the observed value at time t, also called the reference value, and let ŷt be the forecast for y t .</p>
<p>The error E t is then computed by y t − ŷt .Hyndman and Koehler [19] give a detailed review of different accuracy measures used in forecasting and classify the measures into the groups detailed in subsequent sections.</p>
<p>Scale-Dependent Measures</p>
<p>There are some commonly used accuracy measures whose scale depends on the scale of the data.These are useful when comparing different methods on the same set of data, but should not be used, for example, when comparing across data sets that have different scales.</p>
<p>The most commonly used scale-dependent measures are based on the absolute error AE t = |y t − ŷt | or squared error SE t = (y t − ŷt ) 2 .These errors are averaged by arithmetic mean or median, leading to the mean absolute error (MAE, Equation (1)), the median absolute error (MDAE, Equation (2)), the mean squared error (MSE, Equation (3)) or the root mean squared error (RMSE, Equation ( 4)).
MAE = 1 n n ∑ t=1 |y t − ŷt |(1)MDAE = median(|y t − ŷt |)(2)
Energies 2015, 8, 13162-13193
MSE = 1 n n ∑ t=1 (y t − ŷt ) 2 (3) RMSE = 1 n n ∑ t=1 (y t − ŷt ) 2(4)
When comparing forecast methods on a single data set, the MAE is popular as it is easy to understand and compute.While MAE do not penalize extreme forecast errors, MSE and RMSE emphasize the fact that the total forecast error is in fact much affected by large individual errors, i.e., large errors are much expensive than small errors.Often, the RMSE is preferred to the MSE as it is on the same scale as the data.However, MSE and RMSE are more sensitive to outliers than MAE or MDAE.</p>
<p>Percentage Errors</p>
<p>To address the scale-dependency, the error can be divided by the reference value.Thus, the percentage error (PE) is given by 100(y t − ŷt )/(y t ).Percentage errors have the advantage of being scale-independent and, therefore, they are frequently used to compare forecast performance across different data sets.The most commonly used measure is the Mean Absolute Percentage Error (MAPE, Equation ( 5)).
MAPE = 1 n n ∑ t=1 100 y t − ŷt y t(5)
These measures have the disadvantage of being infinite or undefined if y t = 0 for any t in the period of interest, and having an extremely skewed distribution when any y t is close to zero.Where the data involves small counts (which is common with intermittent demand data) it is impossible to use these measures as occurrences of zero values of y t occur frequently.</p>
<p>By using the median for averaging these problems are easier to deal with, as single infinite or undefined values do not necessarily result in an infinite or undefined measure.However, they also have the disadvantage that they put a heavier penalty on positive errors than on negative errors.This observation led to the use of the so-called symmetric measures sMAPE and sMdAPE, defined in Equations ( 6) and (7).
sMAPE = 1 n n ∑ t=1 200 |y t − ŷt | |y t | + | ŷt | (6) sMdAPE = median 200 |y t − ŷt | |y t | + | ŷt |(7)</p>
<p>Relative Errors</p>
<p>An alternative way of scaling is to divide each error by the error obtained using another standard method of forecasting as benchmark.Let r t = e t /e * t denote the relative error where e * t is the forecast error obtained from the benchmark method.Usually, the benchmark method is the random walk where ŷt is equal to the last observation.Then we can define Mean Relative Absolute Error (MRAE, Equation ( 8)) and Median Relative Absolute Error (MdRAE, Equation (9)).
MRAE = mean(|r t |) (8) MdRAE = median(|r t |)(9)
A serious deficiency in relative error measures is that e * t can be small.In fact, r t has infinite variance because e * t has positive probability density at 0. One common special case is when e t and e * t are normally distributed, in which case r t has a Cauchy distribution.</p>
<p>Energies 2015, 8, 13162-13193</p>
<p>Relative Measures</p>
<p>Rather than use relative errors, one can use relative measures.For example, let MAE b denote the MAE from the benchmark method.Then, a relative MAE is given by:
RelMAE = MAE/MAE b(10)
Similar measures can be defined using RMSE, MDAE or MAPE.An advantage of these methods is their interpretability.For example relative MAE measures the possible improvement from the proposed forecast method relative to the benchmark forecast method.When Rel MAE &lt; 1, the proposed method is better than the benchmark method and when Rel MAE &gt; 1, the proposed method is worse than the benchmark method.</p>
<p>When the benchmark method is a random walk, and the forecasts are all one-step forecasts, the relative RMSE is the Theil's U statistic, as defined in Equation (11).The random walk (where ŷt is equal to the last observation) is the most common benchmark method for such calculations.
U = 1 n ∑ n t=1 (y t − ŷt ) 2 1 n ∑ n t=1 y 2 t 1 n ∑ n t=1 ŷ2 t(11)
The Theil's U statistic is a normalized measure of total forecasting error and 0 ≤ U ≤ 1.This measure is affected by change of scale and data transformations.For assessing good forecast accuracy, it is desirable that the Theil's U statistic is close to zero.U = 0 means a perfect fit.</p>
<p>Persistence Model</p>
<p>The persistence model is an important dynamic property of any time series and usually related to memory properties.Specifically, a time series is a persistent process if the effect of infinitesimally small shock will influence future predictions of the time series for a very long time.Thus the longer the influence time the longer is the persistence.</p>
<p>If a series suffers an external shock, the persistence degree provides information about the impact of the shock on such series, whether it will soon revert to its mean path or it will be further pushed away from the mean path.In case of a highly persistence series, a shock to the series tends to persist for long and the series drifts away from its historical mean path.On the contrary, for the case of a time series with low persistence degree after a shock, the time series tends to get back to its historical mean path.</p>
<p>The persistence of a time series model has been measured by different ways in literature [20].</p>
<p>Forecasting Skill</p>
<p>The forecasting skill is a type of measures that scores the ability of a forecasting method to predict future values of a time series with respect to a reference model as benchmark.The forecasting skill is a scaled representation of the relative forecasting error and its purpose is the same of the relative measures introduced in Subsection 3.4.</p>
<p>The most commonly used forecasting skill measure is shown in Equation (12) and it is based on the previously introduced mean squared error (MSE, see Equation ( 3)).MSE is the error of the tested forecasting method and MSE b is the error of the reference benchmark.
SS = 1 − MSE MSE b(12)
A perfect forecast skill implies SS = 1, a forecast with similar skill to the benchmark forecast produces a SS close to 0, and a forecast which is less skillful than the benchmark would produce a negative SS value.</p>
<p>Forecasting Based on Linear Methods</p>
<p>There exist real complex phenomena that cannot be represented by means of linear difference equations since they are not fully deterministic.Therefore, it may be desirable to insert a random component in order to allow a higher flexibility on its analysis.</p>
<p>Linear forecasting methods are those that try to model a time series behavior by means of a linear function.From all the existing techniques, seven of them are quite popular: AR, VAR, MA, ARMA, ARIMA, ARCH and GARCH.These models follow a common methodology, whose application to time series analysis was first introduced by Box and Jenkins.The original work has been extended and published many times since its first apparition in 1970, but the newest version can be found in [21].</p>
<p>Autoregressive -AR(p)-, moving average -MA(q)-, mixed -ARMA(p, q)autoregressive integrated moving average -ARI MA(p, d, q)autoregressive conditional heteroskedastic -ARCH(q)-and generalized autoregressive conditional heteroskedastic -GARCH(p, q)models were described following this idea, where p is the number of autoregressive parameters, q is the number of moving average parameters and d is the number of differentiations for the series to be stationary.Vector autoregressive models -VAR(p)-are the natural extension for AR models to multivariate time series, where p denotes the number of lags considered in the system.</p>
<p>Autoregressive Processes</p>
<p>An autoregressive process (AR) is denoted by AR(p), where p is the order of the AR process.This process assumes that every y t can be expressed as a linear combination of some past values.It is a simple model but that adequately describes many real complex phenomena.The generalized AR model of order p is described by:
y t = p ∑ i=1 α i y t−i + t(13)
where α i are the coefficients that models the linear combination, t the adjustment error, and p the order of the model.When the error is small compared to the actual values, a future value can be estimated as follows:
ŷt = y t + t = p ∑ i=1 w i y t−i(14)</p>
<p>Vector Autoregressive Models</p>
<p>Vector autoregressive models (VAR) are the natural extension of the univariate AR to multivariate time series.VAR models have shown to be especially useful to describe dynamic behaviors in time series and therefore to forecast.In a VAR process of order p with N variables -VAR(p)-, N different equations are estimated.In each equation a regression of the target variable over p lags is carried.</p>
<p>Unlike the univariate case, VAR allow that each series to be related with its own lag and the lag of the other series that form the system.For instance, in two time series systems, there are two equations, one for each variable.This two-series system (VAR(1), N = 2) can be mathematically expressed as follows:
y 1,t = α 11 y 1,t−1 + α 12 y 2,t−1 + 1,t(15)y 2,t = α 21 y 1,t−1 + α 22 y 2,t−1 + 2,t(16)
where y i,t for i = 1, 2 are the series to be modeled, and α's the coefficients to be estimated.</p>
<p>Energies 2015, 8, 13162-13193</p>
<p>Note that the selection of an optimum length of the lag is a critical task for VAR processes and, for this reason, has been widely discussed in literature [22].</p>
<p>Moving Average Processes</p>
<p>When the error t cannot be assumed as negligible, AR processes are not valid.In this situation it is practical to use the moving average (MA) process, where the series is represented as linear combination of the error values:
y t = q ∑ i=1 β i t−i (17)
where q is the order of the MA model and β i the coefficients of the linear combination.As observed, it is not necessary to make explicit use of past values of y t to estimate its future value.Finally, MA processes are seldom used alone in practice.</p>
<p>Autoregressive Moving Average Processes</p>
<p>Autoregressive and moving average models are combined in order to generate better approximations than that of Wold's representation [23].This hybrid model is called autoregressive moving average process (ARMA) and denoted by ARMA(p, q).Formally:
y t = p ∑ i=1 α i y t−i + q ∑ i=1 β i t−i + t(18)
Again, ARMA assumes that t is small compared to y t to estimate future values of y t .The estimates of t past values at time t − i can be obtained from past actual values of y t and past estimated values of ŷt :
êt−i = y t−i − ŷt−i(19)
Therefore, the estimate for ŷt is calculated as follows:
ŷt = p ∑ i=1 α i y t−i + q ∑ i=1 β i ˆ t−i(20)</p>
<p>Generalized Autoregressive Conditional Heteroskedastic Processes</p>
<p>Autoregressive conditional heteroskedastic processes (ARCH), firstly presented in [24], or extended ARCH models, called generalized autoregressive conditional heteroskedastic processes (GARCH), introduced in [25], are especially designed to deal with volatile time series, that is, with series that exhibit high volatility and outlying data (for detailed information refer to [26,27]).The ARCH model considers that the conditional variance is dependent of the time, namely, a MA process of order q of the square error values:
σ( t | t−1 ) = q ∑ i=1 β i 2 t−i (21)
The extension of an ARCH model to a GARCH model is similar to the extension of AR models to ARMA models.The conditional variance depends on their own past values in addition to the past values of the square errors:
σ( t | t−1 ) = p ∑ i=1 α i σ( t−i | t−i−1 ) + q ∑ i=1 β i 2 t−i (22)
Energies 2015, 8, 13162-13193</p>
<p>Autoregressive Integrated Moving Average Processes</p>
<p>Autoregressive integrated moving average processes (ARIMA) are the most general methods and are the result of combining AR and MA processes.ARIMA models are denoted as ARI MA(p, d, q), where p is the number of autoregressive terms, d the number of nonseasonal differences, and q the number of lagged forecast errors in the prediction equation.These models follows a common methodology, whose application to time series analysis was first introduced by Box and Jenkins [21].Thus, this methodology proposes an iterative process formed by four main steps as illustrated in Figure 3. 1. Identification of the model.The first task to be fulfilled is to determine wether the time series is stationary or not, that is, to determine if the mean and variance of a stochastic process do not vary along with time.If the time series does not satisfy this constraint, a transformation has to be applied and the time series has to be differentiated until reaching stationarity.The number of times that the series has to be differentiated is denoted by d and is one of the parameters to be determined in ARIMA models.2. Estimation of the parameters.Once d is determined, the process is reduced to an ARMA model with parameters p and q.These parameters can be estimated by following non-linear strategies.From all of them, three stand out: the evolutionary algorithms, the least squares (LS) minimization and the maximum likelihood (ML).Evolutionary algorithms and LS consist in minimizing the square error of forecasting for a training set while the ML consists in maximizing the likehood function, which is proportional to the probability of obtaining the data given the model.</p>
<p>Comparisons between different Box-Jenkins time series models can be easily found in the literature [28][29][30][31], but there are very few works comparing the results of different parameter estimation methods.ML and LS were compared in [32] to obtain an ARIMA model to predict the gold price.The results reported an error of 0.81% and 2.86% when using a LS and a ML, respectively.A comparative analysis between autocorrelation function, conditional likelihood, unconditional likelihood and genetic algorithms in the context of streamflow forecasting was made in [33].Although similar results were obtained by the four methods, the autocorrelation function and the methods based on ML were the most computationally cost, especially when increased the order of the model.For that, the authors finally recommended the use of evolutionary algorithms.</p>
<p>The good performance of several metaheuristics to solve optimization problems along with the limitations of the classical methods, such as the low precision and poor convergence, has motivated the appearance of recent works comparing evolutionary algorithms and traditional methods for parameter estimation in time series models [34,35].In general, evolutionary algorithms obtain better results due to the likelihood function is highly nonlinear, and therefore, conventional methods usually converge to a local maxima contrarily to genetic algorithms, which tend to find the global maxima [36].3. Validation of the model.Once the ARIMA model has been estimated several hypotheses have to be validated.Thus, the fitness of the model, the residual values or the significance of the coefficients forming the model are forced to agree with some requirements.In cases in which this step is not fulfilled, the process begins again and the parameters are recalculated.</p>
<p>In particular, an ARIMA model is validated if estimated residuals behave as white noise, that is, if they exhibit normal distribution as well as constant variance and null mean and covariance.</p>
<p>To determine if they are white noise, autocorrelation and partial autocorrelation functions are calculated.These values must be significatively small.</p>
<p>Additionally, to assess different models' performance, Akaike information criterion (AIC) and Bayesian information criterion (BIC) measures are typically used (instead of classical error measures, such as MAE or RMSE) given their ability to avoid the overfitting that overparameterization causes.</p>
<p>A problem with the AIC is that it tends to overestimate the number of parameters in the model and this effect can be important in small samples.If AIC and BIC are compared, it can be seen that the BIC penalizes the introduction of new parameters more than the AIC does, hence it tends to choose more parsimonious models [37].4. Forecasts.Finally, if the parameters have been properly determined and validated, the system is ready to perform forecasts.</p>
<p>Related Work</p>
<p>The authors in [38] used the GARCH method to forecast the electricity prices in two regions of New York.The obtained results were compared to different techniques such as dynamic regression (DR), transfer function models (TFM) and exponential smoothing.They also showed that accounting for the spike values and the heteroscedastic variance in these time series could improve the forecasting, reaching error rates lesser than 2.5%.</p>
<p>García et al. [39] proposed a forecasting technique based on a GARCH model.Hence, this paper focused on day-ahead forecast of electricity prices with high volatility periods.The proposal was tested on both mainland Spanish and California deregulated markets.Also related with electricity prices time series, the approach proposed by Malo et al. in [40] was equally noticeable.In it, the authors considered a variety of specification tests for multivariate GARCH models that were used in dynamic hedging in the Nordic electricity markets.Moreover, hedging performance comparison were conducted in terms of unconditional and conditional ex-post variance.</p>
<p>An application of ARMA models to electricity prices can be found in [41], where the exogenous variable is the electricity demand.The study was carried out with data of California.The average error verges on 10%.</p>
<p>In [42] ARIMA models, selected by means of Bayesian Information Criteria, were proposed to obtain the forecasts of electricity prices in the Spanish market.In addition, the work analyzed the optimal number of samples used to build the prediction models.</p>
<p>Weron et al. [43] presented twelve parametric and semi-parametric time series models to predict electricity prices for the next day.Moreover, in this work forecasting intervals were provided and evaluated taking into account the conditional and unconditional coverage.They concluded that the intervals obtained by semi-parametric models are better than that of parametric models.</p>
<p>Table 1 summarizes the content of this section.Note that 5+ models means that the approach has been compared to five or more models.As it can be appreciated, linear methods were very popular at the beginning of 2000's as main methods to make predictions.However, nowadays, these kind of methods have turned into baselines for other methods to be compared to.</p>
<p>Forecasting Based on Non-Linear Methods</p>
<p>Non linear forecasting methods are those that try to model a time series behavior by means of a non linear function.This function is often generated by lineally combining non-linear functions whose parameters have to be determined.Moreover, the non linear methods can be classified in global or local methods depending on the characteristics required for the function to find.</p>
<p>Global Methods</p>
<p>On the other hand, global methods are based on finding a linear function able to model the output data from the input ones.Several techniques form this family of methods, among which the most important are: artificial neural networks, whose main advantage is that they do not need to know the input data distribution; the support-vector machines, which are very powerful classifiers that follow a philosophy similar to that of the artificial neural networks; and genetic programming, where the type of non-linear function that models the data behavior can be selected.</p>
<p>Artificial Neural Networks</p>
<p>This section is devoted to artificial neural networks (ANN) which have widely applied for forecasting energy time series.In particular, a general description is presented in Section 5.1.1.1 and two specific ANN, namely extreme learning machine (ELM) and self-organizing Kohonen's maps (SOM) are introduced in Sections 5.1.1.2and 5.1.1.3,respectively.Finally, Section 5.1.1.4presents a review of recently published literature related to ANN.</p>
<p>Fundamentals</p>
<p>ANNs were originally conceived by McCulloch and Pitts in [44].These mechanisms search for solving problems by using systems inspired in the human brain and not by applying step by step as usually happens in most techniques.Therefore, these systems own a certain intelligence resulting from the combination of simple interconnected units -neurons-that work in parallel in order to solve several tasks, such as prediction, optimization, pattern recognition or control.</p>
<p>Neural networks are inspired in the structure and running of nervous systems, in which the neuron is the key element due to its communication ability.The existing analogies between ANN and the synaptic activity are now explained.Signals that arrive to the synapse are the neuron's inputs and can be whether attenuated or amplified by means of an associated weight.These input signals can excite the neuron if a positive weighted synapsis is carried out or, on the contrary, they can inhibit it if the weight is negative.Finally, if the sum of the weighted inputs is equal or greater than a certain threshold, the neuron is activated.Neurons present, consequently, binary results: activation or not activation.Figure 4 illustrates an usual structure of an ANN.</p>
<p>There are three main features that characterize a neural network: topology, learning paradigm and the representation of the information.A brief description of them are now provided.</p>
<ol>
<li>Topology of the ANN.Neural networks architecture consists in the organization and position of the neurons with regard to the input or output of the network.In this sense, the fundamental parameters of the network are the number of layers, the number of neurons per layer, the connection grade and the type of connections among neurons.With reference to the number of layers, ANN can be classified into monolayer or multilayer networks (MLP).The first ones only have one input layer and one output layer, whereas the multilayer networks [45] are a generalization of the monolayer ones, which add intermediate or hidden layers between the input and the output.When discussing about the connection type, the ANN can be feedforward if the signal propagation is produced in just one way and, therefore, they do not have a memory or recurrent if they keep feedback links between neurons in different layers, neurons in the same layer or in the same neuron.Finally, the connection grade can be totally connected if all neurons in a layer are connected with the neurons in the next layer (feedforward networks) or with the neurons in the last layer (recurrent networks) and, otherwise, partially connected networks in cases where there is not total connection among neurons from different layers.2. Learning paradigm.The learning is a process that consists in modifying the weights of the ANN, according to the input information.The changes that can be carried out during the learning process are removing (the weight is set to zero), adding (conversion of a weight equal to zero to a weight different to zero) or modifying neurons connections.The learning process is said to be finished or, in other words, the network has learnt when the values assigned to the weights remain unchanged.3. Representation of the input/output information.ANN can be also classified according to the way in which information relative to both input and output data is represented.Thus, in a great number of networks input and output data are analog which entails activation functions also analogs, either linear or sigmoidal.In contrast, there are some networks that only allow discrete or even binary values as input data.In this situation, the neurons are activated by means of an echelon function.Finally, hybrid ANNs can be found in which input data may accept continuous values and output data would provide discrete values or viceversa.</li>
</ol>
<p>Extreme Learning Machine</p>
<p>Extreme Learning Machine (ELM) [46] is a feedforward neural network with an only hidden layer that uses a method for the training faster than the classical ANNs.Namely, the ELM randomly generates the weights W 1 that connect the input layer with the hidden layer and computes the weights W 2 that connect the hidden layer with the output using a simple matrix computation.Thus, the output y is defined by the following model:
y = W 2 φ(W 1 x) (23)
where φ is the activation function and x is the input vector.</p>
<p>The training consists in computing the weights W 2 as follows:
H = φ(W 1 x i )(24)W 2 = H + y i(25)
where (x i , y i ) are the points of the training set and H + represents the pseudoinverse of the matrix H.</p>
<p>Self Organizing Maps</p>
<p>The learning in ANN can be either supervised (perceptron and backpropagation [47] techniques) or unsupervised, from which the self-organizing Kohonen's maps (SOM) [48] stands out.</p>
<p>SOM have been mainly applied to discover patterns in data.The learning paradigm is based on a competitive learning, that is the neurons compete among them and win the neuron with the nearest weights to the input vector.Then, all neurons near to the win neuron update their weights according to a specific rule defined by:
w j n+1 = w j n + µ n (x − w j n )(26)
where w j n is the weight associated to the neuron j at the n-th iteration, µ n is the learning factor and x is the input vector.</p>
<p>The neurons that are not neighbors to the win neuron do not update their weights.Finally, a clustering of the data is obtained when the training phase ends.</p>
<p>Related Work</p>
<p>Many references proposing the use of ANNs, or a variation of them, as a powerful tool to forecast time series, can be found in the literature.The most important works are detailed below.Furthermore, the creation of hybrid methods that highlight most of the strengths of each technique is currently the most popular work among the researchers.However, from all of them, the combination of ANN and fuzzy set theory has become a new tool to be explored.</p>
<p>Rodríguez and Anders [49] presented a method to predict electricity prices by means of an ANN and fuzzy logic, as well as a combination of both.The basic selected network configuration consisted of a back propagation neural network with one hidden layer that used a sigmoid transfer function and a one-neuron output layer with a linear transfer function.They also reported the results of applying different regression-based techniques over the Ontario market.</p>
<p>A hybrid model which used ANNs and fuzzy logic was introduced in [50].As regards the neural network presented, it had a feed-forward architecture and three layers, where the hidden nodes of the proposed fuzzy neural network performed the fuzzyfication process.The approach was tested over the Spanish electricity price market and showed to be better than many other techniques such as ARIMA or MLP.</p>
<p>Taylor et al. [51] compared six univariate time series methods to forecast electricity load for Rio de Janeiro and England and Wales markets.These methods were an ARIMA model and an exponential smoothing (both for double seasonality), an artificial neural network, a regression model with a previous principal component analysis and two naive approaches as reference methods.The best method was the proposed exponential smoothing and the regression model showed a good performance for the England and Wales demand.</p>
<p>Another neural network-based approach was introduced in [52] in which multiple combinations were considered.These combinations consisted of networks with different number of hidden layers, different number of units in each layer and several types of transfer functions.The authors evaluated the accuracy of the approach reporting the results from the electricity markets of mainland Spain and California.</p>
<p>Energies 2015, 8, The use of ANN for forecasting electricity prices in the Spanish market was also proposed in [53].The main novelty of this work lies on the proposed training method for ANN, which is based on making a previous selection for the MLP training samples, using an ART-type [54] neural network.</p>
<p>In [55], the authors discussed and presented results by using an ANN to forecast the Jordanian electricity demand, which is trained by a particle swarm optimization technique.They also showed the performance obtained by using a back propagation algorithm (BP) and autoregressive moving average models.</p>
<p>Neupane et al. [56] used an ANN model with carefully selected inputs.Such inputs were selected by means of a wrapper method for feature selection.The proposal was applied to data from Australia, New York and Spain electricity markets, outperforming the PSF algorithm performance.</p>
<p>The feature selection problem to obtain optimal inputs for load forecasting has also been addressed by means of ANN [57].The authors evaluated the performance of four feature selection methods in conjunction with state-of-the-art prediction algorithms, using two years of Australian data.The results outperformed those of exponential smoothing prediction models.</p>
<p>In spite of the widespread use of the ANNs, the ELM has not been too explored to predict energy time series.An ELM and bootstrapping to predict probabilistic intervals for Australian electricity market was proposed in [58].First, an ELM was applied to obtain point forecasts, and later, a bootstrap method was used for uncertainty estimations.The results were compared with two ANNs, namely a back-propagation ANN and a radial basis function neural network, showing that ELM outperforms other methods in most of the test sets.For the same market, prediction intervals (PI) were also obtained in [59].In this case, a maximum likelihood method was used to estimate the noise variance indeed of a bootstrap method.The results were compared to a random walk (RW), and both traditional ANN and ELM with a bootstrap method.The proposed method provided the best training time and errors.</p>
<p>In [60] five recent methods to train radial-basis function (RBF) networks were applied to obtain the short-term load forecasting in New England.These method were SVR, ELM, decay RBF neural networks, improved second order and error correction.The best results regarding the training, errors, network size, and computational time were obtained with the error correction.</p>
<p>Li et al. [61] presented a wavelet transform to deal with the nonstationary of the load time series and an ELM with weights initially computed by an artificial bee colony algorithm to predict the load time series in New England and North American from the wavelet series.The authors showed that the use of an optimization algorithm to set the weights in ELM improves the forecasting errors.</p>
<p>Most approaches based on SOMs published in the literature for forecasting tasks, use the SOM to group the data in an initial stage, and later obtain a prediction model for each group.In [62] the authors propose to combine SOM and support vector machines to predict hourly electricity prices for next-day.First, they applied a SOM to split the data into groups, and then, a support vector machine model for each group is used to obtain the prediction of the prices in the New England electricity market.In this work, two months were used to validate the method, which provided errors of 7% approximately.Likewise, a SOM along with an ANN was applied to forecast the prices for Australian and New York electricity markets [63].In this case, the ANN predicted the nearest cluster and the prediction was obtained by the centroid of the cluster.The errors reported for the year 2006 were around a 1.76% and 2.88% for Australian and New York markets, respectively.A SOM without combining with another technique was presented in [64] to predict the prices for the Spanish electricity market.A preprocessing to select the input variables was proposed as a previous step to the prediction, which was obtained from the prices of the nearest centroid to the input data.The proposed SOM obtained forecasts with an error of 2.32% for the daily market.</p>
<p>Table 2 summarizes the content of this section.A genetic algorithm (GA) [65] is a kind of searching stochastic algorithm based on natural selecting procedures.Such algorithms try to imitate the biological evolutive process since they combine the survival of the best individuals in a set, by means of an structured and random process of information exchange.</p>
<p>Every time the process iterates, a new set of data structures is generated gathering just the best individuals of older generations.Thus, the GA are evolutionary algorithms due to their capacity to efficiently exploit the information relating to past generations.This fact allows the speculation about new searching points in the solution space, trying to obtain better models thanks to its evolution.</p>
<p>Many genetic operators can be defined.However, selection, crossover and mutation are the most relevant and used and are now going to be briefly described.</p>
<ol>
<li>Selection.During each successive generation, a proportion of the existing population is selected to breed a new generation.Individual solutions are selected through a fitness-based process, where fitter solutions (as measured by a fitness function) are typically more likely to be selected.Certain selection methods rate the fitness of each solution and preferentially select the best solutions.Other methods rate only a random sample of the population, as this process may be very time-consuming.Most functions are stochastic and designed so that a small proportion of less fit solutions are selected.This helps keep the diversity of the population large, preventing premature convergence on poor solutions.Popular and well-studied selection methods include roulette wheel selection and tournament selection.2. Crossover.Just after two parents are selected by any selection method, crossover takes place.</li>
</ol>
<p>Crossover is an operator that mates these two parents to produce offspring.The newborn individuals may be better than their parents and the evolution process may continue.In most crossover operators, two individuals are randomly selected and recombined with a crossover probability, p c .That is, an uniform number r is generated and if r ≤ p c the two randomly selected individuals undergo recombination.Otherwise, the offspring can be sheer copies of their parents.The value of p c can either be set experimentally or set based on schema-theorem principles [65].3. Mutation.Mutation is the genetic operator that randomly changes one or more of the individuals' genes.The purpose of the mutation operator is to prevent the genetic population from converging to a local minimum and to introduce to the population new possible solutions.</p>
<p>Genetic programming (GP) is a natural evolution of GA and its first apparition in the literature dates of 1992 [66].It is a specialization of genetic algorithms where each individual is a computer program.Therefore it is used to optimize a population of computer programs according to a fitness landscape determined by a program's ability to perform a given computational task.Hence, specialized genetic operator that generalize crossover and mutation are used for tree-structured programs.</p>
<p>The main steps to be followed when using GP are now summarized.Obviously, depending on the type of the application, these steps may change in order to be adapted to the particular problem to be dealt with.</p>
<ol>
<li>Random generation of an initial population, that is, programs.2. Iterative execution until the stop condition-to be determined in each situation-is fulfilled:</li>
</ol>
<p>(a) To execute each program of the population and to assign an aptitude value, according to their behavior in relation with the problem.(b) To create new programs by applying different primary operations to the programs.i.To copy an existing program in the new generation.ii.To create two programs from two existing ones, genetically and randomly recombining some chosen parts of both programs, making use of the crossover operator, which will also be randomly chosen for each program.iii.To create a program from another randomly chosen by randomly changing a gene.</p>
<ol>
<li>The program identified as possessing the best aptitude (the best for the last generation) is the designed result of the GP running.</li>
</ol>
<p>Related Work</p>
<p>The viability of forecasting the electricity demand via linear GP is analyzed in [67].Hence, the authors considered load demand patterns for ten consecutive months, observed every thirty minutes for the Victoria State of Australia.The performance was compared with an ANN and a neuro-fuzzy system (EFuNN) and the system delivered best results in terms of accuracy and computational cost.</p>
<p>An evolutionary technique applied to the optimal short-term scheduling of the electric energy production was presented in [68].The equations that define the problem led to a nonlinear mixed-integer programming problem with a high number of real and integer variables.The required heuristics, introduced to assure the feasibility of the constraints, are analyzed, along with a brief description of the proposed GA.Results from the Spanish power system were reported and compared to dynamic regression (DR).</p>
<p>Another price forecasting strategy was proposed in [69].In fact the authors presented a mutual information-based feature selection technique (MI) in which the prediction part was a cascaded neuro-evolutionary algorithm.The accuracy was largely evaluated since they compared their results-obtained from Pennsylvania-New Jersey-Maryland and Spanish electricity markets-with seven different models.</p>
<p>The electricity energy consumption is forecasted by using genetic algorithms in Turkey [70].The results were compared with conventional regression techniques, and the estimated values of the Turkish Ministry of Energy and Natural Resources (TMENR).An estimation for the electricity demand in the year 2020 is also provided.</p>
<p>A variant of genetic programming, Multi-Gene Genetic Programming (MGGP), was introduced in [71] and applied to Egypt load forecasting.The method was compared with RBF network and the standard genetic programming.</p>
<p>A variant of genetic programming, improved by incorporating semantic awareness in algorithm, for short term load forecasting is described in [72].The authors analyzed South Italy data and outperformed standard GP and some other machine learning methods.</p>
<p>Finally, Table 3 summarizes all the methods reviewed in this section.The support vector machine (SVM) model the way is nowadays understood, initially appeared in 1992 in the Computational Learning Theory (COLT) Conference and it has been subsequently studied and extended [73,74].The interest for this learning model is continuously increasing and it is considered an emerging and successful technique nowadays.Thus, it has become to a widely accepted standard in machine learning and data mining disciplines.</p>
<p>The learning process in SVM represents an optimization problem under constraints that can be solved by means of quadratic programming.The convexity guarantees a single solution which is an advantage with regard to the classical model of ANN.Furthermore, current implementations provide moderate efficiency for real-world problems with thousands of samples and attributes.</p>
<p>Support vector machines aims at separating points by means of what they defined as hyperplane, which are just linear separators with a high dimensionality whose functions are defined according to different kernels.Formally, a hyperplane in a D-dimensional space is defined as follows:
h(x) =&lt; w, x &gt; +b (27)
where x is the sample, w R D is the orthogonal vector to the hyperplane, b R, w is the weight vector, b is the bias or threshold decision and &lt; w, x &gt; expresses the scalar product in R D .</p>
<p>In case of a binary classifier is required, the equation can be reformulated as:
f (x) = sign (h(x))(28)
where the sign function is defined as:
sign(x) = +1, i f x ≥ 0 −1, i f x &lt; 0 (29)
There exist many algorithms directed to create hyperplanes (w, b) given a dataset linearly separable.These algorithms guarantee the convergency to a solution hyperplane although particularities of all of them will lead to slightly different solutions.Note that there can be infinity hyperplanes that perform adequate separations.So the key problem for the SVM is to choose the best hyperplane, in other words, the hyperplane that maximizes the minimum distance (or geometric margin) between the samples in the dataset and the hyperplane itself.</p>
<p>Another peculiarity of SVM is that only take into consideration those points belonging to the frontiers of the region of decision, which are the points that do not clearly belong to a class or to another.Such points are named support vectors. Figure 5 illustrates a bidimensional representation of an hyperplane equidistant to two classes, as well as showing the support vectors and the existing margin.If non linear transformation is carried out from the input space to the feature space, non linear separators-based learning is reached with SVM.Kernel functions are used thus in order to estimate the scalar product of two vectors in the features space.Consequently the election of an adequate kernel function is crucial and a priori knowledge of problem is required for a proper application of SVM.Nevertheless, the samples may not be linearly separable (see Figure 6) even in the features space.Trying to classify properly all the samples can seriously compromise the generalization of the classifier.This problem is known as overfitting.In such situations it is desirable to admit that some samples will be misclassified in exchange for having more promising and general separators.This behavior is reached by inserting soft margin in the model, whose objective function is composed by the addition of two terms: the geometric margin and the regularization term.The importance of both terms is pondered by means of a typically called parameter C.This model appeared in 1999 [75], and it was the model that really allowed the practical use that SVMs have nowadays, since it provided robustness against the noise.</p>
<p>On the other hand, SVMs can be easily adapted to solve regression problems by means of the introduction of a loss function.SVMs are commonly called Support Vector Regression (SVR) for time series forecasting.Now, the problem consists in finding a non linear function f that minimizes the forecasting error for the training set.The -insensitive loss function L defined by Equation ( 30) is typically used due to a reduced number of support vectors is obtained.The parameter represents the error allowed for each point of the training set.
L (y) =      0 i f |y − f (x)| ≤ |y − f (x)| − otherwise(30)
Energies 2015, 8, To approximate all data of the training set with an error less than is not always possible in practice.For this reason, slack variables ξ i and ξ * i are inserted to allow errors greater.Thus, the SVR model consists in solving the following problem:
minimize 1 2 ||w|| 2 + C ∑ i (ξ i + ξ * i ) subject to y i − f (x i ) ≤ + ξ i f (x i ) − y i ≤ + ξ * i(31)
where (x i , y i ) are the points of the training set, w is the margin and C is the regularization parameter.</p>
<p>Once the optimization problem has been solved, the following function is obtained:
f (x) = n ∑ i=1 (α + i − α − i )K(x, x i )(32)
where α + i and α − i are the multipliers of Lagrange of the dual optimization problem and K is the kernel function.</p>
<p>Related Work</p>
<p>Many works have been focussed on forecasting time series by applying SVM.Hence, the study carried out in [76] analyzed the suitability of applying SVM to forecast the electric load for the Taiwanese market.The results were compared to that of linear regressions and ANN.The same time series type, but related to the Chinese market, was forecasted in [77], in which the authors reached a globally optimized prediction by applying a SVM.</p>
<p>The occurrence of outliers (also called spike prices) or prices significantly larger than the expected values is an usual feature found in these time series.With the aim of dealing with this feature, the authors in [78] proposed a data mining framework based on both SVM and probability classifiers.</p>
<p>The research published in [79] proposed a new prediction approach based on SVM and rough sets techniques (RS) with a previous selection of features from data sets by using an evolutionary method.The approach improved the forecasting quality, reduced the speed of convergence and the computational cost as regards a conventional SVM and a hybrid model formed by a SVM and simulated annealing algorithms (SAA).</p>
<p>The Taiwanese electricity market was forecasted by means of SVR in [80].The author proposed a novel initialization of the SVR by using particle swarm optimization.The results were compared to other SVR but with different initialization strategies, mainly, the least-squares (LS) method.</p>
<p>A two-stage multiple SVM based model for midterm electricity price forecasting was proposed in [81].The first stage was used to separate input data into different price zones, and was carried out by means of a single SVM.Then, four parallel designed SVM were applied to forecast the electricity price.The method was applied to PJM market and the results compared to the standard SVM.</p>
<p>Finally, Table 4 summarizes all the methods reviewed in this section.Note the GRNN stands for general regression neural networks.</p>
<p>Forecasting Based on Local Methods</p>
<p>Due to the complexity to find a global function that models the whole system, the local models emerge as learning methods for time series forecasting.Conversely to global methods, a local model does not use the input data to predict the output but only the points close to the point to forecast.In general, global models have a lower computational cost than local models, since the latter have to be rebuilt for each point of the test set.But, the accuracy achieved by local methods is usually better than that of global methods.The main local methods for prediction tasks are the methods based on nearest neighbors.</p>
<p>Forecasting Based on Nearest Neighbors</p>
<p>Fundamentals</p>
<p>One of the most popular way of either predicting or classifying a new data, based on past and known observations, it the nearest neighbors technique (NN), that was first formulated by Cover and Hart in 1967 [82].The classical example to illustrate the application of NN refers to a doctor that tries to predict the result of a surgical procedure by comparing it with the obtained result from the most similar patient subjected to the same operation.However, a single case in which surgery had failed may have an excessive influence over other slightly different cases in which the operation had successfully carried out.For this reason, the NN algorithm is generalized with the k nearest neighbors, kNN.Thus, a simple election of the k nearest neighbors generates a prediction for every cases.Moreover, this rule can be extended by weighting the importance of the neighbors, giving a larger weight to the really nearest neighbors.</p>
<p>The search of the nearest neighbor process can be defined as follows:</p>
<p>Definition 1.Given a dataset P = p 1 , ..., p n in a metric espace X of distance d, two different type of queries are wanted to be answered:</p>
<p>• Nearest neighbor: find the point in P nearest to q X • Range: given a point q X and r &gt; 0, return all the points p P that satisfy d(p, q) ≤ r</p>
<p>where e C i indicates the assignation of the class label C i to the example e ; and d expresses a distance defined in the m-dimensional space, E m .</p>
<p>Energies 2015, 8, 13162-13193</p>
<p>Related Works</p>
<p>One example is thus labeled according to the nearest neighbor's class.This closeness is defined by means of the distance d which turns the election of this metric essential, since different metrics will most likely generate different classifications.As a consequence the election of the metric is widely discussed in the literature, as shown in [83].Note that the other main drawback that this technique presents is the selection of the number of neighbors to consider [84].</p>
<p>In [85] a forecasting algorithm based on nearest neighbors was introduced.The selected metric was the weighted Euclidean distance and the weights were calculated by means of a GA.The authors forecasted electricity demand time series in the Spanish market and the reported results were compared to those of an ANN.The same algorithm was tested on electricity price time series in [86] in which the authors proposed a methodology based on weighted nearest neighbors (WNN) techniques.The proposed approach was applied to the 24-h load forecasting problem and they built an alternative model by means of a conventional dynamic regression (DR) technique, where the parameters are estimated by solving a least squares problem, to perform a comparative analysis.</p>
<p>A modification of the WNN (mWNN) methodology was proposed in [87].To be precise, they explained how the relevant parameters-the window length of the time series and the number of neighbors to be chosen-are adopted.Then, the approach weighted the nearest neighbors in order to improve the prediction accuracy.The methodology was evaluated with the Spanish electricity prices time series.</p>
<p>Later, WNN was also applied to the California electricity market (CAISO) [88].This time, the authors reported results for year 2000 and compared the approach to ARIMA-based models.</p>
<p>A multivariate KNN (mKNN) regression method for forecasting the electricity demand in the UK market was presented in [89].They reported results date from 2004 and were compared to several benchmarks, as well as to univariate KNN (uKNN).</p>
<p>A work reporting short term load forecasting results for India, years 2012 and 2013, can be found in [90].This paper evaluates the accuracy of Holt-winter model and K-NN algorithm.Their performance is compared to SARIMA, ANN and SVM, showing that K-NN is the method with better results in terms of MAPE.</p>
<p>Finally, Table 5 summarizes all the methods reviewed in this section.It can be concluded that there exist few works based on KNN to forecast time series, which have mainly been assessed by means of diverse distance metrics in order to identify univariate time series motifs or episodes in the historical data [91].Prediction based on decision rules usually makes reference to the expert system developed by Collopy and Armstrong in 1992 [92].The initial approach consisted of 99 rules that combined four extrapolation-based forecasting methods: linear regression, Holt-Winter's exponential smoothing, Brown's exponential smoothing and random walk.During the prediction process, 28 features were extracted in order to characterize the time series.Consequently, this strategy assumed that a time Energies 2015, 8, 13162-13193 series can be reliably identified by some features.Nevertheless, just eight features were obtained by the system itself since the remaining ones were selected by means of experts' inspections.This fact implies high inefficiency insofar as too much time is taken, the ability of the analyst plays an important (and subjective) role and it shows a medium reliability.</p>
<p>Formally, an association rule (AR) can be expressed as a sentence such that: If A Then B, with A a logic predicate over the attributes whose fulfillment involves to classify the elements with a label B. The learning based on rules tries to find rules involving the highest number of attributes and samples.</p>
<p>ARs were first defined by Agrawal et al. [93] as follows.Let I = {i 1 , i 2 , ..., i n } be a set of n items, and D = {tr 1 , tr 2 , ..., tr N } a set of N transactions, where each tr j contains a subset of items.Thus, a rule can be defined as X ⇒ Y, where X, Y ⊆ I and X ∩ Y = ∅.Finally, X and Y are called antecedent (or left side of the rule) and consequent (or right side of the rule), respectively.</p>
<p>When the domain is continuous, the association rules are known as quantitative association rules (QAR).In this context, let F = {F 1 , ..., F n } be a set of features, with values in R. Let A and C be two disjunct subsets of F, that is, A ⊂ F, C ⊂ F, and A ∩ C = ∅.A QAR is a rule X ⇒ Y, in which features in A belong to the antecedent X, and features in C belong to the consequent Y, such that:
X = F i ∈A F i ∈ <a href="34">l i , u i </a>Y = F j ∈C F j ∈ <a href="35">l j , u j </a>
where l i and l j represent the lower limits of the intervals for F i and F j respectively, and the couple u i and u j the upper ones.For instance, QAR could be numerically expressed as:
F 1 ∈ [12, 25] ∧ F 3 ∈ [5, 9] ⇒ F 2 ∈ [3, 7] ∧ F 5 ∈ <a href="36">2, 8</a>
where F 1 and F 3 constitute the features appearing in the antecedent and F 2 and F 5 the ones in the consequent.</p>
<p>Related Work</p>
<p>Ismail et al. [94] presented a mathematical model for forecasting electricity peak load demand using a rule-based approach.The method was applied to data from Malaysia.The results were compared to SARIMA and regression models.</p>
<p>A data association mining-based rule extraction mechanism to extract the patterns in consumers' reaction to price forecasts can be found in [95].The resulting rules were then employed to fine-tune the initially generated demand and price forecasts of a multi-input multi-output (MIMO) engine.The methodology was tested on Australia's and New England's electricity data.</p>
<p>A rule-based approach to forecast anomalous load conditions for Great Britain data was introduced in [96].The authors used Holt-Winters-Taylor exponential smoothing, ARMA, ANN, and singular value decomposition based exponential smoothing to demonstrate how these methods can be adapted to discover outliers, when used together with a rule-based approach.</p>
<p>By contrast, not all the rule-based system provides crisp decisions.Hence, fuzzy rule-based systems are usually used when the available data presents missing values.In these systems, each element can belong to different groups with different grade of membership, not providing thus strict rules for every sample.Due to its flexibility for dealing with incomplete, imprecise or uncertain data, fuzzy rule-based strategies are often applied to prediction purposes.Hence a fuzzy association rule can be expressed as: If X is A Then Y is B, where X, Y are disjoint subsets of attributes that forms the database and A, B contain the fuzzy sets that are associated with X and Y.</p>
<p>A fuzzy rule based approach is presented to generate a crisp estimate for system load in [97].To get this done, historical load, temperature, and time information were converted into fuzzy Energies 2015, 8, 13162-13193 information.The method was applied to the European Energy Exchange (EEE) and the prediction results were compared to the conventional method (CM).</p>
<p>A novel fuzzy logic methodology for short term load forecasting was introduced in [98].It was concluded that using time, temperature and similar previous day load as the inputs and by formulating rule base of fuzzy logic using available data where enough to obtain reliable fuzzy rules for some particular days.Data from Indian market were analyzed.</p>
<p>A paper focused on improving the performance of fuzzy rules-based forecasters through application of FCM algorithm can be found in [99].The approach was evaluated by using data of certain region of the USA.</p>
<p>In general, the search of rule-based works to forecast electricity led to the conclusion that this kind of works is scarce.That is, there could be an interesting starting point for those researchers wanting to develop new algorithms.</p>
<p>Finally, Table 6 summarizes all the methods reviewed in this section, where NP means not provided (the authors did not compared their approach to any other).</p>
<p>Wavelet Transform Methods</p>
<p>Fundamentals</p>
<p>All the methods described are applied in the time domain.However, time series can also be analyzed in the frequency domain by means of several techniques.Fourier transform-and different Fourier-related transforms such as short-time Fourier transform (STFT), fast Fourier transform (FFT) or discrete Fourier transform-is the most widely used tool to extract the spectral components from temporal data.However, there is another technique derived from this analysis which is more suitable to time series analysis in the frequency domain: the wavelet transform.</p>
<p>There are two different types of wavelet transforms.The discrete wavelet transform (DWT) performance is similar to that of low and high-pass filters, since it divides the time series in high and low frequencies.On the other hand, the continuous wavelet transform (CWT) works as if it was a band-pass filter, isolating just the frequency band of interest.Although both strategies can be used to perform spectral analysis, only the CWT is going to be described in this Section because it is much more useful-and, consequently, used-in time series analysis.DWT is usually used in data that present great variations and discontinuities, which is not the case of time series that frequently as modeled by smooth variations.</p>
<p>Hence, the CWT is a convolution of a time series and the wavelet function [100].That is, the time series is filtered by a function that plays the same role of the window in the STFT.Nevertheless, in wavelet transform this window has a variable length according to the frequency band to be studied.Formally, the N points-CWT of a time series x n , sampled each ∆t units of time, is defined as the convolution of such series with an extended and delayed wavelet function Ψ(t):
CWT x (n, s) = 1 √ s N−1 ∑ n =0 x n Ψ * n − n s ∆t with n = 0 . . . N − 1(37)
Energies 2015, 8, As this product has to be done N times for the scale s considered, if N is too large it is faster to estimate the result by using the FFT than by means of the definition.From the convolution theorem [101], the CWT can be obtained from the inverse fast Fourier transform (IFFT) of time series and the wavelet's direct transform:
CWT x (n, s) = IFFT 1 √ s FFT(x(n, ∆t)FFT(Ψ(n, ∆t, s)(38)
Since s is the single parameter from which the transform depends on, the estimation of the CWT can be carried out by means of FFT algorithms for each scale as well as simultaneously for all the points forming the series.</p>
<p>Related Work</p>
<p>Conejo et al. [102] proposed a new approach to predict day-ahead electricity prices based on the wavelet transform and ARIMA models.Thus, they decomposed the time series in a set of better-behaved constitutive series by applying the wavelet transform.Then, the future values of these new series were forecast using ARIMA models, with a prior application of the inverse wavelet transform.This approach improved former strategies that they had also published [103][104][105].</p>
<p>Aggarwal et al. [106] also forecasted electricity prices.For this purpose, they divided each day into segments and they applied a multiple linear regression (MLR) to the original series or the constitutive series obtained by the wavelet transform depending on the segment.Moreover, the regression model used different input variables for each segment.</p>
<p>Pindoriya et al. [107] proposed an adaptive wavelet-based neural network (AWNN) for short-term electricity price time series forecasting for Spanish and California markets.As for the neural network, the output of the hidden layer neurons was based on wavelets that adapted their shape to training data.The authors concluded that their approach converged with higher rate and outperformed in the forecasting the electricity prices compared to other methods due to the ability for modeling the non-stationary and high frequency signals.The target market was PJM.</p>
<p>An approach based on non-decimated multilevel wavelet (ML-WL) transform, combined with feature selection and machine learning prediction algorithm was presented in [108].The feature selection integrated autocorrelation and ranking-based methods.The method was applied to Australian electricity data, outperforming exponential smoothing with single and double seasonality, the industry model and all other baselines.</p>
<p>A methodology to forecast normal and spike prices was proposed in [109].Normal price module was forecasted as a mixture of wavelet transform, ARIMA and ANN models.Price spike occurrences were generated by a three classifiers ensemble.The forecasting accuracy of the proposed method is evaluated with real data from Finland energy market.</p>
<p>The work presented in [110] used Local Linear Wavelet Neural Network (LLWNN) trained by a special adaptive version of the PSO algorithm, with parallel implementation.Experiments for short term load and price forecasting were conducted for Greece and the USA energy markets and were compared to a classic PSO algorithm.</p>
<p>Finally, Table 7 summarizes all the methods reviewed in this section, where WL stands for wavelets.</p>
<p>Ensemble Models</p>
<p>Recently, ensemble models are beginning to receive attention from the research community due to the good performance obtained for classification problems [122,123].In general, ensemble models consists in combining different models in order to improve the accuracy of the individual models.In most of works, the combination is usually based on a system of majority votes (bagging) or weighted majority votes (boosting).</p>
<p>In the last years, ensemble techniques have been also applied to the prediction of energy time series.Fan et al. [124] proposed a machine learning model based on Bayesian Clustering by Dynamics (BCD) and SVM.First, Bayesian clustering techniques were used to split the input data into 24 subsets.Then, SVM methods were applied to each subset to obtain the forecasts of the hourly electricity load for the city of New York.</p>
<p>The work in [125] introduced a price forecasting method based on wavelet transform combined with ARIMA and GARCH models.The method was assessed on Spanish and PJM electricity markets and compared to some other forecasting methods.</p>
<p>An ensemble of RBF neural networks for short-term load forecasting in seven buildings from Italy can be found in [126].The main novelty of this work is the introduction of a new term in the objective function to minimize the correlation between the error of a network with the errors of the rest of networks of the ensemble.In this case, the results were compared to SARIMA, which proved to be more competitive in most of the buildings.</p>
<p>An ensemble of ELM was presented in [127] to short-term load forecasting of Australian electricity market.Both the weights of the input layer and the number of nodes in hidden layer for each ELM were randomly set.The median of the outputs generated for each ELM was the final prediction.The results reported an error of 1.82% for the year 2010 versus 2.89%, 2.93%, and 2.86% obtained by a single ELM, a back-propagation ANN and a RBF neural network, respectively.</p>
<p>Many ensembles of ANN have been recently published in the literature with the purpose of electricity prices or load forecasting.In fact, most of the proposed ensemble techniques for regression tasks have been ensembles of ANN.For instance, the authors in [128] proposed the hybrid method PSF-NN, which combines pattern sequence similarity with neural networks.The results show that the use of ensemble of NNs instead of a single NN in the NN component of the PSF-NN prediction method is beneficial considering that it produces better accuracy at acceptable computational cost.</p>
<p>Another ensemble based on PSF was introduced in [129].In this case, five forecasting models using different clustering techniques: K-means, SOM, Hierarchical Clustering, K-medoids model, and Fuzzy C-means were used.The ensemble model was implemented with an iterative prediction procedure.The method was applied to New York, Australia and Spain markets, and the results compared to those of the original PSF algorithm.</p>
<p>The performance of an ensemble of ANN was compared with a Seasonal Autoregressive Integrated Moving Average (SARIMA) model, a Seasonal Autoregressive Moving Average (SARMA), a Random Forest, a Double Exponential Smoothing and Multiple Regression in [130], providing the best results.The ANNs composing of the ensemble were trained with different subsets provided by a previous clustering.</p>
<p>An ensemble was proposed in [131] to predict the load in California for the next day.The authors used a reference forecast made by the system operator as input variable of the proposed method, and this prediction was improved by means of two Box-Jenkins time series models.Then, the forecasts provided by these two models were combined to obtain the final prediction.The weights of the combination were optimized by means of least square method, and moreover, the authors built different ensembles considering global weights or weights depending on the hour or the day.</p>
<p>Finally, Table 9 summarizes all the methods reviewed in this section.</p>
<p>Conclusions</p>
<p>It is expected that this work serve as initial guide for those researchers interested in time series forecasting and, in particular, in forecasting based on data mining approaches.Thus, a brief but rigorous mathematical description of the main existing data mining techniques that have been applied to forecast time series is reported.Due to the wide variety of application of such techniques, one case study has been selected: The analysis of energy-related time series (electricity price and demand).The large amount of works carried out during the last decade in this topic highlights the strengths that data mining had already exhibit in other fields.With reference to the type of prediction, it can be concluded that almost all methods use a horizon of prediction equals to one day.There are few works forecasting recent years since, for comparative purposes, they prefer to use older data.Moreover, there are several techniques that have been rarely used so far in this research areas: nearest-neighbors and genetic programming.This fact suggests that much work is still remaining for such models.On the contrary, ANN and SVM have been extensively used for this forecasting task.Linear models are still being used, but mainly to be used as baselines, since most of the data mining approaches outperform them in terms of accuracy.Wavelets and rule-based methods are mainly used in hybrid approaches and are causing significative accuracy improvement when properly combined.The accuracy measures mainly used are MAPE and RMSE.Finally, the current trend in electricity forecasting points to the development of ensembles, thus highlighting single strengths of every method.</p>
<p>Figure 1 .
1
Figure 1.Time series example.</p>
<p>Figure 2 Figure 2 .
22
Figure2depicts how a time series can be decomposed in the variables above described.</p>
<p>Figure 3 .
3
Figure 3.The Box-Jenkins methodology.</p>
<p>Figure 4 .
4
Figure 4. Mathematical model of an artificial neural network (ANN).</p>
<p>Figure 5 .
5
Figure 5. Hyperplane (w, b) equidistant to two classes, margin and support vectors.</p>
<p>Figure 6 .
6
Figure 6.Non linearly separable dataset.</p>
<p>Figure 7
7
Figure 7 illustrates an example in which k is set to three (three nearest neighbors are searched for) and an Euclidean metric is used.</p>
<p>Figure 7 .Definition 2 .
72
Figure 7. Three nearest neighbors of an instance to be classified.</p>
<p>Table 1 .
1
Summary on linear methods.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[38]GARCHDR/TFM/Smoothing RMSE/MAPE1 day2002NYISO[39]GARCHARIMARMSE1 day2000CAISO/OMEL[40]GARCH5+ modelsMAPE/MAE1 day2004Northern Europe[41]ARMA5+ modelsRMSE1 day2000CAISO[42]Mixed ARIMAARIMARMSE/MAPE1 day2000-2002OMEL[43]ARIMA5+ modelsMAE/MAPE1 day2004CAISO/Nord Pool</p>
<p>Table 2 .
2
Summary on ANN, self-organizing Kohonen's maps (SOM) and extreme learning machine (ELM) for electricity forecasting.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[49]Hybrid ANN5+ modelsMAPE1 day2002Ontario[50]Hybrid ANN MLP/ARIMA/RBFMRE1 day2002OMEL[51]ANN5+ modelsRMSE/MAE1 day2003Brazil[52]ANNARIMA/NaiveMAPE1 day2000/2002CAISO/OMEL[53]ART-NNARIMA/ANNMAPE1 day2003OMEL[55]ANNARMA/BPRMSE/MAPE1 day2004Jordan[56]ANNPSFMRE/MAPE1 day2006NYISO/ANEM/OMEL[57]ANNSmoothingMAE/MAPE1 day2007ANEM[58]ELM5+ modelsMAE/MAPE/RMSE1 day2006/07ANEM[59]ELMRW/ANNPI1 day2007/09ANEM[60]ELMRBF/SVRMAPE1 day2011ANEM[61]ELM5+ modelsMAPE1 day2006NYISO/ANEM[62]SOMSVMMAE/MAPE1 day2005ANEM[63]SOMPSFMRE/MAPE1 day2006NYISO/ANEM/OMEL[64]SOM5+ modelsMAPE1 day2011OMEL5.1.2. Genetic Programming5.1.2.1 Fundamentals</p>
<p>Table 3 .
3
Summary on genetic programming (GP) for electricity forecasting.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[67]Linear GPANN/EFuNNRMSE2 days1995ANEM[68]GPDRMRE/MAE1 day2002OMEL[69]MI GP5+ modelsMAE/MSRE1 day2007PJM/OMEL[70]GPTMENRMSE1 day2020Turkey[71]MGGPRBF/GPMAPE1 day2012Egypt[72]Semantic GP5+ modelsMAE/MSRE1 day2009/10Italy5.1.3. Support Vector Machines5.1.3.1 Fundamentals</p>
<p>Table 4 .
4
Summary on support vector machine (SVM) for electricity forecasting.
Reference TechniqueOutperformsMetricsHorizonYearMarket[76]SAA-SVMARIMA/GRNN MAE/MSRE1 day2004China[77]SVMANNMAPE1 day2005China[78]M-SVMSVMMAE/MSRE1 day2006ANEM[79]RS-SVMSAA-SVMMAE/MSRE1 day2007NYISO[80]PSO-SVMLS-SVMMSE1 day2009Taiwan[81]M-SVMSVMMAE/MSRE1 day2009/10PJM</p>
<p>Table 5 .
5
Summary on k nearest neighbors (KNN) methods for electricity forecasting.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[85]KNNANNMRE/MAE1 day2002OMEL[86]WNNDRMRE/MAE1 day2002OMEL[87]mWNNANN/GARCHMRE/MAE1 day2002OMEL[88]WNNARIMAMAE/MAPE1 day2000CAISO[89]mKNNuKNN/BenchmarksMAPE1 day2004UK[90]KNN/Holt SARIMA/ANN/SVMMAPE1 day2012/13India6. Rule-Based Forecasting6.1. Fundamentals</p>
<p>Table 6 .
6
Summary on rule-based methods for electricity forecasting.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[94]RulesMA/SmoothingMAE1 day2001-2005 Malaysia[95]MIMONPMAPE1 day2009ANEM[96]Holt/RulesSARMA/ANNMAPE1 day2007UK[97]Fuzzy rulesCMMAPE1 day2002-2005EEE[98]Fuzzy rulesNPMRE1 day2013India[99]Fuzzy rulesHolt/ARIMAMSE/MAPE1 day2005Brazil</p>
<p>Table 7 .
7
Summary on wavelets for electricity forecasting.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[102]WL-ARIMAARIMAMRE1 day2002OMEL[106]WL-MLRGARCHRMSE/MAPE1 day2003-2005ANEM[107]AWNNANN/MLP/RBFMAPE/MSE1 day2002/2004OMEL/PJM[108]ML-WL-FSSmoothingMSE1 day2010ANEM[109]WL-ARIMA-ANNARIMAMAPE1 day2010Finland[110]LLWNNPSORMSE/MAPE1 day2012Greece/NYISO</p>
<p>Table 9 .
9
Summary on ensembles for electricity forecasting.
ReferenceTechniqueOutperformsMetricsHorizonYearMarket[124]BCD+SVMSVRMAPE1 day2001-2003NYISO[125]WL+GARCH5+ modelsRMSE/MAPE1 day2002OMEL/PJM[126]ANNSARIMAMSE/MAE/MAPE1 day2010Italy[127]ELMANN/RBFMAE/MAPE1 day2010ANEM[128]PSF+ANN5+ modelsMAE/MAPE1 day2010ANEM[129]PSF+ClustPSFMRE/MAPE1 day2006NYISO/ANEM/OMEL[130]ANNSARIMAMAPE1 day2012C &amp; I[131]ARIMA5+ modelsRMSE/MAE/MAPE1 day2013CAISO/ERCOT
Energies 2015, 8, 13162-13193; doi:10.3390/en81112361 www.mdpi.com/journal/energies
Acknowledgments:The authors would like to thank Spanish Ministry of Economy and Competitiveness, Junta de Andalucía and Pablo de Olavide University for the support under projects TIN2014-55894-C2-R, P12-TIC-1728 and APPB813097, respectively.Energies 2015, 8, 13162-13193Other ModelsDespite of the vast description of methods provided in prior sections, some authors proposed new forecasting approaches that cannot be classified into any of the aforementioned categories.For this reason, this section is describe to introduce all these works.Hence, transfer functions models (TFM)-known as dynamic econometric models in the economics literature-based on past electricity prices and demand were proposed to forecast day-ahead electricity prices by Nogales et al. in[111], but the prices of all 24 h of the previous day were not known.They used the median as measure due to the presence of outliers and they stated that the model in which the demand was considered presented better forecasts.The authors in[112]focussed on the one year-ahead electricity demand prediction for winter seasons by defining a new Bayesian hierarchical model (BH).They provided the marginal posterior distributions of demand peaks.The results for one year-ahead were compared to those of the National Grid Trasc (NGT) group in the United Kingdom.A fuzzy inference system (FIS)-adopted due to its transparency and interpretability-combined with traditional time series methods was proposed for day-ahead electricity price forecasting[113].A novel non-parametric model using the manifold learning (MFL) methodology was proposed in[114]in order to predict electricity price time series.For this purpose, the authors used cluster analysis based on the embedded manifold of the original dataset.To be precise, they applied manifold-based dimensionality reduction to curve modeling, showing that the day-ahead curve can be represented by a low-dimensional manifold.Another different proposal can be found in[115], where a forecasting algorithm based on Grey Models was introduced to predict the load of Shanghai.In the Grey model the original data series was transformed to reduce the noise of the data series and the accuracy was improved by using Markov chains techniques.The use of clustering as an initial step to forecast electrical time series has been used.For instance, the authors in[116,117]evaluated the performance of both K-means and Fuzzy C-Means in detecting patterns in the Spanish market.Later, these patterns were used to transform the time series into a sequence of labels showing the benefits of using this information as previous step in time series forecasting[118].Finally, an extended and improved approach, PSF, was introduced in[119], where New York, Australian and Spanish electricity and demand time series were successfully forecasted, showing remarkable performance compared to classical methods.The same method was adapted to forecast outliers (o-PSF) for the same markets in[120].A method using a principal component analysis (PCA) network was introduced in[121]to forecast day-ahead prices.The PCA network extracts essential features from periodic information in the market.Later, these features are used as inputs in a multilayer feedforward network.PJM market was used to test the proposed method and the results compared to ARIMA models.Finally, Table8summarizes all the methods reviewed in this section.Author Contributions: Francisco Martínez-Álvarez and Alicia Troncoso conceived the paper.José C. Riquelme and Gualberto Asencio-Cortés proposed the paper structure.All authors contributed to the writing of the paper.Conflicts of Interest:The authors declare no conflict of interest.
Mathematical models of natural gas consumption. K Sabo, R Scitovski, I Vazler, M Zekić-Sušac, 2011Energy Convers. Manag52</p>
<p>Customer segmentation for telecom with the k-means clustering method. L Ye, C Qiuru, X Haixu, L Yijun, Z Guangping, Inf. Technol. J. 122013</p>
<p>Forecasting airborne pollen concentration time series with neural and neuro-fuzzy models. J L Aznarte-Mellado, J M Benítez-Sánchez, D Nieto, C L Fernández, C Díaz, F Alba-Sánchez, Expert Syst. Appl. 322007</p>
<p>Optimization of Multi-classifiers for Computational Biology: Application to gene finding and gene expression. R R Záliz, C Rubio-Escudero, I Zwir, C Del Val, Theor. Chem. Acc. 1252010</p>
<p>Determining the best set of seismicity indicators to predict earthquakes. Two case studies: Chile and the Iberian Peninsula. F Martínez-Álvarez, J Reyes, A Morales-Esteban, C Rubio-Escudero, Knowl.-Based Syst. 502013. 2015</p>
<p>Multimarket Optimal Bidding for a Power Producer. M A Plazas, A J Conejo, F J Prieto, IEEE Trans. Power Syst. 202005</p>
<p>Electricity Price Forecasting in Deregulated Markets: A Review and Evaluation. S K Aggarwal, L M Saini, A Kumar, Int. J. Electr. Power Energy Syst. 312009</p>
<p>Electricity price forecasting: A review of the state-of-the-art with a look into the future. R Weron, Int. J. Forecast. 302014</p>
<p>The New York Independent System Operator. 10 July 2015</p>
<p>Australia's National Electricity Market. 10 July 2015</p>
<p>Independent Electricity System Operator of Ontario. 10 July 2015</p>
<p>Functional Data Analysis. J O Ramsay, B W Silverman, 2005SpringerHeidelberg, Germany</p>
<p>P J Brockwell, R A Davis, Introduction to Time Series and Forecasting. Heidelberg, GermanySpringer2002</p>
<p>. R H Shumway, D S Stoffer, Time Series Analysis and Its Applications (with R Examples. </p>
<p>. Springer, 2011Heidelberg, Germany</p>
<p>. R A Maronna, R D Martin, V Yohai, J. Robust Statistics: Theory and Methods. 2007Wiley</p>
<p>Another look at measures of forecast accuracy. R J Hyndman, A B Koehler, Int. J. Forecast. 222006</p>
<p>Measuring Conditional Persistence in Time Series. G Kapetanios, 2002474UKUniversity of London Queen Mary Economics Working Paper; Department of Economics: London</p>
<p>G Box, G Jenkins, Time Series Analysis: Forecasting and Control. Hoboken, NJ, USAJohn Wiley and Sons2008</p>
<p>Lag Length and Mean Break in Stationary VAR Models. M Yang, Econom. J. 52002</p>
<p>H Wold, A Study in the Analisis of Stationary Time Series; Almquist and Wicksell. Uppsala, Sweden1954</p>
<p>Autoregressive Conditional Heteroskedasticity With Estimates of the Variance of UK. Inflat. Econom. T Kohonen, 198250</p>
<p>Modelling the coherence in short-run nominal exchange rates: A multivariate generalized ARCH model. T Bollerslev, Rev. Econ. Stat. 721986</p>
<p>ARCH Models for Financial Applications. E Xekalaki, S Degiannakis, 2010WileyHoboken, NJ, USA</p>
<p>C Francq, J M Zakoian, GARCH Models: Structure, Statistical Inference and Financial Applications. Hoboken, NJ, USAWiley2010</p>
<p>Parameters Estimate of Autoregressive Moving Average and Autoregressive Integrated Moving Average Models and Compare Their Ability for Inflow Forecasting. M Valipour, M E Banihabib, S M R Behbahani, J. Math. Stat. 82012</p>
<p>Streamflow prediction for estimation of hydropower potential. I Dashora, S Singal, D Srivastav, Water Energy Int. 572015</p>
<p>Estimation of Mean Squared Error of X-11-ARIMA and Other Estimators of Time Series Components. D Pfeffermann, M Sverchkov, J. Off. Stat. 302014</p>
<p>Time series forecasting by using seasonal autoregressive integrated moving average: Subset, multiplicative or additive model. S Suhartono, J. Math. Stat. 72011</p>
<p>On parameter estimation for Malaysian gold prices modelling and forecasting. N H Miswan, P Y Ping, M H Ahmad, Int. J. Math. Anal. 72013</p>
<p>Using genetic algorithms to parameters (d; r) estimation for threshold autoregressive models. B Wu, C L Chang, Comput. Stat. Data Anal. 382002</p>
<p>Research on weighted iterative stage parameter estimation algorithm of time series model. S Wei, L Lei, H Qun, Appl. Mech. Mater. 2014</p>
<p>A new genetic fuzzy system approach for parameter estimation of ARIMA model. S Hassan, J Jaafar, B Belhaouari, A Khosravi, Proceedings of the International Conference on Fundamental and Applied Sciences. the International Conference on Fundamental and Applied SciencesKuala Lumpur, MalaysiaJune 20121482</p>
<p>Maximum Likelihood Parameter Estimation of F-ARIMA Processes Using the Genetic Algorithm in the Frequency Domain. B S Chen, B K Lee, S C Peng, IEEE Trans. Signal Process. 502002</p>
<p>. D Peña, G C Tiao, R S Tsay, Course, Time Series Analysis. 2001Wiley</p>
<p>H S Guirguis, F A Felder, Further Advances in Forecasting Day-Ahead Electricity Prices Using Time Series Models. 2004</p>
<p>A GARCH Forecasting Model to Predict Day-Ahead Electricity Prices. R C García, J Contreras, M Van Akkeren, J B García, IEEE Trans. Power Syst. 202005</p>
<p>Evaluating Multivariate GARCH Models in the Nordic Electricity Markets. P Malo, A Kanto, Commun. Stat. Simul. Comput. 352006</p>
<p>Forecasting Spot Electricity Prices with Time Series Models. R Weron, A Misiorek, Proceedings of the International Conference: The European Electricity Market. the International Conference: The European Electricity MarketLodz, PolandMay 2005</p>
<p>Mixed Models for Short-Run Forecasting of Electricity Prices: Application for the Spanish Market. C García-Martos, J Rodríguez, M J Sánchez, IEEE Trans. Power Syst. 222007</p>
<p>Forecasting Spot Electricity Prices: A Comparison of Parametric and Semiparametric Time Series Models. R Weron, A Misiorek, Int. J. Forecast. 242008</p>
<p>A logical calculus of the ideas immanent in nervous activity. W S Mcculloch, W Pitts, Bull. Math. Biophys. 51943</p>
<p>The perceptron: A probabilistic model for information storage and organization in the brain. F Rosenblatt, Psychol. Rev. 651958</p>
<p>Extreme Learning Machine: Theory and Applications. G B Huang, Q Y Zhu, C K Siew, Neurocomputing. 702006</p>
<p>Learning Internal Representations by Error Propagation. D E Rumelhart, G E Hinton, R J Willians, 1986MIT PressCambridge, MA, USA</p>
<p>Self-organized formation of topologically correct feature maps. T Kohonen, Biol. Cybern. 431986</p>
<p>Energy price forecasting in the Ontario Competitive Power System Market. C P Rodríguez, G J Anders, IEEE Trans. Power Syst. 192004</p>
<p>Day-Ahead Price Forecasting of Electricity Markets by a New Fuzzy Neural Network. N Amjady, IEEE Trans. Power Syst. 212006</p>
<p>Density forecasting for the efficient balancing of the generation and consumption of electricity. J Taylor, Int. J. Forecast. 222006</p>
<p>Short-term electricity prices forecasting in a competitive market: A neural network approach. J P S Catalao, S J P S Mariano, V M F Mendes, L A F M Ferreira, Electr. Power Syst. Res. 772007</p>
<p>Forecasting next-day price of electricity in the Spanish energy market using artificial neural networks. R Pino, J Parreno, A Gómez, P Priore, Eng. Appl. Artif. Intell. 212008</p>
<p>An Introduction to Artificial Neural Systems. J M Zurada, 1992West Publishing CompanySt. Paul, MN, USA</p>
<p>Short-term forecasting of Jordanian electricity demand using particle swarm optimization. M El-Telbany, F El-Karmi, Electr. Power Syst. Res. 782008</p>
<p>Artificial Neural Network-based Electricity Price Forecasting for Smart Grid Deployment. B Neupane, K S Perera, Z Aung, W L Woon, Proceedings of the IEEE International Conference on Computer Systems and Industrial Informatics. the IEEE International Conference on Computer Systems and Industrial InformaticsSharjah, UAE18-20 December 2012</p>
<p>Correlation and instance based feature selection for electricity load forecasting. I Koprinska, M Rana, V G Agelidis, Knowl.-Based Syst. 822015</p>
<p>Electricity Price Forecasting with Extreme Learning Machine and Bootstrapping. X Chen, Z Y Dong, K Meng, Y Xu, K P Wong, H Ngan, IEEE Trans. Power Syst. 272012</p>
<p>A Hybrid Approach for Probabilistic Forecasting of Electricity Price. C Wan, Z Xu, Y Wang, Z Y Dong, K P Wong, IEEE Trans. Smart Grid. 52014</p>
<p>A Novel RBF Training Algorithm for Short-Term Electric Load Forecasting and Comparative Studies. C Cecati, J Kolbusz, P Rozycki, P Siano, B Wilamowski, IEEE Trans. Ind. Electron. 622015</p>
<p>Short-term load forecasting by wavelet transform and evolutionary extreme learning machine. S Li, P Wang, L Goel, Electr. Power Syst. Res. 1222015</p>
<p>Next day electricity-price forecasting using a hybrid network. S Fan, C Mao, L Chen, IET Gener. Transm. Distrib. 12007</p>
<p>A SOM clustering pattern sequence-based next symbol prediction method for day-ahead direct electricity load and price forecasting. C H Jin, G Pok, Y Lee, H W Park, K D Kim, U Yun, K H Ryu, Energy Convers. Manag. 902015</p>
<p>Application of SOM neural networks to short-term load forecasting: The Spanish electricity market case study. M López, S Valero, C Senabre, J Aparicio, A Gabaldon, Electr. Power Syst. Res. 912012</p>
<p>Genetic Algorithms in Search. D E Goldberg, Optimization and Machine Learning. Cambridge, MA, USAAddison-Wesley1989</p>
<p>Genetic Programming: On the Programming of Computers by Means of Natural Selection. J R Koza, 1992MIT PressCambridge, MA, USA</p>
<p>A Linear Genetic Programming Approach for modelling Electricity Demand Prediction in Victoria. M Bhattacharya, A Abraham, B Nath, Proceedings of the International Workshop on Hybrid Intelligent Systems. the International Workshop on Hybrid Intelligent SystemsAdelaide, AustraliaDecember 2001</p>
<p>Time-Series Prediction: Application to the Short Term Electric Energy Demand. A Troncoso, J M Riquelme, J C Riquelme, A Gómez, J L Martínez, Lect. Notes Artif. Intell. 30402004</p>
<p>Day-Ahead Price Forecasting of Electricity Markets by Mutual Information and Cascaded Neuro-Evolutionary Algorithm. N Amjady, F Keynia, IEEE Trans. Power Syst. 242009</p>
<p>Turkey's Electricity Consumption Forecasting Using Genetic Programming. M Cunkas, U Taskiran, Energy Sources Part B Econ. Plan. Policy. 62011</p>
<p>Multi-Gene Genetic Programming for Short Term Load Forecasting. W T Ghareeb, E F El-Saadany, Proceedings of the International Conference on Electric Power and Energy Conversion Systems. the International Conference on Electric Power and Energy Conversion SystemsIstanbul, Turkey2-4 October 2013</p>
<p>Forecasting short-term electricity consumption using a semantics-based genetic programming framework: The South Italy case. M Castelli, L Vanneschi, M D Felice, Energy Econ. 472015</p>
<p>. C Cortes, V Vapnik, Support-Vector, Networks, Mach. Learn. 201995</p>
<p>Statistical Learning Theory. V Vapnik, 1998WileyHoboken, NJ, USA</p>
<p>An Overview of Statistical Learning Theory. V Vapnik, IEEE Trans. Neural Netw. 101999</p>
<p>Electricity Load Forecasting by using SVM with Simulated Annealing Algorithm. W C Hong, Proceedings of the World Congress of Scientific Computation, Applied Mathematics and Simulation. the World Congress of Scientific Computation, Applied Mathematics and SimulationParis, FranceJuly 2005</p>
<p>Support-Vector Machine Model in Electricity Load Forecasting. Y Guo, D Niu, Y Chen, Proceedings of the International Conference on Machine Learning and Cybernetics. the International Conference on Machine Learning and CyberneticsDalian, ChinaAugust 2006</p>
<p>A Framework for Electricity Price Spike Analysis with Advanced Data Mining Methods. J H Zhao, Z Y Dong, X Li, K P Wong, IEEE Trans. Power Syst. 222007</p>
<p>A new method for short-term electricity load forecasting. J Wang, L Wang, Trans. Inst. Meas. Control. 302008</p>
<p>Electricity Consumption Prediction based on Data Mining Techniques with Particle Swarm Optimization. Z Qiu, Int. J. Database Theory Appl. 62013</p>
<p>Midterm Electricity Market Clearing Price Forecasting Using Two-Stage Multiple Support Vector Machine. X Yan, N A Chowdhury, 10.1155/2015/384528J. Energy. 2015. 2015</p>
<p>Nearest neighbor pattern classification. T M Cover, P E Hart, IEEE Trans. Inf. Theory. 131967</p>
<p>Improving nearest neighbor rule with a simple adaptive distance measure. J Wang, P Neskovic, L N Cooper, Pattern Recognit. Lett. 282007</p>
<p>Neighborhood selection in the k-nearest neighbor rule using statistical confidence. J Wang, P Neskovic, L N Cooper, Pattern Recognit. 392006</p>
<p>Electricity Market Price Forecasting: Neural Networks versus Weighted-Distance k Nearest Neighbours. A Troncoso, J C Riquelme, J M Riquelme, J L Martínez, A Gómez, Lect. Notes Comput. Sci. 2002. 2453</p>
<p>A Comparison of Two Techniques for Next-Day Electricity Price Forecasting. A Troncoso, J M Riquelme, J C Riquelme, A Gómez, J L Martínez, Lect. Notes Comput. Sci. 2002. 2412</p>
<p>Electricity Market Price Forecasting Based on Weighted Nearest Neighbours Techniques. A Troncoso, J C Riquelme, J M Riquelme, J L Martínez, A Gómez, IEEE Trans. Power Syst. 222007</p>
<p>Day-Ahead Electricity Price forecasting using Wavelets and Weighted Nearest Neighborhood. C V K Bhanu, G Sudheer, C Radhakrishn, V Phanikanth, Proceedings of the International Conference on Power System Technology. the International Conference on Power System TechnologyNew Delhi, India12-15 October 2008</p>
<p>Multivariate k-Nearest Neighbour Regression for Time Series data-A novel Algorithm for Forecasting UK Electricity Demand. F H Al-Qahtani, S F Crone, Proceedings of the International Joint Conference on Neural Networks. the International Joint Conference on Neural NetworksDallas, TX, USAAugust 2013</p>
<p>Short Term Load Forecasting by Using Data Mining Techniques. M Shelke, P D Thakare, Int. J. Sci. Res. 32014</p>
<p>Improving time series forecasting by discovering frequent episodes in sequences. F Martínez-Álvarez, A Troncoso, J C Riquelme, Lect. Notes Comput. Sci. 57722009</p>
<p>Rule-based forecasting: Development and validation of an expert systems approach to combining time series extrapolations. F Collopy, J S Armstrong, Manag. Sci. 381992</p>
<p>Mining association rules between sets of items in large databases. R Agrawal, T Imielinski, A Swami, Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data. the 1993 ACM SIGMOD International Conference on Management of DataWashington, DC, USAMay 1993</p>
<p>Forecasting Peak Load Electricity Demand Using Statistics and Rule Based Approach. Z Ismail, A Yahya, K Mahpol, Am. J. Appl. Sci. 62009</p>
<p>Short-Term Forecasting of Anomalous Load Using Rule-Based Triple Seasonal Methods. Electr. Price Demand Forecast. A Motamedi, H Zareipour, W D Rosehart, 20123Smart Grids</p>
<p>Short-Term Forecasting of Anomalous Load Using Rule-Based Triple Seasonal Methods. S Arora, J W Taylor, IEEE Trans. Power Syst. 282013</p>
<p>Short-Term Load Forecasting in Deregulated Electricity Markets using Fuzzy Approach. S K Aggarwal, M Kumar, L M Saini, A Kumar, J. Eng. Technol. 12011</p>
<p>Fuzzy logic methodology for short term load forecasting. P P Manoj, A P Shah, Int. J. Res. Eng. Technol. 32010</p>
<p>Improving the performance of fuzzy rules-based forecasters through application of FCM algorithm. C P Faustino, C P Novaes, C A M Pinheiro, O A Carpinteiro, Artif. Intell. Rev. 412014</p>
<p>. I Daubechies, Ten Lectures on Wavelets; Society of Industrial in Applied Mathematics: Philadelphia. 1992</p>
<p>. J G Proakis, D G Manolakis, Digital Signal Processing. 1998Prentice Hall</p>
<p>Day-Ahead Electricity Price Forecasting Using the Wavelet Transform and ARIMA Models. A J Conejo, M A Plazas, R Espínola, B Molina, IEEE Trans. Power Syst. 202005</p>
<p>Short-Term Hydro-Thermal Coordination by Lagrangian Relaxation: Solution of the Dual Problem. N Jiménez, A J Conejo, IEEE Trans. Power Syst. 141999</p>
<p>Forecasting Next-Day Electricity Prices by Time Series Models. F J Nogales, J Contreras, A J Conejo, R Espínola, IEEE Trans. Power Syst. 172002</p>
<p>ARIMA Models to Predict Next-Day Electricity Prices. J Contreras, R Espínola, F J Nogales, A J Conejo, IEEE Trans. Power Syst. 182003</p>
<p>Price forecasting using wavelet transform and LSE based mixed model in Australian Electricity Market. S K Aggarwal, L M Saini, A Kumar, Int. J. Energy Sect. Manag. 22008</p>
<p>An Adaptative Wavelet Neural Network-Based Energy Price Forecasting in Electricity Markets. N M Pindoriya, S N Singh, S K Singh, IEEE Trans. Power Syst. 232008</p>
<p>Electricity Load Forecasting Using Non-Decimated Wavelet Prediction Methods with Two-Stage Feature Selection. M Rana, I Koprinska, Proceedings of the International Joint Conference on Neural Networks. the International Joint Conference on Neural NetworksBrisbane, AustraliaJune 2012</p>
<p>Price Forecasting in the Day-Ahead Energy Market by an Iterative Method with Separate Normal Price and Price Spike Frameworks. Energies. S Voronin, J Partanen, 20136</p>
<p>Agent-Based Short-Term Load and Price Forecasting Using a Parallel Implementation of an Adaptive PSO Trained Local Linear Wavelet Neural Network. A M Kintsakis, A Chrysopoulos, P A Mitkas, Proceedings of the International Conference on the European Energy Market. the International Conference on the European Energy MarketLisbon, PortugalMay 2015</p>
<p>Electricity Price Forecasting Through Transfer Function Models. F J Nogales, A J Conejo, J. Oper. Res. Soc. 572006</p>
<p>The seasonal forecast of electricity demand: A hierchical Bayesian model with climatological weather generator. S Pezzulli, P Frederic, S Majithia, S Sabbagh, E Black, R Sutton, D Stephenson, Appl. Stoch. Models Bus. Ind. 222006. 2015</p>
<p>Day-ahead electricity price forecasting in a grid environment. G Li, C C Liu, C Mattson, J Lawarrée, IEEE Trans. Power Syst. 222007</p>
<p>Electricity Price Curve Modeling by Manifold Learning. J Chen, S J Deng, X Huo, IEEE Trans. Power Syst. 232008</p>
<p>Forecasting electricity demand using Grey-Markov model. X Wang, M Meng, Proceedings of the International Conference on Machine Learning and Cybernetics. the International Conference on Machine Learning and CyberneticsKunming, China12-15 July 2008</p>
<p>Partitioning-clustering techniques applied to the electricity price time series. F Martínez-Álvarez, A Troncoso, J C Riquelme, J M Riquelme, Lect. Notes Comput. Sci. 48812007</p>
<p>Discovering patterns in electricity price using clustering techniques. F Martínez-Álvarez, A Troncoso, J C Riquelme, J M Riquelme, Proceedings of the International Conference on Renewable Energy and Power Quality. the International Conference on Renewable Energy and Power QualitySeville, Spain2007Mach</p>
<p>A Labeled-Based Forecasting Algorithm and Its Application to Electricity Price Time Series. F Martínez-Álvarez, A Troncoso, J C Riquelme, J S Aguilar, Lbf, Proceedings of IEEE International Conference on Data Mining. IEEE International Conference on Data MiningPisa, Italy15-19 December 2008</p>
<p>Energy time series forecasting based on pattern sequence similarity. F Martínez-Álvarez, A Troncoso, J C Riquelme, J S Aguilar, IEEE Trans. Knowl. Data Eng. 232011</p>
<p>Discovery of motifs to forecast outlier occurrence in time series. F Martínez-Álvarez, A Troncoso, J C Riquelme, J S Aguilar-Ruiz, Pattern Recognit. Lett. 322011</p>
<p>Day-Ahead Electricity Price Forecasting Using a Hybrid Principal Component Analysis Network. Energies. Y Y Hong, C P Wu, 20125</p>
<p>EUSBoost: Enhancing Ensembles for Highly Imbalanced Data-Sets by Evolutionary Undersampling. M Galar, A Fernandez, E Barrenechea, F Herrera, Pattern Recognit. 462013</p>
<p>. M Galar, J Derrac, D Peralta, I Triguero, D Paternain, C Lopez-Molina, S García, J Benítez, M Pagola, E Barrenechea, A Survey of Fingerprint Classification Part II: Experimental Analysis and Ensemble Proposal. Knowl.-Based Syst. 812015</p>
<p>Forecasting Electricity Demand by Hybrid Machine Learning Model. S Fan, C Mao, J Zhang, L Chen, Lect. Notes Comput. Sci. 42332006</p>
<p>Day-Ahead Electricity Price Forecasting Using Wavelet Transform Combined with ARIMA and GARCH Models. Z Tan, J Zhang, J Wang, J Xu, Appl. Energy. 872010</p>
<p>Short-Term Load Forecasting with Neural Network Ensembles: A Comparative Study (Application Notes). M De Felice, X Yao, IEEE Comput. Intell. Mag. 62011</p>
<p>Short-term load forecasting of Australian National Electricity Market by an ensemble model of extreme learning machine. R Zhang, Z Y Dong, Y Xu, K Meng, K P Wong, IET Gener. Transm. Distrib. 72013</p>
<p>Combining Pattern Sequence Similarity with Neural Networks for Forecasting Electricity Demand Time Series. I Koprinska, M Rana, A Troncoso, F Martínez-Álvarez, Proceedings of the International Joint Conference on Neural Networks. the International Joint Conference on Neural NetworksDallas, TX, USAAugust 2013</p>
<p>An ensemble model for day-ahead electricity demand time series forecasting. W Shen, V Babushkin, Z Aung, W Woon, Proceedings of the ACM Conference on Future Energy Systems. the ACM Conference on Future Energy SystemsBerkeley, CA, USAMay 2013</p>
<p>Neural network model ensembles for building-level electricity load forecasts. J G Jetcheva, M Majidpour, W P Chen, 2014Energy Build84</p>
<p>This article is an open access article distributed under the terms and conditions of the Creative Commons by Attribution (CC-BY) license. A Kaur, H T Pedro, C F Coimbra, 2015 by the authors; licensee MDPI. Basel, Switzerland201480Ensemble re-forecasting methods for enhanced power load prediction. Energy Convers. Manag</p>            </div>
        </div>

    </div>
</body>
</html>