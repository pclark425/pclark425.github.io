<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9012 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9012</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9012</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-159.html">extraction-schema-159</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <p><strong>Paper ID:</strong> paper-271903190</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2408.09150v3.pdf" target="_blank">CogLM: Tracking Cognitive Development of Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Piaget's Theory of Cognitive Development (PTC) posits that the development of cognitive levels forms the foundation for human learning across various abilities. As Large Language Models (LLMs) have recently shown remarkable abilities across a wide variety of tasks, we are curious about the cognitive levels of current LLMs: to what extent they have developed and how this development has been achieved. To this end, we construct a benchmark CogLM (Cognitive Ability Evaluation for Language Model) based on PTC to assess the cognitive levels of LLMs. CogLM comprises 1,220 questions spanning 10 cognitive abilities crafted by more than 20 human experts, providing a comprehensive testbed for the cognitive levels of LLMs. Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human. (2) The parameter size and optimization objective are two key factors affecting the cognitive levels of LLMs. (3) The performance on downstream tasks is positively correlated with the level of cognitive abilities. These findings fill the gap in research on the cognitive abilities of LLMs, tracing the development of LLMs from a cognitive perspective and guiding the future direction of their evolution.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9012.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9012.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OPT-6.7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OPT (6.7B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A text-completion large language model from the OPT family evaluated on a Piaget-inspired cognitive test battery (COGLM); shows limited calibrated cognitive performance corresponding to a young child in the mapping used by the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OPT-6.7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OPT series text-completion transformer models (Zhang et al., 2022); evaluated from checkpoint weights (HuggingFace); optimized for text completion (no chat fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6.7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>COGLM (Cognitive Ability Evaluation for Language Models)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>A multiple-choice benchmark of 1,220 items across 10 cognitive abilities derived from Piaget's Theory of Cognitive Development (text-only, 10 abilities covering stages analogous to Piaget's stages). Measures calibrated accuracy per ability and maps accuracy to an equivalent human 'cognitive age'.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Calibrated accuracies reported per ability (see paper Table 4); aggregate mapping yields an equivalent cognitive age of 6.5 years (per paper's calibrated mapping function).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Adult human baseline reported in paper (per-stage calibrated accuracies in Table 4) and equivalent cognitive age 21.5 years.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>OPT-6.7B is well below adult-human baseline and maps to early-child cognitive level (≈6.5 years) under COGLM.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Evaluated with greedy sampling on NVIDIA A100; text-completion models tested by concatenating each option with the question and selecting the option with highest generation probability ('concat' method) with generation-probability length normalization; multiple-choice format used to avoid generation-format variability. Calibrated accuracy computed per Equation (1) to correct for differing numbers of choices.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>COGLM excludes sensorimotor/multimodal abilities and uses multiple-choice to control generation variability; mapping to 'cognitive age' depends on regression calibration from human questionnaires (participants aged 6–20) and may not generalize beyond that mapping; some per-ability calibrated accuracies can be negative (worse than chance).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogLM: Tracking Cognitive Development of Large Language Models', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9012.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9012.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2-chat-70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-2-chat (70B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 70B-parameter Llama-2 chat model (fine-tuned for dialogue and RLHF) that attains substantially higher calibrated cognitive scores on COGLM than the corresponding base Llama-2 text model, indicating optimization objective (chat/RLHF fine-tuning) benefits COGLM performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-2-chat-70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Llama-2 family (Touvron et al., 2023) — pretrained generative language models with a 70B-parameter variant fine-tuned for dialogue (Llama-2-chat) and further refined with instruction tuning / RLHF.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>COGLM (Cognitive Ability Evaluation for Language Models)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>1,220 multiple-choice items across 10 Piaget-derived cognitive abilities (text-only). Evaluated via constrained-answer prompts for chat models; macro-averaged calibrated accuracies per stage.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Per-paper calibrated accuracies by ability (Table 4). The paper reports an equivalent cognitive age of 14.1 years for Llama-2-chat-70B under their mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Adult human baseline: equivalent cognitive age 21.5 years; per-ability calibrated accuracies provided in Table 4 of the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Llama-2-chat-70B substantially outperforms smaller/unaligned text-only variants (e.g., Llama-2-70B) but remains below GPT-3.5-Turbo and GPT-4; maps to mid-adolescent cognitive level (≈14.1 years) under COGLM.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Chat-completion models were constrained by instruction templates to return single-answer formats; evaluations run via provided HuggingFace weights; greedy sampling on A100; accuracy per stage is macro-average. The authors compared Llama-2-70B vs Llama-2-chat-70B to isolate optimization objective effects.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Improved COGLM performance may reflect benefits from instruction fine-tuning and RLHF rather than fundamental architectural changes; comparisons conflate parameter scale and fine-tuning differences when not controlled; COGLM is text-only and multiple-choice, which may advantage models optimized for instruction-following.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogLM: Tracking Cognitive Development of Large Language Models', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9012.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9012.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2-70B (base)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-2 (70B, text)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The 70B-parameter Llama-2 base text-completion model (pretrained, not chat fine-tuned); used as a baseline to compare optimization objective effects on COGLM performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-2-70B (text)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Llama-2 series pretrained generative language model for text completion (Touvron et al., 2023); evaluated from HuggingFace weights without chat fine-tuning / RLHF.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>COGLM (Cognitive Ability Evaluation for Language Models)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Same COGLM benchmark: 1,220 multiple-choice items across 10 Piaget-based cognitive abilities; text-completion testing via concatenation of options and ranking by generation probability.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Per-paper: lower calibrated accuracies across stages compared to Llama-2-chat-70B (see Figure 2 and Table 4). Specific per-ability calibrated accuracies are reported in paper tables/figures.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Adult human baseline: equivalent cognitive age 21.5 years; per-ability accuracies in Table 4.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Llama-2-70B underperforms its chat-fine-tuned variant (Llama-2-chat-70B) on COGLM at every stage, suggesting optimization/fine-tuning (chat + RLHF) substantially improves measured cognitive abilities.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Text-completion evaluation used 'concat' option-ranking method with normalized generation-probability length; comparisons in Figure 2 isolate the effect of chat fine-tuning/RLHF by comparing the two 70B variants.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Model differences may also include dataset and fine-tuning pipeline differences not fully reported; the paper notes optimization objective (chat fine-tuning + RLHF) improves COGLM performance, but causality beyond correlation is not fully established.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogLM: Tracking Cognitive Development of Large Language Models', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9012.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9012.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-Turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction/chat-optimized OpenAI model evaluated on COGLM; attains strong calibrated cognitive scores mapped to mid-adolescence and shows some abilities where it matches or exceeds human baselines (e.g., empathy).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's GPT-3.5-Turbo chat-optimized model (instruction-following and dialogue-focused); evaluated via OpenAI API ("2023-03-15-preview" version per paper).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A (proprietary; size not specified in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>COGLM (Cognitive Ability Evaluation for Language Models)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>COGLM: multiple-choice battery (1,220 items) covering 10 cognitive abilities derived from Piagetian theory, with calibrated accuracy metric to account for varying numbers of options.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Per-table calibrated accuracies per ability (Table 4). Equivalent cognitive age reported as 16.1 years. Specific per-ability examples: empathy stage score reported higher than the human baseline (paper notes GPT-3.5-Turbo surpasses humans in empathy ability at stage 2).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Adult human baseline per Table 4; equivalent cognitive age 21.5 years.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>GPT-3.5-Turbo markedly outperforms many open models (e.g., OPT, base Llama-2) and maps to a mid-adolescent cognitive level (~16.1 years), but remains below GPT-4 and adult human baseline overall; it outperforms humans on the empathy subtest per COGLM.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Evaluations run through OpenAI API; chat models were prompted to return a single answer with an explanation; greedy decoding; calibrated accuracy computed as in Equation (1); models were asked for single-answer outputs even if format incorrect; averaging per stage done macro across parts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Model size and training specifics are proprietary; comparisons to humans rely on mapping calibrated accuracy to an age regression function trained on human questionnaire data (ages 6–20); higher empathy scores may reflect sociable/overly helpful instruction-following behavior rather than genuine empathic understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogLM: Tracking Cognitive Development of Large Language Models', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9012.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9012.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI's state-of-the-art chat model evaluated on COGLM; achieves the highest calibrated cognitive scores of the tested models and maps to an adult-like cognitive age nearly comparable to a 20-year-old human, but shows specific weaknesses (notably planning).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's GPT-4 model (architecture and training details undisclosed in paper), chat-optimized and evaluated via OpenAI API; highest-performing model in the COGLM experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A (proprietary; not specified in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>COGLM (Cognitive Ability Evaluation for Language Models)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>COGLM: Piaget-inspired multiple-choice battery (1,220 questions) covering 10 cognitive abilities across four developmental stages; calibrated accuracy metric and calibrated mapping to 'cognitive age'.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Per-paper calibrated accuracies per ability (Table 4). Reported equivalent cognitive age: 20.0 years. Selected numbers: plan ability calibrated accuracy 59.4% (paper highlights plan as a weakness for GPT-4). GPT-4 also exceeds humans on some stage-2 empathy measures.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Adult human baseline per Table 4: per-ability calibrated accuracies and equivalent cognitive age 21.5 years; human plan ability 95.6% (for direct comparison with GPT-4 plan = 59.4%).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>GPT-4 achieves human-like cognitive ability under COGLM (maps to ~20 years), outperforming other tested LLMs overall, matching or exceeding humans on some subtests (e.g., empathy), but substantially underperforming humans on planning ability.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Evaluated via OpenAI API with greedy sampling; chat-completion prompts constrained to a single-answer format; models asked to provide answers with explanations; calibrated accuracy computed to correct for variable numbers of options; mapping to 'age' via regression trained on human questionnaire data (80% train, 20% test; Spearman correlation 0.9354 on held-out human data).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>GPT-4 training/architecture specifics unknown; COGLM is text-only and multiple-choice which may bias comparisons; planning weakness (59.4% vs human 95.6%) highlights areas where high aggregate 'age' does not imply uniformly human-equivalent abilities; Chain-of-Thought prompting did not substantially increase COGLM scores for GPT-3.5 (paper hypothesizes cognitive abilities are intrinsic and not easily changed by prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogLM: Tracking Cognitive Development of Large Language Models', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Using cognitive psychology to understand gpt-3 <em>(Rating: 2)</em></li>
                <li>Development of cognitive intelligence in pre-trained language models <em>(Rating: 2)</em></li>
                <li>Large language models still can't plan (a benchmark for llms on planning and reasoning about change) <em>(Rating: 2)</em></li>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 1)</em></li>
                <li>Llama 2: Open foundation and fine-tuned chat models <em>(Rating: 1)</em></li>
                <li>GPT-4 technical report <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9012",
    "paper_id": "paper-271903190",
    "extraction_schema_id": "extraction-schema-159",
    "extracted_data": [
        {
            "name_short": "OPT-6.7B",
            "name_full": "OPT (6.7B)",
            "brief_description": "A text-completion large language model from the OPT family evaluated on a Piaget-inspired cognitive test battery (COGLM); shows limited calibrated cognitive performance corresponding to a young child in the mapping used by the paper.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "OPT-6.7B",
            "model_description": "OPT series text-completion transformer models (Zhang et al., 2022); evaluated from checkpoint weights (HuggingFace); optimized for text completion (no chat fine-tuning).",
            "model_size": "6.7B",
            "test_battery_name": "COGLM (Cognitive Ability Evaluation for Language Models)",
            "test_description": "A multiple-choice benchmark of 1,220 items across 10 cognitive abilities derived from Piaget's Theory of Cognitive Development (text-only, 10 abilities covering stages analogous to Piaget's stages). Measures calibrated accuracy per ability and maps accuracy to an equivalent human 'cognitive age'.",
            "llm_performance": "Calibrated accuracies reported per ability (see paper Table 4); aggregate mapping yields an equivalent cognitive age of 6.5 years (per paper's calibrated mapping function).",
            "human_baseline_performance": "Adult human baseline reported in paper (per-stage calibrated accuracies in Table 4) and equivalent cognitive age 21.5 years.",
            "performance_comparison": "OPT-6.7B is well below adult-human baseline and maps to early-child cognitive level (≈6.5 years) under COGLM.",
            "experimental_details": "Evaluated with greedy sampling on NVIDIA A100; text-completion models tested by concatenating each option with the question and selecting the option with highest generation probability ('concat' method) with generation-probability length normalization; multiple-choice format used to avoid generation-format variability. Calibrated accuracy computed per Equation (1) to correct for differing numbers of choices.",
            "limitations_or_caveats": "COGLM excludes sensorimotor/multimodal abilities and uses multiple-choice to control generation variability; mapping to 'cognitive age' depends on regression calibration from human questionnaires (participants aged 6–20) and may not generalize beyond that mapping; some per-ability calibrated accuracies can be negative (worse than chance).",
            "uuid": "e9012.0",
            "source_info": {
                "paper_title": "CogLM: Tracking Cognitive Development of Large Language Models",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Llama-2-chat-70B",
            "name_full": "Llama-2-chat (70B)",
            "brief_description": "A 70B-parameter Llama-2 chat model (fine-tuned for dialogue and RLHF) that attains substantially higher calibrated cognitive scores on COGLM than the corresponding base Llama-2 text model, indicating optimization objective (chat/RLHF fine-tuning) benefits COGLM performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama-2-chat-70B",
            "model_description": "Llama-2 family (Touvron et al., 2023) — pretrained generative language models with a 70B-parameter variant fine-tuned for dialogue (Llama-2-chat) and further refined with instruction tuning / RLHF.",
            "model_size": "70B",
            "test_battery_name": "COGLM (Cognitive Ability Evaluation for Language Models)",
            "test_description": "1,220 multiple-choice items across 10 Piaget-derived cognitive abilities (text-only). Evaluated via constrained-answer prompts for chat models; macro-averaged calibrated accuracies per stage.",
            "llm_performance": "Per-paper calibrated accuracies by ability (Table 4). The paper reports an equivalent cognitive age of 14.1 years for Llama-2-chat-70B under their mapping.",
            "human_baseline_performance": "Adult human baseline: equivalent cognitive age 21.5 years; per-ability calibrated accuracies provided in Table 4 of the paper.",
            "performance_comparison": "Llama-2-chat-70B substantially outperforms smaller/unaligned text-only variants (e.g., Llama-2-70B) but remains below GPT-3.5-Turbo and GPT-4; maps to mid-adolescent cognitive level (≈14.1 years) under COGLM.",
            "experimental_details": "Chat-completion models were constrained by instruction templates to return single-answer formats; evaluations run via provided HuggingFace weights; greedy sampling on A100; accuracy per stage is macro-average. The authors compared Llama-2-70B vs Llama-2-chat-70B to isolate optimization objective effects.",
            "limitations_or_caveats": "Improved COGLM performance may reflect benefits from instruction fine-tuning and RLHF rather than fundamental architectural changes; comparisons conflate parameter scale and fine-tuning differences when not controlled; COGLM is text-only and multiple-choice, which may advantage models optimized for instruction-following.",
            "uuid": "e9012.1",
            "source_info": {
                "paper_title": "CogLM: Tracking Cognitive Development of Large Language Models",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Llama-2-70B (base)",
            "name_full": "Llama-2 (70B, text)",
            "brief_description": "The 70B-parameter Llama-2 base text-completion model (pretrained, not chat fine-tuned); used as a baseline to compare optimization objective effects on COGLM performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama-2-70B (text)",
            "model_description": "Llama-2 series pretrained generative language model for text completion (Touvron et al., 2023); evaluated from HuggingFace weights without chat fine-tuning / RLHF.",
            "model_size": "70B",
            "test_battery_name": "COGLM (Cognitive Ability Evaluation for Language Models)",
            "test_description": "Same COGLM benchmark: 1,220 multiple-choice items across 10 Piaget-based cognitive abilities; text-completion testing via concatenation of options and ranking by generation probability.",
            "llm_performance": "Per-paper: lower calibrated accuracies across stages compared to Llama-2-chat-70B (see Figure 2 and Table 4). Specific per-ability calibrated accuracies are reported in paper tables/figures.",
            "human_baseline_performance": "Adult human baseline: equivalent cognitive age 21.5 years; per-ability accuracies in Table 4.",
            "performance_comparison": "Llama-2-70B underperforms its chat-fine-tuned variant (Llama-2-chat-70B) on COGLM at every stage, suggesting optimization/fine-tuning (chat + RLHF) substantially improves measured cognitive abilities.",
            "experimental_details": "Text-completion evaluation used 'concat' option-ranking method with normalized generation-probability length; comparisons in Figure 2 isolate the effect of chat fine-tuning/RLHF by comparing the two 70B variants.",
            "limitations_or_caveats": "Model differences may also include dataset and fine-tuning pipeline differences not fully reported; the paper notes optimization objective (chat fine-tuning + RLHF) improves COGLM performance, but causality beyond correlation is not fully established.",
            "uuid": "e9012.2",
            "source_info": {
                "paper_title": "CogLM: Tracking Cognitive Development of Large Language Models",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "GPT-3.5-Turbo",
            "name_full": "GPT-3.5-Turbo (OpenAI)",
            "brief_description": "An instruction/chat-optimized OpenAI model evaluated on COGLM; attains strong calibrated cognitive scores mapped to mid-adolescence and shows some abilities where it matches or exceeds human baselines (e.g., empathy).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo",
            "model_description": "OpenAI's GPT-3.5-Turbo chat-optimized model (instruction-following and dialogue-focused); evaluated via OpenAI API (\"2023-03-15-preview\" version per paper).",
            "model_size": "N/A (proprietary; size not specified in paper)",
            "test_battery_name": "COGLM (Cognitive Ability Evaluation for Language Models)",
            "test_description": "COGLM: multiple-choice battery (1,220 items) covering 10 cognitive abilities derived from Piagetian theory, with calibrated accuracy metric to account for varying numbers of options.",
            "llm_performance": "Per-table calibrated accuracies per ability (Table 4). Equivalent cognitive age reported as 16.1 years. Specific per-ability examples: empathy stage score reported higher than the human baseline (paper notes GPT-3.5-Turbo surpasses humans in empathy ability at stage 2).",
            "human_baseline_performance": "Adult human baseline per Table 4; equivalent cognitive age 21.5 years.",
            "performance_comparison": "GPT-3.5-Turbo markedly outperforms many open models (e.g., OPT, base Llama-2) and maps to a mid-adolescent cognitive level (~16.1 years), but remains below GPT-4 and adult human baseline overall; it outperforms humans on the empathy subtest per COGLM.",
            "experimental_details": "Evaluations run through OpenAI API; chat models were prompted to return a single answer with an explanation; greedy decoding; calibrated accuracy computed as in Equation (1); models were asked for single-answer outputs even if format incorrect; averaging per stage done macro across parts.",
            "limitations_or_caveats": "Model size and training specifics are proprietary; comparisons to humans rely on mapping calibrated accuracy to an age regression function trained on human questionnaire data (ages 6–20); higher empathy scores may reflect sociable/overly helpful instruction-following behavior rather than genuine empathic understanding.",
            "uuid": "e9012.3",
            "source_info": {
                "paper_title": "CogLM: Tracking Cognitive Development of Large Language Models",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "OpenAI's state-of-the-art chat model evaluated on COGLM; achieves the highest calibrated cognitive scores of the tested models and maps to an adult-like cognitive age nearly comparable to a 20-year-old human, but shows specific weaknesses (notably planning).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI's GPT-4 model (architecture and training details undisclosed in paper), chat-optimized and evaluated via OpenAI API; highest-performing model in the COGLM experiments.",
            "model_size": "N/A (proprietary; not specified in paper)",
            "test_battery_name": "COGLM (Cognitive Ability Evaluation for Language Models)",
            "test_description": "COGLM: Piaget-inspired multiple-choice battery (1,220 questions) covering 10 cognitive abilities across four developmental stages; calibrated accuracy metric and calibrated mapping to 'cognitive age'.",
            "llm_performance": "Per-paper calibrated accuracies per ability (Table 4). Reported equivalent cognitive age: 20.0 years. Selected numbers: plan ability calibrated accuracy 59.4% (paper highlights plan as a weakness for GPT-4). GPT-4 also exceeds humans on some stage-2 empathy measures.",
            "human_baseline_performance": "Adult human baseline per Table 4: per-ability calibrated accuracies and equivalent cognitive age 21.5 years; human plan ability 95.6% (for direct comparison with GPT-4 plan = 59.4%).",
            "performance_comparison": "GPT-4 achieves human-like cognitive ability under COGLM (maps to ~20 years), outperforming other tested LLMs overall, matching or exceeding humans on some subtests (e.g., empathy), but substantially underperforming humans on planning ability.",
            "experimental_details": "Evaluated via OpenAI API with greedy sampling; chat-completion prompts constrained to a single-answer format; models asked to provide answers with explanations; calibrated accuracy computed to correct for variable numbers of options; mapping to 'age' via regression trained on human questionnaire data (80% train, 20% test; Spearman correlation 0.9354 on held-out human data).",
            "limitations_or_caveats": "GPT-4 training/architecture specifics unknown; COGLM is text-only and multiple-choice which may bias comparisons; planning weakness (59.4% vs human 95.6%) highlights areas where high aggregate 'age' does not imply uniformly human-equivalent abilities; Chain-of-Thought prompting did not substantially increase COGLM scores for GPT-3.5 (paper hypothesizes cognitive abilities are intrinsic and not easily changed by prompting).",
            "uuid": "e9012.4",
            "source_info": {
                "paper_title": "CogLM: Tracking Cognitive Development of Large Language Models",
                "publication_date_yy_mm": "2024-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Using cognitive psychology to understand gpt-3",
            "rating": 2,
            "sanitized_title": "using_cognitive_psychology_to_understand_gpt3"
        },
        {
            "paper_title": "Development of cognitive intelligence in pre-trained language models",
            "rating": 2,
            "sanitized_title": "development_of_cognitive_intelligence_in_pretrained_language_models"
        },
        {
            "paper_title": "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)",
            "rating": 2,
            "sanitized_title": "large_language_models_still_cant_plan_a_benchmark_for_llms_on_planning_and_reasoning_about_change"
        },
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 1,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Llama 2: Open foundation and fine-tuned chat models",
            "rating": 1,
            "sanitized_title": "llama_2_open_foundation_and_finetuned_chat_models"
        },
        {
            "paper_title": "GPT-4 technical report",
            "rating": 1,
            "sanitized_title": "gpt4_technical_report"
        }
    ],
    "cost": 0.013208249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>CogLM: Tracking Cognitive Development of Large Language Models
12 Feb 2025</p>
<p>Xinglin Wang wangxinglin@bit.edu.cn 
School of Computer Science
Beijing Institute of Technology</p>
<p>Peiwen Yuan peiwenyuan@bit.edu.cn 
School of Computer Science
Beijing Institute of Technology</p>
<p>Shaoxiong Feng shaoxiongfeng2023@gmail.com 
Xiaohongshu Inc</p>
<p>Yiwei Li liyiwei@bit.edu.cn 
School of Computer Science
Beijing Institute of Technology</p>
<p>Boyuan Pan panboyuan@xiaohongshu.com 
Xiaohongshu Inc</p>
<p>Heda Wang 
Xiaohongshu Inc</p>
<p>Yao Hu 
Xiaohongshu Inc</p>
<p>Kan Li likan@bit.edu.cn 
School of Computer Science
Beijing Institute of Technology</p>
<p>CogLM: Tracking Cognitive Development of Large Language Models
12 Feb 202548F087C94E9A9C693AFE9F6F701B75C3arXiv:2408.09150v3[cs.CL]
Piaget's Theory of Cognitive Development (PTC) posits that the development of cognitive levels forms the foundation for human learning across various abilities.As Large Language Models (LLMs) have recently shown remarkable abilities across a wide variety of tasks, we are curious about the cognitive levels of current LLMs: to what extent they have developed and how this development has been achieved.To this end, we construct a benchmark COGLM (Cognitive Ability Evaluation for Language Model) based on PTC to assess the cognitive levels of LLMs.COGLM comprises 1,220 questions spanning 10 cognitive abilities crafted by more than 20 human experts, providing a comprehensive testbed for the cognitive levels of LLMs.Through extensive experiments across multiple mainstream LLMs with COGLM, we find that: (1) In our testing framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.(2) The parameter size and optimization objective are two key factors affecting the cognitive levels of LLMs.(3) The performance on downstream tasks is positively correlated with the level of cognitive abilities.These findings fill the gap in research on the cognitive abilities of LLMs, tracing the development of LLMs from a cognitive perspective and guiding the future direction of their evolution. 1</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) have recently achieved impressive performance on a wide variety of Natural Language Processing (NLP) tasks, including text comprehension (Kenton and Toutanova, 2019), reasoning (Talmor et al., 2020;Webb et al., 2023), code generation (Chen et al., 2021), and mathematical problems (Fu et al., 2023).However, few studies have explored the reasons behind the evolutionary relationship among various abilities, which makes it difficult to understand the development of LLMs' capabilities as a whole and may pose potential risks to their further development.</p>
<p>To this end, we introduce Piaget's Theory of Cognitive Development (PTC) (Piaget et al., 1952;Flavell, 1977;Badakar et al., 2017), which posits that the development of cognitive levels forms the foundation for human learning across various abilities.Inspired by this, we think that studying the cognitive development of LLMs can assist us in better understanding the current performance of LLMs on downstream tasks and illuminate the path for future enhancements of their capabilities.As the most authoritative theory in the development of psychology, PTC suggests that human children move through four different stages of learning, including the sensorimotor stage (0-2 years old), the preoperational stage (2-7 years old), the concrete operational stage (7-12 years old), and the formal operational stage (above 12 years old).Children in different cognitive stages exhibit significantly distinct patterns of thinking and cognitive abilities, which affects their learning of other skills.Examining LLMs from the perspective of PTC, some natural and crucial questions are: At what stage has the cognitive ability of LLMs developed compared to humans at present?What are the key factors that affect the cognitive abilities of LLMs?Is the emergence of advanced abilities and performance bottlenecks in current LLMs related to their cognitive levels?</p>
<p>To explore the above questions, we construct a benchmark based on the scenario experiments used in PTC for evaluating the cognitive abilities of LLMs, denoted as COGLM.A large-scale human trial was conducted involving 207 participants aged between 6 and 20 years to ensure the alignment be-tween the COGLM and PTC.We then perform extensive experiments on COGLM over several series of language models, including OPT (Zhang et al., 2022), Llama-2 (Touvron et al., 2023), GPT-3.5-Turbo and GPT-4 (OpenAI, 2023).Our results indicate that: (1) Under our testing framework, Advanced LLMs, such as GPT-4, have developed human-like cognitive abilities, matching those of a 20-year-old individual.(2) Two primary factors influencing these cognitive capacities in LLMs are the size of their parameters and their optimization objectives.(3) There is a positive correlation between the cognitive level of LLMs and their performance in downstream tasks.</p>
<p>We believe that our findings can present a clear understanding of the current cognitive level of LLMs and provide insights into the emergence of advanced abilities in LLMs, shedding light on the future development of them.Our contributions can be summarised as follows:</p>
<p>• • We construct a high-quality benchmark (COGLM) for evaluating the cognitive ability level of LLMs.</p>
<p>• Comprehensive experiments across multiple LLM series on COGLM demonstrate the cognitive level of current LLMs, key factors responsible for their varying levels, and relationships between cognitive levels and performance on downstream tasks.</p>
<p>COGLM Benchmark Development</p>
<p>To comprehensively and accurately assess the cognitive abilities of LLMs, we undertake the following efforts: (1) We revisit 12 cognitive abilities proposed by PTC, 10 of which are selected and redefined to construct COGLM according to the characteristics of LLMs (section 2.1).</p>
<p>(2) We create standardized data construction guidelines to ensure the quality of COGLM (section 2.2). (3) We conduct extensive human testing to ensure the alignment between COGLM and PTC (section 2.3).</p>
<p>(4) We build a Calibrated Mapping Function to establish a reliable mapping between testing results on COGLM and cognitive age (section 2.4).</p>
<p>Definition of Cognitive Abilities</p>
<p>According to PTC, the development of human cognition is divided into four stages, which include 12 cognitive abilities.Considering that the interaction interface of most LMs is limited to text-based format, we exclude reflexes and sensorimotor aspects of multimodal interaction and build COGLM based on the remaining 10 cognitive abilities.</p>
<p>We strictly define the concept of each cognitive ability based on PTC and provide representative examples for explanation as shown in Table 1.</p>
<p>Standardized Annotation Guidelines</p>
<p>To ensure that COGLM can accurately reflects the cognitive abilities of LLMs, we have established standardized annotation guidelines and strictly adhere to them during the annotation phase:</p>
<p>Data Format Although modern LLMs generally possess strong generation capabilities, early-aged LLMs (e.g., GPT-2) have limited generation abilities (similar to Human infants).Therefore, we have opted for multiple-choice questions as the assessment format.This approach avoids the influence of variations in generation capabilities on the accurate evaluation of cognitive abilities.</p>
<p>Number of Samples Abilities in the early stages are relatively simple and have a more concentrated form of expression, while abilities in the later stages are more comprehensive and have a more diverse form of expression.Based on this, we have set the number of samples to increase with each stage, as shown in the Table 2.</p>
<p>Qualified Annotator We select adults with backgrounds in psychology or artificial intelligence as data annotators.Annotators are provided with detailed materials on PTC and required to study them carefully.We then assess annotators' understanding of PTC through exams (see Appendix Table 11 for the examination paper).Finally, we provide annotators with at least 3 example samples for each cognitive ability.Each annotator is required to annotate no fewer than 30 questions and options for two specific cognitive abilities.</p>
<p>Annotation Quality Control After annotation, we conduct cross-checks among annotators to identify samples with quality issues.Quality issues include questions that cannot effectively assess the corresponding cognitive abilities, questions with ambiguities, and elements of bias or violence.</p>
<p>Consistency with Theory</p>
<p>After the dataset construction is completed, we consider conducting human tests to further ascertain whether COGLM is consistent with PTC and whether it can effectively reflect cognitive abilities.We randomly select 10 samples from each subset of COGLM to create questionnaires, which are then distributed to testers aged between 6 and 20.Out of the 207 completed questionnaires, 141 are deemed valid (based on the reasonableness of test duration2 ).We calculate the Spearman and Pear-son correlation coefficients between the age of the participants and their questionnaire scores.It turns out that spearman correlation is 0.7169 and pearson correlation is 0.7362 (all the p-values &lt; 1e − 10), indicating a strong correlation between them.This statistical result validates the effectiveness of the Standardized Annotation Guidelines we have developed in ensuring the efficacy of COGLM for assessing cognitive abilities.</p>
<p>Calibrated Cognitive Age Mapping Function</p>
<p>After confirming the positive correlation between answer accuracy and cognitive age, we aim to fur-  ther construct the mapping function between them.</p>
<p>We first make adjustments to the method of calculating accuracy.The number of candidate options for questions in COGLM falls within the range [2, 5].Such a variability can impact the likelihood of providing a correct answer through guessing when participants are uncertain.Therefore, we calculate the calibrated accuracy on certain subset S as follows:
Acc = 1 |S| × |S| i=1 1 predict i =answer i − 1/|candidatesi| 1 − 1/|candidatesi|(1)
A negative calibrated accuracy (worse than random selecting) indicates a clear deficiency in the corresponding cognitive ability.We further use 80% of the questionnaire results in Section 2.3 as the training set S Q to optimize the regression function f (•) as follows:
Lregression = 1 |SQ| × |S Q | i=1 (f (Acci) − agei) 2 f (Acc) = 4 i=1 wi × Accstagei + b (2)
The Spearman correlation between the age predicted by f (•) and the real age on the remaining 20% samples is 0.9354, which signifies that f (•) can precisely approximate the mapping from results on COGLM to cognitive age.We observe that w 1 : w 2 : w 3 : w 4 = 1 : 2.6 : 1.4 : 2.5, indicating that cognitive abilities in the second and fourth stages are better at reflecting cognitive age under the evaluation of COGLM.</p>
<p>Experiments</p>
<p>Experimental Setup</p>
<p>Models We perform evaluations on the most recent and popular architectures for NLP tasks and restrict our experiments to LLMs.We conduct experiments on the popular family of GPT architecture: OPT series (Zhang et al., 2022), including models with sizes of 125M, 1.3B, 2.7B, and 6.7B, optimised for text completion; GPT-3.5-Turbo,optimised for chat; and GPT-4, whose training and architecture details are unknown (OpenAI, 2023).We also perform experiments on Llama-2 family of models (Touvron et al., 2023), including models with scale of 7B, 13B and 70B.In particular, Llama-2 series are pretrained generative language models for text completion, while Llama-2-chat is fine-tuned variation optimised for dialogue applications (see Table 3 for statistics of used LLMs).We conduct experiments on NVIDIA A100 with greedy sampling unless otherwise specified.</p>
<p>Evaluation For GPT-3.5-Turbo and GPT-4, we use the Open AI API3 to run all the evaluations.For OPT, Llama-2 and Llama-2-chat series models, we use the weights provided on the Huggingface hub4 .Llama-2-chat models are used as chatcompletion models, while the others are used as text-completion models.For text-completion models, as they lack the ability to follow instructions and their output format is difficult to control, we concatenate each option with the corresponding question as input, and take the option with the highest generation probability as the model's prediction.For chat-completion models, we constrain the format of the model's generated answers through instructions. 5We consider a model to provide a valid answer even if the format is incorrect.Unless specified otherwise, we always ask the model to provide a single answer with explanations.The ac-  curacy for a stage is calculated as a macro average of the accuracies of each part of that stage.</p>
<p>Main Results</p>
<p>As shown in Table 4, We run the model with the largest number of parameters in each series on COGLM, and report the adult human performance for comparison.Overall, the cognitive abilities of OPT, Llama-2-chat-70B, GPT-3.5-Turbo, and GPT-4 models successively increase, and the performance of each model gradually declines with the increase of stage, consistent with humans.Specifically, the latest state-of-the-art model, GPT-4, has demonstrated remarkable cognitive capabilities, achieving a level comparable to that of a 20-yearold human.It is also worth noting that both GPT-3.5-Turbo and GPT-4 surpass humans in empathy ability at stage 2, which is natural, as humans tend to have some degree of selfishness.Despite its superior performance, GPT-4's performance on plan ability (59.4) is still barely satisfactory, far behind that of humans (95.6), which is consistent with the conclusion of Valmeekam et al. (2022).Our results indicate that enhancing the ability of planning is the major direction for improving the overall cognitive abilities of LLMs in the future.For more detailed evaluation results, please refer to Appendix Table 9.</p>
<p>Analysis and Discussion</p>
<p>What are the key factors affecting the cognitive abilities of LLMs?</p>
<p>We explore this question from two perspectives: the parameter size and the optimization objective of LLMs, as they are proven to have significant impact on other abilities.We leave the exploration of factors that require changes to the parameters of LLMs (e.g.fine-tuning on different types of datasets) for future work.The optimization objective of LLMs As shown in Figure 2, we compare the performance of Llama-2-70B and Llama-2-chat-70B at each stage on COGLM.The results show that the performance of both models generally declines with the increase of stage, while the performance of Llama-2-chat-70B far exceeds that of Llama-2-70B at every stage.</p>
<p>Given that Llama-2-chat-70B is further fine-tuned on dialogue data and RLHF trained compared to Llama-2-70B, it suggests that LLMs could potentially enhance their cognitive abilities through learning to chat with humans, as RLHF is another approach for LLMs to learn the world, apart from text pretraining.</p>
<p>Based on the two sets of experiments above, we can draw the conclusion that the parameter size and optimization objective are key factors affecting the cognitive abilities of LLMs.</p>
<p>Can advanced technologies help enhance LLMs' cognitive abilities?</p>
<p>To answer this question, we applied two representative techniques separately to measure whether cognitive abilities of LLMs could be improved.</p>
<p>Effect of Chain-of-Thought</p>
<p>The approach of guiding LLMs to subsequently solve problems has been shown to significantly enhance the performance in most scenarios (Wei et al., 2022).Thus, we are curious whether Chain-of-Thought (COT) can also be effective in improving the cognitive abilities of LLMs.We tested the performance of GPT-3.5-Turbo with and without COT separately on the COGLM and the results are shown in Table 5.From the perspective of the average calibrated accuracy of all the cognitive abilities, COT does not bring a significant performance improvement.We hypothesize that this is because cognitive abilities are inherent to the LLMs and could not be enhanced through multi-step reasoning.</p>
<p>Effect of Self-Consistency Self-Consistency (SC) (Wang et al., 2023)  This phenomenon is consistent with human.For example, for a boy who lacks the ability of empathy, no matter how many times he is asked to choose, he may find it difficult to realize that a scarf might be a more suitable gift for his grandmother than a lollipop.</p>
<p>Based on the two sets of experiments above, we can draw the conclusion that similar to human beings, it is challenging to achieve significant improvements in LLMs' cognitive abilities without external stimuli.</p>
<p>How Cognitive Ability Affects the Performance of LLM</p>
<p>According to PTC, the development of human cognitive abilities is a gradual process, where the cognitive abilities of early stages can influence the advanced cognitive abilities.Additionally, cognitive abilities significantly determines the capacity to solve real-world problems.Therefore, we are very interested in whether these two aspects are similarly manifested in LLMs.(2) The darker colors along the diagonal indicate that the way we erase the corresponding cognitive abilities is effective.</p>
<p>(3) Constancy is a fundamental capability (in line with PTC), as it significantly influences and is influenced by other cognitive abilities.</p>
<p>The Dependence of Downstream Ability on Cognitive Ability In Table 4, we observed a gradual increase in cognitive abilities for OPT, Llama-2, GPT-3.5-Turbo, and GPT-4.On the other hand, based on extensive evaluation studies (Srivastava et al., 2022;Touvron et al., 2023;Liang et al., 2022), we also noted that this ranking result corresponds with the overall performance of LLMs when it comes to solving downstream tasks.This suggests that cognitive abilities are significantly correlated with practical skills for LLMs.To further understand this correlation, we conducted experiments to assess LLMs' performance on downstream tasks when specific cognitive abilities were erased by cognitive-abilitysetting-prompt.We chose representative math reasoning dataset GSM8K (Cobbe et al., 2021) and commonsense reasoning dataset StrategyQA (Talmor et al., 2019) to conduct our experiments.As shown in Table 6, it is reasonable that the erasure of hypothetico-deductive, propositional operation and plan abilities significantly impact the performance of GPT-3.5-Turbo on GSM8K as they are core abilities to solve math problems.We also found that the erasure of other cognitive abilities (especially in early stages) can also bring a strong impact, even if they may not seem helpful in solving math problems.Similar conclusions can be drawn on Strate-gyQA.These findings indicate that LLMs' abilities to solve downstream tasks is positively correlated with the level of cognitive abilities.The advanced cognitive capabilities of GPT-3.5-Turbo and GPT-4 on COGLM partially account for their outstanding performance in various downstream tasks.From this perspective, we can further understand that Zero-shot COT (Kojima et al., 2022) is essentially enhancing LLMs' cognitive ability of deduction for improved performance on downstream tasks by incorporating "Let's think step by step" into the prompt.Table 7: Calibrated accuracy of Llama-2-chat-7B on COGLM with and without Chain-of-Cognition from GPT-3.5-Turbo as input.</p>
<p>Potential applications of advanced LLM cognitive ability</p>
<p>Although there is still room for improvement, the cognitive abilities of advanced LLMs have approached levels close to that of adult humans as discussed in Section 3.2.A natural question is, what are the potential applications for advanced LLMs' cognitive abilities?When humans address cognitive questions, they deduce and provide answers based on their cognitive abilities.While we have demonstrated in Section 3.3.2that the cognitive chain-of-thought (Chain-of-Cognition, COC) generated by LLMs barely help self-address cognitive questions, we are curious whether COC can assist early-aged LLMs in improving cognitive performance.On this basis, we use the question together with the COCs generated by advanced LLM (GPT-3.5-Turbo)as input to test the performance of early-aged LLM (Llama-2-chat-7B) on COGLM.</p>
<p>As shown in Table 7, in most cognitive abilities, COC can significantly improve the performance of Llama-2-chat-7B.We leave the research on using COC from advanced LLMs to guide the improvement of cognitive abilities in early-aged LLMs and even children for future exploration.</p>
<p>Related Work</p>
<p>LLM Evaluation Due to the importance of LLMs, their abilities have been thoroughly evaluated on a wide range of problems.Large-scale efforts have been invested in constructing large benchmarks itegrated with numerous LM evaluations across a number of fields (Srivastava et al., 2022;Liang et al., 2022;Hendrycks et al., 2020;Biderman et al., 2023).Due to the superior performance of LLMs in a number of traditional NLP tasks, recently challenging tasks have been proposed to test the upper bound performance of LLMs (Hendrycks et al., 2021;Valmeekam et al., 2022;Gendron et al., 2023).Some benchmarks include evaluation of specific cognitive abilities, such as common sense reasoning (Ismayilzada et al., 2023), planning (Xie et al., 2024), and deductive reasoning (Saparov and He, 2022).While previous benchmarks focus on measuring either a type or a category of advanced ability in LLMs, few studies explore the development relationship between different abilities, which is crucial for understanding the emergence of LLMs' abilities.</p>
<p>Cognitive psychology survey on LLMs Several works introduce tools from cognitive psychology to study LLMs.Such as understanding the behavior in LLMs (Ritter et al., 2017;Kosoy et al., 2022;Hagendorff et al., 2022;Portelance et al., 2023), exploring the human-like abilities in LLMs (Han et al., 2022;Kosinski, 2023;Aher et al., 2023;Pan and Zeng, 2023), and improving LLMs' performance on certain task (Betz et al., 2021).</p>
<p>Our work is most similar to present work on using cognitive psychology to explore whether LMs "learn and think like people" by Binz and Schulz (2023), which suggests that LLMs struggle to reason causally due to the differences in how humans and LLMs learn about the world.The key difference in our approaches is that Binz and Schulz (2023) aims to study GPT-3 by assessing its advanced abilities (e.g.decision-making, information search, deliberation, and causal reasoning), while we analyze the relationships between the cognitive abilities of LLMs from the perspective of development, rather than assessing the level of a single cognitive ability of LLMs.Additionally, the other concurrent work (Shah et al., 2024) considers the developmental alignment of LLMs' performance during training to the trajectories of children's thinking, primarily measuring the growth trajectories of various cognitive abilities, whereas our measurement of "development" focuses more on the sequence relationships of different cognitive abilities emerging.(Piaget et al., 1952).PTC suggests that intelligence grows and develops through a series of stages.As children interact with the world around them, they continually add new knowledge, build upon existing knowledge, and adapt previously held ideas to accommodate new information.PTC is widely used in education, psychology, linguistics, and neuroscience, providing a theoretical framework and methodology for research in these areas.</p>
<p>Conclusions</p>
<p>In</p>
<p>Limitations</p>
<p>Despite obtaining some valuable findings through CogLM, our current exploration does not consider the language model's performance at different training stages to further provide insights for model training, and we will explore it in our future work.</p>
<p>Constancy</p>
<p>Please imagine yourself as a child aged 0-2 years old.According to Piaget's theory of cognitive development, you are currently unable to recognize that objects exist both within and outside the field of vision and maintain a certain level of stability.</p>
<p>Early Representation</p>
<p>Please imagine yourself as a child aged 0-2 years old.According to Piaget's theory of cognitive development, You currently cannot give objects corresponding meanings, nor do you have a definite perception of permanent objects in the universe.</p>
<p>Semiotic Function</p>
<p>Please imagine yourself as a child aged 2-7 years old.According to Piaget's theory of cognitive development, You are currently unable to use symbols to represent things and concepts.</p>
<p>Empathy</p>
<p>Please imagine yourself as a child aged 2-7 years old.According to Piaget's theory of cognitive development, You are accustomed to thinking from your own perspective and have not yet formed a sense of empathy.</p>
<p>Reversibility</p>
<p>Please imagine yourself as a child aged 7-11 years old.According to Piaget's theory of cognitive development, You are currently unable to understand the reversibility of physical operations and unable to reverse thinking.</p>
<p>Conservation</p>
<p>Please imagine yourself as a child aged 7-11 years old.According to Piaget's theory of cognitive development, You think that external changes in form (length, shape, etc.) may affect the basic properties of an object (mass, volume, etc.).</p>
<p>Induction</p>
<p>Please imagine yourself as a child aged 7-11 years old.According to Piaget's theory of cognitive development, You currently cannot infer universal rules based on observed results.</p>
<p>Hypothetico-Deductive</p>
<p>Please imagine yourself as a teenager aged 11-18 years old.According to Piaget's theory of cognitive development, You are currently unable to deduce practical problems based on specific assumptions or rules.</p>
<p>Propositional Operation</p>
<p>Please imagine yourself as a teenager aged 11-18 years old.According to Piaget's theory of cognitive development, You are currently unable to understand propositions and determine the logical relationships between propositions.</p>
<p>Plan</p>
<p>Please imagine yourself as a teenager aged 11-18 years old.According to Piaget's theory of cognitive development, You are are currently unable to develop solutions based on specific problem.</p>
<p>We innovatively introduce Piaget's Theory of Cognitive Development (PTC) to analyze the development of cognitive abilities of LLMs.</p>
<p>Figure 2 :
2
Figure 2: Comparison of the performance of Llama-2-70B and Llama-2-chat-70B at each stage on COGLM.</p>
<p>The parameter size of LLMs As shown in Figure1, we compare the overall performance of models with different parameter size across OPT and Llama-2-chat series, and report the performance of humans at different stages as a reference.Specifically, the cognitive abilities of LLMs continuously improve as the size of model parameters increases, which is in line with the conclusion inRen et al. (2024).</p>
<p>Figure 3 :
3
Figure 3: Cognitive ability interdependence matrix.The vertical axis represents cognitive abilities erased through prompts, and the color depth (calibrated accuracy) indicates the impact on the corresponding horizontal axis abilities after erasure.</p>
<p>Piaget' s
s
Theory of Cognitive Development Theory of Cognitive Development (PTC) is the most authoritative theory in the development of psychology, developed by Jean Piaget</p>
<p>Table 1 :
1
Definitions and examples of cognitive abilities included in COGLM.</p>
<p>Table 2 :
2
Data statistics on all ability subsets of COGLM.
COGLMstage 1 const early semio empat rever conse induc deduc propo plan stage 2 stage3 stage4OverallSample Number50 100100 100100 110 100250 100 210 1220Question Tokens 18.5 11.36 11.55 25.27 30.0 26.3 42.0 51.8 30.0 77.9 39.5Candidates Number 2.00 4.00 3.96 2.96 4.00 2.98 4.00 4.00 3.00 4.00 3.66Candidates Tokens 1.00 1.19 1.48 4.23 3.87 4.28 7.58 1.00 1.00 20.30 5.71TypeSeriesSizeText completionOPT Llama-2125M, 1.3B, 2.7B, 6.7B 7B,13B,70BLlama-2-chat7B,13B,70BChat completionGPT-3.5-TurboN/AGPT-4N/A</p>
<p>Table 3 :
3
The statistics of considered language models.</p>
<p>Table 4 :
4
Calibrated accuracy (%) of largest model in evaluating series.Acc and Age refer to calibrated accuracy and the age of equivalent human performance.The value of Age is calculated according to Equation2.Bold indicates the best performance.
Modelstage1 const early semio empat conse induc rever deduc propo plan stage2 stage3 stage4Acc AgeOPT 6.7B-4.0 64.2 41.1 -3.013.5 10.6 20.1-0.8 -0.5 14.2 15.5 6.5Llama-2-chat-70B 52.1 96.2 78.5 66.268.4 65.3 44.0 15.2 40.0 20.6 54.6 14.1GPT-3.5-Turbo92.0 97.3 90.6 85.565.9 64.0 61.3 27.5 49.0 6.7 64.0 16.1GPT-496.0 97.3 96.0 90.390.4 78.7 78.7 99.4 61.0 59.4 84.7 20.0Human100.0 98.0 96.1 84.298.2 91.6 92.0 100.0 82.0 95.6 93.7 21.5
stage4 Figure 1: Average calibrated accuracy (%) of models with different parameter size and humans in different cognitive stage.</p>
<p>Table 5 :
5
Calibrated accuracy of GPT-3.5-Turbo on COGLM with multiple settings."Base" indicates settings where both COT and SC are not used.
The Interdependence Between Cognitive Abili-ties Through preliminary experiments, we foundthat advanced LLMs' ability to follow instructionscan help us erase specific cognitive abilities us-ing a cognitive-ability-setting-prompt (e.g., "You
have not yet formed a sense of empathy".See Appendix Table10for all the prompts).On this basis, We investigated the interdependence of cognitive abilities in LLMs by selectively removing specific cognitive capabilities and testing them on COGLM.</p>
<p>Table 6 :
6
Accuracy (%) of GPT-3.5-Turbo on GSM8K and StrategyQA datasets when different cognitive abilities are erased.
According to the experimental results shown in Fig-ure 3, we can draw the following conclusions: (1)Advanced cognitive abilities significantly rely onearly cognitive abilities, which indicates that thedependency relationships of LLMs' cognitive abili-ties are similar to those of humans.</p>
<p>Table 10 :
10
Cognitive-ability-setting-prompts of different cognitive abilities.Which stage in Piaget's theory marks the point at which children are capable of logical thinking and understanding concepts like quantity, category, space, and time?Answer: Formal operational stage Question: What type of operations can children perform during the concrete operational stage?Answer: Addition and subtraction Question: Janie knows that a bird has wings and can fly.While camping she finds a bat and thinks it's a bird, but realizes that it doesn't act the same way as a bird.She is confused.She is using what adaptation process with this new knowledge?Answer: Accommodation Question: What kind of activities can children engage in during the formal operational stage?Answer: Abstract thinking and logical reasoning Question: In Jean Piaget's cognitive development theory, which stage marks the point at which children begin to use symbols and language to represent objects?Answer: Preoperational stage Question: Which of the following is NOT one of Piaget's stages of cognitive development?Answer: Abstract operational stage Question: Children in the concrete operational stage typically understand what type of concepts?Answer: Concepts of quantity and space Question: What types of problems can children in the formal operational stage handle?Answer: Abstract and hypothetical problems Question: What are common characteristics of children in the preoperational stage?Answer: Subject to egocentrism Question: In the sensorimotor stage, how do children primarily explore the world?Answer: Sensation and movement Question: In the sensorimotor stage, how do infants primarily interact with the world?Answer: Observation and sensation Question: Jean Piaget's cognitive development theory primarily focuses on which age group of children?Answer: Infants and children Question: What types of problems can children in the concrete operational stage typically understand?Answer: Logical problems Question: What characteristics do children in the formal operational stage exhibit?Answer: Ability to engage in abstract thinking and hypothetical reasoning Question: What does Jean Piaget's cognitive development theory emphasize?Answer: The active role of individuals in cognitive development Question: In Jean Piaget's cognitive development theory, which stage marks the point at which children can engage in abstract thinking and hypothetical reasoning?Answer: Formal operational stage Question: What does Piaget's theory emphasize as influencing cognitive development?Answer: A balance of social factors and genetic factors Question: What can children in the formal operational stage consider when thinking?Answer: Future and hypothetical situations Question: What is the primary focus of the sensorimotor stage in Piaget's theory?Answer: Sensory and motor exploration
Question: How many main stages are included in Jean Piaget's cognitive developmenttheory? Answer: 4Question:</p>
<p>Table 11 :
11
Examination paper to ensure the annotators are qualified.</p>
<p>Our code and data have been released on https:// github.com/WangXinglin/CogLM.
We deem the papers completed by the questionnaires in less than 10 minutes as invalid. Humans received the same multiple-choice questions to answer as LLMs.
We use "2023-03-15-preview" version for both.
https://huggingface.co/
We set the valid output format as: "The answer is option " in the prompt.
AcknowledgementsThis work is supported by the Beijing Natural Science Foundation, China (Nos.4222037, L181010).Ethics StatementOur dataset does not contain any harmful or offensive contents.Any personal or sensitive information is anonymized and treated with utmost confidentiality.We ensure the protection of participants' privacy and obtain informed consent for data collection, annotation, and analysis.We incentivized all the annotators uniformly throughout the annotation process.A AppendixA.1 Testing Method of Text-completion ModelsFor text-completion models, as they lack the ability to follow instructions and their output format is difficult to control, we concatenate each option with the corresponding question as input, and take the option with the highest generation probability as model prediction.When calculating the generation probability, we normalized the generation length to eliminate the influence of the option length.Additionally, we compared the approach of having the model interpret the questions as multiple choice and using a letter as the concatenated answer (denoted as "option") with our existing testing method (denoted as "concat") using GPT-2 and OPT-125M.The results (Table8) show that changing the testing method from "concat" to "option" leads to a significant decrease in the performance of the textcompletion model.We suppose this is due to the text-completion model being more sensitive to factors such as position bias and model preference compared to the chat-completion model.As a result, directly concatenating the options with the question and ranking them based on probability is more suitable for testing the text-completion model.-20.0 52.0 38.4 -11.0 1.0 12.0 13.3 -6.1 2.5 -3.0 7.9 5.2 OPT 2.7B -8.0 53.3 43.7 -9.5 9.4 12.0 21.1 -1.3 5.5 3.4 12.95 6.1 OPT 6.7B -4.0 64.2 41.1 -3.0 13.5 10.6 20.1 -0.8 -0.5 14.2 15.5 6.5 LLaMA2-text 7B 16.0 82.6 43.7 -4.0 20.0 1.3 24.0 -16.8 14.5 24.4 20.5 7.3 LLaMA2-text 13B 28.0 84.0 42.4 -3.0 13.0 13.5 24.
Using large language models to simulate multiple humans and replicate human subject studies. Rosa I Gati V Aher, Adam Arriaga, Kalai Tauman, International Conference on Machine Learning. PMLR2023</p>
<p>Evaluation of the relevance of piaget's cognitive principles among parented and orphan children in belagavi city, karnataka, india: A comparative study. Chandrashekhar M Badakar, J Prachi, Thakkar, M Shivayogi, Pratibha Hugar, Kukreja, Niraj Harsha G Assudani, Gokhale, International journal of clinical pediatric dentistry. 1043462017</p>
<p>Thinking aloud: Dynamic context generation improves zero-shot reasoning performance of gpt-2. Gregor Betz, Kyle Richardson, Christian Voigt, arXiv:2103.130332021arXiv preprint</p>
<p>Pythia: a suite for analyzing large language models across training and scaling. Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, O' Kyle, Eric Brien, Mohammad Hallahan, Shivanshu Aflah Khan, Purohit, Sai Usvsn, Edward Prashanth, Raff, Proceedings of the 40th International Conference on Machine Learning. the 40th International Conference on Machine Learning2023</p>
<p>Using cognitive psychology to understand gpt-3. Marcel Binz, Eric Schulz, Proceedings of the National Academy of Sciences. 1206e22185231202023</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, CoRR, abs/2110.141682021</p>
<p>John H Flavell, Cognitive development. Prentice-Hall1977</p>
<p>Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance. Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, Tushar Khot, arXiv:2305.173062023arXiv preprint</p>
<p>Large language models are not abstract reasoners. Gaël Gendron, Qiming Bao, Michael Witbrock, Gillian Dobbie, arXiv:2305.195552023arXiv preprint</p>
<p>Thilo Hagendorff, Sarah Fabi, Michal Kosinski, arXiv:2212.05206Machine intuition: Uncovering human-like intuitive decision-making in gpt-3.5. 2022arXiv preprint</p>
<p>Human-like property induction is a challenge for large language models. Simon Jerome, Han , Keith James Ransom, Andrew Perfors, Charles Kemp, Proceedings of the annual meeting of the cognitive science society. the annual meeting of the cognitive science society202244</p>
<p>Measuring massive multitask language understanding. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, International Conference on Learning Representations. 2020</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, arXiv:2103.038742021arXiv preprint</p>
<p>CRoW: Benchmarking commonsense reasoning in real-world tasks. Mete Ismayilzada, Debjit Paul, Syrielle Montariol, Mor Geva, Antoine Bosselut, 10.18653/v1/2023.emnlp-main.607Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics2023</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of naacL-HLT. Jacob Devlin, Ming-Wei Chang, Kenton , Lee Kristina, Toutanova , naacL-HLT201912</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, NeurIPS. 2022</p>
<p>Michal Kosinski, arXiv:2302.02083Theory of mind may have spontaneously emerged in large language models. 2023arXiv preprint</p>
<p>Nan Rosemary Ke, and Alison Gopnik. 2022. Towards understanding how machines can learn causal overhypotheses. Eliza Kosoy, Adrian David M Chan, Jasmine Liu, Bryanna Collins, Sandy Han Kaufmann, Jessica B Huang, John Hamrick, Canny, arXiv:2206.08353arXiv preprint</p>
<p>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, arXiv:2211.09110Holistic evaluation of language models. Ananya Kumar, et al. 2022arXiv preprint</p>
<p>arXiv:2303.08774Gpt-4 technical report. 2023OpenAIPreprint</p>
<p>Do llms possess a personality? making the mbti test an amazing evaluation for large language models. Keyu Pan, Yawen Zeng, arXiv:2307.161802023arXiv preprint</p>
<p>The origins of intelligence in children. Jean Piaget, Margaret Cook, 1952International Universities Press8New York</p>
<p>Predicting age of acquisition for children's early vocabulary in five languages using language model surprisal. Eva Portelance, Yuguang Duan, Michael C Frank, Gary Lupyan, Cognitive Science. 479e133342023</p>
<p>Renren Yuqi Ren, Tongxuan Jin, Deyi Zhang, Xiong, arXiv:2402.18023Do large language models mirror cognitive language processing. 2024arXiv preprint</p>
<p>Cognitive psychology for deep neural networks: A shape bias case study. Samuel Ritter, David Gt Barrett, Adam Santoro, Matt M Botvinick, International conference on machine learning. PMLR2017</p>
<p>Language models are greedy reasoners: A systematic formal analysis of chain-of-thought. Abulhair Saparov, He He, The Eleventh International Conference on Learning Representations. 2022</p>
<p>Development of cognitive intelligence in pre-trained language models. Raj Shah, Khushi Bhardwaj, Sashank Varma, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. the 2024 Conference on Empirical Methods in Natural Language Processing2024</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal, Md Shoeb, Abubakar Abid, Adam Fisch, Adam Adam R Brown, Aditya Santoro, Adrià Gupta, Garriga-Alonso, arXiv:2206.04615Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. 2022arXiv preprint</p>
<p>Commonsenseqa: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, 10.18653/v1/n19-1421Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational Linguistics2019. June 2-7, 20191</p>
<p>Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge. Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, Jonathan Berant, Advances in Neural Information Processing Systems. 202033</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>Large language models still can't plan (a benchmark for llms on planning and reasoning about change). Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, arXiv:2206.104982022arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, The Eleventh International Conference on Learning Representations, ICLR 2023. Kigali, Rwanda2023. May 1-5, 2023OpenReview.net</p>
<p>Emergent analogical reasoning in large language models. Taylor Webb, Keith J Holyoak, Hongjing Lu, Nature Human Behaviour. 2023</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H Chi, V Quoc, Denny Le, Zhou, 2022In NeurIPS</p>
<p>Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, Yu Su, arXiv:2402.01622Travelplanner: A benchmark for realworld planning with language agents. 2024arXiv preprint</p>
<p>Opt: Open pre-trained transformer language models. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, arXiv:2205.010682022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>