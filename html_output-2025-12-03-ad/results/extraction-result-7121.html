<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7121 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7121</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7121</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-960bbfe08f81e28598a4d77a9ee8db16e184079b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/960bbfe08f81e28598a4d77a9ee8db16e184079b" target="_blank">Theory Unification and Graphical Models in Human Categorization</a></p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7121.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7121.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GCM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generalized Context Model (Exemplar-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An exemplar/instance-based similarity model that represents categories as sets of remembered exemplars in an n-dimensional feature space; category similarity is the (weighted) sum of exponential distance-based similarities between a novel item and stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Exemplar Theory / Generalized Context Model (GCM)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based (instance/exemplar)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Categories are represented as collections of exemplars (previously observed instances) each specified by feature values; similarity of a novel item to a category equals the sum (weighted average) of its similarity to the category's exemplars, where exemplar similarity is a product/exponential function of featurewise distances.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for graded typicality and similarity judgments, supports category classification via similarity-based choice rules (Shepard–Luce), and enables feature inference by sampling from exemplars in the category.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments and model-fitting (psychophysical categorization / similarity rating studies) cited in literature</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>similarity judgments / typicality ratings and categorization tasks (two-stage: compute similarity then apply Shepard–Luce choice rule); model fitting to behavioral choice and similarity data</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>GCM similarity function defined mathematically as exemplar-weighted sum of exponential distances; Danks shows every GCM category's pattern of similarity ratings is proportional to a probability distribution that has a perfect-map representation by a particular Bayes net (Figure 2 graph) under weak regularity constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>GCM can be mapped to a class of Bayes nets only under regularity constraints on P(F_i | E); some empirical results favor alternative models in particular tasks/structures (see Rehder common-effect condition favoring causal models); connectionist models and some category structures may not be well-characterized by standard GCM without generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Danks (year not provided)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7121.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7121.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype (SOP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype-based Theory with Second-Order Features (SOP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prototype theories represent categories by a prototype (summary/average) object; Danks describes an augmented prototype (SOP) that includes second-order features (feature conjunctions/correlations) so similarity accounts for inter-feature dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Prototype Theory (second-order prototype / SOP)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based prototype (summary/statistical)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Categories are represented by prototypical summary statistics (a single prototype vector possibly augmented with higher-order/second-order feature constructs capturing correlations); similarity of an item to the category depends on distance to this prototype across first- and second-order features.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains typicality gradients, rapid category classification via distance to a summary representation, and supports feature inference by reading summary statistics encoded in the prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments and model-fitting (typicality/similarity/categorization studies) cited in literature</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>typicality/similarity ratings, category membership decisions; comparisons of prototype vs exemplar fits to behavioral data</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Danks formalizes second-order prototype similarity (SOP) as product over first- and second-order feature distances and shows SOP patterns correspond to probability distributions that can be perfectly mapped by particular Markov random fields (edges correspond to second-order features).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Simple (single-instance) prototype models fail to capture inter-feature correlations unless augmented (e.g., SOP); some empirical category structures (e.g., those representable by causal Bayes nets but not Markov random fields) are predicted to be poorly fit by prototype-based accounts (Rehder common-effect condition).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Danks (year not provided)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7121.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7121.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal Model Theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Model Theory (Causal Bayes Nets)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Defines categories in terms of underlying causal structures among features (modeled as causal Bayesian networks); similarity is proportional to the likelihood that the category's causal model would generate the observed feature pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Causal Model Theory (causal Bayes nets)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>probabilistic causal graphical model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>A category is represented by a causal Bayesian network (directed acyclic graph plus conditional distributions); the similarity of an instance to a category is proportional to P(instance | causal model), so categorization is inference under a causal generative model.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains similarity judgments driven by causal structure, supports causal reasoning tied to categorization, and enables feature inference and prediction using the category's causal relations.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments and model-fitting (Rehder's empirical studies), plus broader causal-learning literature cited (Ahn et al., Lien & Cheng, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>categorization tasks based on stimuli constructed from causal-structure manipulations (e.g., Rehder's common-cause vs common-effect conditions), similarity ratings and feature inference tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Danks notes current causal model implementations use causal Bayes nets and equates CMT similarity with P(X | M); empirical work (Rehder 2003a) found that in a common-effect condition the causal-model fit was significantly better than second-order prototype fits, supporting causal-model predictions for some structures.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>There are category structures (e.g., simple uncorrelated features or certain Markov random field factorizations) where causal models and prototype/exemplar models make equivalent predictions; empirical support is context-dependent and not universally dominant.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Danks (year not provided)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7121.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7121.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayes Net (Figure 2)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Network representation (naïve Bayes / latent common cause, Figure 2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Directed acyclic probabilistic graphical model used to represent conditional independencies among features; Danks shows GCM categories correspond to Bayes nets with a latent common-cause node (Figure 2 graph) and appropriate conditional distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Bayesian Network (directed probabilistic graphical model)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>probabilistic graphical model (directed)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Representational format where variables/features are nodes in a directed acyclic graph and the joint distribution factors as product of conditionals P(F_i | parents(F_i)); when interpreted causally, edges denote direct causal influences.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Provides compact representations of joint distributions via encoded independencies, supports inference about instance likelihoods P(X | Model) and causal/diagnostic reasoning when edges are causal.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical mapping and computational/model-fitting equivalence proofs; empirical categorization experiments insofar as behavioral similarity patterns can be fit by Bayes-net-parameterized distributions</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>used as a representational hypothesis in analyses of categorization/similarity data; relevant paradigms include categorization based on latent-cause structures and model comparison on behavioral datasets</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Danks proves (sketches) that any GCM similarity pattern can be represented (up to scale) by a Bayes net with the Figure 2 latent-cause graph under weak regularity constraints, establishing formal equivalence between exemplar similarity functions and a subclass of Bayes nets.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Some probability distributions (and therefore some category similarity patterns) that are perfectly represented by Markov random fields cannot be perfectly represented by any Bayes net; directed asymmetries in Bayes nets differ from symmetric second-order prototype correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Danks (year not provided)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7121.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7121.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Markov RF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Markov Random Field (undirected probabilistic graphical model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Undirected graphical model where edges indicate symmetric probabilistic dependencies; Danks maps second-order prototype representations (feature conjunctions/correlations) to Markov random fields whose cliques correspond to those feature dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Markov Random Field (MRF)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>probabilistic graphical model (undirected)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Represents joint distributions via undirected graphs and clique potentials: P(X) ∝ (1/Z) ∏ g_i(X_clique_i); edges denote symmetric dependencies without causal directionality, making MRFs suitable for capturing correlated/relational prototype features.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Captures symmetric inter-feature correlations (second-order features) in a principled probabilistic way, enabling similarity patterns corresponding to prototype models with feature conjunctions and supporting inference via clique potentials.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical mapping and formal argumentation (equivalence results); used to reinterpret prototype-based similarity functions as probability distributions factorizable into clique potentials</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>conceptual/theoretical mapping to behavioral similarity data; can be applied to categorization tasks where feature correlations matter</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Danks shows second-order prototype similarity patterns correspond to probability distributions that have perfect-map representations as Markov random fields (edges correlate with second-order features), and that some MRF factorizations cannot be captured by Bayes nets.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Markov random fields cannot represent asymmetrical causal factorization that Bayes nets can; empirical fits will favor MRF-based prototype accounts only for categories whose structure includes symmetric feature correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Danks (year not provided)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7121.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7121.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>P(X|Model) Unification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>P(X | Model) computational unification hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A unifying functional-level claim that categorization similarity ratings correspond (up to scale) to the probability of the observed feature pattern under some internal model: similarity(X, Category) ∝ P(X | Model), where Model is a probabilistic graphical model (Bayes net or MRF).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Probabilistic Unification: similarity as P(X | Model)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>probabilistic distribution / computational-level representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functional claim: the cognitive computation for similarity-based categorization is computing (a scaled version of) the likelihood of an item under a stored generative model (graphical model) of the category; different representational graph types (directed vs undirected, latent nodes, clique structure) correspond to exemplar, prototype, and causal theories.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how apparently distinct categorization theories can be different parameterizations of a single computational operation (compute P(X|Model)), predicts when different models will be empirically indistinguishable (same P(X) patterns), and guides experimental design to dissociate representational forms.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical derivations / formal equivalences and application to existing behavioral model-comparison results (e.g., Rehder 2003a analyses)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>analysis/model-comparison of categorization and similarity datasets; construction of category stimuli whose underlying P(X) factorizations differ so as to test representational format hypotheses (common-cause vs common-effect manipulations)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Danks demonstrates that GCM, second-order prototypes, and causal model similarity functions can all be expressed as computations proportional to P(X | Model) for different classes of graphical models (Bayes nets with latent cause, MRFs, causal Bayes nets), enabling analytical predictions about when differing theories will or will not be distinguishable experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Not empirical counterevidence per se, but the mapping requires certain regularity constraints for exact equivalence and some category structures (chain graphs) fall outside pure Bayes-net or pure MRF perfect-map representations, predicting systematic human errors not captured by simpler models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Danks (year not provided)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7121",
    "paper_id": "paper-960bbfe08f81e28598a4d77a9ee8db16e184079b",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "GCM",
            "name_full": "Generalized Context Model (Exemplar-based)",
            "brief_description": "An exemplar/instance-based similarity model that represents categories as sets of remembered exemplars in an n-dimensional feature space; category similarity is the (weighted) sum of exponential distance-based similarities between a novel item and stored exemplars.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Exemplar Theory / Generalized Context Model (GCM)",
            "theory_type": "feature-based (instance/exemplar)",
            "theory_description": "Categories are represented as collections of exemplars (previously observed instances) each specified by feature values; similarity of a novel item to a category equals the sum (weighted average) of its similarity to the category's exemplars, where exemplar similarity is a product/exponential function of featurewise distances.",
            "functional_claims": "Accounts for graded typicality and similarity judgments, supports category classification via similarity-based choice rules (Shepard–Luce), and enables feature inference by sampling from exemplars in the category.",
            "evidence_source": "behavioral experiments and model-fitting (psychophysical categorization / similarity rating studies) cited in literature",
            "experimental_paradigm": "similarity judgments / typicality ratings and categorization tasks (two-stage: compute similarity then apply Shepard–Luce choice rule); model fitting to behavioral choice and similarity data",
            "key_result": "GCM similarity function defined mathematically as exemplar-weighted sum of exponential distances; Danks shows every GCM category's pattern of similarity ratings is proportional to a probability distribution that has a perfect-map representation by a particular Bayes net (Figure 2 graph) under weak regularity constraints.",
            "supports_theory": null,
            "counter_evidence": "GCM can be mapped to a class of Bayes nets only under regularity constraints on P(F_i | E); some empirical results favor alternative models in particular tasks/structures (see Rehder common-effect condition favoring causal models); connectionist models and some category structures may not be well-characterized by standard GCM without generalization.",
            "citation": "Danks (year not provided)",
            "uuid": "e7121.0"
        },
        {
            "name_short": "Prototype (SOP)",
            "name_full": "Prototype-based Theory with Second-Order Features (SOP)",
            "brief_description": "Prototype theories represent categories by a prototype (summary/average) object; Danks describes an augmented prototype (SOP) that includes second-order features (feature conjunctions/correlations) so similarity accounts for inter-feature dependencies.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Prototype Theory (second-order prototype / SOP)",
            "theory_type": "feature-based prototype (summary/statistical)",
            "theory_description": "Categories are represented by prototypical summary statistics (a single prototype vector possibly augmented with higher-order/second-order feature constructs capturing correlations); similarity of an item to the category depends on distance to this prototype across first- and second-order features.",
            "functional_claims": "Explains typicality gradients, rapid category classification via distance to a summary representation, and supports feature inference by reading summary statistics encoded in the prototype.",
            "evidence_source": "behavioral experiments and model-fitting (typicality/similarity/categorization studies) cited in literature",
            "experimental_paradigm": "typicality/similarity ratings, category membership decisions; comparisons of prototype vs exemplar fits to behavioral data",
            "key_result": "Danks formalizes second-order prototype similarity (SOP) as product over first- and second-order feature distances and shows SOP patterns correspond to probability distributions that can be perfectly mapped by particular Markov random fields (edges correspond to second-order features).",
            "supports_theory": null,
            "counter_evidence": "Simple (single-instance) prototype models fail to capture inter-feature correlations unless augmented (e.g., SOP); some empirical category structures (e.g., those representable by causal Bayes nets but not Markov random fields) are predicted to be poorly fit by prototype-based accounts (Rehder common-effect condition).",
            "citation": "Danks (year not provided)",
            "uuid": "e7121.1"
        },
        {
            "name_short": "Causal Model Theory",
            "name_full": "Causal Model Theory (Causal Bayes Nets)",
            "brief_description": "Defines categories in terms of underlying causal structures among features (modeled as causal Bayesian networks); similarity is proportional to the likelihood that the category's causal model would generate the observed feature pattern.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Causal Model Theory (causal Bayes nets)",
            "theory_type": "probabilistic causal graphical model",
            "theory_description": "A category is represented by a causal Bayesian network (directed acyclic graph plus conditional distributions); the similarity of an instance to a category is proportional to P(instance | causal model), so categorization is inference under a causal generative model.",
            "functional_claims": "Explains similarity judgments driven by causal structure, supports causal reasoning tied to categorization, and enables feature inference and prediction using the category's causal relations.",
            "evidence_source": "behavioral experiments and model-fitting (Rehder's empirical studies), plus broader causal-learning literature cited (Ahn et al., Lien & Cheng, etc.)",
            "experimental_paradigm": "categorization tasks based on stimuli constructed from causal-structure manipulations (e.g., Rehder's common-cause vs common-effect conditions), similarity ratings and feature inference tasks",
            "key_result": "Danks notes current causal model implementations use causal Bayes nets and equates CMT similarity with P(X | M); empirical work (Rehder 2003a) found that in a common-effect condition the causal-model fit was significantly better than second-order prototype fits, supporting causal-model predictions for some structures.",
            "supports_theory": true,
            "counter_evidence": "There are category structures (e.g., simple uncorrelated features or certain Markov random field factorizations) where causal models and prototype/exemplar models make equivalent predictions; empirical support is context-dependent and not universally dominant.",
            "citation": "Danks (year not provided)",
            "uuid": "e7121.2"
        },
        {
            "name_short": "Bayes Net (Figure 2)",
            "name_full": "Bayesian Network representation (naïve Bayes / latent common cause, Figure 2)",
            "brief_description": "Directed acyclic probabilistic graphical model used to represent conditional independencies among features; Danks shows GCM categories correspond to Bayes nets with a latent common-cause node (Figure 2 graph) and appropriate conditional distributions.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Bayesian Network (directed probabilistic graphical model)",
            "theory_type": "probabilistic graphical model (directed)",
            "theory_description": "Representational format where variables/features are nodes in a directed acyclic graph and the joint distribution factors as product of conditionals P(F_i | parents(F_i)); when interpreted causally, edges denote direct causal influences.",
            "functional_claims": "Provides compact representations of joint distributions via encoded independencies, supports inference about instance likelihoods P(X | Model) and causal/diagnostic reasoning when edges are causal.",
            "evidence_source": "theoretical mapping and computational/model-fitting equivalence proofs; empirical categorization experiments insofar as behavioral similarity patterns can be fit by Bayes-net-parameterized distributions",
            "experimental_paradigm": "used as a representational hypothesis in analyses of categorization/similarity data; relevant paradigms include categorization based on latent-cause structures and model comparison on behavioral datasets",
            "key_result": "Danks proves (sketches) that any GCM similarity pattern can be represented (up to scale) by a Bayes net with the Figure 2 latent-cause graph under weak regularity constraints, establishing formal equivalence between exemplar similarity functions and a subclass of Bayes nets.",
            "supports_theory": null,
            "counter_evidence": "Some probability distributions (and therefore some category similarity patterns) that are perfectly represented by Markov random fields cannot be perfectly represented by any Bayes net; directed asymmetries in Bayes nets differ from symmetric second-order prototype correlations.",
            "citation": "Danks (year not provided)",
            "uuid": "e7121.3"
        },
        {
            "name_short": "Markov RF",
            "name_full": "Markov Random Field (undirected probabilistic graphical model)",
            "brief_description": "Undirected graphical model where edges indicate symmetric probabilistic dependencies; Danks maps second-order prototype representations (feature conjunctions/correlations) to Markov random fields whose cliques correspond to those feature dependencies.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Markov Random Field (MRF)",
            "theory_type": "probabilistic graphical model (undirected)",
            "theory_description": "Represents joint distributions via undirected graphs and clique potentials: P(X) ∝ (1/Z) ∏ g_i(X_clique_i); edges denote symmetric dependencies without causal directionality, making MRFs suitable for capturing correlated/relational prototype features.",
            "functional_claims": "Captures symmetric inter-feature correlations (second-order features) in a principled probabilistic way, enabling similarity patterns corresponding to prototype models with feature conjunctions and supporting inference via clique potentials.",
            "evidence_source": "theoretical mapping and formal argumentation (equivalence results); used to reinterpret prototype-based similarity functions as probability distributions factorizable into clique potentials",
            "experimental_paradigm": "conceptual/theoretical mapping to behavioral similarity data; can be applied to categorization tasks where feature correlations matter",
            "key_result": "Danks shows second-order prototype similarity patterns correspond to probability distributions that have perfect-map representations as Markov random fields (edges correlate with second-order features), and that some MRF factorizations cannot be captured by Bayes nets.",
            "supports_theory": null,
            "counter_evidence": "Markov random fields cannot represent asymmetrical causal factorization that Bayes nets can; empirical fits will favor MRF-based prototype accounts only for categories whose structure includes symmetric feature correlations.",
            "citation": "Danks (year not provided)",
            "uuid": "e7121.4"
        },
        {
            "name_short": "P(X|Model) Unification",
            "name_full": "P(X | Model) computational unification hypothesis",
            "brief_description": "A unifying functional-level claim that categorization similarity ratings correspond (up to scale) to the probability of the observed feature pattern under some internal model: similarity(X, Category) ∝ P(X | Model), where Model is a probabilistic graphical model (Bayes net or MRF).",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Probabilistic Unification: similarity as P(X | Model)",
            "theory_type": "probabilistic distribution / computational-level representation",
            "theory_description": "Functional claim: the cognitive computation for similarity-based categorization is computing (a scaled version of) the likelihood of an item under a stored generative model (graphical model) of the category; different representational graph types (directed vs undirected, latent nodes, clique structure) correspond to exemplar, prototype, and causal theories.",
            "functional_claims": "Explains how apparently distinct categorization theories can be different parameterizations of a single computational operation (compute P(X|Model)), predicts when different models will be empirically indistinguishable (same P(X) patterns), and guides experimental design to dissociate representational forms.",
            "evidence_source": "theoretical derivations / formal equivalences and application to existing behavioral model-comparison results (e.g., Rehder 2003a analyses)",
            "experimental_paradigm": "analysis/model-comparison of categorization and similarity datasets; construction of category stimuli whose underlying P(X) factorizations differ so as to test representational format hypotheses (common-cause vs common-effect manipulations)",
            "key_result": "Danks demonstrates that GCM, second-order prototypes, and causal model similarity functions can all be expressed as computations proportional to P(X | Model) for different classes of graphical models (Bayes nets with latent cause, MRFs, causal Bayes nets), enabling analytical predictions about when differing theories will or will not be distinguishable experimentally.",
            "supports_theory": null,
            "counter_evidence": "Not empirical counterevidence per se, but the mapping requires certain regularity constraints for exact equivalence and some category structures (chain graphs) fall outside pure Bayes-net or pure MRF perfect-map representations, predicting systematic human errors not captured by simpler models.",
            "citation": "Danks (year not provided)",
            "uuid": "e7121.5"
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.01351625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Theory Unification and Graphical Models in Human Categorization</p>
<p>David Danks<br>Department of Philosophy, Carnegie Mellon University; and<br>Institute for Human \&amp; Machine Cognition</p>
<p>Contact information:
Department of Philosophy
135 Baker Hall
Carnegie Mellon University
Pittsburgh, PA 15213
ddanks@cmu.edu
(412) 268-8047 (phone)
(412) 268-1440 (fax)</p>
<h1>Introduction</h1>
<p>Disparate, mutually incompatible theories of categorization are widespread in cognitive psychology. While there are various formal results connecting pairs of these theories, the primary research focus has been on particular empirical tests of people's favorite theories. This chapter steps back from the question of which single theory (if any) is "right," and focuses instead on understanding the intertheoretic relationships among these models. Specifically, I will use the framework of probabilistic graphical models-a set of closely related computational and mathematical model-types-to provide a common lingua franca for a significant subset of the</p>
<p>extant psychological theories of categorization. This unified theoretical framework thus enables us to better understand the systematic relationships between the theories. In particular, we can gain a clearer picture of the overlaps and differences in the models' empirical predictions and underlying assumptions. Furthermore, expressing these psychological models in a common framework helps to identify several natural generalizations of currently proposed models, as well as currently underexplored alternative theories.</p>
<p>This graphical framework for representing various alternative models of categorization has a further, less obvious, benefit. Recent categorization research suggests that at least some categories are defined or described by an underlying causal structure (Ahn, Marsh, Luhmann, \&amp; Lee, 2002; Hadjichristidis, Sloman, Stevenson, \&amp; Over, 2004; Rehder, 2003a, 2003b, this volume; Rehder \&amp; Burnett, in press; Rehder \&amp; Hastie, 2004). Lien \&amp; Cheng (2000) found that people preferentially attend to one category from a set of possible categories, possibly quite a large set, based on which category optimizes causal learning and inference. Categorization thus seems to rely (sometimes) on causal reasoning. At the same time, all causal learning theories currently available-whether associationist or computational, normative or descriptive-assume that people are trying to learn causal relationships among a fixed set of well-defined variables; in other words, all current theories of causal learning assume some fixed categorization of the world. We also know that causal learning and prediction can suffer significantly if we do not have the appropriate (in a still unclear sense) categories (e.g., Spirtes \&amp; Scheines, 2004).</p>
<p>These results and observations all point toward a deep interdependence between (at least parts of) the cognitive abilities of causal learning, inference, and prediction on the one hand, and categorization and category generation/learning on the other hand. As a result, we should aim to find a common representational language for categorization and causation, so that clear questions</p>
<p>can be simultaneously asked about both. Given the growing evidence (much of it described elsewhere in this book) that Bayesian networks-one particular type of probabilistic graphical model-underlie parts of causal cognition, this chapter's framing of categorization theories in terms of probabilistic graphical models provides an important early step towards understanding the relationships between causation and categorization.</p>
<p>In the next section, I will introduce three different categorization theories, all of which have figured prominently in recent research. I then introduce two different types of probabilistic graphical models-Bayesian networks and Markov random fields-and describe how these categorization theories can be straightforwardly understood in terms of inference in particular instances of these model-types. These formal equivalencies have various implications, both theoretical and experimental. Some of the implications are clear and immediate, including simple explanations for various model-fitting results in the experimental literature. Other implications are more suggestive. In particular, the mathematical equivalencies described in earlier sections suggest several substantive categorization theories that are, to my knowledge, novel to the psychological community (though not within machine learning). In the final substantive section, I will focus on one particular model and (programmatically) describe how it could account for a range of intriguing phenomena in various domains.</p>
<h1>Three Similarity Functions</h1>
<p>The general problem of categorization is to classify an object as belonging to a particular group. This classification can then be used for many different purposes, including inference of unobserved properties of this individual based on common properties within the group. For example, when hiking, I frequently (and quickly!) classify poorly-seen animals in terms of their</p>
<p>species. To make this judgment, I must attend to particular features and properties in the world, some of which I consciously attend to, others which I do not. In addition, my classification will depend (in part) on the other possibilities I consider. The same critter that I classify as a "pika" in Colorado might be classified as a "squirrel" in Pennsylvania (since I know that there are no pikas in Pennsylvania). Once I have classified the animal, I then decide whether to be concerned about the animal or not based on what I know about that species (e.g., a mountain lion or a squirrel, respectively). This latter task is typically referred to as feature inference or property induction: determining the likelihood that some novel instance of this category will have a particular property. In this section, I describe three different psychological theories that aim to model the cognitive representations and algorithms underlying this process.</p>
<p>Although there are some exceptions, most psychological models of categorization separate categorization into two stages. For a novel instance $X$ and some set of possible categories, I first determine how representative $X$ is of each potential category. These "similarity ratings" are then integrated in a second step to produce a behavioral response, such as my categorization of this critter as a "squirrel." In experimental settings, the relevant possible categories for a particular novel instance are invariably dictated by the cover story; in the realworld, the possible categories are selected on some poorly-understood bases, such as pragmatics or prior knowledge. Most psychological research has focused on the similarity rating function(s); relatively little empirical work has been done on the second stage integration of similarity ratings (though see Wills, Reimers, Stewart, Suret, \&amp; McLaren, 2000).</p>
<p>More formally, suppose that we represent individuals in terms of $n$ (binary or continuous ${ }^{1}$ ) features, denoted by $F_{1}, \ldots, F_{n}$. These features are presumably selected by some process outside of the categorization theory itself. Throughout this chapter, I will make the</p>
<p>standard assumption for categorization theories that these features are well-defined and wellspecified. Similarity ratings for a particular category are thus just functions on these $n$ features. The standard second-stage integration rule for the similarity ratings is the Shepard-Luce rule (Shepard, 1957; Luce, 1963): if $S_{C}(X)$ denotes the similarity of $X$ to category $C$ and $Q$ indexes over all of the potential categories, then $P\left(\right.$ Respond " $\left.C^{\prime \prime}\right|X)=S_{C}(X) / \Sigma S_{Q}(X)$. That is, the probability of classifying $X$ as a $C$ is given by $X$ 's similarity to $C$, divided by the sum of $X$ 's similarity to every possible category (including $C$ ). Bias parameters are occasionally used (Logan, 2004), as well as other rules with significant formal connections to the Shepard-Luce rule (Ashby \&amp; Maddox, 2003).</p>
<p>In this section, I will focus on the similarity functions for standard versions of exemplar (e.g., Kruschke, 1992; Lamberts, 1998, 2000; Nosofsky, 1986; Nosofsky \&amp; Palmeri, 1997; Zaki, Nosofsky, Stanton, \&amp; Cohen, 2003; Logan, 2004 provides a good overview of recent work), prototype (e.g., Minda \&amp; Smith, 2001; Smith \&amp; Minda, 1998), and causal model (e.g., Rehder, 2003a, 2003b) theories of categorization. Substantial empirical support has been found for all three types of model, depending on the particular category, cover story, and task. And while these three similarity functions do not exhaust the space of proposed theories, they underlie the most widely discussed theories. In particular, this analysis includes Nosofsky's (1986) Generalized Context Model (GCM; described below), which is the almost universal standard against which new psychological theories are judged. Rule-based categorization theories (including Nosofsky, Palmeri, \&amp; McKinley's, 1994 RULEX model) are indirectly covered by this section, since single-feature rules are equivalent to exemplar/prototype models in which we attend to only one feature. More direct analysis of rule-based models is rarely possible, since simulations are almost always required to generate predictions for any realistic situations. Note</p>
<p>that dynamic measures of categorization, including category learning dynamics and response time predictions, will not be considered here. ${ }^{\text {ii }}$</p>
<p>The Generalized Context Model (GCM; Nosofsky, 1986) provides the basis exemplar similarity function for numerous other categorization theories (e.g., Erickson \&amp; Kruschke, 1998; Kruschke, 1992; Lamberts, 1998, 2000; Nosofsky \&amp; Palmeri, 1997). The core intuition behind the GCM is that the similarity or typicality of some novel instance $X$ for category $A$ is given by the average distance in the "category space" between $X$ and some subset of previously observed category instances (the exemplars). In other words, I represent a category in terms of exemplars (previous instances known to be in the category). A new object is similar just to the extent that it is "close" to the previous observations. For example, my category of "bird" is defined by remembered previous instances of birds (e.g., a robin, an ostrich, and so on). My category of "squirrel" is defined by previously observed squirrels. And some new critter is classified as a bird rather than a squirrel just when its average distance to the bird exemplars is less than its average distance to the squirrel exemplars (and those are the only two possibilities considered).</p>
<p>Mathematically, we define a GCM (i.e., exemplar-based) category $A$ by a set of exemplars $E_{1}, \ldots, E_{m}$, each of which is a full specification of values for the $n$ relevant features. Let $Y(i)$ denote $Y$ 's value for the $i$-th feature. The similarity between novel instance $X$ and a particular exemplar $E_{j}$ is then given by $\operatorname{Sim}\left(X, E_{j}\right)=\prod_{i=1}^{c} \exp \left[-c \times \alpha_{i} \mid X(i)-E_{j}(i)\right]$, where $\alpha_{i}$ is a salience parameter for the $i$-th feature, and $c$ is a global weighting parameter. ${ }^{\text {iii }}$ That is, the similarity is the product of (the exponential of) the distances between $X$ and $E_{j}$ on each of the feature dimensions. Note that, if the features are all binary-valued, then the similarity is just the product of $\exp \left[-c \times \alpha_{i}\right]$ for each feature $F_{i}$ on which $X$ and $E_{j}$ differ. The overall similarity rating of novel instance $X$ for category $A$ in the GCM-that is, the output of the first stage of the</p>
<p>categorization model—is the weighted sum of similarities for all category exemplars: $\operatorname{GCM}(X, A)=\sum_{j=1}^{m} W_{j} \operatorname{Sim}\left(X, E_{j}\right)$. The similarity ratings for each GCM-category (e.g., $\operatorname{GCM}(X$, $A), \operatorname{GCM}(X, B)$, and so on) are then combined using the Shepard-Luce rule to generate behavioral responses. In addition, the set of exemplars (i.e., the category definition) can straightforwardly be used for inference about unobserved features of objects placed into the same category: e.g., "this is a squirrel, and most of my squirrel exemplars were not aggressive, therefore this squirrel probably won't be aggressive."</p>
<p>Prototype-based theories offer a different picture of categorization from exemplar-based models. Instead of basing the category on a set of previously remembered instances, categories are defined by prototypes-single objects-that encode a summary or average of people's experiences with the category; these prototypes need not correspond to any actual category instance (and almost never will). A novel instance's similarity to the category then depends on its distance in "category space" to that single prototype. The prototypical bird, for example, is not any bird that has ever been observed, though various actual birds (e.g., robins) are closer to it than others (e.g., ostriches). Mathematically, the prototype model (e.g., Minda \&amp; Smith, 2001; Smith \&amp; Minda, 1998; see also versions in Johansen \&amp; Palmeri, 2002; Olsson, Wennerholm, \&amp; Lyxzèn, 2004) is almost always a GCM model with only one exemplar for the category, but where the exemplar might not have been observed. ${ }^{\text {iv }}$ However, this standard, simple prototype model fails to do justice to the intuition behind prototype models. Information about inter-feature connections or correlations is an important part of any summary of a series of observations, and this information cannot be expressed in the description of a single instance. The standard prototype similarity function requires some augmentation to capture the underlying intuition.</p>
<p>A simple way to incorporate inter-feature correlations is with second-order features: features whose value is entirely determined by the values of two first-order features. (Secondorder features are only one way to capture correlations; a more powerful option is discussed later.) For example, it might be important that both $F_{2}$ and $F_{17}$ occur, perhaps because an observed correlation. In that case, we could define a second-order feature that "occurs" if and only if $F_{2}$ and $F_{17}$ both occur. Second-order features consisting of logical AND functions are quite common (e.g., Rehder, 2003a, 2003b), but are certainly not the only kind of second-order feature that could be introduced; Danks (under review) gives a general, mathematical definition of (plausible) second-order features. If we allow second-order features into a category prototype, then we have to adjust the first-order feature prototype similarity function (which was just the GCM similarity function). For simplicity, I will use $d(i, j)$ to denote the distance between (instance) $X$ and (prototype) $E$ along the feature composed of $F_{i}$ and $F_{j}$ (if $i=j$, this is the appropriate first-order feature). Let $\alpha_{i i}$ be the salience of first-order feature $F_{i}$, and $\alpha_{i j}$ be the salience of the second-order feature composed of $F_{i}$ and $F_{j} .\left(\alpha_{i j}=0\right.$ implies no second-order feature for $F_{i}$ and $F_{j}$.) Given this notation, the second-order prototype (SOP) category similarity function is: $\operatorname{SOP}(X, A)=\prod_{i=1}^{n} \prod_{j=i}^{n} \exp \left[-c \times \alpha_{i j} d(i, j)\right]$. That is, the similarity between some instance $X$ and category $A$ is the product of (the exponentials of) the distances between $X$ and $A$ for each feature, including second-order ones. Once $X$ is categorized into a particular prototypebased category, feature inference is based entirely on the summary statistics encoded in the prototype itself. If the value of "Flies" is 0.95 for the prototypical bird (i.e., $95 \%$ of birds summarized in the prototype could fly), then the probability that this bird flies is 0.95 .</p>
<p>The third psychological theory of categorization is causal model theory (Rehder, 2003a, 2003b, this volume). Causal model theory defines a category in terms of a particular causal</p>
<p>structure among the features, including possibly unobserved features (e.g., an animal's "essence"). The underlying intuition about similarity is that a particular instance is more likely to be a member of category $A$ just when its observed features respect the causal relationships among the various features. Thus, the similarity function for a category in causal model theory is the probability that a particular novel instance would be generated by that category's causal structure (perhaps multiplied by some scaling factor). For example, a particular object is similar to "bird" when the combination of observed features would likely be produced by something with the causal structure underlying the category of "bird." Obviously, the mathematical details of causal model theory depend heavily on the particular representation of causal structures. Current versions of the theory model these structures using causal Bayesian networks (or causal Bayes nets). Details about causal Bayes nets are provided in the next section. For now, the relevant feature of a causal Bayes net is that it can be used to determine the probability of any particular combination of feature values given some causal structure; the causal model theory (CMT) similarity function is directly proportional to that probability. That is, $\operatorname{CMT}(X, A)$ is proportional to $P(X \mid M)$, where $M$ is the causal Bayes net for the category. Given a particular categorization, the causal structure can straightforwardly be used for feature inference (Ahn, et al., 2002; Hadjichristidis, et al., 2004; Rehder \&amp; Burnett, in press; Rehder \&amp; Hastie, 2004).</p>
<p>In this section, I have left out several different types of categorization theories; perhaps most notably, I excluded connectionist models (e.g., Gluck \&amp; Bower, 1988; McClelland \&amp; Rogers, 2003; Rogers \&amp; McClelland, 2004). There is reason for their exclusion. Connectionist models have the ability to model or approximate large classes of input-output functions. However, to determine the exact space of similarity ratings that can be modeled by a particular network, we must perform significant simulations, except in specific networks that can model all</p>
<p>possible input-output relationships. Without analytic results about the input-output relationships that can be modeled by a particular neural network structure, there is no definite target for expression in the framework of probabilistic graphical models. Moreover, it is notoriously difficult to determine what representations are contained in a connectionist model, since much depends on the particular connection weights that emerge from a learning history. As a result, process equivalencies that directly map the symbolic operations of the connectionist model onto a graphical model are also not forthcoming.</p>
<h1>Probabilistic Graphical Models</h1>
<p>The central theoretical claim of this chapter is that the similarity functions from the previous section can be usefully and interestingly described in the framework of probabilistic graphical models. In this section, I outline two types of graphical models-Bayesian networks and Markov random fields-and then describe how various similarity functions are proportional to calculating $P(X \mid$ Model $)$, where Model is one of these probabilistic graphical models. That is, the various psychological theories make different predictions because they assume different graphical model types: a subclass of Bayesian networks for exemplar-based theories (the GCM), causal Bayesian networks for causal model theory, and a subclass of Markov random fields for prototype-based theories. Thus, these diverse theories can be viewed (from a mathematical point-of-view) as different parameterizations of a single unified theory. These mathematical observations raise a range of psychological implications and questions; I take up those issues in the subsequent two sections. Due to space constraints, I have omitted the full proofs and technical details about the various equivalencies; the relevant mathematical specifics can all be found in Danks (2004, under review).</p>
<p>In general, probabilistic graphical models provide a compact representation of a probability distribution by encoding various facts about independence and association in some type of graph. Strevens (this volume) explores the importance of (usefully) compact representations of probability and statistical facts. Bayes nets are one of the most popular probabilistic graphical models for such purposes; I here provide a very brief introduction to the framework. (Neapolitan, 2003; Pearl, 2000; Spirtes, Glymour, \&amp; Scheines, 1993; and other chapters in this volume all provide more comprehensive introductions to Bayes nets.) It is important to realize that, despite the name, there is nothing intrinsically Bayesian about a Bayes net; the name is due to the original uses of the framework. One can be, but need not be, a Bayesian about Bayes nets.</p>
<p>A Bayes net is defined relative to a set of variables; in our current setting, these are the observed features. One half of a Bayes net is a directed acyclic graph containing one node per variable/feature (see Figure 1). These nodes are (possibly) connected by directed edges (e.g., $F_{i}$ $\rightarrow F_{j}$ ), indicating an asymmetric relationship. In "simple" Bayes nets, the asymmetric relationship is purely probabilistic. In contrast, a causal Bayes net (used by causal model theory, as well as multiple psychological theories of causal reasoning) is a Bayes net in which the edges in the graph are provided a causal interpretation. If the causal interpretation is justified by background knowledge, then $X \rightarrow Y$ indicates that $X$ is a direct cause of $Y$, where no particularly substantive theory of causation is presupposed (see Woodward, 2003, for one possibility). We use family terminology (e.g., 'parent' or 'child') to describe the graphical relationships. The 'acyclicity' property of the graph means that there is no (non-trivial) arrow-following path from a variable back to itself (e.g., there cannot be a path like $F_{1} \rightarrow F_{3} \rightarrow F_{17} \rightarrow F_{1}$ in the graph).</p>
<p>The other half of a Bayes net is a joint probability distribution (or density, for continuous variables) that specifies the probability of any particular set of feature values. When the causal interpretation is justified, the joint probability distribution encodes information about the quantitative causal dependencies among the variables. The two Bayes net components-the directed acyclic graph and the joint probability distribution-are connected by a Markov assumption: every variable is probabilistically independent of its non-descendants conditional on its graphical parents. This assumption implies that the joint probability distribution (density) factors as $P(X)=\prod_{i=1}^{n} P\left(F_{i} \mid p a\left(F_{i}\right)\right)$, where $p a\left(F_{i}\right)$ denotes the graphical parents of $F_{i}$. The components are also connected by the Faithfulness assumption: the only probabilistic independencies are those predicted by the Markov assumption. The primary effect of the Faithfulness assumption is to exclude the possibility of multiple pathways whose effects exactly cancel out (e.g., $X \rightarrow Y \rightarrow Z$ and $X \rightarrow Z$, but $X$ and $Z$ are unconditionally independent). Faithfulness is assumed (either explicitly or implicitly) by essentially every Bayes net learning algorithm. An example of a Bayes net is provided in Figure 1.
[Insert Figure 1 about here]
The causal model similarity function is already expressed using causal Bayes nets: the causal structure defining category $A$ must be a causal Bayes net, and the similarity of $X$ to $A$ is given by the probability of $X$ in the joint probability distribution represented by the causal Bayes net. That is, the similarity rating of $X$ for category $A$ is equal to $P(X)$, where the probability distribution is represented by a causal Bayes net. ${ }^{\mathrm{v}}$ Thus, this categorization theory can easily be represented in terms of inference for probabilistic graphical models.</p>
<p>Perhaps more surprisingly, Bayes nets can also be used to express the exemplar-based GCM similarity function. In general, the similarity functions used in these two-stage</p>
<p>categorization theories are defined for all possible instances. Therefore, the pattern of those ratings for a particular category is proportional to some probability distribution over those same possible instances. So for example, if we have some exemplar-based (i.e., GCM) category $A$ with its corresponding similarity function, $G C M(X, A)$, then there is necessarily some probability distribution $P(X)$ such that $G C M(X, A) \propto P(X)$, for all instances $X$ (i.e., there is some constant $K$ such that $G C M(X, A)=K \times P(X)$ for all $\left.X\right)$. Hence, to establish an equivalence between the GCM and some probabilistic graphical model, it suffices to show that, for every probability distribution proportional to a possible set of ratings for a GCM category, there is a perfect map in some class of probabilistic graphical models, and vice versa. A graphical model provides a perfect map of a probability distribution if and only if the graph implies (by Markov and Faithfulness) all and only the probabilistic independencies that occur in that distribution. In general, the (high-level) strategy for expressing categorization theories in terms of probabilistic graphical models is: determine the patterns that could possibly be produced by (normalized) similarity functions, and then find a set of probabilistic graphical models that perfectly represent exactly those patterns.</p>
<p>In the case of the exemplar-based GCM, consider a Bayes net with the directed acyclic graph in Figure 2. $E$ is an unobserved variable whose number of values depends on the category being modeled. By the Markov assumption, the joint probability distribution for this Bayes net factors into $P\left(E, F_{1}, \ldots, F_{n}\right)=P(E) \times P\left(F_{1} \mid E\right) \times \ldots \times P\left(F_{n} \mid E\right)$. The structure of this model is similar to the oft-used naïve Bayes models of machine learning classification problems, though the role and interpretation of the (unobserved) common cause is different in this situation.
[Insert Figure 2 about here]
Regardless of whether the features are binary (e.g., either present or absent) or continuous (e.g., height), every GCM category is proportional to a probability distribution over the $F_{i}$ 's that</p>
<p>has a perfect map given by a Bayes net ${ }^{\text {vi }}$ with this graph. That is, for every GCM category, there is a Bayes net with Figure 2 graph and associated probability distribution such that $G C M(X, A) \propto$ $P(X)$ for every possible instance $X$ over features $F_{1}, \ldots, F_{n}$. The converse of this claim holds with a slight addition: for every probability distribution over the observed $F_{i}$ 's for a Bayes net with Figure 2 graph and a "regularity" constraint on the form of the $P\left(F_{i} \mid E\right)$ terms, there is a GCM category whose ratings are proportional to that distribution. The exact regularity constraint depends on whether the features are binary or continuous, but neither constraint is particularly strong. ${ }^{\text {vii }}$ Since similarity ratings are determined only up to a choice of scale, we can conclude that GCM categories and Bayes nets with a Figure 2 graph (plus regularity constraint) describe exactly the same set of similarity ratings; any responses that can be fit to one model can be fit to the other.</p>
<p>In contrast, there is no corresponding equivalence between Bayes nets and prototypebased categorization models with second-order features. These two types of models are fundamentally different, in that the inter-variable connections in a Bayes net are asymmetric (whether in a probabilistic or causal sense), while the second-order features are symmetric. Hence, we need a probabilistic graphical model with undirected edges between the features to indicate symmetric connections. This model-type is called a Markov random field (see, e.g., Darroch, Lauritzen, \&amp; Speed, 1980; Lauritzen, 1996 for more technical introductions). As with Bayes nets, Markov random fields are defined only relative to a set of variables (features), and are composed of a joint probability distribution (density) and a graph. In contrast with a Bayes net, though, a Markov random field graph contains undirected edges between the nodes (see Figure 3). Roughly speaking, two features being connected by an edge in the graph implies that</p>
<p>there is a probabilistic dependence between those features' values, but no explanation of the correlation is given or presumed (and so there is no asymmetry between the variables).</p>
<p>The graph and probability distribution in the Markov random field are connected by a Markov assumption: the probability of any feature value is dependent only on its graphical neighbors. So for example, in Figure 3, $P(A)$ depends only on $B$ and $C ; A$ is probabilistically independent of $D$ and $E$, conditional on $B$ and $C$. The Markov assumption implies that the joint probability distribution can be factored into the product of functions (called clique potentials) over the maximal cliques in the undirected graph. A graphical clique is any set of nodes for which every pair is connected by an edge, and a clique is maximal if adding any other variable renders it no longer a clique. Thus, the Markov assumption for a Markov random field $G$ implies that, if the maximal cliques in $G$ are denoted by $C_{1}, \ldots, C_{q}$, we can express the probability of some novel instance $X$ as $P(X \mid G)=\frac{1}{Z} \prod_{i=1}^{q} g_{i}(X)$, where $g_{i}(X)$ depends only on the values of variables in $C_{i}$ (and $Z$ is a normalization constant). Figure 3 provides an example of a Markov random field, including both the graph and the factorization of the joint probability distribution into clique potentials.
[Insert Figure 3 about here]
As with Bayes nets and exemplar-based models, we can successfully apply the same high-level strategy to connect Markov random fields and prototype-based models. The patterns of ratings produced by prototype-based similarity functions can be understood as probability distributions, and we can represent that space of probability distributions in terms of Markov random fields. More specifically, for a particular (second-order feature) prototype-based category, its Markov random field counterpart contains an edge between two nodes (features) just when there is a second-order feature for those two. Then, for every possible pattern of</p>
<p>similarity ratings, there is a corresponding (proportional) probability distribution that has a perfect map given by the category's Markov random field counterpart. And for every probability distribution with a Markov random field perfect map (whose clique potentials satisfy a further, relatively weak, regularity constraint), there is a corresponding prototype-based category whose similarity ratings are proportional to the distribution. Just as GCM-categories are equivalent to (probability distributions with perfect maps given by) Bayes nets with Figure 2 graph, (secondorder) prototype-based categories are equivalent to (the probability distributions for) a subset of Markov random fields.</p>
<p>In summary, all three types of similarity functions (GCM, second-order prototype, and causal model) can be expressed (up to a scaling parameter) as computations of $P(X \mid$ Model $)$, where the differential theory predictions arise from different assumptions about the underlying graphical model. The precise psychological model $\leftrightarrow$ graphical model relationships are:</p>
<p>GCM rating for $X \leftrightarrow P(X \mid$ Bayes net with Figure 2 graph and constraint)
Second-order prototype rating for $X \leftrightarrow P(X \mid$ Markov random fields with a constraint)
Causal model rating for $X \leftrightarrow P(X \mid$ Causal Bayes net $)$
The representation of category similarity functions as probability distributions has been previously explored by Myung (1994), Ashby \&amp; Alfonso-Reese (1995), and Rosseel (2002). In contrast to that work, the results detailed here use the framework of probabilistic graphical models, which allow us to extend the formal results to a broader class of prototype theories, as well as to include causal model theory. In related research, Nosofsky (1990) and Ashby \&amp; Maddox (1993) pursued a more direct strategy and found conditions in which exemplar models could be directly transformed into prototype models and vice versa without the framework of probability theory or graphical models (see also Barsalou, 1990). While important for</p>
<p>understanding those two theory-types, though, the direct results are not readily extensible to other psychological theories (e.g., causal model theory) because they do not situate the theories in a more general framework.</p>
<p>With these equivalencies in hand, I now turn to their implications. The next two sections demonstrate several pragmatic uses of the representation of these models as probabilistic graphical models, including better understanding of existing experimental results, suggestions of novel experiments, and more speculatively, the possibility of interesting generalizations of existing psychological theories.</p>
<h1>Applying the Graphical Model Equivalencies</h1>
<p>The most obvious application of these equivalencies is to facilitate rapid determination of the conditions in which the categorization theories make differential predictions, thus enabling us to both explain previous experimental results, and construct appropriate novel experiments. In particular, if the two probabilistic graphical model-types can perfectly represent different probability distributions and people's behavioral responses approximate the observed probability distribution for some category, then we can determine analytically whether some experiment is likely able to discriminate between the second-order prototype (=Markov random field) and causal model (=causal Bayes net) theories. In fact, the expressive potentials of Bayes nets and Markov random fields are appropriately overlapping. That is, there are probability distributions that can be represented perfectly by a Markov random field but not a Bayes net, and vice versa. There are also probability distributions (e.g., those equivalent to first-order prototype-based similarity functions) that can be represented perfectly by both Bayes nets and Markov random fields, as well as some that cannot be represented perfectly by models from either framework.</p>
<p>As a concrete example, there is no Bayes net that perfectly represents a probability distribution with the (Markov random field) factorization given in Figure 3. Thus, if Figure 3 describes the actual underlying category structure (i.e., the probability that any novel instance comes from that category), then a causal-model-based categorizer would not be able to perfectly learn the category structure. Similarly, there is no Markov random field that perfectly represents a probability distribution with the (Bayes net) factorization in Figure 1, and so a categorizer using second-order prototype-based categories would not be able to accurately learn that category. Finally, a simple category structure consisting of uncorrelated features can be equally well-represented by models from both frameworks, and so no experiment based on such categories will be able to distinguish between causal model and second-order prototype-based categorization (i.e., the psychological theories should have equally good model fits).</p>
<p>We can also apply this analysis to published-not just hypothetical-experiments. Rehder (2003a)'s common-cause condition uses a category probability distribution that can be equally well-represented by a Bayes net (= causal model) and a Markov random field (= secondorder prototype). As predicted, he found no model fit difference between the corresponding psychological theories (see Table 5, p. 729). In contrast, Rehder (2003a)'s common-effect condition used a probability distribution that can be represented by Bayes nets but not Markov random fields. Thus, the two psychological theories should be distinguishable by that experiment: second-order prototype categorizers will do poorly, and causal-model categorizers should do well. Alternately, if we assume that people can learn a wide range of category structures, then we should expect the second-order prototype theory to have a significantly worse model fit than the causal model theory. The subsequent data analysis found exactly that significant model-fit difference in favor of causal model theory, which can represent the</p>
<p>underlying probability distribution (see Table 5, p. 729). (See also Experiment 3 in Rehder, this volume, for further evidence of an asymmetry between common cause and common effect networks.)</p>
<p>Finally, we can use this analysis to design experiments to push the outer boundaries of human category learning. As noted previously, there are probability distributions, and so categories, that none of the psychological theories can completely model. Correct theoretical predictions of cognitive failures (in this case, failure to correctly represent the category) are typically thought to constitute stronger evidence for a theory than predictions that people will behave close-to-optimally. Thus, a natural way to separate these three theory-types is to present individuals with categories whose structure cannot be mapped onto any of these representations without loss of information. In particular, we want to find categories for which each theory picks out different aspects of the structure, and so they predict different patterns of failure. Chain graphs are probabilistic graphical models that use both directed and undirected edges (further discussed below), and there are perfect map chain graphs for probability distributions with no Markov random field or Bayes net perfect map. One such graph is: $F_{1} \rightarrow F_{2}-F_{3} \leftarrow F_{4}$. ${ }^{\text {viii }}$ All three psychological theories predict that people will make significant, systematic, predictable errors when presented with a category with this structure, and those errors are predictable using the probabilistic graphical model equivalencies described here. The differential error predictions can then be used to better determine which theory best describes an individual's categorization process. To my knowledge, no such experiment appears in the literature.</p>
<p>In additional to methodological implications, these equivalencies suggest natural generalizations of existing psychological theories. The exemplar-based and second-order prototype-based similarity functions are equivalent with only subclasses of Bayes nets with</p>
<p>Figure 2 graphs and Markov random fields, respectively. In both cases, the equivalent graphical models have constraints on the probability distribution beyond those implied by the graphical model. From the probabilistic graphical model point-of-view, these additional constraints seem arbitrary, though they have a natural justification in terms of ensuring computational tractability. Setting aside computational issues, though, we might naturally consider generalizing the GCM to include patterns of similarity ratings that are proportional to any probability distribution with a perfect map Bayes net with Figure 2 graph. This generalization has a straightforward interpretation within the GCM framework: it corresponds to allowing exemplar-dependent feature saliences in the similarity function. Similarly, we can generalize the second-order prototype model to include any probability distribution with an arbitrary Markov random field perfect map. This generalization would significantly extend the scope of that theory, while retaining the basic intuition of prototype theories that the category representation is a summary of the observed category instances. Importantly, both of these generalizations remain bounded in explanatory power; there are experiments and patterns of similarity ratings, such as Rehder (2003a)'s common-effect condition, that can distinguish these generalizations from one another.</p>
<p>Finally, these equivalencies suggest alternate responses to two existing problems for categorization theories: empirical support for (seemingly) inconsistent theories, and (apparent) shifts in category structure during learning. The first problem is that there is significant empirical evidence supporting all three of these psychological similarity ratings, depending on the particular domain, presentation format, contrast class, and so on. One response to this fact has been to argue that there are distinct cognitive systems for different categorization strategies (e.g., exemplar vs. rule-based), and that contextual factors and background knowledge determine which system is activated. This idea is supported by evidence from reaction time (Allen \&amp;</p>
<p>Brooks, 1991) and neuroimaging (Grossman, Smith, Koenig, Glosser, DeVita, Moore, \&amp; McMillan, 2002; Patalano, Smith, Jonides, \&amp; Koeppe, 2001; Smith, Patalano, \&amp; Jonides, 1998) studies (see also Machery, in press). In a similar vein, Ashby and his colleagues have argued that different neural systems underlie implicit and explicit category learning, which are distinguished by whether participants can give a simple, verbal rule to differentiate the categories (Ashby, Alfonso-Reese, Turken, \&amp; Waldron, 1998; Ashby \&amp; Waldron, 2000; Waldron \&amp; Ashby, 2001). These proposals all share the underlying idea that there are multiple processing systems in the brain responsible for the different types of categories.</p>
<p>The equivalencies described here suggest a different response to the range of empirical supports: the differential behaviors (perhaps) arise from differing parameterizations of a common categorization algorithm. That is, these distinct psychological theories might correspond to the same operation applied to three different representations (i.e., types of graphs), rather than distinct cognitive mechanisms. There might be only one process in which similarity ratings are based on $P(X \mid$ Model $)$, but where the particular category model-type depends on factors such as experiential history, context, other background knowledge, and so on. Differential behavior arises from different inputs to the same process, rather than fundamentally different processes. If the cognitive representation of the category structure is a Bayes net with Figure 2 graph, the person will exhibit GCM category behavior. If the representation is a suitable Markov random field or causal Bayes net, categorizations will be best understood using second-order prototype or causal model theory, respectively. Of course, this suggestion is not intended to demonstrate that there cannot possibly be multiple processes; rather, it is intended to defeat the (too quick) inference from "support for multiple theories" to "multiple cognitive processes must exist."</p>            </div>
        </div>

    </div>
</body>
</html>