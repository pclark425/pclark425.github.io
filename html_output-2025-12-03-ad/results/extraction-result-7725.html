<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7725 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7725</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7725</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-144.html">extraction-schema-144</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-277856996</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.12976v1.pdf" target="_blank">Sparks of Science: Hypothesis Generation Using Structured Paper Data</a></p>
                <p><strong>Paper Abstract:</strong> Generating novel and creative scientific hypotheses is a cornerstone in achieving Artificial General Intelligence. Large language and reasoning models have the potential to aid in the systematic creation, selection, and validation of scientifically informed hypotheses. However, current foundation models often struggle to produce scientific ideas that are both novel and feasible. One reason is the lack of a dedicated dataset that frames Scientific Hypothesis Generation (SHG) as a Natural Language Generation (NLG) task. In this paper, we introduce HypoGen, the first dataset of approximately 5500 structured problem-hypothesis pairs extracted from top-tier computer science conferences structured with a Bit-Flip-Spark schema, where the Bit is the conventional assumption, the Spark is the key insight or conceptual leap, and the Flip is the resulting counterproposal. HypoGen uniquely integrates an explicit Chain-of-Reasoning component that reflects the intellectual process from Bit to Flip. We demonstrate that framing hypothesis generation as conditional language modelling, with the model fine-tuned on Bit-Flip-Spark and the Chain-of-Reasoning (and where, at inference, we only provide the Bit), leads to improvements in the overall quality of the hypotheses. Our evaluation employs automated metrics and LLM judge rankings for overall quality assessment. We show that by fine-tuning on our HypoGen dataset we improve the novelty, feasibility, and overall quality of the generated hypotheses. The HypoGen dataset is publicly available at huggingface.co/datasets/UniverseTBD/hypogen-dr1.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7725.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7725.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HypoGen</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HypoGen dataset and fine-tuning pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A curated dataset (~5.5k samples) of structured problem→hypothesis pairs (Bit-Flip-Spark + Chain-of-Reasoning) extracted from top-tier CS papers and used to fine-tune LLaMA-style LLMs to generate hypotheses conditioned on a problem statement (Bit). The pipeline uses an LLM to extract structured elements from abstracts/full text, fine-tunes causal LM models, and evaluates generated hypotheses with LLM judges and humans.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Sparks of Science: Hypothesis Generation Using Structured Paper Data</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Charles O'neill et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2025</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>HypoGen (Bit-Flip-Spark + Chain-of-Reasoning fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use an LLM (OpenAI o1) to extract a structured hypothesis schema (Bit, Spark, Flip, Chain-of-Reasoning) from paper abstracts and full text to produce a training corpus; fine-tune LLaMA-family causal language models (with LoRA, 4-bit quantization) on this dataset so that at inference the model receives only a Bit and generates a Spark plus detailed Chain-of-Reasoning as a hypothesis.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Abstracts and available full-text papers (NeurIPS 2023, ICLR 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Textual structured hypotheses (Spark + Flip + Chain-of-Reasoning) conditioned on a Bit</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Structured extraction prompts for Bit/Flip/Spark, chain-of-reasoning style prompts for full-text extraction; causal LM fine-tuning; one-shot / few-shot inference baselines for comparison</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI o1 (extraction), Meta LLaMA 3.1-8B and R1-distilled LLaMA 3.1-8B (fine-tuning), Claude 3.7 Sonnet and o3-mini (LLM judges)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B parameters (LLaMA 3.1-8B variants); extraction/judge models unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>HypoGen: ~5478 samples compiled from NeurIPS 2023 (3218 papers) and ICLR 2024 (2260 papers); held-out test of 50 recent hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Perplexity, IAScore (Idea Alignment Score), Idea Distinctiveness Index, pairwise LLM-judge novelty/feasibility/overall preference, small-scale human evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Fine-tuning on HypoGen increased IAScore substantially and produced hypotheses judged more feasible and higher overall quality than one-shot variants (86–92% preference vs one-shot), while reducing novelty/diversity; human hypotheses still preferred overall in most comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on LLMs for both extraction and evaluation which can introduce hallucination and bias; structured schema is subjective; domain generalization beyond CS remains untested; trade-off observed between alignment/feasibility and semantic distinctiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7725.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bit-Flip-Spark+CoR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bit-Flip-Spark plus Chain-of-Reasoning schema</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A structured hypothesis representation combining a conventional assumption (Bit), a concise core insight (Spark), a counterproposal (Flip), and an explicit first-person Chain-of-Reasoning that narrates the abductive path from Bit to Flip. Designed to make LLM-generated hypotheses more interpretable and reproducible.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Sparks of Science: Hypothesis Generation Using Structured Paper Data</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Charles O'neill et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2025</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Bit-Flip-Spark + Chain-of-Reasoning schema</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Represent scientific contributions as a four-part structured object (Bit, Spark, Flip, Chain-of-Reasoning); use LLM prompts to extract these elements from paper text and train a causal LM to conditionally generate Sparks and Chains-of-Reasoning given a Bit, improving transparency of ideation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Paper abstracts (Bit/Flip/Spark extraction) and full text (Chain-of-Reasoning extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured textual schema containing Bit, Spark, Flip, and a first-person Chain-of-Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Specialized structured prompts for extraction; chain-of-thought/first-person style chain-of-reasoning reconstruction; conditional fine-tuning so only Bit is required at inference</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI o1 (extraction), LLaMA-family fine-tuned models (generation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>o1 and judge model sizes unspecified; LLaMA variants 8B</td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Compiled from NeurIPS 2023 and ICLR 2024 papers within the HypoGen dataset</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Downstream improvements in IAScore, judge preference, perplexity and Idea Distinctiveness Index reported in paper</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Using the schema for supervision improved alignment (IAScore) and produced more feasible, higher-quality hypotheses after fine-tuning, at the cost of some semantic distinctiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Schema is interpretive and subjective; extraction depends on upstream LLM quality and may propagate extraction errors; may bias models toward producing more conventional (less novel) outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7725.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HypoGeniC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HypoGeniC (iterative RLHF hypothesis generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior system that expands iterative proposal/evaluation loops by applying reinforcement learning with human feedback to refine hypothesis generation produced by LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Zhou et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>HypoGeniC (iterative RLHF)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Iteratively generate candidate hypotheses with an LLM and refine selection/policies using reinforcement learning informed by human feedback, effectively looping proposal and evaluation to improve generated hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Textual problem statements and candidate hypotheses (iterative proposals)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Refined hypotheses and candidate idea rankings</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Iterative generation+evaluation with reinforcement learning from human feedback (RLHF)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (unspecified in text)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Depends on human feedback for shaping rewards and may inherit annotator biases; resource-intensive due to RLHF loop.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7725.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KG-CoI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge-Grounded Chain of Ideas (KG-CoI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A task/system that removes specific links from a biomedical knowledge graph and asks LLMs to propose plausible missing relations, enabling evaluation against held-out ground truth edges; used as a proxy for hypothesis plausibility grounded in existing structured knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Improving scientific hypothesis generation with knowledge grounded large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Improving scientific hypothesis generation with knowledge grounded large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Xiong et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>KG-CoI (knowledge-grounded relation completion)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Present an LLM with a knowledge-graph-derived partial context (with edges removed) and prompt it to predict plausible missing relations; because ground-truth edges exist, generated hypotheses can be validated automatically against held-out known facts.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Biomedical knowledge graph fragments (structured graph with removed edges)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Predicted relations / missing edges (structured proposals)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Knowledge-grounded prompting that conditions the LLM on contextual graph information</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (referred generically; exact model unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Biomedical knowledge graph(s) (not specified in text)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Validation against held-out ground-truth graph links (precision against known relations)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Limited to hypotheses that map to existing KG schemas and ground truths; may not discover wholly novel relations outside the KG; depends on KG coverage and quality.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7725.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree of Thoughts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reasoning paradigm that factors decision making into sub-stages by using tree search over multiple candidate partial solutions generated by an LLM, enabling evaluation and selection among structured reasoning paths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Yao et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2023</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Tree of Thoughts (ToT)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use an LLM to expand branching candidate reasoning steps into a search tree, evaluate branches (with heuristics or model scoring), and search the tree to find higher-quality solutions than single-chain generation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Textual problem descriptions / prompts</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Candidate solution paths and final selected solutions (textual reasoning traces)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Tree-structured search using LLM-generated continuations with branch evaluation (multi-step chain-of-thought style)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (unspecified in paper text)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Computationally heavier than single-pass decoding and still depends on the correctness of model-evaluated branch scoring; susceptible to hallucination in branches.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7725.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach where LLM-based agents iteratively introspect and self-correct their outputs using verbalized feedback signals and reinforcement-style updates, enabling progressive refinement of hypotheses or actions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Shinn et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2023</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Reflexion (iterative self-correction)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Allow an LLM agent to review its prior outputs, generate reflective critiques or corrections in natural language, and use those verbal critiques to guide subsequent generations, forming an iterative refinement loop.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Agent-generated textual actions/hypotheses and task context</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Refined text outputs (corrected hypotheses / actions)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Iterative self-critique prompts and verbal reinforcement-style updates</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Risk of self-reinforcing errors or amplification of biases; effectiveness depends on quality of self-critique prompts and signals.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7725.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Discovery World</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discovery World virtual environment</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A virtual experimental environment where AI agents can propose hypotheses and perform simulated experiments, enabling end-to-end testing of automated scientific discovery workflows driven by LLM-based agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Jansen et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Discovery World (virtual experimental sandbox)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Provide a simulated laboratory where agentic systems (including LLM-driven agents) can propose hypotheses, plan and run experiments in simulation, and observe outcomes to close the scientific loop.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Simulated experimental tasks and textual hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Hypotheses paired with simulated experimental outcomes and analyses</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Agentic interaction with environment, tool use, and iterative planning guided by LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Agentic LLMs (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Simulated environments and task benchmarks (specific datasets not detailed in text)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Simulator fidelity limits real-world transfer; evaluation in simulation may not capture practical experimental constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7725.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7725.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Scientist (agentic automated discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agentic framework aiming for end-to-end automated open-ended scientific discovery where systems generate hypotheses, design and run experiments, analyze results, and document findings, often leveraging LLM reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The ai scientist: Towards fully automated open-ended scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>The ai scientist: Towards fully automated open-ended scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Lu et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>AI Scientist (agentic discovery pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compose interconnected modules (hypothesis proposer, experiment designer, executor, analyzer, writer) often driven by LLMs for ideation and decision making, enabling end-to-end discovery in simulated or real experimental setups.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Task specifications, datasets, or simulated experimental contexts</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>End-to-end discovery outputs: hypotheses, experiment designs, analyses, and write-ups</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Agent orchestration, retrieval, planning and LLM-based reasoning (multi-module pipelines)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large language models (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Challenges in validation, reproducibility, and robustness when moving from simulation to real experiments; relies on multiple interconnected models which can compound errors.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sparks of Science: Hypothesis Generation Using Structured Paper Data', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tree of thoughts: Deliberate problem solving with large language models. <em>(Rating: 2)</em></li>
                <li>Improving scientific hypothesis generation with knowledge grounded large language models. <em>(Rating: 2)</em></li>
                <li>Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents. <em>(Rating: 2)</em></li>
                <li>Reflexion: Language agents with verbal reinforcement learning. <em>(Rating: 2)</em></li>
                <li>Hypothesis generation with large language models. <em>(Rating: 2)</em></li>
                <li>Scimon: Scientific inspiration machines optimized for novelty. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7725",
    "paper_id": "paper-277856996",
    "extraction_schema_id": "extraction-schema-144",
    "extracted_data": [
        {
            "name_short": "HypoGen",
            "name_full": "HypoGen dataset and fine-tuning pipeline",
            "brief_description": "A curated dataset (~5.5k samples) of structured problem→hypothesis pairs (Bit-Flip-Spark + Chain-of-Reasoning) extracted from top-tier CS papers and used to fine-tune LLaMA-style LLMs to generate hypotheses conditioned on a problem statement (Bit). The pipeline uses an LLM to extract structured elements from abstracts/full text, fine-tunes causal LM models, and evaluates generated hypotheses with LLM judges and humans.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
            "authors": "Charles O'neill et al.",
            "year": 2025,
            "method_name": "HypoGen (Bit-Flip-Spark + Chain-of-Reasoning fine-tuning)",
            "method_description": "Use an LLM (OpenAI o1) to extract a structured hypothesis schema (Bit, Spark, Flip, Chain-of-Reasoning) from paper abstracts and full text to produce a training corpus; fine-tune LLaMA-family causal language models (with LoRA, 4-bit quantization) on this dataset so that at inference the model receives only a Bit and generates a Spark plus detailed Chain-of-Reasoning as a hypothesis.",
            "input_type": "Abstracts and available full-text papers (NeurIPS 2023, ICLR 2024)",
            "output_type": "Textual structured hypotheses (Spark + Flip + Chain-of-Reasoning) conditioned on a Bit",
            "prompting_technique": "Structured extraction prompts for Bit/Flip/Spark, chain-of-reasoning style prompts for full-text extraction; causal LM fine-tuning; one-shot / few-shot inference baselines for comparison",
            "model_name": "OpenAI o1 (extraction), Meta LLaMA 3.1-8B and R1-distilled LLaMA 3.1-8B (fine-tuning), Claude 3.7 Sonnet and o3-mini (LLM judges)",
            "model_size": "8B parameters (LLaMA 3.1-8B variants); extraction/judge models unspecified",
            "datasets_used": "HypoGen: ~5478 samples compiled from NeurIPS 2023 (3218 papers) and ICLR 2024 (2260 papers); held-out test of 50 recent hypotheses",
            "evaluation_metric": "Perplexity, IAScore (Idea Alignment Score), Idea Distinctiveness Index, pairwise LLM-judge novelty/feasibility/overall preference, small-scale human evaluation",
            "reported_results": "Fine-tuning on HypoGen increased IAScore substantially and produced hypotheses judged more feasible and higher overall quality than one-shot variants (86–92% preference vs one-shot), while reducing novelty/diversity; human hypotheses still preferred overall in most comparisons.",
            "limitations": "Relies on LLMs for both extraction and evaluation which can introduce hallucination and bias; structured schema is subjective; domain generalization beyond CS remains untested; trade-off observed between alignment/feasibility and semantic distinctiveness.",
            "counterpoint": true,
            "uuid": "e7725.0",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Bit-Flip-Spark+CoR",
            "name_full": "Bit-Flip-Spark plus Chain-of-Reasoning schema",
            "brief_description": "A structured hypothesis representation combining a conventional assumption (Bit), a concise core insight (Spark), a counterproposal (Flip), and an explicit first-person Chain-of-Reasoning that narrates the abductive path from Bit to Flip. Designed to make LLM-generated hypotheses more interpretable and reproducible.",
            "citation_title": "",
            "mention_or_use": "use",
            "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
            "authors": "Charles O'neill et al.",
            "year": 2025,
            "method_name": "Bit-Flip-Spark + Chain-of-Reasoning schema",
            "method_description": "Represent scientific contributions as a four-part structured object (Bit, Spark, Flip, Chain-of-Reasoning); use LLM prompts to extract these elements from paper text and train a causal LM to conditionally generate Sparks and Chains-of-Reasoning given a Bit, improving transparency of ideation.",
            "input_type": "Paper abstracts (Bit/Flip/Spark extraction) and full text (Chain-of-Reasoning extraction)",
            "output_type": "Structured textual schema containing Bit, Spark, Flip, and a first-person Chain-of-Reasoning",
            "prompting_technique": "Specialized structured prompts for extraction; chain-of-thought/first-person style chain-of-reasoning reconstruction; conditional fine-tuning so only Bit is required at inference",
            "model_name": "OpenAI o1 (extraction), LLaMA-family fine-tuned models (generation)",
            "model_size": "o1 and judge model sizes unspecified; LLaMA variants 8B",
            "datasets_used": "Compiled from NeurIPS 2023 and ICLR 2024 papers within the HypoGen dataset",
            "evaluation_metric": "Downstream improvements in IAScore, judge preference, perplexity and Idea Distinctiveness Index reported in paper",
            "reported_results": "Using the schema for supervision improved alignment (IAScore) and produced more feasible, higher-quality hypotheses after fine-tuning, at the cost of some semantic distinctiveness.",
            "limitations": "Schema is interpretive and subjective; extraction depends on upstream LLM quality and may propagate extraction errors; may bias models toward producing more conventional (less novel) outputs.",
            "counterpoint": true,
            "uuid": "e7725.1",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "HypoGeniC",
            "name_full": "HypoGeniC (iterative RLHF hypothesis generation)",
            "brief_description": "A prior system that expands iterative proposal/evaluation loops by applying reinforcement learning with human feedback to refine hypothesis generation produced by LLMs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "paper_title": "",
            "authors": "Zhou et al.",
            "year": 2024,
            "method_name": "HypoGeniC (iterative RLHF)",
            "method_description": "Iteratively generate candidate hypotheses with an LLM and refine selection/policies using reinforcement learning informed by human feedback, effectively looping proposal and evaluation to improve generated hypotheses.",
            "input_type": "Textual problem statements and candidate hypotheses (iterative proposals)",
            "output_type": "Refined hypotheses and candidate idea rankings",
            "prompting_technique": "Iterative generation+evaluation with reinforcement learning from human feedback (RLHF)",
            "model_name": "Large language models (unspecified in text)",
            "model_size": "",
            "datasets_used": "",
            "evaluation_metric": "",
            "reported_results": "",
            "limitations": "Depends on human feedback for shaping rewards and may inherit annotator biases; resource-intensive due to RLHF loop.",
            "counterpoint": true,
            "uuid": "e7725.2",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "KG-CoI",
            "name_full": "Knowledge-Grounded Chain of Ideas (KG-CoI)",
            "brief_description": "A task/system that removes specific links from a biomedical knowledge graph and asks LLMs to propose plausible missing relations, enabling evaluation against held-out ground truth edges; used as a proxy for hypothesis plausibility grounded in existing structured knowledge.",
            "citation_title": "Improving scientific hypothesis generation with knowledge grounded large language models.",
            "mention_or_use": "mention",
            "paper_title": "Improving scientific hypothesis generation with knowledge grounded large language models.",
            "authors": "Xiong et al.",
            "year": 2024,
            "method_name": "KG-CoI (knowledge-grounded relation completion)",
            "method_description": "Present an LLM with a knowledge-graph-derived partial context (with edges removed) and prompt it to predict plausible missing relations; because ground-truth edges exist, generated hypotheses can be validated automatically against held-out known facts.",
            "input_type": "Biomedical knowledge graph fragments (structured graph with removed edges)",
            "output_type": "Predicted relations / missing edges (structured proposals)",
            "prompting_technique": "Knowledge-grounded prompting that conditions the LLM on contextual graph information",
            "model_name": "Large language models (referred generically; exact model unspecified)",
            "model_size": "",
            "datasets_used": "Biomedical knowledge graph(s) (not specified in text)",
            "evaluation_metric": "Validation against held-out ground-truth graph links (precision against known relations)",
            "reported_results": "",
            "limitations": "Limited to hypotheses that map to existing KG schemas and ground truths; may not discover wholly novel relations outside the KG; depends on KG coverage and quality.",
            "counterpoint": true,
            "uuid": "e7725.3",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "ToT",
            "name_full": "Tree of Thoughts",
            "brief_description": "A reasoning paradigm that factors decision making into sub-stages by using tree search over multiple candidate partial solutions generated by an LLM, enabling evaluation and selection among structured reasoning paths.",
            "citation_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "mention_or_use": "mention",
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "authors": "Yao et al.",
            "year": 2023,
            "method_name": "Tree of Thoughts (ToT)",
            "method_description": "Use an LLM to expand branching candidate reasoning steps into a search tree, evaluate branches (with heuristics or model scoring), and search the tree to find higher-quality solutions than single-chain generation.",
            "input_type": "Textual problem descriptions / prompts",
            "output_type": "Candidate solution paths and final selected solutions (textual reasoning traces)",
            "prompting_technique": "Tree-structured search using LLM-generated continuations with branch evaluation (multi-step chain-of-thought style)",
            "model_name": "Large language models (unspecified in paper text)",
            "model_size": "",
            "datasets_used": "",
            "evaluation_metric": "",
            "reported_results": "",
            "limitations": "Computationally heavier than single-pass decoding and still depends on the correctness of model-evaluated branch scoring; susceptible to hallucination in branches.",
            "counterpoint": true,
            "uuid": "e7725.4",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Reflexion",
            "name_full": "Reflexion: Language agents with verbal reinforcement learning",
            "brief_description": "An approach where LLM-based agents iteratively introspect and self-correct their outputs using verbalized feedback signals and reinforcement-style updates, enabling progressive refinement of hypotheses or actions.",
            "citation_title": "Reflexion: Language agents with verbal reinforcement learning.",
            "mention_or_use": "mention",
            "paper_title": "Reflexion: Language agents with verbal reinforcement learning.",
            "authors": "Shinn et al.",
            "year": 2023,
            "method_name": "Reflexion (iterative self-correction)",
            "method_description": "Allow an LLM agent to review its prior outputs, generate reflective critiques or corrections in natural language, and use those verbal critiques to guide subsequent generations, forming an iterative refinement loop.",
            "input_type": "Agent-generated textual actions/hypotheses and task context",
            "output_type": "Refined text outputs (corrected hypotheses / actions)",
            "prompting_technique": "Iterative self-critique prompts and verbal reinforcement-style updates",
            "model_name": "LLMs (unspecified)",
            "model_size": "",
            "datasets_used": "",
            "evaluation_metric": "",
            "reported_results": "",
            "limitations": "Risk of self-reinforcing errors or amplification of biases; effectiveness depends on quality of self-critique prompts and signals.",
            "counterpoint": true,
            "uuid": "e7725.5",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Discovery World",
            "name_full": "Discovery World virtual environment",
            "brief_description": "A virtual experimental environment where AI agents can propose hypotheses and perform simulated experiments, enabling end-to-end testing of automated scientific discovery workflows driven by LLM-based agents.",
            "citation_title": "Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents.",
            "mention_or_use": "mention",
            "paper_title": "Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents.",
            "authors": "Jansen et al.",
            "year": 2024,
            "method_name": "Discovery World (virtual experimental sandbox)",
            "method_description": "Provide a simulated laboratory where agentic systems (including LLM-driven agents) can propose hypotheses, plan and run experiments in simulation, and observe outcomes to close the scientific loop.",
            "input_type": "Simulated experimental tasks and textual hypotheses",
            "output_type": "Hypotheses paired with simulated experimental outcomes and analyses",
            "prompting_technique": "Agentic interaction with environment, tool use, and iterative planning guided by LLMs",
            "model_name": "Agentic LLMs (unspecified)",
            "model_size": "",
            "datasets_used": "Simulated environments and task benchmarks (specific datasets not detailed in text)",
            "evaluation_metric": "",
            "reported_results": "",
            "limitations": "Simulator fidelity limits real-world transfer; evaluation in simulation may not capture practical experimental constraints.",
            "counterpoint": true,
            "uuid": "e7725.6",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "AI Scientist",
            "name_full": "AI Scientist (agentic automated discovery)",
            "brief_description": "An agentic framework aiming for end-to-end automated open-ended scientific discovery where systems generate hypotheses, design and run experiments, analyze results, and document findings, often leveraging LLM reasoning.",
            "citation_title": "The ai scientist: Towards fully automated open-ended scientific discovery.",
            "mention_or_use": "mention",
            "paper_title": "The ai scientist: Towards fully automated open-ended scientific discovery.",
            "authors": "Lu et al.",
            "year": 2024,
            "method_name": "AI Scientist (agentic discovery pipeline)",
            "method_description": "Compose interconnected modules (hypothesis proposer, experiment designer, executor, analyzer, writer) often driven by LLMs for ideation and decision making, enabling end-to-end discovery in simulated or real experimental setups.",
            "input_type": "Task specifications, datasets, or simulated experimental contexts",
            "output_type": "End-to-end discovery outputs: hypotheses, experiment designs, analyses, and write-ups",
            "prompting_technique": "Agent orchestration, retrieval, planning and LLM-based reasoning (multi-module pipelines)",
            "model_name": "Large language models (unspecified)",
            "model_size": "",
            "datasets_used": "",
            "evaluation_metric": "",
            "reported_results": "",
            "limitations": "Challenges in validation, reproducibility, and robustness when moving from simulation to real experiments; relies on multiple interconnected models which can compound errors.",
            "counterpoint": true,
            "uuid": "e7725.7",
            "source_info": {
                "paper_title": "Sparks of Science: Hypothesis Generation Using Structured Paper Data",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "Improving scientific hypothesis generation with knowledge grounded large language models.",
            "rating": 2,
            "sanitized_title": "improving_scientific_hypothesis_generation_with_knowledge_grounded_large_language_models"
        },
        {
            "paper_title": "Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents.",
            "rating": 2,
            "sanitized_title": "discoveryworld_a_virtual_environment_for_developing_and_evaluating_automated_scientific_discovery_agents"
        },
        {
            "paper_title": "Reflexion: Language agents with verbal reinforcement learning.",
            "rating": 2,
            "sanitized_title": "reflexion_language_agents_with_verbal_reinforcement_learning"
        },
        {
            "paper_title": "Hypothesis generation with large language models.",
            "rating": 2,
            "sanitized_title": "hypothesis_generation_with_large_language_models"
        },
        {
            "paper_title": "Scimon: Scientific inspiration machines optimized for novelty.",
            "rating": 1,
            "sanitized_title": "scimon_scientific_inspiration_machines_optimized_for_novelty"
        }
    ],
    "cost": 0.020614499999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Sparks of Science: Hypothesis Generation Using Structured Paper Data
17 Apr 2025</p>
<p>Charles O'neill cponeill00@gmail.com 
Tirthankar Ghosal ghosalt@ornl.gov 
Roberta Rȃileanu r.raileanu@ucl.ac.uk 
Mike Walmsley m.walmsley@utoronto.ca 
Thang Bui thang.bui@anu.edu.au 
Kevin Schawinski schawinski@gmail.com 
Ioana Ciucȃ iciuca@stanford.edu 
Hypogen Dataset </p>
<p>University of Oxford</p>
<p>Oak Ridge National Laboratory</p>
<p>University College London</p>
<p>University of Toronto</p>
<p>Australian National University</p>
<p>Stanford University</p>
<p>Research Papers</p>
<p>Sparks of Science: Hypothesis Generation Using Structured Paper Data
17 Apr 2025D189B4D36A41240A8FF1ECB0A4C2A548arXiv:2504.12976v1[cs.CL]
Generating novel and creative scientific hypotheses is a cornerstone in achieving Artificial General Intelligence.Large language and reasoning models have the potential to aid in the systematic creation, selection, and validation of scientifically informed hypotheses.However, current foundation models often struggle to produce scientific ideas that are both novel and feasible.One reason is the lack of a dedicated dataset that frames Scientific Hypothesis Generation (SHG) as a Natural Language Generation (NLG) task.In this paper, we introduce HypoGen, the first dataset of approximately 5500 structured problem-hypothesis pairs extracted from top-tier computer science conferences structured with a Bit-Flip-Spark schema, where the Bit is the conventional assumption, the Spark is the key insight or conceptual leap, and the Flip is the resulting counterproposal.HypoGen uniquely integrates an explicit Chain-of-Reasoning component that reflects the intellectual process from Bit to Flip.We demonstrate that framing hypothesis generation as conditional language modelling, with the model fine-tuned on Bit-Flip-Spark and the Chain-of-Reasoning (and where, at inference, we only provide the Bit), leads to improvements in the overall quality of the hypotheses.Our evaluation employs automated metrics and LLM judge rankings for overall quality assessment.We show that by fine-tuning on our HypoGen dataset we improve the novelty, feasibility, and overall quality of the generated hypotheses.The HypoGen dataset is publicly available at huggingface.co/datasets/UniverseTBD/hypogen-dr1.</p>
<p>Introduction</p>
<p>Hypothesis generation is the first step of the scientific process and its de facto foundation.Creative and innovative ideas have long enabled scientists to model and predict the behaviour of complex systems, from neuroscience to astrophysics.Recently, the impressive capabilities of large language models have prompted researchers to explore their potential to advance the generation of scientific ideas (Ziems et al., 2023;Birhane et al., 2023;Xie et al., 2023;Noever &amp; McKee, 2023;Si et al., 2024;Kumar et al., 2024;Xiong et al., 2024b;Zhou et al., 2024b;Cohrs et al., 2025).Not only do these models excel in understanding and generating human language (e.g., Devlin et al., 2018;Brown et al., 2020;Team et al., 2023;Grattafiori et al., 2024), but they also demonstrate a remarkable ability to make nuanced deductions and establish relationships across varied contexts (Elkins &amp; Chun, 2020), rendering them an ideal basis for the generation of semantic hypotheses.Recent work has evaluated LLMs on the entire scientific discovery process, from hypothesis generation to running experiments, analyzing the results, and even writing a paper (Lu et al., 2024a;Chan et al., 2024;Chen et al., 2024;Gottweis et al., 2025;Nathani et al., 2025;Schmidgall et al., 2025;Schmidgall &amp; Moor, 2025).However, most works highlight limitations of current models when applied to open research problems, particularly with respect to generating novel, creative, diverse, feasible, actionable, interesting, and useful ideas or hypotheses (Nathani et al., 2025).</p>
<p>LLMs face significant challenges when applied to scientific ideation.These models are prone to hallucinations, often producing non-factual content due to their token likelihood maximization objective (Manakul et al., 2023;McKenna et al., 2023;Li et al., 2023;Zhang, 2023;Tonmoy et al., 2024;Lu et al., 2024a).Recent benchmarks highlight that such inaccuracies can be difficult to detect, as LLMs often present them with high confidence (Qi et al., 2023;Zhou et al., 2024a).Additionally, probability-maximizing decoding strategies (e.g., greedy or high-beam search) can lead to text that lacks lexical diversity, a problem that persists even in models with hundreds of billions of parameters (Holtzman et al., 2019;Li et al., 2022;Meister et al., 2022;Su et al., 2022;Zhou et al., 2024a).</p>
<p>The design of a validation scheme to rigorously test these machine-generated hypotheses poses additional challenges (Alaa et al., 2021;Si et al., 2024;Luo et al., 2025).To be effective, scientific hypotheses not only require creative insight drawn from a broad understanding of the domain at hand, but also must be rooted in the existing literature to ensure their novelty and relevance (Simonton, 2004;Runco &amp; Jaeger, 2012;Doboli et al., 2014;Strøm, 2018;Wang et al., 2023).In addition, it is difficult to determine in an automated fashion to what extent a certain idea already exists in the literature, which is particularly problematic due to the tendency of LLMs to copy subsets of their training data in generation (McCoy et al., 2021;Liu &amp; Hulden, 2021).Given that validation is integral to the scientific method, the closed-box nature of LLMs requires a careful and nuanced approach to ensure that the results are replicable and robust.</p>
<p>To address these challenges, we introduce HypoGen, a dataset comprising approximately 5500 structured problem-hypothesis pairs extracted from top-tier computer science conferences.This dataset represents a significant step forward in framing scientific hypothesis generation as a conditional language modeling problem.By conditioning hypotheses on a clear formulation of the problem (the Bit), our approach provides a robust foundation for developing and evaluating LLMs in the context of scientific discovery.Importantly, HypoGen incorporates a detailed Chain-of-Reasoning narrative that mirrors the iterative and reflective process used by human scientists to transition from conventional wisdom to innovative counterproposals, thus improving both the quality and the trustworthiness of the generated hypotheses.</p>
<p>Our key contributions include the development of the HypoGen dataset and the novel framing of scientific hypothesis generation as a conditional language modeling problem enriched with an explicit reasoning chain.We present baseline performance measures of an LLaMA-based model on a hypothesis generation task after being fine-tuned on the HypoGen dataset.We employ a straightforward evaluation framework that assesses hypotheses along the dimensions of novelty and feasibility, incorporating automated metrics and LLM judgements.By capturing the full chain of reasoning, our approach provides valuable insights into the thought processes underlying scientific discovery.</p>
<p>Related Work</p>
<p>Several approaches factor the decision process into sub-stages.In the proposal stage, reasoning and sometimes retrieval are used to generate candidate actions or hypotheses (Chen et al., 2021;Wang et al., 2022).The evaluation stage then scores these candidates (for example, perplexity (Ahn et al., 2022) or learned reward functions (Yao et al., 2020)), identifying which candidates are the most promising.Techniques such as ToT (Yao et al., 2023) and RAP (Hao et al., 2023) use tree search paradigms to propose and evaluate multiple solution paths in a structured manner.Reflexive approaches such as Shinn et al. (2023) and Lindes &amp; Peter (2023) explicitly incorporate iterative self-correction of hypothesized actions.The work of Zhou et al. (2024a) with HypoGeniC expands this process with iterative reinforcement learning with human feedback.These advances stress the need for benchmarks that realistically reflect the capacity of LLMs to generate, validate, and refine scientific hypotheses (e.g., Kumar et al., 2024;Majumder et al., 2024;Luo et al., 2025).For example, the "Knowledge Grounded Chain of Ideas" or KG-CoI system (Xiong et al., 2024a) removes specific links from a biomedical knowledge graph and asks LLMs to propose plausible missing relations.Because these links are derived from previously held information, LLM-generated hypotheses can be validated against known ground truths.Such tasks resemble real-world discovery scenarios, where a laboratory of AI agents can interact with human experts, document interactions, and call tools to achieve a particular task, for example, to design a novel protein binder (e.g., Swanson et al., 2024).Other innovative evaluation environments, such as Discovery World (Jansen et al., 2024) or AI Scientist (Lu et al., 2024b), provide virtual environments where an AI agent can propose hypotheses and conduct simulated experiments, opening the possibility of end-to-end science.</p>
<p>However, there remains a lack of standardized "frontier" benchmarks designed to evaluate hypothesis generation capabilities, especially in the context of agentic AI systems, which rely on highly interconnected modules that require complex reasoning (Shao et al., 2024).To this end, we introduce HypoGen, a benchmark dataset specifically designed to address current deficits in the evaluation of the generation of scientific hypotheses.In contrast to existing benchmarks, HypoGen explicitly emphasizes Chain-of-Reasoning: each hypothesis includes a transparent abductive logic trail that mirrors the thought process of a human expert.Our method uses a structured Bit-Flip-Spark + Chain-of-Reasoning format to capture the conceptual progression from an initial problem statement (Bit), to a key insight (Spark), and finally to a refined idea (Flip).By incorporating a detailed reasoning chain, HypoGen helps mitigate the risk of hallucination (Tonmoy et al., 2024), while simultaneously providing researchers with a reproducible step-by-step notebook of how a new idea was generated.</p>
<p>Methodology and the Bit-Flip-Spark+Chain-of-Reasoning Format</p>
<p>Figure 1 illustrates the overall pipeline of HypoGen1 , which is designed to extract structured information from scientific papers using the Bit-Flip-Spark+Chain-of-Reasoning format.The Stanford Bit-Flip schema2 serves as a concise and structured hypothesis formulation technique designed to encapsulate the core intellectual contribution of a research paper.The Bit identifies the prevailing belief or assumption in the research domain that the paper aims to challenge.The Flip articulates the novel approach or counterargument that the paper introduces to advance the field.In addition, we introduce a novel concept, Spark, which contains the "essence of an idea", formalized as a conceptual leap.We provide an example extracted from Bahdanau et al. (2015) and the full prompt to obtain this representation in Appendix A.</p>
<p>Example HypoGen Hypothesis</p>
<p>Bit: Conventional neural machine translation encodes the entire source sentence into a single fixed-length vector.This approach imposes a bottleneck, because crucial contextual information can be lost in the compression process.Spark: Soft alignment for flexible translation.Flip: An idea was introduced that enables the model to automatically search for relevant parts of the source sentence at each decoding step.This removes the need for a single fixed-length representation by allowing a soft-alignment mechanism that dynamically focuses on important source information.Chain-of-Reasoning: I started by considering that traditionally neural machine translation relies on a single fixed-length vector to encode an entire source sentence before generating the target sequence, and that this rigid bottleneck can lose important contextual information, limiting translation quality and flexibility.I questioned whether a more dynamic way to capture contextual cues was needed, especially for longer sequences.Instead, I introduced a learnable (soft) search mechanism that dynamically aligns each target word with the most relevant parts of the source sentence, shifting away from a fixed-length encoding to attend to context more flexibly and generate higher-quality translations.I trained a bidirectional encoderdecoder on a large bilingual corpus, used a thirty-thousand-word vocabulary, and optimized it via minibatch gradient methods while testing different hidden-layer sizes.How did we confirm that the new approach was identifying correct alignments?I visualized alignment weights and observed that the decoder selectively focused on relevant source words, substantially improving clarity and accuracy.A follow-up question examined how to handle unknown or rare terms, prompting an exploration of further lexical coverage strategies.I recognized a turning point when it became evident that soft attention preserved essential details for both short and long inputs.I validated performance on held-out test sets, noting that the model equaled or surpassed phrase-based benchmarks and maintained robustness on lengthy sentences.This integrated reasoning closed the gap between the original limitation and the dynamic alignment concept, paving the way for more context-aware neural translation.</p>
<p>The objective is to distill the complex ideas within a paper into a simplified yet rigorous representation, allowing for clear communication of both the problem being tackled (Flip) and the proposed solution (Bit).This approach is grounded in the understanding that a wellarticulated hypothesis is the cornerstone of impactful research.Although this structured representation of hypotheses is subjective and is merely one of many options, we found that it worked well for the generation of a solution (i.e.Flip) conditioned on a problem (i.e., the Bit).Finally, the Chain-of-Reasoning presents a detailed narrative that captures the scientist's ideation process that connects the Bit to the Flip.</p>
<p>Preprocessing and Dataset Construction</p>
<p>We compile our dataset from papers accepted at the two top-tier computer science conferences, NeurIPS 2023 (3218 papers) and ICLR 2024 (2260 papers), resulting in 5478 distinct samples.We then used OpenAI's o1 model for the structured extraction step.For each paper, we first extract the Bit, Flip, and Spark components from the abstract.We prompted o1 to identify the conventional assumption, the innovative approach, and a concise 4-6-word summary of the core insight.We then used a robust parallel processing approach with a retry mechanism with up to three attempts per extraction to ensure high-quality output.</p>
<p>For papers with available full text, we extract the Chain-of-Reasoning component using a separate prompt that guides the model to recreate the intellectual progression from Bit to Flip.This step removes the abstract section from the full text to prevent redundancy.It then processes the paper to generate a first-person narrative detailing the scientist's ideation process.We store the output in JSON format and include metadata such as the paper ID, title, authors, venue, year, and citation information.We construct an independent test set of 50 hypotheses from the authors' recent submissions and relevant work between 2024 and 2025.</p>
<p>Fine-tuning and Inference Pipeline</p>
<p>Our baseline models include Meta LLaMA 3.1 8B and R1-distilled LLaMA 3.1 8B.These models are trained on extensive corpora with a context window of 128,000 tokens and employ byte-pair encoding for tokenization (Sennrich et al., 2015;Kudo &amp; Richardson, 2018), incorporating a vocabulary of 128,000 tokens.The R1-distilled LLaMA 3.1 8B is a specialized model with knowledge transferred from the larger DeepSeek-R1 model with 671B parameters.This substantial pre-training provides robust language understanding capabilities essential for scientific hypothesis generation.</p>
<p>We leverage our curated dataset of structured problem-hypothesis pairs for fine-tuning, employing the causal language modeling objective.The process utilizes four NVIDIA H100 GPUs, each with 80GB of VRAM.We implement 4-bit quantization and deploy LoRA (Hu et al., 2021) with hyperparameters: α = 16 and a dropout rate of 0.1.The models are loaded with 4-bit precision base loading, using appropriate compute precision (bf16 where supported otherwise fp16).We use the AdamW 8-bit optimizer (Loshchilov &amp; Hutter, 2017) with a weight decay of 0.01, a batch size of 32, and a learning rate of 2 × 10 −4 .The training follows a linear scheduler with 5 warmup steps and proceeds for approximately 60 total steps, with logging at each step.During inference, only the Bit is provided to the model.The model then generates the corresponding Spark along with a detailed Chain-of-Reasoning.We use the ollama LLM framework for the LLaMA one-shot inference.</p>
<p>Evaluation</p>
<p>The task of evaluating generative models tailored for the generation of scientific hypotheses is challenging, given the inherently subjective nature of scientific research.In this paper, we focus on a dual evaluation framework that primarily incorporates traditional automated metrics and LLM-based judges.</p>
<p>Our evaluation strategy relies on a test set of 50 hypotheses extracted from the recent literature from primarily 2024 and 2025.It combines automated metrics with an LLM Judge module that assesses novelty, feasibility, and overall quality from pairwise comparisons.We further test the robustness of our approach with a second LLM judge.For a subset of our evaluation set, we also use human evaluation to assess whether fine-tuning LLaMA-base models on our HypoGen dataset improves the quality of the hypotheses.</p>
<p>Automated Evaluation Metrics</p>
<p>Perplexity is used as a preliminary metric to assess the fluency and coherence of the hypotheses generated (Chen et al., 1998).It is defined as the exponentiated average negative log-likelihood of a given token sequence X = (x 0 , x 1 , . . .x t ).</p>
<p>Mathematically, this is expressed as:
PPL(X) = exp − 1 t t ∑ i log p θ (x i | x &lt;i ) (1)
Here, log p θ (x i |x &lt;i ) denotes the log-likelihood of the i-th token conditioned on its preceding tokens according to the model.The metric serves as an indicator of the predictive performance of the model, with lower values suggesting better generalization.</p>
<p>IAScore quantifies alignment between LLM-generated hypotheses and expert-proposed research ideas.For each paper j, the IAScore computes the average alignment between author-proposed future research ideas (AP-FRI j ) and each generated idea I ij using an IdeaMatcher (IM) model (Kumar et al., 2024):
AvgScore j = 1 N j N j ∑ i=1 IM(AP-FRI j , I ij )(2)
The domain-wide IAScore for model M is then calculated by averaging across all P papers:
IAScore domain,M = 1 P P ∑ j=1
AvgScore j</p>
<p>(3) Kumar et al. (2024) employed GPT as the IdeaMatcher due to its superior performance (91.8% accuracy) compared to Natural Language Inference using RoBERTa MNLI and BERTScore in determining if a generated idea is contained within the author's proposals.Higher IAScore values indicate greater alignment between LLM-generated ideas and author perspectives across the domain.</p>
<p>Idea Distinctiveness Index evaluates the semantic diversity between the hypotheses generated using embedding-based similarity rather than textual differences at the surface level.For a set of ideas I, each idea id i is embedded into vector v i using a pre-trained BERT model (Kumar et al., 2024).The distinctness between ideas id i and id j is defined as
D ij = 1 − sim(v i , v j )
, where sim is cosine similarity.The overall distinctiveness for a set of n ideas is:
D I = 1 n(n − 1) n ∑ i=1 n ∑ j=1 j̸ =i D ij (4)
To assess the performance of a model within a domain, we can calculate the Idea Distinctness Index D I p M for all ideas generated by model M for each paper p, then average across all m papers:
D domain,M = 1 m m ∑ p=1 D I p M(5)
Higher D domain,M values signify greater idea diversity, indicating the model's ability to generate semantically varied hypotheses within the domain.</p>
<p>LLM Evaluation</p>
<p>To evaluate the quality of the hypotheses in our evaluation set, we employed Anthropic's Claude 3.7 Sonnet-Thinking model as the automated evaluator.We perform a pairwise evaluation on each dataset consisting of 50 problems and proposals of paired solutions generated by two LLMs for each evaluation experiment.We have nine experiments corresponding to LLaMA 3.1-8B-FT (LLaMA-8B-FT for brevity) vs Human, LlaMA 3.1-8B-FT (LLaMA-8B-FT) vs an o1 model with one example (1shot), followed by an R1-distilled-LlaMA-3.1-8B-FT (R1-distilled-LlaMA-FT) vs Human and o1-1shot, LLaMA-8b-FT vs R1-distilled-LLaMA-8b-FT, Human vs o1-1shot, R1-distilled-LlaMA-8b-1shot vs R1-distilled-LLaMA-8b-FT, LLaMA-8B-1shot vs LLaMA-8B-FT and LLaMA-8B-1shot vs R1-distilled-LLaMA-8B-1shot (R1-distilled-LlaMA-1shot).We provide our results in Fig. 2. The Human hypotheses are the o1 structured hypotheses generated from the evaluation set.</p>
<p>For each Bit, the LLM evaluator was asked to evaluate which proposal (Spark + Chain-of-Reasoning) provided the overall better proposal, taking into account novelty and feasibility.We randomize the presentation order of the solutions to mitigate order effects.After each evaluation experiment, we obtain whether proposal A wins in novelty, feasibility, and overall, with an option for a tie.The model's "thinking" is further enabled with an 8,000 token budget to encourage thorough deliberation.</p>
<p>The LLM-based evaluation provides consistency and scalability; however, it comes at the cost of robustness and verifiability.To account for some of these challenges, we rerun our experimental analysis with the OpenAI o3-mini model as a judge to see the degree of agreement.In addition, we conducted a blind human evaluation with 20 hypothesis pairs evaluated by one of the authors.We provide our complete prompts in Appendix A.</p>
<p>Results</p>
<p>Results from Automated Metrics Table 1 shows that human-generated hypotheses have much higher perplexity values than their LLM counterparts.In particular, LLaMA base models exhibit values between 16.70 and 34.98 compared to human ones (89.31).This could point to the semantic creativity present in human-generated ideas.Although perplexity remains lower overall, fine-tuning increases the perplexity score of the LLaMA models, indicating increased "unpredictability" as it stands to ideation.</p>
<p>Secondly, fine-tuning improves idea alignment with the target domain, as shown by the significant improvement in IAScore for the standard LLaMA model (0.2781 → 0.6746).This result could mean that the structured Bit-Flip-Spark+Chain-of-Reasoning training enables models to generate hypotheses that better align with expert-level scientific thinking.The fact that we do not see this effect to the same extent in the distilled LLaMA model may hint at the effectiveness of knowledge transfer.</p>
<p>The inverse relationship between IAScore improvements and Idea Distinctness Index reductions, which are particularly notable in the R1 Distilled LLaMA with a reduction from 0.7146 → 0.6288, indicates a possible trade-off in hypothesis generation: as models better align with expert scientific thinking patterns, they may produce less semantically diverse outputs.</p>
<p>Pairwise Comparison using LLM Judges</p>
<p>As shown in the upper panel of Fig. 2, finetuning consistently improves overall hypothesis quality relative to one-shot variants of the same architecture (86-92% preference for fine-tuned versions), despite the reduction in novelty scores.This indicates that fine-tuning on HypoGen steers models toward generating more practical hypotheses.</p>
<p>The LLM evaluation results in 2 reveal a consistent trade-off between novelty and feasibility in the different experiments.Models that excel in creativity metrics seem to underperform in feasibility and vice versa.Human-generated hypotheses win overall in quality assessments compared to LLM-generated alternatives, with human ideas preferred in 80-90% of the comparisons.However, fine-tuned models demonstrate comparable feasibility scores relative to the human set (A=62-64% vs. B=36-38%).Rerunning our analysis with o3-mini as the LLM judge shows consistent behaviour across most experiment: agreement on the key novelty-feasibility trade-off in fine-tuned versus one-shot models and confirming the win of human hypotheses for overall quality.We show our results in Fig. 3 in Appendix B.</p>
<p>Human Evaluation Results</p>
<p>The results of the small-scale human evaluation trace the observed patterns with the Claude 3.7 Sonnet Thinking model.For the R1-distilled LLaMA comparison, the human evaluator preferred fine-tuned model outputs for novelty (95% vs. 5%) and feasibility (70% vs. 30%), with an overall preference for fine-tuned outputs (70% preference, 25% tie, 5% base model).The standard LLaMA-8B comparison revealed more competitive performance, with the fine-tuned model maintaining modest advantages in novelty (47.6% vs 42.9%, 9. 5% tie) and feasibility (52.4% vs 42.9%, 4. 8% tie), resulting in a narrower overall preference (42.9% fine-tuned, 33.3% one shot, 23.8% tie).The human evaluation provides further evidence that fine-tuning on structured Bit-Flip-Spark+Chainof-Reasoning data improves hypothesis quality, with particularly dramatic improvements observed in the R1-distilled architecture.However, further human evaluation is needed.</p>
<p>Discussion and Future Work</p>
<p>We introduced the HypoGen dataset for the generation of scientific hypothesis that extends the conventional Bit-Flip-Spark format by incorporating a detailed Chain-of-Reasoning component.We showed that fine-tuning on HypoGen enables the LLaMA 3.1-8B and R1-distilled-LLaMA 3.1-8B models to improve their hypotheses.This demonstrates the effectiveness of fine-tuning in the intermediate steps of an idea, which provides more transparency and interpretability.We release HypoGen under an MIT license to encourage the development of AI agents capable of supporting human experts in the ideation process.</p>
<p>The primary limitation of HypoGen is that it uses LLMs to evaluate the hypotheses generated.</p>
<p>Although LLM-as-a-judge modules can perform robustly under certain conditions (Lu et al., 2024a), they may be biased by their training regime in highly non-trivial ways.To mitigate these unexpected effects, we plan to perform an extensive human evaluation to determine the degree to which human and LLM align on a particular judgement.These findings will guide the construction of more robust reward models that align closely with human expertise, further strengthening HypoGens applicability in real-world scientific discovery.</p>
<p>Looking to the future, we want to examine how our approach with HypoGen generalizes to other scientific domains.Our evaluation focused on computer science, and it remains an open question how well the fine-tuning on one domain generalizes to another.We also plan to expand our dataset to fields such as astrophysics, biology, and materials science, where hypothesis generation could accelerate scientific discoveries in fundamentally different fields.This work aims to enable interdisciplinary AI teammates that collaborate with human experts on challenging scientific tasks (Swanson et al., 2024), with the overarching goal of democratising science.</p>
<p>-Explain the ** method ** or ** technique ** that enables this change .</p>
<p>-Include ** enough detail ** so the Flip is understandable on its own .-<strong> Bit </strong>: at least two sentences , with sufficient detail about the conventional approach and its limitation .-<strong> Flip </strong>: at least two sentences , describing the new approach or perspective with enough detail to understand the main technique .-<strong> Spark </strong>: a concise 4 -6 word summary of the core idea .Follow these rules : -Do not cite the paper itself or its authors .</p>
<p>-Instead of saying " We /I introduced an idea ", just say " An idea was introduced ...".</p>
<p>Return ONLY the JSON object in ** this exact format ** ( no extra text ): \{{ " Bit ": " Technical limitation or conventional approach , in at least two sentences ", " Flip ": " Innovative approach or solution , in at least two sentences ", " Spark ": "4 -6 word summary " \}} """ A.2 Chain-of-Reasoning Prompt NOTEBOOK_PROMPT = """ You are a highly advanced computer scientist with extraordinary ability in scientific hypothesis generation .</p>
<p>You are given : -A pre -identified " Bit "( the conventional assumption or limitation ) -A pre -identified " Flip "( the innovative approach or solution ) -The full text of the paper .</p>
<p>Please provide the Scientist ' s Ideation Notebook to obtain the intellectual process that went from Bit to Flip .In other words , how did the Bit go to the Flip ?The goal is to model the intellectual process of a scientist in a comprehensive cycle of analysis , summarizing , exploration , reassessment , reflection , backtracing , and iteration to develop a well -considered thinking process as they understand how to go from the Bit to the Flip .</p>
<p>This scientist_notebook should be detailed enough to write the paper and must include a mix of interrogative and reflective output .It needs to include questions that probe the process alongside reflective answers that elaborate on methodological details , as well as experimental observations and results that emerged during hypothesis testing .It should also include a few additional important questions regarding experimental design , data analysis , and validation , and contain a reflection that highlights a breakthrough insight akin to a Eureka moment , without stating that you experienced one .It needs to be written in first person singular and follow these rules : Rules : -Use scientific language .</p>
<p>-Ensure that the scientist_notebook includes explicit questions that probe your reasoning process , clearly interwoven with your reflective responses .</p>
<p>A.4 Model Generations</p>
<p>A.5 Original Bit</p>
<p>Conventional information retrieval methods rely on large labeled datasets for finetuning, which can be expensive or impractical to obtain.Moreover, even when such datasets are available, their effectiveness rapidly decreases in new domains due to distributional shifts.</p>
<p>A.5.1 LLaMA-8B-1shot</p>
<p>I started by considering the limitations of conventional information retrieval methods.They heavily rely on large labeled datasets, which can be expensive or impractical to obtain in some cases.Moreover, even when such datasets are available, their effectiveness rapidly decreases in new domains due to distributional shifts.This led me to wonder: how might I address these challenges without breaking the bank or requiring extensive data annotation?I explored whether utilizing self-supervised learning techniques could help bridge this gap.By generating pseudo-labels from unlabeled data and using them for fine-tuning, I asked: could we leverage weakly supervised or even unsupervised methods to adapt conventional retrieval models more efficiently?Another question that arose was: might we tap into the strengths of pre-trained language models by leveraging their rich contextual representations?This led me to ponder whether augmenting these representations with domain-specific knowledge graphs could enhance the model's robustness and generalizability across diverse domains.As I delved deeper, I began to consider the potential benefits of meta-learning.By training a model on multiple tasks or datasets simultaneously, it might learn more transferable and flexible representations that can adapt quickly to novel environments.This sparked another question: how would we evaluate the performance of such models in real-world settings?Upon further reflection, I realized that addressing these challenges may involve a multidisciplinary approach.By integrating insights from natural language processing (NLP), graph neural networks (GNNs), and meta-learning, we could potentially develop more adaptive and domainagnostic retrieval methods.</p>
<p>A.5.2 LLaMA-8B-FT</p>
<p>I began by asking whether large labeled datasets were necessary to fine-tune a retrieval model, and I found that in many cases, they are not.I tested a method that learns to rank from unlabeled data and confirmed that it outperformed standard fine-tuning approaches on several benchmarks.I then questioned how to ensure that the model generalizes well in new domains, and I introduced a domain-specific pretraining stage to adapt the model to different distributions.I asked how to measure the impact of this pre-training, so I performed extensive experiments that showed consistent improvements across diverse domains.I also examined how to validate that the model's rankings were robust, and I measured the correlation between the predicted rankings and true relevance scores.I found that the pre-training stage effectively bridged the gap between different distributions, and I wondered if further hyperparameter tuning would yield even better performance.I tested different data augmentation strategies and found that they further enhanced the model's adaptability.I reflected on whether this approach could scale to larger datasets, and I confirmed that it maintained its effectiveness even with millions of unlabeled examples.Finally, I concluded that domain-specific pre-training on unlabeled data can greatly reduce reliance on labeled data and enable more efficient retrieval in new domains.</p>
<p>B o3-mini Evaluation</p>
<p>Figure 1 :
1
Figure 1: The HypoGen process begins with input paper abstracts, from which the structured Bit (the problem), Flip (the solution) and Spark (key insight) are extracted by OpenAI's o1 model.The Chain of Reasoning is extracted by the o1 model from the main body of the paper.These outputs are used to fine-tune a LLaMA-based model, which then generates hypotheses from the provided Bit.A judge module (Claude 3.7 Sonnet) assesses the overall quality based on novelty and feasibility.</p>
<p>Figure 2 :
2
Figure2: Comparative analysis of the quality of generated hypotheses across nine experiments as evaluated by an LLM Judge Claude 3.7 Sonnet.Upper: Win rates comparing non-fine-tuned versus fine-tuned LLaMA 3.1-8B (LlaMA-8B-FT) and R1-distilled-LlaMA-3.1-8B (R1-distilled-8B-FT) models on novelty and feasibility, showing the consistent trade-off in which fine-tuned models excel at feasibility (74-86% win rate).Non-fine-tuned variants show greater novelty (54-86% win rate).Lower: Pairwise win rate heatmap (read on the horizontal) between human experts, fine-tuned models (LLaMA-8B-FT, R1-FT), and one-shot models (O1-1shot, LLaMA-8B-1shot, R1-1shot) across novelty, feasibility, and overall quality dimensions.Human hypotheses are the overall winners (82-90% win rate), with fine-tuned models achieving comparable feasibility scores (62-64% vs Human).The fine-tuned models perform better than their one-shot counterparts in overall quality (86-92% win rate).</p>
<ol>
<li>** Spark ( Core Summary ) <strong>: -A concise </strong>4 -6 word ** phrase capturing the core idea .Now , consider this research abstract : { abstract } Your task : Identify the Bit , Flip , and Spark from the abstract in a ** detailed ** manner :</li>
</ol>
<p>Figure 3 :
3
Figure 3: Comparative analysis of the quality of generated hypotheses across nine experiments as evaluated by an LLM Judge o3-mini.</p>
<p>Table 1 :
1
Automated evaluation metrics comparing different model outputs.IAScore measures idea alignment with source material, while the Idea Distinctness Index quantifies the uniqueness of generated hypotheses.
ModelPerplexity IAScore Idea Distinctness IndexGold Outputs89.31--Before FinetuningLLaMA 3.1 8B16.700.27810.6669R1 Distilled LlaMA 3.1 8B19.850.60490.7146After FinetuningLLaMA 3.1 8B -FT32.410.67460.6297R1 Distilled LlaMA 3.1 8B -FT34.980.67290.6288</p>
<p>-Use only evidence from the paper text , don ' t quote it but rephrase it in a more concise form . -Be very specific and clear about methodological details .Integrate technical and methodological details in a reflective style that explains and justifies each inquiry .-You can use parts of the provided Bit or Flip , but do not incorporate their text verbatim .-Do not use generic phrases such as The Bit suggests ... a l w a y s use the actual content of the Bit .-Only citations referenced in the paper are allowed .Do not make up citations .-Keep the notebook concise and with great logical flow , with a maximum of ten relatively short sentences , optimally .Do not use overlong sentences .-When specific methods or models are mentioned , incorporate further context provided in the paper text to strengthen your analysis .-Include discussion of experimental results and additional probing questions related to experimental design , data analysis , and validation .-Do not mention you experienced an " Eureka !" moment , but provide a question or reflection that clearly highlights a breakthrough insight akin to a turning point .-The output needs to be in continuous flow , for example , no bullet points or numbered lists .-Have good grammar , syntax and punctuation .
Bit : { bit }Flip : { flip }Paper text :{ paper_text }Return ONLY the JSON below ( no other text ):{{" notebook ": scientist_notebook}}"""\ appendix\ section { Prompts Used in Experiments }\ subsection { Abstract -Level Analysis Prompt }\ begin { lstlisting }[ breaklines = true , basicstyle =\ small \ ttfamily ]ABSTRACT_PROMPT = """..."""A.3 Evaluation Promptprompt = f """I need you to evaluate two different proposed solutions to a problem . I 'll provide the problem statement and two options (A and B) , each witha " Spark " ( the core idea ) and a " Chain of Reasoning " ( detailedexplanation ).PROBLEM :{ problem }OPTION A:Spark : { option_a [' spark ']}Chain of Reasoning : { option_a [' chain ']}
Our code implementation is publicly available at github.com/UniverseTBD/hypogen-cs.
https://web.stanford.edu/class/cs197c/slides/02-literature-search.pdf
. ** Flip ( Innovation ) **: -Provide at least ** two ** sentences describing the ** novel approach ** or perspective .
AcknowledgmentsThe authors are deeply grateful to Dr. Charles F. McMillan, whose encouragement to pursue bold ideas inspired this work, and we dedicate this study to him.We thank Microsoft Research and the Microsoft Accelerating Foundation Models Research program for their continuous support and for providing the OpenAI credits used to generate the HypoGen outputs.We also thank the Oak Ridge Leadership Computing Facility for access to highperformance computing resources that supported this research.A Appendix: Prompts used in the analysisA.1 Abstract-Level Bit-Flip-Spark Prompt ABSTRACT_PROMPT = """ You are a highly advanced research assistant , specialized in reading scientific papers for hypothesis generation and identifying innovative ideas .Before you begin , let ' s revisit the Bit -Flip concept with an example ( BERT in NLP ):Bit : Traditional NLP models ( RNNs , LSTMs ) process text sequentially , limiting their ability to understand long -range dependencies and fully capture bidirectional context .Flip : Instead , consider entire sentences at once , allowing context from both directions .This helps capture nuanced relationships among words .Spark : Bidirectional context for NLP .Bit -Flip Defined :A Bit -Flip inverts a commonly held assumption , questioning existing constraints or reapplying techniques to new domains / scales .The " Bit " is the prevailing belief , and the " Flip " is the counterargument .Then provide a brief explanation of your reasoning (2 -3 sentences )."""A.5.3 R1-distilled-LLaMA-1shotI recognized the challenge of costly labeled datasets in information retrieval.I hypothesized that pre-trained models could offer a foundation for new domains without extensive fine-tuning.I explored transfer learning strategies to adapt these models to specific tasks, testing domain adaptation techniques for better generalization.I also considered self-supervised learning to leverage unlabeled data and enhance robustness across distributions.Through empirical validation, I demonstrated that these approaches significantly reduced dependency on large datasets while maintaining performance.A.5.4 R1-distilled-LLaMA-FTI first asked how to train retrieval models without relying on large labeled datasets, and I tested a few approaches that only use unlabeled text.I hypothesized that self-supervised methods could offer a more efficient training path, so I designed a pipeline that first pre-trained a retrieval model on unlabeled text and then used a small labeled subset to refine it.I observed that this approach improved retrieval performance over methods that solely used labeled data, especially in domains with limited labeled samples.To validate this conclusion, I conducted multiple experiments on diverse domains, measuring retrieval accuracy and efficiency.I noticed that the pre-training phase was crucial for capturing general patterns, while the refinement step fine-tuned the model to better match specific labels.I then asked if this approach would generalize across different datasets and found consistent improvements across multiple benchmark sets.I tested the model on a domain with a large labeled set and observed that it performed as well as the fine-tuned model, indicating that the self-supervised pre-training was sufficient.I also questioned whether the refinement step was truly necessary and found that omitting it degraded retrieval performance.In analyzing the data, I realized that the small labeled subset was vital for aligning the model with the target tasks, confirming the importance of both pre-training and refinement.I then considered whether the approach would remain robust if the labeled subset was too small, and the results indicated that it still performed adequately.Ultimately, I concluded that combining self-supervised pre-training with a small labeled refinement step is an effective and efficient method for training retrieval models in diverse domains.and efficient method for training retrieval models in diverse domains.
Anthony Michael Ahn, Noah Brohan, Yevgen Brown, Omar Chebotar, Byron Cortes, Chelsea David, Chuyuan Finn, Keerthana Fu, Karol Gopalakrishnan, Hausman, arXiv:2204.01691Do as i can, not as i say: Grounding language in robotic affordances. 2022arXiv preprint</p>
<p>How faithful is your synthetic data? sample-level metrics for evaluating and auditing generative models. Ahmed M Alaa, Boris Van Breugel, Evgeny S Saveliev, Mihaela Van Der Schaar, International Conference on Machine Learning. 2021</p>
<p>Neural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)2015</p>
<p>Science in the age of large language models. Abeba Birhane, Atoosa Kasirzadeh, David Leslie, Sandra Wachter, Nature Reviews Physics. 52023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Mle-bench: Evaluating machine learning agents on machine learning engineering. Neil Jun Shern Chan, Oliver Chowdhury, James Jaffe, Dane Aung, Evan Sherburn, Giulio Mays, Kevin Starace, Leon Liu, Tejal Maksin, Patwardhan, arXiv:2410.07095arXiv:2107.033742024. 2021arXiv preprintet al. Evaluating large language models trained on code</p>
<p>Evaluation metrics for language models. Douglas Stanley F Chen, Roni Beeferman, Rosenfeld, 1998</p>
<p>Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, Yifei Li, Zeyi Liao, Chen Wei, Zitong Lu, arXiv:2410.05080Toward rigorous assessment of language agents for data-driven scientific discovery. 2024arXiv preprint</p>
<p>Vasileios Sitokonstantinou, Gherardo Varando, and Gustau Camps-Valls. Large language models for causal hypothesis generation in science. Kai-Hendrik Cohrs, Emiliano Diaz, Machine Learning: Science and Technology. 61130012025</p>
<p>Bert: Pretraining of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>Simona Doboli, Fanshu Zhao, Alex Doboli, arXiv:1406.7582New measures for evaluating creativity in scientific publications. 2014arXiv preprint</p>
<p>Can gpt-3 pass a writers turing test. Katherine Elkins, Jon Chun, Journal of Cultural Analytics. 522020</p>
<p>Towards an ai co-scientist. Juraj Gottweis, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom Myaskovsky, Felix Weissenberger, Keran Rong, Ryutaro Tanno, arXiv:2502.188642025arXiv preprint</p>
<p>The llama 3 herd of models. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, arXiv:2407.217832024arXiv preprint</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992Reasoning with language model is planning with world model. 2023arXiv preprint</p>
<p>The curious case of neural text degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, ArXiv, abs/1904.097512019</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021arXiv preprint</p>
<p>Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents. Peter Alexander Jansen, Marc-Alexandre Cot'e, Tushar Khot, Erin Bransom, Bhavana Dalvi, Prasad Bodhisattwa, Oyvind Majumder, Peter Tafjord, Clark, ArXiv, abs/2406.067692024270380311</p>
<p>Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. Taku Kudo, John Richardson, arXiv:1808.062262018arXiv preprint</p>
<p>Can large language models unlock novel scientific research ideas?. Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal, arXiv:2409.061852024arXiv preprint</p>
<p>Halueval: A large-scale hallucination evaluation benchmark for large language models. Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jianyun Nie, Ji Rong, Wen , ArXiv, abs/2305.117472023</p>
<p>Contrastive decoding: Open-ended text generation as optimization. Lisa Xiang, Ari Li, Daniel Holtzman, Percy Fried, Jason Liang, Tatsunori Eisner, Luke Hashimoto, Mike Zettlemoyer, Lewis, Annual Meeting of the Association for Computational Linguistics. 2022</p>
<p>Improving knowledge extraction from llms for robotic task learning through agent analysis. R James, Wray Lindes, Peter, arXiv:2306.067702023arXiv preprint</p>
<p>Can a transformer pass the wug test? tuning copying bias in neural morphological inflection models. Ling Liu, Mans Hulden, ArXiv, abs/2104.064832021</p>
<p>Ilya Loshchilov, Frank Hutter, arXiv:1711.05101Decoupled weight decay regularization. 2017arXiv preprint</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha, arXiv:2408.062922024aarXiv preprint</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob N Foerster, Jeff Clune, David Ha, ArXiv, abs/2408.062922024b</p>
<p>Llm4sr: A survey on large language models for scientific research. Ziming Luo, Zonglin Yang, Zexin Xu, Wei Yang, Xinya Du, 2025</p>
<p>Discoverybench: Towards data-driven discovery with large language models. Prasad Bodhisattwa, Harshit Majumder, Dhruv Surana, Bhavana Agarwal, Abhijeetsingh Dalvi, Aryan Meena, Tirth Prakhar, Tushar Vora, Ashish Khot, Peter Sabharwal, Clark, ArXiv, abs/2407.017252024</p>
<p>Selfcheckgpt: Zeroresource black-box hallucination detection for generative large language models. Potsawee Manakul, Adian Liusie, Mark John, Francis Gales, ArXiv, abs/2303.088962023</p>
<p>How much do language models copy from their training data? evaluating linguistic novelty in text generation using raven. R Thomas Mccoy, Paul Smolensky, Tal Linzen, Jianfeng Gao, Asli Celikyilmaz, Transactions of the Association for Computational Linguistics. 112021</p>
<p>Sources of hallucination by large language models on inference tasks. Nick Mckenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini, Mark Johnson, Mark Steedman, ArXiv, abs/2305.145522023</p>
<p>Typical decoding for natural language generation. Clara Meister, Tiago Pimentel, Gian Wiher, Ryan Cotterell, ArXiv, abs/2202.006662022246442062</p>
<p>Deepak Nathani, Lovish Madaan, Nicholas Roberts, Nikolay Bashlykov, Ajay Menon, Vincent Moens, Amar Budhiraja, Despoina Magka, Vladislav Vorotilov, Gaurav Chaurasia, arXiv:2502.14499A new framework and benchmark for advancing ai research agents. 2025arXiv preprint</p>
<p>Numeracy from literacy: Data science as an emergent skill from large language models. David Noever, Forrest Mckee, ArXiv, abs/2301.133822023256416333</p>
<p>Large language models are zero shot hypothesis proposers. Biqing Qi, Kaiyan Zhang, Haoxiang Li, Kai Tian, Sihang Zeng, Zhangren Chen, Bowen Zhou, ArXiv, abs/2311.059652023</p>
<p>The standard definition of creativity. A Mark, Garrett J Runco, Jaeger, Creativity research journal. 2412012</p>
<p>Samuel Schmidgall, Michael Moor, arXiv:2503.18102Agentrxiv: Towards collaborative autonomous research. 2025arXiv preprint</p>
<p>Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, Emad Barsoum, arXiv:2501.04227Agent laboratory: Using llm agents as research assistants. 2025arXiv preprint</p>
<p>Neural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, Alexandra Birch, ArXiv, abs/1508.079092015</p>
<p>Collaborative gym: A framework for enabling and evaluating human-agent collaboration. Yijia Shao, Vinay Samuel, Yucheng Jiang, John Yang, Diyi Yang, ArXiv, abs/2412.157012024</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, arXiv:2303.113662023arXiv preprint</p>
<p>Can llms generate novel research ideas? a large-scale human study with 100+ nlp researchers. Chenglei Si, Diyi Yang, Tatsunori Hashimoto, arXiv:2409.041092024arXiv preprint</p>
<p>Creativity in science: Chance, logic, genius, and zeitgeist. Dean Keith, Simonton , 2004Cambridge University Press</p>
<p>Creativity in science-scientific essay. Heidi Angell, Strøm , 2018</p>
<p>A contrastive framework for neural text generation. Yixuan Su, Tian Lan, Yan Wang, Dani Yogatama, Lingpeng Kong, Nigel Collier, ArXiv, abs/2202.064172022246823043</p>
<p>The virtual lab: Ai agents design new sars-cov-2 nanobodies with experimental validation. Kyle Swanson, Wesley Wu, L Nash, John E Bulaong, James Pak, Zou, 10.1101/2024.11.11.623004bioRxiv. 2024</p>
<p>Gemini: a family of highly capable multimodal models. Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican, arXiv:2312.118052023arXiv preprint</p>
<p>S M Towhidul Islam Tonmoy, S M Mehedi Zaman, Vinija Jain, Anku Rani, Aman Vipula Rawte, Amitava Chadha, Das, arXiv:2401.01313A comprehensive survey of hallucination mitigation techniques in large language models. 2024arXiv preprint</p>
<p>Scimon: Scientific inspiration machines optimized for novelty. Qingyun Wang, Doug Downey, Heng Ji, Tom Hope, Annual Meeting of the Association for Computational Linguistics. 2023</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712022arXiv preprint</p>
<p>Large language models as master key: Unlocking the secrets of materials science with gpt. Tong Xie, Yuwei Wan, Wei Huang, Yufei Zhou, Yixuan Liu, Qingyuan, Shaozhou Linghu, Chunyu Wang, Clara Kit, W Grazian, Zhang, Bram, Hoex, ArXiv, abs/2304.022132023</p>
<p>Improving scientific hypothesis generation with knowledge grounded large language models. Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang, ArXiv, abs/2411.023822024a</p>
<p>Improving scientific hypothesis generation with knowledge grounded large language models. Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang, arXiv:2411.023822024barXiv preprint</p>
<p>Keep calm and explore: Language models for action generation in text-based games. Shunyu Yao, Rohan Rao, Matthew Hausknecht, Karthik Narasimhan, arXiv:2010.029032020arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>User-controlled knowledge fusion in large language models: Balancing creativity and hallucination. Chen Zhang, ArXiv, abs/2307.161392023260334043</p>
<p>Hypothesis generation with large language models. Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, Chenhao Tan, ArXiv, abs/2404.043262024a</p>
<p>Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, Chenhao Tan, arXiv:2404.04326Hypothesis generation with large language models. 2024barXiv preprint</p>
<p>Can large language models transform computational social science?. Caleb Ziems, William B Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, Diyi Yang, ArXiv, abs/2305.035142023</p>            </div>
        </div>

    </div>
</body>
</html>