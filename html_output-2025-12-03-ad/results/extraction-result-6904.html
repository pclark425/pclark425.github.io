<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6904 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6904</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6904</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-220830873</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2007.13840v2.pdf" target="_blank">Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior</a></p>
                <p><strong>Paper Abstract:</strong> Semantic feature models have become a popular tool for prediction and interpretation of fMRI data. In particular, prior work has shown that differences in the fMRI patterns in sentence reading can be explained by context-dependent changes in the semantic feature representations of the words. However, whether the subjects are aware of such changes and agree with them has been an open question. This paper aims to answer this question through a human-subject study. Subjects were asked to judge how the word change from their generic meaning when the words were used in specific sentences. The judgements were consistent with the model predictions well above chance. Thus, the results support the hypothesis that word meaning change systematically depending on sentence context.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6904.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6904.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept Attributes Representation (CAR) / Experiential attribute representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A brain‑based, componential semantic representation that models each concept as a 66‑dimensional vector of modality‑specific experiential attributes (sensory, motor, affective, spatial, temporal, social, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward a brainbased componential semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Concept Attributes Representation (CAR)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as a fixed‑length vector whose components correspond to neurobiologically motivated modalities/attributes (e.g., vision, touch, motion, social cognition, affect). Each component's magnitude encodes strength of association between that attribute/neural system and the concept.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how modality‑specific neural systems instantiate concept features; supports interpreting distributed neural activity as weighted combinations of attributes; allows context to reweight attributes to produce context‑sensitive meanings.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI data (sentence imaging), human attribute rating datasets (crowdsourced CAR ratings), computational simulation (mapping CARs to fMRI)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>fMRI sentence reading; aggregate SynthWord and SynthSent fMRI representations; semantic attribute rating collection (Mechanical Turk); human semantic‑feature change judgement survey (more/less/neutral)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>CAR vectors (66‑dimensional) can be adjusted by CEREBRA to predict sentence fMRI patterns, and these context‑adjusted CARs correspond to human judgements of attribute change above chance.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Human behavioural judgements are noisy (inter‑rater agreement ~47%) and model–human agreement gain is modest (~9% above a simple chance baseline); authors note need for more balanced stimuli and word‑level fMRI to strengthen claims.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder et al., 2016; Aguirre-Celis & Miikkulainen, 2017/2018/2019</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6904.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6904.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CEREBRA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Context-dependent mEaning REPresentation in the BRAin (CEREBRA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural network model that adjusts CAR input vectors per sentence context by fitting predicted sentence fMRI to observed fMRI using FGREP backpropagation, thereby producing context‑specific word representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>From Words to Sentences & Back: Characterizing Context-dependent Meaning Rep in the Brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>CEREBRA (contextual change model of CARs)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>computational feature‑based/vector transformation (neural network)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>CEREBRA maps CAR word vectors through a trained network to predicted sentence fMRI; for each sentence it backpropagates error while freezing network weights and changing only CAR components (FGREP), producing context‑adjusted CAR vectors for words.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Contextual meaning arises by reweighting feature components of a concept's CAR vector driven by sentence‑level neural signals; these reweighted vectors capture context effects present in brain activity and are meaningful to humans.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulation (neural network training and FGREP reweighting), fMRI sentence data, behavioural human survey validation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Train mapping CAR→fMRI on sentence data; FGREP per‑sentence backprop to adjust CARs; test predicted attribute changes against human judgments from a crowdsourced survey.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>CEREBRA's context‑adjusted CARs matched human judgements on a subset of reliable questions at 54% vs. a 45% chance baseline (statistically significant across subjects), showing systematic context effects.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Effect size over baseline is modest (≈9%) and depends on selecting questions with sufficient inter‑rater reliability; results limited to sentence fMRI and averaged SynthWord representations rather than isolated word fMRI.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Aguirre-Celis & Miikkulainen, 2017/2018/2019</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6904.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6904.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FGREP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Forming Global Representations with Extended Backpropagation (FGREP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A training procedure where network weights are held fixed while inputs (here CAR word vectors) are adjusted via backpropagation to reduce error between network output and target patterns; used to derive context‑specific input representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Natural Language Processing with Modular PDP Networks and Distributed Lexicon</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>FGREP (input‑adjustment backpropagation method)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>algorithmic/learning procedure for vector representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Instead of tuning network weights, FGREP holds weights constant and backpropagates output error to modify input vectors, thereby forming context‑specific input encodings that better match observed targets (e.g., fMRI patterns).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Enables deriving context‑sensitive modifications of conceptual feature vectors that reflect observed output patterns without changing the mapping function; supports building revised input representations aligned with neural data.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulation; applied here to fMRI prediction task</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Train feedforward network mapping CARs→fMRI; for each sentence, run FGREP to update CAR inputs to minimize sentence fMRI error; aggregate adjusted inputs into SynthWord/SynthSent.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>FGREP produced consistent context‑adjusted CAR variants across multiple training seeds and subjects, enabling CEREBRA to predict attribute change patterns reflected in fMRI and human judgements.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>No direct contradictions reported here, but approach assumes the mapping weights are correct and that input adjustment is an appropriate model of brain reweighting; dependence on averaged SynthWord signals may limit specificity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Miikkulainen & Dyer, 1991; Aguirre-Celis & Miikkulainen, 2017/2018/2019</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6904.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6904.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DSM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributional Semantic Models (DSM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Models that derive conceptual representations from statistical co‑occurrence patterns in text (high‑dimensional distributional vectors) rather than grounding them in perceptual/motor neural systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Composition in distributional models of semantics</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Distributional Semantic Models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional distributional vector (text‑based)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is encoded as vector embeddings learned from word co‑occurrence statistics in large text corpora; semantic relatedness and composition arise from algebraic operations on these vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Can capture semantic similarity and composition from linguistic experience, predict word co‑occurrence based relationships, and be used to model many behavioral semantics tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational modeling and behavioral benchmarks (cited in literature), contrasted here with CAR/brain‑based evidence</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Text corpora training, similarity/relatedness benchmarks; contrasted in this paper with fMRI mapping of CARs</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Authors argue DSMs are not grounded in perception/motor mechanisms and their representations are not directly interpretable neurobiologically, unlike CARs which correspond to modality‑specific neural systems.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Paper asserts DSMs lack interpretability and grounding in neural systems; no direct empirical contradiction presented here, but DSMs are acknowledged as powerful for language‑based semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Mitchell & Lapata, 2010; Aguirre-Celis & Miikkulainen, present paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6904.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6904.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual combination</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual combination (theory)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theoretical account that when concepts are combined in context, attributes from constituent concepts are reweighted or instantiated differently to form a combined meaning (e.g., property inheritance, emergent properties).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual combination</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Conceptual combination</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature‑based / compositional reweighting theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Combination of concepts (e.g., 'pet fish') leads to a new representation produced by selective weighting, suppression or emergence of attributes from the constituents; attribute centrality and contextual relevance determine final weights.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how novel compound meanings arise, why some properties are preserved or suppressed, and predicts context‑dependent attribute salience.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral studies on concept combination, cited literature; here used as a theoretical motivation for context‑dependent CAR adjustments</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Property‑rating tasks, conceptual combination behavioral experiments; in this paper, analogized to sentence context effects tested via fMRI and surveys</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Paper uses conceptual combination literature to motivate why certain CAR attributes increase/decrease in sentence contexts and as background for interpreting CEREBRA adjustments.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>No direct contradictory evidence in this paper; authors note variability and noisy human judgements which complicate measurement of fine conceptual‑combination effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Hampton, 1996/1997; Wisniewsky, 1998; Medin & Shoben, 1988; Aguirre-Celis & Miikkulainen, present paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6904.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6904.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Contextual modulation / Attribute centrality</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Contextual modulation / Attribute centrality theories</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The idea that the relevance (weight) of semantic attributes for a concept is modulated by context, and that some attributes are more central to certain concepts (attribute centrality).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Contextual modulation / Attribute centrality</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature‑weighting / dynamic feature representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual representations consist of attributes whose weights are dynamically adjusted by contextual information; central attributes resist change while peripheral attributes fluctuate more with context.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for graded typicality, context‑sensitive property activation, and differences in which features change across contexts and concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral literature (classic cognitive studies) and used here to interpret fMRI/CEREBRA findings</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Semantic feature rating, contextual property verification; in this paper, operationalized via CAR adjustments and human 'more/less/neutral' attribute judgements plus fMRI sentence reading.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Used to justify why some CAR attributes consistently increase across contexts and why direction alone is insufficient — leading to relative measures used in model–human comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Paper notes systematic increases for some attributes across contexts (central attributes) which complicate simple direction‑of‑change predictions; no direct contradiction but highlights measurement challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Barclay et al., 1974; Medin & Shoben, 1988; Aguirre-Celis & Miikkulainen, present paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6904.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6904.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sentence-level common core representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sentence-level common/core distributed representation (neural-network / distributed brain representation view)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The hypothesis that sentence comprehension involves constructing a common core representation that integrates multiple word meanings across distributed brain regions; supports averaging across contexts to form generic word representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting Neural activity patterns associated with sentences using neurobiologically motivated model of semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Sentence-level common core distributed representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>distributed network / high‑dimensional integrated representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Comprehension constructs a sentence‑level network where multiple word meanings combine into a shared distributed pattern; this integrated representation can be used to infer how sentence context modifies individual word representations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains why averaging activity across multiple sentence contexts may approximate a 'generic' word representation, and why sentence context yields shared neural signatures across words.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI studies of sentence comprehension (cited Neuroimaging work), computational mapping (Anderson et al., 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>fMRI sentence reading and pattern prediction; network analyses of sentence‑level activation patterns</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Cited neurological evidence motivates one of the CEREBRA measurement approaches — averaging SynthWord activations across contexts to form generic representations and then measuring relative changes.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Not contradicted here, but authors note that using averaged sentence data (SynthWord) rather than isolated word fMRI may limit specificity and recommends future studies with single‑word fMRI.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Anderson et al., 2016; Gennari et al., 2007; Aguirre-Celis & Miikkulainen, present paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Toward a brainbased componential semantic representation <em>(Rating: 2)</em></li>
                <li>Predicting Neural activity patterns associated with sentences using neurobiologically motivated model of semantic representation <em>(Rating: 2)</em></li>
                <li>Natural Language Processing with Modular PDP Networks and Distributed Lexicon <em>(Rating: 2)</em></li>
                <li>From Words to Sentences & Back: Characterizing Context-dependent Meaning Rep in the Brain <em>(Rating: 2)</em></li>
                <li>Combining fMRI Data and Neural Networks to Quantify Contextual Effects in the Brain <em>(Rating: 2)</em></li>
                <li>Composition in distributional models of semantics <em>(Rating: 1)</em></li>
                <li>Conceptual combination <em>(Rating: 1)</em></li>
                <li>Context and structure in conceptual combination <em>(Rating: 1)</em></li>
                <li>Context-dependent interpretation of words: Evidence for interactive neural processes <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6904",
    "paper_id": "paper-220830873",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "CAR",
            "name_full": "Concept Attributes Representation (CAR) / Experiential attribute representation",
            "brief_description": "A brain‑based, componential semantic representation that models each concept as a 66‑dimensional vector of modality‑specific experiential attributes (sensory, motor, affective, spatial, temporal, social, etc.).",
            "citation_title": "Toward a brainbased componential semantic representation",
            "mention_or_use": "use",
            "theory_name": "Concept Attributes Representation (CAR)",
            "theory_type": "feature-based vector",
            "theory_description": "Conceptual knowledge is represented as a fixed‑length vector whose components correspond to neurobiologically motivated modalities/attributes (e.g., vision, touch, motion, social cognition, affect). Each component's magnitude encodes strength of association between that attribute/neural system and the concept.",
            "functional_claims": "Explains how modality‑specific neural systems instantiate concept features; supports interpreting distributed neural activity as weighted combinations of attributes; allows context to reweight attributes to produce context‑sensitive meanings.",
            "evidence_source": "fMRI data (sentence imaging), human attribute rating datasets (crowdsourced CAR ratings), computational simulation (mapping CARs to fMRI)",
            "experimental_paradigm": "fMRI sentence reading; aggregate SynthWord and SynthSent fMRI representations; semantic attribute rating collection (Mechanical Turk); human semantic‑feature change judgement survey (more/less/neutral)",
            "key_result": "CAR vectors (66‑dimensional) can be adjusted by CEREBRA to predict sentence fMRI patterns, and these context‑adjusted CARs correspond to human judgements of attribute change above chance.",
            "supports_theory": true,
            "counter_evidence": "Human behavioural judgements are noisy (inter‑rater agreement ~47%) and model–human agreement gain is modest (~9% above a simple chance baseline); authors note need for more balanced stimuli and word‑level fMRI to strengthen claims.",
            "citation": "Binder et al., 2016; Aguirre-Celis & Miikkulainen, 2017/2018/2019",
            "uuid": "e6904.0",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "CEREBRA",
            "name_full": "Context-dependent mEaning REPresentation in the BRAin (CEREBRA)",
            "brief_description": "A neural network model that adjusts CAR input vectors per sentence context by fitting predicted sentence fMRI to observed fMRI using FGREP backpropagation, thereby producing context‑specific word representations.",
            "citation_title": "From Words to Sentences & Back: Characterizing Context-dependent Meaning Rep in the Brain",
            "mention_or_use": "use",
            "theory_name": "CEREBRA (contextual change model of CARs)",
            "theory_type": "computational feature‑based/vector transformation (neural network)",
            "theory_description": "CEREBRA maps CAR word vectors through a trained network to predicted sentence fMRI; for each sentence it backpropagates error while freezing network weights and changing only CAR components (FGREP), producing context‑adjusted CAR vectors for words.",
            "functional_claims": "Contextual meaning arises by reweighting feature components of a concept's CAR vector driven by sentence‑level neural signals; these reweighted vectors capture context effects present in brain activity and are meaningful to humans.",
            "evidence_source": "computational simulation (neural network training and FGREP reweighting), fMRI sentence data, behavioural human survey validation",
            "experimental_paradigm": "Train mapping CAR→fMRI on sentence data; FGREP per‑sentence backprop to adjust CARs; test predicted attribute changes against human judgments from a crowdsourced survey.",
            "key_result": "CEREBRA's context‑adjusted CARs matched human judgements on a subset of reliable questions at 54% vs. a 45% chance baseline (statistically significant across subjects), showing systematic context effects.",
            "supports_theory": true,
            "counter_evidence": "Effect size over baseline is modest (≈9%) and depends on selecting questions with sufficient inter‑rater reliability; results limited to sentence fMRI and averaged SynthWord representations rather than isolated word fMRI.",
            "citation": "Aguirre-Celis & Miikkulainen, 2017/2018/2019",
            "uuid": "e6904.1",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "FGREP",
            "name_full": "Forming Global Representations with Extended Backpropagation (FGREP)",
            "brief_description": "A training procedure where network weights are held fixed while inputs (here CAR word vectors) are adjusted via backpropagation to reduce error between network output and target patterns; used to derive context‑specific input representations.",
            "citation_title": "Natural Language Processing with Modular PDP Networks and Distributed Lexicon",
            "mention_or_use": "use",
            "theory_name": "FGREP (input‑adjustment backpropagation method)",
            "theory_type": "algorithmic/learning procedure for vector representations",
            "theory_description": "Instead of tuning network weights, FGREP holds weights constant and backpropagates output error to modify input vectors, thereby forming context‑specific input encodings that better match observed targets (e.g., fMRI patterns).",
            "functional_claims": "Enables deriving context‑sensitive modifications of conceptual feature vectors that reflect observed output patterns without changing the mapping function; supports building revised input representations aligned with neural data.",
            "evidence_source": "computational simulation; applied here to fMRI prediction task",
            "experimental_paradigm": "Train feedforward network mapping CARs→fMRI; for each sentence, run FGREP to update CAR inputs to minimize sentence fMRI error; aggregate adjusted inputs into SynthWord/SynthSent.",
            "key_result": "FGREP produced consistent context‑adjusted CAR variants across multiple training seeds and subjects, enabling CEREBRA to predict attribute change patterns reflected in fMRI and human judgements.",
            "supports_theory": true,
            "counter_evidence": "No direct contradictions reported here, but approach assumes the mapping weights are correct and that input adjustment is an appropriate model of brain reweighting; dependence on averaged SynthWord signals may limit specificity.",
            "citation": "Miikkulainen & Dyer, 1991; Aguirre-Celis & Miikkulainen, 2017/2018/2019",
            "uuid": "e6904.2",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "DSM",
            "name_full": "Distributional Semantic Models (DSM)",
            "brief_description": "Models that derive conceptual representations from statistical co‑occurrence patterns in text (high‑dimensional distributional vectors) rather than grounding them in perceptual/motor neural systems.",
            "citation_title": "Composition in distributional models of semantics",
            "mention_or_use": "mention",
            "theory_name": "Distributional Semantic Models",
            "theory_type": "high-dimensional distributional vector (text‑based)",
            "theory_description": "Conceptual knowledge is encoded as vector embeddings learned from word co‑occurrence statistics in large text corpora; semantic relatedness and composition arise from algebraic operations on these vectors.",
            "functional_claims": "Can capture semantic similarity and composition from linguistic experience, predict word co‑occurrence based relationships, and be used to model many behavioral semantics tasks.",
            "evidence_source": "computational modeling and behavioral benchmarks (cited in literature), contrasted here with CAR/brain‑based evidence",
            "experimental_paradigm": "Text corpora training, similarity/relatedness benchmarks; contrasted in this paper with fMRI mapping of CARs",
            "key_result": "Authors argue DSMs are not grounded in perception/motor mechanisms and their representations are not directly interpretable neurobiologically, unlike CARs which correspond to modality‑specific neural systems.",
            "supports_theory": null,
            "counter_evidence": "Paper asserts DSMs lack interpretability and grounding in neural systems; no direct empirical contradiction presented here, but DSMs are acknowledged as powerful for language‑based semantics.",
            "citation": "Mitchell & Lapata, 2010; Aguirre-Celis & Miikkulainen, present paper",
            "uuid": "e6904.3",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "Conceptual combination",
            "name_full": "Conceptual combination (theory)",
            "brief_description": "A theoretical account that when concepts are combined in context, attributes from constituent concepts are reweighted or instantiated differently to form a combined meaning (e.g., property inheritance, emergent properties).",
            "citation_title": "Conceptual combination",
            "mention_or_use": "mention",
            "theory_name": "Conceptual combination",
            "theory_type": "feature‑based / compositional reweighting theory",
            "theory_description": "Combination of concepts (e.g., 'pet fish') leads to a new representation produced by selective weighting, suppression or emergence of attributes from the constituents; attribute centrality and contextual relevance determine final weights.",
            "functional_claims": "Explains how novel compound meanings arise, why some properties are preserved or suppressed, and predicts context‑dependent attribute salience.",
            "evidence_source": "behavioral studies on concept combination, cited literature; here used as a theoretical motivation for context‑dependent CAR adjustments",
            "experimental_paradigm": "Property‑rating tasks, conceptual combination behavioral experiments; in this paper, analogized to sentence context effects tested via fMRI and surveys",
            "key_result": "Paper uses conceptual combination literature to motivate why certain CAR attributes increase/decrease in sentence contexts and as background for interpreting CEREBRA adjustments.",
            "supports_theory": true,
            "counter_evidence": "No direct contradictory evidence in this paper; authors note variability and noisy human judgements which complicate measurement of fine conceptual‑combination effects.",
            "citation": "Hampton, 1996/1997; Wisniewsky, 1998; Medin & Shoben, 1988; Aguirre-Celis & Miikkulainen, present paper",
            "uuid": "e6904.4",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "Contextual modulation / Attribute centrality",
            "name_full": "Contextual modulation / Attribute centrality theories",
            "brief_description": "The idea that the relevance (weight) of semantic attributes for a concept is modulated by context, and that some attributes are more central to certain concepts (attribute centrality).",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Contextual modulation / Attribute centrality",
            "theory_type": "feature‑weighting / dynamic feature representation",
            "theory_description": "Conceptual representations consist of attributes whose weights are dynamically adjusted by contextual information; central attributes resist change while peripheral attributes fluctuate more with context.",
            "functional_claims": "Accounts for graded typicality, context‑sensitive property activation, and differences in which features change across contexts and concepts.",
            "evidence_source": "behavioral literature (classic cognitive studies) and used here to interpret fMRI/CEREBRA findings",
            "experimental_paradigm": "Semantic feature rating, contextual property verification; in this paper, operationalized via CAR adjustments and human 'more/less/neutral' attribute judgements plus fMRI sentence reading.",
            "key_result": "Used to justify why some CAR attributes consistently increase across contexts and why direction alone is insufficient — leading to relative measures used in model–human comparisons.",
            "supports_theory": true,
            "counter_evidence": "Paper notes systematic increases for some attributes across contexts (central attributes) which complicate simple direction‑of‑change predictions; no direct contradiction but highlights measurement challenges.",
            "citation": "Barclay et al., 1974; Medin & Shoben, 1988; Aguirre-Celis & Miikkulainen, present paper",
            "uuid": "e6904.5",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "Sentence-level common core representation",
            "name_full": "Sentence-level common/core distributed representation (neural-network / distributed brain representation view)",
            "brief_description": "The hypothesis that sentence comprehension involves constructing a common core representation that integrates multiple word meanings across distributed brain regions; supports averaging across contexts to form generic word representations.",
            "citation_title": "Predicting Neural activity patterns associated with sentences using neurobiologically motivated model of semantic representation",
            "mention_or_use": "mention",
            "theory_name": "Sentence-level common core distributed representation",
            "theory_type": "distributed network / high‑dimensional integrated representation",
            "theory_description": "Comprehension constructs a sentence‑level network where multiple word meanings combine into a shared distributed pattern; this integrated representation can be used to infer how sentence context modifies individual word representations.",
            "functional_claims": "Explains why averaging activity across multiple sentence contexts may approximate a 'generic' word representation, and why sentence context yields shared neural signatures across words.",
            "evidence_source": "fMRI studies of sentence comprehension (cited Neuroimaging work), computational mapping (Anderson et al., 2016)",
            "experimental_paradigm": "fMRI sentence reading and pattern prediction; network analyses of sentence‑level activation patterns",
            "key_result": "Cited neurological evidence motivates one of the CEREBRA measurement approaches — averaging SynthWord activations across contexts to form generic representations and then measuring relative changes.",
            "supports_theory": true,
            "counter_evidence": "Not contradicted here, but authors note that using averaged sentence data (SynthWord) rather than isolated word fMRI may limit specificity and recommends future studies with single‑word fMRI.",
            "citation": "Anderson et al., 2016; Gennari et al., 2007; Aguirre-Celis & Miikkulainen, present paper",
            "uuid": "e6904.6",
            "source_info": {
                "paper_title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior",
                "publication_date_yy_mm": "2020-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Toward a brainbased componential semantic representation",
            "rating": 2,
            "sanitized_title": "toward_a_brainbased_componential_semantic_representation"
        },
        {
            "paper_title": "Predicting Neural activity patterns associated with sentences using neurobiologically motivated model of semantic representation",
            "rating": 2,
            "sanitized_title": "predicting_neural_activity_patterns_associated_with_sentences_using_neurobiologically_motivated_model_of_semantic_representation"
        },
        {
            "paper_title": "Natural Language Processing with Modular PDP Networks and Distributed Lexicon",
            "rating": 2,
            "sanitized_title": "natural_language_processing_with_modular_pdp_networks_and_distributed_lexicon"
        },
        {
            "paper_title": "From Words to Sentences & Back: Characterizing Context-dependent Meaning Rep in the Brain",
            "rating": 2,
            "sanitized_title": "from_words_to_sentences_back_characterizing_contextdependent_meaning_rep_in_the_brain"
        },
        {
            "paper_title": "Combining fMRI Data and Neural Networks to Quantify Contextual Effects in the Brain",
            "rating": 2,
            "sanitized_title": "combining_fmri_data_and_neural_networks_to_quantify_contextual_effects_in_the_brain"
        },
        {
            "paper_title": "Composition in distributional models of semantics",
            "rating": 1,
            "sanitized_title": "composition_in_distributional_models_of_semantics"
        },
        {
            "paper_title": "Conceptual combination",
            "rating": 1,
            "sanitized_title": "conceptual_combination"
        },
        {
            "paper_title": "Context and structure in conceptual combination",
            "rating": 1,
            "sanitized_title": "context_and_structure_in_conceptual_combination"
        },
        {
            "paper_title": "Context-dependent interpretation of words: Evidence for interactive neural processes",
            "rating": 1,
            "sanitized_title": "contextdependent_interpretation_of_words_evidence_for_interactive_neural_processes"
        }
    ],
    "cost": 0.01280425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior</p>
<p>Nora Aguirre-Celis 
Risto Miikkulainen </p>
<p>ITESM
MonterreyMexico</p>
<p>Department of Computer Science
The University of Texas at Austin
2317, 78712Speedway AustinTXUSA</p>
<p>Department of Computer Science
The University of Texas at Austin
2317, 78712Speedway AustinTXUSA</p>
<p>Characterizing the Effect of Sentence Context on Word Meanings: Mapping Brain to Behavior
08F2554CAFE9E8F93B0C03F8F2E98B6BContext EffectConcept RepresentationsfMRI Data AnalysisNeural NetworksEmbodied Cognition
Semantic feature models have become a popular tool for prediction and interpretation of fMRI data.In particular, prior work has shown that differences in the fMRI patterns in sentence reading can be explained by context-dependent changes in the semantic feature representations of the words.However, whether the subjects are aware of such changes and agree with them has been an open question.This paper aims to answer this question through a human-subject study.Subjects were asked to judge how the word change from their generic meaning when the words were used in specific sentences.The judgements were consistent with the model predictions well above chance.Thus, the results support the hypothesis that word meaning change systematically depending on sentence context.</p>
<p>Introduction</p>
<p>Semantic feature theory suggests that a word meaning is instantiated by weighting its semantic attributes according to the context.(Barclay, et.al., 1974;Hampton, 1996;Kiefer &amp; Pulvermüller 2012;Medin &amp; Shoben, 1988;Mitchell &amp; Lapata, 2010;Murphy, 1990;Wisniewsky, 1998).For example, when people think of the word football, they heavily weigh features like 'shape' and 'lower limbs' and features like 'smell' and 'size' lightly.In contrast, when they think of forest, the weighing on those features is likely to reverse.However, when the words appear in the context of a sentence such as The team lost the football in the forest, the context might bring up more unusual features like 'Landmark', 'Fearful', and 'Surprise'.Thus, when words share features, those aspects of the word representation that are relevant to the context are strengthened (Hampton, 1996;Kiefer &amp; Pulvermüller 2012;Medin &amp; Shoben, 1988;Mitchell &amp; Lapata, 2010;Murphy, 1990;Wisniewsky, 1998).</p>
<p>If this theory is correct, it should be possible to see such changes in the fMRI patterns of subjects that are reading words in different contexts.Such effect has indeed been demonstrated in earlier work (Aguirre-Celis &amp; Miikkulainen, 2017, 2018, and 2019).Their model was able to identify the effect of similar context on different concepts (boat crossed vs. car crossed), as well as the effect of different contexts on the same concept (bird flew vs. plane flew).These effects were quantified across a large corpus of sentences, demonstrating that the meaning of the sentence context is transferred, to a degree, to each word in the sentence.The results were obtained by mapping sentence fMRI to the FGREP mechanism (Forming Global Representations with Extended BP, Miikkulainen &amp; Dyer, 1991), to adjust those representations to take context into account.</p>
<p>What remains to be shown is that the changes in the word representation are actually meaningful to the subjects, i.e., that they are aware of them and agree on the predictions of the model.To that end, a human subject study is presented in this paper.Subjects were given words in context and asked to evaluate possible changes.</p>
<p>In the following sections, the modeling framework is first reviewed, including fMRI imaging data collection, the brain-based semantic model, and the neural network model that produces the predictions.The methods and results of the human subject study are then described, followed by the methods and results of the computational study.The methods and results of comparing the human judgements and the computational model predictions concludes the paper.</p>
<p>Modeling Framework</p>
<p>The neural network model used in this study CEREBRA (Context-dependent mEaning REpresentation in the BRAin), was developed by Aguirre-Celis &amp; Miikkulainen (2017Miikkulainen ( , 2018Miikkulainen ( , and 2019) ) to investigate how words change under the context of a sentence using imaging data.It is based on the CAR semantic feature model (Concept Attributes Representation, Binder, 2016) , and implemented using the FGREP neural network (Miikkulainen &amp; Dyer, 1991).The model is trained to predict sentence fMRI, using CEREBRA to map CAR representations of words into fMRI data of subjects reading everyday sentences.</p>
<p>CARs (a.k.a. the experiential attribute representation model), represent the basic components of meaning defined in terms of known neural processes and brain systems.They are composed of a list of well-known modalities that correspond to specialized sensory, motor and affective brain processes, systems processing spatial, temporal, and casual information, and areas involved in social cognition.These aspects of mental experience model each word as a collection of a 66-dimensional feature vector that captures the strength of association between each neural attribute and the word meaning.For instance, Figure 1 shows the CAR for the concept football.For a more detailed account of the attribute selection and definition see Binder, et al. (2009Binder, et al. ( , 2011Binder, et al. ( , 2016aBinder, et al. ( , and 2016b)).</p>
<p>Aguirre-Celis &amp; Miikkulainen's model was developed based on three sets of data: A sentence collection prepared by Glasgow et al. (2016), the semantic vectors (CAR ratings) for the words obtained via Mechanical Turk, and the fMRI images for the sentences, both collected by the Medical College of Wisconsin (Anderson, et al., 2016;Binder, et al., 2016).Additionally, fMRI representations for individual words (called SynthWord) were synthesized by averaging the sentence fMRI.</p>
<p>The CEREBRA model was trained to map the CAR representations of words in each sentence into the observed fMRI of the sentence (Figure 2).Gradient descent was then continued separately for each sentence, reducing the error by modifying only the CARs at the input of the network (i.e., using the FGREP method).As a result, the strengths of the attributes in the CARs changed according to how relevant each attribute is for that sentence context.</p>
<p>The CEREBRA model was trained 20 times for each of the eleven fMRI subjects with different random seeds.A total of 20 different sets of 786 context word representations (one word representation for each sentence where the word appears) were thus produced for each subject.Afterwards, the mean of the 20 representations was used as the final representation for each word.These context-based word vectors were then used as predictions for the human judgements obtained in the human subject study in this paper.</p>
<p>Figure 1: Bar plot of the 66 semantic features for the concept football (Binder, et al., 2016).The values represent average human ratings for each feature.Given that football is an object, it gets low weightings on human-related attributes such as Temperature, Speech, and Taste, and emotions including Sad and Angry, and high weightings on attributes like Shape, Touch, Lower-limb, and Manipulation.</p>
<p>Measuring Human Judgements</p>
<p>The purpose of the survey is to evaluate the computational model predictions addressing the central question: How does the meaning of a word change in different sentences?According to Aguirre-Celis &amp; Miikkulainen (2017Miikkulainen ( , 2018Miikkulainen ( , and 2019)), different attributes of the target word are weighted differently depending on context.Thus, the model is used to determine how the generic meaning of a word would have to change in order to account for the context.Specifically, the survey was designed to characterize these changes by asking the subject directly: In this context, how does this attribute change?</p>
<p>Materials and Design</p>
<p>The survey design was based on the fMRI subject data and sentence collection, the CEREBRA predictions, and the CAR's literal descriptions.A script was implemented to select the most representative subjects, sentences, words, and word attributes.To make the questions more understandable for the participants, the original descriptions of the 66 attributes were rephrased to make the questionnaires easy to read and to respond to, while retaining the meaning of the original descriptions elaborated by Binder et al. (2016).The data from the aggregation analysis prepared by Aguirre-Celis &amp; Miikkulainen (2019), was used as the starting point, and filtered further to make it systematic and uniform.Only the centroid non-copula sentences, three word classes, and  1 shows a sample of 5 sentences and 15 words from this collection.The table on the top part, shows the original sentence number from the Glasgow collection, the sentence itself, and the number of times each particular sentence was selected by the script.The table on the bottom part, lists the three classes, the words in alphabetical order, and the word number from the original collection.Red indicates words used in two different roles in various sentences (e.g., activist as Agent or Patient).</p>
<p>The complete survey is an array of 24 questionnaires that include 15 sentences each.For each sentence, the survey measures 10 attribute changes for each target word.Overall, each questionnaire thus contains 150 evaluations.For example, a questionnaire might measure changes on 10 specific attributes such as 'is visible', 'living thing that moves', 'is identified by sound', 'has a distinctive taste', for a specific word class as in politician, for 15 sentences such as The politician celebrated at the hotel.An example sentence questionnaire is shown in Figure 3.</p>
<p>To select which attributes to test the following process was used: (1) use the sentences with at least 10 statistically significant attribute changes (ssa), (2) from the 25 attributes with the largest change (or the number of ssa available), randomly select 10 within a sentence, and (3) organize the attribute collection for each question using Binder's (2016) original list arrangement.</p>
<p>The statistically significant attribute changes thus selected represent meaningful differences between the new and the original CAR representations.The point of the random selection within the top 25 was that: (1) there is a large number of potentially meaningful attributes, i.e. 25 at least;</p>
<p>(2) for simplicity, the survey must not contain many questions; (3) the differences among the top 25 are not very large; and (4) it is necessary to get a varied selection of attributes.Choosing the top 10 instead would have resulted in too many visual features for most sentences, either because they frequently changed more, or because visual attributes are more numerous (i.e., 15 out of the 66).</p>
<p>Figure 3: Example sentence in a questionnaire prepared to evaluate the computational model results.The sentence is The politician celebrated at the hotel, the target word is politician in the role of Agent.Ten different attribute changes are measured by selecting whether the attribute increased ("more"), decreased ("less") or remained "neutral".The human judgements were thus matched with those predicted by the CEREBRA model trained with the fMRI data.</p>
<p>Participants</p>
<p>Human judgements were crowdsourced using Google Forms in accordance with the University of Texas Institutional Review Board (2018-08-0114).The experiments were completed by 27 unpaid volunteers (nine females).The participants' ages ranged from 18 to 64 years, with the mean of 33.Nineteen of them were self-reported bilinguals (English as a second language) and eight English native speakers.Four subjects were affiliated with The University; the rest of the population consisted of working people residing in different parts of north and central America (Texas, Seattle, California, Costa Rica, and Mexico).The subjects had no background in linguistics, psychology or neurosciences.</p>
<p>Procedure</p>
<p>The 24 questionnaires were designed using Google Forms.The respondents were asked to think how the meaning of a specific word changes within the context of a sentence compared to its generic meaning, by evaluating which word attributes change "more", "less", or stay the same.Subjects were recruited by sending emails or text messages directly along with the survey link to access their assigned questionnaire.The data collection was done online and the participants responded using their cell phone or personal computer.Each questionnaire consisted of an Introduction, Description of the Experiment, Example, and the Survey.Each questionnaire takes about 15 minutes to complete.</p>
<p>Three of the participants responded to all of the 24 questionnaires.The entire survey consisted of a total of 3600 questions, so it took them four to seven days to complete this task at a pace of approximately four questionnaires (i.e., an hour per day).This task was a lot of work, the fourth set of responses was obtained by distributing it among multiple raters: twenty-four additional participants were recruited to each respond to one of the 24 questionnaires.</p>
<p>Table 2: Distribution analysis and inter-rater agreement.The top part shows human judgement distribution for the three possible questionnaire responses "less" (-1), "neutral" (0), and "more" (1).The bottom part shows percent agreement for the four raters.The task was difficult and the agreement low.Only those questions where three out of four participants agreed were considered reliable and compared to the CEREBRA model.</p>
<p>Results</p>
<p>Human responses were first characterized through data distribution analysis.Table 2 shows the number of answers "less" (-1), "neutral" (0), and "more" (1) for each respondent.Columns labeled P1, P2, and P3, show the responses of the three participants that were assigned the entire survey (24 questionnaires, 3600 answers).Column labeled P4 shows the combined answers of the 24 different participants responding to one questionnaire each.The top part of the table shows the distribution of the rater's responses and the bottom part shows the level of agreement among them.As can be seen, participants agreed only 47% of the time.</p>
<p>According to Grand, et. al (2018) it is not worth comparing system predictions vs. human judgements if inter-subject reliability is too low.However, since there were a lot of questions, it was possible to include only questions that were the most reliable, i.e., where three out of four participants agreed.There were 1966 such questions or 55% of the total set of questions.</p>
<p>Measuring Model Predictions</p>
<p>Three different approaches were designed to quantify the predictions of the FGREP model.In order to measure the level of agreement between humans and FGREP a model fitting procedure was implemented.</p>
<p>Quantifying the FGREP Predictions</p>
<p>The survey directly asks for the direction of change of a specific word attribute in a particular sentence, compared to a generic meaning.Since the changes in the CEREBRA model range within (-1,1), in principle that is exactly what the model produces.However, Aguirre-Celis &amp; Miikkulainen (2017Miikkulainen ( , 2018Miikkulainen ( , and 2019) ) found that some word attributes always increase, and do so more in some contexts than others.This effect is related to conceptual combination (Hampton, 1996;Wisniewsky, 1998), contextual modulation (Barclay, 1974), or attribute centrality (Medin &amp; Shoben, 1988): the same property is true for two different concepts but more central to one than to the other (e.g., it is more important for boomerangs to be curved than for bananas).</p>
<p>The direction of change is therefore not a good predictor of human responses; instead these changes need to be measured relative to changes in other words.Thus such approaches were evaluated:</p>
<ol>
<li>
<p>What is the effect of the rest of the sentence in the target word?This effect was measured by computing the average of the CEREBRA changes (i.e., new-original) of the other words in the sentence, and subtracting that average change from the change of the target word:</p>
</li>
<li>
<p>What is the effect of the entire sentence in the target word?This effect was measured by computing the average of the CEREBRA changes (i.e., new-original) of all the words in the sentence including the target word, and subtracting that average change from the change of the target word:  The first two approaches have the advantage of being simple.However the third approach is motivated by neurological evidence suggesting that sentence comprehension involves a common core representation of multiple word meanings combined into a network of regions distributed across the brain (Anderson, et al., 2016;Gennari, et. al., 2007).In line with this view, a generic (or isolated) word representation can be formed by averaging the activity in multiple sentence contexts.</p>
</li>
</ol>
<p>In each of these cases, the resulting vectors are expected to accurately represent the direction of change asked in the questionnaires.They are the ratings used in the evaluation procedure described in the following section.</p>
<p>Procedure</p>
<p>Starting from a different random seed, the CEREBRA model was trained 20 times for each of the eight best fMRI subjects (i.e., where the fMRI data in general was most consistent).Responses for each model where thus obtained for the 1966 questions where three out of four participants agreed.In order to demonstrate that the CEREBRA model has captured human performance, the agreements of the CEREBRA changes and human surveys need to be at least above chance.Therefore a baseline model that generated random changes in the same range as the CEREBRA model was created.The chance model was queried 20 times for each of the 1966 questions, for each of the eight subjects.In this manner, 20 means and variances for each of the eight subjects for both CEREBRA and chance were created.</p>
<p>To estimate the level of agreement of CEREBRA and chance models with humans, a single parameter in each model was fit to human data: the boundary value above which the change was taken to be an increase (i.e., "more") or decrease/no change (i.e., "less"/"neutral").The "less" and "neutral" categories were combined because they were much smaller than the "more" category in human data.The optimal value for this parameter was found by simply sweeping through the range (-1..1) and finding the value that measured on the highest number of matching responses where the 1966 questions are.</p>
<p>Matching Predictions with Human Judgements</p>
<p>The three approaches to measuring the predictions of the CEREBRA model, i.e., the context effect of the rest of the sentence, the context effect of the entire sentence, and the context effect of the word in different contexts, were implemented and fit to human data using single-boundary model fitting.The three sets of data produced very similar results, therefore only those of the third approach, are reported in this paper.In fact, the other two approaches achieved slightly better results than this one (by 1%).</p>
<p>The match results are presented in Table 3 and the statistical significance in Table 4.The CEREBRA model matches human responses in 54% of the questions when the chance level is 45% -which is indistinguishable from always guessing "more", i.e., the largest category of human responses.The differences shown in Table 4 are statistically strongly significant for all of the eight subjects.These results show that the changes in word meanings due to sentence context that are observed in the fMRI and interpreted to semantic feature representations are real and meaningful to the subjects.</p>
<p>Discussion and Future Work</p>
<p>The study provides a missing piece on the theory of semantic feature representations: The context-dependent changes in them are actionable and can be used to predict human judgements.Given how noisy human responses data is, the 9% difference between CEREBRA and chance is a strong result.An interesting direction for future work would be to replicate the study on a more extensive data set with a fully balanced stimuli and with fMRI images of individual words.The differences should be even stronger and should be possible to uncover even more refined effects.Such data should also improve the survey, since it would be possible to identify questions where the effects can be expected to be more reliable.Inter-raters reliability could also be improved by training the raters better so that they are comfortable with the concept of generic meaning and the concept of variable meanings.It may also be possible to design the questions such that they allow comparing alternatives which may be easier for the participants.</p>
<p>In regard to other models that map the semantic space of the brain.CAR theory enables direct correspondence between conceptual content and neural representations.Conceptual knowledge is distributed across a small set of modality-specific neural systems that are engaged when instances of the concept are experienced.In contrast, distributional semantic models (DSM) construct conceptual knowledge from text co-occurrence.They are not grounded on perception and motor mechanisms, instead their representations reflect the semantic knowledge acquired through a lifetime of linguistic experience.The richness and complexity of the representations in the CAR theory offers a powerful method to further explore the semantic space of the brain.To this end, the CEREBRA model (Aguirre-Celis &amp; Miikkulainen, 2017Miikkulainen, , 2018Miikkulainen, , 2019) ) have demonstrated that CARs can capture fine distinctions in meaning, creating many possibilities of improvements of the theory itself, and supporting the explainable feature representations of CARs by discerning how concepts are dynamically represented in the brain.In contrast, DSM representations cannot be interpreted.</p>
<p>Conclusion</p>
<p>This paper provides experimental and computational support on these main ideas: (1) context-dependent meaning representations are embedded in the fMRI sentences, and (2) they can be characterized.Using brain-based semantic feature representations (CARs) together with the CEREBRA change model, (3) such changes are real and meaningful to the subjects.It therefore takes a step towards understanding how the brain constructs sentence-level meanings from word-level attributes.</p>
<p>Figure 2 :
2
Figure 2: The CEREBRA model to account for context effects (Aguirre-Celis &amp; Miikkulainen, 2017, 2018, and 2019).(1) Propagate CARWords to SynthWords.(2) Construct SynthSent by averaging the SynthWords into a prediction of the sentence.(3) Compare SynthSent against observed fMRI sentence.(4) Backpropagate the error with FGREP for each sentence, freezing network weights and changing only CARWords.(5) Repeat until error reaches zero or CAR components reach their upper or lower limits.Thus, the CEREBRA model captures context effects by mapping brain-based semantic representations to fMRI sentence images.</p>
<p>3.</p>
<p>What is the effect of CARs used in context as opposed to CARs used in isolation?This effect was measured by computing the average of the CEREBRA changes (i.e., new-original) of the different representations of the same word in several contexts, and subtracting that average change from the change of the target word:</p>
<p>/S MOT SPAT EVENT COG EVA EMO DR AT CAR representations for "FOOTBALL"
forwardfMRISentbackward1VISIONW2:built W'2:SynthWord W3:computer W'3:SynthWord SOM AUDIT GSynthSent W1:engineer W'1:SynthWord CARWord?W2:built W3:computer SynthSent (Revised) (w'1+w'2+w'3)/3 W1:engineer W'2:SynthWord W'1:SynthWord W'3:SynthWord ɛ=error CARWord Revised0Vision Bright Dark Color Pattern Large Small Motion Biomot Fast Slow Shape Cmplex Face Body Touch Temp Texture Weight Pain Audit Loud Low High Sound Music Speech Taste Smell Head ULimb LLimb Manip Object Landmk Path Scene Near Toward Away Number Time Duration Long Short Caused Conseq Social Human Comm Self Cognition Benefit Harm Pleasant Unpls Happy Sad Angry Disgust Fearful Surpris Drive Needs Att Arousal
(w'1+w'2+w'3)/3</p>
<p>Table 1 :
1
A sample of 5 sentences and a sample of 15 words used in the questionnaires are shown.The top part of the table shows the original sentence number, the sentence itself, and the number of times each sentence was included in the survey.The bottom part shows the words in alphabetical order divided into Agent, Verb, and any of Patient/Object/Location/Event (POLE).Words shown in red appeared in two different roles in separate sentences.
the top 10 statistically significant attribute changes for thetarget words (classes) were used. The final stimuli that metthis criteria consisted of 64 different sentences from theGlasgow corpora containing the roles of Agent, Verb, andPatient/Object/Location/Event(POLE).Altogethercontained 123 words: 38 Agents, 39 Verbs, and 46 POLEwords. Table</p>
<p>Questionnaires Unique Sentences No. Sentence Occ 113 The author kicked the desk 4 116 The injured horse slept at night 1 149 The banker watched the peaceful protest 1 150 The mob approached the embassy 2 154 The politician celebrated at the hotel 2 Questionnaires Unique Words
No. AgentNo. VerbNo. POLE2 activist10 arrested2 activist13 author12 ate21 bird15 banker27 bought25 boat21 bird31 broke26 book25 boat38 celebrated41 chicken</p>
<p>Table 3 :
3
Matching CEREBRA predictions with human data, compared to chance.The table shows the average agreement of the 20 repetitions across all subjects.CEREBRA agrees with human responses 54% when the chance level is 45%.</p>
<p>Table 4 :
4
Statistical analysis for CEREBRA and chance.The table shows the means and variances of CEREBRA and chance models for each subject and the p-values of the t-test, showing that the differences are highly significant.
The$commander$ate$chicken$at$dinneratecommanderchickendinnerate4!PARTICIPANTS!AVERAGE!AGREEMENTRATINGS HUMAN FGREPCHANCE!"1/010744668The$The$dog$The$tourist$The$old$The$reporter$1892587886commander$ ate chicken$ at$dinnerate the$eggate bread$ on$vacationfarmer$ate at$ the$expensive$ hotelate at$the$new$ restaurantTOTAL !!!!!!!!!!!!!!!!!!AVERAGE 19661053 54%894 45%4
AcknowledgmentsWe would like to thank Jeffery Binder (Medical College of Wisconsin), Rajeev Raizada and Andrew Anderson (University of Rochester), Mario Aguilar and Patrick Connolly (Teledyne Scientific Company) for their work and valuable help regarding this research.This work was supported in part by IARPA-FA8650-14-C-7357 and by NIH 1U01DC014922 grants.
From Words to Sentences &amp; Back: Characterizing Context-dependent Meaning Rep in the Brain. N Aguirre-Celis, R Miikkulainen, Proceedings of the 39th Annual Conference of the Cognitive Science Society. the 39th Annual Conference of the Cognitive Science SocietyLondon2017</p>
<p>Combining fMRI Data and Neural Networks to Quantify Contextual Effects in the Brain. N Aguirre-Celis, R Miikkulainen, Brain Informatics. BI. Wang S. et al.113092018. 2018Springer</p>
<p>Quantifying the Conceptual Combination Effect on Words Meanings. N Aguirre-Celis, R Miikkulainen, Proceedings of the 41th Annual Conference of the Cognitive Science Society. the 41th Annual Conference of the Cognitive Science SocietyMontreal, CA2019</p>
<p>Predicting Neural activity patterns associated with sentences using neurobiologically motivated model of semantic representation. A J Anderson, J R Binder, L Fernandino, C J Humpries, L L Conant, M Aguilar, X Wang, S Doko, R D Raizada, Cerebral Cortex. 2016</p>
<p>Comprehension and semantic flexibility. J R Barclay, J D Bransford, J J Franks, N S Mccarrell, K Nitsch, Journal of Verbal Learning and Verbal Behavior. 131974</p>
<p>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. J R Binder, R H Desai, W W Graves, L L Conant, Cerebral Cortex. 192009</p>
<p>The neurobiology of semantic memory. J R Binder, R H Desai, Trends in Cognitive Science. 15112011</p>
<p>Toward a brainbased componential semantic representation. J R Binder, L L Conant, C J Humpries, L Fernandino, S Simons, M Aguilar, R Desai, Cognitive Neuropsychology. 333-42016a</p>
<p>J R Binder, defense of abstract conceptual representations. 2016b23</p>
<p>Context-dependent interpretation of words: Evidence for interactive neural processes. S Gennari, M Macdonald, B Postle, S Seidenberg, NeuroImage. 3532007</p>
<p>Evaluating semantic models with word-sentence relatedness. K Glasgow, M Roos, A J Haufler, M Chevillet, A Wolmetz, M , arXiv:1603.072532016</p>
<p>G Grand, I Blank, F Pereira, E Fedorenko, arXiv:1802.01241v2Semantic Projection: Recovering Human Knowledge of Multiple, Distinct Object Features from Word Embeddings. 2018</p>
<p>Conceptual combination. J Hampton, Studies in cognition. Knowledge, concepts and categories. K Lamberts, D R Shanks, MIT Press1997</p>
<p>Conceptual representations in mind and brain: theoretical developments, current evidence and future directions. M Kiefer, F Pulvermüller, Cortex. 482012</p>
<p>Context and structure in conceptual combination. D L Medin, E J Shoben, Cognitive Psychology. 201988</p>
<p>Composition in distributional models of semantics. J Mitchell, M Lapata, Cognitive Science. 3882010</p>
<p>Natural Language Processing with Modular PDP Networks and Distributed Lexicon. R Miikkulainen, M Dyer, G , Cognitive Science. 151991</p>
<p>Noun Phrase Interpretation and Conceptual Combination. G Murphy, Journal of Memory and Language. 291990</p>
<p>Property Instantiation in Conceptual Combination. E Wisniewski, Memory &amp; Cognition. 261998</p>            </div>
        </div>

    </div>
</body>
</html>