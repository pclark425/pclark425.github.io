<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4304 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4304</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4304</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-99.html">extraction-schema-99</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <p><strong>Paper ID:</strong> paper-277468085</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.00752v1.pdf" target="_blank">LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Extracting structured information from unstructured text is crucial for modeling real-world processes, but traditional schema mining relies on semi-structured data, limiting scalability. This paper introduces schema-miner, a novel tool that combines large language models with human feedback to automate and refine schema extraction. Through an iterative workflow, it organizes properties from text, incorporates expert input, and integrates domain-specific ontologies for semantic depth. Applied to materials science--specifically atomic layer deposition--schema-miner demonstrates that expert-guided LLMs generate semantically rich schemas suitable for diverse real-world applications.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4304.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4304.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>schema-miner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMs4SchemaDiscovery / schema-miner</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human-in-the-loop software tool and three-stage workflow that leverages LLMs to discover, refine, and finalize JSON schemas (properties, data types, constraints, relationships) from scientific literature, with final ontology grounding via an ontology lookup service.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLMs4SchemaDiscovery (schema-miner)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A 3-stage iterative workflow: (1) GenerateInitialSchema — an LLM is prompted using structured SystemPrompts + a User domain specification to produce an initial JSON schema (properties P, types T, constraints C, relationships R). (2) RefineSchema — the LLM ingests 1–10 curated domain papers plus optional expert feedback (either descriptive guidance or direct schema edits) and iteratively updates P, T, C, R. (3) FinalizeSchema — the LLM validates and generalizes the schema using a larger uncurated corpus (up to ~100+ papers). A final Ontology Grounding stage queries an ontology lookup service (OLS), filters candidates by description availability, and ranks matches using a sentence-transformer similarity score to attach ontology concepts. The implementation uses LangChain for LLM integration and supports Ollama / Hugging Face / OpenAI-compatible APIs. Prompts follow a formalized SystemPrompt(User role, Task, InputFormat, OutputFormat) + UserPrompt(PrevSchema, SciPaper, ExpertFeedback) template. Outputs are JSON schemas with datatype and unit annotations and ontology links.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-4o (ver.2024-08-06), GPT-4-turbo (ver.2024-04-09), LLaMA 3.1 (8B) — also compatible with other Ollama/Hugging Face models</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials science (Atomic Layer Deposition use case); generalizable across scientific domains</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>7 curated (per setting) in Stage 2 + larger uncurated collection in Stage 3 (tool supports up to 100+ papers); experiments reported: 21 runs (7 per model)</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Extraction of quantitative experimental and simulation parameters and relationships (e.g., reaction step energies, growth rates, growth-per-cycle, thickness, temperature, pressure, dosing/purge durations) and constraints/relationships among these parameters; not presented as novel closed-form scaling laws but as structured quantitative process parameters and relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>JSON schemas (structured JSON objects): properties with data types, units, constraints, nested relationships; ontology-grounded annotations (ontology IDs/descriptions).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Domain expert evaluation / human-in-the-loop review at each refinement iteration; quantitative comparison of schema outputs across LLMs using text-similarity metrics (ROUGE-L, BLEU, SciBERT-based BERTScore) to measure inter-model agreement; qualitative expert adjudication to select best schema.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Inter-model schema similarity metrics reported: Stage 1 ROUGE-L examples (GPT-4-turbo vs LLaMA 3.1: 0.4118; LLaMA 3.1 vs GPT-4o: 0.3100; GPT-4o vs GPT-4-turbo: 0.3428). BERTScore (SciBERT) range reported Stage 1: 0.8044–0.8098. Stage 2: GPT-4-turbo BLEU 0.4515 vs GPT-4o (comparison), LLaMA 3.1 scored 0.3316 in same comparison. Stage 3: GPT-4-turbo vs GPT-4o BLEU 0.4151, BERTScore 0.8046. (Metrics measure schema text/structure similarity across models rather than absolute extraction accuracy of numeric values.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared LLM outputs against each other (GPT-4o, GPT-4-turbo, LLaMA 3.1) and a no-feedback baseline (Experiment 4). Qualitatively, GPT-4o and LLaMA 3.1 (8B) produced more stable/semantically coherent schemas; GPT-4-turbo tended to introduce overly specific or irrelevant properties. No numeric baseline comparing to non-LLM schema-discovery algorithms was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Reported failure modes include incorrect unit assignments (e.g., reaction rate units mis-assigned), repeated/duplicated properties across nested structures, overly specific additions when exposed to broad uncurated corpora (loss of generalizability), unnecessary boolean properties, instability/variance across models and runs, and susceptibility to prompt/instruction framing. The approach requires curated domain specifications and benefits strongly from iterative expert feedback. Performance metrics reported measure inter-model agreement rather than ground-truth extraction accuracy for numeric laws.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4304.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4304.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based schema enrichment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based semantic schema enrichment (general approach, related work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of approaches that leverage large language models to extract attribute values and semantic labels from unstructured or semi-structured data and enrich discovered schemas with additional semantic meaning (e.g., linking attributes to ontology concepts).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM-based semantic schema enrichment</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Described in related work as methods that use LLMs to extract attribute values and add semantic meaning to discovered schemas, complementing classical clustering and rule-based schema inference techniques; typically outputs augmented schema elements with labels and semantic links.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General / cross-domain (cited as complementing traditional schema inference across datasets such as tabular, JSON, scientific corpora)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Attribute/value extraction and semantic labeling of quantitative attributes (e.g., units, data types), but not necessarily discovery of closed-form laws.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Augmented schema representations (e.g., enriched JSON/XML/RDF with semantic annotations).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Not specified in-paper (referenced in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Related-work note: traditional methods still suffer semantic understanding limits; LLM approaches can complement but require domain expertise and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4304.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4304.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ExtractGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ExtractGPT (Exploring potential of large language models for product attribute value extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based system referenced in related work that explores using large language models to extract product attribute values from text (e.g., commercial/product descriptions).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extractgpt: Exploring the potential of large language models for product attribute value extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ExtractGPT (attribute extraction with LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Referenced as an example of using LLMs to extract structured attribute-value pairs from unstructured product descriptions; likely uses prompting and LLM parsing to output attribute values in structured form.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>E-commerce / product catalogs (example domain in related work)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Extraction of quantitative and categorical attribute values (e.g., sizes, weights, numeric product attributes) — not explicit law discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Structured attribute-value outputs (likely JSON or tabular).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4304.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4304.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-JSON-schema (Mior 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language models for JSON schema discovery (M. J. Mior, 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited work that applies large language models specifically to the task of JSON schema discovery from data/text sources.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language models for json schema discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM-based JSON schema discovery (Mior 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cited as prior work that uses LLMs to infer JSON schema structures from input data/text; referenced in related work to situate schema-miner among LLM-driven schema discovery efforts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General / data schema inference</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Schema discovery for structured representation of attributes (not explicitly closed-form laws).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>JSON schema</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Extractgpt: Exploring the potential of large language models for product attribute value extraction. <em>(Rating: 2)</em></li>
                <li>Large language models for json schema discovery. <em>(Rating: 2)</em></li>
                <li>Parametric schema inference for massive json datasets. <em>(Rating: 1)</em></li>
                <li>Turning online ald and ale databases into ai-ready tools for development of new sustainable materials and fabrication processes. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4304",
    "paper_id": "paper-277468085",
    "extraction_schema_id": "extraction-schema-99",
    "extracted_data": [
        {
            "name_short": "schema-miner",
            "name_full": "LLMs4SchemaDiscovery / schema-miner",
            "brief_description": "A human-in-the-loop software tool and three-stage workflow that leverages LLMs to discover, refine, and finalize JSON schemas (properties, data types, constraints, relationships) from scientific literature, with final ontology grounding via an ontology lookup service.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "LLMs4SchemaDiscovery (schema-miner)",
            "method_description": "A 3-stage iterative workflow: (1) GenerateInitialSchema — an LLM is prompted using structured SystemPrompts + a User domain specification to produce an initial JSON schema (properties P, types T, constraints C, relationships R). (2) RefineSchema — the LLM ingests 1–10 curated domain papers plus optional expert feedback (either descriptive guidance or direct schema edits) and iteratively updates P, T, C, R. (3) FinalizeSchema — the LLM validates and generalizes the schema using a larger uncurated corpus (up to ~100+ papers). A final Ontology Grounding stage queries an ontology lookup service (OLS), filters candidates by description availability, and ranks matches using a sentence-transformer similarity score to attach ontology concepts. The implementation uses LangChain for LLM integration and supports Ollama / Hugging Face / OpenAI-compatible APIs. Prompts follow a formalized SystemPrompt(User role, Task, InputFormat, OutputFormat) + UserPrompt(PrevSchema, SciPaper, ExpertFeedback) template. Outputs are JSON schemas with datatype and unit annotations and ontology links.",
            "llm_model_used": "GPT-4o (ver.2024-08-06), GPT-4-turbo (ver.2024-04-09), LLaMA 3.1 (8B) — also compatible with other Ollama/Hugging Face models",
            "scientific_domain": "Materials science (Atomic Layer Deposition use case); generalizable across scientific domains",
            "number_of_papers": "7 curated (per setting) in Stage 2 + larger uncurated collection in Stage 3 (tool supports up to 100+ papers); experiments reported: 21 runs (7 per model)",
            "type_of_quantitative_law": "Extraction of quantitative experimental and simulation parameters and relationships (e.g., reaction step energies, growth rates, growth-per-cycle, thickness, temperature, pressure, dosing/purge durations) and constraints/relationships among these parameters; not presented as novel closed-form scaling laws but as structured quantitative process parameters and relationships.",
            "extraction_output_format": "JSON schemas (structured JSON objects): properties with data types, units, constraints, nested relationships; ontology-grounded annotations (ontology IDs/descriptions).",
            "validation_method": "Domain expert evaluation / human-in-the-loop review at each refinement iteration; quantitative comparison of schema outputs across LLMs using text-similarity metrics (ROUGE-L, BLEU, SciBERT-based BERTScore) to measure inter-model agreement; qualitative expert adjudication to select best schema.",
            "performance_metrics": "Inter-model schema similarity metrics reported: Stage 1 ROUGE-L examples (GPT-4-turbo vs LLaMA 3.1: 0.4118; LLaMA 3.1 vs GPT-4o: 0.3100; GPT-4o vs GPT-4-turbo: 0.3428). BERTScore (SciBERT) range reported Stage 1: 0.8044–0.8098. Stage 2: GPT-4-turbo BLEU 0.4515 vs GPT-4o (comparison), LLaMA 3.1 scored 0.3316 in same comparison. Stage 3: GPT-4-turbo vs GPT-4o BLEU 0.4151, BERTScore 0.8046. (Metrics measure schema text/structure similarity across models rather than absolute extraction accuracy of numeric values.)",
            "baseline_comparison": "Compared LLM outputs against each other (GPT-4o, GPT-4-turbo, LLaMA 3.1) and a no-feedback baseline (Experiment 4). Qualitatively, GPT-4o and LLaMA 3.1 (8B) produced more stable/semantically coherent schemas; GPT-4-turbo tended to introduce overly specific or irrelevant properties. No numeric baseline comparing to non-LLM schema-discovery algorithms was reported.",
            "challenges_limitations": "Reported failure modes include incorrect unit assignments (e.g., reaction rate units mis-assigned), repeated/duplicated properties across nested structures, overly specific additions when exposed to broad uncurated corpora (loss of generalizability), unnecessary boolean properties, instability/variance across models and runs, and susceptibility to prompt/instruction framing. The approach requires curated domain specifications and benefits strongly from iterative expert feedback. Performance metrics reported measure inter-model agreement rather than ground-truth extraction accuracy for numeric laws.",
            "requires_human_in_loop": true,
            "fully_automated": false,
            "uuid": "e4304.0",
            "source_info": {
                "paper_title": "LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "LLM-based schema enrichment",
            "name_full": "LLM-based semantic schema enrichment (general approach, related work)",
            "brief_description": "A class of approaches that leverage large language models to extract attribute values and semantic labels from unstructured or semi-structured data and enrich discovered schemas with additional semantic meaning (e.g., linking attributes to ontology concepts).",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "LLM-based semantic schema enrichment",
            "method_description": "Described in related work as methods that use LLMs to extract attribute values and add semantic meaning to discovered schemas, complementing classical clustering and rule-based schema inference techniques; typically outputs augmented schema elements with labels and semantic links.",
            "llm_model_used": null,
            "scientific_domain": "General / cross-domain (cited as complementing traditional schema inference across datasets such as tabular, JSON, scientific corpora)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Attribute/value extraction and semantic labeling of quantitative attributes (e.g., units, data types), but not necessarily discovery of closed-form laws.",
            "extraction_output_format": "Augmented schema representations (e.g., enriched JSON/XML/RDF with semantic annotations).",
            "validation_method": "Not specified in-paper (referenced in related work).",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Related-work note: traditional methods still suffer semantic understanding limits; LLM approaches can complement but require domain expertise and validation.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4304.1",
            "source_info": {
                "paper_title": "LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "ExtractGPT",
            "name_full": "ExtractGPT (Exploring potential of large language models for product attribute value extraction)",
            "brief_description": "An LLM-based system referenced in related work that explores using large language models to extract product attribute values from text (e.g., commercial/product descriptions).",
            "citation_title": "Extractgpt: Exploring the potential of large language models for product attribute value extraction.",
            "mention_or_use": "mention",
            "method_name": "ExtractGPT (attribute extraction with LLMs)",
            "method_description": "Referenced as an example of using LLMs to extract structured attribute-value pairs from unstructured product descriptions; likely uses prompting and LLM parsing to output attribute values in structured form.",
            "llm_model_used": null,
            "scientific_domain": "E-commerce / product catalogs (example domain in related work)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Extraction of quantitative and categorical attribute values (e.g., sizes, weights, numeric product attributes) — not explicit law discovery.",
            "extraction_output_format": "Structured attribute-value outputs (likely JSON or tabular).",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4304.2",
            "source_info": {
                "paper_title": "LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "LLM-JSON-schema (Mior 2024)",
            "name_full": "Large language models for JSON schema discovery (M. J. Mior, 2024)",
            "brief_description": "A cited work that applies large language models specifically to the task of JSON schema discovery from data/text sources.",
            "citation_title": "Large language models for json schema discovery.",
            "mention_or_use": "mention",
            "method_name": "LLM-based JSON schema discovery (Mior 2024)",
            "method_description": "Cited as prior work that uses LLMs to infer JSON schema structures from input data/text; referenced in related work to situate schema-miner among LLM-driven schema discovery efforts.",
            "llm_model_used": null,
            "scientific_domain": "General / data schema inference",
            "number_of_papers": null,
            "type_of_quantitative_law": "Schema discovery for structured representation of attributes (not explicitly closed-form laws).",
            "extraction_output_format": "JSON schema",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4304.3",
            "source_info": {
                "paper_title": "LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Extractgpt: Exploring the potential of large language models for product attribute value extraction.",
            "rating": 2,
            "sanitized_title": "extractgpt_exploring_the_potential_of_large_language_models_for_product_attribute_value_extraction"
        },
        {
            "paper_title": "Large language models for json schema discovery.",
            "rating": 2,
            "sanitized_title": "large_language_models_for_json_schema_discovery"
        },
        {
            "paper_title": "Parametric schema inference for massive json datasets.",
            "rating": 1,
            "sanitized_title": "parametric_schema_inference_for_massive_json_datasets"
        },
        {
            "paper_title": "Turning online ald and ale databases into ai-ready tools for development of new sustainable materials and fabrication processes.",
            "rating": 1,
            "sanitized_title": "turning_online_ald_and_ale_databases_into_aiready_tools_for_development_of_new_sustainable_materials_and_fabrication_processes"
        }
    ],
    "cost": 0.01131775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models
1 Apr 2025</p>
<p>Sameer Sadruddin sameer.sadruddin@tib.eu 
TIB Leibniz Information Centre for Science and Technology
HannoverGermany</p>
<p>Jennifer D'souza jennifer.dsouza@tib.eu 
TIB Leibniz Information Centre for Science and Technology
HannoverGermany</p>
<p>Eleni Poupaki 
TU/e Eindhoven
University of Technology
Netherlands</p>
<p>Alex Watkins 
University of Warwick
United Kingdom</p>
<p>Hamed Babaei Giglou 
TIB Leibniz Information Centre for Science and Technology
HannoverGermany</p>
<p>Anisa Rula 
University of Brescia
Italy</p>
<p>Bora Karasulu 
University of Warwick
United Kingdom</p>
<p>Sören Auer 
TIB Leibniz Information Centre for Science and Technology
HannoverGermany</p>
<p>L3S Research Center
Leibniz University of Hannover
Germany</p>
<p>Adrie Mackus 
TU/e Eindhoven
University of Technology
Netherlands</p>
<p>Erwin Kessels 
TU/e Eindhoven
University of Technology
Netherlands</p>
<p>LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models
1 Apr 20251F35083220075620166C036B522A59C710.5281/zenodo.14781824arXiv:2504.00752v1[cs.CL]Schema DiscoverySchema MiningScientific SchemasLarge Language ModelsHuman-in-the-loop Workflow
Extracting structured information from unstructured text is crucial for modeling real-world processes, but traditional schema mining relies on semi-structured data, limiting scalability.This paper introduces schema-miner, a novel tool that combines large language models with human feedback to automate and refine schema extraction.Through an iterative workflow, it organizes properties from text, incorporates expert input, and integrates domain-specific ontologies for semantic depth.Applied to materials science-specifically atomic layer deposition-schema-miner demonstrates that expert-guided LLMs generate semantically rich schemas suitable for diverse real-world applications.</p>
<p>Introduction</p>
<p>Scientific research generates vast amounts of structured, semi-structured, and unstructured data across domains like biology, chemistry, physics, and environmental science.Although findings are mainly communicated through unstructured research papers, these documents offer limited structured metadata and often lack formal mechanisms to capture content-level information.Yet, the expertise embedded in such papers makes them a rich source of scientific knowledge, with strong potential for structured pattern discovery.Since the goal and challenges of schema information extraction vary with the input type, content, and desired output, this paper contributes a software resource for extracting schemas from natural language sources as a foundation for broader knowledge applications.</p>
<p>Schemas are essential for standardizing data, enabling validation, ensuring interoperability, and supporting tasks like knowledge extraction, data integration, and automation [14,42,11,41].They form the backbone of ontology engineering (OE) [19,34] and knowledge graph (KG) construction [47,49], especially in scientific domains.For example, the Open Research Knowledge Graph (ORKG) [7] leverages expert-defined, domain-specific schemas to enhance the discoverability and integration of scientific knowledge.However, schema development in science remains fragmented, domain-specific, and often manually crafted, lacking generalizability.Much scientific data lacks formal schemas or follows undocumented formats, making schema discovery-a critical step for standardization and automation-especially challenging.Addressing this requires tools that can formalize complex data structures.Large Language Models (LLMs), with their strengths in pattern recognition and text synthesis, offer a promising solution.</p>
<p>LLMs [6,18] are well-suited for schema discovery due to their ability to recognize patterns, synthesize knowledge, and generate human-like outputs.Generalpurpose LLMs [2,35,44,29,21,32,10,4] are known to be pretrained on large code corpora, enabling them to learn meaningful representations that support extracting text-and code-based schemas.Their ability to capture structural and semantic patterns makes them effective for generating standardized schema formats like JSON from unstructured data.However, human expertise remains essential to ensure accuracy and domain relevance, highlighting the value of human-in-the-loop workflows that combine LLM output with expert refinement.</p>
<p>In this resource paper, we introduce schema-miner, a first-of-its-kind software tool for schema mining in scientific domains.Our approach, called LLMs4SchemaDiscovery, leverages LLMs to identify candidate schemas from small to large scientific paper collections.Designed in a plug-and-play modus, it supports seamless integration with most LLMs via the Ollama or Hugging-Face libraries and accepts user-defined literature collections-making it adaptable across models and domains.The approach follows a three-stage workflow: initial schema design, refinement, and finalization, with the latter two incorporating human-in-the-loop feedback to ensure schema quality and domain relevance.By combining LLM pattern recognition with expert oversight, schemaminer accelerates schema development and promotes scientific data standardization.The paper makes three key contributions.1. Systematic Methodology: A scalable, structured approach for schema discovery using LLMs.2. Human-in-the-Loop Workflow: An adaptable pipeline that combines automated extraction with expert refinement.3. Practical Demonstration: We apply schema-miner to a materials science use case on Atomic Layer Deposition (ALD), demonstrating its ability to extract meaningful schemas for generating AI-ready KGs that enable machine-actionable, integrative research across industrially relevant scenarios.</p>
<p>Related Work</p>
<p>Schema discovery involves identifying the underlying structure of data and has evolved significantly due to the increasing demand for data integration and understanding.Early approaches focused on syntactic characteristics and statistical analysis of tabular data, leveraging predefined rules, frequency distributions, and clustering techniques to identify schema elements.However, these methods often struggled with semantic understanding, handling noisy data, and required manual intervention for maintaining rules or labeled training data [30,25].Machine learning approaches, particularly deep learning, have been applied to schema matching tasks, using clustering techniques to group similar data values (e.g., "male" and "female") and neural networks to learn intricate patterns and relationships.While these methods enhance schema matching accuracy [20,37,3], they differ from our task of schema discovery as they focus on aligning existing schemas rather than identifying new structures, and they often require large labeled datasets with limited interpretability.Another related line of work is semantic schema enrichment, which builds on initial schema discovery, which we do in this work, by linking data to existing knowledge.It includes inferring schema elements from implicit data structures, such as graph-based datasets [22,26], enriching schemas with new statements or entity typing (e.g., rdf:type) [13,38], and identifying schema patterns like frequent RDF graph structures [22,13,9].The rise of NoSQL databases has introduced new challenges for schema discovery due to their lack of predefined schemas and high variability in data representation.Work has focused on inferring implicit schemas from NoSQL data, such as using hierarchical clustering for property graphs [15] and schema inference algorithms for JSON documents [8,17].More recent approaches leverage LLMs to extract attribute values and add semantic meaning to discovered schemas, complementing traditional techniques like clustering and rule-based methods [16,31].</p>
<p>Unlike prior work focused on schema alignment, enrichment, or domainspecific inference, our approach introduces a generalizable, human-in-the-loop workflow for schema discovery using LLMs.It uniquely combines automated extraction with expert refinement to address domain specificity, semantic complexity, and data fragmentation.Implemented in the schema-miner tool, this is the first framework to systematically mine schemas from unstructured scientific text at scale, adaptable to various LLMs and domains.This sets our work apart from recent LLM-based efforts that emphasize schema enrichment [31] rather than full schema discovery.</p>
<p>Task Definition</p>
<p>This work addresses the task of schema discovery-identifying and formalizing the underlying structure of data in scientific papers.Schema discovery is key to standardizing diverse scientific data and supporting automation, integration, and formal reasoning.A schema S is defined as a tuple: S = (P, T, C, R), where P is a set of properties, T : P → T maps each property to a data type T , C defines constraints, and R captures relationships among nested structures.The goal is to extract candidate schemas S * from unstructured data D = {d 1 , d 2 , . . ., d n }, where d i ∈ D and D includes text-based or semi-structured sources.</p>
<p>Our Approach: LLMs4SchemaDiscovery</p>
<p>The LLMs4SchemaDiscovery framework (see Figure 1) comprises three iterative stages: initial schema generation, refinement, and finalization.The process begins with a specification document provided as input to the LLM, which generates an initial schema.This schema is iteratively refined using curated scientific knowledge from papers and expert feedback, enhancing its structural and semantic relationships.The final schema offers a comprehensive, semantically enriched representation of the target domain, with mechanisms to organize schema properties and relationships through an ontology lookup service API.Stage 2 (orange box) refines the schema using a small, expert-curated set of papers and optional feedback.Stage 3 (red box) finalizes the schema with a larger, non-curated collection of papers.The workflow iteratively updates the schema and concludes by grounding schema properties to ontologies using an ontology lookup service API.</p>
<p>Stage 1: Generate Initial Schema</p>
<p>In this stage, the LLM generates an initial JSON schema encompassing essential properties, their data types, and associated constraints for the target do-main.This foundational schema, guided by structured prompts and domain specifications, serves as the basis for further refinement and enrichment with domain-specific knowledge and ontological relationships in subsequent stages.The process is formalized as follows:</p>
<p>GenerateSchema(P, T, C, R) is defined as SystemPrompt(Role, Task, InputFormat, OutputFormat)+</p>
<p>UserPrompt(DomainSpecifications),</p>
<p>where SystemPrompt specifies structured instructions provided to the LLM, consisting of: Role, assigning the LLM a specific function (e.g., "You are an expert in schema design for scientific data"); Task, defining the goal (e.g., "Identify properties, data types, constraints, and relationships to generate an initial schema from the provided domain specifications"); InputFormat, describing the format of the input data that will be provided via the user prompt, such as free text or semi-structured data; and OutputFormat, defining the expected schema structure-including P , T , C, and R-formatted as JSON.User-Prompt(DomainSpecification) represents the unstructured or semi-structured domain specifications provided by the human expert, including descriptive details, domain-specific examples, or predefined metadata.The output is the initial schema S 1 = (P 1 , T 1 , C 1 , R 1 ), where P 1 denotes properties identified by the LLM, T 1 maps data types to properties, C 1 includes inferred or specified constraints, and R 1 captures relationships among nested structures.</p>
<p>Stage 2: Refine Schema</p>
<p>The refinement stage enhances the initial schema by iteratively analyzing a curated collection of scientific papers and incorporating expert feedback.Using a small set of 1 to 10 expert-selected papers, the LLM refines the schema by updating its properties, mapping refined data types, revising constraints, and identifying or modifying relationships between schema elements.The iterative process ensures the schema becomes both specific and generalizable, capturing structural and semantic consistency across various research descriptions.A human-in-theloop approach is employed, where domain experts review the schema at each iteration, providing feedback to guide updates and address potential errors or omissions.</p>
<p>RefineSchema(P, T, C, R) is defined as
SystemPrompt(Role, Task, InputFormat, OutputFormat)+ UserPrompt(PrevSchema, SciPaper, ExpertFeedback),
where SystemPrompt specifies the structured instructions provided to the LLM and consists of: Role, which defines the LLM's function (e.g., "You are an expert in refining scientific schemas using curated papers and feedback"); Task, which specifies the objective (e.g., "Iteratively refine the schema by analyzing properties, data types, constraints, and relationships within the context of the provided scientific paper and feedback, while ensuring semantic consistency"); InputFormat and OutputFormat are the same as before.The UserPrompt incorporates PrevSchema, i.e., the schema S 1 generated in Stage 1 or the previous step in Stage 2. SciPaper: A single paper from a curated collection of n scientific papers, where 1 ≤ n ≤ 10.Each paper provides domain-specific information to enrich the schema.ExpertFeedback (optional): Feedback from a domain expert to further improve the schema.</p>
<p>Expert feedback in this stage is solicited based on clear guidelines to ensure relevance and clarity.Experts can provide feedback in one of two ways:</p>
<p>(1) as descriptive text addressing four guiding questions-Should any properties be merged, and what would you name the merged property?Which properties should be grouped into a single unit, and how would you describe it?Are there any essential properties missing?Are the current property descriptions clear and comprehensive?Or (2) through direct edits to the schema, modifying properties, constraints, or relationships as needed.These methods balance high-level conceptual feedback with precise, actionable changes.Our domain expert feedback guidelines is released online.By incorporating both feedback types, this stage iteratively refines the schema while evaluating the most effective method for LLM-driven improvements.Systematic empirical tests are explored in section 7.</p>
<p>This iterative process continues for each paper in the curated set, progressively refining the schema through semantic enrichment, expert guidance, and LLM-driven observations from the research papers, ensuring the schema aligns with the domain's structural and semantic requirements.</p>
<p>The output of this stage is the refined schema
S 2 = (P 2 , T 2 , C 2 , R 2 )
, where P 2 represents the updated set of properties derived from the scientific paper and expert feedback, T 2 maps these refined properties to their updated data types, C 2 captures the revised constraints inferred or specified during the refinement process, and R 2 encompasses any new relationships between schema elements.</p>
<p>Stage 3: Finalize Schema</p>
<p>The finalization stage refines the schema using a larger, uncurated corpus of up to 100 or more scientific papers to enhance its structural and semantic comprehensiveness and generalizability.The LLM validates and expands the schema by incorporating new properties, correcting omissions, and ensuring appropriate data types and constraints while avoiding irrelevant or redundant additions.Domain-expert feedback remains critical, guiding iterative refinements to ensure accuracy, generalizability, and semantic robustness.</p>
<p>FinalizeSchema(P, T, C, R) is defined as
SystemPrompt(Role, Task, InputFormat, OutputFormat)+ UserPrompt(PrevSchema, SciPaper, ExpertFeedback),
where the structure follows RefineSchema but adapts to the larger dataset.The output of this stage is the finalized schema S 3 = (P 3 , T 3 , C 3 , R 3 ), representing a comprehensive and semantically robust structure for the target process.This stage ensures the schema's completeness and general applicability across diverse research descriptions.</p>
<p>Contrasting stages 2 and 3, the refinement stage 2, which uses a small, domain-expert curated papers (1-10), helps establish a high-quality, domaingrounded baseline schema.By first aligning the LLM-generated schema with authoritative, carefully selected example research papers, the model can integrate core concepts and domain-specific nuances more reliably.This ensures that the schema's foundational structure and terminology are accurate before it is exposed to the larger, more heterogeneous collection of up to 100 or even more non-curated papers in stage 3.As a result, the subsequent broader refinement stage can generalize and expand the schema while retaining its integrity and relevance, ultimately leading to a more robust and widely applicable schema.</p>
<p>Stage 4: Ontology Grounding</p>
<p>The ontology lookup service (OLS) represents the final stage of schema discovery, grounding schema elements to relevant ontology concepts.Designed with a plug-and-play modus, the OLS can integrate with APIs from various institutions for their curated knowledge bases tailored to specific domains.This flexibility allows the system to adapt to different scientific disciplines.OLS integration into schema-miner involves four steps: 1) Preprocessing: Replace underscores with spaces for ontology label compatibility.2) Search: Query OLS resources-classes, properties, individuals, and ontologies-via the OLS API. 3) Validation: Exclude candidates lacking descriptions to ensure interpretability.4) Ranking: Use a sentence-transformer model to score similarity between query terms and ontology descriptions, prioritizing description-based matches to select top-k candidates.This process enhances schema properties with ontology-grounded elements, ensuring semantic rigor and alignment with domain standards.</p>
<p>For instance, in the materials science domain, the TIB Terminology Service (TS) offers seamless integration as a curated knowledge base of ontologies, supporting semantic alignment.Of the 94 ontologies identified in [33], 21 are available in TS, along with 19 from [43].The NFDI4Chem project collection significantly overlaps with these, comprising 39 ontologies.To address gaps, four additional ontologies-'ChemOnt,' 'OntoKin,' 'QUDT,' and 'OntoCAPE'-were manually added, resulting in a refined pool of 50 unique ontologies.By integrating metadata from TS, the lookup service enriches schema properties with ontological context, enhancing semantic coherence and interoperability.</p>
<p>schema-miner Tool Usage</p>
<p>The schema-miner tool enables users to discover schemas in JSON format for a target domain in a practical and configurable manner.Parameters such as API keys, base URLs, and model settings are managed in a dedicated .envconfiguration file.The workflow begins by preparing a knowledge base, which includes an initial domain specification document and relevant research papers.</p>
<p>For machine processing, the input documents are in plain text format.If research papers are in PDF format, schema-miner includes a script that converts them to plain text using LangChain's PyPDFLoader.The script takes the directory of the PDFs and returns the text files to the same directory.</p>
<p>Schema mining proceeds in three stages after preparing the knowledge base.Stage 1 generates an initial JSON schema using the domain specification and selected LLM.Input: Domain specification and LLM configuration.Output: Initial JSON schema saved to the specified directory.Stage 2 iteratively refines the schema by analyzing curated research papers and integrating expert feedback.Input: Initial schema, curated papers, and expert input.Output: Iteratively updated JSON schema.Stage 3 validates and finalizes the schema using a broader, uncurated corpus to ensure generalizability and semantic robustness.Input: Refined schema and uncurated research papers.Output: Final JSON schema with improved coverage.A human-in-the-loop workflow supports user feedback and iteration control.Sample runs and detailed documentation are in the README.</p>
<p>Application: Materials Science Use Case</p>
<p>In 2023, industry leaders Merck and Intel launched the "AI-Aware Pathways to Sustainable Semiconductor Process and Manufacturing Technologies (AWASES)" project [1], in the Materials Sciences with a key focus on, "Turning Online Atomic Layer Deposition (ALD) and Etching (ALE) Databases Into AI-Ready Tools for Development of New Sustainable Materials and Fabrication Processes" [27].ALD's precise control over thin-film deposition is critical for advancing highperformance semiconductor and electronics manufacturing, making it a priority for these industry leaders.To address this, we propose semantic modeling of ALD processes in KGs as a solution for creating AI-ready representations.Schema discovery is a crucial step in this endeavor, and we take ALD processes as a use case to test schema-miner.Specifically, we apply schema-miner to generate schemas for ALD process descriptions in two contexts: experimental and simulation.This use case is particularly compelling due to the involvement of domain experts within the project collaboration, who provide iterative feedback on the generated schemas during refinement stages 2 and 3.The remainder of the paper presents systematic experiments in both ALD settings, demonstrating the efficacy of schema-miner as a schema discovery tool.</p>
<p>The reproducibility and control of ALD processes (see Figure 2) make them essential for advanced electronics, photovoltaics, energy storage, and catalysis [5], while their consistency supports predictive AI models for process development.ALD is performed through laboratory experiments and computational simulations.ALD experiments, though based on straightforward self-limiting chemical processes, require meticulous design and execution to ensure reliable outcomes [40,45].Researchers must define the application, select suitable precursors, co-reactants, and substrates, and optimize parameters such as pulse and purge durations, reactor type, temperature, and pressure.Repeated experiments ensure reproducibility, and characterization verifies properties like thickness, growth per Fig. 2.An ALD cycle of two half-reactions: precursor addition and surface reaction, followed by co-reactant intro., with purge phases ensuring clean, controlled growth [45].</p>
<p>cycle, structure (e.g., crystallinity, composition), and morphology (e.g., conformality, uniformity) [23].In contrast, ALD simulations advance process understanding, complementing experiments or serving as standalone studies.These range from atomistic models, which explore mechanisms and reaction energies [28], to continuum models analyzing reactor-scale properties like gas flow [46].Commonly studied properties, such as reaction step energies or growth rates [39], often lack standardized reporting in scientific papers, hindering analysis and comparison.Semantic web technologies can address this by structuring key information, improving the efficiency of literature searches and studies for ALD.</p>
<p>Experiments and Results</p>
<p>We now present our experiments applying schema-miner to ALD process experiments and simulations to discover their schemas, respectively.In stage 1, domain experts provided process specification documents for both ALD experiment and simulation scenarios.In stage 2, the experts curated seven high-quality papers for each setting.Finally, in stage 3, the research papers collection was sourced from the AtomicLimits ALD Database developed by TU/e in 2019.Next, we provide details of the experimental setup.</p>
<p>Experimental Setup</p>
<p>The schema-miner tool is implemented in Python, using the LangChain library for interfacing with LLMs.In our experiments, we tested three models: GPT-4o (ver.2024-08-06), GPT-4-turbo (ver.2024-04-09), and LLama 3.1 (8B).For OpenAI models (GPT-4o and GPT-4-turbo), we used the ChatOpenAI class from LangChain to interface with OpenAI services.For LLama 3.1 (8B), we utilized the Scalable AI Accelerator (SAIA) platform, which supports multiple open-source LLMs via an OpenAI-compatible API, ensuring seamless integration with tools like ChatOpenAI.schema-miner also integrates with Ollama, providing users a choice of a wide range of open-source LLMs.The key hyperparameters adjusted in our experiments were context length and temperature.Context length varied based on model architecture; for the three models used in our study, we set a uniform context length of 128K tokens.To balance output stability and creativity, we used a fixed temperature value of 0.3 across all models.For the cloud-based GPT models, schema-miner was executed using minimal local resources on a personal laptop.Although the Llama 3.1 8B model is CPU-compatible, we leveraged an institutional GPU node (64-core CPU, 500 GB RAM, RTX 3090 GPU) to expedite inference.Notably, the model itself requires no more than 16 GB of RAM to run.A key feature of schema-miner is its flexibility and suitability, especially in compute-constrained environments, allowing users to integrate their LLM of choice, including smaller distilled or quantized LLM variants.The compute requirements scale with the model size and the applied quantization level.</p>
<p>Earlier in section 4, we introduced two methods for soliciting domain expert feedback: (1) descriptive text and (2) direct edits to the schema.These methods informed the design of our experimental settings, which comprised four main types.In Experiment 1, descriptive feedback was provided in two variants: (a) included only at the first iteration or (b) included at every iteration.In Experiment 2, expert-edited schemas were used, with reviews conducted either (a) only at the first iteration or (b) at every iteration.Experiment 3 combined both descriptive feedback and expert-edited schemas, also with two variants: (a) reviewed only at the first iteration or (b) reviewed at every iteration.Finally, Experiment 4 served as a baseline with no feedback.These variations aimed to evaluate the model's sensitivity to different feedback types and their impact on schema quality.Experiment 3, where both feedback formats were incorporated at every iteration, emerged as the best-performing protocol based on domain expert evaluations, identifying its schema as the most accurate representation of the ALD process.A total of 21 experiments were conducted with schema-miner end-to-end, comprising seven experiments for the three LLMs tested.</p>
<p>Results and Discussion</p>
<p>As a first step, we conduct a surface analysis of the variability in the schemas generated by the three LLMs across stages 1, 2, and 3 w.r.t.quantitative measures for just the schemas from Experiment 3.</p>
<p>Quantitative Results.Here, the focus was on measuring property variance and changes across models and stages, addressing questions like: How did the schema evolve across stages?And how closely aligned were the schemas generated by three different LLMs?Due to space constraints, this discussion is limited to ALD experimental schemas.However, we provide all generated schemas-per stage, per step in stages 2 and 3, per experimental setting, and per LLM for both ALD experiments and simulations-in our software repository.We measured schema variance using three complementary metrics commonly used in text generation to compare candidate and reference texts.Here, one LLM's output serves as the candidate schema compared against the outputs of the other two LLMs as reference schemas.The metrics used are ROUGE [24], BLEU [36], and BERTScore [48].ROUGE measures recall and n-gram overlap, BLEU evaluates precision in text summarization, and BERTScore, using BERT-type embeddings, Table 1.Quantitative schema variance across Stages 1, 2, and 3 of schema-miner for ALD experimental processes, evaluated using ROUGE-L, BLEU, and BERTScore metrics, comparing schemas from GPT-4o, GPT-4-turbo, and LLama 3.1 (8B).assesses semantic similarity.For BERTScore, we used the SciBERT model [12], given its suitability for scientific text.The results are shown in Table 1.</p>
<p>In stage 1, RougeL scores highlight differences in schema alignment across LLMs.GPT-4-turbo achieved a RougeL of 0.4118 compared to LLama 3.1 (8B), indicating high alignment, while LLama 3.1 (8B) scored 0.3100 against GPT-4o, showing weaker agreement.GPT-4o had balanced performance with a RougeL of 0.3428 compared to GPT-4-turbo, suggesting greater structural similarity between the GPT-4 models than with LLama 3.1 (8B).Semantic similarity, measured by BERTScore, was consistent across models, ranging from 0.8044 to 0.8098.In stage 2, GPT-4-turbo demonstrated strong semantic alignment with GPT-4o, achieving a BLEU score of 0.4515, while LLama 3.1 (8B) scored 0.3316 in the same comparison.These results suggest that GPT-4-turbo produced semantically rich but slightly less structurally coherent schemas compared to LLama 3.1 (8B).By stage 3, GPT-4-turbo and GPT-4o showed strong semantic and structural alignment, with a BLEU score of 0.4151 and BERTScore of 0.8046.Overall, the results highlight GPT-4o's robustness and adaptability, LLama 3.1 (8B)'s strength in semantic comprehension, and GPT-4-turbo's challenges in maintaining generalizability in later stages.</p>
<p>Qualitative Results and Discussion.This section forms the core of the paper, discussing key observations on applying schema-miner w.r.t.qualitative aspects of schema generation, often informed by domain expert feedback.</p>
<ol>
<li>LLM Stability: Stability refers to an LLM's ability to maintain consistency across runs and avoid unnecessary additions during refinement, particularly in stages 2 and 3. GPT-4o and LLama 3.1 (8B) demonstrated high stability, introducing no irrelevant changes.In contrast, GPT-4-turbo frequently added overly specific details, reducing the schema's generalizability and utility for domain experts.2. Comprehension of the ALD Process: A key factor was evaluating how well each model understood the ALD process and adapted the schema accordingly.GPT-4o and LLama 3.1 (8B) demonstrated superior comprehension, capturing relationships and constraints inherent to ALD processes.While GPT-4-turbo produced acceptable schemas, its understanding was less robust.This suggests that certain LLMs may be better suited for comprehending scientific domains, which is crucial for generating high-quality schemas.3. Complexity of the Schema: During schema refinement in stages 2 and 3, experts observed that GPT-based models often created overly nested structures with unnecessary complexity and repetitive properties.Some schemas became excessively long due to redundant elements within nested structures.However, expert feedback was crucial in addressing these issues, positively shaping model behavior, and guiding it toward producing more accurate and concise schemas.This highlights the efficacy of incorporating domain expert feedback in the workflow of schema-miner.4. Schema Property Data Types and Units.The LLM was effective at assigning accurate data types and units to properties, such as temperature in degrees Celsius, pressure in pascals, dosing time in seconds, thickness in nanometers, and growth per cycle in nanometers/cycle.However, some errors occurred.For instance, in the simulation schema generated by GPT-4o, the units for reaction rate were incorrectly assigned as atoms/second instead of moles/second.Additionally, the LLM often added unnecessary boolean properties, which confused domain experts about their relevance to the process.These issues could be remedied through continuous expert feedback and introducing more examples of ALD processes.Since schema-miner incorporated expert feedback, this workflow of the LLM and human expert complementing each other is offered as a general recommendation of this work, as it proved to be efficacious in various scenarios in our experiments.5. Repetition of Properties.Domain experts noted repeated properties within the schema, causing confusion.For example, in the schema generated by LLama 3.1 (8B), properties such as uniformity, roughness, density, temperature profile, and chemical composition were duplicated in both observables.filmPropertiesand experimentalResults.results.filmProperties,with nearly identical structures and descriptions.The issue was corrected by including specific instructions in the prompt for the LLM to avoid repeating properties based on domain expert feedback.The experiments were rerun to better effect.6.Effect of Stage 1.In both experimental and simulation use cases, the process specification document provided a strong foundation for LLMs to list and structure ALD process properties.The experimental specification document included properties like precursor and co-reactant selection, thickness control, saturation, and material properties.Similarly, the simulation document covered properties such as growth rate, surface desorption, decomposition, and binding.Using these documents and the pre-trained knowledge of LLMs, initial schemas were generated.The schemas organized relevant information into nested objects, creating semantic clusters of related properties.For example, in the experimental case, precursor and coreactant were grouped as reactants, while temperature, pressure, and cycle details were grouped as process conditions.This proved to be a strong base of basic properties to build upon for later stages 2 and 3, looking at scientific literature, allowing the schemas to evolve into more advanced forms.7. Effect of Larger Research Paper Collection in Stage 3. In stage 3, a broader collection of research papers, including ALD review papers, was used.This caused some models to deviate from the original schema by incorporating overly specific properties tied to individual papers.GPT-4-turbo was particularly affected in the simulation use case, showing significant divergence from the schema created in stage 2. In contrast, GPT-4o and LLama 3.1 (8B) remained relatively consistent.8. Effect of the Different Feedback Methods.In evaluating feedback methods, descriptive feedback, schema editing, and their combination were tested.In the simulation use case, descriptive feedback guided models to include missing details and correct inaccuracies.For example, experts noted the need for methodological details (e.g., timesteps for MD simulations or functionals for DFT) and distinctions between simulation and experimental findings, prompting improvements to align schemas with expert expectations.Edited schemas allowed experts to directly correct errors, such as removing invalid properties (e.g., substrate velocity) and refining groupings (e.g., limiting reactor conditions to pressure, carrier gas flow, precursor flow, and gap distance).The most effective approach combined both methods, offering clarity on missing details through descriptive feedback and precise corrections through edits.This comprehensive strategy improved schema groupings, added domain-relevant properties, and reduced inconsistencies, demonstrating its efficacy in aligning schemas with expert standards.Note that we also tested the no feedback setting in experiment 4. Experts observed that schemas became overly specific to individual research papers, as no restrictions were imposed on the model's output, leading to derailment.9. Overall LLM Performance in schema-miner across Stages.In stage 1, GPT-4o and LLama 3.1 (8B) demonstrated the highest structural and semantic coherence in the experimental use case, while LLama 3.1 (8B) excelled in the simulation use case with superior classification and extraction.In stage 2, domain experts observed that more complex LLMs tended to deviate from feedback, but GPT-4-turbo performed best for the experimental use case, identifying key properties without adding irrelevant details.For the simulation use case, GPT-4o produced the most structured and detailed schema.The best results in this stage were achieved when both feedback formats-descriptive and schema edits-were incorporated, providing clear guidance for corrections.In stage 3, using a larger collection of scientific papers, GPT-4o and LLama 3.1 (8B) outperformed GPT-4-turbo in structuring and identifying key properties for both use cases, while GPT-4-turbo's schemas lacked detail, included irrelevant properties, and exhibited poor structuring.The final schema for the experimental use case (see Figure 3), produced by GPT-4o, has four levels of nesting with top-level properties as ALD system, reactant selection, process parameters, and material properties, further detailing nested aspects like reactor and thickness control.For the simulation use case, the final schema, selected from GPT-4o and LLama 3.1 (8B) outputs, includes three levels of nesting with top-level properties like simulation parameters, materials, growth rate, and reactor conditions.</li>
</ol>
<p>Discussion</p>
<p>While our evaluation discussion in this paper focused on the ALD use case in materials science, schema-miner is inherently designed to be domain-and use-caseagnostic, broadly applicable across any scientific discipline.Its modular architecture allows users to provide domain specifications and relevant literature corpora, making it highly adaptable to new use cases.In the life sciences, for example, schema-miner could model workflows such as artificial enzyme engineering, where process parameters include substrate binding affinities, catalytic turnover rates, and amino acid modifications-all commonly embedded in diverse reporting styles across biochemical literature.In DNA autocatalysis research, relevant parameters like reaction rates, temperature profiles, and nucleotide sequences are often reported heterogeneously, necessitating automated schema generation to consolidate process knowledge.Similarly, for metabolic reaction networks, schema-miner can help extract structured information about metabolite concentrations, flux rates, enzyme activity levels, and regulatory feedback loops from pathway modeling studies.As additional domain examples, in environmental science, use cases such as redox chemistry in soils involve parameters like redox potential, microbial community composition, electron donor/acceptor availability, and mineralogy-typically scattered across field study papers, lab analyses, and simulation results.Manually standardizing this information into a schema is prohibitively time-consuming.A tool like schema-miner, operating over a large, heterogeneous corpus, helps to surface common patterns and abstract them into generalized, semantically meaningful schemas, enabling integration across studies.In engineering sciences, as another domain, schema-miner can be applied to fluid dynamics simulations by extracting key parameters such as flow velocity, pressure gradients, turbulence models, boundary conditions, and mesh resolution from computational studies and experimental setups.Even in social sciences, schema-miner can be used to develop structured representations of qualitative research protocols by extracting coding themes, participant demographics, and interview formats from ethnographic or survey-based studies.</p>
<p>In all these examples, the richness, variability, and scale of scientific reporting make automated schema discovery essential.Schema-miner's human-in-the-loop design enables domain experts to guide schema evolution while leveraging the scalability of LLMs to parse and structure large, unstructured corpora.This approach bridges the gap between free-text scientific discourse and machineactionable knowledge, supporting the creation of semantically coherent schemas that standardize information and enable downstream applications such as KG construction and cross-disciplinary integration.</p>
<p>Conclusion and Future Work</p>
<p>We presented schema-miner, a tool for LLM-assisted schema discovery, outlining its workflow and capabilities.Applied to a complex scientific domain, our experiments demonstrated the effectiveness of combining LLMs with expert feedback in a structured human-in-the-loop process.A maintenance plan has been released, and we invite community contributions to support ongoing development and feature expansion.Future work could explore ensemble approaches that combine the strengths of multiple LLMs-for example, integrating one model's structural precision with another's domain-specific semantics-to generate more robust, generalizable schemas.This could further optimize schema discovery for scientific knowledge representation and AI-ready data modeling.</p>
<p>Fig. 1 .
1
Fig. 1.Overview of the LLMs4SchemaDiscovery workflow implemented in schemaminer.Stage 1 (gray box) generates an initial schema from domain specifications.Stage 2 (orange box) refines the schema using a small, expert-curated set of papers and optional feedback.Stage 3 (red box) finalizes the schema with a larger, non-curated collection of papers.The workflow iteratively updates the schema and concludes by grounding schema properties to ontologies using an ontology lookup service API.</p>
<p>Fig. 3 .
3
Fig. 3.A UMLS diagram of the best ALD experimental schema from schema-miner.</p>
<p>Sadruddin &amp; D'Souza et al.
Acknowledgments.This work was supported by the AWASES project (funded by Merck and Intel), the KISSKI AI Service Center (BMBF, Grant ID: 01IS22093C) and SCINEXT (BMBF, Grant ID: 01IS22070).Disclosure of Interests.The authors have no competing interests to declare that are relevant to the content of this article.
J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>G Aldafian, M Abdelrahman, A C Ngomo, arXiv:2101.08014Deep learning based schema matching. 2021arXiv preprint</p>
<p>Qwen: Open-source large language models by alibaba cloud. Alibaba Cloud, 2024</p>
<p>Characterizing the field of atomic layer deposition: Authors, topics, and collaborations. E Alvaro, A Yanguas-Gil, Plos one. 131e01891372018</p>
<p>Transformer models: an introduction and catalog. X Amatriain, A Sankar, J Bing, P K Bodigutla, T J Hazen, M Kazi, arXiv:2302.077302023arXiv preprint</p>
<p>Improving access to scientific literature with knowledge graphs. S Auer, A Oelen, M Haris, M Stocker, J D'souza, K E Farfar, L Vogt, M Prinz, V Wiens, M Y Jaradeh, Bibliothek Forschung und Praxis. 4432020</p>
<p>Parametric schema inference for massive json datasets. M A Baazizi, D Colazzo, G Ghelli, C Sartiani, Proceedings of the 20th International Conference on Extending Database Technology. the 20th International Conference on Extending Database Technology2017</p>
<p>Parametric schema inference for massive JSON datasets. M Baazizi, D Colazzo, G Ghelli, C Sartiani, 10.1007/s00778-018-0532-7VLDB J. 2842019</p>
<p>J Bai, S Bai, Y Chu, Z Cui, K Dang, X Deng, Y Fan, W Ge, Y Han, F Huang, arXiv:2309.16609Qwen technical report. 2023arXiv preprint</p>
<p>Schemas for integration and translation of structured and semi-structured data. C Beeri, T Milo, International conference on database theory. Springer1999</p>
<p>Scibert: A pretrained language model for scientific text. I Beltagy, K Lo, A Cohan, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingEMNLP-IJCNLP2019</p>
<p>Entity type prediction leveraging graph walks and entity descriptions. R Biswas, J Portisch, H Paulheim, H Sack, M Alam, U Sattler, A Hogan, C M Keet, V Presutti, J P A Almeida, H Takeda, P Monnin, G Pirrò, 10.1007/978-3-031-19433-7_23The Semantic Web -ISWC 2022 -21st International Semantic Web Conference, Virtual Event. Proceedings. Lecture Notes in Computer Science. C Amato, SpringerOctober 23-27, 2022. 202213489</p>
<p>Linked data-the story so far. C Bizer, T Heath, T Berners-Lee, Linking the World's Information: Essays on Tim Berners-Lee's Invention of the World Wide Web. 2023</p>
<p>Discopg: Property graph schema discovery and exploration. A Bonifati, S Dumbrava, E Martinez, F Ghasemi, M Jaffré, P Luton, T Pickles, 10.14778/3554821.3554867Proc. VLDB Endow. VLDB Endow202215</p>
<p>Extractgpt: Exploring the potential of large language models for product attribute value extraction. A Brinkmann, R Shraga, arXiv:2310.125372023arXiv preprint</p>
<p>Discovering implicit schemas in json data. J L Cánovas Izquierdo, J Cabot, International Conference on Web Engineering. Springer2013</p>
<p>A catalog of transformer models. D' Souza, J , 10.48366/R6093372023</p>
<p>. N Guarino, D Oberle, S Staab, 2009What is an ontology? Handbook on ontologies</p>
<p>A survey on deep learning for schema matching. J Hu, J Li, C Zhang, X Dong, ACM SIGMOD Record. 4812019</p>
<p>A Q Jiang, A Sablayrolles, A Mensch, C Bamford, D S Chaplot, D Casas, F Bressand, G Lengyel, G Lample, L Saulnier, arXiv:2310.06825Mistral 7b. 2023arXiv preprint</p>
<p>Formal concept discovery in semantic web data. M Kirchberg, E Leonardi, Y S Tan, S Link, R K L Ko, B S Lee, Formal Concept Analysis. F Domenach, D I Ignatov, J Poelmans, Berlin Heidelberg; Berlin; HeidelbergSpringer2012</p>
<p>Atomic layer deposition. H C Knoops, S E Potts, A A Bol, W Kessels, Handbook of Crystal Growth. 2015Elsevier</p>
<p>Rouge: A package for automatic evaluation of summaries. C Y Lin, Text summarization branches out. 2004</p>
<p>From tabular data to knowledge graphs: A survey of semantic table interpretation tasks and methods. J Liu, Y Chabot, R Troncy, V Huynh, T Labbé, P Monnin, J. Web Semant. 761007612023</p>
<p>Statix -statistical type inference on linked data. A Lutov, S Roshankish, M Khayati, P Cudré-Mauroux, IEEE International Conference on Big Data. IEEE2018. 2018</p>
<p>Turning online ald and ale databases into ai-ready tools for development of new sustainable materials and fabrication processes. A Mackus, B Macco, B Karasulu, J D'souza, S Auer, E Kessels, AVS 24th Int. Conf. on Atomic Layer Deposition. 2024ALD 2024</p>
<p>Area-selective atomic layer deposition of sio2 using acetylacetone as a chemoselective inhibitor in an abc-type cycle. A Mameli, M J M Merkx, B Karasulu, F Roozeboom, W E M M Kessels, A J M Mackus, 10.1021/acsnano.7b04701pMID: 28850774ACS Nano. 1192017</p>
<p>A I Meta, Llama: Large language model meta ai. 2024</p>
<p>R J Miller, P Andritsos, Schema discovery. 200326</p>
<p>Large language models for json schema discovery. M J Mior, arXiv:2407.032862024arXiv preprint</p>
<p>A I Mistral, Mistral ai: Next-generation open-weight language models. 2024</p>
<p>E Norouzi, J Waitelonis, H Sack, arXiv:2408.06034The landscape of ontologies in materials science and engineering: A survey and evaluation. 2024arXiv preprint</p>
<p>N F Noy, D L Mcguinness, A guide to creating your first ontology. 2001101</p>
<p>OpenAI: Gpt-4: Openai's most advanced system (2024). </p>
<p>Bleu: a method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W J Zhu, Proceedings of the 40th annual meeting of the Association for Computational Linguistics. the 40th annual meeting of the Association for Computational Linguistics2002</p>
<p>Automating schema matching and instance matching using deep learning: A survey. H Paulheim, European Semantic Web Conference. Springer2020</p>
<p>Type inference on noisy RDF data. H Paulheim, C Bizer, The Semantic Web -ISWC 2013. Springer2013</p>
<p>Combined ab initio quantum chemistry and computational fluid dynamics calculations for prediction of gallium nitride growth. D Sengupta, S Mazumder, W Kuykendall, S A Lowry, 10.1016/j.jcrysgro.2005.02.036Journal of Crystal Growth. 27932005</p>
<p>Recent advances in theoretical development of thermal atomic layer deposition: a review. M Shahmohammadi, R Mukherjee, C Sukotjo, U M Diwekar, C G Takoudis, Nanomaterials. 1258312022</p>
<p>A Shepherd, 10.1575/1912/65893Science on schema.org. 2023</p>
<p>Federated database systems for managing distributed, heterogeneous, and autonomous databases. A P Sheth, J A Larson, ACM Computing Surveys (CSUR). 2231990</p>
<p>Ontologies4chem: the landscape of ontologies in chemistry. P Strömert, J Hunold, A Castro, S Neumann, O Koepler, Pure and Applied Chemistry. 9462022</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Atomic-layer deposition process development-10 steps to successfully develop, optimize and characterize ald recipes. M Vos, 2019</p>
<p>Reactor scale simulations of ald and ale: Ideal and non-ideal self-limited processes in a cylindrical and a 300 mm wafer crossflow reactor. A Yanguas-Gil, J A Libera, J W Elam, 10.1116/6.0001212Journal of Vacuum Science &amp; Technology A. 3966240409 2021</p>
<p>Schema-adaptable knowledge graph construction. H Ye, H Gui, X Xu, X Chen, H Chen, N Zhang, Findings of the Association for Computational Linguistics: EMNLP 2023. 2023</p>
<p>T Zhang, V Kishore, F Wu, K Q Weinberger, Y Artzi, arXiv:1904.09675Bertscore: Evaluating text generation with bert. 2019arXiv preprint</p>
<p>Schere: Schema reshaping for enhancing knowledge graph construction. D Zhou, B Zhou, Z Zheng, A Soylu, O Savkovic, E V Kostylev, E Kharlamov, Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management. the 31st ACM International Conference on Information &amp; Knowledge Management2022</p>            </div>
        </div>

    </div>
</body>
</html>