<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7552 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7552</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7552</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-138.html">extraction-schema-138</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <p><strong>Paper ID:</strong> paper-60126292c0b31dfc8628d99001e057b9f8355000</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/60126292c0b31dfc8628d99001e057b9f8355000" target="_blank">SciAgent: Tool-augmented Language Models for Scientific Reasoning</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> This work develops SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving, and constructs a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools.</p>
                <p><strong>Paper Abstract:</strong> Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs’ abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than 8.0% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7552.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7552.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCIAGENT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciAgent (tool-augmented language model agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework and set of fine-tuned LLM agents that act as tool-users: they plan, retrieve domain-specific Python functions from a provided toolset, generate code+explanations, and execute code to solve quantitative scientific problems across multiple domains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SCIAGENT (family)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B / 8B / 13B variants reported</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction-fine-tuned on MATHFUNC; retrieval-augmented / tool-use enabled (planning+retrieval+action modules)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain: Mathematics, Physics, Chemistry, Finance, EECS (electrical engineering & CS)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Text-based simulation of domain computations by retrieving/writing and executing Python functions to solve quantitative, textbook-style scientific problems (e.g., compute integrals, apply physics formulae, solve equations, compute thermodynamic or financial quantities).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Retrieval-augmented prompting with a unified Program-of-Thought (PoT) style prompt (two demonstrations); internal pipeline: generate planning (high-level steps), retrieve top-3 functions using a dense retriever, generate interleaved rationale and program (optionally calling retrieved functions), then execute the program via Python executor; instruction-finetuning on MATHFUNC (mix of planning and action instructions).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (exact-answer correctness on SciToolBench and CREATION challenge subsets)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>SciAgent-DEEPMATH-7B: 40.0% (overall ALL on SciToolBench human+synthetic combined, Table 2); SciAgent-LLAMA3-8B: 34.7% (ALL); SciAgent-Coder (7B): 27.6% (ALL); SciAgent-Coder (13B): 29.8% (ALL).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Best open-source baselines (without SciAgent tool-augmented fine-tuning) range from ~6.9% to ~26.7% depending on model and config; ChatGPT baseline ~31.0% (ALL human+synthetic combined in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['fine-tuning on math-related, tool-augmented corpus (MATHFUNC)', 'model backbone / pretraining (math-specialized pretraining like Deepseek-Math helps)', 'model size (7B/8B/13B differences reported)', 'retriever quality (hit@3 of retrieved functions)', 'planning module (generating targeted retrieval queries)', 'cross-retrieval strategy for dataset construction (reduces ad-hoc function artifacts)', 'presence/quality of domain-specific toolset (related vs unrelated vs no toolset)', 'composition of training data (function-augmented vs function-free samples)']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Retriever returns 3 functions per question; unified PoT prompt with two demonstrations for models; MATHFUNC training: 31,375 samples + 5,981 math functions; retrieval model fine-tuned (RoBERTa-base backbone DPR) on query=[question; plan]; inference uses same retriever for all compared LLMs; execution performed by a Python executor; dataset-generation used nucleus sampling (temperature=0.6) for some steps; training used ZeRO Stage3 across GPUs with learning rates per backbone (e.g., 2e-5 for CodeLlama), batch size 128.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Despite improvements, SCIAGENT lags GPT-4 by ~20 percentage points; performance still limited when retriever hit@3 is perfect (~40% ceiling reported); tool attachment degrades performance for models not fine-tuned on tool-augmented data; removal of planning or function-augmented training data significantly reduces accuracy; agents may overfit to ad-hoc functions if dataset not constructed with cross-retrieval; performance varies by domain (Math generally stronger than other scientific domains).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7552.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCIAGENT-DEEPMATH-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SCIAGENT fine-tuned on Deepseek-Math backbone (7B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specific SciAgent variant built on a math-specialized 7B LLM (Deepseek-Math) fine-tuned on MATHFUNC to act as a retrieval-augmented, tool-using agent for multi-domain scientific problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SCIAGENT-DeePMATH</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>math-pretrained backbone; fine-tuned on MATHFUNC (instruction-tuned for planning+action), retrieval-augmented tool-user</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain (Math, Physics, Chemistry, Finance, EECS)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Solve quantitative scientific problems by generating plans, retrieving domain functions, producing code that calls these functions, and executing code to obtain numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Retrieval-augmented PoT-style prompting with two demonstrations; internal planning -> retrieval (top-3) -> action (code+rationale) -> execution; models trained via imitation learning on MATHFUNC (mixture of planning and action tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (exact correctness on SciToolBench and CREATION benchmark subsets)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>40.0% overall (ALL column in Table 2); human-annotated subset performance higher (see Table 2: 60.4% on CREATION with toolset for this model variant).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>ChatGPT: 31.0% (ALL); other open-source baselines range lower (see Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['math-specialized pretraining improves base math competence', 'fine-tuning on MATHFUNC critical for tool-use benefit', 'retriever quality and hit@3', 'planning module and cross-retrieval strategy', 'availability of domain-specific toolset']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Three retrieved functions provided; evaluation uses unified PoT prompt; retriever shared among all models; Python executor runs generated code; CREATION repurposed toolset of 2,047 functions used in that benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Although it outperforms ChatGPT, it still falls short of GPT-4; even with perfect retrieval, accuracy saturates (~40%) indicating limits in reasoning/model execution and other deficiencies (e.g., argument selection, code correctness, domain knowledge gaps).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7552.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCIAGENT-LLAMA3-8B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SCIAGENT fine-tuned on Llama-3 backbone (8B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An 8B SciAgent variant built on Llama-3 (open-source) fine-tuned on MATHFUNC, acting as a retrieval-augmented tool-using agent across scientific domains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SCIAGENT-Llama3</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>open-source LLM fine-tuned on MATHFUNC (instruction-tuned), retrieval-augmented tool-user</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain (Math, Physics, Chemistry, Finance, EECS)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Text-based simulation of domain computations by retrieving and calling domain functions inside generated Python code and executing it for numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>PoT-style prompting with two demonstrations; planning + retrieval + action pipeline; top-3 retrieved functions provided and optionally called.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy on SciToolBench (exact-answer correctness)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>34.7% overall (ALL, Table 2); outperforms many comparable open-source models after MATHFUNC fine-tuning (paper notes SciAgent-Llama3-8B surpasses comparable-size LLMs by >8.0% absolute accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Llama-3 baseline without MATHFUNC fine-tuning: ~26.0% (ALL column for Llama-3 8B without toolset in Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['fine-tuning on MATHFUNC (tool-augmented data)', 'retriever hit@3 and planning quality', 'model pretraining and size']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Shared retriever (3 functions); unified PoT prompt; models fine-tuned with imitation learning on planning/action tasks from MATHFUNC; evaluated on human-annotated and synthesized subsets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Still behind GPT-4; vulnerable to poor retriever quality or unrelated toolsets; removal of planning or function-augmented samples decreases performance appreciably.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7552.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A powerful closed-source large language model used as an upper-reference baseline in this work; evaluated both with and without attached toolsets as reference points.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary / very large (not specified in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>closed-source instruction-tuned model (not fine-tuned on MATHFUNC in this paper), evaluated as baseline with/without external toolset</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain (Math, Physics, Chemistry, Finance, EECS) as evaluated</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Solve textbook-style scientific problems via reasoning and code-generation when provided with toolset; serves as an upper benchmark for tool-augmented scientific reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Evaluated with/without provided toolsets; when toolsets provided, same unified PoT-based prompt and three retrieved functions were supplied; models instructed to call functions optionally.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (exact-answer correctness on SciToolBench and CREATION)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Without toolsets (reference): 59.2% ALL; With toolsets: 59.7% ALL (Table 2). On human-annotated subsets tool-augmented performance increased notably in some domains (e.g., math/physics).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Used as top-line baseline; other open-source models reported lower accuracies (see Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['benefits from attached toolsets when properly instructed', 'strong inherent reasoning and execution skills compared to open-source models']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Same retriever-provided functions and PoT prompt used for fairness; evaluations done on human-annotated and synthesized question subsets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Paper notes even GPT-4 has limited accuracy on some scientific tasks (e.g., prior work reports ~50% on TheoremQA); tool-augmentation yields gains but gaps with SciAgent variants vary by domain.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7552.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (OpenAI Chat Model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used chat-oriented LLM evaluated as a baseline for tool-augmented scientific reasoning; performance reported both with and without attached toolsets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary (not specified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>closed-source chat model/instruction-tuned; evaluated without additional fine-tuning on MATHFUNC</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Answered scientific benchmark questions; tested with optional provided toolsets (three retrieved functions) to assess benefit from external tools.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Unified PoT-based prompt with two demonstrations; three retrieved functions optionally provided.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Overall ALL: 31.0% without toolset; with toolset reported ~30.9% (Table 2) — small/variable gains depending on domain.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Used as a competitive baseline; SciAgent-DeepMath-7B reported ~40.0% ALL, outperforming ChatGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['not all models benefit from attached toolsets unless fine-tuned on tool-augmented data', 'domain and function relevance influences whether toolsets help']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Same retriever used to supply three functions; models evaluated with unified PoT prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>ChatGPT did not consistently benefit from attached toolsets in this evaluation and is outperformed by SciAgent variants fine-tuned on MATHFUNC.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7552.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToRA-Coder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ToRA-Coder (tool-integrated reasoning agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source code-capable LLM baseline (fine-tuned with Program-of-Thought style data) evaluated with/without toolsets to compare tool-use performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ToRA-Coder</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B and 13B variants reported</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction-fine-tuned on programmatic/mathematical corpora (tool-agnostic original fine-tuning); supplied with retriever functions at inference for comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Math-centered baseline but evaluated across SciToolBench domains</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Generate programmatic solutions to math/science questions, optionally calling provided functions.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Original ToRA instruction shape (PoT style) with appended tool-augmented description and provided retrieved functions; evaluated with same retriever.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>ToRA-Coder (7B) with no toolset: e.g., ~24.4% (CREATION) and varying across SciToolBench domains; with toolset performance varied and sometimes degraded (see Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Compared against SciAgent variants and other baselines; SciAgent-Coder surpassed ToRA-Coder by large margins after MATHFUNC fine-tuning (paper reports SciAgent-Coder surpasses ToRA-Coder by 13.4% (7B) and 12.7% (13B) in absolute accuracy on certain comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['original fine-tuning format may not be optimal for tool-use unless fine-tuned on tool-augmented data', 'retriever quality and instruction-shaping affect performance']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Evaluated using unified PoT prompt and the same retriever; for tool-augmented evaluation, three functions were provided and a short tool-augmented description appended to original prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>ToRA-Coder's performance can drop when attaching toolsets if it has not been fine-tuned on tool-augmented data; output shaping matters (variants with/without output shaping differ significantly).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7552.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MAmmoTH-Coder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MAmmoTH-Coder</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source LLM baseline fine-tuned on math-related corpora evaluated as a baseline for scientific tool-augmented reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MAmmoTH-Coder</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B and 13B variants reported</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction-fine-tuned on math corpora (tool-agnostic)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Math-centric baseline; evaluated across SciToolBench domains</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Generate programmatic problem solutions (math/scientific) without explicit tool-use or with optional retrieved functions appended at inference.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Original MAmmoTH instructions, with optional appended tool-usage note and retrieved functions for tool-augmented evaluation; unified PoT used in some comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>MAmmoTH-Coder (7B) without toolset: ~32.1% on MATH test set (Table 9); on SciToolBench varies (see Table 2; e.g., ALL ~26.7% in some configurations).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Used as a baseline for assessing the benefit of tool-augmented fine-tuning; SciAgent variants surpass it after MATHFUNC fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['math-specialized fine-tuning improves math competence', 'without tool-augmented fine-tuning models may not leverage toolsets effectively']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Shared retriever provided when evaluating tool-augmented scenarios; unified PoT prompt sometimes used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Performance may degrade when attaching unrelated toolsets or when model not adapted to using external functions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7552.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CodeLlama</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CodeLlama (code-capable LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source code-specialized LLM used as a baseline (7B and 13B) and also fine-tuned into SciAgent variants; evaluated with/without toolsets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CodeLlama</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B and 13B variants</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>pretrained code model; versions used both as baseline and fine-tuned (SciAgent-Coder)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain evaluation (math-heavy tasks included)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Generate executable Python solutions for scientific problems and optionally call retrieved functions.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Unified PoT-based prompt; when used as SciAgent-Coder, fine-tuned on MATHFUNC; when baseline, provided with retrieved functions via appending.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>CodeLlama baseline (7B) ALL ~6.9% (no toolset) rising to ~7.4% with toolset in some evaluations; SciAgent-Coder (fine-tuned from CodeLlama) significantly higher (e.g., 27.6% ALL for 7B SciAgent-Coder).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Used as baseline for showing fine-tuning benefits; SciAgent-Coder outperforms the original CodeLlama baseline by large margins after MATHFUNC fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['fine-tuning on MATHFUNC critical to gain effective tool-use ability', 'retriever and planning greatly influence performance']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Same retriever used; three functions provided; training hyperparameters: e.g., learning rate 2e-5 for CodeLlama fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Out-of-the-box CodeLlama performs poorly on SciToolBench unless fine-tuned on tool-augmented data; attaching toolsets to non-finetuned models can reduce performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e7552.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral (7B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source high-performance 7B LLM evaluated as a baseline with/without attached toolsets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>pretrained open-source LLM (not fine-tuned on MATHFUNC for baseline runs)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multi-domain (evaluated across SciToolBench domains)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Generate natural-language+code solutions to scientific problems; optionally use retrieved functions when provided.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Unified PoT-style prompt for evaluation; provided with top-3 retrieved functions for tool-augmented runs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Mistral (7B) ALL ~14.8% without toolset rising to ~13.7% with toolset depending on fine-tuning; SciAgent-Mistral variant (7B) achieved ~30.3% ALL after MATHFUNC fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Compared to SciAgent-Mistral which is fine-tuned on MATHFUNC, baseline Mistral performs worse.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['fine-tuning on MATHFUNC is necessary to benefit from toolsets', 'retriever quality affects final accuracy']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Shared retriever; unified PoT prompt; fine-tuning hyperparameters varied for SciAgent variants (2e-6 used for Mistral fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Without tool-augmented fine-tuning, attaching function toolsets may not improve or may slightly degrade performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7552.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e7552.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deepseek-Math</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deepseek-Math (math-specialized LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A math-oriented open-source LLM backbone that provides strong math reasoning priors; used both as a baseline and as the backbone for a SciAgent variant.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Deepseek-Math</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>math-pretrained open-source LLM; used as both baseline and as SciAgent backbone (fine-tuned on MATHFUNC)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Math and multi-domain scientific problems</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Solve mathematical and scientific problems by generating programs and reasoning steps; when fine-tuned on MATHFUNC, acts as a retrieval-augmented tool user.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Unified PoT prompt; when fine-tuned, uses planning+retrieval+action pipeline with three retrieved functions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Deepseek-Math baseline (7B) without toolset: ~26.7% ALL; SciAgent-DeePMATH (7B) after fine-tuning: 40.0% ALL (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Used as a strong math-pretrained baseline; improved further by MATHFUNC fine-tuning into SciAgent.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['math-pretraining yields better base performance on scientific problems', 'further fine-tuning on tool-augmented data (MATHFUNC) yields substantial gains in tool-use scenarios']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Same retriever and PoT prompting used during evaluation; fine-tuning schedules differ per backbone (e.g., 5e-6 for Deepseek-Math).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Math-specialized pretraining helps math but cross-domain reasoning still benefits from tool-augmented fine-tuning; without such fine-tuning, models do not reliably use external functions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SciAgent: Tool-augmented Language Models for Scientific Reasoning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>CREATOR: Tool creation for disentangling abstract and concrete reasoning of large language models <em>(Rating: 2)</em></li>
                <li>Tool learning with foundation models <em>(Rating: 2)</em></li>
                <li>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks <em>(Rating: 2)</em></li>
                <li>SciBench: Evaluating college-level scientific problem-solving abilities of large language models <em>(Rating: 2)</em></li>
                <li>TheoremQA: A theorem-driven question answering dataset <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7552",
    "paper_id": "paper-60126292c0b31dfc8628d99001e057b9f8355000",
    "extraction_schema_id": "extraction-schema-138",
    "extracted_data": [
        {
            "name_short": "SCIAGENT",
            "name_full": "SciAgent (tool-augmented language model agent)",
            "brief_description": "A framework and set of fine-tuned LLM agents that act as tool-users: they plan, retrieve domain-specific Python functions from a provided toolset, generate code+explanations, and execute code to solve quantitative scientific problems across multiple domains.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "SCIAGENT (family)",
            "model_size": "7B / 8B / 13B variants reported",
            "model_type": "instruction-fine-tuned on MATHFUNC; retrieval-augmented / tool-use enabled (planning+retrieval+action modules)",
            "scientific_domain": "Multi-domain: Mathematics, Physics, Chemistry, Finance, EECS (electrical engineering & CS)",
            "simulation_task_description": "Text-based simulation of domain computations by retrieving/writing and executing Python functions to solve quantitative, textbook-style scientific problems (e.g., compute integrals, apply physics formulae, solve equations, compute thermodynamic or financial quantities).",
            "prompting_strategy": "Retrieval-augmented prompting with a unified Program-of-Thought (PoT) style prompt (two demonstrations); internal pipeline: generate planning (high-level steps), retrieve top-3 functions using a dense retriever, generate interleaved rationale and program (optionally calling retrieved functions), then execute the program via Python executor; instruction-finetuning on MATHFUNC (mix of planning and action instructions).",
            "evaluation_metric": "Accuracy (exact-answer correctness on SciToolBench and CREATION challenge subsets)",
            "reported_accuracy": "SciAgent-DEEPMATH-7B: 40.0% (overall ALL on SciToolBench human+synthetic combined, Table 2); SciAgent-LLAMA3-8B: 34.7% (ALL); SciAgent-Coder (7B): 27.6% (ALL); SciAgent-Coder (13B): 29.8% (ALL).",
            "baseline_accuracy": "Best open-source baselines (without SciAgent tool-augmented fine-tuning) range from ~6.9% to ~26.7% depending on model and config; ChatGPT baseline ~31.0% (ALL human+synthetic combined in paper).",
            "factors_reported": [
                "fine-tuning on math-related, tool-augmented corpus (MATHFUNC)",
                "model backbone / pretraining (math-specialized pretraining like Deepseek-Math helps)",
                "model size (7B/8B/13B differences reported)",
                "retriever quality (hit@3 of retrieved functions)",
                "planning module (generating targeted retrieval queries)",
                "cross-retrieval strategy for dataset construction (reduces ad-hoc function artifacts)",
                "presence/quality of domain-specific toolset (related vs unrelated vs no toolset)",
                "composition of training data (function-augmented vs function-free samples)"
            ],
            "experimental_conditions": "Retriever returns 3 functions per question; unified PoT prompt with two demonstrations for models; MATHFUNC training: 31,375 samples + 5,981 math functions; retrieval model fine-tuned (RoBERTa-base backbone DPR) on query=[question; plan]; inference uses same retriever for all compared LLMs; execution performed by a Python executor; dataset-generation used nucleus sampling (temperature=0.6) for some steps; training used ZeRO Stage3 across GPUs with learning rates per backbone (e.g., 2e-5 for CodeLlama), batch size 128.",
            "limitations_or_failure_modes": "Despite improvements, SCIAGENT lags GPT-4 by ~20 percentage points; performance still limited when retriever hit@3 is perfect (~40% ceiling reported); tool attachment degrades performance for models not fine-tuned on tool-augmented data; removal of planning or function-augmented training data significantly reduces accuracy; agents may overfit to ad-hoc functions if dataset not constructed with cross-retrieval; performance varies by domain (Math generally stronger than other scientific domains).",
            "uuid": "e7552.0",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "SCIAGENT-DEEPMATH-7B",
            "name_full": "SCIAGENT fine-tuned on Deepseek-Math backbone (7B)",
            "brief_description": "A specific SciAgent variant built on a math-specialized 7B LLM (Deepseek-Math) fine-tuned on MATHFUNC to act as a retrieval-augmented, tool-using agent for multi-domain scientific problem solving.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "SCIAGENT-DeePMATH",
            "model_size": "7B",
            "model_type": "math-pretrained backbone; fine-tuned on MATHFUNC (instruction-tuned for planning+action), retrieval-augmented tool-user",
            "scientific_domain": "Multi-domain (Math, Physics, Chemistry, Finance, EECS)",
            "simulation_task_description": "Solve quantitative scientific problems by generating plans, retrieving domain functions, producing code that calls these functions, and executing code to obtain numeric answers.",
            "prompting_strategy": "Retrieval-augmented PoT-style prompting with two demonstrations; internal planning -&gt; retrieval (top-3) -&gt; action (code+rationale) -&gt; execution; models trained via imitation learning on MATHFUNC (mixture of planning and action tasks).",
            "evaluation_metric": "Accuracy (exact correctness on SciToolBench and CREATION benchmark subsets)",
            "reported_accuracy": "40.0% overall (ALL column in Table 2); human-annotated subset performance higher (see Table 2: 60.4% on CREATION with toolset for this model variant).",
            "baseline_accuracy": "ChatGPT: 31.0% (ALL); other open-source baselines range lower (see Table 2).",
            "factors_reported": [
                "math-specialized pretraining improves base math competence",
                "fine-tuning on MATHFUNC critical for tool-use benefit",
                "retriever quality and hit@3",
                "planning module and cross-retrieval strategy",
                "availability of domain-specific toolset"
            ],
            "experimental_conditions": "Three retrieved functions provided; evaluation uses unified PoT prompt; retriever shared among all models; Python executor runs generated code; CREATION repurposed toolset of 2,047 functions used in that benchmark.",
            "limitations_or_failure_modes": "Although it outperforms ChatGPT, it still falls short of GPT-4; even with perfect retrieval, accuracy saturates (~40%) indicating limits in reasoning/model execution and other deficiencies (e.g., argument selection, code correctness, domain knowledge gaps).",
            "uuid": "e7552.1",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "SCIAGENT-LLAMA3-8B",
            "name_full": "SCIAGENT fine-tuned on Llama-3 backbone (8B)",
            "brief_description": "An 8B SciAgent variant built on Llama-3 (open-source) fine-tuned on MATHFUNC, acting as a retrieval-augmented tool-using agent across scientific domains.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "SCIAGENT-Llama3",
            "model_size": "8B",
            "model_type": "open-source LLM fine-tuned on MATHFUNC (instruction-tuned), retrieval-augmented tool-user",
            "scientific_domain": "Multi-domain (Math, Physics, Chemistry, Finance, EECS)",
            "simulation_task_description": "Text-based simulation of domain computations by retrieving and calling domain functions inside generated Python code and executing it for numeric answers.",
            "prompting_strategy": "PoT-style prompting with two demonstrations; planning + retrieval + action pipeline; top-3 retrieved functions provided and optionally called.",
            "evaluation_metric": "Accuracy on SciToolBench (exact-answer correctness)",
            "reported_accuracy": "34.7% overall (ALL, Table 2); outperforms many comparable open-source models after MATHFUNC fine-tuning (paper notes SciAgent-Llama3-8B surpasses comparable-size LLMs by &gt;8.0% absolute accuracy).",
            "baseline_accuracy": "Llama-3 baseline without MATHFUNC fine-tuning: ~26.0% (ALL column for Llama-3 8B without toolset in Table 2).",
            "factors_reported": [
                "fine-tuning on MATHFUNC (tool-augmented data)",
                "retriever hit@3 and planning quality",
                "model pretraining and size"
            ],
            "experimental_conditions": "Shared retriever (3 functions); unified PoT prompt; models fine-tuned with imitation learning on planning/action tasks from MATHFUNC; evaluated on human-annotated and synthesized subsets.",
            "limitations_or_failure_modes": "Still behind GPT-4; vulnerable to poor retriever quality or unrelated toolsets; removal of planning or function-augmented samples decreases performance appreciably.",
            "uuid": "e7552.2",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "A powerful closed-source large language model used as an upper-reference baseline in this work; evaluated both with and without attached toolsets as reference points.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": "proprietary / very large (not specified in paper)",
            "model_type": "closed-source instruction-tuned model (not fine-tuned on MATHFUNC in this paper), evaluated as baseline with/without external toolset",
            "scientific_domain": "Multi-domain (Math, Physics, Chemistry, Finance, EECS) as evaluated",
            "simulation_task_description": "Solve textbook-style scientific problems via reasoning and code-generation when provided with toolset; serves as an upper benchmark for tool-augmented scientific reasoning.",
            "prompting_strategy": "Evaluated with/without provided toolsets; when toolsets provided, same unified PoT-based prompt and three retrieved functions were supplied; models instructed to call functions optionally.",
            "evaluation_metric": "Accuracy (exact-answer correctness on SciToolBench and CREATION)",
            "reported_accuracy": "Without toolsets (reference): 59.2% ALL; With toolsets: 59.7% ALL (Table 2). On human-annotated subsets tool-augmented performance increased notably in some domains (e.g., math/physics).",
            "baseline_accuracy": "Used as top-line baseline; other open-source models reported lower accuracies (see Table 2).",
            "factors_reported": [
                "benefits from attached toolsets when properly instructed",
                "strong inherent reasoning and execution skills compared to open-source models"
            ],
            "experimental_conditions": "Same retriever-provided functions and PoT prompt used for fairness; evaluations done on human-annotated and synthesized question subsets.",
            "limitations_or_failure_modes": "Paper notes even GPT-4 has limited accuracy on some scientific tasks (e.g., prior work reports ~50% on TheoremQA); tool-augmentation yields gains but gaps with SciAgent variants vary by domain.",
            "uuid": "e7552.3",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "ChatGPT",
            "name_full": "ChatGPT (OpenAI Chat Model)",
            "brief_description": "A widely used chat-oriented LLM evaluated as a baseline for tool-augmented scientific reasoning; performance reported both with and without attached toolsets.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChatGPT",
            "model_size": "proprietary (not specified)",
            "model_type": "closed-source chat model/instruction-tuned; evaluated without additional fine-tuning on MATHFUNC",
            "scientific_domain": "Multi-domain",
            "simulation_task_description": "Answered scientific benchmark questions; tested with optional provided toolsets (three retrieved functions) to assess benefit from external tools.",
            "prompting_strategy": "Unified PoT-based prompt with two demonstrations; three retrieved functions optionally provided.",
            "evaluation_metric": "Accuracy",
            "reported_accuracy": "Overall ALL: 31.0% without toolset; with toolset reported ~30.9% (Table 2) — small/variable gains depending on domain.",
            "baseline_accuracy": "Used as a competitive baseline; SciAgent-DeepMath-7B reported ~40.0% ALL, outperforming ChatGPT.",
            "factors_reported": [
                "not all models benefit from attached toolsets unless fine-tuned on tool-augmented data",
                "domain and function relevance influences whether toolsets help"
            ],
            "experimental_conditions": "Same retriever used to supply three functions; models evaluated with unified PoT prompt.",
            "limitations_or_failure_modes": "ChatGPT did not consistently benefit from attached toolsets in this evaluation and is outperformed by SciAgent variants fine-tuned on MATHFUNC.",
            "uuid": "e7552.4",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "ToRA-Coder",
            "name_full": "ToRA-Coder (tool-integrated reasoning agent)",
            "brief_description": "An open-source code-capable LLM baseline (fine-tuned with Program-of-Thought style data) evaluated with/without toolsets to compare tool-use performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ToRA-Coder",
            "model_size": "7B and 13B variants reported",
            "model_type": "instruction-fine-tuned on programmatic/mathematical corpora (tool-agnostic original fine-tuning); supplied with retriever functions at inference for comparisons",
            "scientific_domain": "Math-centered baseline but evaluated across SciToolBench domains",
            "simulation_task_description": "Generate programmatic solutions to math/science questions, optionally calling provided functions.",
            "prompting_strategy": "Original ToRA instruction shape (PoT style) with appended tool-augmented description and provided retrieved functions; evaluated with same retriever.",
            "evaluation_metric": "Accuracy",
            "reported_accuracy": "ToRA-Coder (7B) with no toolset: e.g., ~24.4% (CREATION) and varying across SciToolBench domains; with toolset performance varied and sometimes degraded (see Table 2).",
            "baseline_accuracy": "Compared against SciAgent variants and other baselines; SciAgent-Coder surpassed ToRA-Coder by large margins after MATHFUNC fine-tuning (paper reports SciAgent-Coder surpasses ToRA-Coder by 13.4% (7B) and 12.7% (13B) in absolute accuracy on certain comparisons).",
            "factors_reported": [
                "original fine-tuning format may not be optimal for tool-use unless fine-tuned on tool-augmented data",
                "retriever quality and instruction-shaping affect performance"
            ],
            "experimental_conditions": "Evaluated using unified PoT prompt and the same retriever; for tool-augmented evaluation, three functions were provided and a short tool-augmented description appended to original prompt.",
            "limitations_or_failure_modes": "ToRA-Coder's performance can drop when attaching toolsets if it has not been fine-tuned on tool-augmented data; output shaping matters (variants with/without output shaping differ significantly).",
            "uuid": "e7552.5",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "MAmmoTH-Coder",
            "name_full": "MAmmoTH-Coder",
            "brief_description": "An open-source LLM baseline fine-tuned on math-related corpora evaluated as a baseline for scientific tool-augmented reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "MAmmoTH-Coder",
            "model_size": "7B and 13B variants reported",
            "model_type": "instruction-fine-tuned on math corpora (tool-agnostic)",
            "scientific_domain": "Math-centric baseline; evaluated across SciToolBench domains",
            "simulation_task_description": "Generate programmatic problem solutions (math/scientific) without explicit tool-use or with optional retrieved functions appended at inference.",
            "prompting_strategy": "Original MAmmoTH instructions, with optional appended tool-usage note and retrieved functions for tool-augmented evaluation; unified PoT used in some comparisons.",
            "evaluation_metric": "Accuracy",
            "reported_accuracy": "MAmmoTH-Coder (7B) without toolset: ~32.1% on MATH test set (Table 9); on SciToolBench varies (see Table 2; e.g., ALL ~26.7% in some configurations).",
            "baseline_accuracy": "Used as a baseline for assessing the benefit of tool-augmented fine-tuning; SciAgent variants surpass it after MATHFUNC fine-tuning.",
            "factors_reported": [
                "math-specialized fine-tuning improves math competence",
                "without tool-augmented fine-tuning models may not leverage toolsets effectively"
            ],
            "experimental_conditions": "Shared retriever provided when evaluating tool-augmented scenarios; unified PoT prompt sometimes used.",
            "limitations_or_failure_modes": "Performance may degrade when attaching unrelated toolsets or when model not adapted to using external functions.",
            "uuid": "e7552.6",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "CodeLlama",
            "name_full": "CodeLlama (code-capable LLM)",
            "brief_description": "An open-source code-specialized LLM used as a baseline (7B and 13B) and also fine-tuned into SciAgent variants; evaluated with/without toolsets.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "CodeLlama",
            "model_size": "7B and 13B variants",
            "model_type": "pretrained code model; versions used both as baseline and fine-tuned (SciAgent-Coder)",
            "scientific_domain": "Multi-domain evaluation (math-heavy tasks included)",
            "simulation_task_description": "Generate executable Python solutions for scientific problems and optionally call retrieved functions.",
            "prompting_strategy": "Unified PoT-based prompt; when used as SciAgent-Coder, fine-tuned on MATHFUNC; when baseline, provided with retrieved functions via appending.",
            "evaluation_metric": "Accuracy",
            "reported_accuracy": "CodeLlama baseline (7B) ALL ~6.9% (no toolset) rising to ~7.4% with toolset in some evaluations; SciAgent-Coder (fine-tuned from CodeLlama) significantly higher (e.g., 27.6% ALL for 7B SciAgent-Coder).",
            "baseline_accuracy": "Used as baseline for showing fine-tuning benefits; SciAgent-Coder outperforms the original CodeLlama baseline by large margins after MATHFUNC fine-tuning.",
            "factors_reported": [
                "fine-tuning on MATHFUNC critical to gain effective tool-use ability",
                "retriever and planning greatly influence performance"
            ],
            "experimental_conditions": "Same retriever used; three functions provided; training hyperparameters: e.g., learning rate 2e-5 for CodeLlama fine-tuning.",
            "limitations_or_failure_modes": "Out-of-the-box CodeLlama performs poorly on SciToolBench unless fine-tuned on tool-augmented data; attaching toolsets to non-finetuned models can reduce performance.",
            "uuid": "e7552.7",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Mistral",
            "name_full": "Mistral (7B)",
            "brief_description": "An open-source high-performance 7B LLM evaluated as a baseline with/without attached toolsets.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mistral",
            "model_size": "7B",
            "model_type": "pretrained open-source LLM (not fine-tuned on MATHFUNC for baseline runs)",
            "scientific_domain": "Multi-domain (evaluated across SciToolBench domains)",
            "simulation_task_description": "Generate natural-language+code solutions to scientific problems; optionally use retrieved functions when provided.",
            "prompting_strategy": "Unified PoT-style prompt for evaluation; provided with top-3 retrieved functions for tool-augmented runs.",
            "evaluation_metric": "Accuracy",
            "reported_accuracy": "Mistral (7B) ALL ~14.8% without toolset rising to ~13.7% with toolset depending on fine-tuning; SciAgent-Mistral variant (7B) achieved ~30.3% ALL after MATHFUNC fine-tuning.",
            "baseline_accuracy": "Compared to SciAgent-Mistral which is fine-tuned on MATHFUNC, baseline Mistral performs worse.",
            "factors_reported": [
                "fine-tuning on MATHFUNC is necessary to benefit from toolsets",
                "retriever quality affects final accuracy"
            ],
            "experimental_conditions": "Shared retriever; unified PoT prompt; fine-tuning hyperparameters varied for SciAgent variants (2e-6 used for Mistral fine-tuning).",
            "limitations_or_failure_modes": "Without tool-augmented fine-tuning, attaching function toolsets may not improve or may slightly degrade performance.",
            "uuid": "e7552.8",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Deepseek-Math",
            "name_full": "Deepseek-Math (math-specialized LLM)",
            "brief_description": "A math-oriented open-source LLM backbone that provides strong math reasoning priors; used both as a baseline and as the backbone for a SciAgent variant.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Deepseek-Math",
            "model_size": "7B (reported)",
            "model_type": "math-pretrained open-source LLM; used as both baseline and as SciAgent backbone (fine-tuned on MATHFUNC)",
            "scientific_domain": "Math and multi-domain scientific problems",
            "simulation_task_description": "Solve mathematical and scientific problems by generating programs and reasoning steps; when fine-tuned on MATHFUNC, acts as a retrieval-augmented tool user.",
            "prompting_strategy": "Unified PoT prompt; when fine-tuned, uses planning+retrieval+action pipeline with three retrieved functions.",
            "evaluation_metric": "Accuracy",
            "reported_accuracy": "Deepseek-Math baseline (7B) without toolset: ~26.7% ALL; SciAgent-DeePMATH (7B) after fine-tuning: 40.0% ALL (Table 2).",
            "baseline_accuracy": "Used as a strong math-pretrained baseline; improved further by MATHFUNC fine-tuning into SciAgent.",
            "factors_reported": [
                "math-pretraining yields better base performance on scientific problems",
                "further fine-tuning on tool-augmented data (MATHFUNC) yields substantial gains in tool-use scenarios"
            ],
            "experimental_conditions": "Same retriever and PoT prompting used during evaluation; fine-tuning schedules differ per backbone (e.g., 5e-6 for Deepseek-Math).",
            "limitations_or_failure_modes": "Math-specialized pretraining helps math but cross-domain reasoning still benefits from tool-augmented fine-tuning; without such fine-tuning, models do not reliably use external functions.",
            "uuid": "e7552.9",
            "source_info": {
                "paper_title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "CREATOR: Tool creation for disentangling abstract and concrete reasoning of large language models",
            "rating": 2
        },
        {
            "paper_title": "Tool learning with foundation models",
            "rating": 2
        },
        {
            "paper_title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
            "rating": 2
        },
        {
            "paper_title": "SciBench: Evaluating college-level scientific problem-solving abilities of large language models",
            "rating": 2
        },
        {
            "paper_title": "TheoremQA: A theorem-driven question answering dataset",
            "rating": 2
        }
    ],
    "cost": 0.022524,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>SciAgent: Tool-augmented Language Models for Scientific Reasoning</h1>
<p>Yubo Ma ${ }^{1 <em>}$, Zhibin Gou ${ }^{2 </em>}$, Junheng Hao ${ }^{3}$, Ruochen Xu ${ }^{3}$, Shuohang Wang ${ }^{3}$, Liangming Pan ${ }^{1}$, Yujiu Yang ${ }^{2}$, Yixin Cao ${ }^{5} \dagger$, Aixin Sun ${ }^{1} \dagger$<br>${ }^{1}$ Nanyang Technological University ${ }^{2}$ Tsinghua University ${ }^{3}$ Microsoft<br>${ }^{4}$ University of Arizona ${ }^{5}$ Fudan University<br>yubo001@e.ntu.edu.sg</p>
<h4>Abstract</h4>
<p>Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a toolaugmented training corpus named MATHFUNC which encompasses over 30,000 samples and roughly 6,000 tools. Building on MATHFUNC, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs' abilities with tool assistance. Extensive experiments on SCIToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than $8.0 \%$ in absolute accuracy. Furthermore, SciAgent-DeePMATH-7B shows much superior performance than ChatGPT.</p>
<h2>1 Introduction</h2>
<p>Scientific reasoning (Ouyang et al., 2023; Zhao et al., 2023) aims to comprehend and make decisions regarding problems among STEM (Science, Technology, Engineering and Mathematics) domains. It is a fundamental aspect of intelligence, a demanding capability of Large Language Models (LLMs), and a notoriously challenging task. For instance, even GPT-4 (OpenAI, 2023) achieves only $50 \%$ and $35 \%$ accuracy on TheoremQA (Chen et al., 2023b) and SciBench (Wang et al., 2023b), respectively. Regarding open-source LLMs such as Llama3 (LlamaTeam, 2024) and Mistral (Jiang</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Two paradigms for scientific reasoning task. Different colors represent different scientific domains. Left: Supervised fine-tuning setting. Collecting annotations and fine-tuning LLMs domain by domain. Right: Our proposed tool-augmented setting. We decompose the scientific reasoning ability into three aspects: math reasoning ability, tool-use ability and domain-specific knowledge. LLMs are fine-tuned on math-related, toolaugmented samples (color in red). When adapting LLMs to a specific domain, a pluggable and domainspecific toolset is attached to provide the domain knowledge. No additional fine-tuning is further required.
et al., 2023), the performances are only about $30 \%$ accuracy or even less.</p>
<p>The challenge in scientific reasoning arises from the need for both mathematical (math) and domainspecific reasoning abilities. To address the physical problem in Figure 3, for example, it is necessary to both understand Malus' law (domain knowledge) for analyzing the intensity of polarized light, and possess quantitative ability for calculating the light intensity ratios. A natural approach involves collecting annotations and fine-tuning LLMs to enhance their math and domain-specific reasoning abilities, as depicted in Figure 1 (left). However, annotating scientific reasoning problems is extremely expensive. What is worse, adapting LLMs to a new domain demands a fresh round of annotation and fine-tuning, rendering this approach impractical.</p>
<p>In this paper, we draw inspirations from tool learning (Qin et al., 2023a) to enhance LLMs' scientific reasoning capabilities. Instead of solving</p>
<p>scientific problem from scratch, humans have summarized and wrapped various points as generalized and well-documented functions in scientific computing softwares, such as Matlab ${ }^{1}$, WolframAlpha ${ }^{2}$, SymPy $^{3}$, etc. These functions ${ }^{4}$, which could be equivalently viewed as external tools, greatly facilitate math-adept users to solve difficult scientific problems. In analogy with humans, we do not pursue an omniscient solver across various scientific domains. Instead, we assume the access to domainspecific toolsets and purse a unified, generalized LLM-based tool-user as shown in the Figure 1 (right). This approach tackles domain-specific reasoning challenges by enabling LLMs learn to use a reusable and scalable toolkit. It alleviates the reasoning challenges of LLMs by concentrating solely on enhancing their tool-use abilities. These abilities are not only easier to acquire but also applicable across a variety of scientific fields. By attaching domain-specific toolsets, our tool-users can be readily adapted to different fields without the need for additional in-domain fine-tuning.</p>
<p>This work focuses on developing and benchmarking the ability of LLMs in scientific reasoning with the help of tools. We envision a scenario where LLMs have access to a domain-specific toolset, comprising various specialized functions. Upon this scenario, we propose a complete framework of dataset construction, model training and evaluation. Given a scientific question, LLMs are supposed to retrieve functions from the toolset and optionally incorporate functions into the formulated solution. We employ an automatic pipeline featuring GPT-4/-4o to compile a large-scale, mathrelated, tool-augmented training corpus named as MathFunc. This corpus is designed to enable LLMs to learn both essential math skills and how to retrieve, understand and use functions properly. As a result, MathFunc contains 31,375 samples and equipped with a toolset encompassing 5,981 generalized and well-documented functions. We detail this training corpus in Section 3.</p>
<p>We fine-tune open-source LLMs on MathFunc to develop tool-augmented agents named SCIAGENT detailed in Section 4. As shown in Figure 3, SCIAGENT firstly generate a high-level planning in response to a given question. The agents then</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>use this plan, along with the question, to retrieve functions from the given toolset. Leveraging these retrieved functions, the agents further complete the low-level action integrating natural language and Python code. Finally the agents execute the code to complete the problem at hand.</p>
<p>To benchmark the tool-use abilities in scientific reasoning, we develop a new benchmark named SciToolBench as described in Section 5. Building upon TheoremQA (Chen et al., 2023b) and SciBench (Wang et al., 2023b), it has 4,250 questions covering five domains: Mathematics, Physical, Chemistry, EECS, and Finance. It also contains five domain-specific toolsets comprising a total of 2,285 functions. We evaluate SCIAGENT on SciToolBench and another benchmark derived from CREATOR-challenge (Qian et al., 2023). Experimental results demonstrate that our agents present remarkable scientific reasoning capabilities. Notably, SCIAGENT-Llama3-8B surpasses the best comparable open-source LLMs by an absolute $8.0 \%$ accuracy, and SCIAGENT-DeEPMATH-7B outperforms ChatGPT by a large margin. We also conduct an extensive analysis of the benefits and limitations of SCIAGENT series, providing valuable insights for future research.</p>
<h2>2 Preliminary</h2>
<p>Related Work. Current methods (Chen et al., 2023b; Xu et al., 2023b; Ouyang et al., 2023), especially those based on open-source LLMs, perform far from satisfactory on scientific reasoning benchmarks (Chen et al., 2023b; Wang et al., 2023b). We attribute it to the scarcity of annotated samples across diverse scientific domains. As a comparison, LLMs present much more remarkable performance on math problems (Yue et al., 2023b; Gou et al., 2023b; Azerbayev et al., 2023) due to the abundant training corpora and/or annotations. Different from concurrent work (Zhang et al., 2024) which collects physics and chemistry annotations, we do not pursue a problem-solver on some specific scientific domains. Instead, we consider to develop a generalized tool-user being proficient on solving diverse scientific problems with the aid of tools. Following previous work on math domain (Qian et al., 2023; Cai et al., 2023; Yuan et al., 2023a), the tools here refer to Python functions. Please see more detailed literature review in Appendix A.
Task Formulation. Given a scientific domain $D$ (e.g., physics), tool-augmented scientific reasoning</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Automatic pipeline for MATHFUNC construction. Please view it starting from the bottom left corner and proceed clockwise. We disentangle the constructions of toolset (dashed lines) and function-augmented samples (solid lines) for more generalized annotations. We do not visualize the function-free samples for simplicity.</p>
<p>Task assumes access to (1) a question q ∈ D and (2) a toolset F<sup>D</sup>. F<sup>D</sup> encompasses large amounts of well-documented, domain-specific functions {f<sub>1</sub>, ..., f<sub>m</sub>}. Our objective is to develop an agent M which selectively use functions in F<sup>D</sup> to enhance the answering for the question q.</p>
<h1>3 Training Corpus: MATHFUNC</h1>
<p>To our best knowledge, there are no readily available tool-augmented datasets in scientific reasoning domains. Therefore, we construct a corpus named MATHFUNC teaching LLMs to better understand and use functions. MATHFUNC is composed of (1) a toolset F<sup>5</sup> including 5,981 generalized, well-documented, math-related functions and (2) a dataset D encompassing 31,375 samples in which solutions call the function from the toolset if necessary (e.g., ④ in Figure 2). We build this corpus based on MATH (Hendrycks et al., 2021b) training set because we expect to teach LLMs both math skills and tool-use abilities.</p>
<p><strong>Sample Format.</strong> Each sample is a quintuple (q, G<sub>q</sub>, F<sub>q</sub>, S<sub>q</sub>, a<sub>q</sub>). Here q is a question, G<sub>q</sub> is the planning, F<sub>q</sub> is the function set filtered from the toolset (F<sub>q</sub> ⊂ F, |F<sub>q</sub>| ≪ |F|), S<sub>q</sub> is the solution and a<sub>q</sub> is the answer. S<sub>q</sub> interleaves rationales E<sub>q</sub><sup>h</sup> and programs P<sub>q</sub> which optionally call functions in F<sub>q</sub> to facilitate the problem solving.</p>
<p>We employ an automatic pipeline to construct MATHFUNC. We illustrate the pipeline in Figure 2 and detail the process in the following subsections.</p>
<h3>3.1 Planning and Toolset Construction</h3>
<p>This module is depicted in the top-left side of Figure 2. Given a question q and its ground-truth solution (written in pure natural language) in MATH training set, we ask GPT-4 to generate (1) a high-level planning G<sub>q</sub> to analyze this question, (2) one or more well-documented functions F<sub>q</sub> and (3) a solution S<sub>q</sub> calling the functions above. The prompt used is shown in Appendix H.1. In the prompt, we emphasize that the functions should be as <strong>composable and generalized</strong> as possible. Specifically, we do not hope that each question generates only one ad-hoc function (which could only be used by this question). Instead, we expect GPT-4 to generate functions that follow the points in the planning G<sub>q</sub> and can be reused by other questions. Following previous work (Qian et al., 2023; Pan et al., 2023), we provide the error feedback to GPT-4 if the solutions fail to execute, and ask GPT-4 to rectify the errors in F<sub>q</sub> or S<sub>q</sub>. We repeat this procedure until successful execution or reaching maximum loop limitation. The prompt used for rectification is shown in Appendix H.2.</p>
<p>We collect G<sub>q</sub> (① in Figure 2, the same below) and add F<sub>q</sub> to the toolset (②) for question q if the rectified solution S<sub>q</sub> leads to the correct answer a<sub>q</sub>. Regarding the toolset, it is iterated on all questions and finally accumulated as below:</p>
<p>$$F = \bigcup_{q \in D} \hat{F}_q \cdot \mathbf{1}(\hat{a}_q \text{ is correct})$$</p>
<h3>3.2 Function-augmented Solutions</h3>
<p>To collect function-augmented solution S<sub>q</sub> and F<sub>q</sub>, a natural idea is to directly use the S<sub>q</sub> and F<sub>q</sub> generated above. However, we find that S<sub>q</sub> tends to</p>
<p><sup>5</sup>We remove the domain-specific subscript D for expression simplicity. The same below.</p>
<p><sup>6</sup>Here E<sub>q</sub> is written in natural language but formatted as the annotation lines in the program.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The model architecture of SCIAGENT. Given a domain-specific toolset <strong>✓</strong>, our agent answers the question through four consecutive modules. (1) <strong>Planning</strong> provides a high-level plan for this problem. (2) <strong>Retrieval</strong> retrieves related functions from attached toolset. (3) <strong>Action</strong> generates a low-level solution interleaving rationale and program. The program uses the retrieved functions if necessary. (4) <strong>Execution</strong> calls Python executor to run the program and outputs the final answer. Not included in this figure for simplicity.</p>
<p>be contrived and specifically tailored to fit the requirements of function-calling. Moreover, some functions in $$F_q$$ tend to be ad-hoc. For examples, the function $$f(x, y)$$ in Figure 2 merely parameterizes the hyperbola for a specific question. Therefore we disentangle the construction of toolset and function-augmented solutions. Given the developed toolset, we design a <strong>cross-retrieval</strong> strategy to retrieve more generalized functions $$F_q$$ and generate more qualified solutions $$S_q$$. Specifically, we remove $$F_q$$ from $$F$$ temporarily and then retrieve new functions $$F_q \subseteq (F \setminus F_q)$$ for question $$q$$. This strategy eliminates the likelihood of calling ad-hoc functions from $$F_q$$ in $$S_q$$. See examples of retrieved functions, all of which are derived from other questions, in the right side of Figure 2.</p>
<p><strong>Retriever.</strong> The cross-retrieval strategy necessitates a retriever because it is impractical to enumerate thousands of functions in $$F \setminus F_q$$. We train a dense retriever $$R$$ (3) in Figure 2). We concatenate the question $$q$$ and the generated planning $$G_q$$ as the query, and view the generated functions $$F_q$$ in Section 3.1 as the keys. See details about $$R$$ in Appendix B.1.</p>
<p><strong>Solution Generation.</strong> Upon the toolset $$F$$ and the retriever $$R$$, we retrieve three functions as $$F_q$$:</p>
<p>$$F_q = R([q, G_q]; F \setminus F_q)$$</p>
<p>Then we employ GPT-4 to write solutions which optionally call functions in $$F_q$$ to generate the solution $$S_q$$ (④). The prompt used is illustrated in Appendix H.3. We explicitly point out in the prompt that $$f \in F_q$$ should be called if and only if when they do lower the difficulty of problem solving. It mitigates the over-exploitation of function calling in $$S_q$$ and increases the robustness of models finetuned on these samples. Specifically, we firstly use GPT-4 with greedy decoding to generate solutions. For those failing to yield correct answers, we further apply nucleus sampling (Holtzman et al., 2020) with 5 repeat times and 0.6 temperature. We filter wrong solutions and collect remaining 6,229 samples as our function-augmented solutions.</p>
<p>In parallel, we use GPT-4 to generate function-free solutions. Though not indispensable, we expect them to further enhance the math reasoning, and accordingly the scientific reasoning, abilities of LLMs. We collect a total of 24,946 function-free solutions nucleus sampling with 5 repeat times and 0.6 temperature. These samples share similar format as ToRA-corpus (Gou et al., 2023b), and do not retrieve/use any functions, <em>i.e.,</em> $$F_q = \emptyset$$.</p>
<h1>4 Model: SCIAGENT</h1>
<p>We develop SCIAGENT for tool-augmented scientific reasoning task. It could make plan, retrieve functions, and leverage retrieved functions to facilitate the reasoning. We describe its inference procedure and training approach as below.</p>
<h2>4.1 Overview</h2>
<p>As shown in Figure 3, SCIAGENT comprises four successive modules.</p>
<p><strong>Planning.</strong> This module provides a high-level profile for each question: $$G_q = \mathcal{M}_{\text{planning}}(q)$$. Such planning instructs a more targeted retrieval process.</p>
<p><strong>Retrieval.</strong> Given the question and generated planning $$G_q$$, the retriever $$\mathcal{M}<em _text_retrieval="\text{retrieval">{\text{retrieval}}$$ is introduced to retrieve related functions from the domain-specific toolset: $$F_q = \mathcal{M}</em>([q, G_q]; F_D) \subseteq F_D$$.}</p>
<p><sup>7</sup>Despite we instruct GPT-4 to avoid generating ad-hoc functions, there are still some ad-hoc functions in $$F_q$$</p>
<p>Action. This module aims to generate low-level solutions. Specifically, the agent produces $S_{q}=$ $\mathcal{M}<em q="q">{\text {action }}\left(q ; F</em>$ call retrieved functions with proper arguments if necessary.
Execution. This module is simply a Python Executor to run the program $P_{q}$ for the final answer: $a_{q}=$ Python-Executor $\left(P_{q}\right)$.}\right)$. The solution $S_{q}$ is interleaved with natural language rationale $E_{q}$ and program snippet $P_{q}$. The program $P_{q</p>
<h3>4.2 Training</h3>
<p>Language models are used in three out of four modules in SCIAGENT: planning, retrieval and action. Rearding retrieval, we directly use the retriever $R$ fine-tuned in Section 3.2 as $\mathcal{M}<em _planning="{planning" _text="\text">{\text {retrieval }}$. For planning and action modules, they share the same LLMs: $\mathcal{M}=\mathcal{M}</em>}}=\mathcal{M<em q="q">{\text {action }}$. We fine-tune $\mathcal{M}$ with different instructions to make it act as planning and action modules, respectively. We construct instructions from $d=\left(q, G</em>\right)$ in MATHFUNC.}, F_{q}, S_{q}, a_{q</p>
<p>$$
\begin{aligned}
D_{\text {planning }} &amp; =\left{\left(I_{\text {plan }}(q), G_{q}\right) \mid d \in D\right} \
D_{\text {action }} &amp; =\left{\left(I_{\text {action }}\left(q, F_{q}\right), S_{q}\right) \mid d \in D\right}
\end{aligned}
$$</p>
<p>Here $I_{\text {plan }}$ and $I_{\text {action }}$ are instruction templates for planning and action modules. We show these instructions in Appendix B.2, and mix up them as the training set $D=\left(D_{\text {planning }} \bigcup D_{\text {action }}\right)$. Then we apply imitation learning on $D$ to fine-tune $\mathcal{M}$.</p>
<p>$$
L_{\mathcal{M}}=\sum_{(X, Y) \in D}-\log \mathcal{P}(Y \mid X)
$$</p>
<p>Implementation We detail the training process of (1) the retriever $\mathcal{M}_{\text {retrieval }}$ and (2) the planner and actor $\mathcal{M}$ in Appendix B. 1 and B.2, respectively.</p>
<h2>5 Benchmark: SciToolBench</h2>
<p>There currently exists no benchmark assessing the scientific reasoning capabilities of LLMs when aided by tools. To address this gap, we develop a benchmark called SciToolBench. Our benchmark covers five domains: Mathematics (math) ${ }^{8}$, Physics, Chemistry, Finance, Electrical Engineering and Computer Science (EECS). Each domain is composed of a set of questions and a domainspecific toolset. The toolset consists of abundant generalized, high-quality and well-documented</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>functions. We expect LLMs to retrieve, understand and, if necessary, use functions in it for reasoning.</p>
<h3>5.1 Dataset Overview.</h3>
<p>The statistics of SciToolBench are presented in Table 1. We leave more detailed statistics in Appendix E.2. Briefly, our benchmark comprises a total of 4,250 questions and 2,285 functions spanning across 5 scientific domains. SciToolBench differs from previous tool-based benchmarks, such as Creation Challenge (Qian et al., 2023), in several aspects: (1) Our benchmark encompasses a diverse range of scientific domains. (2) The provided tools are both composable and generalized across different questions. As indicated in Table 1, each question requires an average of 1.51 functions for resolution. And over 500 functions are designed to be applicable to two or more questions, such as integrate_function in math domain, coulombs_law in physical domain, and calculate_pressure_van_der_waals in chemistry domain, etc. It signifies that the functions in our toolset are not ad-hoc solutions tailored for specific questions. Instead, the effective utilization of the toolset demands significant reasoning abilities of tool-augmented LLMs. Thus we claim this benchmark challenging and practical.</p>
<p>Table 1: The statistics of our benchmark. #H.A./#Syn.: The number of human-annotated/synthesized questions. #Pos./ #Neg.: The number of positive/negative functions in the toolset. FPQ (function per question): The number of derived positive functions from each question. Counted on H.A. questions only.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Question</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Function</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;"># Question</td>
<td style="text-align: center;">#H.A. / #Syn.</td>
<td style="text-align: center;"># Function</td>
<td style="text-align: center;">#Pos. / #Neg.</td>
<td style="text-align: center;">Avg. FPQ</td>
</tr>
<tr>
<td style="text-align: left;">Math</td>
<td style="text-align: center;">2031</td>
<td style="text-align: center;">434 / 1597</td>
<td style="text-align: center;">964</td>
<td style="text-align: center;">403 / 561</td>
<td style="text-align: center;">1.47</td>
</tr>
<tr>
<td style="text-align: left;">Physics</td>
<td style="text-align: center;">855</td>
<td style="text-align: center;">156 / 699</td>
<td style="text-align: center;">516</td>
<td style="text-align: center;">225 / 291</td>
<td style="text-align: center;">1.63</td>
</tr>
<tr>
<td style="text-align: left;">Chemistry</td>
<td style="text-align: center;">639</td>
<td style="text-align: center;">118 / 521</td>
<td style="text-align: center;">349</td>
<td style="text-align: center;">138 / 211</td>
<td style="text-align: center;">1.34</td>
</tr>
<tr>
<td style="text-align: left;">Finance</td>
<td style="text-align: center;">369</td>
<td style="text-align: center;">66 / 303</td>
<td style="text-align: center;">245</td>
<td style="text-align: center;">89 / 156</td>
<td style="text-align: center;">1.62</td>
</tr>
<tr>
<td style="text-align: left;">EECS</td>
<td style="text-align: center;">356</td>
<td style="text-align: center;">82 / 274</td>
<td style="text-align: center;">211</td>
<td style="text-align: center;">87 / 124</td>
<td style="text-align: center;">1.68</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">4250</td>
<td style="text-align: center;">856 / 3394</td>
<td style="text-align: center;">2285</td>
<td style="text-align: center;">942 / 1343</td>
<td style="text-align: center;">1.51</td>
</tr>
</tbody>
</table>
<h3>5.2 Dataset Annotation</h3>
<p>We design a semi-automatic pipeline shown in Figure 4 to annotate the benchmark. It employs both GPT-4 and human annotators to combine their merits. This pipeline includes two subsequent modules: question collection and toolset construction. We introduce these modules as below and leave their details in Appendix D.
Question Collection: Our benchmark comprises 4,250 questions from two sources. (1) Humanannotated: We curate 856 questions from Theo-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Semi-automatic annotation pipeline for SciToolBench. : GPT-4. : Human annotator.
remQA (Chen et al., 2023b) and SciBench (Wang et al., 2023b) ( $\square$ in Figure 4, the same below). (2) Synthesized: To further expand the question set, we use these 856 questions as seed examples and automatically generate another 3,394 synthesized questions ( $\square$ ).
Toolset Construction: We construct domainspecific toolsets via two cascade modules: positive and negative function construction. (1) Positive functions: We define positive functions ( $\square$ ) as functions directly deriving from questions. The 1,216 candidate positive functions are firstly generated from GPT-4. Then human annotators carefully check them and rewrite and/or remove the unqualified ones. Both the correctness and generalization of these auto-generated functions are evaluated in this human checking process. We finalize a total of 942 positive questions. (2) Negative functions: We further automatically construct 1,343 negative functions ( $\square$ ) based on positive functions. These negative functions are apparently similar as positive ones but can not directly solve questions in our benchmark. We add them to reduce the shortcuts about question-function matching as much as possible. We finally combine both positive and negative functions as the toolset, including a total of 2,285 functions, in our benchmark.</p>
<h2>6 Experiments</h2>
<h3>6.1 Setup</h3>
<p>We conduct experiments on SciToolBench to evaluate the tool-augmented scientific reasoning abilities of LLMs. We report results categorized by both question domains and construction methods for fine-grained analysis. We also employ CREATION Challenge (Qian et al., 2023) as the second benchmark. It comprises 2,047 samples, with each sample consisting of a question and a ground-truth function. We re-purpose all functions to assemble a global toolset (thus including 2,047 functions). We report accuracy as the metric in all experiments.</p>
<h3>6.2 Baselines</h3>
<p>We compare SciAgent series with six opensource LLMs: (1) CodeLlama (Rozière et al., 2023), (2) MAmmoTH-Coder (Yue et al., 2023b), (3) ToRA-Coder (Gou et al., 2023b), (4) Mistral (Jiang et al., 2023), (5) Deepseek-Math (Shao et al., 2024), (6) Llama-3 (Touvron et al., 2023). We also list the performance of ChatGPT and GPT4 for reference. For fair comparison, we provide all LLMs the same retriever in Section 3.2 to retrieve functions from toolset (if attached). Please see more details in Appendix C.</p>
<h3>6.3 Main Results</h3>
<p>We fine-tune CodeLlama, Mistral, Llama-3 and Deepseek-Math for different SciAgent variants. We present their results, along with associated baselines, in Table 2 and draw following conclusions:
The importance of math skills. The LLMs pretrained on math-related corpus, i.e., DeepseekMath series, present more competitive performance than others. And the models fine-tuned on mathrelated datasets from CodeLlama, i.e., ToRA- and MAmmoTH-Coder, perform better than CodeLlama itself by $5.5 \%$ absolute accuracy. It presents the importance of essential math skills among diverse scientific domains.
The necessity of tool-augmented learning. Most evaluated LLMs are not inherently proficient at using tools. When equipped with toolsets, the performance of LLMs that have not undergone toolaugmented learning degrades significantly. For instance, the $7 \sim 8 \mathrm{~B}$ models such as ToRA-Coder, Mistral, Deepseek-Math, and Llama-3 show performance drops of $3.0 \%, 0.9 \%, 4.9 \%$, and $3.7 \%$, respectively. As shown in Figure 5, LLMs demonstrate proficient tool-use abilities and benefit from the attached toolsets only when they have undergone tool-augmented learning, i.e., fine-tuning on MathFunc. As a result, our agents outperform other open-source LLMs by a large margin. No-</p>
<p>Table 2: Main results on two benchmarks. We highlight our SCIAGENT series in purple. The best results (among all open-source LLMs, the same below) are in bold face and the second best are underlined.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Size</th>
<th style="text-align: center;">Toolset</th>
<th style="text-align: center;">CREATION</th>
<th style="text-align: center;">SciToolBench</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ALL</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">HUMAN-ANNOTATED</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">SYNTHESIZED</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Math</td>
<td style="text-align: center;">Physics</td>
<td style="text-align: center;">Chemistry</td>
<td style="text-align: center;">Finance</td>
<td style="text-align: center;">EECS</td>
<td style="text-align: center;">Math</td>
<td style="text-align: center;">Physics</td>
<td style="text-align: center;">Chemistry</td>
<td style="text-align: center;">Finance</td>
<td style="text-align: center;">EECS</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">54.6</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">19.2</td>
<td style="text-align: center;">18.6</td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">23.0</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">31.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">59.8</td>
<td style="text-align: center;">32.0</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">32.6</td>
<td style="text-align: center;">27.5</td>
<td style="text-align: center;">22.5</td>
<td style="text-align: center;">25.9</td>
<td style="text-align: center;">35.9</td>
<td style="text-align: center;">30.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">52.8</td>
<td style="text-align: center;">42.9</td>
<td style="text-align: center;">47.5</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">62.3</td>
<td style="text-align: center;">58.4</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">69.6</td>
<td style="text-align: center;">66.7</td>
<td style="text-align: center;">59.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">69.8</td>
<td style="text-align: center;">63.1</td>
<td style="text-align: center;">63.5</td>
<td style="text-align: center;">63.6</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">59.1</td>
<td style="text-align: center;">50.2</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">58.7</td>
<td style="text-align: center;">59.7</td>
</tr>
<tr>
<td style="text-align: center;">CodeLlama</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">17.7</td>
<td style="text-align: center;">6.5</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">4.9</td>
<td style="text-align: center;">7.6</td>
<td style="text-align: center;">10.4</td>
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">3.6</td>
<td style="text-align: center;">8.8</td>
<td style="text-align: center;">6.9</td>
<td style="text-align: center;">6.9</td>
</tr>
<tr>
<td style="text-align: center;">CodeLlama</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">26.1</td>
<td style="text-align: center;">9.2</td>
<td style="text-align: center;">8.3</td>
<td style="text-align: center;">10.2</td>
<td style="text-align: center;">24.2</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">6.6</td>
<td style="text-align: center;">4.3</td>
<td style="text-align: center;">4.2</td>
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">12.2</td>
<td style="text-align: center;">7.4</td>
</tr>
<tr>
<td style="text-align: center;">ToRA-Coder</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">29.7</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">4.5</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">9.1</td>
<td style="text-align: center;">24.4</td>
<td style="text-align: center;">18.8</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">7.1</td>
<td style="text-align: center;">10.5</td>
<td style="text-align: center;">10.6</td>
<td style="text-align: center;">14.2</td>
</tr>
<tr>
<td style="text-align: center;">ToRA-Coder</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">21.4</td>
<td style="text-align: center;">21.7</td>
<td style="text-align: center;">4.5</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">13.6</td>
<td style="text-align: center;">15.9</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">9.6</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">13.9</td>
<td style="text-align: center;">11.2</td>
</tr>
<tr>
<td style="text-align: center;">M.heimeTH-Coder</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">21.6</td>
<td style="text-align: center;">14.8</td>
<td style="text-align: center;">18.5</td>
<td style="text-align: center;">11.0</td>
<td style="text-align: center;">25.8</td>
<td style="text-align: center;">40.0</td>
<td style="text-align: center;">14.3</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">6.7</td>
<td style="text-align: center;">13.1</td>
<td style="text-align: center;">12.9</td>
<td style="text-align: center;">12.8</td>
</tr>
<tr>
<td style="text-align: center;">Mistral</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">30.1</td>
<td style="text-align: center;">11.3</td>
<td style="text-align: center;">9.6</td>
<td style="text-align: center;">7.6</td>
<td style="text-align: center;">18.2</td>
<td style="text-align: center;">13.4</td>
<td style="text-align: center;">19.2</td>
<td style="text-align: center;">10.7</td>
<td style="text-align: center;">9.4</td>
<td style="text-align: center;">16.8</td>
<td style="text-align: center;">18.5</td>
<td style="text-align: center;">14.8</td>
</tr>
<tr>
<td style="text-align: center;">Mistral</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">27.6</td>
<td style="text-align: center;">13.1</td>
<td style="text-align: center;">13.5</td>
<td style="text-align: center;">14.4</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">19.5</td>
<td style="text-align: center;">10.4</td>
<td style="text-align: center;">15.2</td>
<td style="text-align: center;">13.1</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">15.2</td>
<td style="text-align: center;">13.7</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-Math</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">44.7</td>
<td style="text-align: center;">26.5</td>
<td style="text-align: center;">19.2</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">20.7</td>
<td style="text-align: center;">31.6</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">23.6</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">26.7</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-Math</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">41.3</td>
<td style="text-align: center;">24.2</td>
<td style="text-align: center;">24.4</td>
<td style="text-align: center;">25.4</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">19.8</td>
<td style="text-align: center;">21.6</td>
<td style="text-align: center;">17.7</td>
<td style="text-align: center;">24.1</td>
<td style="text-align: center;">20.8</td>
<td style="text-align: center;">21.8</td>
</tr>
<tr>
<td style="text-align: center;">Llama-3</td>
<td style="text-align: center;">8B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">40.3</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">10.9</td>
<td style="text-align: center;">16.9</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">32.7</td>
<td style="text-align: center;">18.3</td>
<td style="text-align: center;">21.3</td>
<td style="text-align: center;">27.4</td>
<td style="text-align: center;">24.1</td>
<td style="text-align: center;">26.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-3</td>
<td style="text-align: center;">8B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">38.0</td>
<td style="text-align: center;">24.7</td>
<td style="text-align: center;">26.9</td>
<td style="text-align: center;">25.4</td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;">37.8</td>
<td style="text-align: center;">20.2</td>
<td style="text-align: center;">19.7</td>
<td style="text-align: center;">18.4</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">28.4</td>
<td style="text-align: center;">22.3</td>
</tr>
<tr>
<td style="text-align: center;">SciAGENT-CODER</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">28.3</td>
<td style="text-align: center;">24.6</td>
<td style="text-align: center;">39.3</td>
<td style="text-align: center;">57.3</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">20.1</td>
<td style="text-align: center;">22.9</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">29.7</td>
<td style="text-align: center;">27.6</td>
</tr>
<tr>
<td style="text-align: center;">SciAGENT-MitTRAL</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">31.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">48.5</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">30.3</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">35.8</td>
<td style="text-align: center;">36.6</td>
<td style="text-align: center;">30.3</td>
</tr>
<tr>
<td style="text-align: center;">SciAGENT-LLAMA3</td>
<td style="text-align: center;">8B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">34.3</td>
<td style="text-align: center;">41.0</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">34.9</td>
<td style="text-align: center;">32.2</td>
<td style="text-align: center;">29.4</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">34.6</td>
<td style="text-align: center;">34.7</td>
</tr>
<tr>
<td style="text-align: center;">SciAGENT-DEEPMATH</td>
<td style="text-align: center;">7B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">60.4</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">54.5</td>
<td style="text-align: center;">44.9</td>
<td style="text-align: center;">57.5</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">40.2</td>
<td style="text-align: center;">40.0</td>
</tr>
<tr>
<td style="text-align: center;">CodeLlama</td>
<td style="text-align: center;">13B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">23.0</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">9.1</td>
<td style="text-align: center;">6.1</td>
<td style="text-align: center;">13.5</td>
<td style="text-align: center;">4.4</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">8.8</td>
<td style="text-align: center;">12.9</td>
<td style="text-align: center;">9.3</td>
</tr>
<tr>
<td style="text-align: center;">CodeLlama</td>
<td style="text-align: center;">13B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">38.9</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">14.7</td>
<td style="text-align: center;">7.6</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">34.1</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">6.4</td>
<td style="text-align: center;">4.4</td>
<td style="text-align: center;">12.4</td>
<td style="text-align: center;">11.9</td>
<td style="text-align: center;">9.8</td>
</tr>
<tr>
<td style="text-align: center;">ToRA-Coder</td>
<td style="text-align: center;">13B</td>
<td style="text-align: center;">$\lambda$</td>
<td style="text-align: center;">30.9</td>
<td style="text-align: center;">28.6</td>
<td style="text-align: center;">3.8</td>
<td style="text-align: center;">4.2</td>
<td style="text-align: center;">16.7</td>
<td style="text-align: center;">30.5</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">8.5</td>
<td style="text-align: center;">13.1</td>
<td style="text-align: center;">16.5</td>
<td style="text-align: center;">17.1</td>
</tr>
<tr>
<td style="text-align: center;">ToRA-Coder</td>
<td style="text-align: center;">13B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">28.0</td>
<td style="text-align: center;">32.0</td>
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">11.9</td>
<td style="text-align: center;">24.2</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">17.9</td>
<td style="text-align: center;">12.9</td>
<td style="text-align: center;">11.7</td>
<td style="text-align: center;">13.9</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">16.9</td>
</tr>
<tr>
<td style="text-align: center;">M.heimeTH-Coder</td>
<td style="text-align: center;">13B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">54.7</td>
<td style="text-align: center;">21.4</td>
<td style="text-align: center;">18.6</td>
<td style="text-align: center;">11.0</td>
<td style="text-align: center;">25.8</td>
<td style="text-align: center;">39.0</td>
<td style="text-align: center;">20.4</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">10.7</td>
<td style="text-align: center;">15.3</td>
<td style="text-align: center;">25.1</td>
<td style="text-align: center;">18.2</td>
</tr>
<tr>
<td style="text-align: center;">SciAGENT-CODER</td>
<td style="text-align: center;">13B</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">54.4</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">30.9</td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">30.6</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">29.8</td>
</tr>
</tbody>
</table>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Evaluated LLMs are not native tool-users. Their performance drops when they are equipped with either self-derived or external toolsets (color in blue and red, respectively). Tool-augmented learning (color in purple; fine-tuning on MATHFUNC) makes them benefit from attached toolsets.
tably, SCIAGENT-CODER surpasses ToRA-Coder by absolute accuracy of $13.4 \%$ and $12.7 \%$ on the 7B and 13B versions. Our strongest agent, SCIA-GENT-DEEPMATH-7B, substantially outperforms ChatGPT ( $40.0 \%$ v.s. $31.0 \%$ ).
The challenges of scientific reasoning. However, our agents still lags far behind GPT-4 by absolutely $20 \%$ or even more. This gap highlights the challenges of tool-augmented scientific reasoning, as well as our benchmark.</p>
<h3>6.4 Ablation Study</h3>
<p>We investigate the effectiveness of components in our training data and agent modules. The specific variants we considered are as follows. (1) We remove the planning module in the agent. (2) We additionally drop the cross-retrieval strategy introduced in Section 3.2. In its place, we construct function-augmented solutions directly from $\tilde{F}<em q="q">{q}$ and $\tilde{S}</em>$ for inference.}$. (3) We further remove all function-augmented solutions from our training data and only keep the solutions without function callings (functionfree solutions). (4) We do not fine-tune agents but merely use CodeLlama as $\mathcal{M}_{\text {action }</p>
<p>We illustrate the performance of our agents and their ablated variants in Table 3. We observe that (1) Planning module significantly improves scientific reasoning abilities. As detailed and targeted queries for the retriever, the generated plannings increase the relatedness of retrieved functions. For instance, the function's Recall@3 increases from $48.3 \%$ to $53.2 \%$ in physics domain, and from $37.3 \%$ to $39.8 \%$ in chemistry domain. (2) The use of the cross-retrieval strategy is essential. Otherwise, the function-augmented solutions directly from $\tilde{F}<em q="q">{q}$ and $\tilde{S}</em>$ degrade the performance because they are too artificial and ad-hoc to teach LLMs using functions properly. (3) The absence of function-augmented solutions results in a performance drop (row 1 v.s. row 4 in Table 3) of $5.9 \%$ and $5.3 \%$ in absolute accuracy for 7B and 13B LLMs, respectively. It underscores the critical role of function-augmented solutions to enhance LLMs' tool-use abilities, and the necessity of our MATHFUNC corpus. (4) The removal of function-free solutions (row 4 v.s. row 5) leads to an absolutely $14.4 \%$ accuracy decrease. Specifically focusing on non-math samples, there is a notable performance drop of about $12 \%$ as well.</p>
<p>Table 3: Ablation study on human-annotated subset of SciToolBench. We report the accuracy of samples across (1) all domains, (2) four domains excluding the math domain (wo. math).</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Planning</th>
<th style="text-align: center;">Function-augmented <br> solutions</th>
<th style="text-align: center;">Function-free <br> solutions</th>
<th style="text-align: center;">Accuracy (7B)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Accuracy (13B)</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SCIAGENT-Coder</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$ (cross-retrieval)</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\mathbf{3 2 . 2}$</td>
<td style="text-align: center;">$\mathbf{3 4 . 6}$</td>
<td style="text-align: center;">$\mathbf{3 5 . 7}$</td>
<td style="text-align: center;">$\mathbf{3 6 . 5}$</td>
</tr>
<tr>
<td style="text-align: left;">Intermediate variants</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$ (cross-retrieval)</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\underline{30.3}$</td>
<td style="text-align: center;">$\underline{33.9}$</td>
<td style="text-align: center;">$\underline{32.8}$</td>
<td style="text-align: center;">$\underline{34.4}$</td>
</tr>
<tr>
<td style="text-align: left;">1-3</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$ (direct-use)</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">26.6</td>
<td style="text-align: center;">31.0</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">26.1</td>
<td style="text-align: center;">30.4</td>
<td style="text-align: center;">31.7</td>
</tr>
<tr>
<td style="text-align: left;">CodeLlama</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">11.9</td>
<td style="text-align: center;">14.7</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">19.4</td>
</tr>
</tbody>
</table>
<p>This clearly demonstrates the fundamental importance of math skills in diverse scientific reasoning tasks, and highlights how our math-related samples enhance LLMs' capabilities in this area.</p>
<h3>6.5 Analysis ${ }^{9}$</h3>
<p>Robustness of Toolsets. We acknowledge the construction and maintenance of toolsets is sometime challenging. Therefore, we stress the importance of our agents' robustness. If a sub-par toolset were provided, an robust agent should at the very least perform comparably, if not better, than other competitive LLMs without tool-use. To evaluate the robustness of SCIAGENT-CODER, we simulate two sub-par settings. (1) weak-related: for each question, we restrict the agents from retrieving functions that are directly derived from it. This setting greatly decreases the likelihood of retrieving a proper function from the toolset. (2) unrelated: we completely remove the domain-specific toolset in SciToolBench. As a substitution, we provide the unrelated toolset constructed in MathFunc.</p>
<p>Table 4: Accuracy on SCIAGENT with sub-par toolsets. WR: weak-related toolsets. UR: unrelated toolsets. NA: No toolset. The subscripts indicate the difference from the best LLMs (wo. toolsets) each column.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Toolset</th>
<th style="text-align: center;">Accuracy (7B)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Accuracy (13B)</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">wo.math</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">wo. math</td>
</tr>
<tr>
<td style="text-align: center;">SCIAGENT <br> -Coder</td>
<td style="text-align: center;">WR</td>
<td style="text-align: center;">$18.8+0.7$</td>
<td style="text-align: center;">$18.0+0.6$</td>
<td style="text-align: center;">$24.6+4.0$</td>
<td style="text-align: center;">$19.9+7.0$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">UR</td>
<td style="text-align: center;">$14.7+0.7$</td>
<td style="text-align: center;">$10.7+1.0$</td>
<td style="text-align: center;">$20.3+0.9$</td>
<td style="text-align: center;">$14.7+2.4$</td>
</tr>
<tr>
<td style="text-align: center;">MAmmo-C</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">16.4</td>
<td style="text-align: center;">12.3</td>
</tr>
<tr>
<td style="text-align: center;">ToRA-C</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">18.1</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">11.1</td>
</tr>
</tbody>
</table>
<p>We compare our agents with two competitive LLMs, i.e., ToRA-Coder and MAmmoTH-Coder, in above two settings. As shown in Table 4, (1) SCIAGENT series with unrelated toolsets present comparable performance with the two LLMs. In</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>other words, our tool-augmented agents are unlikely to degrade the performance even under the extreme scenarios. (2) Our agents with weakrelated toolsets significantly outperform the two LLMs, which further validates the robustness.
The Effect of Retriever Quality. We explore the effect of retriever quality on the ending performance. We substitute our fine-tuned retriever in ScIAGENT series by two competitive variants: SimCSE (Gao et al., 2021) and Contriever (Izacard et al., 2021). As shown in Figure 6 (top), our retriever surpasses the other two. It shows that finetuning on the math domain benefits the retrieval of tools in the generalized scientific domains.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Top: Performance of SciAGENT-CODER on SciToolBench with different retriever variants. Bottom: Relationship between the performance and the hit@3 of retrieved functions (artificially controlled).</p>
<p>We further dive deep into the relationship between the hit ratio of tools and the agents' performance. To this end, we manually control the hit@3 ratio by artificially adding/removing the positive functions to/from the retrieved list. Results in Figure 6 (bottom) show a clearly positive correlation between the hit ratio and the task accuracy. It illustrates that the retrieved functions facilitate the reasoning of scientific problems. However, we still observe a limit ( $40 \%$ accuracy) when the hit ratios</p>
<p>reaching $100 \%$, showing the challenge of scientific reasoning even when aided by tools. We hope the future work to bridge this performance gap.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: The performance of SCIAGENT-CODER (w. toolset) and MAmmoTH-Coder (wo. toolset) on samples which (1) use and (2) not use retrieved functions.</p>
<p>How the Retrieved Functions Benefit. To assess how the retrieved functions aid in the reasoning process of LLMs, we divided the samples into two subsets based on whether our agents use the retrieved functions to solve the problems. We evaluate the performance of these two subsets respectively, comparing with MAmmoTH-Coder series (without tool-use). The results in Figure 7 reveal a two-fold benefit: (1) For samples where functions are explicitly called to solve the questions, our agents demonstrate a substantial $25 \%$ improvement in absolute accuracy over LLMs that do not have access to functions. (2) Even for samples that do not directly use functions in their written program, we still observe a slight improvement. It suggests that our agents are capable of learning from retrieved functions as a reference, and then imitate these functions to write their own programs. For instance, example in Figure 13 shows the agents learn how to use scipy.integrate by observing the retrieved function average_value_of_function(...).</p>
<h2>7 Conclusion</h2>
<p>This work proposes tool-augmented scientific reasoning, a task aiming to solve challenging scientific problems aided by generalized and scalable tools. To facilitate and evaluate the scientific tooluse abilities of LLMs, we construct a math-related, tool-augmented training corpus MathFunc and a benchmark SciToolBench covering 5 scientific domains. Additionally, we develop open-source agents, SCIAGENT series, as competitive baselines. Extensive experiments reveal that our agents exhibit tool-use abilities exceeding ChatGPT in scientific reasoning tasks.</p>
<h2>Limitations</h2>
<p>The primary limitation of our work comes from the way we compile SciToolBench.
Toolsets The tools are constructed directly based on the benchmark's questions, raising concerns about potential information leakage. To address this, we invest significant human effort in our annotation process as detailed in Appendix D.3. We manually review and, if necessary, revise all derived functions to ensure their generalizability and quality. As shown in Figure 6 (bottom), our agents achieve only about $40 \%$ accuracy when we provide each question the exact function from which it derives (i.e., $100 \%$ hit ratio). It not only highlights the inherent challenge of scientific reasoning tasks, but also suggests that our benchmark suffers minimal impact from the potential information leakage.
Question We expand the questions in our benchmark by adding auto-synthesized questions. Though the evaluation on synthesized datasets has been commonly used by some recent work (Masry et al., 2022; Ge et al., 2024), the rationality and quality of these synthesized questions deserve deeper discussion. To this end, we compare the results on human-annotated questions and synthesized questions and observe a high correlation between them on different LLMs. Quantitatively, they have a Spearman's Rank Correlation Coefficient as 0.903 (p-value 2.2e-8). In other words, if a model performs better than another model on synthesized questions, it very likely achieves a higher score on human-annotated questions. Therefore, we believe that the accuracy on synthesized dataset could overall indicate the tool-use abilities of these LLMs.</p>
<h2>Ethics Statement</h2>
<p>We ensure that SciToolBench was constructed in compliance with the terms of use of all source materials and with full respect for the intellectual property and privacy rights of the original authors of the texts. We also provide details on the characteristics and annotation steps of SciToolBench in Section 5 and Appendix D. We believe our created datasets do not cause any potential risks.</p>
<h2>References</h2>
<p>Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman, and Sean Welleck. 2023. Llemma: An open language model for mathematics.</p>
<p>Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller. 2023. Chemcrow: Augmenting large-language models with chemistry tools.</p>
<p>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. 2023. Large language models as tool makers.</p>
<p>Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. 2023a. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Transactions on Machine Learning Research.</p>
<p>Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and Tony Xia. 2023b. TheoremQA: A theorem-driven question answering dataset. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7889-7901, Singapore. Association for Computational Linguistics.</p>
<p>Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Xin Zhao, and Ji-Rong Wen. 2023c. ChatCoT: Tool-augmented chain-of-thought reasoning on chatbased large language models. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 14777-14790, Singapore. Association for Computational Linguistics.</p>
<p>Ethan Chern, Haoyang Zou, Xuefeng Li, Jiewen Hu, Kehua Feng, Junlong Li, and Pengfei Liu. 2023. Generative ai for math: Abel. https://github.com/ GAIR-NLP/abel.</p>
<p>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, and Huajun Chen. 2023. Mol-instructions: A large-scale biomolecular instruction dataset for large language models.</p>
<p>Shen Gao, Zhengliang Shi, Minghang Zhu, Bowen Fang, Xin Xin, Pengjie Ren, Zhumin Chen, Jun Ma, and Zhaochun Ren. 2023. Confucius: Iterative tool learning from introspection feedback by easy-to-difficult curriculum.</p>
<p>Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. SimCSE: Simple contrastive learning of sentence embeddings. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6894-6910, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu. 2024. Scaling synthetic data creation with $1,000,000,000$ personas.</p>
<p>Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. 2023a. Critic: Large language models can self-correct with tool-interactive critiquing.</p>
<p>Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen. 2023b. Tora: A tool-integrated reasoning agent for mathematical problem solving.</p>
<p>Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. 2023. Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings.</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021a. Measuring massive multitask language understanding. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.</p>
<p>Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b. Measuring mathematical problem solving with the math dataset. NeurIPS.</p>
<p>Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and Junxian He. 2023. C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models.</p>
<p>Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2021. Unsupervised dense information retrieval with contrastive learning.</p>
<p>Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023. Mistral 7b.</p>
<p>Qiao Jin, Yifan Yang, Qingyu Chen, and Zhiyong Lu. 2023. Genegpt: Augmenting large language models with domain tools for improved access to biomedical information.</p>
<p>Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for opendomain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6769-6781, Online. Association for Computational Linguistics.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach.</p>
<p>Yuliang Liu, Xiangru Tang, Zefan Cai, Junjie Lu, Yichi Zhang, Yanjun Shao, Zexuan Deng, Helan Hu, Zengxian Yang, Kaikai An, Ruijun Huang, Shuzheng Si, Sheng Chen, Haozhe Zhao, Zhengliang Li, Liang Chen, Yiming Zong, Yan Wang, Tianyu Liu, Zhiwei Jiang, Baobao Chang, Yujia Qin, Wangchunshu Zhou, Yilun Zhao, Arman Cohan, and Mark Gerstein. 2023. Ml-bench: Large language models leverage open-source libraries for machine learning tasks.</p>
<p>LlamaTeam. 2024. The llama 3 herd of models.
Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, KaiWei Chang, Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. Chameleon: Plug-and-play compositional reasoning with large language models.</p>
<p>Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct.</p>
<p>Ahmed Masry, Xuan Long Do, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. 2022. ChartQA: A benchmark for question answering about charts with visual and logical reasoning. In Findings of the Association for Computational Linguistics: ACL 2022, pages 22632279, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>OpenAI. 2023. Gpt-4 technical report.
Siru Ouyang, Zhuosheng Zhang, Bing Yan, Xuan Liu, Jiawei Han, and Lianhui Qin. 2023. Structured chemistry reasoning with large language models.</p>
<p>Liangming Pan, Alon Albalak, Xinyi Wang, and William Wang. 2023. Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 3806-3824, Singapore. Association for Computational Linguistics.</p>
<p>Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. 2023. Gorilla: Large language model connected with massive apis.</p>
<p>Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao. 2023. Check your facts and try again: Improving large language models with external knowledge and automated feedback.</p>
<p>PhiTeam. 2024. Phi-3 technical report: A highly capable language model locally on your phone.</p>
<p>Cheng Qian, Chi Han, Yi Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. 2023. CREATOR: Tool creation for disentangling abstract and concrete reasoning of large language models. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 6922-6939, Singapore. Association for Computational Linguistics.</p>
<p>Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, and Maosong Sun. 2023a. Tool learning with foundation models.</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. 2023b. Toolllm: Facilitating large language models to master 16000+ real-world apis.</p>
<p>Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, and Yuxiong He. 2021. Zero-infinity: Breaking the gpu memory wall for extreme scale deep learning. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC '21, New York, NY, USA. Association for Computing Machinery.</p>
<p>Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel Synnaeve. 2023. Code llama: Open foundation models for code.</p>
<p>Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. 2024. Deepseekmath: Pushing the limits of mathematical reasoning in open language models.</p>
<p>Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. In Advances in Neural Information Processing Systems.</p>
<p>Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo Song, Hailiang Huang, Cheng Li, Ke Wang, Rong Yao, Ye Tian, and Sujian Li. 2023. Restgpt: Connecting large language models with real-world restful apis.</p>
<p>Liangtai Sun, Yang Han, Zihan Zhao, Da Ma, Zhennan Shen, Baocai Chen, Lu Chen, and Kai Yu. 2023. Scieval: A multi-level large language model evaluation benchmark for scientific research.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti</p>
<p>Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open foundation and finetuned chat models.</p>
<p>Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2019. Representation learning with contrastive predictive coding.</p>
<p>Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2023a. Mathcoder: Seamless code integration in llms for enhanced mathematical reasoning.</p>
<p>Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Arjun R. Loomba, Shichang Zhang, Yizhou Sun, and Wei Wang. 2023b. Scibench: Evaluating college-level scientific problem-solving abilities of large language models.</p>
<p>Xingyao Wang, Zihan Wang, Jiateng Liu, Yangyi Chen, Lifan Yuan, Hao Peng, and Heng Ji. 2023c. Mint: Evaluating llms in multi-turn interaction with tools and language feedback.</p>
<p>Zhiruo Wang, Daniel Fried, and Graham Neubig. 2024. Trove: Inducing verifiable and efficient toolboxes for solving programmatic tasks.</p>
<p>Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. 2023. Visual chatgpt: Talking, drawing and editing with visual foundation models.</p>
<p>Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, and Jian Zhang. 2023a. On the tool manipulation capability of open-source large language models.</p>
<p>Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, Zhoujun Cheng, Siheng Zhao, Lingpeng Kong, Bailin Wang, Caiming Xiong, and Tao Yu. 2023b. Lemur: Harmonizing natural language and code for language agents.</p>
<p>Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, and Ying Shan. 2023. Gpt4tools: Teaching large language model to use tools via self-instruction.</p>
<p>Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, and Bill Yuchen Lin. 2023. Lumos: Learning agents with unified data, modular design, and open-source llms.</p>
<p>Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. Metamath: Bootstrap your own mathematical questions for large language models. ArXiv preprint, abs/2309.12284.</p>
<p>Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R. Fung, Hao Peng, and Heng Ji. 2023a. Craft: Customizing llms by creating and retrieving from specialized toolsets.</p>
<p>Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Keming Lu, Chuanqi Tan, Chang Zhou, and Jingren Zhou. 2023b. Scaling relationship on learning mathematical reasoning with large language models.</p>
<p>Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023a. Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi.</p>
<p>Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023b. Mammoth: Building math generalist models through hybrid instruction tuning.</p>
<p>Dan Zhang, Ziniu Hu, Sining Zhoubian, Zhengxiao Du, Kaiyu Yang, Zihan Wang, Yisong Yue, Yuxiao Dong, and Jie Tang. 2024. Sciglm: Training scientific language models with self-reflective instruction annotation and tuning.</p>
<p>Wenxuan Zhang, Sharifah Mahani Aljunied, Chang Gao, Yew Ken Chia, and Lidong Bing. 2023a. M3exam: A multilingual, multimodal, multilevel benchmark for examining large language models.</p>
<p>Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. 2023b. Cumulative reasoning with large language models.</p>
<p>Yilun Zhao, Hongjun Liu, Yitao Long, Rui Zhang, Chen Zhao, and Arman Cohan. 2023. Knowledgemath: Knowledge-intensive math word problem solving in finance domains.</p>
<p>Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2023. Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification.</p>
<h2>A Detailed Related Work</h2>
<h2>A. 1 Scientific Reasoning</h2>
<p>Scientific reasoning can be roughly categorized into two branches: (1) mathematical reasoning and (2) reasoning across other scientific domains.</p>
<p>Mathematical Reasoning. As a fundamental task to evaluate the capabilities of LLMs (PhiTeam, 2024; LlamaTeam, 2024), mathematical (math) reasoning has attracted much more attentions recently. There are intensive studies for more powerful mathoriented LLMs by prompt engineering (Qian et al., 2023; Zhang et al., 2023b; Zhou et al., 2023), instruction-tuning (Yuan et al., 2023b; Yue et al., 2023b; Gou et al., 2023b; Yu et al., 2023; Wang et al., 2023a) and even pre-training (Luo et al., 2023; Azerbayev et al., 2023; Chern et al., 2023). Regarding instruction-tuning, we notice that recent studies have automatically constructed high-quality instructions from GPT-4, i.e., fine-tuning opensource LLMs by Program-of-thought (PoT; Chen et al. 2023a) prompting. It enables open-source LLMs to present remarkable performance, even comparable with GPT-4.</p>
<p>Reasoning across Other Domains. There have been intensive works on scientific LLMs (Bran et al., 2023; Jin et al., 2023; Fang et al., 2023) and benchmarks (Hendrycks et al., 2021a; Huang et al., 2023; Zhang et al., 2023a; Yue et al., 2023a; Sun et al., 2023). However, they primarily target on problems involving less complicated reasoning like knowledge retrieval or simple tool utilization.</p>
<p>Regarding complicated scientific reasoning problems (Chen et al., 2023b; Wang et al., 2023b), questions are scattered among diverse topics and each topic additionally requires domain-specific knowledge. So annotating questions and their solutions domain by domain is much more laborconsuming. Most current benchmarks (Chen et al., 2023b; Wang et al., 2023b; Zhao et al., 2023) merely include hundreds of questions (in all; less for each single domain) from textbooks and provide no training samples. A concurrent work (Zhang et al., 2024) develop a large-scale scientific training corpus, but only focuses three common domains: math, physical and chemistry. Accordingly, the progress of reasoning tasks in these domains is slower than that in math domain: the most competitive approach only achieves $50 \%$ and $35 \%$ on TheoremQA and SciBench, respectively. Instead of developing an omniscient and proficient LLMs on
reasoning tasks across various scientific domains, we believe it is more practical to teach LLMs the ability to use domain-specific tools to facilitate their reasoning abilities in some domain when external functions (toolset) are attached.</p>
<h2>A. 2 Tool Learning</h2>
<p>LLMs, both proprietary ones and open-source ones, demonstrate promising capabilities leveraging external tools to solve problems beyond their limits (Qin et al., 2023a). Combined with specific tools, these tool-augmented LLMs achieve great success on various tasks such as machine learning (Wu et al., 2023; Shen et al., 2023; Patil et al., 2023; Yang et al., 2023; Liu et al., 2023), question answering (Peng et al., 2023; Gou et al., 2023a), daily assistance (Xu et al., 2023a; Qin et al., 2023b; Song et al., 2023; Gao et al., 2023), etc.</p>
<p>Previous work usually pre-defines several tools, e.g., equation solver or calculator, to facilitate math reasoning tasks (Gou et al., 2023a; Lu et al., 2023; Hao et al., 2023; Chen et al., 2023c; Wang et al., 2023c; Xu et al., 2023b; Yin et al., 2023). Cai et al. (2023) generalize the concept of tools to Program functions. Following this concept, CREATOR (Qian et al., 2023) scale up the function number towards thousand level. However, these ad-hoc, argument-free functions are more like solution wrapper rather than well-generalized tools. CRAFT (Yuan et al., 2023a) targetedly design an automatic pipeline to extract generalized functions for tool-use. Though leading to improvement, these functions are still not generalized enough and serve more as reference rather than as tools for direct calling ${ }^{10}$. Ouyang et al. 2023 ask LLM to generate chemistry formulae as knowledge reference to assist the following reasoning and achieve enhanced performance on chemistry questions in SciBench. Similar as our attached toolset, Zhao et al. (2023) maintain a knowledge bank in which saves more than 900 financial definitions/equations/models as the format of functions for retrieval and use. To our best knowledge, our work is the first which (1) finetunes open-source, tool-augmented LLM agents for scientific reasoning tasks and (2) provides a benchmark covering multiple scientific domains to evaluate LLMs' tool-use abilities.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>B Training Details</h2>
<h2>B. 1 Retriever</h2>
<p>To fine-tune a retriever, we construct the training samples from MATHFUNC. We concatenate the question and its planning as the query, and view the generated functions as the keys. We finally collect a total of 8,603 query-key pairs for training, and split $10 \%$ training samples as validation set.</p>
<p>$$
\begin{aligned}
\text { query } &amp; =\left[q ; G_{q}\right] \
\text { key } &amp; =f \in \tilde{F}_{q}
\end{aligned}
$$</p>
<p>We follow DPR (Karpukhin et al., 2020) to train a dense retriever $R$. We use ROBERTA-BASE (Liu et al., 2019) as the backbone. We set the training step as 500 , the batch size as 128 and the learning rate as $2 \mathrm{e}-5$. We also set the temperature coefficient of the InfoNCE loss (van den Oord et al., 2019) as 0.07 . We run this experiment on a single NVIDIA Quadro RTX8000 GPU. The whole training process lasts for about 20 minutes.</p>
<h2>B. 2 Planning and Action</h2>
<p>We fine-tune CodeLlama (Rozière et al., 2023), Mistral (Jiang et al., 2023), Llama-3 (Touvron et al., 2023) and DeepMath (Shao et al., 2024) on MATHFunc to develop the planning and action modules in our tool-augmented agents SCIAGENT series. We set the global batch size as 128 . We use the learning rate as $2 \mathrm{e}-5$ for CodeLlama, 2e-6 for Mistral and Llama-3, and 5e-6 for DeepMath. We use a cosine scheduler with a $3 \%$ warm-up period for 2 epochs. We train all models with ZeRO Stage3 (Rajbhandari et al., 2021) on 8 V100 GPUs. The whole training process lasts for about 3 hours for 7B LLMs and 7.5 hours for 13B LLMs.</p>
<p>The planning and action modules share the same model but act differently with different input instructions. We detail the format of planning and action instructions as below:
Planning. Given a question $q$, we construct a planning sample as $\left(I_{\text {plan }}(q), G_{q}\right)$, where $I_{\text {plan }}(q)$ is the input instruction, $G_{q}$ is the output, and $I_{\text {plan }}(.)$ is the template for planning module. We provide an example of planning instruction as below:</p>
<p>Listing 1: An example of the planning sample. We separate the input instruction and output answer by the dashed line.
Read the following question and provide a high-level, step-by-step plan for this problem.</p>
<p>Question: Two complementary angles are in a ratio of $\$ 3: 2 \$$. What is the measure, in degrees, of the smaller angle?</p>
<p>Answer:
To solve this problem, we need to perform the following steps:</p>
<ul>
<li>Set up an equation using the given ratio and the fact that the angles are complementary.</li>
<li>Solve the equation for the variable representing the ratio.</li>
<li>Calculate the measure of the smaller angle using the found variable value.</li>
</ul>
<p>Action. Given a question $q$, we construct an action sample as $\left(I_{\text {action }}\left(q, F_{q}\right), S_{q}\right)$, where $I_{\text {action }}\left(q, F_{q}\right)$ is the input instruction, $S_{q}$ is the output answer, and $I_{\text {action }}(.)$ is the template for action module. $F_{q}$ are retrieved functions from the toolset in MATHFunc. We adopt the retriever in Appendix B. 1 to retrieve three functions in the toolset. We provide an example of action instruction as below:</p>
<p>Listing 2: An example of the action sample. We separate the input instruction and output answer by the dashed line. We only show one retrieved function in this sample for visualization convenience.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Read</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">mathematical</span><span class="w"> </span><span class="n">question</span>
<span class="w">    </span><span class="ow">and</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="n">it</span><span class="o">.</span><span class="w"> </span><span class="n">Please</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">you</span>
<span class="w">    </span><span class="n">could</span><span class="w"> </span><span class="p">(</span><span class="n">optionally</span><span class="p">,</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">required</span><span class="p">)</span>
<span class="w">    </span><span class="n">call</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">functions</span><span class="w"> </span><span class="n">when</span>
<span class="w">    </span><span class="n">writing</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">code</span><span class="p">:</span>
<span class="n">def</span><span class="w"> </span><span class="n">angle_ratio_to_degrees</span><span class="p">(</span><span class="n">ratio</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the angle measures in</span>
<span class="sd">        degrees given their ratio.</span>
<span class="sd">    Parameters:</span>
<span class="sd">    - ratio (tuple): The ratio of the</span>
<span class="sd">        angles.</span>
<span class="sd">    Returns:</span>
<span class="sd">    - tuple: The angle measures in</span>
<span class="sd">        degrees.</span>
<span class="sd">    Formula:</span>
<span class="sd">    - angle_1 = ratio[0] * x</span>
<span class="sd">    - angle_2 = ratio[1] * x</span>
<span class="sd">    - angle_3 = ratio[2] * x</span>
<span class="sd">    - where x is the common variable such</span>
<span class="sd">        that angle_1 + angle_2 + angle_3</span>
<span class="sd">            = 180 degrees</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="w">    </span><span class="n">sum_ratios</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">180</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sum_ratios</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tuple</span><span class="p">(</span><span class="n">angle</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">angle</span><span class="w"> </span><span class="ow">in</span>
<span class="w">        </span><span class="n">ratio</span><span class="p">)</span>
</code></pre></div>

<p>[...Two more retrieved functions...]</p>
<p>Question: Two complementary angles are in a ratio of $\$ 3: 25$. What is the measure, in degrees, of the smaller angle?</p>
<p>Answer:
# Define the ratio of the angles. ratio $=(3,2)$
# Since the angles are complementary, they add up to 90 degrees.
# We can find the value of each part of the ratio by dividing 90 by the sum of the parts of the ratio.
value_of_each_part = 90 / sum(ratio)
# The measure of the smaller angle is the value of each part times the smaller part of the ratio.
smaller_angle = value_of_each_part * min (ratio)
# Print the result.
print(smaller_angle)</p>
<h2>C Evaluation Details</h2>
<p>We evaluate (1) the tool-use abilities of LLMs in scientific reasoning task, and (2) their performance when supplemented without any toolsets for comparison. We detail these two settings as below:
With Toolsets. We use the unified PoT-based prompt (Chen et al., 2023a) for all pretrainingbased models and our SCIAGENT series. The unified prompt consists of a short task description and two demonstrations. We show the prompt in Appendix H.4. For each question, we provide three retrieved functions and instruct LLMs to use them if (and only if) necessary. Note that we use the same retriever, i.e., fine-tuned from MATHFUNC, for all LLMs. For MAmmoTH-Coder and ToRA-Coder which are fine-tuned on specific (tool-agnostic) instructions, we try to enable them to use retrieved tools while keeping the formats of their original instructions as much as possible. Specifically, we append a short tool-augmented description at the end of their original prompts:
[original prompt]
Please note that you could (optionally, not required) call the following functions when writing the program:
[retrieved functions]
Without Toolsets. Similar as above, we use the unified PoT-based prompt (Chen et al., 2023a) shown in Appendix H. 5 for all pretraining-based models and our SCIAGENT series. And we follow the original instructions used for MAmmoTH-Coder and ToRA-Coder to evaluate their performance.</p>
<h2>D Details of SciToolBench Annotation</h2>
<p>We provide a more thorough description about SCITOOLBENCH construction in this section. This semi-automatic annotation pipeline involves both GPT-4 and humans to balance the quality and cost. Specifically, we enlist two authors to serve as human annotators. Both of them are graduate students with proficiency in English. Additionally, they hold Bachelor of Science and/or Engineering degrees and have completed undergraduate-level courses in the five scientific domains corresponding to our benchmark. We detail the four subsequent submodules in our annotation pipeline, i.e., humanannotated question curation, synthesized question generation, positive function construction and negative function construction, as below.</p>
<h2>D. 1 Human-annotated Question Curation</h2>
<p>We curate the questions from TheoremQA (Chen et al., 2023b) and SciBench (Wang et al., 2023b), both of which are available under the MIT License. Among 1,495 questions in these original two datasets, we remove three kinds of questions.
Image-required: There are 37 questions from TheoremQA which include images and necessitate visual understanding abilities. We remove these samples because our benchmark is text-oriented.
Reasoning-agnostic: There are some multi-choice questions from TheoremQA which merely requires the memorization of knowledge points but involves little reasoning process. For example:</p>
<p>Question: The open mapping theorem can be proved by
(a) Baire category theorem.
(b) Cauchy integral theorem.
(c) Random graph theorem.
(d) None of the above.</p>
<p>We manually check each samples and remove 68 such kind of samples.
Over-difficult: Too hard questions confuse all models and weaken the discrimination of our benchmark. To balance the difficulty and discrimination, we employ 4 advanced proprietary models ${ }^{11}$ to generate related functions and functionaugmented program solutions. We generate 6 solutions for each model (one generated by greedy decoding and the other five by nucleus sampling</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>with 0.6 temperature) and 24 solutions in all. We view questions that are answered incorrectly by all 24 solutions as over-difficult questions. We remove all over-difficult questions, and retain $73.5 \%$ questions in TheoremQA and $47.8 \%$ in SciBench.</p>
<p>By removing three kinds of samples mentioned above, there are a total of 856 questions in our SciToolBench benchmark.</p>
<h2>D. 2 Synthesized Question Generation</h2>
<p>The human-annotated questions mentioned above are curated from two small-scale yet diverse datasets. As a result, there are limited questions that share the same knowledge points and, consequently, the functions in the toolsets. This limitation may constrain the validation of the toolset's generalizability. To address this gap, we expand the question set for better varied applicability of the functions. We synthesize new questions by a two-step, automatic pipeline as below:
Question Generation. For each human-annotated question, we employ GPT-4o to generate an additional six similar but not identical questions. To ensure that the generated questions are as independent as possible, we (1) set a high temperature of 1.0 , and (2) run GPT-4o six times in parallel, generating one question in each run to prevent the influence of previously generated questions on new ones. We show the used prompt as below.</p>
<p>Listing 3: Prompt for synthesized question generation</p>
<div class="codehilite"><pre><span></span><code><span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">scientific</span><span class="w"> </span><span class="n">question</span><span class="p">,</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">are</span>
<span class="w">    </span><span class="n">tasked</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">generate</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">question</span>
<span class="w">    </span><span class="n">following</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">requirements</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">below</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">question</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span>
<span class="w">    </span><span class="n">quantitative</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">specific</span><span class="w"> </span><span class="n">number</span><span class="p">.</span>
<span class="o">-</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">question</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">share</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">same</span>
<span class="w">    </span><span class="n">scientific</span><span class="w"> </span><span class="n">core</span><span class="w"> </span><span class="n">knowledge</span><span class="w"> </span><span class="n">or</span>
<span class="w">    </span><span class="n">formula</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="n">one</span><span class="p">.</span>
<span class="o">-</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">question</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">too</span>
<span class="w">    </span><span class="n">similar</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="n">question</span><span class="p">.</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">make</span><span class="w"> </span><span class="n">significant</span><span class="w"> </span><span class="n">changes</span>
<span class="w">    </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">question</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">altering</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">narrative</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">specific</span><span class="w"> </span><span class="n">numbers</span><span class="p">,</span>
<span class="w">    </span><span class="n">etc</span><span class="p">.</span>
<span class="o">-</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">settings</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">new</span>
<span class="w">        </span><span class="n">question</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">realistic</span><span class="p">,</span>
<span class="w">    </span><span class="n">avoiding</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">impossible</span><span class="w"> </span><span class="n">scenarios</span>
<span class="w">    </span><span class="n">such</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="mi">2000</span><span class="n">kg</span><span class="w"> </span><span class="n">human</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">temperature</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="mi">-100</span><span class="n">K</span><span class="p">.</span>
<span class="n">Output</span><span class="w"> </span><span class="n">format</span><span class="o">:</span>
<span class="err">```</span><span class="n">Question</span>
<span class="p">[</span><span class="n">New</span><span class="w"> </span><span class="n">Question</span><span class="p">]</span>
</code></pre></div>

<p>Question Filtering. The above step results in the generation of 5,136 synthesized questions</p>
<p>WITHOUT ground-truth answers and functionaugmented solutions. To ensure the quality of these questions, we have GPT-4o generate answers five times for each synthesized question and adopt the majority vote as the (silver) answer. Questions for which GPT-4o fails to provide a major-voting answer are removed. Additionally, a manual review of some synthesized questions reveals that GPT-4o occasionally generates overly simplistic questions, which diminishes the necessity for tool-use applications. Therefore, questions with unanimously predictions (5/5) are considered overly simplistic and downsampled at a ratio of 0.5 . Consequently, a total of 3,394 out of 5,136 synthesized questions are finalized as part of our benchmark.</p>
<h2>D. 3 Positive Function Construction</h2>
<h2>Function Generation</h2>
<p>In practice, we merge this sub-module to the process of over-difficult question identification in Appendix D.1. We randomly sample one set of functions which yield correct solutions for each question. As a result, we collect a total of 1,216 candidates for the next verification sub-module. We additionally save other functions leading to correct solutions and use them as reference in the refinement sub-module.</p>
<h2>Function Verification</h2>
<p>We verify the generated functions from both correctness and generalizations. We detail them separately as below.</p>
<ol>
<li>Correctness: Since all candidate functions lead to correct solutions, we speculate that almost all of them are correct. We randomly sample 100 functions ( 20 per domain) and manually check their correctness. The results shown in Table 5 validate our speculation. Therefore, we assume all candidate functions are correct and retain them.</li>
</ol>
<p>Table 5: The correctness of 100 randomly sampled functions across five domains.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Correct</th>
<th style="text-align: center;">Partially Correct</th>
<th style="text-align: center;">Wrong</th>
<th style="text-align: center;">All</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Math</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">Physics</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">Chemistry</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">Finance</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">EECS</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">93</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">100</td>
</tr>
</tbody>
</table>
<ol>
<li>Generalization: We encounter the similar problem as the function construction in MathFunc, i.e., some of the auto-generated functions are not</li>
</ol>
<p>generalized enough. If ad-hoc functions were in the provided toolsets of our benchmark, they would cause a significant overestimation of LLMs' tooluse abilities. To mitigate it as much as possible, we manually check all candidate functions to ensure their generalization. Specifically, we design a binary classification task and assign each function a label in {Retained, Refined}. We label a function as refined if it had one of the problems listed below: (1) a pure solution wrapper. (2) merely defining a non-generalized expression (likely only occur in this question). (3) the argument names or document describing the special scenario of corresponding question and not being generalized/abstractive enough. (4) including adhoc constants or code snippets. The annotators firstly co-annotate 100 functions. We calculate Cohen's kappa value of their annotation results as 0.85 , illustrating an ideal agreement. Therefore, the annotators separately annotate the remaining functions. It takes about 6 hours per annotator to classify about 650 functions. We show some Refined function cases in Figure 11, and the annotation interface in Figure 9.</p>
<p>As a result, we collect 1,012 Retained and 206 Refined functions. We keep all Retained as the component of positive functions. We also feed the Refined functions to next refinement sub-module to modify them as much as possible.</p>
<h2>Function Refinement</h2>
<p>This sub-module aims to rewrite 206 Refined functions to make them qualified. To this end, we associate each function with (1) the question from which it is derived, (2) the function-augmented solutions, and (3) the alternative functions from the generation sub-module (if have). Then we provide them to the annotators. The annotators are asked to rewrite the functions to improve their generalization as much as possible. If one function were successfully rewritten, we also require the annotator to write a solution involving the new function to the related question. The solution must yield correct answer to ensure the correctness of the rewritten function. We show some rewritten cases in Figure 11, and the screenshot of the annotation interface in Figure 10.</p>
<p>It takes approximately 12 hours per annotator to check each Refined function and, if applicable, rewrite it. As a consequence, we successfully rewrite 91 Refined functions and drop the remaining ones. We combine these 91 rewritten functions and the 1,012 Retained functions to
construct 1,103 positive functions. At last step, we deduplicate these functions and finalize a collection of 942 functions.</p>
<h2>D. 4 Negative Function Construction</h2>
<p>The positive functions constructed above have satisfied the minimum requirements of the toolset in our benchmark. However, we find that such kind of benchmark contains shortcuts for LLM to retrieve and use functions. Take a physical question about frequency-angular conversion as example, the previous modules construct a positive function named angular_from_frequency(...) to solve this question. Without any other similar functions, the LLMs could readily select and use the only function by superficial shortcuts. These shortcuts significantly weaken the function-understanding and -use abilities evaluation of our benchmark. To mitigate this problem, we design an additional module to eliminate the shortcuts by constructing some (hard) negative functions for each positive function, like frequency_from_angular(...) and frequency_from_energy(...) in the above example. Among three similar functions, LLMs are forced to understand their usages and choose proper ones to use. In summary, we add negative functions into the toolset to simulate a more challenging scenario and better evaluate LLMs' tooluse abilities.</p>
<p>Listing 4: Prompt for constructing negative functions
Given a function about the {subfield} field, could you please write two more functions which satisfy:</p>
<ul>
<li>The functions should be in the same field with the provided function, while the knowledge point is not compulsorily the same.</li>
<li>The functions should be similar, but not identical with the provided function.</li>
<li>The new written functions should be wrapped as the below format:</li>
</ul>
<p>New function 1:
<code>python
[new_written_function_1]</code></p>
<p>New function 2:
<code>python
[new_written_function_2]</code></p>
<p>Specifically, we employ GPT-4 for each positive function to generate two similar but not identical functions as the negative functions. The prompt used is shown as below. We do not validate the cor-</p>
<p>rectness of negative functions for simplicity, as they are not intended to be used for any question. We filter the duplicated functions and retain the other 1,343 functions in all. By merging 942 positive functions and 1,343 negative functions, we finally collect a total of 2,285 functions in our toolset.</p>
<h2>E More Details for Datasets</h2>
<h2>E. 1 MATHFUNC</h2>
<p>Quality Checking We conduct quality checking on the functions and solutions in MATHFUNC. Specifically, we randomly sample 100 functions from the toolset and 100 function-augmented solutions from the sample set ${ }^{12}$. Then we manually check the correctness of them as what we have done in Appendix D.3. The results demonstrate that 96 functions and 98 solutions are correct, which validate the quality of these auto-generated data and our construction pipeline.
More Statistics We count the number of used functions in each function-augmented solution, i.e., the function occurrence, and show the results as below.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Function Occurrence</th>
<th style="text-align: center;">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1250</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">712</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">91</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">18</td>
</tr>
<tr>
<td style="text-align: center;">$\geq 5$</td>
<td style="text-align: center;">10</td>
</tr>
</tbody>
</table>
<p>Table 6: Function occurrence in MATHFUNC</p>
<p>We find that (1) $40.3 \%$ of solutions do not call any functions. We deliberately include these samples in MATHFUNCo enhance the model's robustness, i.e., learning not to use retrieved functions if they were not appropriate. (2) For other solutions, each of them calls 1.31 functions on average.
Function Examples We list the top-10 frequent functions and other 10 representative highfrequency functions in the toolset of MATHFUNC in the following two tables.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Function name</th>
<th style="text-align: center;">Frequency</th>
<th style="text-align: center;">Function name</th>
<th style="text-align: center;">Frequency</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">combinations</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">solve_quadratic</td>
<td style="text-align: center;">44</td>
</tr>
<tr>
<td style="text-align: center;">gcd</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">triangle_area</td>
<td style="text-align: center;">43</td>
</tr>
<tr>
<td style="text-align: center;">factorial</td>
<td style="text-align: center;">58</td>
<td style="text-align: center;">solve_quadratic</td>
<td style="text-align: center;">40</td>
</tr>
<tr>
<td style="text-align: center;">is_prime</td>
<td style="text-align: center;">52</td>
<td style="text-align: center;">circle_area</td>
<td style="text-align: center;">38</td>
</tr>
<tr>
<td style="text-align: center;">solve_linear_system</td>
<td style="text-align: center;">51</td>
<td style="text-align: center;">binomial_coefficient</td>
<td style="text-align: center;">37</td>
</tr>
</tbody>
</table>
<p>Table 7: Top-10 frequent functions in MATHFUNC</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Function name</th>
<th style="text-align: center;">Frequency</th>
<th style="text-align: center;">Function name</th>
<th style="text-align: center;">Frequency</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">mod_exp</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">repeating_decimal_to_fraction</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: center;">base_n_to_base_10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">dot_product</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: center;">degrees_to_radians</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">arrangements_with_repeats</td>
<td style="text-align: center;">11</td>
</tr>
<tr>
<td style="text-align: center;">is_splinitome</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">arithmetic_sequence_with_term</td>
<td style="text-align: center;">9</td>
</tr>
<tr>
<td style="text-align: center;">simplify_expression</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">sum_of_arithmetic_sequence</td>
<td style="text-align: center;">9</td>
</tr>
</tbody>
</table>
<p>Table 8: Ten representative functions in MATHFUNC
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Left: Histogram of FPQ (function per question). Higher values indicate greater composability. Right: Histogram of function occurrence. Higher values indicate more generalization and wider application.</p>
<h2>E. 2 SCIToolBENCH</h2>
<p>More Statistics We present additional statistics to illustrate the composability and generalization of the toolsets in SciToolBench. (1) Regarding composability, we count the FPQ (the number of positive functions used in solutions) for each question in the human-annotated subset, as shown in Figure 8 (left). The results indicate that more than $36 \%$ questions call more than one functions in their golden solutions, and each question requires an average of 1.51 functions. They demonstrate a high degree of composability on these functions. (2) For generalization, we provide the statistics about the functions' usage frequency among the whole question set in Figure 8 (right) ${ }^{13}$. We observe a clear bi-modal distribution pattern, which we attribute to the presence of negative functions. As explained in Appendix D.4, we include a number of negative functions, i.e., functions that are never used by any questions and are counted as 0 in the aforementioned figure, in our toolset to eliminate</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model (7B)</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">MAmmoTH-Coder</td>
<td style="text-align: center;">32.1</td>
</tr>
<tr>
<td style="text-align: left;">ToRA-Coder_wo. output shaping</td>
<td style="text-align: center;">40.2</td>
</tr>
<tr>
<td style="text-align: left;">ToRA-Coder</td>
<td style="text-align: center;">44.6</td>
</tr>
<tr>
<td style="text-align: left;">SCIAGENT-Coder</td>
<td style="text-align: center;">41.0</td>
</tr>
<tr>
<td style="text-align: left;">Model (13B)</td>
<td style="text-align: center;">Accuracy</td>
</tr>
<tr>
<td style="text-align: left;">MAmmoTH-Coder</td>
<td style="text-align: center;">36.3</td>
</tr>
<tr>
<td style="text-align: left;">ToRA-Coder_wo. output shaping</td>
<td style="text-align: center;">44.6</td>
</tr>
<tr>
<td style="text-align: left;">ToRA-Coder</td>
<td style="text-align: center;">48.1</td>
</tr>
<tr>
<td style="text-align: left;">SCIAGENT-Coder</td>
<td style="text-align: center;">45.2</td>
</tr>
</tbody>
</table>
<p>Table 9: Performance comparison on MATH test set.
the potential shortcuts. While these negative functions appear to reduce the average function occurrences, they enhance the overall generalization of our toolsets. When excluding these negative functions, the average function occurrences rise to 4.58 , with over $76 \%$ of positive functions being reused. These results validate the robust generalization of our toolsets in SciToolBench.</p>
<h1>F Discussion on In-domain Tool Using</h1>
<p>This work facilitates LLMs' scientific reasoning abilities with the aid of tools. Due to the scarce annotations across scientific domain, we construct our training corpus, i.e., MATHFUNC, from math domain. Here raises a natural question: whether our fine-tuned tool-augmented agents improve the in-domain performance?</p>
<p>To answer this question, we run experiments on MATH test set and show their results in Table 9. It demonstrates that our SCIAGENT-Coder surpasses MAmmoTH-Coder and achieves comparable performance with ToRA-Coder. However, we also do not observe significant benefit from tool augmentation on MATH test set. Though previous and concurrent work (Qian et al., 2023; Yuan et al., 2023a; Wang et al., 2024) have developed impressive tool-augmented approaches to enhance various kinds of reasoning tasks on models without additional fine-tuning, it is still an open question that whether tools benefit fine-tuned, in-domain models (especially when the tools are derived from the finetuned annotations). And our primary experiments here implicit that the answer might be No. We believe this question deserves deeper investigation as a future work.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: The screenshot of our annotation interface to evaluate functions' generalization.</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: The screenshot of our annotation interface to rewrite functions. We provide no alternative functions in this example for convenience of visualization.</p>
<p><img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Function before rewriting
def calculate_emptying_time(height, radius, side_length, g=0.06):
Calculates the time it takes for a cylindrical tank to go from full to empty.
Parameters:
- height (float): The height of the cylindrical tank.
- radius (float): The radius of the cylindrical tank.
- side_length (float): The length of the side of the square hole in the bottom of the tank.
- g (float): The acceleration due to gravity.
Returns:
- float: The time it takes for the tank to empty.
from math import al, sqrt</p>
<h1>calculate the area of the tank and the hole</h1>
<h1>for a general solution, we attempt to prove the second derivative is always</h1>
<p>$x$ value
return value
value balustrer("Maximum number of iterations reached without convergence.")</p>
<h1>Function before rewriting</h1>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_emptying_time</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">radius</span><span class="p">,</span> <span class="n">side_length</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="n">tank</span> <span class="n">to</span> <span class="n">go</span> <span class="kn">from</span><span class="w"> </span><span class="nn">full</span> <span class="n">to</span> <span class="n">empty</span><span class="o">.</span>
<span class="n">Parameters</span><span class="p">:</span>
    <span class="n">height</span> <span class="p">(</span><span class="nb">float</span><span class="p">):</span> <span class="n">The</span> <span class="n">height</span> <span class="n">of</span> <span class="n">the</span> <span class="n">cylindrical</span> <span class="n">tank</span><span class="o">.</span>
    <span class="n">radius</span> <span class="p">(</span><span class="nb">float</span><span class="p">):</span> <span class="n">The</span> <span class="n">radius</span> <span class="n">of</span> <span class="n">the</span> <span class="n">cylindrical</span> <span class="n">tank</span><span class="o">.</span>
    <span class="n">side_length</span> <span class="p">(</span><span class="nb">float</span><span class="p">):</span> <span class="n">The</span> <span class="n">length</span> <span class="n">of</span> <span class="n">the</span> <span class="n">side</span> <span class="n">of</span> <span class="n">the</span> <span class="n">square</span> <span class="n">hole</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">bottom</span> <span class="n">of</span> <span class="n">the</span> <span class="n">tank</span><span class="o">.</span>
    <span class="n">g</span> <span class="p">(</span><span class="nb">float</span><span class="p">):</span> <span class="n">The</span> <span class="n">acceleration</span> <span class="n">due</span> <span class="n">to</span> <span class="n">gravity</span><span class="o">.</span>
<span class="n">Returns</span><span class="p">:</span>
    <span class="nb">float</span><span class="p">:</span> <span class="n">The</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">the</span> <span class="n">tank</span> <span class="n">to</span> <span class="n">empty</span><span class="o">.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function before rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function before rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the second derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<h2>Function after rewriting</h2>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mean_time</span><span class="p">(</span><span class="n">times</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">gravity</span><span class="o">=</span><span class="mf">0.06</span><span class="p">):</span>
<span class="n">Calculates</span> <span class="n">the</span> <span class="n">time</span> <span class="n">it</span> <span class="n">takes</span> <span class="k">for</span> <span class="n">a</span> <span class="n">cylindrical</span> <span class="nb">object</span> <span class="n">to</span> <span class="n">drain</span> <span class="n">using</span>
<span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">the</span>
    <span class="k">for</span> <span class="n">the</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">al</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="c1"># calculate the area of the tank and the hole</span>
<span class="c1"># for a general solution, we attempt to prove the first derivative is always</span>
<span class="err">$</span><span class="n">x</span><span class="err">$</span> <span class="n">value</span>
<span class="k">return</span> <span class="n">value</span>
<span class="n">value</span> <span class="n">balustrer</span><span class="p">(</span><span class="s2">&quot;Maximum number of iterations reached without convergence.&quot;</span>
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{12}$ We assume the correctness of their called functions when we check the solutions.
${ }^{13}$ Although there are no golden function-augmented solutions for the synthesized subset, we estimate the function occurrences using the following approximation: The synthesized questions inherit the human-annotated functions from which they are derived. We argue that this approximation is reasonable because the synthesized questions share the same knowledge points as the original human-annotated questions. Additionally, the experimental results in Figure 2 clearly demonstrate that our SCIAGENT series successfully utilize functions to improve performance on the synthesized subsets, validating the applicability of these functions for the synthesized questions.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>