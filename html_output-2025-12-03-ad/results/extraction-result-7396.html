<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7396 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7396</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7396</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-277780165</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.09504v1.pdf" target="_blank">MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs</a></p>
                <p><strong>Paper Abstract:</strong> When applying pre-trained large language models (LLMs) to address anomaly detection tasks, the multivariate time series (MTS) modality of anomaly detection does not align with the text modality of LLMs. Existing methods simply transform the MTS data into multiple univariate time series sequences, which can cause many problems. This paper introduces MADLLM, a novel multivariate anomaly detection method via pre-trained LLMs. We design a new triple encoding technique to align the MTS modality with the text modality of LLMs. Specifically, this technique integrates the traditional patch embedding method with two novel embedding approaches: (i) Skip Embedding, which alters the order of patch processing in traditional methods to help LLMs retain knowledge of previous features, and (ii) Feature Embedding, which leverages contrastive learning to allow the model to better understand the correlations between different features. Experimental results demonstrate that our method outperforms state-of-the-art methods in various public anomaly detection datasets.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7396.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7396.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MADLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multivariate Anomaly Detection via Pre-trained LLMs (MADLLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that adapts pre-trained large language models to multivariate time-series anomaly detection by introducing a triple encoding (patch, skip, and feature embeddings) and fine-tuning lightweight parts of the LLM plus a contrastive encoder for feature correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>pre-trained LLM (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pre-trained transformer LLM body used as backbone; multi-head attention and feed-forward layers are frozen during fine-tuning while normalization layers are periodically fine-tuned; decoder/encoder specifics are not specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>fine-tuning of a pre-trained LLM with encoding adaptations (triple encoding: patch + skip + feature embeddings) and a contrastive learning encoder (exponentially causal convolutional network) trained with a patch-based triplet (InfoNCE) loss</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Supervised fine-tuning on public multivariate time-series datasets (training portions of SMD, PSM, SWaT, SMAP, MSL). Also evaluated in a limited-data setting using 20% of training data (few-shot / low-data regime experiment).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multivariate time-series (tabular time-indexed vectors / patches)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SMD, PSM, SWaT, SMAP, MSL</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>F1 score and AUC (ROC AUC)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Average over five datasets: F1 = 0.9371, AUC = 0.9736. Per-dataset (Table II) reported MADLLM results: SMD F1=0.9372 AUC=0.9872; PSM F1=0.9787 AUC=0.9852; SWaT F1=0.9138 AUC=0.9451; SMAP F1=0.9323 AUC=0.9668; MSL F1=0.9237 AUC=0.9838. With 20% training data (few-shot setting, Table III) MADLLM: SMD F1=0.9265 AUC=0.9782; PSM F1=0.9268 AUC=0.9381; SWaT F1=0.9098 AUC=0.9447; SMAP F1=0.9302 AUC=0.9663; MSL F1=0.9203 AUC=0.9547.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against MERLIN, OmniAnomaly, USAD, TimesNet, TranAD, ImDiffusion and LLM-based baselines (SFT, AnomalyLLM, LLMAD). MADLLM reports average improvements of +1.27% F1 and +2.55% AUC over the best-performing baseline averaged across datasets (Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fine-tuned (fully supervised) in main experiments; also evaluated in limited-data (few-shot-like) setting using 20% of training data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>On SMD MADLLM did not achieve the best F1 (ImDiffusion obtained higher F1 on SMD), attributed to small distributional bias between normal and anomalous samples in that dataset; ablation shows removing feature embedding reduces average F1 by 3.91% and removing skip embedding reduces average F1 by 4.63%; hyperparameter N (number of negative patches in triplet loss) must be tuned—too small reduces effectiveness, too large leads to overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported training time on SMD (Table IV) for MADLLM approximately 5.66 seconds (fine-tuning only normalization layers + contrastive encoder); training is slightly slower than SFT (which reported ~1.32s) but much faster than most non-LLM baselines. Inference cost/latency not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7396.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7396.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SFT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SFT (pre-trained LLM fine-tuning baseline referenced in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced baseline that inputs multivariate time-series into a pre-trained LLM and fine-tunes it for anomaly detection; cited in the paper as an LLM-based prior approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>pre-trained LLM (paper mentions GPT-2 in relation to prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Prior work fine-tunes a pre-trained LLM on time-series data; exact architecture/variant not specified within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>fine-tuning of a pre-trained LLM on time-series data (treated as concatenated/univariate sequences via patch embedding in prior art)</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Used as baseline on same multivariate datasets: SMD, PSM, SWaT, SMAP, MSL (trained on full training splits for main experiments and on 20% training data for limited-data experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multivariate time-series</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SMD, PSM, SWaT, SMAP, MSL</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>F1 score and AUC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Table II (full-data): SMD F1=0.8388 AUC=0.9012; PSM F1=0.9686 AUC=0.9724; SWaT F1=0.8887 AUC=0.9263; SMAP F1=0.6888 AUC=0.7743; MSL F1=0.8391 AUC=0.9133. Table III (20% data): SMD F1=0.8027 AUC=0.8596; PSM F1=0.9236 AUC=0.9317; SWaT F1=0.8850 AUC=0.9204; SMAP F1=0.6675 AUC=0.7538; MSL F1=0.7547 AUC=0.8687.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Included among baselines MERLIN, OmniAnomaly, USAD, TimesNet, TranAD, ImDiffusion, AnomalyLLM, LLMAD; MADLLM reports higher average F1/AUC than SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fine-tuning (supervised); also evaluated in limited-data (20% training) experiments as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>SFT is a lighter-weight finetuning baseline with very low training time but lower detection accuracy than MADLLM in most datasets; specific failure modes not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported training time on SMD (Table IV) ~1.32 seconds (very low because only limited parts of LLM are fine-tuned).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7396.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7396.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AnomalyLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AnomalyLLM (LLM distillation baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline method that distills a pre-trained LLM into a student network; anomalies are signaled when student network features differ substantially from the LLM's features during inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>pre-trained LLM (distilled into a student network; specific LLM unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Distillation-based approach: LLM distilled to a student network; detection via discrepancy between student and teacher representations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>distillation of LLM into a student network; anomaly detection via representation discrepancy (embedding similarity/distance based)</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Evaluated on the paper's five multivariate time-series datasets (SMD, PSM, SWaT, SMAP, MSL) as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multivariate time-series</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SMD, PSM, SWaT, SMAP, MSL</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>F1 score and AUC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Table II (full-data): SMD F1=0.9332 AUC=0.9568; PSM F1=0.9714 AUC=0.9728; SWaT F1=0.8875 AUC=0.9248; SMAP F1=0.9149 AUC=0.9237; MSL F1=0.9103 AUC=0.9211. Table III (20% data): SMD F1=0.9204 AUC=0.9433; PSM F1=0.9135 AUC=0.9224; SWaT F1=0.8735 AUC=0.9123; SMAP F1=0.9127 AUC=0.9112; MSL F1=0.9090 AUC=0.9041.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with classical and deep-learning baselines (MERLIN, OmniAnomaly, USAD, TimesNet, TranAD, ImDiffusion, SFT, LLMAD). Generally competitive with other LLM-based baselines; MADLLM outperforms it on average.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Trained (distillation + supervised training); also evaluated in limited-data (20% training) setting in the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No specific failure cases detailed in this paper beyond aggregate performance comparisons; training time larger than SFT but not quantified precisely here (Table IV shows AnomalyLLM training time substantially larger than SFT and MADLLM).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported training time on SMD (Table IV) ~160.38 seconds (higher than SFT and MADLLM).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7396.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7396.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMAD (LLM-based anomaly detection baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced LLM-based anomaly detection baseline included in comparisons; treats time-series as sequences to leverage LLM capabilities for detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>pre-trained LLM (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LLM-based anomaly detection approach; paper does not give model family or architecture details for this baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>LLM-based fine-tuning / embedding-similarity detection (specifics not given in this paper beyond being an LLM-based method)</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Evaluated on the same five datasets used throughout the paper (SMD, PSM, SWaT, SMAP, MSL) as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multivariate time-series</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>SMD, PSM, SWaT, SMAP, MSL</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>F1 score and AUC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Table II (full-data): SMD F1=0.9142 AUC=0.9535; PSM F1=0.9633 AUC=0.9689; SWaT F1=0.8815 AUC=0.9243; SMAP F1=0.9177 AUC=0.9238; MSL F1=0.9088 AUC=0.9226. Table III (20% data): SMD F1=0.9086 AUC=0.9488; PSM F1=0.9127 AUC=0.9215; SWaT F1=0.8744 AUC=0.9213; SMAP F1=0.9062 AUC=0.9154; MSL F1=0.9069 AUC=0.8937.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Included among LLM-based and non-LLM baselines; MADLLM shows improved average F1/AUC over LLMAD in the presented experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fine-tuning / supervised training (evaluated on both full-data and 20% training-data settings in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper does not provide per-method failure-mode analysis for LLMAD beyond the aggregate comparative results.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported training time on SMD (Table IV) ~86.45 seconds.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7396.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7396.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-2 (prior usage)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-2 as applied to time-series anomaly detection (prior work referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior referenced work (Zhou et al. [1] as discussed in this paper) inputs multivariate time-series (after conversion) to a pre-trained GPT-2 model and fine-tunes it for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer pre-trained on large text corpora; used in referenced prior work to be fine-tuned on time-series anomaly detection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>fine-tuning a pre-trained GPT-2 model after converting multivariate time-series into token sequences via patch embedding (prior-art approach noted as naive in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Prior work trained/fine-tuned on time-series datasets (not specified in detail in this paper); used as a motivating example for pre-trained LLM application to time-series.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multivariate time-series</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Not specified within this paper for the GPT-2 prior work (paper cites it as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Discussed as prior method that treats MTS as concatenated univariate sequences and thus suffers forgetting and correlation-neglect issues; compared conceptually against MADLLM's triple-encoding improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fine-tuning (prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Mentioned limitations: treating MTS as serial concatenation of univariate sequences ignores inter-feature correlations and leads to very long sequences where LLMs can forget early features (motivates skip embedding and feature embedding in MADLLM).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>One fits all: Power general time series analysis by pretrained lm. <em>(Rating: 2)</em></li>
                <li>Large language model guided knowledge distillation for time series anomaly detection. <em>(Rating: 2)</em></li>
                <li>Large language models can deliver accurate and interpretable time series anomaly detection. <em>(Rating: 2)</em></li>
                <li>Imputed diffusion models for multivariate time series anomaly detection. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7396",
    "paper_id": "paper-277780165",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "MADLLM",
            "name_full": "Multivariate Anomaly Detection via Pre-trained LLMs (MADLLM)",
            "brief_description": "A method that adapts pre-trained large language models to multivariate time-series anomaly detection by introducing a triple encoding (patch, skip, and feature embeddings) and fine-tuning lightweight parts of the LLM plus a contrastive encoder for feature correlations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "pre-trained LLM (unspecified)",
            "model_description": "Pre-trained transformer LLM body used as backbone; multi-head attention and feed-forward layers are frozen during fine-tuning while normalization layers are periodically fine-tuned; decoder/encoder specifics are not specified in the paper.",
            "model_size": null,
            "anomaly_detection_approach": "fine-tuning of a pre-trained LLM with encoding adaptations (triple encoding: patch + skip + feature embeddings) and a contrastive learning encoder (exponentially causal convolutional network) trained with a patch-based triplet (InfoNCE) loss",
            "prompt_template": null,
            "training_data": "Supervised fine-tuning on public multivariate time-series datasets (training portions of SMD, PSM, SWaT, SMAP, MSL). Also evaluated in a limited-data setting using 20% of training data (few-shot / low-data regime experiment).",
            "data_type": "multivariate time-series (tabular time-indexed vectors / patches)",
            "dataset_name": "SMD, PSM, SWaT, SMAP, MSL",
            "evaluation_metric": "F1 score and AUC (ROC AUC)",
            "performance": "Average over five datasets: F1 = 0.9371, AUC = 0.9736. Per-dataset (Table II) reported MADLLM results: SMD F1=0.9372 AUC=0.9872; PSM F1=0.9787 AUC=0.9852; SWaT F1=0.9138 AUC=0.9451; SMAP F1=0.9323 AUC=0.9668; MSL F1=0.9237 AUC=0.9838. With 20% training data (few-shot setting, Table III) MADLLM: SMD F1=0.9265 AUC=0.9782; PSM F1=0.9268 AUC=0.9381; SWaT F1=0.9098 AUC=0.9447; SMAP F1=0.9302 AUC=0.9663; MSL F1=0.9203 AUC=0.9547.",
            "baseline_comparison": "Compared against MERLIN, OmniAnomaly, USAD, TimesNet, TranAD, ImDiffusion and LLM-based baselines (SFT, AnomalyLLM, LLMAD). MADLLM reports average improvements of +1.27% F1 and +2.55% AUC over the best-performing baseline averaged across datasets (Table II).",
            "zero_shot_or_few_shot": "Fine-tuned (fully supervised) in main experiments; also evaluated in limited-data (few-shot-like) setting using 20% of training data.",
            "limitations_or_failure_cases": "On SMD MADLLM did not achieve the best F1 (ImDiffusion obtained higher F1 on SMD), attributed to small distributional bias between normal and anomalous samples in that dataset; ablation shows removing feature embedding reduces average F1 by 3.91% and removing skip embedding reduces average F1 by 4.63%; hyperparameter N (number of negative patches in triplet loss) must be tuned—too small reduces effectiveness, too large leads to overfitting.",
            "computational_cost": "Reported training time on SMD (Table IV) for MADLLM approximately 5.66 seconds (fine-tuning only normalization layers + contrastive encoder); training is slightly slower than SFT (which reported ~1.32s) but much faster than most non-LLM baselines. Inference cost/latency not detailed.",
            "uuid": "e7396.0",
            "source_info": {
                "paper_title": "MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SFT",
            "name_full": "SFT (pre-trained LLM fine-tuning baseline referenced in paper)",
            "brief_description": "A referenced baseline that inputs multivariate time-series into a pre-trained LLM and fine-tunes it for anomaly detection; cited in the paper as an LLM-based prior approach.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "pre-trained LLM (paper mentions GPT-2 in relation to prior work)",
            "model_description": "Prior work fine-tunes a pre-trained LLM on time-series data; exact architecture/variant not specified within this paper.",
            "model_size": null,
            "anomaly_detection_approach": "fine-tuning of a pre-trained LLM on time-series data (treated as concatenated/univariate sequences via patch embedding in prior art)",
            "prompt_template": null,
            "training_data": "Used as baseline on same multivariate datasets: SMD, PSM, SWaT, SMAP, MSL (trained on full training splits for main experiments and on 20% training data for limited-data experiments).",
            "data_type": "multivariate time-series",
            "dataset_name": "SMD, PSM, SWaT, SMAP, MSL",
            "evaluation_metric": "F1 score and AUC",
            "performance": "Table II (full-data): SMD F1=0.8388 AUC=0.9012; PSM F1=0.9686 AUC=0.9724; SWaT F1=0.8887 AUC=0.9263; SMAP F1=0.6888 AUC=0.7743; MSL F1=0.8391 AUC=0.9133. Table III (20% data): SMD F1=0.8027 AUC=0.8596; PSM F1=0.9236 AUC=0.9317; SWaT F1=0.8850 AUC=0.9204; SMAP F1=0.6675 AUC=0.7538; MSL F1=0.7547 AUC=0.8687.",
            "baseline_comparison": "Included among baselines MERLIN, OmniAnomaly, USAD, TimesNet, TranAD, ImDiffusion, AnomalyLLM, LLMAD; MADLLM reports higher average F1/AUC than SFT.",
            "zero_shot_or_few_shot": "Fine-tuning (supervised); also evaluated in limited-data (20% training) experiments as a baseline.",
            "limitations_or_failure_cases": "SFT is a lighter-weight finetuning baseline with very low training time but lower detection accuracy than MADLLM in most datasets; specific failure modes not detailed in this paper.",
            "computational_cost": "Reported training time on SMD (Table IV) ~1.32 seconds (very low because only limited parts of LLM are fine-tuned).",
            "uuid": "e7396.1",
            "source_info": {
                "paper_title": "MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "AnomalyLLM",
            "name_full": "AnomalyLLM (LLM distillation baseline)",
            "brief_description": "A baseline method that distills a pre-trained LLM into a student network; anomalies are signaled when student network features differ substantially from the LLM's features during inference.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "pre-trained LLM (distilled into a student network; specific LLM unspecified)",
            "model_description": "Distillation-based approach: LLM distilled to a student network; detection via discrepancy between student and teacher representations.",
            "model_size": null,
            "anomaly_detection_approach": "distillation of LLM into a student network; anomaly detection via representation discrepancy (embedding similarity/distance based)",
            "prompt_template": null,
            "training_data": "Evaluated on the paper's five multivariate time-series datasets (SMD, PSM, SWaT, SMAP, MSL) as a baseline.",
            "data_type": "multivariate time-series",
            "dataset_name": "SMD, PSM, SWaT, SMAP, MSL",
            "evaluation_metric": "F1 score and AUC",
            "performance": "Table II (full-data): SMD F1=0.9332 AUC=0.9568; PSM F1=0.9714 AUC=0.9728; SWaT F1=0.8875 AUC=0.9248; SMAP F1=0.9149 AUC=0.9237; MSL F1=0.9103 AUC=0.9211. Table III (20% data): SMD F1=0.9204 AUC=0.9433; PSM F1=0.9135 AUC=0.9224; SWaT F1=0.8735 AUC=0.9123; SMAP F1=0.9127 AUC=0.9112; MSL F1=0.9090 AUC=0.9041.",
            "baseline_comparison": "Compared with classical and deep-learning baselines (MERLIN, OmniAnomaly, USAD, TimesNet, TranAD, ImDiffusion, SFT, LLMAD). Generally competitive with other LLM-based baselines; MADLLM outperforms it on average.",
            "zero_shot_or_few_shot": "Trained (distillation + supervised training); also evaluated in limited-data (20% training) setting in the paper's experiments.",
            "limitations_or_failure_cases": "No specific failure cases detailed in this paper beyond aggregate performance comparisons; training time larger than SFT but not quantified precisely here (Table IV shows AnomalyLLM training time substantially larger than SFT and MADLLM).",
            "computational_cost": "Reported training time on SMD (Table IV) ~160.38 seconds (higher than SFT and MADLLM).",
            "uuid": "e7396.2",
            "source_info": {
                "paper_title": "MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "LLMAD",
            "name_full": "LLMAD (LLM-based anomaly detection baseline)",
            "brief_description": "A referenced LLM-based anomaly detection baseline included in comparisons; treats time-series as sequences to leverage LLM capabilities for detection.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "pre-trained LLM (unspecified)",
            "model_description": "LLM-based anomaly detection approach; paper does not give model family or architecture details for this baseline.",
            "model_size": null,
            "anomaly_detection_approach": "LLM-based fine-tuning / embedding-similarity detection (specifics not given in this paper beyond being an LLM-based method)",
            "prompt_template": null,
            "training_data": "Evaluated on the same five datasets used throughout the paper (SMD, PSM, SWaT, SMAP, MSL) as a baseline.",
            "data_type": "multivariate time-series",
            "dataset_name": "SMD, PSM, SWaT, SMAP, MSL",
            "evaluation_metric": "F1 score and AUC",
            "performance": "Table II (full-data): SMD F1=0.9142 AUC=0.9535; PSM F1=0.9633 AUC=0.9689; SWaT F1=0.8815 AUC=0.9243; SMAP F1=0.9177 AUC=0.9238; MSL F1=0.9088 AUC=0.9226. Table III (20% data): SMD F1=0.9086 AUC=0.9488; PSM F1=0.9127 AUC=0.9215; SWaT F1=0.8744 AUC=0.9213; SMAP F1=0.9062 AUC=0.9154; MSL F1=0.9069 AUC=0.8937.",
            "baseline_comparison": "Included among LLM-based and non-LLM baselines; MADLLM shows improved average F1/AUC over LLMAD in the presented experiments.",
            "zero_shot_or_few_shot": "Fine-tuning / supervised training (evaluated on both full-data and 20% training-data settings in the paper).",
            "limitations_or_failure_cases": "Paper does not provide per-method failure-mode analysis for LLMAD beyond the aggregate comparative results.",
            "computational_cost": "Reported training time on SMD (Table IV) ~86.45 seconds.",
            "uuid": "e7396.3",
            "source_info": {
                "paper_title": "MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "GPT-2 (prior usage)",
            "name_full": "GPT-2 as applied to time-series anomaly detection (prior work referenced)",
            "brief_description": "Prior referenced work (Zhou et al. [1] as discussed in this paper) inputs multivariate time-series (after conversion) to a pre-trained GPT-2 model and fine-tunes it for anomaly detection.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-2",
            "model_description": "Decoder-only transformer pre-trained on large text corpora; used in referenced prior work to be fine-tuned on time-series anomaly detection tasks.",
            "model_size": null,
            "anomaly_detection_approach": "fine-tuning a pre-trained GPT-2 model after converting multivariate time-series into token sequences via patch embedding (prior-art approach noted as naive in this paper)",
            "prompt_template": null,
            "training_data": "Prior work trained/fine-tuned on time-series datasets (not specified in detail in this paper); used as a motivating example for pre-trained LLM application to time-series.",
            "data_type": "multivariate time-series",
            "dataset_name": null,
            "evaluation_metric": "Not specified within this paper for the GPT-2 prior work (paper cites it as related work).",
            "performance": null,
            "baseline_comparison": "Discussed as prior method that treats MTS as concatenated univariate sequences and thus suffers forgetting and correlation-neglect issues; compared conceptually against MADLLM's triple-encoding improvements.",
            "zero_shot_or_few_shot": "Fine-tuning (prior work).",
            "limitations_or_failure_cases": "Mentioned limitations: treating MTS as serial concatenation of univariate sequences ignores inter-feature correlations and leads to very long sequences where LLMs can forget early features (motivates skip embedding and feature embedding in MADLLM).",
            "computational_cost": null,
            "uuid": "e7396.4",
            "source_info": {
                "paper_title": "MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "One fits all: Power general time series analysis by pretrained lm.",
            "rating": 2,
            "sanitized_title": "one_fits_all_power_general_time_series_analysis_by_pretrained_lm"
        },
        {
            "paper_title": "Large language model guided knowledge distillation for time series anomaly detection.",
            "rating": 2,
            "sanitized_title": "large_language_model_guided_knowledge_distillation_for_time_series_anomaly_detection"
        },
        {
            "paper_title": "Large language models can deliver accurate and interpretable time series anomaly detection.",
            "rating": 2,
            "sanitized_title": "large_language_models_can_deliver_accurate_and_interpretable_time_series_anomaly_detection"
        },
        {
            "paper_title": "Imputed diffusion models for multivariate time series anomaly detection.",
            "rating": 1,
            "sanitized_title": "imputed_diffusion_models_for_multivariate_time_series_anomaly_detection"
        }
    ],
    "cost": 0.01405325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs
13 Apr 2025</p>
<p>Wei Tao ♠♡ 
Huazhong University of Science and Technology
WuhanChina</p>
<p>Ping An Technology (Shenzhen) Co., Ltd
ShenzhenChina</p>
<p>Xiaoyang Qu 
Ping An Technology (Shenzhen) Co., Ltd
ShenzhenChina</p>
<p>Xiaoyang Qu</p>
<p>Kai Lu kailu@hust.edu.cn 
Huazhong University of Science and Technology
WuhanChina</p>
<p>Xiaoyang Qu</p>
<p>Wan ♠ Jiguang 
Huazhong University of Science and Technology
WuhanChina</p>
<p>Guokuan Li 
Huazhong University of Science and Technology
WuhanChina</p>
<p>Jianzong Wang 
Ping An Technology (Shenzhen) Co., Ltd
ShenzhenChina</p>
<p>MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs
13 Apr 2025E57E7AAA2ACA47A19765473F40FB8046arXiv:2504.09504v1[cs.CL]multivariate time seriesanomaly detectionLLMskip embeddingfeature embedding
When applying pre-trained large language models (LLMs) to address anomaly detection tasks, the multivariate time series (MTS) modality of anomaly detection does not align with the text modality of LLMs.Existing methods simply transform the MTS data into multiple univariate time series sequences, which can cause many problems.This paper introduces MADLLM, a novel multivariate anomaly detection method via pre-trained LLMs.We design a new triple encoding technique to align the MTS modality with the text modality of LLMs.Specifically, this technique integrates the traditional patch embedding method with two novel embedding approaches: (i) Skip Embedding, which alters the order of patch processing in traditional methods to help LLMs retain knowledge of previous features, and (ii) Feature Embedding, which leverages contrastive learning to allow the model to better understand the correlations between different features.Experimental results demonstrate that our method outperforms state-of-the-art methods in various public anomaly detection datasets.</p>
<p>I. INTRODUCTION</p>
<p>Anomaly detection is widely used across a range of fields, including finance.Previous scholars have relied on classic machine learning methods, deep neural network architectures, and attention-based models to handle anomaly detection tasks, yielding remarkable breakthroughs.However, due to concerns about business secrets, enterprises are often unwilling to disclose their anomaly data.This causes a severe shortage of labeled anomaly data, which poses a significant challenge for anomaly detection tasks.In this case, traditional models usually face unknown pattern anomalies and require a complex redesign and lengthy retraining.Recently, some researchers have proposed to leverage pre-trained large language models (LLMs) to detect time series anomalies, using their inherent abstraction and generalization capabilities [1], [2].The unified framework and strong generalization capabilities provided by the pre-trained LLMs effectively solve the problem of the lack of labeled data prevalent in anomaly detection tasks.</p>
<p>The problem of anomaly detection via pre-trained LLMs lies in the encoding method of the input data.The original input modality of LLMs is discrete text, while the input modality of the anomaly detection task is continuous multivariate time series (MTS) data.The two modalities cannot be aligned, which can reduce the accuracy of the model.To solve this problem, researchers have proposed a patch embedding method Fig. 1: An example of anomalies in the SMD dataset.The four features are marked as Feature1-4 due to dataset privacy.</p>
<p>to encode the MTS data [1].The current patch embedding method treats the multivariate time series data as multiple univariate time series sequences, concatenates them serially, and inputs them into the pre-trained LLMs.However, this approach has two challenges.First, it ignores the correlations among different features (we call each variate in the MTS data a feature), which can lead to misjudgment.Anomalies are often accompanied by problems with multiple features, and anomaly detection requires combining the observations of multiple features to make judgments.For example, we extract a segmentation from a famous MTS dataset SMD [3] and illustrate it in Figure 1.In the time period marked as Normal A, Feature1-3 all have a spike, which can be mistakenly classified as an anomaly if we do not pay attention to Feature4.A similar situation happens to Normal B, where only Feature2 has a spike.We need to consider all the features to detect a true anomaly, such as Anomaly A and Anomaly B. Second, the input sequence becomes very long after the serial concatenation of multiple feature sequences.Therefore, when the model processes the feature data at the end of the input sequence, it may forget the feature information at the beginning of the input sequence.</p>
<p>To address the challenges described above, in this paper, we propose a new method for multivariate anomaly detection problems based on pre-trained LLMs, i.e., MADLLM.We design a new triple encoding technique to encode the MTS input data, which can help the LLMs better maintain the memory of distant historical feature information and understand the correlations among various features.Specifically, the triple encoding technique incorporates the patch embedding method in previous works with two novel embedding approaches: skip embedding and feature embedding.Skip embedding is achieved by rearranging the patch processing order in traditional patch embedding.We skip to patches of other features every time after processing the patch of one feature so that the model does not forget information about other features just because they are too far away on the input sequence.Feature embedding is achieved by a contrastive learning encoder.We use a causal convolutional network as the network backbone and define a patch-based triplet loss to update the encoder.</p>
<p>The contributions of our work are summarized as follows:</p>
<p>• We design a new triple encoding technique for more accurate anomaly detection with MTS data.</p>
<p>II. RELATED WORKS A. Anomaly Detection via Traditional Models</p>
<p>Anomaly detection has always been a widespread problem in both industrial and research areas.Traditional models for anomaly detection can be summarized as three kinds.First, some researchers propose to use traditional machine learning methods to tackle anomaly detection.MERLIN [4] employs a parameter-free approach to detect time series anomaly by iteratively comparing subsequences of different lengths with their adjacent neighbors.Second, some researchers address anomaly detection problems via deep neural networks [3], [5]- [7], including convolutional neural networks (CNN), recurrent neural networks (RNN) and long-short term memory (LSTM).For example, OmniAnomaly [5] reconstructs input data by the representations of the normal pattern of MTS and uses the reconstruction probabilities to determine anomalies.Third, models based on transformer modules or attention mechanisms have emerged recently [8]- [10].For instance, Tuli et al. [10] propose TranAD, a deep transformer network-based anomaly detection and diagnosis model that uses attentionbased sequence encoders to swiftly perform inference with the knowledge of the broader temporal trends in the data.However, these models require complex redesign and lengthy retraining periods when facing unprecedented anomaly types.In this paper, we propose to use pre-trained LLMs to address anomaly detection problems.With the strong generalization capabilities of the pre-trained LLMs, we only need to finetune the model in the case of novel anomaly patterns.</p>
<p>B. LLMs for Time Series Data Tasks</p>
<p>Recent years have witnessed the emergence of a series of LLMs [11].Therefore, researchers have proposed to apply LLMs to the field of anomaly detection [1], [12]- [14].For instance, Zhou et al. [1] propose to input the MTS data into a pre-trained GPT2 model and fine-tune the model to achieve anomaly detection results.AnomalyLLM [13] distills the LLM into a student network.During inference, when the features of the student network are greatly different from those of the LLM, anomalies are indicated.LLMAD [14] leverages positive and negative similar time series segments and an Anomaly Detection Chain-of-Thought approach to accurately predict anomalies.However, these methods treat MTS as multiple univariate series, which makes the model forget distant history feature information and neglect the correlations among features.This paper proposes two optimizations (skip embedding and feature embedding) to avoid these problems.</p>
<p>III. PROPOSED METHOD</p>
<p>In this section, we first introduce the overall architecture of MADLLM.Then, we describe the two important optimizations in MADLLM: skip embedding and feature embedding.</p>
<p>A. Architecture</p>
<p>Figure 2 shows the architecture of our MADLLM method.The MTS data is first segmented into a token series according to the temporal order, where the data of each feature is divided into equal-sized patches.Then, we use triple encoding to encode the token series into three embeddings, including traditional patch embedding, skip embedding, and feature embedding.We integrate the three embeddings to form the final input of the pre-trained LLM, which is called token embedding.During the inference process of MADLLM, we freeze the multi-head attention and feed forward layers in the pre-trained LLM body while periodically fine-tuning the normalization layers and the feature embedding module.This is because the multi-head attention and feed forward layers contain the majority of learned knowledge from pre-trained LLMs.Freezing them can not only maintain the representation ability of the model but also save lots of fine-tuning time.described above, the main order of traditional patch embedding is from feature to feature.It converts the sequence of patches within each feature into embeddings, and after the conversion of data within one feature is completed, it proceeds to the following feature for conversion.In contrast, the main order of our skip embedding approach is from time period to time period.After converting a patch within a specific feature into an embedding, we "skip" to the next feature within the same time period to continue conversion.For example, first, the model selects a patch from the series of the first feature, then it skips to the series of the second feature and selects a patch in the same time period, then the third feature.This is why our method is called skip embedding.After processing patches of all the features in this time period, it turns to the following time period and continues the loop.</p>
<p>B. Skip Embedding</p>
<p>During inference, to reduce the latency in the "skip" process, we reorder the patches in the original token series to ensure that the patches in the same time period are contiguous in physical memory.Suppose that the original token series is:
S = {s 1 1 , s 1 2 , • • • , s 1 P , s 2 1 , • • • , s 2 P , • • • , s M P }(1)
where s j i is the i th patch in the j th feature, P and M are the number of patches and features, respectively.Then, the new token series is as follows:
E = {s 1 1 , s 2 1 , • • • , s M 1 , s 1 2 , • • • , s M 2 , • • • , s M P }(2)
After reordering the patches in the token series, we convert the new token series E with the same embedding function as how patch embedding is achieved, and we finally get the skip embedding.Patch embedding captures the information of a single feature over different time periods, while skip embedding captures the information of different features at a single time period.Skip embedding helps prevent the model from forgetting information from features that are in the distant past, while patch embedding compensates for the difficulty of skip embedding in capturing cross-time period information.These two types of embeddings are complementary.Therefore, we combine them to achieve better anomaly detection results.</p>
<p>C. Feature Embedding</p>
<p>Since contrastive learning does not rely on prior knowledge, it will not be influenced by the lack of labeled anomaly Denote the number of patches in a feature as P 3:</p>
<p>Randomly choose s i p as the s anc , 1 ≤ p ≤ P 4:</p>
<p>Randomly choose another s i q as the s + , 1 ≤ q ≤ P , p ̸ = q, 5:</p>
<p>Randomly choose N number from [1, M ], i j ̸ = i, j = 0, 1, ..., N 6:</p>
<p>for j = 1 to N do Calculate triplet loss L i by equation 7 10: end for 11: L ← Concatenate all the L i 12: return L data [12].Therefore, we employ contrastive learning to learn the correlations among different features and achieve a new embedding called feature embedding.We introduce an additional deep learning network called contrastive learning encoder (independent from the pre-trained LLM) to generate the feature embedding.The encoder is randomly initialized and will be updated at the fine-tuning stage of MADLLM.</p>
<p>To learn the correlations among different features, we need to make the representations of the data from similar features closer while increasing the distance among the representations of data from dissimilar features.Inspired by the idea of [15], we propose a patch-based triplet loss to update our contrastive learning encoder.We denote patches from the same feature as similar, while patches from random different features are denoted as dissimilar.</p>
<p>Algorithm 1 demonstrates how we calculate the patchbased triplet loss in contrastive learning.For each feature, we randomly sample a patch from the feature and denote it as the anchor patch, named s anc .Then, we randomly choose another patch from the same feature as the positive patch, named s + .Furthermore, we randomly sample N features (N is a pre-defined hyperparameter) from the rest of the features and randomly select one patch from each feature as a negative patch, named {s − j } N j=1 .Given the effectiveness and efficiency of InfoNCE [16] in minimizing the difference among positive pairs and maximizing the difference among negative pairs in the embedding space, we adopt the InfoNCE algorithm to calculate our triplet loss.The patch-based triplet loss for one feature is calculated as follows:
L = −log exp(f (s anc , s + )) exp(f (s anc , s + )) + N j=1 exp(f (s anc , s − j ))(3)
where f () is the cosine similar function.Specifically, f () is:
f (u, v) = u T v ||u|| 2 • ||v|| 2(4)
Fig. 4: The workflow of feature embedding.where ||u|| 2 means the L2 norm of vector u.We travel through all the features, find such (s anc , s + , s − ) triple tuple, and calculate patch-based triplet loss for each feature.Finally, we concatenate the patch-based triplet loss of all the features to form the patch-based triplet loss of the whole token series, which will be used to update our contrastive learning encoder.</p>
<p>After we achieve the patch-based triplet loss of the whole token series, we need to determine a network backbone to execute the contrastive learning task and achieve the feature embedding.Exponentially causal convolutional networks [17] are neural network architectures that combine causal convolutions and exponential decay mechanisms.They avoid the vanishing and exploding gradient problems associated with RNNs while ensuring the causality of time series data, a property that ordinary CNNs lack.This makes them particularly wellsuited for handling time series data.Therefore, we choose the exponentially causal convolution network as our contrastive learning encoder backbone.</p>
<p>Figure 4 demonstrates the workflow of feature embedding.During the fine-tuning stage of MADLLM, we use the token series as the input and the patch-based triplet loss as the loss to update the contrastive learning encoder.The fine-tuning of the contrastive learning encoder is independent of the finetuning of the LLM body.Since the network of the contrastive learning encoder does not have too many layers, the finetuning process is lightweight.During the inference stage, we input the token series into the updated contrastive learning encoder and achieve the feature embedding.</p>
<p>IV. EXPERIMENTS</p>
<p>In this section, we conduct a comprehensive evaluation of MADLLM.</p>
<p>A. Experimental Setup</p>
<p>Datasets.We compare our method with the baseline methods on five widely used public time-series anomaly detection datasets, all of which are multivariate.The datasets are: (1) SMD [3], which is collected from 28 different machines from a large Internet company.( 2) PSM [18], which is collected internally from multiple application server nodes at eBay.(3) SWaT [19], which is collected from a real-world water treatment plant.( 4) SMAP [20], which is a dataset of soil samples and telemetry information labeled by the SMAP satellite of NASA.( 5) MSL [20], which is similar to SMAP, but it is labeled by the MSL rover of NASA.To ensure the fairness of the experiments, we test the models on all the subsets of these datasets rather than only on some non-trivial subsets [10], so the results of some baseline methods may be different from the statistics in their paper.The details of the datasets are shown in Table I.Baselines.We compare our method with several current state-of-the-art anomaly detection solutions that use different models, including classic machine learning methods (MERLIN [4]), traditional deep neural networks (OmniAnomaly [3], USAD [6], TimesNet [7]), attention mechanism-based models ( TranAD [10], ImDifussion [9]), and methods based on pretrained LLMs (SFT [1], AnomalyLLM [13], LLMAD [14]).</p>
<p>Evaluation Metrics.Anomaly detection is a binary classification task, and we need to judge if the time period is normal or anomalous.Therefore, we use F1 score and AUC as the evaluation metrics.</p>
<p>B. Evaluation Results</p>
<p>We compare MADLLM with the baseline models on all the five datasets discussed above.As is illustrated in Table II, the average F1 score and AUC of our MADLLM model are 0.9371 and 0.9736, respectively.Our MADLLM model outperforms all the baseline methods over all five datasets except SMD on the F1 score evaluation metric.This might be because the distribution bias between normal and anomalous data in this dataset is relatively small, and ImDiffusion's unconditional attribution algorithm is able to amplify the attribution error gap between normal and anomalous data, making it particularly suitable for this dataset.As for AUC results, MADLLM outperforms all the baseline methods on all five datasets.MADLLM can improve the F1 score by 1.27% and improve the AUC result by 2.55% on average compared with the best performance of the baseline models over the five datasets.</p>
<p>Since models usually have to face unknown pattern anomalies, we also test the few-shot learning (learning with limited training data) ability of MADLLM.Specifically, for the five MTS datasets above, we use 20% of the training datasets to train the models.The validation and test datasets stay the same.The results are shown in Table III.Table III illustrates that on each dataset, MADLLM achieves the best F1 score and AUC results.MADLLM has an F1 score 1.26% higher and AUC 2.65% higher on average than the best performance of the baseline models over all the datasets with 20% training data.The results prove the ability of MADLLM to face unknown pattern anomalies.Compared to Table II, the LLM-based methods (SFT, AnomalyLLM, LLMAD, and MADLLM) exhibit smaller decreases in F1 score and AUC compared with other methods.This is because LLM has strong generalization capabilities and can achieve good performance even with limited training data.</p>
<p>We also compare the training time of MADLLM with baseline methods.The experiment is conducted on the SMD dataset.As is shown in Table IV, compared with all the methods other than SFT, the training time of MADLLM is</p>
<p>C. Ablation Study</p>
<p>We further measure the impact of skip embedding and feature embedding in MADLLM, respectively.As is shown in Figure 5, removing feature embedding leads to an average decrease of 3.91% in F1 score and 3.87% in AUC, removing skip embedding leads to an average decrease of 4.63% in F1 score and 4.90% in AUC.These results prove the effect of the two optimizations.</p>
<p>D. Analysis</p>
<p>We test the F1 score and AUC of MADLLM under different numbers of negative patches selected in the feature embedding triplet loss, i.e., the hyperparameter N in Section III-C.The results are shown in Figure 6.When N is small, the F1 scores and AUC results are also quite low.This is because the number of negative patches is too small, and feature embedding cannot entirely exert its effect.As N increases, both the F1 score and AUC gradually increase as well.However, when N is too large, the F1 score and AUC results of MADLLM decrease due to overfitting.</p>
<p>To make a more concrete evaluation of MADLLM, we provide a case study on how MADLLM detects anomaly periods for given real-world MTS datasets.This case study is conducted using a segmentation of the SMD dataset, similar to the experiment in Figure 1.As is shown in Figure 7, MADLLM can accurately detect the true anomaly (Anomaly A).Note that in Normal A and Normal B, Feature1, 3, and 4 all show an obvious spike, but Feature2 does not.Such a situation is because of a periodically coming task, but these two time periods can easily be misidentified as anomalous.Our MADLLM can effectively prevent such misjudgments.</p>
<p>V. CONCLUSION</p>
<p>In this paper, we introduce MADLLM, a novel multivariate anomaly detection method based on pre-trained LLMs.We implement two key optimizations: (i) Skip Embedding: we rearrange the patch processing order in traditional patch embedding method to avoid the pre-trained LLMs forgetting the information of features input in the distant past.(ii) Feature Embedding: We employ a contrastive learning encoder to learn the correlations among different features, where we design a triplet loss to update the encoder.Experimental results demonstrate that our method outperforms state-of-theart anomaly detection methods in various public datasets.</p>
<p>Fig. 2 :
2
Fig. 2: The architecture of MADLLM.</p>
<p>Figure 3
3
Figure3illustrates a demonstration workflow of traditional patch embedding and skip embedding.For the token series</p>
<p>Fig. 3 :
3
Fig. 3: The workflow of skip embedding and traditional patch embedding.</p>
<p>Algorithm 1
1
The calculation of our patch-based triplet loss in contrastive learning in a fine-tuning epoch.Require: Token series S, Number of features M Ensure: Patch-based triplet loss of the contrastive learning L 1: for i = 1 to M do 2:</p>
<p>F 1 SFig. 5 :
15
Fig. 5: Ablation study results on different datasets.</p>
<p>Fig. 6 :
6
Fig. 6: (a) The impact of hyperparameter N on F1 score.(b) The impact of hyperparameter N on AUC.</p>
<p>We propose feature embedding to capture the correlations among different features.•Extensive experiments conducted on several public datasets illustrate that our method outperforms state-ofthe-art anomaly detection methods.</p>
<p>• We propose skip embedding to prevent LLMs from forgetting features from distant past inputs.•</p>
<p>TABLE I :
I
Information of Evaluation Datasets.
DatasetTrainTestFeatures Anomalies (%)SMD [3]708405 708420384.16PSM [18]13248187841251.0SWaT [19]496800 4499195111.98SMAP [20] 153183 4276172513.13MSL [20]58317737295510.72</p>
<p>TABLE II :
II
The performance comparison of different anomaly detection methods on different datasets.
MethodSMDPSMSWaTSMAPMSLF1 ↑AUC ↑F1 ↑AUC ↑F1 ↑AUC ↑F1 ↑AUC ↑F1 ↑AUC ↑MERLIN [4]0.38420.71580.47020.72450.36690.61750.27240.74260.33450.6281OmniAnomaly [3]0.88990.94010.91920.90450.80610.84670.89960.90510.82220.8875USAD [6]0.89910.94950.91460.94770.77890.84600.77030.87520.85090.9057TimesNet [7]0.85870.90320.96020.94550.88240.89730.71520.84350.85170.8246TranAD [10]0.89440.93620.92200.94570.71430.84910.83610.89250.91210.9344ImDifussion [9]0.94880.93460.97820.96840.87190.92330.91750.92480.87820.9091SFT [1]0.83880.90120.96860.97240.88870.92630.68880.77430.83910.9133AnomalyLLM [13]0.93320.95680.97140.97280.88750.92480.91490.92370.91030.9211LLMAD [14]0.91420.95350.96330.96890.88150.92430.91770.92380.90880.9226MADLLM0.93720.98720.97870.98520.91380.94510.93230.96680.92370.9838</p>
<p>TABLE III :
III
The performance comparison of different anomaly detection methods using 20% training data.
MethodSMDPSMSWaTSMAPMSLF1 ↑AUC ↑F1 ↑AUC ↑F1 ↑AUC ↑F1 ↑AUC ↑F1 ↑AUC ↑MERLIN [4]0.32020.63580.40910.62860.30190.52840.23460.69890.26750.5542OmniAnomaly [3]0.80640.70240.86480.85580.74330.76190.81310.80790.74090.7863USAD [6]0.82340.80560.86640.82570.70870.79380.73280.72450.51980.8413TimesNet [7]0.66250.81340.57180.86490.41450.66900.54180.70070.57180.7812TranAD [10]0.84070.88940.86030.85660.65940.77380.77280.78780.83800.8652Imdifussion [9]0.78160.80490.79180.80310.80010.84210.83690.75630.60180.5728SFT [1]0.80270.85960.92360.93170.88500.92040.66750.75380.75470.8687AnomalyLLM [13]0.92040.94330.91350.92240.87350.91230.91270.91120.90900.9041LLMAD [14]0.90860.94880.91270.92150.87440.92130.90620.91540.90690.8937MADLLM0.92650.97820.92680.93810.90980.94470.93020.96630.92030.9547</p>
<p>TABLE IV :
IV
The training time comparison of different anomaly detection methods on SMD dataset.
MethodsMERLIN OmniAnomalyUSADTimesNet TranAD ImDifussionSFTAnomalyLLM LLMADMADLLMTraining Time (s) ↓72.32276.97250.97346.8643.56303.491.32160.3886.451.8995.66%-99.46% lower. The reason why SFT and MALLMcan achieve such low training time is that they only requirefine-tuning of certain parts of the pre-trained LLM. SinceMADLLM also involves fine-tuning the contrastive learningencoder, its training time is slightly higher than SFT. However,Table II shows that MADLLM increases SFT by 9.2% in F1score and 7.8% in AUC on average over all the datasets. There-fore, compared with SFT, MADLLM achieves a significantimprovement in accuracy at the cost of a minimal increasein training time.
VI. ACKNOWLEDGEMENTSThis work was sponsored by the Key Research and Development Program of Guangdong Province under grant No. 2021B0101400003, the National Key Research and Development Program of China under Grant No.2023YFB4502701, the China Postdoctoral Science Foundation under Grant No.2024M751011, the Postdoctor Project of Hubei Province under Grant No.2004HBBHCXA027.
One fits all: Power general time series analysis by pretrained lm. Tian Zhou, Peisong Niu, Liang Sun, Rong Jin, Advances in Neural Information Processing Systems. 202336</p>
<p>Incprompt: Task-aware incremental prompting for rehearsal-free class-incremental learning. Zhiyuan Wang, Xiaoyang Qu, Jing Xiao, Bokui Chen, Jianzong Wang, ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing. ICASSP</p>
<p>Robust anomaly detection for multivariate time series through stochastic recurrent neural network. Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, Dan Pei, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining2019</p>
<p>Merlin: Parameter-free discovery of arbitrary length anomalies in massive time series archives. Takaaki Nakamura, Makoto Imamura, Ryan Mercer, Eamonn Keogh, 2020 IEEE international conference on data mining (ICDM). IEEE2020</p>
<p>Deep autoencoding gaussian mixture model for unsupervised anomaly detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, International Conference on Learning Representations. 2018</p>
<p>Usad: Unsupervised anomaly detection on multivariate time series. Julien Audibert, Pietro Michiardi, Frédéric Guyard, Sébastien Marti, Maria A Zuluaga, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining2020</p>
<p>Timesnet: Temporal 2d-variation modeling for general time series analysis. Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, Mingsheng Long, The Eleventh International Conference on Learning Representations. Fig. 7: Case study of MADLLM on the SMD dataset. </p>
<p>opengauss: An autonomous database system. Guoliang Li, Xuanhe Zhou, Ji Sun, Xiang Yu, Yue Han, Lianyuan Jin, Wenbo Li, Tianqing Wang, Shifu Li, Proceedings of the VLDB Endowment. the VLDB Endowment202114</p>
<p>Imdiffusion: Imputed diffusion models for multivariate time series anomaly detection. Yuhang Chen, Chaoyun Zhang, Minghua Ma, Yudong Liu, Ruomeng Ding, Bowen Li, Shilin He, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, Proceedings of the VLDB Endowment. the VLDB Endowment202317</p>
<p>Tranad: deep transformer networks for anomaly detection in multivariate time series data. Shreshth Tuli, Giuliano Casale, Nicholas R Jennings, Proceedings of the VLDB Endowment. the VLDB Endowment202215</p>
<p>Cocktail: Chunk-adaptive mixed-precision quanization for long-context llm inference. Wei Tao, Bin Zhang, Xiaoyang Qu, Jiguang Wan, Jianzong Wang, Design, Automation, and Test in Europe. 2025</p>
<p>Test: Text prototype aligned embedding to activate llm's ability for time series. Chenxi Sun, Hongyan Li, Yaliang Li, Shenda Hong, The Twelfth International Conference on Learning Representations. </p>
<p>Large language model guided knowledge distillation for time series anomaly detection. Chen Liu, Shibo He, Qihang Zhou, Shizhong Li, Wenchao Meng, Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence. the Thirty-Third International Joint Conference on Artificial Intelligence2024</p>
<p>Large language models can deliver accurate and interpretable time series anomaly detection. Jun Liu, Chaoyun Zhang, Jiaxu Qian, Minghua Ma, Si Qin, Chetan Bansal, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, arXiv:2405.153702024arXiv preprint</p>
<p>Unsupervised scalable representation learning for multivariate time series. Jean-Yves Franceschi, Aymeric Dieuleveut, Martin Jaggi, Advances in Neural Information Processing Systems. 201932</p>
<p>Momentum contrast for unsupervised visual representation learning. Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2020</p>
<p>An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. Shaojie Bai, Zico Kolter, Vladlen Koltun, Universal Language Model Fine-tuning for Text Classification</p>
<p>Practical approach to asynchronous multivariate time series anomaly detection and localization. Ahmed Abdulaal, Zhuanghua Liu, Tomer Lancewicki, Proceedings of the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining. the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining2021</p>
<p>Swat: A water treatment testbed for research and training on ics security. Aditya P Mathur, Nils Ole Tippenhauer, 2016 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater. IEEE2016</p>
<p>Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, Tom Soderstrom, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining2018</p>            </div>
        </div>

    </div>
</body>
</html>