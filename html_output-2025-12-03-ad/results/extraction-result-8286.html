<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8286 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8286</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8286</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-152.html">extraction-schema-152</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-279070471</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.24354v1.pdf" target="_blank">Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research</a></p>
                <p><strong>Paper Abstract:</strong> Language agents powered by large language models (LLMs) have demonstrated remarkable capabilities in understanding, reasoning, and executing complex tasks. However, developing robust agents presents significant challenges: substantial engineering overhead, lack of standardized components, and insufficient evaluation frameworks for fair comparison. We introduce Agent Graph-based Orchestration for Reasoning and Assessment (AGORA), a flexible and extensible framework that addresses these challenges through three key contributions: (1) a modular architecture with a graph-based workflow engine, efficient memory management, and clean component abstraction; (2) a comprehensive suite of reusable agent algorithms implementing state-of-the-art reasoning approaches; and (3) a rigorous evaluation framework enabling systematic comparison across multiple dimensions. Through extensive experiments on mathematical reasoning and multimodal tasks, we evaluate various agent algorithms across different LLMs, revealing important insights about their relative strengths and applicability. Our results demonstrate that while sophisticated reasoning approaches can enhance agent capabilities, simpler methods like Chain-of-Thought often exhibit robust performance with significantly lower computational overhead. AGORA not only simplifies language agent development but also establishes a foundation for reproducible agent research through standardized evaluation protocols.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8286.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8286.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting technique that elicits intermediate reasoning steps from LLMs to improve performance on complex arithmetic and symbolic tasks by including step-by-step rationale in the prompt (zero-shot or few-shot variants).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various (GPT-3.5 Turbo, GPT-4o, Doubao-lite-32k, Qwen2.5-72B, Qwen2.5-7B, Llama-3.3-70B, deepseek-r1-1.5B, InternLM2.5-7B-Chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multiple commercial and open-source LLMs evaluated across sizes from ~1.5B to 72B parameters; some models (<=7B) were self-hosted locally, larger models accessed via API. Default inference temperature 0 unless otherwise specified.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['chain-of-thought']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Prompt-based elicitation of intermediate reasoning steps; applied in 0-shot/4-shot/8-shot settings depending on dataset (paper used 8-shot for GSM8K, 4-shot for MATH-500, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Direct evaluations of CoT across many LLMs on GSM8K, AQuA, and MATH-500; compared to more complex agent algorithms (PoT, ToT, RAP, GoT, DnC) in aggregated score/token analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>GSM8K (elementary math word problems, 8-shot), AQuA (algebraic problems, zero-shot), MATH-500 (hard math problems, 4-shot)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>CoT achieved the best trade-off of accuracy and token usage among agent algorithms; example: on GSM8K with Doubao-lite-32k, CoT achieved 89.31% accuracy with token cost $0.0558. Across experiments CoT often outperformed more complex agent algorithms while using fewer tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>CoT's simplicity reduces error accumulation (fewer intermediate steps/decision points), yields lower token consumption and cost, is easier to tune, and is robust across model sizes; smaller models benefit notably from CoT. The paper reports that CoT often outperforms more complex agents on math tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Simpler chain-of-thought methods deliver robust performance and better cost-effectiveness than many more complex agent algorithms; start with CoT before adding complexity only if necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8286.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8286.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SC-CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistent Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of CoT that samples multiple independent reasoning chains (paths) for the same problem and aggregates answers (majority voting) to reduce variability and increase correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various (evaluated with same LLM pool as CoT; appendix: SC-CoT used temperature=1 and number_of_paths=5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same set of commercial and open-source LLMs as other experiments; SC-CoT configured to sample multiple reasoning paths per question and aggregate.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['self-consistent chain-of-thought (multiple sampled chains + majority voting)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Generate N independent CoT reasoning traces (paper used 5 paths) at higher sampling temperature, then aggregate final answers via majority voting to select the most consistent answer.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Implemented SC-CoT with temperature=1 and 5 sampled paths (Appendix). Compared qualitatively to single-path CoT; paper notes SC-CoT's benefits but reports practical issues with smaller models (difficulty adhering to output instruction and parsing).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Mathematical benchmarks (GSM8K, AQuA, MATH-500)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Paper states SC-CoT can improve robustness via aggregation but observes parsing/output-adherence issues on smaller models; no single aggregate numeric improvement across all LLMs reported in main text beyond qualitative observation.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>SC-CoT can exploit the observation that correct answers appear more consistently across multiple sampled chains, improving robustness; however, smaller LLMs struggle to follow output formatting across multiple samples, limiting SC-CoT's efficacy in low-resource models.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>SC-CoT increases reasoning diversity and can improve answer reliability for sufficiently capable models, but its benefits are reduced for smaller models due to instruction-adherence and parsing failures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8286.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8286.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reasoning and Acting (ReAct) and ReAct-Pro</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent algorithm that interleaves reasoning and environment/tool actions (Think, Act, Observe) and a modified ReAct-Pro which separates Think and Act into distinct model calls and adds prompt changes to allow arbitrary steps.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>React: Synergizing reasoning and acting in language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 Turbo (primary reported numbers), other LLMs included in broader comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3.5 Turbo (API access) used for ReAct baseline and ReAct-Pro evaluations reported in Table 2; ReAct-Pro configured with max steps=10 in Appendix.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['iterative reasoning+action (think-action-observe loop)', 'prompt-engineered multi-step iterative reasoning (ReAct-Pro)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>ReAct: single-call interleaving of thoughts and actions; ReAct-Pro: separates Think and Action into two model calls allowing more focused reasoning per phase, and an additional prompt sentence 'You can take as many steps as needed' to permit extended iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Explicit ablation/comparison in Table 2: base ReAct vs ReAct-Pro; additionally an experiment adding a simple prompt line to allow unlimited steps vs baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>GSM8K and AQuA (mathematical reasoning datasets; results in Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Table 2 (GPT-3.5 Turbo): ReAct on GSM8K = 38.13; ReAct-Pro on GSM8K = 74.91. ReAct on AQuA = 34.25; ReAct-Pro on AQuA = 64.57. The single added prompt sentence 'You can take as many steps as needed' boosted ReAct-Pro accuracy (on AQuA) from 34.25 to 64.57 (described as ~90% relative improvement over baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Separating Think and Action into distinct calls and allowing unlimited steps dramatically improved performance, showing high sensitivity to prompt design and to architectural choice of single vs separated model calls; demonstrates that enabling more iterative, multi-step reasoning (diversity of steps) can substantially help when implemented correctly.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Prompt design and operator decomposition (separating think/action) can produce large performance gains; enabling models to take more internal steps (i.e., more diverse iterative reasoning) yields big improvements on math benchmarks for GPT-3.5 Turbo.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8286.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8286.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Program-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent algorithm that leverages code-like program outputs (executable programs) as intermediate reasoning steps, relying on the model's code generation and a program executor to compute sub-results.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various LLMs (notably smaller models tested expose limitations; details reported across evaluated models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Implemented as modular operator in AGORA with a program executor and answer extractor (merging short-answer and multiple-choice workflows into a single pipeline).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['programmatic reasoning (code generation + execution)', 'tool use / external execution']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Model generates program-like outputs (e.g., code) that are executed to produce intermediate/calculated results; final answers extracted by an answer-extractor module.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>similar (single programmatic chain) but can involve external tool execution</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared against CoT and other agent algorithms on mathematical benchmarks; qualitative analysis and aggregate performance comparisons indicate PoT underperforms on math tasks with smaller LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>GSM8K, AQuA, MATH-500 (mathematical reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Paper reports PoT performed worse on mathematical problems compared to simpler algorithms, sometimes negatively affecting performance for smaller LLMs due to inferior code generation/parsing; no single aggregate numeric value provided in main text for PoT standalone.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>PoT's reliance on high-quality code generation and parsing makes it fragile for smaller models; code-generation bottlenecks can negate potential benefits of executable reasoning and can introduce additional errors.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Programmatic/executable reasoning does not necessarily improve performance on math tasks and can harm performance for smaller models due to code quality/parsing issues; algorithmic complexity must be justified by model capability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8286.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8286.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree-of-Thoughts (ToT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A search-based approach that constructs and explores a tree of intermediate 'thoughts' (coherent textual units) using search strategies (BFS/DFS) to find high-quality solution chains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various LLMs (ToT implemented with bfs in experiments; BFS params: b=1, max_depth=6, max_steps=6, evaluations=3 as per Appendix)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>ToT implemented as modular operator in AGORA using breadth-first search with beam b=1 and limited depth/steps for managing token usage.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['tree-search over candidate thoughts', 'state evaluation and multi-path exploration']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>ToT enumerates candidate intermediate thoughts and searches the tree (e.g., BFS) while evaluating and expanding nodes to derive a final chain-of-thought; paper used BFS with constrained depth/steps and multiple evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>ToT executed with BFS (b=1) and evaluation budget; compared to CoT and other algorithms in aggregate score/token consumption analyses. ToT's token usage and performance assessed; constrained settings noted in Appendix.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Mathematical reasoning (GSM8K, AQuA, MATH-500)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Authors report ToT (and PoT) performed worse than simpler CoT on mathematical problems, with substantially increased token usage and no commensurate accuracy gains; no single numeric accuracy provided for ToT in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>ToT increases token consumption and complexity (thinking generation and state evaluation) which can worsen practical performance and cost; additional steps can introduce more opportunities for error rather than reduce reasoning difficulty for math tasks in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Tree-based multi-path search does not guarantee better performance on math benchmarks; high token cost and error accumulation in multiple steps can make ToT less effective than simple CoT for the tested tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8286.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8286.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MultimodalAgents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ZoomEye vs V* (multimodal agent workflows)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two multimodal agent algorithms for high-resolution image question answering: V* (SEAL-guided visual search) simulates guided visual search and visual working memory; ZoomEye simulates human zooming via tree-based image exploration to find relevant regions without training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>VLMs: Llava-v1.5-7B, InternVL2.5-8B, Qwen2.5-VL-7B-Instruct, Qwen2.5-VL-72B-Instruct (evaluated within ZoomEye/V* frameworks on MME-RealWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source multimodal vision-language models (7B and 72B sizes) evaluated locally; ZoomEye and V* implemented as agent pipelines to recursively search or zoom image regions for high-resolution (2K-4K) images.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['guided visual search (V*)', 'tree-based zooming visual exploration (ZoomEye)', 'aggregation of visual observations + reasoning']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>V*: LLM-guided SEAL visual search that recursively partitions the image guided by VWM and confidence thresholds (parameters in Appendix). ZoomEye: dynamic zooming tree exploration prioritized by VLM cues to locate targets and gather details for final answer generation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Comparisons run on MME-RealWorld benchmark (lite version with 2K–4K images). Implemented and compared IO baseline, V*, and ZoomEye; V* token usage not available due to model specifics. ZoomEye applied to several VLMs; paper reports improvements in final scores after applying ZoomEye.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MME-RealWorld (high-resolution multimodal question answering, lite subset with 2K–4K images)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>ZoomEye improved final scores across evaluated VLMs; Qwen2.5-VL-7B-Instruct with ZoomEye outperformed Qwen2.5-VL-72B-Instruct IO baseline. V* obtained one of the lowest scores (low pass rate). Exact numerical scores are reported in Appendix C / Table 3 (not fully reproduced in main text).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Multimodal agent workflows (ZoomEye) can substantially boost visual detail in answers and improve accuracy, sometimes enabling smaller VLMs (7B) with ZoomEye to outperform larger (72B) models without such workflows; V* struggled with pass rate and was computationally expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Specialized multimodal agent algorithms like ZoomEye can meaningfully improve performance on high-resolution image tasks and can mitigate the gap between smaller and larger VLMs when efficient search/zooming strategies are used; V* may be too slow/low-pass-rate for some high-res scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models. <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models. <em>(Rating: 2)</em></li>
                <li>React: Synergizing reasoning and acting in language models. <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models. <em>(Rating: 2)</em></li>
                <li>Graph of thoughts: Solving elaborate problems with large language models. <em>(Rating: 2)</em></li>
                <li>Guided visual search as a core mechanism in multimodal llms. <em>(Rating: 2)</em></li>
                <li>Program of Thought <em>(Rating: 1)</em></li>
                <li>Zoomeye: Enhancing multimodal llms with human-like zooming capabilities through tree-based image exploration. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8286",
    "paper_id": "paper-279070471",
    "extraction_schema_id": "extraction-schema-152",
    "extracted_data": [
        {
            "name_short": "CoT",
            "name_full": "Chain-of-Thought prompting",
            "brief_description": "A prompting technique that elicits intermediate reasoning steps from LLMs to improve performance on complex arithmetic and symbolic tasks by including step-by-step rationale in the prompt (zero-shot or few-shot variants).",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models.",
            "mention_or_use": "use",
            "model_name": "Various (GPT-3.5 Turbo, GPT-4o, Doubao-lite-32k, Qwen2.5-72B, Qwen2.5-7B, Llama-3.3-70B, deepseek-r1-1.5B, InternLM2.5-7B-Chat)",
            "model_description": "Multiple commercial and open-source LLMs evaluated across sizes from ~1.5B to 72B parameters; some models (&lt;=7B) were self-hosted locally, larger models accessed via API. Default inference temperature 0 unless otherwise specified.",
            "reasoning_methods": [
                "chain-of-thought"
            ],
            "reasoning_methods_description": "Prompt-based elicitation of intermediate reasoning steps; applied in 0-shot/4-shot/8-shot settings depending on dataset (paper used 8-shot for GSM8K, 4-shot for MATH-500, etc.).",
            "reasoning_diversity": "similar",
            "reasoning_diversity_experimental_setup": "Direct evaluations of CoT across many LLMs on GSM8K, AQuA, and MATH-500; compared to more complex agent algorithms (PoT, ToT, RAP, GoT, DnC) in aggregated score/token analyses.",
            "task_or_benchmark": "GSM8K (elementary math word problems, 8-shot), AQuA (algebraic problems, zero-shot), MATH-500 (hard math problems, 4-shot)",
            "performance_results": "CoT achieved the best trade-off of accuracy and token usage among agent algorithms; example: on GSM8K with Doubao-lite-32k, CoT achieved 89.31% accuracy with token cost $0.0558. Across experiments CoT often outperformed more complex agent algorithms while using fewer tokens.",
            "qualitative_findings": "CoT's simplicity reduces error accumulation (fewer intermediate steps/decision points), yields lower token consumption and cost, is easier to tune, and is robust across model sizes; smaller models benefit notably from CoT. The paper reports that CoT often outperforms more complex agents on math tasks.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Simpler chain-of-thought methods deliver robust performance and better cost-effectiveness than many more complex agent algorithms; start with CoT before adding complexity only if necessary.",
            "uuid": "e8286.0",
            "source_info": {
                "paper_title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "SC-CoT",
            "name_full": "Self-Consistent Chain-of-Thought",
            "brief_description": "An extension of CoT that samples multiple independent reasoning chains (paths) for the same problem and aggregates answers (majority voting) to reduce variability and increase correctness.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models.",
            "mention_or_use": "use",
            "model_name": "Various (evaluated with same LLM pool as CoT; appendix: SC-CoT used temperature=1 and number_of_paths=5)",
            "model_description": "Same set of commercial and open-source LLMs as other experiments; SC-CoT configured to sample multiple reasoning paths per question and aggregate.",
            "reasoning_methods": [
                "self-consistent chain-of-thought (multiple sampled chains + majority voting)"
            ],
            "reasoning_methods_description": "Generate N independent CoT reasoning traces (paper used 5 paths) at higher sampling temperature, then aggregate final answers via majority voting to select the most consistent answer.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "Implemented SC-CoT with temperature=1 and 5 sampled paths (Appendix). Compared qualitatively to single-path CoT; paper notes SC-CoT's benefits but reports practical issues with smaller models (difficulty adhering to output instruction and parsing).",
            "task_or_benchmark": "Mathematical benchmarks (GSM8K, AQuA, MATH-500)",
            "performance_results": "Paper states SC-CoT can improve robustness via aggregation but observes parsing/output-adherence issues on smaller models; no single aggregate numeric improvement across all LLMs reported in main text beyond qualitative observation.",
            "qualitative_findings": "SC-CoT can exploit the observation that correct answers appear more consistently across multiple sampled chains, improving robustness; however, smaller LLMs struggle to follow output formatting across multiple samples, limiting SC-CoT's efficacy in low-resource models.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "SC-CoT increases reasoning diversity and can improve answer reliability for sufficiently capable models, but its benefits are reduced for smaller models due to instruction-adherence and parsing failures.",
            "uuid": "e8286.1",
            "source_info": {
                "paper_title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "ReAct",
            "name_full": "Reasoning and Acting (ReAct) and ReAct-Pro",
            "brief_description": "An agent algorithm that interleaves reasoning and environment/tool actions (Think, Act, Observe) and a modified ReAct-Pro which separates Think and Act into distinct model calls and adds prompt changes to allow arbitrary steps.",
            "citation_title": "React: Synergizing reasoning and acting in language models.",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 Turbo (primary reported numbers), other LLMs included in broader comparisons",
            "model_description": "GPT-3.5 Turbo (API access) used for ReAct baseline and ReAct-Pro evaluations reported in Table 2; ReAct-Pro configured with max steps=10 in Appendix.",
            "reasoning_methods": [
                "iterative reasoning+action (think-action-observe loop)",
                "prompt-engineered multi-step iterative reasoning (ReAct-Pro)"
            ],
            "reasoning_methods_description": "ReAct: single-call interleaving of thoughts and actions; ReAct-Pro: separates Think and Action into two model calls allowing more focused reasoning per phase, and an additional prompt sentence 'You can take as many steps as needed' to permit extended iteration.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Explicit ablation/comparison in Table 2: base ReAct vs ReAct-Pro; additionally an experiment adding a simple prompt line to allow unlimited steps vs baseline.",
            "task_or_benchmark": "GSM8K and AQuA (mathematical reasoning datasets; results in Table 2)",
            "performance_results": "Table 2 (GPT-3.5 Turbo): ReAct on GSM8K = 38.13; ReAct-Pro on GSM8K = 74.91. ReAct on AQuA = 34.25; ReAct-Pro on AQuA = 64.57. The single added prompt sentence 'You can take as many steps as needed' boosted ReAct-Pro accuracy (on AQuA) from 34.25 to 64.57 (described as ~90% relative improvement over baseline).",
            "qualitative_findings": "Separating Think and Action into distinct calls and allowing unlimited steps dramatically improved performance, showing high sensitivity to prompt design and to architectural choice of single vs separated model calls; demonstrates that enabling more iterative, multi-step reasoning (diversity of steps) can substantially help when implemented correctly.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Prompt design and operator decomposition (separating think/action) can produce large performance gains; enabling models to take more internal steps (i.e., more diverse iterative reasoning) yields big improvements on math benchmarks for GPT-3.5 Turbo.",
            "uuid": "e8286.2",
            "source_info": {
                "paper_title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "PoT",
            "name_full": "Program-of-Thought",
            "brief_description": "An agent algorithm that leverages code-like program outputs (executable programs) as intermediate reasoning steps, relying on the model's code generation and a program executor to compute sub-results.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Various LLMs (notably smaller models tested expose limitations; details reported across evaluated models)",
            "model_description": "Implemented as modular operator in AGORA with a program executor and answer extractor (merging short-answer and multiple-choice workflows into a single pipeline).",
            "reasoning_methods": [
                "programmatic reasoning (code generation + execution)",
                "tool use / external execution"
            ],
            "reasoning_methods_description": "Model generates program-like outputs (e.g., code) that are executed to produce intermediate/calculated results; final answers extracted by an answer-extractor module.",
            "reasoning_diversity": "similar (single programmatic chain) but can involve external tool execution",
            "reasoning_diversity_experimental_setup": "Compared against CoT and other agent algorithms on mathematical benchmarks; qualitative analysis and aggregate performance comparisons indicate PoT underperforms on math tasks with smaller LLMs.",
            "task_or_benchmark": "GSM8K, AQuA, MATH-500 (mathematical reasoning)",
            "performance_results": "Paper reports PoT performed worse on mathematical problems compared to simpler algorithms, sometimes negatively affecting performance for smaller LLMs due to inferior code generation/parsing; no single aggregate numeric value provided in main text for PoT standalone.",
            "qualitative_findings": "PoT's reliance on high-quality code generation and parsing makes it fragile for smaller models; code-generation bottlenecks can negate potential benefits of executable reasoning and can introduce additional errors.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Programmatic/executable reasoning does not necessarily improve performance on math tasks and can harm performance for smaller models due to code quality/parsing issues; algorithmic complexity must be justified by model capability.",
            "uuid": "e8286.3",
            "source_info": {
                "paper_title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "ToT",
            "name_full": "Tree-of-Thoughts (ToT)",
            "brief_description": "A search-based approach that constructs and explores a tree of intermediate 'thoughts' (coherent textual units) using search strategies (BFS/DFS) to find high-quality solution chains.",
            "citation_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "mention_or_use": "use",
            "model_name": "Various LLMs (ToT implemented with bfs in experiments; BFS params: b=1, max_depth=6, max_steps=6, evaluations=3 as per Appendix)",
            "model_description": "ToT implemented as modular operator in AGORA using breadth-first search with beam b=1 and limited depth/steps for managing token usage.",
            "reasoning_methods": [
                "tree-search over candidate thoughts",
                "state evaluation and multi-path exploration"
            ],
            "reasoning_methods_description": "ToT enumerates candidate intermediate thoughts and searches the tree (e.g., BFS) while evaluating and expanding nodes to derive a final chain-of-thought; paper used BFS with constrained depth/steps and multiple evaluations.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "ToT executed with BFS (b=1) and evaluation budget; compared to CoT and other algorithms in aggregate score/token consumption analyses. ToT's token usage and performance assessed; constrained settings noted in Appendix.",
            "task_or_benchmark": "Mathematical reasoning (GSM8K, AQuA, MATH-500)",
            "performance_results": "Authors report ToT (and PoT) performed worse than simpler CoT on mathematical problems, with substantially increased token usage and no commensurate accuracy gains; no single numeric accuracy provided for ToT in main text.",
            "qualitative_findings": "ToT increases token consumption and complexity (thinking generation and state evaluation) which can worsen practical performance and cost; additional steps can introduce more opportunities for error rather than reduce reasoning difficulty for math tasks in experiments.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Tree-based multi-path search does not guarantee better performance on math benchmarks; high token cost and error accumulation in multiple steps can make ToT less effective than simple CoT for the tested tasks.",
            "uuid": "e8286.4",
            "source_info": {
                "paper_title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "MultimodalAgents",
            "name_full": "ZoomEye vs V* (multimodal agent workflows)",
            "brief_description": "Two multimodal agent algorithms for high-resolution image question answering: V* (SEAL-guided visual search) simulates guided visual search and visual working memory; ZoomEye simulates human zooming via tree-based image exploration to find relevant regions without training.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "VLMs: Llava-v1.5-7B, InternVL2.5-8B, Qwen2.5-VL-7B-Instruct, Qwen2.5-VL-72B-Instruct (evaluated within ZoomEye/V* frameworks on MME-RealWorld)",
            "model_description": "Open-source multimodal vision-language models (7B and 72B sizes) evaluated locally; ZoomEye and V* implemented as agent pipelines to recursively search or zoom image regions for high-resolution (2K-4K) images.",
            "reasoning_methods": [
                "guided visual search (V*)",
                "tree-based zooming visual exploration (ZoomEye)",
                "aggregation of visual observations + reasoning"
            ],
            "reasoning_methods_description": "V*: LLM-guided SEAL visual search that recursively partitions the image guided by VWM and confidence thresholds (parameters in Appendix). ZoomEye: dynamic zooming tree exploration prioritized by VLM cues to locate targets and gather details for final answer generation.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "Comparisons run on MME-RealWorld benchmark (lite version with 2K–4K images). Implemented and compared IO baseline, V*, and ZoomEye; V* token usage not available due to model specifics. ZoomEye applied to several VLMs; paper reports improvements in final scores after applying ZoomEye.",
            "task_or_benchmark": "MME-RealWorld (high-resolution multimodal question answering, lite subset with 2K–4K images)",
            "performance_results": "ZoomEye improved final scores across evaluated VLMs; Qwen2.5-VL-7B-Instruct with ZoomEye outperformed Qwen2.5-VL-72B-Instruct IO baseline. V* obtained one of the lowest scores (low pass rate). Exact numerical scores are reported in Appendix C / Table 3 (not fully reproduced in main text).",
            "qualitative_findings": "Multimodal agent workflows (ZoomEye) can substantially boost visual detail in answers and improve accuracy, sometimes enabling smaller VLMs (7B) with ZoomEye to outperform larger (72B) models without such workflows; V* struggled with pass rate and was computationally expensive.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Specialized multimodal agent algorithms like ZoomEye can meaningfully improve performance on high-resolution image tasks and can mitigate the gap between smaller and larger VLMs when efficient search/zooming strategies are used; V* may be too slow/low-pass-rate for some high-res scenarios.",
            "uuid": "e8286.5",
            "source_info": {
                "paper_title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models.",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models.",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "React: Synergizing reasoning and acting in language models.",
            "rating": 2,
            "sanitized_title": "react_synergizing_reasoning_and_acting_in_language_models"
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "Graph of thoughts: Solving elaborate problems with large language models.",
            "rating": 2,
            "sanitized_title": "graph_of_thoughts_solving_elaborate_problems_with_large_language_models"
        },
        {
            "paper_title": "Guided visual search as a core mechanism in multimodal llms.",
            "rating": 2,
            "sanitized_title": "guided_visual_search_as_a_core_mechanism_in_multimodal_llms"
        },
        {
            "paper_title": "Program of Thought",
            "rating": 1,
            "sanitized_title": "program_of_thought"
        },
        {
            "paper_title": "Zoomeye: Enhancing multimodal llms with human-like zooming capabilities through tree-based image exploration.",
            "rating": 2,
            "sanitized_title": "zoomeye_enhancing_multimodal_llms_with_humanlike_zooming_capabilities_through_treebased_image_exploration"
        }
    ],
    "cost": 0.014296999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research
30 May 2025</p>
<p>Qianqian Zhang 
Om AI Research</p>
<p>Jiajia Liao 
Binjiang Institute of Zhejiang University</p>
<p>Heting Ying 
Om AI Research</p>
<p>Yibo Ma 
Om AI Research</p>
<p>Haozhan Shen 
College of Computer Science and Technology
Zhejiang University</p>
<p>Jingcheng Li 
Om AI Research</p>
<p>Peng Liu 
Om AI Research</p>
<p>Lu Zhang 
Om AI Research</p>
<p>Chunxin Fang 
Binjiang Institute of Zhejiang University</p>
<p>Kyusong Lee 
Om AI Research</p>
<p>Binjiang Institute of Zhejiang University</p>
<p>Ruochen Xu 
Om AI Research</p>
<p>Tiancheng Zhao tianchez@zju-bj.com 
Om AI Research</p>
<p>Binjiang Institute of Zhejiang University</p>
<p>Keyu Chen 
Xin Chen 
Xun Chen 
Zehui Chen 
Zhi Chen 
Pei Chu 
Xiaoyi Dong 
Haodong Duan 
Qi Fan 
Zhaoye Fei 
Yang Gao 
Jiaye Ge 
Chenya Gu 
Yuzhe Gu 
Tao Gui 
Aijia Guo 
Qipeng Guo 
Conghui He 
Yingfan Hu 
Ting Huang 
Tao Jiang 
Penglong Jiao 
Zhenjiang Jin 
Zhikai Lei 
Jiaxing Li 
Jingwen Li 
Linyang Li 
Shuaibin Li 
Wei Li 
Yin- Ing Li 
Hongwei Liu 
Jiangning Liu 
Jiawei Hong 
Kaiwen Liu 
Kuikun Liu 
Xiaoran Liu 
Chengqi Lv 
Haijun Lv 
Kai Lv 
Li Ma 
Runyuan Ma 
Zerun Ma 
Wenchang Ning 
Linke Ouyang 
Jiantao Qiu 
Yuan Qu 
Fukai Shang 
Yunfan Shao 
Weize Chen 
Yusheng Su 
Jingwei Zuo 
Cheng Yang 
Chenfei Yuan 
Chi-Min Chan 
Heyang Yu 
Yaxi Lu 
Yi-Hsin Hung 
Chen Qian 
Yujia Qin 
Xin Cong 
Zhe Chen 
Weiyun Wang 
Yue Cao 
Yangzhou Liu 
Zhangwei Gao 
Erfei Cui 
Jinguo Zhu 
Shenglong Ye 
Hao Tian 
Zhaoyang Liu 
Lixin Gu 
Xuehui Wang 
Qingyun Li 
Yimin Ren 
Zixuan Chen 
Jiapeng Luo 
Jiahao Wang 
Tan Jiang 
Bo Wang 
Bo- Tian Shi 
Xingcheng Zhang 
Han Lv 
Yi Wang 
Wenqi Shao 
Zhongying Tu 
Tong He 
Zhiyong Wu 
Huipeng Deng 
Kai Chen 
Kaipeng Zhang 
Limin Wang 
Min Dou 
Lewei Lu 
Xizhou Zhu 
Tong Lu 
Dahua Lin 
Yu Qiao 
Karl Cobbe 
Vineet Kosaraju 
Mohammad Bavarian 
Mark Chen 
Heewoo Jun 
Lukasz Kaiser 
Matthias Plappert 
Jerry Tworek 
Jacob Hilton 
Reiichiro Nakano 
Christopher Hesse </p>
<p>Demin Song
Haochen Ye
Jiaqi Wang, Ji-ayu Wang, Xingjian Wei, Qizhen Weng, Fan Wu, Ruiliang Xu, Hang Yan, Jia Yu, Jing Yu, Yuhang Zang, Pan Zhang, Ruijie Zhang, Shuo Zhang, Songyang Zhang, Wenjian Zhang, Wenwei Zhang, Fengzhe Zhou, Zaida Zhou, Jingming Zhuo, Yicheng Zou, Xipeng QiuZi-fan Song, Zhihao Sui, Peng Sun, Yu Sun, Huanze Tang, Bin Wang, Guoteng Wang, Rui Wang, Yudong Wang, Ziyi Wang, Yingtong Xiong, Chao Xu, Yirong Yan, Xiaogui Yang, Huaiyuan Ying, Chuyu Zhang, Li Zhang, Peng Zhang, Xingcheng Zhang, Xinyue Zhang, Hui Zhao, Xiaomeng Zhao, Yu QiaoQian Zhao</p>
<p>Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research
30 May 2025CEE4053B36180379B73D01C67DA9E2C0arXiv:2505.24354v1[cs.CL]
Language agents powered by large language models (LLMs) have demonstrated remarkable capabilities in understanding, reasoning, and executing complex tasks.However, developing robust agents presents significant challenges: substantial engineering overhead, lack of standardized components, and insufficient evaluation frameworks for fair comparison.We introduce Agent Graph-based Orchestration for Reasoning and Assessment (AGORA) 1 , a flexible and extensible framework that addresses these challenges through three key contributions: (1) a modular architecture with a graphbased workflow engine, efficient memory management, and clean component abstraction;(2) a comprehensive suite of reusable agent algorithms implementing state-of-the-art reasoning approaches; and (3) a rigorous evaluation framework enabling systematic comparison across multiple dimensions.Through extensive experiments on mathematical reasoning and multimodal tasks, we evaluate various agent algorithms across different LLMs, revealing important insights about their relative strengths and applicability.Our results demonstrate that while sophisticated reasoning approaches can enhance agent capabilities, simpler methods like Chain-of-Thought often exhibit robust performance with significantly lower computational overhead.AGORA not only simplifies language agent development but also establishes a foundation for reproducible agent research through standardized evaluation protocols.</p>
<p>Introduction</p>
<p>Language agents powered by large language models (LLMs) are rapidly transforming how we ap- 1 We made a demo video at: https://www.youtube.com/watch?v=WRH-F1zegKI.</p>
<p>The comparison of agent algorithms across different LLMs is also available at https://huggingface.co/spaces/omlab/ open-agent-leaderboard.Source code of AGORA can be found at https://github.com/om-ai-lab/OmAgent. proach complex computational tasks across diverse domains.Industry adoption of these technologies is accelerating, with projections suggesting that 33% of organizations will implement LLM-based applications by 20252 .This growing adoption stems from the unprecedented ability of these systems to integrate natural language understanding with action-oriented capabilities.</p>
<p>Despite their promising trajectory, the practical implementation of language agents remains challenging for researchers and developers.Current frameworks often require substantial custom engineering efforts for each application domain, leading to fragmented implementations and difficulty in comparing different approaches.</p>
<p>To bridge this gap, we present AGORA, a comprehensive framework focused on both practical implementation and scientific evaluation of language agents.AGORA provides an integrated environment where researchers can experiment with various reasoning strategies while developers can build robust applications with minimal engineering overhead.Our framework makes three key contributions that differentiate it from existing approaches: a graph-based workflow orchestration engine that simplifies complex task execution; modular agent algorithm support for diverse reasoning paradigms; and easy-to-use client interfaces for evaluation and interaction.</p>
<p>Through systematic evaluation on mathematical and multimodal reasoning tasks, we demonstrate that AGORA not only facilitates rapid development but also enables rigorous scientific comparison of different agent paradigms.Our results provide actionable insights for researchers and practitioners navigating the growing landscape of language agent technologies.</p>
<p>Related Work</p>
<p>Recent years have seen significant development in LLM agent frameworks and evaluation methodologies.Frameworks like LangChain (Developers, 2022), AutoGPT (Developers, 2023), and Agent-Verse (Chen et al., 2024) offer general-purpose infrastructures for agent development, while Au-toAgent (Tang et al., 2025) provides zero-code solutions through declarative interfaces.Specialized frameworks address domain-specific applications, including ChemCrow (Bran et al., 2023) for chemistry and OS-Copilot (Wu et al., 2024) for operating systems.For evaluation, comprehensive benchmark suites such as AgentBench (Liu et al., 2023b) and WebArena (Zhou et al., 2023) assess agents across multiple dimensions including reasoning, tool use, and web browsing.Leaderboard platforms like Agent Arena (Yekollu et al., 2024) enable systematic comparison of agents across models, frameworks, and tools through user-driven evaluations.A notable benchmark in this space is the Agent Leaderboard (Bhavsar, 2025), which primarily evaluates LLMs' tool calling and API interaction capabilities.Our work differs by providing a comprehensive evaluation framework that assesses both the underlying LLM capabilities and the effectiveness of different reasoning language agent algorithms, enabling researchers to understand the interplay between model selection and reasoning strategies.</p>
<p>AGORA Framework</p>
<p>AGORA is built on top of the OmAgent framework (Zhang et al., 2024), extending it into a flexible and extensible system for building, orchestrating, and evaluating language agents.It abstracts engineering complexity while exposing essential, reusable components-such as LLMs, VLMs, tools, and workflows-needed to construct powerful and research-friendly agents.</p>
<p>Graph-based Workflow Orchestration Engine.At the core of AGORA is a graph-based orchestration engine designed for modularity and scalability.As shown in Figure 1, the system uses a Directed Acyclic Graph (DAG) where each node represents a task.Tasks are either simple tasks-developer-defined custom logic-or logical tasks-built-in control flows such as branching and looping.Built on the Conductor library, this engine provides visual representations of workflows, making agent behavior intuitive to trace and debug.It also supports asynchronous, distributed execution, which is ideal for managing long-running, complex agent workflows.</p>
<p>Modular Agent Algorithm Support.AGORA includes a diverse set of agent algorithms such as Chain-of-Thought (CoT), Program-of-Thought (PoT), ReAct, Tree-of-Thought (ToT), and more.Each algorithm is implemented as a modular component, allowing developers to reuse common functions like memory access, LLM inference, or tool use.This structure encourages rapid prototyping, easy extensibility, and consistent evaluation across reasoning paradigms.</p>
<p>Client Interfaces for Evaluation and Interaction.After constructing an agent, AGORA provides a suite of Client interfaces tailored to different usage scenarios.</p>
<p>• WebPageClient: delivers a web-based chat interface that allows users to directly interact with the agent in real time, making it particularly suitable for qualitative studies such as usability testing or behavioral observation.</p>
<p>• ProgrammaticClient: supports automated evaluation using predefined JSON test files, making it ideal for quantitative studies with structured benchmarks-it efficiently runs batch test cases, logs outputs, and summarizes scores.</p>
<p>• DefaultClient: offers a lightweight command-line interface, designed for quick testing and debugging of agent logic during development.These clients are plug-and-play and can be easily configured via a configuration file, enabling researchers to seamlessly adapt the interface to different stages of experimentation and evaluation.These client interfaces are plug-and-play and can be easily configured via a user-friendly config file, enabling seamless switching based on development or evaluation needs.</p>
<p>Agent Algorithms</p>
<p>The AGORA framework uses modular, reusable components called operators to simplify building and customizing AI systems.Each operator acts as a self-contained unit designed for a specific task, with clear input and output connections that make it easy to integrate into larger workflows.</p>
<p>We implemented various agent algorithms as operators and rigorously evaluated their performance in standardized, controlled environments.A description of the implemented agent algorithms is provided in Table 1.In particular, RAP enables more reliable and transparent decision-making processes by transforming complex reasoning tasks into systematic planning problems.The RAP implementation follows a tree-search-based architecture with four main components: selection, expansion, simulation, and backpropagation.In contrast to ToT, RAP enables backpropagation in the search framework, enhancing the efficiency of decisiontree traversal.</p>
<p>Implemented Agent Algorithms</p>
<p>In addition, We enhaced ReAct to ReAct-pro inspired by the Reflexion (Shinn et al., 2023) implementation.We modified our approach by separating the previously combined Think and Action steps into two distinct model calls, allowing the model to focus more intently on each phase.We also improved PoT by merging short-answer and multiple-choice questions processes into a single workflow consisting of two modules: the program executor and the answer extractor.For GoT, we extend the original GoT implementation into general GoT by allowing it to conduct any tasks other than the predefined tasks like sorting.</p>
<p>Evaluation Framework</p>
<p>Our experimental evaluation focused on two distinct domains: unimodal mathematical reasoning tasks and multimodal high-resolution image question-answering reasoning tasks.Mathematical reasoning tasks serve as canonical benchmarks for logical inference and problem decomposition, challenging agents to exhibit systematic reasoning and numerical accuracy.These tasks are inherently language-intensive yet require precise stepby-step deduction, making them ideal for evaluat-Agent Algorithms Description Chain of Thought (CoT) (Wei et al., 2022) Through encourage reasoning in the prompt, CoT enhances LLMs' reasoning by leverages intermediate steps, improving performance in complex tasks like arithmetic and symbolic reasoning.It can be broadly categorized into two types: Zero-shot-CoT and Few-shot-CoT (Kojima et al., 2022).Self-Consistent CoT (SC-CoT) (Wang et al., 2022) SC-CoT extends traditional CoT by generating multiple independent reasoning paths for the same problem and aggregating results through majority voting.This approach addresses the inherent variability in LLM reasoning by exploiting the observation that correct answers tend to emerge more consistently across different reasoning attempts than incorrect ones.Tree of Thoughts (ToT) (Yao et al., 2023) ToT facilitates advanced decision-making by examining coherent textual units, or "thoughts," as intermediate steps in problem-solving.Unlike traditional token-level approaches, ToT enables LLMs to construct and evaluate a thought tree using methods like Breadth-First Search (BFS) or Depth-First Search (DFS) to derive an optimal chain of thought.Reasoning and Acting (ReAct) (Yao et al., 2022) ReAct allows language models to engage with external environments through an iterative cycle of thought, action, and observation.The model reasons about the current state, executes relevant actions, and processes feedback until it gathers sufficient information to deliver a final response.Program of Thought (PoT) (Chen et al., 2022) PoT is designed to enhance the reasoning capabilities of language models by integrating programming language statements into their outputs.Unlike CoT, PoT leverages the strengths of language models like Codex to generate both text and executable code.Divide-and-Conquer (DnC) (Zhang et al., 2024) DnC enhances problem-solving by decomposing complex issues into manageable sub-problems.In this approach, LLMs alternate between the roles of conqueror, which directly addresses the problem, and divider, which breaks it down into smaller components.The conqueror and the divider operate in an iterative loop until the termination criteria are met.Graph-of-Thought (GoT) (Besta et al., 2024) GoT extends the ToT framework by introducing aggregation and refining transformations, enabling advanced graph-based reasoning.This approach decomposes tasks into identical subtasks, processes them independently, and aggregates sub-responses while leveraging internal loops to refine response quality.Reasoning via Planning (RAP) (Hao et al., 2023) RAP enhances LLMs by framing complex reasoning tasks as structured planning problems and employing a Monte Carlo Tree Search (MCTS) framework.The RAP implementation follows a tree-search-based architecture with four main components: selection, expansion, simulation, and backpropagation.Selection means intelligently choosing promising paths through the reasoning tree; Expansion breaks down complex questions into manageable sub-questions; Simulation evaluates potential solution paths through systematic exploration; and Backpropagation updates the search strategy based on solutions discovered.In contrast to ToT, RAP enables backpropagation in the search framework, enhancing the efficiency of decision-tree traversal.V<em> (Wu and Xie, 2023) V</em> introduces a meta-architecture for VLMs, SEAL (Show, sEArch, and TelL), a LLM-guided visual search method that enhances high-resolution image processing through iterative search and contextual reasoning.V<em> simulates human visual search process and leverages top-down features and contextual guidance to address the limitations of traditional visual encoders.First, V</em> assesses whether visual search is necessary.If so, the VLM identifies the target object.Subsequently, the LLM-guided search model recursively partitions the image into smaller regions and searches for the target based on the confidence scores derived from contextual cues until the target is located.The information about the identified target is stored in the Visual Working Memory (VWM).Finally, the VLM generates the response using the visual information of all targets stored in the VWM.</p>
<p>A implementation of V* is presented in Algorithm 1. ZoomEye (Shen et al., 2024) ZoomEye is a training-free agent algorithm that enhances VLM performance on high-resolution images by simulating human zooming behavior.Treating the image as a tree structure, it dynamically explores zoomed-in regions based on visual cues and problem-specific priorities calculated by the VLMs.ing the core reasoning capabilities of LLMs.Meanwhile, multimodal tasks involving high-resolution image understanding address the growing demand for agents to simulate real-world scenarios where contextual reasoning across diverse inputs is essential.Comprehensive experiments were conducted across multiple evaluation metrics, agent algorithms, and LLMs to assess reasoning capabilities in both domains.</p>
<p>To evaluate language agents, this study defines four key metrics: accuracy, cost, token usage, and pass rate.Specially, accuracy assesses the proportion of predictions that exactly match the groundtruth response; cost quantifies the total expenditure incurred measured in US dollar.We used API services for close-sourced models and models with more than 70 billion from SiliconFlow 1 and OpenAI2 ; Token usage measures the number of tokens that a language agent uses to generate predictions, and pass rate measures the proportion of valid predictions among all predictions, where a prediction is considered valid if it is neither empty nor null.</p>
<p>Experimental Setup</p>
<p>Mathematical Reasoning Tasks</p>
<p>The mathematical reasoning benchmarks include: GSM8K (Cobbe et al., 2021): A dataset for evaluating language agents' ability to solve elementary math word problems.we conducted the evaluation using 8-shot learning.</p>
<p>AQuA (Ling et al., 2017): This dataset is specifically designed to reason through diverse algebraic problems to assess reasoning abilities.We employed zero-shot learning in the experiments.</p>
<p>MATH-500 (Hendrycks et al., 2021): A dataset comprising 500 mathematical reasoning problems has been meticulously designed to evaluate the ability of language agents to tackle complex mathematical challenges, where 4-shot learning is applied.</p>
<p>We applied both commercial and open-source models in the experiments.</p>
<p>Commercial Models: In our experiment, GPT-3.5 Turbo and GPT-4o from OpenAI, and Doubaolite-32k from ByteDance were used as LLM for agent algorithms, and GPT-3.5 Turbo was also used for the extraction of AQuA answers.</p>
<p>Open-source models:</p>
<p>We also evaluated open source models like Llama and Qwen for performance and cost effectiveness.We used the following models as the LLMs for Agents: Qwen2.5-72B-Instruct,Qwen2.5-7B-Instruct(Yang et al., 2024b), Qwen2-1.5B-Instruct,Qwen2-0.5B-Instruct(Yang et al., 2024a), Llama-3.3-70B-Instruct,Llama-3.1-8B-Instruct(Grattafiori et al., 2024), InternLM2.5-7B-Chat(Cai et al., 2024), deepseek-r1-1.5B(Guo et al., 2025).</p>
<p>In the experiments, the default setting uses a temperature of 0.More algorithm settings other than default can be found in Appendix A.</p>
<p>Multimodal Reasoning Tasks</p>
<p>Regarding multimodal reasoning task, we implemented MME-RealWorld (Zhang et al., 2025) as the benchmark.MME-RealWorld aims at solving high-resolution image problems highly relevant to real-world applications.Specifically, we selected images with resolutions between 2K and 4K in the lite version.We implemented V* and ZoomEye in the evaluation, implementation details can be found in Appendix A. Because we only applied open source VLMs and all models used were deployed locally, cost is not involved for evaluation.</p>
<p>Mathematical Reasoning Results</p>
<p>Performance Comparison</p>
<p>The average scores and average token consumptions of LLM and algorithm pairs are illustrated in Figure 2, where the average token consumption is calculated by first summing the input and output tokens per sample for each dataset, then computing the overall mean across all benchmarks.The comparison details can be found at Open Agent leaderboard (Lab, 2025).Furthermore, we performed a score versus cost analysis for different LLM agent algorithms, as depicted in Figure 3.The dashed line in the plot represents an ideal trend line, which  serves as a visual benchmark, illustrating the optimal balance between cost and performance.Points on the top-left corner indicate agent-LLM pairs that offer the best possible trade-off between task accuracy and computational cost.Models smaller than 7B parameters were self-hosted locally, thus their cost metrics are not shown.It should be mentioned that GoT, RAP and DnC were excluded from the comparison.GoT is specifically designed to decompose complex tasks into several identical sub-tasks, such as sorting and keyword counting.RAP and DnC was not included due to its high token consumption.</p>
<p>Open-source models with 70 billion parameters have demonstrated exceptional performance compared to other models.Also, Qwen2.5-7B-Instructsurpasses GPT-3.5 Turbo in this task.Surprisingly, deepseek-r1-1.5B, with only 1.5 billion parameters, exhibits remarkable performance by outperforming the InternLM2.5-7B-Chatmodel.When considering different agent algorithms, the simplest CoT approach also outperforms other agent algorithms while utilizing the least number of tokens.</p>
<p>Key Findings</p>
<p>Simple agent algorithms show robust performance.CoT and SC-CoT algorithm has demonstrated remarkable performance despite their simplicity.Utilizing the Doubao-lite-32k model, CoT achieved an accuracy of 89.31% on the GSM8K dataset, with a token cost of only $0.0558.However, SC-CoT encounters challenges with smaller models, which struggle to strictly adhere to instructions, resulting in difficulties parsing the output.Notably, more advanced algorithms, such as PoT and TOT, which incorporate external tools, perform worse on mathematical problems compared to the simpler algorithms.We observed that PoT's reliance on the code generation and parsing capabilities of LLMs does not lead to significant improvements compared to other agent algorithms.In fact, it can have negative effects, particularly with smaller LLM models due to the code generation quality.Moreover, the thinking generation and state evaluation for ToT does not significantly reduce the difficulty of reasoning, but rather significantly increases its token usage, which leads to exhibiting poorer performance.</p>
<p>This phenomenon prompts a reflection on the value of algorithmic complexity.The advantage of simpler methods is primarily reflected in the reduction of error accumulation.Complex agent algorithms often involve multiple steps, each potentially introducing errors, whereas a single reasoning chain significantly reduces the risk of error propagation.CoT's simple prompts are easier to adjust and optimize, making the reasoning process more transparent, easier to understand, and improved.In terms of cost-effectiveness, CoT's advantages are even more apparent.Lower token consumption translates to reduced operational costs, and faster reasoning speeds enhance system responsiveness.Additionally, the straightforward implementation reduces development and maintenance costs.These findings offer important practical insights.When designing intelligent systems, we should prioritize simple and direct solutions, introducing complexity only when necessary.It is advisable to start with a basic CoT implementation and gradually optimize based on the specific task characteristics, while carefully evaluating the actual benefits of each added complexity.</p>
<p>Agent algorithms can be sensitive to prompts.We also noticed the importance of prompt design.As shown in Table 2, the base ReAct achieved a baseline performance of 34.25% on the AQuA dataset.Inspired by the Reflexion implementation, we prompt ReAct to ReAct-Pro by separating the previously combined Think and Action steps into two distinct model calls, allowing the model to focus more intently on each phase.This modification alone boosted accuracy to 40.16%.The real breakthrough came from a remarkably simple addition by including the sentence: "You can take as many steps as needed" in the prompt, we observed an extraordinary increase in accuracy to 64.57%, an almost 90% improvement over the baseline.This simple prompt fundamentally transformed the model's behavior patterns.Open-source models are competitive with commercial ones.Open-source models at the 70B level, such as Llama-3.3-70B-Instruct and Qwen2.5-72B-Instruct,have shown outputs that exceed those of the closed-source GPT-4o.However, the enhancement brought by agent frameworks to top-tier large models (such as GPT and models above 70B) is relatively limited.In some cases, complex agents like ReAct may even lead to a decline in performance.</p>
<p>Small models perform better with simple agent algorithms.For smaller models, such as Qwen2.5-7B-Instruct,CoT demonstrates a marked improvement, while PoT shows limited enhancement.This limitation is primarily attributed to the bottleneck in code generation capabilities.</p>
<p>Multimodal Reasoning Results</p>
<p>Performance Comparison</p>
<p>We compared IO, V<em>, and ZoomEye using various models.The detailed comparison results are shown in Table 3 in Appendix C. It is important to note that due to the specific nature of the V</em> models, we were unable to obtain their token usage data.Overall, the final scores of the same models improved after using the ZoomEye framework, particularly the Qwen2.5-VL-7B-Instructmodel, which even outperformed the Qwen2.5-VL-72B-InstructIO.After applying the agent algorithms, both the input and output token usage increased sig-nificantly.Notably, the Qwen2.5-VLmodels (7B and 72B) demonstrated identical token consumption patterns in IO, which can be attributed to their strong instruction adherence capabilities and the multiple-choice format of the benchmark questions.Moreover, the V* framework received one of the lowest scores, primarily due to its low pass rate.</p>
<p>Key Findings</p>
<p>In our experiments, we found that the performance of the models was generally improved after using a multimodal agent workflow like ZoomEye, especially the 7B model outperformed the 72B model.This phenomenon suggests that adopting multimodal agent can effectively provide more visual details in final answer, thus helping the model to generate more accurate answers.Therefore, if computational resources are sufficient, it is recommended to prioritize models with larger parameters to fully leverage their potential.However, if computational resources are limited, smaller models combined with efficient agent workflows can still achieve comparable results.</p>
<p>Discussion</p>
<p>In the design of agent systems, it is crucial to prioritize straightforward and direct solutions, incorporating complexity only when necessary.It is recommended to begin with a fundamental CoT that achieves a balance between performance and cost.Complexity can be progressively increased based on task requirements (e.g., using ToT for hierarchical planning when CoT proves insufficient) , ensuring a systematic trade-off between efficiency and task complexity.For the selection of LLMs, we recommend utilizing models with at least 7 billion parameters or employing reasoning models such as deepseek-r1.This recommendation is primarily due to the tendency of smaller models to exhibit issues with instruction adherence.Furthermore, we noticed multimodal agent algorithms like Zoom-Eye can enhance agent performance by providing valuable visual details.Although larger models should be prioritized when resources allow, smaller models can still yield competitive outcomes.</p>
<p>Conclusions</p>
<p>In this paper, we present AGORA , a comprehensive framework for building and evaluating language agent algorithms that addresses critical challenges of engineering overhead, fragmented implementations, and insufficient evaluation standards.</p>
<p>Our graph-based workflow orchestration engine (built on DAGs) enables dynamic task decomposition and asynchronous distributed execution.Meanwhile, its modular design standardizes agent algorithms (e.g., CoT, V<em>) for plug-and-play integration.The multi-client evaluation interfaces also facilitate both qualitative user studies and quantitative benchmarking, enabling rigorous cross-algorithm comparisons across LLMs and tasks.We systematically integrated 10 state-of-the-art agent algorithms spanning from CoT to V</em>, under a unified modular architecture, which reduces engineering overhead.</p>
<p>Our evaluation across mathematical and multimodal tasks revealed several important insights.First, simpler reasoning approaches like CoT often demonstrate robust performance and consume less cost than more complex alternatives.Second, the effectiveness of different agent algorithms varies substantially across different model sizes.Third, for multimodal tasks, specialized agent algorithms like ZoomEye can substantially enhance model performance on high-resolution images, highlighting the value of reasoning strategies using VLMs.</p>
<p>As the field continues to evolve, we believe this framework will serve as a valuable foundation for exploring increasingly sophisticated agent architectures and reasoning approaches.Future work of AGORA should focus on: (1) expanding the evaluation framework to encompass broader complex real-world tasks (e.g., tool utilization and web interaction scenarios); (2) developing adaptive agents that dynamically select optimal reasoning strategies based on task characteristics; and (3) prioritizing seamless integration of emerging LLMs via extensions to AGORA's modular architecture.</p>
<p>Figure 1 :
1
Figure 1: A demonstration of AGORA structure.</p>
<p>(a) Average scores.(b) Average input and output token consumptions.</p>
<p>Figure 2 :
2
Figure 2: LLMs and agent algorithms average scores and average token consumptions on mathematical reasoning tasks.</p>
<p>Figure 3 :
3
Figure 3: Score versus cost analysis for different LLM agent algorithms.The ideal models appear in the top-left corner with high performance and low cost.Models smaller than 7B parameters were self-hosted locally, thus their cost metrics are not shown.</p>
<p>Table 1 :
1
Agent algorithms implemented in AGORA.</p>
<p>Table 2 :
2
Comparison of ReAct and ReAct-Pro on different datasets.
Agent AlgorithmDatasetLLMScoreReActGSM8KGPT-3.5 Turbo38.13ReAct-ProGSM8KGPT-3.5 Turbo74.91ReActAQuAGPT-3.5 Turbo34.25ReAct-ProAQuAGPT-3.5 Turbo64.57</p>
<p>Table 3 :
3
Performance comparison of different agents and VLMs on MME-RealWorld.</p>
<p>https://www.gartner.com/en/articles/ intelligent-agent-in-ai?
SiliconFlow: https://siliconflow.cn/zh-cn/
OpenAI: https://openai.com/
A Agent Algorithm Parameter SettingsIn the experiments of this paper, the default setting for LLMs uses a temperature of 0. For ReAct-Pro, the parameter is set with a maximum number of steps equal to 10.For SC-CoT, the temperature is 1 and the number of paths is 5; For TOT, we use bfs as the search method, with b as 1, max depth and a max steps are both setted as 6, and the number of evaluations is 3.The mulitmodal model configration is described as follows:V*: The SEAL structure uses specific models trained on llava-7b, including seal_vqa_7b and seal_vsm_7b.seal_vqa is responsible for identifying and providing the target objects needed for the search from question, as well as utilizing the data in the VWM(visual working memory) to answer the relevant questions.seal_vsm combines the common sense knowledge with the context of the image to locate the target object and records its information into VWM.Due to the specificity of the model, parameters such as temperature and max_tokens were not configured.As for the visual search parameters such as the confidence threshold, we use the same parameters as the original settings: confidence maximum 0.5, minimum 0.3, target cue threshold 6.0, target cue threshold decay 0.7, target cue threshold minimum 3.0.In addition we set 10 as the maximum search steps for each target.The reason for this is that the minimum image size of Vstar is 224×224, which can take an hour or even longer when searching for high-resolution images (e.g., 4K images) if we do not limit the number of search steps.ZoomEye: As a more generalized agent visual search framework, we apply and evaluate a variety of mainstream open-source multimodal models, including Llava-v1.5-7B(Liu et al., 2023a), InternVL2.5-8B(Chen et al., 2025), Qwen2.5-VL-7B-Instruct(Bai et al., 2025), and Qwen2.5-VL-72B-Instruct,which support a wide range of complex multimodal visual questioning tasks.For these VLMs, we set temperature to 0.0 and max_tokens to 2048.We also set the same parameters as the ZoomEye original settings:• Answering Confidence Threshold:-Maximum: 0.4 -Minimum: 0
Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, Humen Zhong, Yuanzhi Zhu, Mingkun Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, arXiv:2502.13923Haiyang Xu, and Junyang Lin. 2025. Qwen2.5-vl technical report. Preprint</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>. Pratik Bhavsar, 2025Agent leaderboard</p>
<p>Sam Andres M Bran, Oliver Cox, Carlo Schilter, Andrew D Baldassari, Philippe White, Schwaller, Chemcrow: Augmenting large-language models with chemistry tools. 2023</p>
<p>AutoGPT Developers. 2023. Autogpt. LangChain Developers. 2022. Langchain: Framework for developing applications powered by language models. Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, </p>
<p>Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, arXiv:2407.21783The llama 3 herd of models. 2024arXiv preprint</p>
<p>Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, arXiv:2501.12948Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. 2025arXiv preprint</p>
<p>Reasoning with language model is planning with world model. Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen Wang, Daisy Wang, Zhiting Hu, 10.18653/v1/2023.emnlp-main.507Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics2023</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, arXiv:2103.038742021arXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, ( Shixiang, Machel Shane) Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in Neural Information Processing Systems. Curran Associates, Inc202235</p>
<p>A I Om, Lab, Open agent leaderboard. 2025</p>
<p>Program induction by rationale generation: Learning to solve and explain algebraic word problems. Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom, arXiv:1705.041462017arXiv preprint</p>
<p>Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee, arXiv:2304.08485Visual instruction tuning. 2023aPreprint</p>
<p>Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, arXiv:2308.03688Yuxiao Dong, and Jie Tang. 2023b. Agentbench: Evaluating llms as agents. arXiv preprint</p>
<p>Zoomeye: Enhancing multimodal llms with human-like zooming capabilities through tree-based image exploration. Haozhan Shen, Kangjia Zhao, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Mingwei Zhu, Jianwei Yin, arXiv:2411.160442024Preprint</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202336</p>
<p>Autoagent: A fully-automated and zero-code framework for llm agents. Jiabin Tang, Tianyu Fan, Chao Huang, 20252502arXiv e-prints</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, 10.48550/arXiv.2203.11171arXiv:2203.111712022arXiv preprintPublished at ICLR 2023</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, 2022In NeurIPS</p>
<p>V*: Guided visual search as a core mechanism in multimodal llms. Penghao Wu, Saining Xie, arXiv:2312.141352023Preprint</p>
<p>Os-copilot: Towards generalist computer agents with self-improvement. Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu, Lingpeng Kong, arXiv:2402.074562024arXiv preprint</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, arXiv:2407.10671Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. 2024a. Qwen2 technical report. Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei ChuarXiv preprint</p>
<p>An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, arXiv:2412.15115Qwen2. 5 technical report. 2024barXiv preprint</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, 10.48550/arXiv.2210.03629arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprintPublished at ICLR 2023</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Anastasios Angelopoulos. NeurIPS. Nithik Yekollu, Arth Bohra, Ashwin Chirumamilla, Kai Wen, Sai Kolasani Wei-Lin Chiang2023. 2024Agent arena</p>
<p>Omagent: A multi-modal agent framework for complex video understanding with task divide-and-conquer. Lu Zhang, Tiancheng Zhao, Heting Ying, Yibo Ma, Kyusong Lee, arXiv:2406.166202024arXiv preprint</p>
<p>Mme-realworld: Could your multimodal llm challenge high-resolution real-world scenarios that are difficult for humans?. Yi-Fan Zhang, Huanyu Zhang, Haochen Tian, Chaoyou Fu, Shuangqing Zhang, Junfei Wu, Feng Li, Kun Wang, Qingsong Wen, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan, arXiv:2408.132572025Preprint</p>
<p>Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, arXiv:2307.13854Webarena: A realistic web environment for building autonomous agents. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>