<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-648 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-648</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-648</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-8d17543c20f23b6a40bec9334d50e9c15a08c1c4</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/8d17543c20f23b6a40bec9334d50e9c15a08c1c4" target="_blank">Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> A novel model is proposed, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and Knowledge Bases entities and relations that is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting.</p>
                <p><strong>Paper Abstract:</strong> Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e648.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e648.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GRAFT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graphs of Relations Among Facts and Text Networks (GRAFT-Net)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-convolutional neural network that performs early fusion of a symbolic knowledge base (KB) and entity-linked text by operating on a heterogeneous question-specific subgraph of KB entities, relations and text sentence tokens to directly classify answer nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GRAFT-Net</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GRAFT-Net constructs a heterogeneous subgraph for each question containing KB entities and relations, text sentences (as document nodes with token-level LSTM representations), and entity-link edges. It learns node representations with layer-wise message passing that uses (a) heterogeneous update rules for entity nodes (feed-forward layers aggregating neighbor entity messages, mentions from text tokens, and a question representation) and for document nodes (token-wise aggregation of linked entity states followed by an LSTM over positions), and (b) directed, question-conditioned propagation controlled by scalar personalized PageRank scores and attention over relation types. The final node embeddings are used with a sigmoid classifier to predict answer entities.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>A symbolic Knowledge Base (KB) represented as a directed multi-relational graph: entities V, relation triplets (s, r, o) in E, and explicit entity-links between KB entities and positions in text; relations are represented with learned relation vectors x_r and a special linking relation r_L.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural graph-based message-passing network: token-level LSTMs for document initialization and intra-document propagation, feed-forward networks (FFNs) for entity updates and edge transformations, relation-attention mechanisms, and gradient-based end-to-end learning (binary cross-entropy). Also uses PageRank-style scalar propagation computed iteratively (deterministic procedural update but learned attention used inside).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Early fusion into a single heterogeneous graph (KB facts, text tokens, and linking edges) processed end-to-end by a neural message-passing architecture. Integration specifics: (1) heterogeneous update rules keep text and KB updates distinct (LSTM for text tokens, FFN for entities), (2) attention over relation vectors x_r conditions message propagation on the question, (3) personalized/directed propagation via scalar PageRank scores pr_v^(l) localizes multi-hop propagation starting from question seed entities, and (4) fact-dropout randomly drops edges during training to encourage using both sources.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines structured KB connectivity and rich unstructured text representations to (a) perform multi-hop, question-conditioned reasoning along relational paths while also leveraging textual evidence for entities not present in the KB; (b) localize propagation from question seeds enabling focused multi-step inference across modalities; (c) disambiguate multiple entities co-mentioned in the same text via position-aware token-level updates; and (d) better aggregate multiple supporting facts across KB and text versus late fusion baselines. These behaviors emerge from the interaction of symbolic graph structure (declarative) and learned neural message passing (imperative).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Open-domain Question Answering over combined KB and entity-linked text; evaluated on WikiMovies (various KB completeness settings) and WebQuestionsSP (with subsets of KB facts downsampled to 10%, 30%, 50%, 100%).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Reported across settings (Hits@1 / F1): WikiMovies-10K GN-EF (KB+Text early fusion): e.g. 100% KB: 96.9 / 94.1 (Hits@1 / F1); 50% KB: 87.6 / 76.2; 10% KB: 75.4 / 66.3. WebQuestionsSP GN-EF: 100% KB: 67.8 / 60.4; 50% KB: 49.9 / 34.7; 10% KB: 31.5 / 17.7. (Values as reported in Table 2 of the paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Neural-only baselines reported in paper (examples): GN-KB (GRAFT-Net using KB only): WikiMovies 100% KB: 97.0 / 97.6 (Hits@1 / F1); WebQuestionsSP 100% KB: 66.7 / 62.4. GN (text-only) listed as GN-LF/text-only: WikiMovies text-only GN-LF: 73.2 / 64.0; WebQuestionsSP text-only GN-LF: 25.3 / 15.3. (These represent GRAFT-Net variants restricted to a single modality.)</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>GRAFT-Net generalizes across KB completeness regimes: early-fusion GRAFT-Net outperforms late-fusion and memory-network baselines especially when the KB is incomplete, showing robustness to missing KB facts by exploiting text; as KB completeness increases, the marginal benefit of text decreases. The directed propagation mechanism encourages compositional multi-hop reasoning from question seeds, improving multi-step inference compared to undirected/agnostic propagation (ablation shows directed propagation and relation attention both contribute). Out-of-distribution/generalization claims beyond these dataset splits are not formally proven in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Partial interpretability via explicit graph structure and learned attention/PageRank scalars: attention weights α_r^{v'} over outgoing relation types and scalar PageRank scores pr_v^(l) indicate which relation-edges and paths are being emphasized during propagation, offering interpretable signals about which KB edges and document mentions contributed to predictions. However, the overall decision is produced by dense embeddings and FFNs/LSTMs, so explanations are soft (attention/score based), not symbolic derivations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Limitations identified in the paper: (1) performance constrained by subgraph retrieval recall (e.g., KB-only subgraph recall <100% limits max performance); (2) struggles on queries that require strict constraint reasoning (e.g., superlatives or extra constraints) and when thresholding for variable-size answer sets is not tuned per-question; (3) dependence on entity-linking quality; (4) potential heavy memory/computation for large subgraphs (mitigated by using relation vectors rather than full relation matrices); (5) as KB completeness increases, the advantage of text diminishes; (6) some failure cases show missing or extra answers when answer sets are multi-valued.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>No formal mathematical theory is presented; the design is motivated by complementary strengths: the paper argues for a division of labor where symbolic KB structure provides easily queryable relations and text provides broad coverage, and their hybrid is realized through graph message passing localized by personalized PageRank and question-conditioned attention — framed as an instantiation of message-passing neural networks (MPNN) extended to heterogeneous nodes and directed propagation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e648.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e648.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KV-MemNN (KV-EF)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Key-Value Memory Networks (early-fusion variant used with KB+Text)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory-network-based neural architecture that stores both KB triples and text snippets as key-value memories and answers questions by attending over and reading from these memories; in this paper used as an early-fusion baseline combining KB and text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Key-value memory networks for directly reading documents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KV-MemNN (early fusion variant)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>KV-MemNN populates a memory module with entries derived independently from KB facts and text sentences: keys encode context (e.g., sentence embeddings or KB triple keys) and values encode candidate answers (e.g., entities). The question embedding attends over these keys to retrieve values; multiple hops can be applied via stacked attention. In the early-fusion variant (KV-EF) both KB facts and text sentences are placed into the same memory and jointly attended.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>KB facts and KB-derived tuples/triples converted into key-value records (KB represented as tuples inserted into memory), effectively a structured knowledge store encoded as neural memory entries rather than as an explicit symbolic graph during reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural Key-Value Memory Network: neural encoders (BiLSTM for sentences in text keys), attention-based retrieval over memories, and stacked/nested memory hops trained with gradient descent.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Early fusion by populating a single memory module with entries derived from both KB triples and text snippets; integration occurs at the attention/readout stage where the same attention mechanism scores KB and text memories. This is a modular but end-to-end trained neural approach (in the paper the authors re-implement and train KV-EF).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Can retrieve answers from both KB and text in a unified attention-based retrieval process, allowing cross-source attention weights; however, it treats each memory (fact or sentence) independently and thus does not exploit explicit relational graph structure across facts and text, limiting the ability to follow multi-hop relational paths across KB facts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Open-domain Question Answering over combined KB and text; evaluated in this paper on WikiMovies and WebQuestionsSP (same subgraph retrieval settings as GRAFT-Net).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Reported (Hits@1 / F1): WikiMovies-10K KV-EF: text-only 50.4 / 40.9; KB+Text varying completeness e.g. 100% KB: 93.8 / 81.4; 10% KB: 53.6 / 44.0. WebQuestionsSP KV-EF: text-only 23.2 / 13.0; 100% KB: 40.5 / 30.9. (Values from Table 2 and Table 4 in paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Neural-only variants used for comparison: KV-KB (KB-only): WikiMovies 100% KB: 94.3 / 76.1; WebQuestionsSP 100% KB: 46.7 / 38.6. KV (text-only) reimplementation: WikiMovies doc-only 76.2 / - (Table 4), KV* text doc: 80.3 / 72.1 (re-implemented).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>KV-EF can leverage text to improve recall when KB is incomplete (improves over KV-KB at low KB completeness), but when KB is complete KV-EF can underperform or not improve much because memory attention treats memories independently and cannot easily aggregate relational multi-hop evidence; thus KV-EF generalizes less well for multi-hop relational reasoning compared to graph-based models.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Moderate: attention weights over memory slots indicate which facts or sentences contributed to an answer, but because relations and multi-hop structure are not explicitly modeled, deriving path-like symbolic explanations is limited.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Key limitations noted in the paper: ignores relational structure connecting facts and text (so poorly suited for multi-hop reasoning over KB chains), attention normalization over memories can prevent assigning high probability to multiple supporting facts simultaneously, and overall inferior to graph-based early-fusion (GRAFT-Net) on the combined setting.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Not elaborated in this paper beyond the standard memory-network framing; the paper notes KV-MemNNs use universal schema to populate memory but lack explicit graph-propagation mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e648.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e648.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NSM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Symbolic Machines (NSM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-symbolic system that learns to generate executable programs (logical forms) to query a KB using weak supervision, combining neural sequence models with symbolic execution over a KB.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Symbolic Machines (NSM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NSM uses an encoder-decoder neural architecture to produce program-like logical forms (a sequence of tokens representing queries) which are executed against a symbolic KB (Freebase) by a deterministic executor; training is done with weak supervision (denotations) and augmentation strategies (reinforcement learning). The system tightly couples neural program generation with symbolic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic query language / executable logical forms evaluated deterministically against a structured KB (Freebase); symbolic execution retrieves answers exactly given the program.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural sequence-to-sequence or program-generation model that learns to produce programs/logical forms conditioned on the question; trained with reinforcement/weak supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybrid neural-symbolic pipeline: neural program generator (imperative) produces symbolic programs which are executed by a deterministic symbolic executor over the KB; training couples the two via weak supervision/reward signals (not end-to-end differentiable through executor).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Exact symbolic execution provides deterministic retrieval and precise adherence to logical constraints (good for constrained queries and variable-sized answer sets) while the neural generator allows learning to map natural language to programs; this leads to strong KB-only QA performance on constrained queries.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Knowledge-base question answering; reported in this paper as a comparison on WebQuestionsSP (KB-only).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Reported in Table 4 (as cited): WebQuestionsSP (KB-only): 69.0 (F1) (the table reports NSM: - / 69.0 in the KB column; the paper cites NSM's KB-only performance).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Not analyzed in detail in this paper; NSM's strength is precise handling of compositional queries via symbolic execution but may suffer when KB subgraph retrieval misses required entities or when natural language paraphrases are diverse; the GRAFT-Net paper suggests NSM outperforms GRAFT-Net in one KB-only setting but attributes part of the gap to subgraph recall and thresholding issues.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability for the symbolic execution portion: produced logical forms and execution traces are explicit and human-interpretable; neural generator still opaque but outputs an explicit program.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Mentioned in the paper as outperforming GRAFT-Net on WebQuestionsSP KB-only setting, but GRAFT-Net analysis notes that subgraph retrieval recall limits neural approaches; NSM may require high-quality entity linking and may be brittle to language variations outside its training distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Neural program induction + symbolic execution framework (neural generator + discrete executor) as described in the NSM literature; not further formalized in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e648.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e648.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Universal Schema</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Universal Schema (matrix-factorization approach to joint KB+text embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representation learning approach that embeds both KB relations and textual relations in a shared space (universal schema) so that KB completion and relation extraction can leverage both structured and unstructured evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Relation extraction with matrix factorization and universal schemas</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Universal Schema (as used with memory networks)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Universal schema creates a joint embedding space for KB relations and surface textual patterns; in QA contexts it can be used to populate memory modules with entries that encode both KB triples and textual relation patterns, enabling retrieval across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>KB relations and triples (structured facts) represented as parts of a joint relation matrix; symbolic KB is encoded as entries in the universal schema.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural embedding/matrix-factorization techniques (learning distributed representations for relation cells), and used in combination with memory-network-style attention (in related work Das et al., 2017c).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Integration by embedding both KB relations and textual patterns into a joint latent matrix (universal schema), then using these learned embeddings as neural memory keys/values (early fusion into a memory network).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Allows transfer between textual patterns and KB relations, improving relation extraction/answer retrieval where direct KB coverage is missing by leveraging paraphrases learned from text; however, it does not explicitly model multi-hop relational structure across KB facts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Relation extraction / KB completion and used as a component in QA over KB and text (cited in the paper as part of prior early-fusion approaches).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Enables generalization across textual paraphrases and KB relations by sharing parameters in the joint embedding; not directly evaluated in this paper for QA performance beyond its use in cited prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Embeddings are dense and not directly interpretable; mapping between textual surface forms and relations is indirect via learned vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Does not exploit explicit relational graph topology for compositional multi-hop reasoning; memory-based deployments ignore inter-memory relational structure.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Matrix factorization / joint embedding of KB relations and textual patterns into a universal schema; motivates early fusion by representing both sources in a common latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e648.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e648.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MINERVA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MINERVA (reinforcement-learning-based path-walking KB reasoner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reinforcement-learning agent that learns to walk over a knowledge graph (KB) following relation paths to reach answer entities, thus performing multi-hop reasoning over the symbolic KB guided by a neural policy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MINERVA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MINERVA frames multi-hop KB reasoning as a sequential decision process: a neural policy (e.g., RNN-based) conditions on the question and the current entity and decides which outgoing relation edge to traverse next; rollouts terminate at candidate answer entities and training is via reinforcement learning (policy gradient) using reward from correct answers.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Structured KB graph providing nodes and labeled relation edges which are traversed deterministically by the environment/executor during policy rollouts.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural sequential policy (RNN/agent) trained with reinforcement learning to select relations (actions) to traverse the KB graph.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybridization via a learned neural policy that interacts with a symbolic KB environment through discrete actions (edge traversals); integration is procedural (policy-driven) and training uses RL signals rather than differentiable end-to-end supervision through the symbolic executor.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Learns to perform multi-hop compositional path-based reasoning and to discover useful relation-path patterns for answering questions without requiring explicit program supervision; can generalize to multi-step relation chains by learning policies that compose relations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Knowledge-base question answering (KB-only); evaluated in the paper's related-results table (compared on WikiMovies).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Reported in Table 4 for WikiMovies (KB-only): MINERVA: 97.0 (Hits@1) / - (F1 not reported in table cell).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Demonstrates learned compositional path-following behavior enabling multi-hop reasoning; generalization depends on training signal and exploration—paper does not analyze OOD generalization in depth.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Reasoning is partially interpretable via the relation paths the agent chooses (explicit traversed paths can be inspected), giving more interpretable traces than black-box embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires good subgraph retrieval or access to relevant KB neighbourhoods; training with RL can be fragile and sensitive to reward shaping/exploration; in combined KB+text settings MINERVA alone does not incorporate text evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Reinforcement-learning framing of multi-hop KB reasoning: policy network interacts with symbolic KB transitions; cited as complementary prior work motivating graph-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e648.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e648.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>R-GCN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Relational Graph Convolutional Network (R-GCN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph neural network architecture that performs relational message passing on multi-relational graphs by using relation-specific linear transformations, applied for modeling KBs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Modeling relational data with graph convolutional networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>R-GCN</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>R-GCN extends graph convolution by using relation-specific weight matrices to transform neighbor node embeddings before aggregation, enabling learning on directed multi-relational graphs (KBs). It is primarily a neural model operating over KB graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Knowledge base represented as a multi-relational graph (entities and labeled edges); relations are used to index relation-specific transformation weights in the neural aggregator.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural relational graph convolutional layers (learned relation-specific linear transforms and aggregation), trained with gradient-based optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Applies neural message passing over explicit symbolic KB structure (graph); in the context of this paper R-GCN is cited as a KB-only neural model and used for comparative evaluation (not combined with text in the cited results).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Captures relational patterns via learned relation-specific transformations enabling strong performance on KB-only reasoning/prediction; however, standard R-GCN does not natively ingest raw text tokens or entity-linked sentences.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used for KB-only QA/KB modeling; reported in Table 4 as a KB-only baseline on WikiMovies and WebQuestionsSP.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Reported (re-implemented R-GCN*): WikiMovies (KB-only) 96.5 / 97.4 (Hits@1 / F1); WebQuestionsSP KB-only 37.2 / 30.5 (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Inductive representation learning capability noted (can generalize to unseen nodes with GraphSAGE-style inductive setups in related work), but not analyzed for cross-modal generalization in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Weights are relation-specific which can aid some interpretability of how relations transform messages, but learned dense transforms are not directly symbolic explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Does not directly consume unstructured text or entity mentions; when used alone on QA tasks that require external textual evidence, performance can be limited.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Relational extension of graph convolutional networks; viewed as an instance of message-passing neural networks for multi-relational data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text', 'publication_date_yy_mm': '2018-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Question answering on knowledge bases and text using universal schema and memory networks <em>(Rating: 2)</em></li>
                <li>Key-value memory networks for directly reading documents <em>(Rating: 2)</em></li>
                <li>Neural symbolic machines: Learning semantic parsers on freebase with weak supervision <em>(Rating: 2)</em></li>
                <li>Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning <em>(Rating: 2)</em></li>
                <li>Modeling relational data with graph convolutional networks <em>(Rating: 2)</em></li>
                <li>Relation extraction with matrix factorization and universal schemas <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-648",
    "paper_id": "paper-8d17543c20f23b6a40bec9334d50e9c15a08c1c4",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "GRAFT-Net",
            "name_full": "Graphs of Relations Among Facts and Text Networks (GRAFT-Net)",
            "brief_description": "A graph-convolutional neural network that performs early fusion of a symbolic knowledge base (KB) and entity-linked text by operating on a heterogeneous question-specific subgraph of KB entities, relations and text sentence tokens to directly classify answer nodes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GRAFT-Net",
            "system_description": "GRAFT-Net constructs a heterogeneous subgraph for each question containing KB entities and relations, text sentences (as document nodes with token-level LSTM representations), and entity-link edges. It learns node representations with layer-wise message passing that uses (a) heterogeneous update rules for entity nodes (feed-forward layers aggregating neighbor entity messages, mentions from text tokens, and a question representation) and for document nodes (token-wise aggregation of linked entity states followed by an LSTM over positions), and (b) directed, question-conditioned propagation controlled by scalar personalized PageRank scores and attention over relation types. The final node embeddings are used with a sigmoid classifier to predict answer entities.",
            "declarative_component": "A symbolic Knowledge Base (KB) represented as a directed multi-relational graph: entities V, relation triplets (s, r, o) in E, and explicit entity-links between KB entities and positions in text; relations are represented with learned relation vectors x_r and a special linking relation r_L.",
            "imperative_component": "Neural graph-based message-passing network: token-level LSTMs for document initialization and intra-document propagation, feed-forward networks (FFNs) for entity updates and edge transformations, relation-attention mechanisms, and gradient-based end-to-end learning (binary cross-entropy). Also uses PageRank-style scalar propagation computed iteratively (deterministic procedural update but learned attention used inside).",
            "integration_method": "Early fusion into a single heterogeneous graph (KB facts, text tokens, and linking edges) processed end-to-end by a neural message-passing architecture. Integration specifics: (1) heterogeneous update rules keep text and KB updates distinct (LSTM for text tokens, FFN for entities), (2) attention over relation vectors x_r conditions message propagation on the question, (3) personalized/directed propagation via scalar PageRank scores pr_v^(l) localizes multi-hop propagation starting from question seed entities, and (4) fact-dropout randomly drops edges during training to encourage using both sources.",
            "emergent_properties": "Combines structured KB connectivity and rich unstructured text representations to (a) perform multi-hop, question-conditioned reasoning along relational paths while also leveraging textual evidence for entities not present in the KB; (b) localize propagation from question seeds enabling focused multi-step inference across modalities; (c) disambiguate multiple entities co-mentioned in the same text via position-aware token-level updates; and (d) better aggregate multiple supporting facts across KB and text versus late fusion baselines. These behaviors emerge from the interaction of symbolic graph structure (declarative) and learned neural message passing (imperative).",
            "task_or_benchmark": "Open-domain Question Answering over combined KB and entity-linked text; evaluated on WikiMovies (various KB completeness settings) and WebQuestionsSP (with subsets of KB facts downsampled to 10%, 30%, 50%, 100%).",
            "hybrid_performance": "Reported across settings (Hits@1 / F1): WikiMovies-10K GN-EF (KB+Text early fusion): e.g. 100% KB: 96.9 / 94.1 (Hits@1 / F1); 50% KB: 87.6 / 76.2; 10% KB: 75.4 / 66.3. WebQuestionsSP GN-EF: 100% KB: 67.8 / 60.4; 50% KB: 49.9 / 34.7; 10% KB: 31.5 / 17.7. (Values as reported in Table 2 of the paper.)",
            "declarative_only_performance": null,
            "imperative_only_performance": "Neural-only baselines reported in paper (examples): GN-KB (GRAFT-Net using KB only): WikiMovies 100% KB: 97.0 / 97.6 (Hits@1 / F1); WebQuestionsSP 100% KB: 66.7 / 62.4. GN (text-only) listed as GN-LF/text-only: WikiMovies text-only GN-LF: 73.2 / 64.0; WebQuestionsSP text-only GN-LF: 25.3 / 15.3. (These represent GRAFT-Net variants restricted to a single modality.)",
            "has_comparative_results": true,
            "generalization_properties": "GRAFT-Net generalizes across KB completeness regimes: early-fusion GRAFT-Net outperforms late-fusion and memory-network baselines especially when the KB is incomplete, showing robustness to missing KB facts by exploiting text; as KB completeness increases, the marginal benefit of text decreases. The directed propagation mechanism encourages compositional multi-hop reasoning from question seeds, improving multi-step inference compared to undirected/agnostic propagation (ablation shows directed propagation and relation attention both contribute). Out-of-distribution/generalization claims beyond these dataset splits are not formally proven in the paper.",
            "interpretability_properties": "Partial interpretability via explicit graph structure and learned attention/PageRank scalars: attention weights α_r^{v'} over outgoing relation types and scalar PageRank scores pr_v^(l) indicate which relation-edges and paths are being emphasized during propagation, offering interpretable signals about which KB edges and document mentions contributed to predictions. However, the overall decision is produced by dense embeddings and FFNs/LSTMs, so explanations are soft (attention/score based), not symbolic derivations.",
            "limitations_or_failures": "Limitations identified in the paper: (1) performance constrained by subgraph retrieval recall (e.g., KB-only subgraph recall &lt;100% limits max performance); (2) struggles on queries that require strict constraint reasoning (e.g., superlatives or extra constraints) and when thresholding for variable-size answer sets is not tuned per-question; (3) dependence on entity-linking quality; (4) potential heavy memory/computation for large subgraphs (mitigated by using relation vectors rather than full relation matrices); (5) as KB completeness increases, the advantage of text diminishes; (6) some failure cases show missing or extra answers when answer sets are multi-valued.",
            "theoretical_framework": "No formal mathematical theory is presented; the design is motivated by complementary strengths: the paper argues for a division of labor where symbolic KB structure provides easily queryable relations and text provides broad coverage, and their hybrid is realized through graph message passing localized by personalized PageRank and question-conditioned attention — framed as an instantiation of message-passing neural networks (MPNN) extended to heterogeneous nodes and directed propagation.",
            "uuid": "e648.0",
            "source_info": {
                "paper_title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "KV-MemNN (KV-EF)",
            "name_full": "Key-Value Memory Networks (early-fusion variant used with KB+Text)",
            "brief_description": "A memory-network-based neural architecture that stores both KB triples and text snippets as key-value memories and answers questions by attending over and reading from these memories; in this paper used as an early-fusion baseline combining KB and text.",
            "citation_title": "Key-value memory networks for directly reading documents",
            "mention_or_use": "use",
            "system_name": "KV-MemNN (early fusion variant)",
            "system_description": "KV-MemNN populates a memory module with entries derived independently from KB facts and text sentences: keys encode context (e.g., sentence embeddings or KB triple keys) and values encode candidate answers (e.g., entities). The question embedding attends over these keys to retrieve values; multiple hops can be applied via stacked attention. In the early-fusion variant (KV-EF) both KB facts and text sentences are placed into the same memory and jointly attended.",
            "declarative_component": "KB facts and KB-derived tuples/triples converted into key-value records (KB represented as tuples inserted into memory), effectively a structured knowledge store encoded as neural memory entries rather than as an explicit symbolic graph during reasoning.",
            "imperative_component": "Neural Key-Value Memory Network: neural encoders (BiLSTM for sentences in text keys), attention-based retrieval over memories, and stacked/nested memory hops trained with gradient descent.",
            "integration_method": "Early fusion by populating a single memory module with entries derived from both KB triples and text snippets; integration occurs at the attention/readout stage where the same attention mechanism scores KB and text memories. This is a modular but end-to-end trained neural approach (in the paper the authors re-implement and train KV-EF).",
            "emergent_properties": "Can retrieve answers from both KB and text in a unified attention-based retrieval process, allowing cross-source attention weights; however, it treats each memory (fact or sentence) independently and thus does not exploit explicit relational graph structure across facts and text, limiting the ability to follow multi-hop relational paths across KB facts.",
            "task_or_benchmark": "Open-domain Question Answering over combined KB and text; evaluated in this paper on WikiMovies and WebQuestionsSP (same subgraph retrieval settings as GRAFT-Net).",
            "hybrid_performance": "Reported (Hits@1 / F1): WikiMovies-10K KV-EF: text-only 50.4 / 40.9; KB+Text varying completeness e.g. 100% KB: 93.8 / 81.4; 10% KB: 53.6 / 44.0. WebQuestionsSP KV-EF: text-only 23.2 / 13.0; 100% KB: 40.5 / 30.9. (Values from Table 2 and Table 4 in paper.)",
            "declarative_only_performance": null,
            "imperative_only_performance": "Neural-only variants used for comparison: KV-KB (KB-only): WikiMovies 100% KB: 94.3 / 76.1; WebQuestionsSP 100% KB: 46.7 / 38.6. KV (text-only) reimplementation: WikiMovies doc-only 76.2 / - (Table 4), KV* text doc: 80.3 / 72.1 (re-implemented).",
            "has_comparative_results": true,
            "generalization_properties": "KV-EF can leverage text to improve recall when KB is incomplete (improves over KV-KB at low KB completeness), but when KB is complete KV-EF can underperform or not improve much because memory attention treats memories independently and cannot easily aggregate relational multi-hop evidence; thus KV-EF generalizes less well for multi-hop relational reasoning compared to graph-based models.",
            "interpretability_properties": "Moderate: attention weights over memory slots indicate which facts or sentences contributed to an answer, but because relations and multi-hop structure are not explicitly modeled, deriving path-like symbolic explanations is limited.",
            "limitations_or_failures": "Key limitations noted in the paper: ignores relational structure connecting facts and text (so poorly suited for multi-hop reasoning over KB chains), attention normalization over memories can prevent assigning high probability to multiple supporting facts simultaneously, and overall inferior to graph-based early-fusion (GRAFT-Net) on the combined setting.",
            "theoretical_framework": "Not elaborated in this paper beyond the standard memory-network framing; the paper notes KV-MemNNs use universal schema to populate memory but lack explicit graph-propagation mechanisms.",
            "uuid": "e648.1",
            "source_info": {
                "paper_title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "NSM",
            "name_full": "Neural Symbolic Machines (NSM)",
            "brief_description": "A neural-symbolic system that learns to generate executable programs (logical forms) to query a KB using weak supervision, combining neural sequence models with symbolic execution over a KB.",
            "citation_title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "mention_or_use": "mention",
            "system_name": "Neural Symbolic Machines (NSM)",
            "system_description": "NSM uses an encoder-decoder neural architecture to produce program-like logical forms (a sequence of tokens representing queries) which are executed against a symbolic KB (Freebase) by a deterministic executor; training is done with weak supervision (denotations) and augmentation strategies (reinforcement learning). The system tightly couples neural program generation with symbolic execution.",
            "declarative_component": "Symbolic query language / executable logical forms evaluated deterministically against a structured KB (Freebase); symbolic execution retrieves answers exactly given the program.",
            "imperative_component": "Neural sequence-to-sequence or program-generation model that learns to produce programs/logical forms conditioned on the question; trained with reinforcement/weak supervision.",
            "integration_method": "Hybrid neural-symbolic pipeline: neural program generator (imperative) produces symbolic programs which are executed by a deterministic symbolic executor over the KB; training couples the two via weak supervision/reward signals (not end-to-end differentiable through executor).",
            "emergent_properties": "Exact symbolic execution provides deterministic retrieval and precise adherence to logical constraints (good for constrained queries and variable-sized answer sets) while the neural generator allows learning to map natural language to programs; this leads to strong KB-only QA performance on constrained queries.",
            "task_or_benchmark": "Knowledge-base question answering; reported in this paper as a comparison on WebQuestionsSP (KB-only).",
            "hybrid_performance": "Reported in Table 4 (as cited): WebQuestionsSP (KB-only): 69.0 (F1) (the table reports NSM: - / 69.0 in the KB column; the paper cites NSM's KB-only performance).",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Not analyzed in detail in this paper; NSM's strength is precise handling of compositional queries via symbolic execution but may suffer when KB subgraph retrieval misses required entities or when natural language paraphrases are diverse; the GRAFT-Net paper suggests NSM outperforms GRAFT-Net in one KB-only setting but attributes part of the gap to subgraph recall and thresholding issues.",
            "interpretability_properties": "High interpretability for the symbolic execution portion: produced logical forms and execution traces are explicit and human-interpretable; neural generator still opaque but outputs an explicit program.",
            "limitations_or_failures": "Mentioned in the paper as outperforming GRAFT-Net on WebQuestionsSP KB-only setting, but GRAFT-Net analysis notes that subgraph retrieval recall limits neural approaches; NSM may require high-quality entity linking and may be brittle to language variations outside its training distribution.",
            "theoretical_framework": "Neural program induction + symbolic execution framework (neural generator + discrete executor) as described in the NSM literature; not further formalized in this paper.",
            "uuid": "e648.2",
            "source_info": {
                "paper_title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "Universal Schema",
            "name_full": "Universal Schema (matrix-factorization approach to joint KB+text embeddings)",
            "brief_description": "A representation learning approach that embeds both KB relations and textual relations in a shared space (universal schema) so that KB completion and relation extraction can leverage both structured and unstructured evidence.",
            "citation_title": "Relation extraction with matrix factorization and universal schemas",
            "mention_or_use": "mention",
            "system_name": "Universal Schema (as used with memory networks)",
            "system_description": "Universal schema creates a joint embedding space for KB relations and surface textual patterns; in QA contexts it can be used to populate memory modules with entries that encode both KB triples and textual relation patterns, enabling retrieval across modalities.",
            "declarative_component": "KB relations and triples (structured facts) represented as parts of a joint relation matrix; symbolic KB is encoded as entries in the universal schema.",
            "imperative_component": "Neural embedding/matrix-factorization techniques (learning distributed representations for relation cells), and used in combination with memory-network-style attention (in related work Das et al., 2017c).",
            "integration_method": "Integration by embedding both KB relations and textual patterns into a joint latent matrix (universal schema), then using these learned embeddings as neural memory keys/values (early fusion into a memory network).",
            "emergent_properties": "Allows transfer between textual patterns and KB relations, improving relation extraction/answer retrieval where direct KB coverage is missing by leveraging paraphrases learned from text; however, it does not explicitly model multi-hop relational structure across KB facts.",
            "task_or_benchmark": "Relation extraction / KB completion and used as a component in QA over KB and text (cited in the paper as part of prior early-fusion approaches).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Enables generalization across textual paraphrases and KB relations by sharing parameters in the joint embedding; not directly evaluated in this paper for QA performance beyond its use in cited prior work.",
            "interpretability_properties": "Embeddings are dense and not directly interpretable; mapping between textual surface forms and relations is indirect via learned vectors.",
            "limitations_or_failures": "Does not exploit explicit relational graph topology for compositional multi-hop reasoning; memory-based deployments ignore inter-memory relational structure.",
            "theoretical_framework": "Matrix factorization / joint embedding of KB relations and textual patterns into a universal schema; motivates early fusion by representing both sources in a common latent space.",
            "uuid": "e648.3",
            "source_info": {
                "paper_title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "MINERVA",
            "name_full": "MINERVA (reinforcement-learning-based path-walking KB reasoner)",
            "brief_description": "A reinforcement-learning agent that learns to walk over a knowledge graph (KB) following relation paths to reach answer entities, thus performing multi-hop reasoning over the symbolic KB guided by a neural policy.",
            "citation_title": "Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning",
            "mention_or_use": "mention",
            "system_name": "MINERVA",
            "system_description": "MINERVA frames multi-hop KB reasoning as a sequential decision process: a neural policy (e.g., RNN-based) conditions on the question and the current entity and decides which outgoing relation edge to traverse next; rollouts terminate at candidate answer entities and training is via reinforcement learning (policy gradient) using reward from correct answers.",
            "declarative_component": "Structured KB graph providing nodes and labeled relation edges which are traversed deterministically by the environment/executor during policy rollouts.",
            "imperative_component": "Neural sequential policy (RNN/agent) trained with reinforcement learning to select relations (actions) to traverse the KB graph.",
            "integration_method": "Hybridization via a learned neural policy that interacts with a symbolic KB environment through discrete actions (edge traversals); integration is procedural (policy-driven) and training uses RL signals rather than differentiable end-to-end supervision through the symbolic executor.",
            "emergent_properties": "Learns to perform multi-hop compositional path-based reasoning and to discover useful relation-path patterns for answering questions without requiring explicit program supervision; can generalize to multi-step relation chains by learning policies that compose relations.",
            "task_or_benchmark": "Knowledge-base question answering (KB-only); evaluated in the paper's related-results table (compared on WikiMovies).",
            "hybrid_performance": "Reported in Table 4 for WikiMovies (KB-only): MINERVA: 97.0 (Hits@1) / - (F1 not reported in table cell).",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Demonstrates learned compositional path-following behavior enabling multi-hop reasoning; generalization depends on training signal and exploration—paper does not analyze OOD generalization in depth.",
            "interpretability_properties": "Reasoning is partially interpretable via the relation paths the agent chooses (explicit traversed paths can be inspected), giving more interpretable traces than black-box embeddings.",
            "limitations_or_failures": "Requires good subgraph retrieval or access to relevant KB neighbourhoods; training with RL can be fragile and sensitive to reward shaping/exploration; in combined KB+text settings MINERVA alone does not incorporate text evidence.",
            "theoretical_framework": "Reinforcement-learning framing of multi-hop KB reasoning: policy network interacts with symbolic KB transitions; cited as complementary prior work motivating graph-based approaches.",
            "uuid": "e648.4",
            "source_info": {
                "paper_title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text",
                "publication_date_yy_mm": "2018-09"
            }
        },
        {
            "name_short": "R-GCN",
            "name_full": "Relational Graph Convolutional Network (R-GCN)",
            "brief_description": "A graph neural network architecture that performs relational message passing on multi-relational graphs by using relation-specific linear transformations, applied for modeling KBs.",
            "citation_title": "Modeling relational data with graph convolutional networks",
            "mention_or_use": "mention",
            "system_name": "R-GCN",
            "system_description": "R-GCN extends graph convolution by using relation-specific weight matrices to transform neighbor node embeddings before aggregation, enabling learning on directed multi-relational graphs (KBs). It is primarily a neural model operating over KB graph structure.",
            "declarative_component": "Knowledge base represented as a multi-relational graph (entities and labeled edges); relations are used to index relation-specific transformation weights in the neural aggregator.",
            "imperative_component": "Neural relational graph convolutional layers (learned relation-specific linear transforms and aggregation), trained with gradient-based optimization.",
            "integration_method": "Applies neural message passing over explicit symbolic KB structure (graph); in the context of this paper R-GCN is cited as a KB-only neural model and used for comparative evaluation (not combined with text in the cited results).",
            "emergent_properties": "Captures relational patterns via learned relation-specific transformations enabling strong performance on KB-only reasoning/prediction; however, standard R-GCN does not natively ingest raw text tokens or entity-linked sentences.",
            "task_or_benchmark": "Used for KB-only QA/KB modeling; reported in Table 4 as a KB-only baseline on WikiMovies and WebQuestionsSP.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": "Reported (re-implemented R-GCN*): WikiMovies (KB-only) 96.5 / 97.4 (Hits@1 / F1); WebQuestionsSP KB-only 37.2 / 30.5 (Table 4).",
            "has_comparative_results": false,
            "generalization_properties": "Inductive representation learning capability noted (can generalize to unseen nodes with GraphSAGE-style inductive setups in related work), but not analyzed for cross-modal generalization in this paper.",
            "interpretability_properties": "Weights are relation-specific which can aid some interpretability of how relations transform messages, but learned dense transforms are not directly symbolic explanations.",
            "limitations_or_failures": "Does not directly consume unstructured text or entity mentions; when used alone on QA tasks that require external textual evidence, performance can be limited.",
            "theoretical_framework": "Relational extension of graph convolutional networks; viewed as an instance of message-passing neural networks for multi-relational data.",
            "uuid": "e648.5",
            "source_info": {
                "paper_title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text",
                "publication_date_yy_mm": "2018-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Question answering on knowledge bases and text using universal schema and memory networks",
            "rating": 2
        },
        {
            "paper_title": "Key-value memory networks for directly reading documents",
            "rating": 2
        },
        {
            "paper_title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "rating": 2
        },
        {
            "paper_title": "Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Modeling relational data with graph convolutional networks",
            "rating": 2
        },
        {
            "paper_title": "Relation extraction with matrix factorization and universal schemas",
            "rating": 1
        }
    ],
    "cost": 0.018880249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text</h1>
<p>Haitian Sun<em> Bhuwan Dhingra</em> Manzil Zaheer Kathryn Mazaitis<br>Ruslan Salakhutdinov William W. Cohen<br>School of Computer Science<br>Carnegie Mellon University<br>{haitians, bdhingra,manzilz,krivard,rsalakhu,wcohen}@cs.cmu.edu</p>
<h4>Abstract</h4>
<p>Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entitylinked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting.</p>
<h2>1 Introduction</h2>
<p>Open domain Question Answering (QA) is the task of finding answers to questions posed in natural language. Historically, this required a specialized pipeline consisting of multiple machinelearned and hand-crafted modules (Ferrucci et al., 2010). Recently, the paradigm has shifted towards training end-to-end deep neural network models for the task (Chen et al., 2017; Liang et al., 2017; Raison et al., 2018; Talmor and Berant, 2018; Iyyer et al., 2017). Most existing models, however, answer questions using a single information source, usually either text from an encyclopedia, or a single knowledge base (KB).</p>
<p>Intuitively, the suitability of an information source for QA depends on both its coverage and</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: To answer a question posed in natural language, GRAFT-Net considers a heterogeneous graph constructed from text and KB facts, and thus can leverage the rich relational structure between the two information sources.
the difficulty of extracting answers from it. A large text corpus has high coverage, but the information is expressed using many different text patterns. As a result, models which operate on these patterns (e.g. BiDAF (Seo et al., 2017)) do not generalize beyond their training domains (Wiese et al., 2017; Dhingra et al., 2018) or to novel types of reasoning (Welbl et al., 2018; Talmor and Berant, 2018). KBs , on the other hand, suffer from low coverage due to their inevitable incompleteness and restricted schema (Min et al., 2013), but are easier to extract answers from, since they are constructed precisely for the purpose of being queried.</p>
<p>In practice, some questions are best answered using text, while others are best answered using KBs . A natural question, then, is how to effectively combine both types of information. Surprisingly little prior work has looked at this problem. In this paper we focus on a scenario in which a large-scale KB (Bollacker et al., 2008; Auer et al., 2007) and a text corpus are available, but neither is sufficient alone for answering all questions.</p>
<p>A naïve option, in such a setting, is to take state-of-the-art QA systems developed for each source, and aggregate their predictions using some heuristic (Ferrucci et al., 2010; Baudiš, 2015). We call this approach late fusion, and show that it can be sub-optimal, as models have limited ability to aggregate evidence across the different sources (§5.4). Instead, we focus on an early fusion strategy, where a single model is trained to extract answers from a question subgraph (Fig 1) containing relevant KB facts as well as text sentences. Early fusion allows more flexibility in combining information from multiple sources.</p>
<p>To enable early fusion, in this paper we propose a novel graph convolution based neural network, called GRAFT-Net (Graphs of Relations Among Facts and Text Networks), specifically designed to operate over heterogeneous graphs of KB facts and text sentences. We build upon recent work on graph representation learning (Kipf and Welling, 2016; Schlichtkrull et al., 2017), but propose two key modifications to adopt them for the task of QA. First, we propose heterogeneous update rules that handle KB nodes differently from the text nodes: for instance, LSTM-based updates are used to propagate information into and out of text nodes (§ 3.2). Second, we introduce a directed propagation method, inspired by personalized Pagerank in IR (Haveliwala, 2002), which constrains the propagation of embeddings in the graph to follow paths starting from seed nodes linked to the question (§ 3.3). Empirically, we show that both these extensions are crucial for the task of QA.</p>
<p>We evaluate these methods on a new suite of benchmark tasks for testing QA models when both KB and text are present. Using WikiMovies (Miller et al., 2016) and WebQuestionsSP (Yih et al., 2016), we construct datasets with a varying amount of training supervision and KB completeness, and with a varying degree of question complexity. We report baselines for future comparison, including Key Value Memory Networks (Miller et al., 2016; Das et al., 2017c), and show that our proposed GRAFT-Nets have superior performance across a wide range of conditions (§5). We also show that GRAFT-Nets are competitive with the state-of-the-art methods developed specifically for text-only QA, and state-of-the art methods developed for KB-only QA (§5.4) ${ }^{1}$.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>2 Task Setup</h2>
<h3>2.1 Description</h3>
<p>A knowledge base is denoted as $\mathcal{K}=(\mathcal{V}, \mathcal{E}, \mathcal{R})$, where $\mathcal{V}$ is the set of entities in the KB , and the edges $\mathcal{E}$ are triplets $(s, r, o)$ which denote that relation $r \in \mathcal{R}$ holds between the subject $s \in \mathcal{V}$ and object $o \in \mathcal{V}$. A text corpus $\mathcal{D}$ is a set of documents $\left{d_{1}, \ldots, d_{|\mathcal{D}|}\right}$ where each document is a sequence of words $d_{i}=\left(w_{1}, \ldots, w_{|d_{i}|}\right)$. We further assume that an (imperfect) entity linking system has been run on the collection of documents whose output is a set $\mathcal{L}$ of links $\left(v, d_{p}\right)$ connecting an entity $v \in \mathcal{V}$ with a word at position $p$ in document $d$, and we denote with $\mathcal{L}_{d}$ the set of all entity links in document $d$. For entity mentions spanning multiple words in $d$, we include links to all the words in the mention in $\mathcal{L}$.</p>
<p>The task is, given a natural language question $q=\left(w_{1}, \ldots, w_{|q|}\right)$, extract its answers ${a}_{q}$ from $\mathcal{G}=(\mathcal{K}, \mathcal{D}, \mathcal{L})$. There may be multiple correct answers for a question. In this paper, we assume that the answers are entities from either the documents or the KB. We are interested in a wide range of settings, where the KB $\mathcal{K}$ varies from highly incomplete to complete for answering the questions, and we will introduce datasets for testing our models under these settings.</p>
<p>To solve this task we proceed in two steps. First, we extract a subgraph $\mathcal{G}<em q="q">{q} \subset \mathcal{G}$ which contains the answer to the question with high probability. The goal for this step is to ensure high recall for answers while producing a graph small enough to fit into GPU memory for gradient-based learning. Next, we use our proposed model GRAFT-Net to learn node representations in $\mathcal{G}</em>$, conditioned on $q$, which are used to classify each node as being an answer or not. Training data for the second step is generated using distant supervision. The entire process mimics the search-and-read paradigm for text-based QA (Dhingra et al., 2017).</p>
<h3>2.2 Question Subgraph Retrieval</h3>
<p>We retrieve the subgraph $\mathcal{G}_{q}$ using two parallel pipelines - one over the KB $\mathcal{K}$ which returns a set of entities, and the other over the corpus $\mathcal{D}$ which returns a set of documents. The retrieved entities and documents are then combined with entity links to produce a fully-connected graph.</p>
<p>KB Retrieval. To retrieve relevant entities from the KB we first perform entity linking on the ques-</p>
<p>tion $q$, producing a set of seed entities, denoted $S_{q}$. Next we run the Personalized PageRank (PPR) method (Haveliwala, 2002) around these seeds to identify other entities which might be an answer to the question. The edge-weights around $S_{q}$ are distributed equally among all edges of the same type, and they are weighted such that edges relevant to the question receive a higher weight than those which are not. Specifically, we average word vectors to compute a relation vector $v(r)$ from the surface form of the relation, and a question vector $v(q)$ from the words in the question, and use cosine similarity between these as the edge weights. After running PPR we retain the top $E$ entities $v_{1}, \ldots, v_{E}$ by PPR score, along with any edges between them, and add them to $\mathcal{G}_{q}$.</p>
<p>Text Retrieval. We use Wikipedia as the corpus and retrieve text at the sentence level, i.e. documents in $\mathcal{D}$ are defined along sentences boundaries ${ }^{2}$. We perform text retrieval in two steps: first we retrieve the top 5 most relevant Wikipedia articles, using the weighted bag-of-words model from DrQA (Chen et al., 2017); then we populate a Lucene $^{3}$ index with sentences from these articles, and retrieve the top ranking ones $d_{1}, \ldots, d_{D}$, based on the words in the question. For the sentence-retrieval step, we found it beneficial to include the title of the article as an additional field in the Lucene index. As most sentences in an article talk about the title entity, this helps in retrieving relevant sentences that do not explicitly mention the entity in the question. We add the retrieved documents, along with any entities linked to them, to the subgraph $\mathcal{G}_{q}$.</p>
<p>The final question subgraph is $\mathcal{G}<em q="q">{q}=$ $\left(\mathcal{V}</em>}, \mathcal{E<em q="q">{q}, \mathcal{R}^{+}\right)$, where the vertices $\mathcal{V}</em>}$ consist of all the retrieved entities and documents, i.e. $\mathcal{V<em 1="1">{q}=\left{v</em>$ among these entities, plus the entity-links between documents and entities, i.e.}, \ldots, v_{E}\right} \cup\left{d_{1}, \ldots, d_{D}\right}$. The edges are all relations from $\mathcal{K</p>
<p>$$
\begin{aligned}
\mathcal{E}<em q="q">{q}= &amp; \left{(s, o, r) \in \mathcal{E}: s, o \in \mathcal{V}</em>\right} \
&amp; \cup\left{\left(v, d_{p}, r_{L}\right):\left(v, d_{p}\right) \in \mathcal{L}}, r \in \mathcal{R<em q="q">{d}, d \in \mathcal{V}</em>\right}
\end{aligned}
$$</p>
<p>where $r_{L}$ denotes a special "linking" relation. $\mathcal{R}^{+}=\mathcal{R} \cup\left{r_{L}\right}$ is the set of all edge types in the subgraph.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>3 GRAFT-Nets</h2>
<p>The question $q$ and its answers ${a}<em q="q">{q}$ induce a labeling of the nodes in $\mathcal{V}</em>=1$ if $v \in{a}}$ : we let $y_{v<em v="v">{q}$ and $y</em>}=0$ otherwise for all $v \in$ $\mathcal{V<em q="q">{q}$. The task of QA then reduces to performing binary classification over the nodes of the graph $\mathcal{G}</em>$. Several graph-propagation based models have been proposed in the literature which learn node representations and then perform classification of the nodes (Kipf and Welling, 2016; Schlichtkrull et al., 2017). Such models follow the standard gather-apply-scatter paradigm to learn the node representation with homogeneous updates, i.e. treating all neighbors equally.</p>
<p>The basic recipe for these models is as follows:</p>
<ol>
<li>Initialize node representations $h_{v}^{(0)}$.</li>
<li>For $l=1, \ldots, L$ update node representations</li>
</ol>
<p>$$
h_{v}^{(l)}=\phi\left(h_{v}^{(l-1)}, \sum_{v^{\prime} \in N_{r}(v)} h_{v^{\prime}}^{(l-1)}\right)
$$</p>
<p>where $N_{r}(v)$ denotes the neighbours of $v$ along incoming edges of type $r$, and $\phi$ is a neural network layer.</p>
<p>Here $L$ is the number of layers in the model and corresponds to the maximum length of the paths along which information should be propagated in the graph. Once the propagation is complete the final layer representations $h_{v}^{(L)}$ are used to perform the desired task, for example link prediction in knowledge bases (Schlichtkrull et al., 2017).</p>
<p>However, there are two differences in our setting from previously studied graph-based classification tasks. The first difference is that, in our case, the graph $\mathcal{G}_{q}$ consists of heterogeneous nodes. Some nodes in the graph correspond to KB entities which represent symbolic objects, whereas other nodes represent textual documents which are variable length sequences of words. The second difference is that we want to condition the representation of nodes in the graph on the natural language question $q$. In $\S 3.2$ we introduce heterogeneous updates to address the first difference, and in $\S 3.3$ we introduce mechanisms for conditioning on the question (and its entities) for the second.</p>
<h3>3.1 Node Initialization</h3>
<p>Nodes corresponding to entities are initialized using fixed-size vectors $h_{v}^{(0)}=x_{v} \in \mathbb{R}^{n}$, where</p>
<p>$x_{v}$ can be pre-trained KB embeddings or random, and $n$ is the embedding size. Document nodes in the graph describe a variable length sequence of text. Since multiple entities might link to different positions in the document, we maintain a variable length representation of the document in each layer. This is denoted by $H_{d}^{(l)} \in \mathbb{R}^{|d| \times n}$. Given the words in the document $\left(w_{1}, \ldots, w_{|d|}\right)$, we initialize its hidden representation as:</p>
<p>$$
H_{d}^{(0)}=\operatorname{LSTM}\left(w_{1}, w_{2}, \ldots\right)
$$</p>
<p>where LSTM refers to a long short-term memory unit. We denote the $p$-th row of $H_{d}^{(l)}$, corresponding to the embedding of $p$-th word in the document $d$ at layer $l$, as $H_{d, p}^{(l)}$.</p>
<h3>3.2 Heterogeneous Updates</h3>
<p>Figure 2 shows the update rules for entities and documents, which we describe in detail here.</p>
<p>Entities. Let $M(v)={(d, p)}$ be the set of positions $p$ in documents $d$ which correspond to a mention of entity $v$. The update for entity nodes involves a single-layer feed-forward network (FFN) over the concatenation of four states:
$h_{v}^{(l)}=\operatorname{FFN}\left(\left[\begin{array}{c} h_{v}^{(l-1)} \ h_{q}^{(l-1)} \ \sum_{r} \sum_{v^{\prime} \in N_{r}(v)} \alpha_{r}^{v^{\prime}} \psi_{r}\left(h_{v^{\prime}}^{(l-1)}\right) \ \sum_{(d, p) \in M(v)} H_{d, p}^{(l-1)}\end{array}\right]\right)$.
The first two terms correspond to the entity representation and question representation (details below), respectively, from the previous layer.</p>
<p>The third term aggregates the states from the entity neighbours of the current node, $N_{r}(v)$, after scaling with an attention weight $\alpha_{r}^{v^{\prime}}$ (described in the next section), and applying relation specific transformations $\psi_{r}$. Previous work on RelationalGraph Convolution Networks (Schlichtkrull et al., 2017) used a linear projection for $\psi_{r}$. For a batched implementation, this results in matrices of size $O\left(B\left|\mathcal{R}<em q="q">{q}\right| \mathcal{E}</em>$ instead of matrices, and compute the update along an edge as:}\right| n$ ), where $B$ is the batch size, which can be prohibitively large for large subgraphs ${ }^{4}$. Hence in this work we use relation vectors $x_{r}$ for $r \in \mathcal{R}_{q</p>
<p>$$
\psi_{r}\left(h_{v^{\prime}}^{(l-1)}\right)=p r_{v^{\prime}}^{(l-1)} \operatorname{FFN}\left(x_{r}, h_{v^{\prime}}^{(l-1)}\right)
$$</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Here $p r_{v^{\prime}}^{(l-1)}$ is a PageRank score used to control the propagation of embeddings along paths starting from the seed nodes, which we describe in detail in the next section. The memory complexity of the above is $O\left(B\left(\left|\mathcal{F}<em q="q">{q}\right|+\left|\mathcal{E}</em>}\right|\right) n\right)$, where $\left|\mathcal{F<em q="q">{q}\right|$ is the number of facts in the subgraph $\mathcal{G}</em>$.</p>
<p>The last term aggregates the states of all tokens that correspond to mentions of the entity $v$ among the documents in the subgraph. Note that the update depends on the positions of entities in their containing document.</p>
<p>Documents. Let $L(d, p)$ be the set of all entities linked to the word at position $p$ in document $d$. The document update proceeds in two steps. First we aggregate over the entity states coming in at each position separately:</p>
<p>$$
\tilde{H}<em d_="d," p="p">{d, p}^{(l)}=\operatorname{FFN}\left(H</em>\right)
$$}^{(l-1)}, \sum_{v \in L(d, p)} h_{v}^{(l-1)</p>
<p>Here $h_{v}^{(l-1)}$ are normalized by the number of outgoing edges at $v$. Next we aggregate states within the document using an LSTM:</p>
<p>$$
H_{d}^{(l)}=\operatorname{LSTM}\left(\tilde{H}_{d}^{(l)}\right)
$$</p>
<h3>3.3 Conditioning on the Question</h3>
<p>For the parts described thus far, the graph learner is largely agnostic of the question. We introduce dependence on question in two ways: by attention over relations, and by personalized propagation.</p>
<p>To represent $q$, let $w_{1}^{q}, \ldots, w_{|q|}^{q}$ be the words in the question. The initial representation is computed as:</p>
<p>$$
h_{q}^{(0)}=\operatorname{LSTM}\left(w_{1}^{q}, \ldots, w_{|q|}^{q}\right)_{|q|} \in \mathbb{R}^{n}
$$</p>
<p>where we extract the final state from the output of the LSTM. In subsequent layers the question representation is updated as $h_{q}^{(l)}=$ $\operatorname{FFN}\left(\sum_{v \in S_{q}} h_{v}^{(l)}\right)$, where $S_{q}$ denotes the seed entities mentioned in the question.</p>
<p>Attention over Relations. The attention weight in the third term of Eq. (1) is computed using the question and relation embeddings:</p>
<p>$$
\alpha_{r}^{v^{\prime}}=\operatorname{softmax}\left(x_{r}^{T} h_{q}^{(l-1)}\right)
$$</p>
<p>where the softmax normalization is over all outgoing edges from $v^{\prime}$, and $x_{r}$ is the relation vector for relation $r$. This ensures that embeddings are propagated more along edges relevant to the question.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Illustration of the heterogeneous update rules for entities (left) and text documents (right)</p>
<p><strong>Directed Propagation.</strong> Many questions require multi-hop reasoning, which follows a path from a seed node mentioned in the question to the target answer node. To encourage such a behaviour when propagating embeddings, we develop a technique inspired from personalized PageRank in IR (Haveliwala, 2002). The propagation starts at the seed entities $S_q$ mentioned in the question. In addition to the vector embeddings $h^<em>(l) v$ at the nodes, we also maintain scalar "PageRank" scores $pr^</em>(l) v$ which measure the total weight of paths from a seed entity to the current node, as follows:</p>
<p>$$
pr^*(0) = \begin{cases}
\frac{1}{|S_q|} &amp; \text{if } \quad v \in S_q \
0 &amp; \text{o.w.}
\end{cases}
$$</p>
<p>$$
pr^<em>(l) = (1 - \lambda)pr^</em>(l-1) + \lambda \sum_r \sum_{v' \in N_r(v)} \alpha_v^v' pr^*(l-1).
$$</p>
<p>Notice that we reuse the attention weights $\alpha_v^v'$ when propagating PageRank, to ensure that nodes along paths relevant to the question receive a high weight. The PageRank score is used as a scaling factor when propagating embeddings along the edges in Eq. (2). For $l = 1$, the PageRank score will be 0 for all entities except the seed entities, and hence propagation will only happen outward from these nodes. For $l = 2$, it will be non-zero for the seed entities and their 1-hop neighbors, and propagation will only happen along these edges. Figure 3 illustrates this process.</p>
<h3>3.4 Answer Selection</h3>
<p>The final representations $h^_(L) v \in \mathbb{R}^n$, are used for binary classification to select the answers:</p>
<p>$$
\Pr(v \in {a}<em>q | \mathcal{G}_q, q) = \sigma (w^T h^</em>(L) v + b),
$$</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Directed propagation of embeddings in GRAFT-Net. A scalar PageRank score $pr^<em>(l) v$ is maintained for each node $v$ across layers, which spreads out from the seed node. Embeddings are only propagated from nodes with $pr^</em>(l) v &gt; 0$.</p>
<p>where $\sigma$ is the sigmoid function. Training uses binary cross-entropy loss over these probabilities.</p>
<h3>3.5 Regularization via Fact Dropout</h3>
<p>To encourage the model to learn a robust classifier, which exploits all available sources of information, we randomly drop edges from the graph during training with probability $p_0$. We call this fact-dropout. It is usually easier to extract answers from the KB than from the documents, so the model tends to rely on the former, especially when the KB is complete. This method is similar to DropConnect (Wan et al., 2013).</p>
<h3>4 Related Work</h3>
<p>The work of Das et al. (2017c) attempts an early fusion strategy for QA over KB facts and text. Their approach is based on Key-Value Memory Networks (KV-MemNNs) (Miller et al., 2016) coupled with a universal schema (Riedel et al., 2013) to populate a memory module with representations of KB triples and text snippets independently. The key limitation for this model is that it ignores the rich relational structure between the</p>
<p>facts and text snippets. Our graph-based method, on the other hand, explicitly uses this structure for the propagation of embeddings. We compare the two approaches in our experiments (§5), and show that GRAFT-Nets outperform KV-MemNNs over all tasks.</p>
<p>Non-deep learning approaches have been also attempted for QA over both text assertions and KB facts. Gardner and Krishnamurthy (2017) use traditional feature extraction methods of openvocabulary semantic parsing for the task. Ryu et al. (2014) use a pipelined system aggregating evidence from both unstructured and semistructured sources for open-domain QA.</p>
<p>Another line of work has looked at learning combined representations of KBs and text for relation extraction and Knowledge Base Completion (KBC) (Lao et al., 2012; Riedel et al., 2013; Toutanova et al., 2015; Verga et al., 2016; Das et al., 2017b; Han et al., 2016). The key difference in QA compared to KBC is that in QA the inference process on the knowledge source has to be conditioned on the question, so different questions induce different representations of the KB and warrant a different inference process. Furthermore, KBC operates under the fixed schema defined by the KB before-hand, whereas natural language questions might not adhere to this schema.</p>
<p>The GRAFT-Net model itself is motivated from the large body of work on graph representation learning (Scarselli et al., 2009; Li et al., 2016; Kipf and Welling, 2016; Atwood and Towsley, 2016; Schlichtkrull et al., 2017). Like most other graph-based models, GRAFT-Nets can also be viewed as an instantiation of the Message Passing Neural Network (MPNN) framework of Gilmer et al. (2017). GRAFT-Nets are also inductive representation learners like GraphSAGE (Hamilton et al., 2017), but operate on a heterogeneous mixture of nodes and use retrieval for getting a subgraph instead of random sampling. The recently proposed Walk-Steered Convolution model uses random walks for learning graph representations (Jiang et al., 2018). Our personalization technique also borrows from such random walk literature, but uses it to localize propagation of embeddings.</p>
<p>Tremendous progress on QA over KB has been made with deep learning based approaches like memory networks (Bordes et al., 2015; Jain, 2016) and reinforcement learning (Liang et al., 2017; Das et al., 2017a). But extending them with text,
which is our main focus, is non-trivial. In another direction, there is also work on producing parsimonious graphical representations of textual data (Krause et al., 2016; Lu et al., 2017); however in this paper we use a simple sequential representation augmented with entity links to the KB which works well.</p>
<p>For QA over text only, a major focus has been on the task of reading comprehension (Seo et al., 2017; Gong and Bowman, 2017; Hu et al., 2017; Shen et al., 2017; Yu et al., 2018) since the introduction of SQuAD (Rajpurkar et al., 2016). These systems assume that the answer-containing passage is known apriori, but there has been progress when this assumption is relaxed (Chen et al., 2017; Raison et al., 2018; Dhingra et al., 2017; Wang et al., 2018, 2017; Watanabe et al., 2017). We work in the latter setting, where relevant information must be retrieved from large information sources, but we also incorporate KBs into this process.</p>
<h2>5 Experiments \&amp; Results</h2>
<h3>5.1 Datasets</h3>
<p>WikiMovies-10K consists of $10 K$ randomly sampled training questions from the WikiMovies dataset (Miller et al., 2016), along with the original test and validation sets. We sample the training questions to create a more difficult setting, since the original dataset has $100 K$ questions over only 8 different relation types, which is unrealistic in our opinion. In $\S 5.4$ we also compare to the existing state-of-the-art using the full training set.</p>
<p>We use the KB and text corpus constructed from Wikipedia released by Miller et al. (2016). For entity linking we use simple surface level matches, and retrieve the top 50 entities around the seeds to create the question subgraph. We further add the top 50 sentences (along with their article titles) to the subgraph using Lucene search over the text corpus. The overall answer recall in our constructed subgraphs is $99.6 \%$.
WebQuestionsSP (Yih et al., 2016) consists of 4737 natural language questions posed over Freebase entities, split up into 3098 training and 1639 test questions. We reserve 250 training questions for model development and early stopping. We use the entity linking outputs from S-MART ${ }^{5}$ and retrieve 500 entities from the neighbourhood around the question seeds in Freebase to populate the</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>question subgraphs ${ }^{6}$. We further retrieve the top 50 sentences from Wikipedia with the two-stage process described in $\S 2$. The overall recall of answers among the subgraphs is $94.0 \%$.</p>
<p>Table 1 shows the combined statistics of all the retreived subgraphs for the questions in each dataset. These two datasets present varying levels of difficulty. While all questions in WikiMovies correspond to a single KB relation, for WebQuestionsSP the model needs to aggregate over two KB facts for $\sim 30 \%$ of the questions, and also requires reasoning over constraints for $\sim 7 \%$ of the questions (Liang et al., 2017). For maximum portability, QA systems need to be robust across several degrees of KB availability since different domains might contain different amounts of structured data; and KB completeness may also vary over time. Hence, we construct an additional 3 datasets each from the above two, with the number of KB facts downsampled to $10 \%, 30 \%$ and $50 \%$ of the original to simulate settings where the KB is incomplete. We repeat the retrieval process for each sampled KB.</p>
<h3>5.2 Compared Models</h3>
<p>KV-KB is the Key Value Memory Networks model from Miller et al. (2016); Das et al. (2017c) but using only KB and ignoring the text. KV-EF (early fusion) is the same model with access to both KB and text as memories. For text we use a BiLSTM over the entire sentence as keys, and entity mentions as values. This re-implementation shows better performance on the text-only and KB-only WikiMovies tasks than the results reported previously ${ }^{7}$ (see Table 4). GN-KB is the GRAFT-Net model ignoring the text. GN-LF is a late fusion version of the GRAFT-Net model: we train two separate models, one using text only and the other using KB only, and then ensemble the two ${ }^{8}$. GN-EF is our main GRAFT-Net model with early fusion. GN-EF+LF is an ensemble over the GN-EF and GN-LF models, with the same ensembling method as GN-LF. We report Hits@1, which</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup>is the accuracy of the top-predicted answer from the model, and the F1 score. To compute the F1 score we tune a threshold on the development set to select answers based on binary probabilities for each node in the subgraph.</p>
<h3>5.3 Main Results</h3>
<p>Table 2 presents a comparison of the above models across all datasets. GRAFT-Nets (GN) shows consistent improvement over KV-MemNNs on both datasets in all settings, including KB only (-KB), text only (-EF, Text Only column), and early fusion (-EF). Interestingly, we observe a larger relative gap between the Hits and F1 scores for the KV models than we do for our GN models. We believe this is because the attention for KV is normalized over the memories, which are KB facts (or text sentences): hence the model is unable to assign high probabilities to multiple facts at the same time. On the other hand, in GN, we normalize the attention over types of relations outgoing from a node, and hence can assign high weights to all the correct answers.</p>
<p>We also see a consistent improvement of early fusion over late fusion (-LF), and by ensembling them together we see the best performance across all the models. In Table 2 (right), we further show the improvement for KV-EF over KV-KB, and GN-LF and GN-EF over GN-KB, as the amount of KB is increased. This measures how effective these approaches are in utilizing text plus a KB. For KV-EF we see improvements when the KB is highly incomplete, but in the full KB setting, the performance of the fused approach is worse. A similar trend holds for GN-LF. On the other hand, GN-EF with text improves over the KB-only approach in all settings. As we would expect, though, the benefit of adding text decreases as the KB becomes more and more complete.</p>
<h3>5.4 Comparison to Specialized Methods</h3>
<p>In Table 4 we compare GRAFT-Nets to state-of-the-art models that are specifically designed and tuned for QA using either only KB or only text. For this experiment we use the full WikiMovies dataset to enable direct comparison to previously reported numbers. For DrQA (Chen et al., 2017), following the original paper, we restrict answer spans for WebQuestionsSP to match an entity in Freebase. In each case we also train GRAFT-Nets using only KB facts or only text sentences. In three out of the four cases, we find that GRAFT-Nets ei-</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: center;"># train / dev / test</th>
<th style="text-align: center;"># entity nodes</th>
<th style="text-align: center;"># edge types</th>
<th style="text-align: center;"># document nodes</th>
<th style="text-align: center;"># question vocab</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">WikiMovies-10K</td>
<td style="text-align: center;">10K / 10K / 10K</td>
<td style="text-align: center;">43,233</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">79,728</td>
<td style="text-align: center;">1759</td>
</tr>
<tr>
<td style="text-align: left;">WebQuestionsSP</td>
<td style="text-align: center;">2848 / 250 / 1639</td>
<td style="text-align: center;">528,617</td>
<td style="text-align: center;">513</td>
<td style="text-align: center;">235,567</td>
<td style="text-align: center;">3781</td>
</tr>
</tbody>
</table>
<p>Table 1: Statistics of all the retrieved subgraphs $\cup_{q} \mathcal{G}_{q}$ for WikiMovies-10K and WebQuestionsSP.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Text Only</th>
<th style="text-align: center;">KB + Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$10 \%$</td>
<td style="text-align: center;">$30 \%$</td>
<td style="text-align: center;">$50 \%$</td>
<td style="text-align: center;">$100 \%$</td>
</tr>
<tr>
<td style="text-align: center;">WikiMovies-10K</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">KV-KB</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">15.8 / 9.8</td>
<td style="text-align: center;">44.7 / 30.4</td>
<td style="text-align: center;">63.8 / 46.4</td>
<td style="text-align: center;">94.3 / 76.1</td>
</tr>
<tr>
<td style="text-align: center;">KV-EF</td>
<td style="text-align: center;">50.4 / 40.9</td>
<td style="text-align: center;">53.6 / 44.0</td>
<td style="text-align: center;">60.6 / 48.1</td>
<td style="text-align: center;">75.3 / 59.1</td>
<td style="text-align: center;">93.8 / 81.4</td>
</tr>
<tr>
<td style="text-align: center;">GN-KB</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">19.7 / 17.3</td>
<td style="text-align: center;">48.4 / 37.1</td>
<td style="text-align: center;">67.7 / 58.1</td>
<td style="text-align: center;">97.0 / 97.6</td>
</tr>
<tr>
<td style="text-align: center;">GN-LF</td>
<td style="text-align: center;">73.2 / 64.0</td>
<td style="text-align: center;">74.5 / 65.4</td>
<td style="text-align: center;">78.7 / 68.5</td>
<td style="text-align: center;">83.3 / 74.2</td>
<td style="text-align: center;">96.5 / 92.0</td>
</tr>
<tr>
<td style="text-align: center;">GN-EF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">75.4 / 66.3</td>
<td style="text-align: center;">82.6 / 71.3</td>
<td style="text-align: center;">87.6 / 76.2</td>
<td style="text-align: center;">96.9 / 94.1</td>
</tr>
<tr>
<td style="text-align: center;">GN-EF+LF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">79.0 / 66.7</td>
<td style="text-align: center;">84.6 / 74.2</td>
<td style="text-align: center;">88.4 / 78.6</td>
<td style="text-align: center;">96.8 / 97.3</td>
</tr>
<tr>
<td style="text-align: center;">WebQuestionsSP</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">KV-KB</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">12.5 / 4.3</td>
<td style="text-align: center;">25.8 / 13.8</td>
<td style="text-align: center;">33.3 / 21.3</td>
<td style="text-align: center;">46.7 / 38.6</td>
</tr>
<tr>
<td style="text-align: center;">KV-EF</td>
<td style="text-align: center;">23.2 / 13.0</td>
<td style="text-align: center;">24.6 / 14.4</td>
<td style="text-align: center;">27.0 / 17.7</td>
<td style="text-align: center;">32.5 / 23.6</td>
<td style="text-align: center;">40.5 / 30.9</td>
</tr>
<tr>
<td style="text-align: center;">GN-KB</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">15.5 / 6.5</td>
<td style="text-align: center;">34.9 / 20.4</td>
<td style="text-align: center;">47.7 / 34.3</td>
<td style="text-align: center;">66.7 / 62.4</td>
</tr>
<tr>
<td style="text-align: center;">GN-LF</td>
<td style="text-align: center;">25.3 / 15.3</td>
<td style="text-align: center;">29.8 / 17.0</td>
<td style="text-align: center;">39.1 / 25.9</td>
<td style="text-align: center;">46.2 / 35.6</td>
<td style="text-align: center;">65.4 / 56.8</td>
</tr>
<tr>
<td style="text-align: center;">GN-EF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">31.5 / 17.7</td>
<td style="text-align: center;">40.7 / 25.2</td>
<td style="text-align: center;">49.9 / 34.7</td>
<td style="text-align: center;">67.8 / 60.4</td>
</tr>
<tr>
<td style="text-align: center;">GN-EF+LF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">33.3 / 19.3</td>
<td style="text-align: center;">42.5 / 26.7</td>
<td style="text-align: center;">52.3 / 37.4</td>
<td style="text-align: center;">68.7 / 62.3</td>
</tr>
</tbody>
</table>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Table 2: Left: Hits@1 / F1 scores of GRAFT-Nets (GN) compared to KV-MemNN (KV) in KB only (-KB), early fusion (-EF), and late fusion (-LF) settings. Right: Improvement of early fusion (-EF) and late fusion (-LF) over KB only (-KB) settings as KB completeness increases.
ther match or outperform the existing state-of-theart models. We emphasize that the latter have no mechanism for dealing with the fused setting.</p>
<p>The one exception is the KB-only case for WebQuestionsSP where GRAFT-Net does $6.2 \%$ F1 points worse than Neural Symbolic Machines (Liang et al., 2017). Analysis suggested three explanations: (1) In the KB-only setting, the recall of subgraph retrieval is only $90.2 \%$, which limits overall performance. In an oracle setting where we ensure the answers are part of the subgraph, the F1 score increases by $4.8 \%$. (2) We use the same probability threshold for all questions, even though the number of answers may vary significantly. Models which parse the query into a symbolic form do not suffer from this problem since answers are retrieved in a deterministic fashion. If we tune separate thresholds for each question the F1 score improves by $7.6 \%$. (3) GRAFT-Nets perform poorly in the few cases where there is a constraint involved in picking out the answer (for example, "who first voiced Meg in Family Guy"). If we ignore such constraints, and consider all entities with the same sequence of relations to the seed as correct, the performance improves by $3.8 \% \mathrm{~F} 1$. Heuristics such as those used by Yu et al. (2017) can be used to improve these cases. Figure 3 shows
examples where GRAFT-Net fails to predict the correct answer set exactly.</p>
<h3>5.5 Effect of Model Components</h3>
<p>Heterogeneous Updates. We tested a nonheterogeneous version of our model, where instead of using fine-grained entity linking information for updating the node representations ( $M(v)$ and $L(d, p)$ in Eqs. 1, 3a), we aggregate the document states across all its positions as $\sum_{p} H_{d, p}^{(l)}$ and use this combined state for all updates. Without the heterogeneous update, all entities $v \in L(d, \cdot)$ will receive the same update from document $d$. Therefore, the model cannot disambiguate different entities mentioned in the same document. The result in Table 5 shows that this version is consistently worse than the heterogeneous model.</p>
<p>Conditioning on the Question. We performed an ablation test on the directed propagation method and attention over relations. We observe that both components lead to better performance. Such effects are observed in both complete and incomplete KB scenarios, e.g. on WebQuestionsSP dataset, as shown in Figure 4 (left).</p>
<p>Fact Dropout. Figure 4 (right) compares the performance of the early fusion model as we vary</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Question</th>
<th style="text-align: left;">Correct Answers</th>
<th style="text-align: left;">Predicted Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">what language do most people speak in afghanistan</td>
<td style="text-align: left;">Pashto language, <br> Farsi (Eastern Language)</td>
<td style="text-align: left;">Pashto language</td>
</tr>
<tr>
<td style="text-align: left;">what college did john stockton go to</td>
<td style="text-align: left;">Gonzaga University</td>
<td style="text-align: left;">Gonzaga University, <br> Gonzaga Preparatory School</td>
</tr>
</tbody>
</table>
<p>Table 3: Examples from WebQuestionsSP dataset. Top: The model misses a correct answer. Bottom: The model predicts an extra incorrect answer.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">WikiMovies (full)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">WebQuestionsSP</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">kb</td>
<td style="text-align: center;">doc</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">kb</td>
<td style="text-align: center;">doc</td>
</tr>
<tr>
<td style="text-align: left;">MINERVA</td>
<td style="text-align: center;">$\mathbf{9 7 . 0 / -}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">R2-AsV</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$85.8 /-$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">NSM</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-\mathbf{6 9 . 0}$</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">DrQA*</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$21.5 /-$</td>
</tr>
<tr>
<td style="text-align: left;">R-GCN*</td>
<td style="text-align: center;">$\mathbf{9 6 . 5 / 9 7 . 4}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$37.2 / 30.5$</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">KV</td>
<td style="text-align: center;">$93.9 /-$</td>
<td style="text-align: center;">$76.2 /-$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-/-$</td>
<td style="text-align: center;">$-/-$</td>
</tr>
<tr>
<td style="text-align: left;">KV*</td>
<td style="text-align: center;">$95.6 / 88.0$</td>
<td style="text-align: center;">$80.3 / 72.1$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$46.7 / 38.6$</td>
<td style="text-align: center;">$23.2 / 13.0$</td>
</tr>
<tr>
<td style="text-align: left;">GN</td>
<td style="text-align: center;">$\mathbf{9 6 . 8 / 9 7 . 2}$</td>
<td style="text-align: center;">$\mathbf{8 6 . 6 / 8 0 . 8}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$67.8 / 62.8$</td>
<td style="text-align: center;">$\mathbf{2 5 . 3 / 1 5 . 3}$</td>
</tr>
</tbody>
</table>
<p>Table 4: Hits@1 / F1 scores compared to SOTA models using only KB or text: MINERVA (Das et al., 2017a), R2-AsV (Watanabe et al., 2017), Neural Symbolic Machines (NSM) (Liang et al., 2017), DrQA (Chen et al., 2017), RGCN (Schlichtkrull et al., 2017) and KV-MemNN (Miller et al., 2016). <em>DrQA is pretrained on SQuAD. </em>Re-implemented.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">0 KB</th>
<th style="text-align: center;">0.1 KB</th>
<th style="text-align: center;">0.3 KB</th>
<th style="text-align: center;">0.5 KB</th>
<th style="text-align: center;">1.0 KB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NH</td>
<td style="text-align: center;">$22.7 / 13.6$</td>
<td style="text-align: center;">$28.7 / 15.8$</td>
<td style="text-align: center;">$35.6 / 23.2$</td>
<td style="text-align: center;">$47.2 / 33.3$</td>
<td style="text-align: center;">$66.5 / 59.8$</td>
</tr>
<tr>
<td style="text-align: left;">H</td>
<td style="text-align: center;">$25.3 / 15.3$</td>
<td style="text-align: center;">$31.5 / 17.7$</td>
<td style="text-align: center;">$40.7 / 25.2$</td>
<td style="text-align: center;">$49.9 / 34.7$</td>
<td style="text-align: center;">$67.8 / 60.4$</td>
</tr>
</tbody>
</table>
<p>Table 5: Non-Heterogeneous (NH) vs. Heterogeneous (H) updates on WebQuestionsSP
the rate of fact dropout. Moderate levels of fact dropout improve performance on both datasets. The performance increases as the fact dropout rate increases until the model is unable to learn the inference chain from KB.</p>
<h2>6 Conclusion</h2>
<p>In this paper we investigate QA using text combined with an incomplete KB, a task which has received limited attention in the past. We introduce several benchmark problems for this task by modifying existing question-answering datasets, and discuss two broad approaches to solving this problem-"late fusion" and "early fusion". We show that early fusion approaches perform better.</p>
<p>We also introduce a novel early-fusion model, called GRAFT-Net, for classifying nodes in subgraph consisting of both KB entities and text doc-
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4: Left: Effect of directed propagation and query-based attention over relations for the WebQuestionsSP dataset with $30 \% \mathrm{~KB}$ and $100 \%$ KB. Right: Hits@1 with different rates of factdropout on and WikiMovies and WebQuestionsSP.
uments. GRAFT-Net builds on recent advances in graph representation learning but includes several innovations which improve performance on this task. GRAFT-Nets are a single model which achieve performance competitive to state-of-theart methods in both text-only and KB-only settings, and outperform baseline models when using text combined with an incomplete KB. Current directions for future work include - (1) extending GRAFT-Nets to pick spans of text as answers, rather than only entities and (2) improving the subgraph retrieval process.</p>
<h2>Acknowledgments</h2>
<p>Bhuwan Dhingra is supported by NSF under grants CCF-1414030 and IIS-1250956 and by grants from Google. Ruslan Salakhutdinov is supported in part by ONR grant N000141812861, Apple, and Nvidia NVAIL Award.</p>
<h2>References</h2>
<p>James Atwood and Don Towsley. 2016. Diffusionconvolutional neural networks. In Advances in Neu-</p>
<p>ral Information Processing Systems, pages 19932001.</p>
<p>Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In The semantic web, pages 722-735. Springer.</p>
<p>Petr Baudiš. 2015. Yodaqa: a modular question answering system pipeline. In POSTER 2015-19th International Student Conference on Electrical Engineering, pages 1156-1165.</p>
<p>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, pages 1247-1250. AcM.</p>
<p>Antoine Bordes, Nicolas Usunier, Sumit Chopra, and Jason Weston. 2015. Large-scale simple question answering with memory networks. arXiv preprint arXiv:1506.02075.</p>
<p>Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading Wikipedia to answer opendomain questions. In Association for Computational Linguistics (ACL).</p>
<p>Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Luke Vilnis, Ishan Durugkar, Akshay Krishnamurthy, Alex Smola, and Andrew McCallum. 2017a. Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning. arXiv preprint arXiv:1711.05851.</p>
<p>Rajarshi Das, Arvind Neelakantan, David Belanger, and Andrew McCallum. 2017b. Chains of reasoning over entities, relations, and text using recurrent neural networks. EACL.</p>
<p>Rajarshi Das, Manzil Zaheer, Siva Reddy, and Andrew McCallum. 2017c. Question answering on knowledge bases and text using universal schema and memory networks. $A C L$.</p>
<p>Bhuwan Dhingra, Kathryn Mazaitis, and William W Cohen. 2017. Quasar: Datasets for question answering by search and reading. arXiv preprint arXiv:1707.03904.</p>
<p>Bhuwan Dhingra, Danish Pruthi, and Dheeraj Rajagopal. 2018. Simple and effective semi-supervised question answering. NAACL.</p>
<p>David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A Kalyanpur, Adam Lally, J William Murdock, Eric Nyberg, John Prager, et al. 2010. Building watson: An overview of the deepqa project. AI magazine, 31(3):59-79.</p>
<p>Matt Gardner and Jayant Krishnamurthy. 2017. Openvocabulary semantic parsing with both distributional statistics and formal knowledge. In AAAI, pages $3195-3201$.</p>
<p>Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. ICML.</p>
<p>Yichen Gong and Samuel R Bowman. 2017. Ruminating reader: Reasoning with gated multi-hop attention. arXiv preprint arXiv:1704.07415.</p>
<p>William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. CoRR, abs/1706.02216.</p>
<p>Xu Han, Zhiyuan Liu, and Maosong Sun. 2016. Joint representation learning of text and knowledge for knowledge graph completion. arXiv preprint arXiv:1611.04125.</p>
<p>Taher H Haveliwala. 2002. Topic-sensitive pagerank. In Proceedings of the 11th international conference on World Wide Web, pages 517-526. ACM.</p>
<p>Minghao Hu, Yuxing Peng, and Xipeng Qiu. 2017. Mnemonic reader for machine comprehension. arXiv preprint arXiv:1705.02798.</p>
<p>Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017. Search-based neural structured learning for sequential question answering. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 1821-1831.</p>
<p>Sarthak Jain. 2016. Question answering over knowledge base using factual memory networks. In Proceedings of the NAACL Student Research Workshop, pages 109-115.</p>
<p>Jiatao Jiang, Zhen Cui, Chunyan Xu, Chengzheng Li, and Jian Yang. 2018. Walk-steered convolution for graph classification. arXiv preprint arXiv:1804.05837.</p>
<p>Thomas N Kipf and Max Welling. 2016. Semisupervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.</p>
<p>Sebastian Krause, Leonhard Hennig, Andrea Moro, Dirk Weissenborn, Feiyu Xu, Hans Uszkoreit, and Roberto Navigli. 2016. Sae-graphs: A language resource connecting linguistic knowledge with semantic relations from knowledge graphs. Web Semantics: Science, Services and Agents on the World Wide Web, 37:112-131.</p>
<p>Ni Lao, Amarnag Subramanya, Fernando Pereira, and William W Cohen. 2012. Reading the web with learned syntactic-semantic inference rules. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1017-1026. Association for Computational Linguistics.</p>
<p>Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2016. Gated graph sequence neural networks. ICLR.</p>
<p>Chen Liang, Jonathan Berant, Quoc Le, Kenneth D Forbus, and Ni Lao. 2017. Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. $A C L$.</p>
<p>Zhengdong Lu, Haotian Cui, Xianggen Liu, Yukun Yan, and Daqi Zheng. 2017. Object-oriented neural programming (oonp) for document understanding. arXiv preprint arXiv:1709.08853.</p>
<p>Alexander Miller, Adam Fisch, Jesse Dodge, AmirHossein Karimi, Antoine Bordes, and Jason Weston. 2016. Key-value memory networks for directly reading documents. EMNLP.</p>
<p>Bonan Min, Ralph Grishman, Li Wan, Chang Wang, and David Gondek. 2013. Distant supervision for relation extraction with an incomplete knowledge base. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 777-782.</p>
<p>Martin Raison, Pierre-Emmanuel Mazaré, Rajarshi Das, and Antoine Bordes. 2018. Weaver: Deep coencoding of questions and documents for machine reading. arXiv preprint arXiv:1804.10490.</p>
<p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250.</p>
<p>Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages $74-84$.</p>
<p>Pum-Mo Ryu, Myung-Gil Jang, and Hyun-Ki Kim. 2014. Open domain question answering using wikipedia-based knowledge model. Information Processing and Management, 50(5):683 - 692.</p>
<p>Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80.</p>
<p>Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. 2017. Modeling relational data with graph convolutional networks. arXiv preprint arXiv:1703.06103.</p>
<p>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2017. Bidirectional attention flow for machine comprehension. ICLR.</p>
<p>Yelong Shen, Po-Sen Huang, Jianfeng Gao, and Weizhu Chen. 2017. Reasonet: Learning to stop reading in machine comprehension. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1047-1055. ACM.
A. Talmor and J. Berant. 2018. The web as a knowledge-base for answering complex questions. In North American Association for Computational Linguistics (NAACL).</p>
<p>Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoifung Poon, Pallavi Choudhury, and Michael Gamon. 2015. Representing text for joint embedding of text and knowledge bases. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499-1509.</p>
<p>Patrick Verga, David Belanger, Emma Strubell, Benjamin Roth, and Andrew McCallum. 2016. Multilingual relation extraction using compositional universal schema. NAACL.</p>
<p>Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus. 2013. Regularization of neural networks using dropconnect. In International Conference on Machine Learning, pages 1058-1066.</p>
<p>Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerald Tesauro, Bowen Zhou, and Jing Jiang. 2018. R ${ }^{3}$ : Reinforced reader-ranker for open-domain question answering. AAAI.</p>
<p>Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, and Murray Campbell. 2017. Evidence aggregation for answer re-ranking in open-domain question answering. arXiv preprint arXiv:1711.05116.</p>
<p>Yusuke Watanabe, Bhuwan Dhingra, and Ruslan Salakhutdinov. 2017. Question answering from unstructured text by retrieval and comprehension. arXiv preprint arXiv:1703.08885.</p>
<p>Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2018. Constructing datasets for multi-hop reading comprehension across documents. TACL.</p>
<p>Georg Wiese, Dirk Weissenborn, and Mariana Neves. 2017. Neural domain adaptation for biomedical question answering. In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 281-289, Vancouver, Canada. Association for Computational Linguistics.</p>
<p>Wen-tau Yih, Matthew Richardson, Chris Meek, MingWei Chang, and Jina Suh. 2016. The value of semantic parse labeling for knowledge base question answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), volume 2, pages 201-206.</p>
<p>Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, and Quoc V Le. 2018. Qanet: Combining local convolution with global self-attention for reading comprehension. ICLR.</p>
<p>Mo Yu, Wenpeng Yin, Kazi Saidul Hasan, Cicero dos Santos, Bing Xiang, and Bowen Zhou. 2017. Improved neural relation detection for knowledge base question answering. $A C L$.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6} \mathrm{~A}$ total of 13 questions had no detected entities. These were ignored during training and considered as incorrect during evaluation.
${ }^{7}$ For all KV models we tuned the number of layers ${1,2,3}$, batch size ${10,30,50}$, model dimension ${50,80}$. We also use fact dropout regularization in the KB+Text setting tuned between ${0,0.2,0.4}$.
${ }^{8}$ For ensembles we take a weighted combination of the answer probabilities produced by the models, with the weights tuned on the dev set. For answers only in text or only in KB, we use the probability as is.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>