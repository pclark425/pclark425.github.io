<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6832 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6832</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6832</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-131.html">extraction-schema-131</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <p><strong>Paper ID:</strong> paper-252070866</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2209.00840v2.pdf" target="_blank">FOLIO: Natural Language Reasoning with First-Order Logic</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have achieved remarkable performance on a variety of natural language understanding tasks. However, existing benchmarks are inadequate in measuring the complex logical reasoning capabilities of a model. We present FOLIO, a human-annotated, logically complex and diverse dataset for reasoning in natural language (NL), equipped with first-order logic (FOL) annotations. FOLIO consists of 1,430 examples (unique conclusions), each paired with one of 487 sets of premises used to deductively reason for the validity of each conclusion. The logical correctness of the premises and conclusions is ensured by their FOL annotations, which are automatically verified by an FOL inference engine. In addition to the main NL reasoning task, NL-FOL pairs in FOLIO constitute a new NL-FOL translation dataset. Our experiments on FOLIO systematically evaluate the FOL reasoning ability of supervised fine-tuning on medium-sized language models. For both NL reasoning and NL-FOL translation, we benchmark multiple state-of-the-art language models. Our results show that a subset of FOLIO remains a challenge for one of the most capable Large Language Model (LLM) publicly available, GPT-4.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6832.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6832.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FOLIO: Natural Language Reasoning with First-Order Logic</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human-annotated dataset of 1,430 first-order-logic reasoning examples (487 stories) pairing natural-language premises and conclusions with verified FOL formulas and True/False/Unknown labels; used to evaluate strict FOL reasoning by language models and as an NL->FOL translation benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>dataset</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Expert-authored NL stories with parallel FOL annotations and FOL-verified labels; includes WikiLogic and HybLogic subsets with varying reasoning depths and AST diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>N/A (benchmark dataset for first-order deductive reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>A Stanford CS221 first-order logic inference engine was used to verify FOL annotations and compute True/False/Unknown labels for each conclusion.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order logic (FOL) reasoning dataset containing NL stories paired with FOL formulas; tasks: truth-value classification (True/False/Unknown) and NL->FOL translation (syntactic validity and inference-engine execution accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order deductive reasoning (truth-value classification); NL->FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (reasoning), Syntactic Validity (SynV) and Execution Accuracy (ExcAcc) for NL->FOL</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Baseline majority 38.5%; dataset used in all experiments reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>N/A (dataset itself)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>FOLIO is more logically diverse and deeper than prior benchmarks; poses a challenge to state-of-the-art LLMs including GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Moderate scale (1,430 examples) due to intensive expert annotation; not designed to evaluate temporal/modal logic beyond first-order logic.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6832.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art closed-source large language model evaluated in few-shot prompting with several prompting strategies; used as a base model for neurosymbolic methods in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language model (closed-source). Treated as a strong publicly-available LLM for few-shot prompting; used as base for applying higher-level reasoning strategies and for plug-in neurosymbolic methods.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not publicly reported</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>not reported in paper (closed-source); experiments used FOLIO few-shot or FOLIO test inputs for evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>few-shot prompting; chain-of-thought (CoT); self-consistency (SC); tree-of-thought (ToT); used as base for Logic-LM, LINC, DetermLR</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Truth-value classification on natural-language stories requiring FOL reasoning; also NL->FOL translation (execution accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (truth-value classification); NL->FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (reasoning); SynV and ExcAcc for NL->FOL</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Few-shot NL prompting: 64.2% accuracy (paper's reported few-shot baseline). With CoT: 68.9%; CoT+SC: 69.5%; ToT: 70.0%. NL->FOL few-shot SynV 93.9% and ExcAcc 63.8%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>CoT improves over vanilla few-shot by ~+4.7 percentage points; SC adds +0.6 pp to CoT; ToT slightly outperforms CoT+SC (~+0.5 pp). Neurosymbolic methods (Logic-LM/DetermLR/LINC) improve further (see respective entries).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GPT-4 is the best single LLM few-shot performer on FOLIO but still substantially below expert human performance (~31.82% gap vs expert annotators). Prompting strategies (CoT/SC/ToT) and neurosymbolic augmentations yield meaningful gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Struggles with long/deep reasoning chains and complex HybLogic templates; common failures include faulty reasoning paths (65%), wrong derivations (25%), syntactic comprehension failures (5%), and spurious shortcuts (5%).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6832.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-Turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A strong but less capable OpenAI LLM compared to GPT-4; evaluated in few-shot and zero-shot settings on FOLIO tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based LLM (closed-source, smaller/capability lower than GPT-4). Evaluated in zero- and few-shot prompting for reasoning and NL->FOL translation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not publicly reported</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>not reported in paper; experiments used FOLIO few-shot examples</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>zero-shot/few-shot prompting; standard prompting (no reported neurosymbolic augmentations in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning and NL->FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction; NL->FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy; SynV and ExcAcc for NL->FOL</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Zero-shot reasoning: 53.1% (text reports zero-shot GPT-3.5 better than few-shot text-davinci-002). Few-shot reasoning reported ~58.34% in Table 4. NL->FOL few-shot: SynV 93.3%, ExcAcc 56.0%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Underperforms GPT-4 by a sizeable margin on FOLIO; NL->FOL translation ExcAcc lower than GPT-4 by ~7.8 percentage points.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Can generate syntactically valid FOL formulas at scale but has lower semantic/entailment execution accuracy than GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Less able to leverage FOL annotations to improve reasoning compared to GPT-4 (paper reports GPT-3.5 performs worse when FOL is concatenated).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6832.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>text-davinci-002</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>text-davinci-002 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier OpenAI model version used as a few-shot baseline in experiments; shows weaker performance relative to GPT-3.5 and GPT-4 on FOLIO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-davinci-002</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Older OpenAI transformer-based LLM used as a few-shot baseline (8-shot referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not publicly reported</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>few-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning and NL->FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Few-shot NL prompting: 49.53% accuracy (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Underperforms GPT-3.5 and GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Earlier model with lower performance on strict FOL reasoning tasks compared to later GPT variants.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Low few-shot accuracy on FOLIO relative to newer models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6832.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-13B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA 13B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 13-billion parameter open model family member evaluated few-shot on FOLIO; shows near-chance performance on the reasoning task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-13B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer language model (13B parameters) from LLaMA family.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>not reported in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>few-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (truth-value classification)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Few-shot NL prompting: 33.63% (â‰ˆchance 33%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Slightly above random chance; substantially lower than larger LLaMA-70B and GPT models.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Small/medium-sized LMs struggle on FOLIO in few-shot setups.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Very limited capability for complex first-order reasoning in few-shot evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6832.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA 70B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 70B-parameter LLaMA-family model evaluated with few-shot prompting and advanced prompting strategies showing modest gains but still below GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer language model (70B parameters). Evaluated with few-shot prompting, Chain-of-Thought and Tree-of-Thought prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>not reported in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>few-shot prompting; Chain-of-Thought (CoT) and Tree-of-Thought (ToT) applied</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Few-shot NL prompting: 43.97% (Table text ~44.0%); +CoT => 47.8%; +ToT => 48.4%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>About 10% better than LLaMA-13B; CoT/ToT provide modest improvements (~3-4 pp).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Scaling helps but larger open models still trail GPT-4; prompting strategies give further gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Remains substantially below top-performing GPT-4+methods on deep FOL reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6832.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT / RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT / RoBERTa (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard pretrained encoder transformers fine-tuned on FOLIO for truth-value classification; obtain moderate performance when fully supervised.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT; RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained encoder transformers (BERT and RoBERTa) fine-tuned with an added two-layer classification head for 3-way truth-value prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>base: ~110M; large: ~340M</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer (encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine-tuned on FOLIO training split (1,001 examples)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>fully supervised fine-tuning on labelled FOLIO examples</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (truth-value classification)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>BERT-base 56.83%; BERT-large 59.0%; RoBERTa-base 56.8%; RoBERTa-large 62.1% (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>All fine-tuned encoder models outperform majority baseline (38.5%) and random (33.3%); RoBERTa-large performs best among them at 62.1%.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Supervised fine-tuning on FOLIO yields better performance than few-shot prompting for some smaller LMs; fine-tuning can exploit dataset-specific patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Fine-tuned models still fall short of expert human performance and best neurosymbolic methods; may overfit template patterns (HybLogic) rather than general FOL reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6832.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-T5-Large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Flan-T5-Large (instruction-tuned T5)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Instruction-tuned encoder-decoder transformer fine-tuned on FOLIO for classification; achieves the highest accuracy among supervised fine-tuning models reported.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-T5-Large</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Sequence-to-sequence transformer (Flan-T5 variant) with instruction tuning, fine-tuned for the truth-value classification task.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>783M</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer (encoder-decoder)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine-tuned on FOLIO training split</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>fully supervised fine-tuning</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (truth-value classification)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>65.7% accuracy (best among finetuned models reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>+~6 pp over RoBERTa-large; substantial improvement over majority baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Instruction-tuned seq2seq fine-tuning yields the strongest supervised performance on FOLIO in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Still substantially below neurosymbolic methods and expert performance; fine-tuning limited by dataset size.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6832.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting technique that elicits intermediate reasoning steps from an LLM to improve performance on complex reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>prompting strategy</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Sequential natural-language rationales or intermediate steps included in prompts (few-shot) to guide LLMs to break down reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>prompting/control-flow</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>few-shot exemplars from FOLIO in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>eliciting step-by-step intermediate reasoning (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Applied to truth-value classification on FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction with intermediate rationale</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>When applied to GPT-4 few-shot: CoT improves accuracy from 64.2% to 68.9% (+4.7 pp).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>+~4+ pp over vanilla few-shot GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CoT increases GPT-4 performance on FOLIO; helps elicit multi-step reasoning but does not close the gap to expert performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Still fails on many deep-chain examples; can produce faulty intermediate steps for complex derivations (paper reports 65% faulty reasoning paths among GPT-4 errors).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6832.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Consistency (SC)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency for Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A decoding/aggregation technique that samples multiple chain-of-thought reasoning traces and selects the most consistent final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>decoding/aggregation method</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Aggregate multiple stochastic CoT generations and pick the most frequent final answer (self-consistency).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>decoding/aggregation</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>few-shot CoT exemplars from FOLIO used during experiments</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>ensemble over multiple CoT traces (self-consistency)</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Applied in combination with CoT on GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (truth-value classification)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>CoT+SC on GPT-4: 69.5% accuracy (+0.6 pp over CoT alone; +5.3 pp over vanilla few-shot).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Small additional improvement over CoT; overall helpful but modest.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Self-consistency gives incremental gains beyond CoT on FOLIO.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Computationally more expensive (multiple samples); still insufficient for many deep reasoning examples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6832.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree-of-Thought (ToT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A search-based deliberation framework where the LLM explores a tree of intermediate reasoning steps and uses a search/pruning strategy to select a final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>prompting/control-flow method</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Exploratory prompting that constructs and searches over multiple possible reasoning branches (tree of thoughts) to improve problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>search over LM-generated reasoning traces</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>few-shot examples from FOLIO used in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>search-based exploration of reasoning chains</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Evaluated on few-shot truth-value classification</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>ToT on GPT-4: 70.0% accuracy (slightly better than CoT+SC and CoT alone).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>+~5.8 pp over vanilla few-shot GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Tree-of-Thought offers the largest single-method prompting gain reported in the paper for GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Higher computational cost and complexity; still fails on many hybLogic/deep reasoning cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6832.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LINC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LINC (Olausson et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neurosymbolic approach that combines language models with first-order logic provers; evaluated in this paper using GPT-4 as the LM backbone and shows substantial accuracy gains on FOLIO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LINC</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Neurosymbolic pipeline combining an LLM (GPT-4 in experiments) with an FOL prover to perform faithful logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>base LM: GPT-4 (size not reported)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>neurosymbolic (transformer + FOL prover)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>few-shot examples from FOLIO used in experiments (paper-level description); original LINC paper not introduced here</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>combine LLM reasoning with a symbolic FOL prover to validate/guide inference</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Integrates an external first-order logic prover (neurosymbolic architecture) to check/augment LM inferences; in this paper LINC is applied using GPT-4 as LM base.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning truth-value classification</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (hybrid neurosymbolic inference)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>73.1% accuracy on FOLIO (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>â‰ˆ+9 percentage points over few-shot GPT-4 baseline (~64.2%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Neurosymbolic integration meaningfully improves strict FOL reasoning over vanilla prompting of GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires integration with external provers; extra engineering and computational cost; not all failure modes eliminated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e6832.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Logic-LM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic-LM (Pan et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that empowers LLMs with symbolic solvers for faithful logical reasoning; when applied with GPT-4 in this paper it yields the highest reported accuracy among tested approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Logic-LM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A neurosymbolic method that couples LLM outputs with symbolic solvers to produce faithful logical inferences and proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>base LM: GPT-4 (size not reported)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>neurosymbolic (transformer + symbolic solver)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>few-shot examples from FOLIO used for evaluation; original Logic-LM training specifics not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>LM-guided invocation of symbolic solvers to validate and construct logical derivations</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Uses symbolic solvers (theorem provers) integrated with GPT-4 to improve logical correctness of outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning truth-value classification</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction with symbolic verification</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>78.1% accuracy on FOLIO (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>â‰ˆ+13.9 percentage points over few-shot GPT-4 (~64.2%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Symbolic solver integration yields the largest performance gains reported in the paper, demonstrating the effectiveness of neurosymbolic methods for strict logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires external symbolic tooling and orchestration; increased complexity and computational cost; paper notes substantial residual gap to perfect reasoning despite gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e6832.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DetermLR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DetermLR (Sun et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach (referenced as augmenting LLMs for determinacy in logical reasoning) applied with GPT-4 in this paper and reported to significantly improve FOLIO accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DetermLR</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Method that augments LLMs with mechanisms to make logical reasoning more determinate, applied here on GPT-4 as the LM backbone.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>base LM: GPT-4 (not reported)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>neurosymbolic / augmentation (transformer + symbolic/deterministic component)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>few-shot examples from FOLIO for evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>LM augmentation with deterministic logical checks/procedures (paper references only; exact integration details in original DetermLR paper)</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Combines LLM outputs with deterministic logical modules/provers to improve correctness of deductions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>First-order reasoning truth-value classification</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>first-order logical deduction (augmented with deterministic verification)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>77.5% accuracy on FOLIO (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>â‰ˆ+13.3 percentage points over few-shot GPT-4 (~64.2%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Augmenting LLMs with deterministic or symbolic verification substantially improves strict logical reasoning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires coupling to external logical modules; extra engineering and compute overhead; not fully eliminating deep-chain errors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e6832.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FOL inference engine (Stanford CS221)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Stanford CS221 first-order logic inference engine (used for verification)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A compact Python theorem-prover module adopted to verify FOL annotations and determine conclusion truth values; used in dataset construction and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FOL inference engine (Stanford CS221)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A compact first-order logic inference engine used to check syntactic validity and to execute the translated FOL to compute True/False/Unknown labels.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>symbolic theorem prover</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>symbolic first-order theorem proving</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Converts human-written FOL into the prover's input via a custom parser and runs proofs/queries to obtain conclusion labels; used both to verify dataset annotations and to evaluate NL->FOL execution accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO (verification tool)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Tool for verifying FOL annotations and computing ground-truth labels</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>symbolic first-order theorem proving (verification)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>used as authoritative execution engine for labels; not reported as an accuracy metric itself</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>N/A (used as verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Enables automated, exact evaluation of NL->FOL translations via execution accuracy metric.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Original prover input syntax differs from human FOL; required building a parser to convert annotated FOL into prover format; prover resource/time limits apply.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6832.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e6832.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NL->FOL translation (task)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Natural Language to First-Order Logic Translation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A translation task introduced in FOLIO where models must generate FOL formulas semantically equivalent to NL premises and conclusions; evaluated by syntactic validity and execution accuracy with the FOL prover.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>task</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generative task to translate NL sentences/stories into syntactically-valid FOL and semantically correct FOL such that a prover yields the same truth values.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>FOLIO NL-FOL paired annotations (few-shot prompting used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>generation of formal FOL expressions from NL; evaluated by prover execution</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Syntactic validity checked locally; semantic correctness judged by feeding generated FOL to the FOL inference engine (ExcAcc).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>FOLIO NL-FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Measures syntactic validity (SynV) and inference-engine execution accuracy (ExcAcc) of generated FOL from NL prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>semantic parsing into first-order logic; executable formalization</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>SynV (binary per example) and ExcAcc (prover label accuracy)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Few-shot SynV: GPT-3.5-Turbo 93.3% / ExcAcc 56.0%; GPT-4 SynV 93.9% / ExcAcc 63.8% (Table 5). Zero-shot SynV lower (GPT-3.5 68.4%, GPT-4 86.1%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>GPT-4 better than GPT-3.5 both at syntactic validity and execution accuracy; models are proficient at FOL syntax but weaker at semantic equivalence.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Large LMs can generate syntactically-valid FOL but often fail to produce FOL semantically equivalent to NL (lower ExcAcc).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>ExcAcc substantially below SynV â€” models produce syntactically plausible but semantically incorrect FOL; NL->FOL alignment remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'FOLIO: Natural Language Reasoning with First-Order Logic', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers <em>(Rating: 2)</em></li>
                <li>Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning <em>(Rating: 2)</em></li>
                <li>From indeterminacy to determinacy: Augmenting logical reasoning capabilities with large language models <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models <em>(Rating: 2)</em></li>
                <li>Transformers as soft reasoners over language <em>(Rating: 1)</em></li>
                <li>Transformers as soft reasoners over language. (2021 extension / ProofWriter / RuleTaker citations) <em>(Rating: 1)</em></li>
                <li>GPT-4 Technical Report <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6832",
    "paper_id": "paper-252070866",
    "extraction_schema_id": "extraction-schema-131",
    "extracted_data": [
        {
            "name_short": "FOLIO",
            "name_full": "FOLIO: Natural Language Reasoning with First-Order Logic",
            "brief_description": "A human-annotated dataset of 1,430 first-order-logic reasoning examples (487 stories) pairing natural-language premises and conclusions with verified FOL formulas and True/False/Unknown labels; used to evaluate strict FOL reasoning by language models and as an NL-&gt;FOL translation benchmark.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "dataset",
            "model_description": "Expert-authored NL stories with parallel FOL annotations and FOL-verified labels; includes WikiLogic and HybLogic subsets with varying reasoning depths and AST diversity.",
            "model_size": null,
            "architecture_type": null,
            "training_data": null,
            "reasoning_method": "N/A (benchmark dataset for first-order deductive reasoning)",
            "external_tool_used": true,
            "external_tool_description": "A Stanford CS221 first-order logic inference engine was used to verify FOL annotations and compute True/False/Unknown labels for each conclusion.",
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order logic (FOL) reasoning dataset containing NL stories paired with FOL formulas; tasks: truth-value classification (True/False/Unknown) and NL-&gt;FOL translation (syntactic validity and inference-engine execution accuracy).",
            "task_type": "first-order deductive reasoning (truth-value classification); NL-&gt;FOL translation",
            "performance_metric": "accuracy (reasoning), Syntactic Validity (SynV) and Execution Accuracy (ExcAcc) for NL-&gt;FOL",
            "performance_value": "Baseline majority 38.5%; dataset used in all experiments reported in this paper.",
            "comparison_with_baseline": "N/A (dataset itself)",
            "key_findings": "FOLIO is more logically diverse and deeper than prior benchmarks; poses a challenge to state-of-the-art LLMs including GPT-4.",
            "limitations": "Moderate scale (1,430 examples) due to intensive expert annotation; not designed to evaluate temporal/modal logic beyond first-order logic.",
            "uuid": "e6832.0",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "A state-of-the-art closed-source large language model evaluated in few-shot prompting with several prompting strategies; used as a base model for neurosymbolic methods in experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Transformer-based large language model (closed-source). Treated as a strong publicly-available LLM for few-shot prompting; used as base for applying higher-level reasoning strategies and for plug-in neurosymbolic methods.",
            "model_size": "not publicly reported",
            "architecture_type": "transformer",
            "training_data": "not reported in paper (closed-source); experiments used FOLIO few-shot or FOLIO test inputs for evaluation",
            "reasoning_method": "few-shot prompting; chain-of-thought (CoT); self-consistency (SC); tree-of-thought (ToT); used as base for Logic-LM, LINC, DetermLR",
            "external_tool_used": null,
            "external_tool_description": null,
            "benchmark_name": "FOLIO",
            "benchmark_description": "Truth-value classification on natural-language stories requiring FOL reasoning; also NL-&gt;FOL translation (execution accuracy).",
            "task_type": "first-order logical deduction (truth-value classification); NL-&gt;FOL translation",
            "performance_metric": "accuracy (reasoning); SynV and ExcAcc for NL-&gt;FOL",
            "performance_value": "Few-shot NL prompting: 64.2% accuracy (paper's reported few-shot baseline). With CoT: 68.9%; CoT+SC: 69.5%; ToT: 70.0%. NL-&gt;FOL few-shot SynV 93.9% and ExcAcc 63.8%.",
            "comparison_with_baseline": "CoT improves over vanilla few-shot by ~+4.7 percentage points; SC adds +0.6 pp to CoT; ToT slightly outperforms CoT+SC (~+0.5 pp). Neurosymbolic methods (Logic-LM/DetermLR/LINC) improve further (see respective entries).",
            "key_findings": "GPT-4 is the best single LLM few-shot performer on FOLIO but still substantially below expert human performance (~31.82% gap vs expert annotators). Prompting strategies (CoT/SC/ToT) and neurosymbolic augmentations yield meaningful gains.",
            "limitations": "Struggles with long/deep reasoning chains and complex HybLogic templates; common failures include faulty reasoning paths (65%), wrong derivations (25%), syntactic comprehension failures (5%), and spurious shortcuts (5%).",
            "uuid": "e6832.1",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "GPT-3.5-Turbo",
            "name_full": "GPT-3.5-Turbo (OpenAI)",
            "brief_description": "A strong but less capable OpenAI LLM compared to GPT-4; evaluated in few-shot and zero-shot settings on FOLIO tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo",
            "model_description": "Transformer-based LLM (closed-source, smaller/capability lower than GPT-4). Evaluated in zero- and few-shot prompting for reasoning and NL-&gt;FOL translation.",
            "model_size": "not publicly reported",
            "architecture_type": "transformer",
            "training_data": "not reported in paper; experiments used FOLIO few-shot examples",
            "reasoning_method": "zero-shot/few-shot prompting; standard prompting (no reported neurosymbolic augmentations in this paper)",
            "external_tool_used": null,
            "external_tool_description": null,
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning and NL-&gt;FOL translation",
            "task_type": "first-order logical deduction; NL-&gt;FOL translation",
            "performance_metric": "accuracy; SynV and ExcAcc for NL-&gt;FOL",
            "performance_value": "Zero-shot reasoning: 53.1% (text reports zero-shot GPT-3.5 better than few-shot text-davinci-002). Few-shot reasoning reported ~58.34% in Table 4. NL-&gt;FOL few-shot: SynV 93.3%, ExcAcc 56.0%.",
            "comparison_with_baseline": "Underperforms GPT-4 by a sizeable margin on FOLIO; NL-&gt;FOL translation ExcAcc lower than GPT-4 by ~7.8 percentage points.",
            "key_findings": "Can generate syntactically valid FOL formulas at scale but has lower semantic/entailment execution accuracy than GPT-4.",
            "limitations": "Less able to leverage FOL annotations to improve reasoning compared to GPT-4 (paper reports GPT-3.5 performs worse when FOL is concatenated).",
            "uuid": "e6832.2",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "text-davinci-002",
            "name_full": "text-davinci-002 (OpenAI)",
            "brief_description": "An earlier OpenAI model version used as a few-shot baseline in experiments; shows weaker performance relative to GPT-3.5 and GPT-4 on FOLIO.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "text-davinci-002",
            "model_description": "Older OpenAI transformer-based LLM used as a few-shot baseline (8-shot referenced).",
            "model_size": "not publicly reported",
            "architecture_type": "transformer",
            "training_data": "not reported",
            "reasoning_method": "few-shot prompting",
            "external_tool_used": null,
            "external_tool_description": null,
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning and NL-&gt;FOL translation",
            "task_type": "first-order logical deduction",
            "performance_metric": "accuracy",
            "performance_value": "Few-shot NL prompting: 49.53% accuracy (Table 4).",
            "comparison_with_baseline": "Underperforms GPT-3.5 and GPT-4.",
            "key_findings": "Earlier model with lower performance on strict FOL reasoning tasks compared to later GPT variants.",
            "limitations": "Low few-shot accuracy on FOLIO relative to newer models.",
            "uuid": "e6832.3",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "LLaMA-13B",
            "name_full": "LLaMA 13B",
            "brief_description": "A 13-billion parameter open model family member evaluated few-shot on FOLIO; shows near-chance performance on the reasoning task.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-13B",
            "model_description": "Decoder-only transformer language model (13B parameters) from LLaMA family.",
            "model_size": "13B",
            "architecture_type": "transformer",
            "training_data": "not reported in this paper",
            "reasoning_method": "few-shot prompting",
            "external_tool_used": null,
            "external_tool_description": null,
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning benchmark",
            "task_type": "first-order logical deduction (truth-value classification)",
            "performance_metric": "accuracy",
            "performance_value": "Few-shot NL prompting: 33.63% (â‰ˆchance 33%).",
            "comparison_with_baseline": "Slightly above random chance; substantially lower than larger LLaMA-70B and GPT models.",
            "key_findings": "Small/medium-sized LMs struggle on FOLIO in few-shot setups.",
            "limitations": "Very limited capability for complex first-order reasoning in few-shot evaluation.",
            "uuid": "e6832.4",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "LLaMA-70B",
            "name_full": "LLaMA 70B",
            "brief_description": "A 70B-parameter LLaMA-family model evaluated with few-shot prompting and advanced prompting strategies showing modest gains but still below GPT-4.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-70B",
            "model_description": "Decoder-only transformer language model (70B parameters). Evaluated with few-shot prompting, Chain-of-Thought and Tree-of-Thought prompting.",
            "model_size": "70B",
            "architecture_type": "transformer",
            "training_data": "not reported in this paper",
            "reasoning_method": "few-shot prompting; Chain-of-Thought (CoT) and Tree-of-Thought (ToT) applied",
            "external_tool_used": null,
            "external_tool_description": null,
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning benchmark",
            "task_type": "first-order logical deduction",
            "performance_metric": "accuracy",
            "performance_value": "Few-shot NL prompting: 43.97% (Table text ~44.0%); +CoT =&gt; 47.8%; +ToT =&gt; 48.4%.",
            "comparison_with_baseline": "About 10% better than LLaMA-13B; CoT/ToT provide modest improvements (~3-4 pp).",
            "key_findings": "Scaling helps but larger open models still trail GPT-4; prompting strategies give further gains.",
            "limitations": "Remains substantially below top-performing GPT-4+methods on deep FOL reasoning.",
            "uuid": "e6832.5",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "BERT / RoBERTa",
            "name_full": "BERT / RoBERTa (fine-tuned)",
            "brief_description": "Standard pretrained encoder transformers fine-tuned on FOLIO for truth-value classification; obtain moderate performance when fully supervised.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT; RoBERTa",
            "model_description": "Pretrained encoder transformers (BERT and RoBERTa) fine-tuned with an added two-layer classification head for 3-way truth-value prediction.",
            "model_size": "base: ~110M; large: ~340M",
            "architecture_type": "transformer (encoder)",
            "training_data": "Fine-tuned on FOLIO training split (1,001 examples)",
            "reasoning_method": "fully supervised fine-tuning on labelled FOLIO examples",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning benchmark",
            "task_type": "first-order logical deduction (truth-value classification)",
            "performance_metric": "accuracy",
            "performance_value": "BERT-base 56.83%; BERT-large 59.0%; RoBERTa-base 56.8%; RoBERTa-large 62.1% (Table 4).",
            "comparison_with_baseline": "All fine-tuned encoder models outperform majority baseline (38.5%) and random (33.3%); RoBERTa-large performs best among them at 62.1%.",
            "key_findings": "Supervised fine-tuning on FOLIO yields better performance than few-shot prompting for some smaller LMs; fine-tuning can exploit dataset-specific patterns.",
            "limitations": "Fine-tuned models still fall short of expert human performance and best neurosymbolic methods; may overfit template patterns (HybLogic) rather than general FOL reasoning.",
            "uuid": "e6832.6",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Flan-T5-Large",
            "name_full": "Flan-T5-Large (instruction-tuned T5)",
            "brief_description": "Instruction-tuned encoder-decoder transformer fine-tuned on FOLIO for classification; achieves the highest accuracy among supervised fine-tuning models reported.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Flan-T5-Large",
            "model_description": "Sequence-to-sequence transformer (Flan-T5 variant) with instruction tuning, fine-tuned for the truth-value classification task.",
            "model_size": "783M",
            "architecture_type": "transformer (encoder-decoder)",
            "training_data": "Fine-tuned on FOLIO training split",
            "reasoning_method": "fully supervised fine-tuning",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning benchmark",
            "task_type": "first-order logical deduction (truth-value classification)",
            "performance_metric": "accuracy",
            "performance_value": "65.7% accuracy (best among finetuned models reported).",
            "comparison_with_baseline": "+~6 pp over RoBERTa-large; substantial improvement over majority baseline.",
            "key_findings": "Instruction-tuned seq2seq fine-tuning yields the strongest supervised performance on FOLIO in this study.",
            "limitations": "Still substantially below neurosymbolic methods and expert performance; fine-tuning limited by dataset size.",
            "uuid": "e6832.7",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Chain-of-Thought (CoT)",
            "name_full": "Chain-of-Thought prompting",
            "brief_description": "A prompting technique that elicits intermediate reasoning steps from an LLM to improve performance on complex reasoning tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "prompting strategy",
            "model_description": "Sequential natural-language rationales or intermediate steps included in prompts (few-shot) to guide LLMs to break down reasoning.",
            "model_size": null,
            "architecture_type": "prompting/control-flow",
            "training_data": "few-shot exemplars from FOLIO in experiments",
            "reasoning_method": "eliciting step-by-step intermediate reasoning (CoT)",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "FOLIO",
            "benchmark_description": "Applied to truth-value classification on FOLIO",
            "task_type": "first-order logical deduction with intermediate rationale",
            "performance_metric": "accuracy",
            "performance_value": "When applied to GPT-4 few-shot: CoT improves accuracy from 64.2% to 68.9% (+4.7 pp).",
            "comparison_with_baseline": "+~4+ pp over vanilla few-shot GPT-4",
            "key_findings": "CoT increases GPT-4 performance on FOLIO; helps elicit multi-step reasoning but does not close the gap to expert performance.",
            "limitations": "Still fails on many deep-chain examples; can produce faulty intermediate steps for complex derivations (paper reports 65% faulty reasoning paths among GPT-4 errors).",
            "uuid": "e6832.8",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Self-Consistency (SC)",
            "name_full": "Self-Consistency for Chain-of-Thought",
            "brief_description": "A decoding/aggregation technique that samples multiple chain-of-thought reasoning traces and selects the most consistent final answer.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "decoding/aggregation method",
            "model_description": "Aggregate multiple stochastic CoT generations and pick the most frequent final answer (self-consistency).",
            "model_size": null,
            "architecture_type": "decoding/aggregation",
            "training_data": "few-shot CoT exemplars from FOLIO used during experiments",
            "reasoning_method": "ensemble over multiple CoT traces (self-consistency)",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "FOLIO",
            "benchmark_description": "Applied in combination with CoT on GPT-4",
            "task_type": "first-order logical deduction (truth-value classification)",
            "performance_metric": "accuracy",
            "performance_value": "CoT+SC on GPT-4: 69.5% accuracy (+0.6 pp over CoT alone; +5.3 pp over vanilla few-shot).",
            "comparison_with_baseline": "Small additional improvement over CoT; overall helpful but modest.",
            "key_findings": "Self-consistency gives incremental gains beyond CoT on FOLIO.",
            "limitations": "Computationally more expensive (multiple samples); still insufficient for many deep reasoning examples.",
            "uuid": "e6832.9",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Tree-of-Thought (ToT)",
            "name_full": "Tree-of-Thought prompting",
            "brief_description": "A search-based deliberation framework where the LLM explores a tree of intermediate reasoning steps and uses a search/pruning strategy to select a final answer.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "prompting/control-flow method",
            "model_description": "Exploratory prompting that constructs and searches over multiple possible reasoning branches (tree of thoughts) to improve problem solving.",
            "model_size": null,
            "architecture_type": "search over LM-generated reasoning traces",
            "training_data": "few-shot examples from FOLIO used in experiments",
            "reasoning_method": "search-based exploration of reasoning chains",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "FOLIO",
            "benchmark_description": "Evaluated on few-shot truth-value classification",
            "task_type": "first-order logical deduction",
            "performance_metric": "accuracy",
            "performance_value": "ToT on GPT-4: 70.0% accuracy (slightly better than CoT+SC and CoT alone).",
            "comparison_with_baseline": "+~5.8 pp over vanilla few-shot GPT-4",
            "key_findings": "Tree-of-Thought offers the largest single-method prompting gain reported in the paper for GPT-4.",
            "limitations": "Higher computational cost and complexity; still fails on many hybLogic/deep reasoning cases.",
            "uuid": "e6832.10",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "LINC",
            "name_full": "LINC (Olausson et al., 2023)",
            "brief_description": "A neurosymbolic approach that combines language models with first-order logic provers; evaluated in this paper using GPT-4 as the LM backbone and shows substantial accuracy gains on FOLIO.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LINC",
            "model_description": "Neurosymbolic pipeline combining an LLM (GPT-4 in experiments) with an FOL prover to perform faithful logical reasoning.",
            "model_size": "base LM: GPT-4 (size not reported)",
            "architecture_type": "neurosymbolic (transformer + FOL prover)",
            "training_data": "few-shot examples from FOLIO used in experiments (paper-level description); original LINC paper not introduced here",
            "reasoning_method": "combine LLM reasoning with a symbolic FOL prover to validate/guide inference",
            "external_tool_used": true,
            "external_tool_description": "Integrates an external first-order logic prover (neurosymbolic architecture) to check/augment LM inferences; in this paper LINC is applied using GPT-4 as LM base.",
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning truth-value classification",
            "task_type": "first-order logical deduction (hybrid neurosymbolic inference)",
            "performance_metric": "accuracy",
            "performance_value": "73.1% accuracy on FOLIO (Table 4).",
            "comparison_with_baseline": "â‰ˆ+9 percentage points over few-shot GPT-4 baseline (~64.2%).",
            "key_findings": "Neurosymbolic integration meaningfully improves strict FOL reasoning over vanilla prompting of GPT-4.",
            "limitations": "Requires integration with external provers; extra engineering and computational cost; not all failure modes eliminated.",
            "uuid": "e6832.11",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Logic-LM",
            "name_full": "Logic-LM (Pan et al., 2023)",
            "brief_description": "A method that empowers LLMs with symbolic solvers for faithful logical reasoning; when applied with GPT-4 in this paper it yields the highest reported accuracy among tested approaches.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Logic-LM",
            "model_description": "A neurosymbolic method that couples LLM outputs with symbolic solvers to produce faithful logical inferences and proofs.",
            "model_size": "base LM: GPT-4 (size not reported)",
            "architecture_type": "neurosymbolic (transformer + symbolic solver)",
            "training_data": "few-shot examples from FOLIO used for evaluation; original Logic-LM training specifics not provided here",
            "reasoning_method": "LM-guided invocation of symbolic solvers to validate and construct logical derivations",
            "external_tool_used": true,
            "external_tool_description": "Uses symbolic solvers (theorem provers) integrated with GPT-4 to improve logical correctness of outputs.",
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning truth-value classification",
            "task_type": "first-order logical deduction with symbolic verification",
            "performance_metric": "accuracy",
            "performance_value": "78.1% accuracy on FOLIO (Table 4).",
            "comparison_with_baseline": "â‰ˆ+13.9 percentage points over few-shot GPT-4 (~64.2%).",
            "key_findings": "Symbolic solver integration yields the largest performance gains reported in the paper, demonstrating the effectiveness of neurosymbolic methods for strict logical reasoning.",
            "limitations": "Requires external symbolic tooling and orchestration; increased complexity and computational cost; paper notes substantial residual gap to perfect reasoning despite gains.",
            "uuid": "e6832.12",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "DetermLR",
            "name_full": "DetermLR (Sun et al., 2023)",
            "brief_description": "An approach (referenced as augmenting LLMs for determinacy in logical reasoning) applied with GPT-4 in this paper and reported to significantly improve FOLIO accuracy.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "DetermLR",
            "model_description": "Method that augments LLMs with mechanisms to make logical reasoning more determinate, applied here on GPT-4 as the LM backbone.",
            "model_size": "base LM: GPT-4 (not reported)",
            "architecture_type": "neurosymbolic / augmentation (transformer + symbolic/deterministic component)",
            "training_data": "few-shot examples from FOLIO for evaluation",
            "reasoning_method": "LM augmentation with deterministic logical checks/procedures (paper references only; exact integration details in original DetermLR paper)",
            "external_tool_used": true,
            "external_tool_description": "Combines LLM outputs with deterministic logical modules/provers to improve correctness of deductions.",
            "benchmark_name": "FOLIO",
            "benchmark_description": "First-order reasoning truth-value classification",
            "task_type": "first-order logical deduction (augmented with deterministic verification)",
            "performance_metric": "accuracy",
            "performance_value": "77.5% accuracy on FOLIO (Table 4).",
            "comparison_with_baseline": "â‰ˆ+13.3 percentage points over few-shot GPT-4 (~64.2%).",
            "key_findings": "Augmenting LLMs with deterministic or symbolic verification substantially improves strict logical reasoning performance.",
            "limitations": "Requires coupling to external logical modules; extra engineering and compute overhead; not fully eliminating deep-chain errors.",
            "uuid": "e6832.13",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "FOL inference engine (Stanford CS221)",
            "name_full": "Stanford CS221 first-order logic inference engine (used for verification)",
            "brief_description": "A compact Python theorem-prover module adopted to verify FOL annotations and determine conclusion truth values; used in dataset construction and evaluation.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "FOL inference engine (Stanford CS221)",
            "model_description": "A compact first-order logic inference engine used to check syntactic validity and to execute the translated FOL to compute True/False/Unknown labels.",
            "model_size": null,
            "architecture_type": "symbolic theorem prover",
            "training_data": null,
            "reasoning_method": "symbolic first-order theorem proving",
            "external_tool_used": true,
            "external_tool_description": "Converts human-written FOL into the prover's input via a custom parser and runs proofs/queries to obtain conclusion labels; used both to verify dataset annotations and to evaluate NL-&gt;FOL execution accuracy.",
            "benchmark_name": "FOLIO (verification tool)",
            "benchmark_description": "Tool for verifying FOL annotations and computing ground-truth labels",
            "task_type": "symbolic first-order theorem proving (verification)",
            "performance_metric": "used as authoritative execution engine for labels; not reported as an accuracy metric itself",
            "performance_value": "N/A (used as verifier)",
            "comparison_with_baseline": "N/A",
            "key_findings": "Enables automated, exact evaluation of NL-&gt;FOL translations via execution accuracy metric.",
            "limitations": "Original prover input syntax differs from human FOL; required building a parser to convert annotated FOL into prover format; prover resource/time limits apply.",
            "uuid": "e6832.14",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "NL-&gt;FOL translation (task)",
            "name_full": "Natural Language to First-Order Logic Translation",
            "brief_description": "A translation task introduced in FOLIO where models must generate FOL formulas semantically equivalent to NL premises and conclusions; evaluated by syntactic validity and execution accuracy with the FOL prover.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "task",
            "model_description": "Generative task to translate NL sentences/stories into syntactically-valid FOL and semantically correct FOL such that a prover yields the same truth values.",
            "model_size": null,
            "architecture_type": null,
            "training_data": "FOLIO NL-FOL paired annotations (few-shot prompting used in experiments)",
            "reasoning_method": "generation of formal FOL expressions from NL; evaluated by prover execution",
            "external_tool_used": true,
            "external_tool_description": "Syntactic validity checked locally; semantic correctness judged by feeding generated FOL to the FOL inference engine (ExcAcc).",
            "benchmark_name": "FOLIO NL-FOL translation",
            "benchmark_description": "Measures syntactic validity (SynV) and inference-engine execution accuracy (ExcAcc) of generated FOL from NL prompts.",
            "task_type": "semantic parsing into first-order logic; executable formalization",
            "performance_metric": "SynV (binary per example) and ExcAcc (prover label accuracy)",
            "performance_value": "Few-shot SynV: GPT-3.5-Turbo 93.3% / ExcAcc 56.0%; GPT-4 SynV 93.9% / ExcAcc 63.8% (Table 5). Zero-shot SynV lower (GPT-3.5 68.4%, GPT-4 86.1%).",
            "comparison_with_baseline": "GPT-4 better than GPT-3.5 both at syntactic validity and execution accuracy; models are proficient at FOL syntax but weaker at semantic equivalence.",
            "key_findings": "Large LMs can generate syntactically-valid FOL but often fail to produce FOL semantically equivalent to NL (lower ExcAcc).",
            "limitations": "ExcAcc substantially below SynV â€” models produce syntactically plausible but semantically incorrect FOL; NL-&gt;FOL alignment remains challenging.",
            "uuid": "e6832.15",
            "source_info": {
                "paper_title": "FOLIO: Natural Language Reasoning with First-Order Logic",
                "publication_date_yy_mm": "2022-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers",
            "rating": 2,
            "sanitized_title": "linc_a_neurosymbolic_approach_for_logical_reasoning_by_combining_language_models_with_firstorder_logic_provers"
        },
        {
            "paper_title": "Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning",
            "rating": 2,
            "sanitized_title": "logiclm_empowering_large_language_models_with_symbolic_solvers_for_faithful_logical_reasoning"
        },
        {
            "paper_title": "From indeterminacy to determinacy: Augmenting logical reasoning capabilities with large language models",
            "rating": 2,
            "sanitized_title": "from_indeterminacy_to_determinacy_augmenting_logical_reasoning_capabilities_with_large_language_models"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "Transformers as soft reasoners over language",
            "rating": 1,
            "sanitized_title": "transformers_as_soft_reasoners_over_language"
        },
        {
            "paper_title": "Transformers as soft reasoners over language. (2021 extension / ProofWriter / RuleTaker citations)",
            "rating": 1,
            "sanitized_title": "transformers_as_soft_reasoners_over_language_2021_extension_proofwriter_ruletaker_citations"
        },
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 1,
            "sanitized_title": "gpt4_technical_report"
        }
    ],
    "cost": 0.02220225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>FOLIO: Natural Language Reasoning with First-Order Logic
11 Oct 2024</p>
<p>Simeng Han 
Yale University</p>
<p>Hailey Schoelkopf 
Yale University</p>
<p>Yilun Zhao 
Yale University</p>
<p>Zhenting Qi 
Harvard University</p>
<p>Martin Riddell 
Yale University</p>
<p>Wenfei Zhou 
NVIDIA</p>
<p>James Coady 
Yale University</p>
<p>David Peng 
Yale University</p>
<p>Yujie Qiao 
Yale University</p>
<p>Luke Benson 
Yale University</p>
<p>Lucy Sun 
Yale University</p>
<p>Alex Wardle-Solano 
Yale University</p>
<p>Hannah Szabo 
Yale University</p>
<p>Ekaterina Zubova 
Yale University</p>
<p>Matthew Burtell 
Yale University</p>
<p>Jonathan Fan 
Iowa City West High School</p>
<p>Yixin Liu 
Yale University</p>
<p>Brian Wong 
Yale University</p>
<p>Malcolm Sailor 
Yale University</p>
<p>Ansong Ni 
Yale University</p>
<p>Linyong Nan 
Yale University</p>
<p>Jungo Kasai 
University of Washington</p>
<p>Tao Yu 
University of Hong Kong</p>
<p>Rui Zhang 
Penn State University
8 Meta AI</p>
<p>Alexander R Fabbri 
Salesforce Research</p>
<p>Wojciech KryÅ›ci Åƒski 
Salesforce Research</p>
<p>Semih Yavuz 
Salesforce Research</p>
<p>Ye Liu 
Salesforce Research</p>
<p>Victoria Xi 
Lin 
Shafiq Joty 
Salesforce Research</p>
<p>Yingbo Zhou 
Salesforce Research</p>
<p>Caiming Xiong 
Salesforce Research</p>
<p>Rex Ying 
Yale University</p>
<p>Arman Cohan 
Yale University</p>
<p>Dragomir Radev 
Yale University</p>
<p>Salesforce Research</p>
<p>FOLIO: Natural Language Reasoning with First-Order Logic
11 Oct 202491EE60091D091474A0C7AA791AED16AEarXiv:2209.00840v3[cs.CL]
Large language models (LLMs) have achieved remarkable performance on a variety of natural language understanding tasks.However, existing benchmarks are inadequate in measuring the complex logical reasoning capabilities of a model.We present FOLIO, a human-annotated, logically complex and diverse dataset for reasoning in natural language (NL), equipped with first-order logic (FOL) annotations.FOLIO consists of 1,430 examples (unique conclusions), each paired with one of 487 sets of premises used to deductively reason for the validity of each conclusion.The logical correctness of the premises and conclusions is ensured by their FOL annotations, which are automatically verified by an FOL inference engine.In addition to the main NL reasoning task, NL-FOL pairs in FOLIO constitute a new NL-FOL translation dataset.Our experiments on FOLIO systematically evaluate the FOL reasoning ability of supervised fine-tuning on medium-sized language models.For both NL reasoning and NL-FOL translation, we benchmark multiple state-of-the-art language models.Our results show that a subset of FOLIO presents a challenge for one of the most capable Large Language Model (LLM) publicly available, GPT-4.</p>
<p>Introduction</p>
<p>Large language models (LLMs) have achieved remarkable performance on a variety of natural language tasks (OpenAI et al., 2023;Touvron et al., 2023;Srivastava et al., 2023;Wang et al., 2019a).Logical reasoning is a central component for intelligent systems and should be sufficiently and independently evaluated (Russell and Norvig, 2010).</p>
<p>However, existing natural language tasks are inadequate in measuring the complex logical reasoning capability of a model (Srivastava et al., 2023;Saparov and He, 2023;Tian et al., 2021).</p>
<p>Several datasets related to logical reasoning have recently been proposed.However, existing benchmarks often exhibit limited complexity in reasoning or lack language naturalness.Some of these common benchmarks do not specifically evaluate logical reasoning independently of other forms of reasoning (Yu et al., 2020;Liu et al., 2021).Those specifically designed for measuring logical reasoning are insufficient in terms of logical reasoning complexity and natural language variety.As shown in Table 1, examples in RuleTaker (Clark et al., 2020) and LogicNLI (Tian et al., 2021) need at most five depths of reasoning.The entire corpus of RuleTaker or LogicNLI has fewer than 50 distinct abstract syntax trees.RuleTaker has only 101 words in its vocabulary and LogicNLI has 1077 words in the vocabulary.Moreover, none of them are written by humans with information drawn from real-world knowledge, making them less applicable to real-world reasoning scenarios.The logical deduction portion in BigBench (Srivastava et al., 2023) requires commonsense reasoning besides logical deduction.ProntoQA (Saparov and He, 2023) only contains logical reasoning questions that are answerable with repeated applications of the Modus Ponens inference rule.</p>
<p>We present a natural language reasoning dataset, FOLIO, with first-order logic reasoning problems which require the models to decide the correctness of conclusions given a world defined by the premises.In FOLIO, we aim to ensure high lan- A FOLIO example based on the Wild Turkey Wikipedia page: https://en.wikipedia.org/wiki/Wild_turkeyNL premises NL Conclusions -&gt; Labels 1.There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould's wild turkey, A. Tom is an Ocellated wild turkey.-&gt; True Merriam's wild turkey, Rio Grande wild turkey, and the Ocellated wild turkey.</p>
<p>B. Tom is an Eastern wild turkey.-&gt; False 2. Tom is not an Eastern wild turkey.</p>
<p>C. Joey is a wild turkey.-&gt; Unknown 3. Tom is not an Osceola wild turkey.4. Tom is also not a Gould's wild turkey.5. Tom is neither a Merriam's wild turkey, nor a Rio Grande wild turkey.6. Tom is a wild turkey.</p>
<p>FOL Premises</p>
<p>FOL conclusions -&gt; Labels
1. âˆ€x(WildTurkey(x) â†’ (EasternWildTurkey(x) âˆ¨ OsceolaWildTurkey(x) âˆ¨ GouldsWildTurkey(x) A. OcellatedWildTurkey(tom) -&gt; True âˆ¨ MerriamsWildTurkey(x) âˆ¨ RiograndeWildTurkey(x) âˆ¨ OcellatedWildTurkey(x))) B. EasternWildTurkey(tom) -&gt; False 2. Â¬EasternWildTurkey(tom)
C. WildTurkey(joey) -&gt; Unknown 3. Â¬OsceolaWildTurkey(tom)) 4. Â¬GouldsWildTurkey(tom) 5. Â¬MerriamsWildTurkey(tom) âˆ§ Â¬RiograndeWildTurkey(tom) 6. WildTurkey(tom) Table 2: An example story in FOLIO based on the knowledge from the Wikipedia page on wild turkeys.The story consists of five premises and three conclusions with their corresponding FOL formulas and labels for the conclusions.All five premises are needed to infer the conclusions.The model needs to reason under logic patterns with universal quantification (âˆ€), negation (Â¬), conjunction (âˆ§), and disjunction (âˆ¨).guage naturalness and complexity, an abundant vocabulary, and factuality while also maintaining high reasoning complexity.FOLIO is a high-quality and manually curated dataset, written by CS undergraduate and graduate students and researchers in academia and industry.To ensure the conclusions of our examples follow the premises logically, we annotated all reasoning examples with first-order logic (FOL) formulas.An example of FOLIO is shown in Table 2. Based on our annotations, we propose a new NL-FOL translation task where an NL reasoning example is translated into its FOL counterpart.Finally, we benchmark the performance of strong LMs in both fully supervised and few-shot settings to understand their capabilities in logical reasoning (i.e., deriving the truth value of a logical conclusion from NL premises).</p>
<p>Under the few-shot setting, the most capable publicly available LLM so far achieves only 53.1% on the stories written in a hybrid manner, which is slightly better than random.</p>
<p>To sum up, the contributions of this paper are threefold.1) We release a natural language reasoning dataset written by expert annotators, FOLIO, with first-order logical reasoning problems.2) We use formal logic, i.e., FOL to ensure the logical validity of the examples written in NL and propose a new NL-FOL translation task.3) We benchmark the performance of LMs by fine-tuning models and prompting LLMs with few-shot examples, on the FOLIO reasoning task.We hope that FOLIO, as a challenging logical reasoning dataset, will be used to facilitate measuring progress in the logical reasoning capabilities of language models.</p>
<p>Related Work</p>
<p>Datasets for reasoning from text</p>
<p>Developing models that can reason in texts has been a core goal in NLP since the field's early days (Cooper et al., 1996).Since then, there has been massive progress in reasoning over text.Various benchmarks that focus on different aspects of reasoning over textual inputs are proposed, including natural language inference (NLI) (Bowman et al., 2015;Wang et al., 2019b), reasoning for commonsense knowledge (Talmor et al., 2019;He et al., 2021) and multi-hop reasoning (Yang et al., 2018;Chen et al., 2020).Among these reasoning abilities, logical reasoning has recently attracted an increasing amount of study.ReClor (Yu et al., 2020) and LogiQA (Liu et al., 2021) both collected multiplechoice questions from standardized graduate admission examinations, answering which requires various types of logical reasoning.However, these datasets cover mixed forms of reasoning and are not intended to test logical reasoning in isolation.</p>
<p>Meanwhile, testing logical reasoning in isolation without involving other forms of reasoning has also attracted researchers in recent years.CLUTRR (Sinha et al., 2019) covers inductive reasoning, which is beyond the scope of first-order logic.Synthetic corpuses of deductive reasoning are proposed to evaluate the deductive reasoning ability of pretrained LMs (Clark et al., 2021;Saeed et al., 2021;Tian et al., 2021).However, these datasets do not contain highly natural sentences and often cover limited forms of logic while FOL is much more expressive.Kazemi et al. (2023) created a dataset for reasoning with contradictory information.Kawabata and Sugawara (2023) crowdsourced rationales for over 3000 examples based on ReClor (Yu et al., 2020).ProntoQA (Saparov and He, 2023) is comprised solely of logical reasoning queries that can be resolved through applying the Modus Ponens inference rule while FOLIO questions require applications of multiple types of inference rules.As shown in Table 1, FOLIO is the first large-scale first-order logic (FOL) reasoning dataset with formal logic annotations in FOL.FO-LIO is logically diverse and complex with complex natural language sentences and a rich vocabulary.</p>
<p>Reasoning using large language models</p>
<p>Reasoning has been demonstrated as one of the emergent abilities of LLMs of sufficient scale recently (Talmor et al., 2020;Wei et al., 2022a;Chowdhery et al., 2022).One such emergent behavior, Chain-of-Thought prompting (Wei et al., 2022b), consists of a series of intermediate reasoning steps output by an LLM.This improves the performance on arithmetic, commonsense, and symbolic reasoning benchmarks significantly.There has been a line of research continuing on from Chain-of-Thought (Kojima et al., 2022;Li et al., 2022;Yao et al., 2023) to elicit reasoning behavior from LLMs.Building on Chain-of-Thought prompting, many techniques used on top of LLMs to improve downstream performance have been formalized into control flows and programs.These are called language model cascades (Dohan et al., 2022), subsuming techniques such as Chain-of-Thought prompting, STaR (Zelikman et al., 2022), and Selection-Inference (Creswell et al., 2022) for reasoning.Dasgupta et al. (2022) studied the reasoning ability of LLMs but only used a small set of 48 syllogisms with only two premises each.Saparov and He (2023) created a synthetic dataset that and showed that LLMs are capable of making correct individual deduction steps.</p>
<p>With FOLIO, we aim to set a high standard, ensuring that achieving high performance through superficial strategies and shallow heuristics is prevented, allowing a robust evaluation of the firstorder logic reasoning capabilities of LLMs.We show that many LLMs fall short on complex firstorder logic reasoning, and that significant room for improvement in this area remains.</p>
<p>FOLIO Corpus Construction</p>
<p>We collected FOLIO through a carefully designed manual annotation process to achieve high-quality examples that necessitate complex logical reasoning.Writing natural language reasoning stories with FOL requires sufficient knowledge in both semantic parsing and first-order logic, as well as strong analytical skills.Given the complexities of such annotations, we selected annotators based on a few important criteria to ensures that our dataset is annotated with the highest level of precision and expertise, reflecting the complexity and nuance required for first-order logical reasoning.1).Our annotators are either college or graduate students who are native English speakers or possess nearnative proficiency in English.4 2).They possess formal education in first-order logic, having either completed relevant coursework or undertaken self-directed studies in first-order logic or seman-tic parsing.At the NL quality check stage, only annotators who are experts in natural language processing or computational linguistics are involved.For the FOL quality check, only annotators who are experts in first-order logic are involved.We also give the annotators several training sessions on how to write a story, by providing them with detailed annotation guidelines.All stories and FOL annotations in FOLIO are written and reviewed by expert annotators, including CS undergraduate and graduate students, and senior researchers, who met the aforementioned criteria.</p>
<p>We develop our dataset in six stages: WikiLogic collection, HybLogic collection, NL quality control, FOL quality control, NL-FOL alignment and FOL verification, spending 980 man-hours in total.</p>
<p>Example collection</p>
<p>We collected our dataset using two different methods in order to obtain examples that are both logically diverse and complex and have abundant abstract syntax tree (AST) variations.The annotators are free to write stories based on any topic they want while writing the stories.</p>
<p>WikiLogic: annotation from scratch using Wikipedia articles as seeds.At this annotation stage, the annotators are asked to select random Wikipedia pages by repeatedly using the Wikipedia Special Random link. 1 The Wikipedia articles are used to develop ideas for topics to write new stories.We ask the annotators to create new stories from scratch without using templates based on realworld knowledge, which should be plausible in general.Each of the stories is composed of several premises and conclusions with truth values of True, False, or Unknown (see Table 2 for an example).We also ask the annotators to write parallel FOL sentences for both the premises and conclusions.This results in a wide range of topics, abundant AST variations, and a wide vocabulary for FOLIO.Table 1 shows a comparison of FOLIO with other reasoning datasets that purely evaluate first-order logic or deductive reasoning.</p>
<p>HybLogic: hybrid annotation The task of generating logically sound stories from scratch for a set of facts is very time-consuming for human writers, where the main challenge is to create complex and varied logical patterns to arrive at a conclusion.To address the problems of solely using manual 1 https://en.wikipedia.org/wiki/Special:Randomannotation, we also consider a hybrid approach to facilitate the process.Our hybrid method is based on a common form of logical stories: syllogisms.A syllogism consists of two premises and a single conclusion, and the conclusion states some facts about the entities and categories in the premises.</p>
<p>In this approach, we first generate logically valid stories, which are templates containing abstract categories and entities, by combining multiple syllogisms into a single story template: the conclusion of one syllogism is used as a premise for the next syllogism.There are 256 logically distinct types of syllogisms and 24 of them are valid (Lehman, 1973).We use various combinations of 24 valid syllogisms.We also add in conjunction, disjunction, and implication.We show an example of the resulting templates in Appendix B. We then ask human annotators to assign nouns, phrases, or clauses to the abstract entities or categories that reflect real-life scenarios to each template and write logically-valid stories in natural language.The usage of the template is to ensure that we have a set of varied and complex logical stories with multiple conclusions.There are many ways of expressing the same logic template in natural language, and so the generated templates augment, rather than limit, the creativity of humans.</p>
<p>Quality control for NL sentences</p>
<p>To ensure the highest quality of the dataset, we dedicated considerable attention to the following key aspects of the natural language sentences during the quality control process.</p>
<p>Factuality and bias Our dataset prioritizes realism and factual accuracy, steering clear of biases and stereotypes linked to identity markers like race, ethnicity, gender, sexuality, nationality, class, and religion.Toward these objectives, we manually screened all stories and found that 39.2% of the stories suffer from at least one of these issues.We implemented a detailed protocol to rewrite these stories.The protocol is in Appendix C.</p>
<p>Language quality Apart from grammar, we make sure the sentences in our dataset are highly natural.All the sentences are first checked with a grammar checking tool, Grammarly.Our annotators who have graduated from or are senior students studying English Literature conducted a thorough round of review for grammatical correctness and language naturalness.We also eliminate natural language ambiguity when it is possible.We include rules on eliminating ambiguity in Appendix D. Employing these rules effectively reduces the ambiguity of natural language in this reasoning dataset, but incurs the tradeoff of limiting variations in some usage of language.However, we note that there is still sufficient variation in terms of sentence structures and logical structures as shown in Table 1.</p>
<p>Quality control for FOL formulas</p>
<p>We adopt the FOL definitions and syntax most widely used in the AI community (Russell and Norvig, 2010).We include more details on the definition of FOL we consider and the FOL modelling convention in Appendix E In preliminary investigations, we found that the human-written FOL formulas suffer from FOL consistency issues, which necessitates an additional round of quality control for FOL formulas.</p>
<p>FOL consistency One NL sentence can be translated into FOL through multiple non-equivalent ways.For example, sometimes additional information inferred from a sentence can be represented in FOL, leading to multiple representations.We therefore design an annotation protocol for FOL translation in order to ensure that our FOL translations are as consistent as possible across all examples in our dataset.We highlight a few important strategies used in the annotation protocol in Appendix F.</p>
<p>NL-FOL alignment review</p>
<p>Apart from checking whether NL and FOL express equivalent meanings, we also add necessary commonsense knowledge in both the NL and FOL premises.Sometimes humans do not write certain commonsense knowledge in the premises that is required in the FOL reasoning process, which is based solely on the premises given.We add such knowledge as additional premises at this stage.In particular, intrinsic properties of some predicates are required in the FOL reasoning process.For example, "LocatedIn(x,y)" should be transitive and "BeFamily(x,y)" should be symmetric.</p>
<p>FOL verification</p>
<p>Recognizing that the FOL formula annotations can be error-prone, we verify the syntactic validity and label consistency of FOL formula annotations with an FOL inference engine.We include the details of the FOL inference engine in Appendix G.</p>
<p>Dataset statistics</p>
<p>We show basic statistics of FOLIO and demonstrate the abundant vocabulary and logical complexity of FOLIO: Tables 1, 3 and Figure 1.Natural language complexity We use the Dale-Chall Readability Formula (Dale andChall, 1948, 1995) to show the text complexity of FOLIO following (Singh et al., 2023;Arps et al., 2022;Wei et al., 2021).We show the distribution of readability in Appendix H.</p>
<p>Basic statistics</p>
<p>Logical complexity and diversity statistics</p>
<p>As shown in Figure 1, the mode of reasoning depths is four in FOLIO.28.7% of the examples need five or more depths of reasoning to infer the conclusions, while the previous datasets needed at most five reasoning depths as shown in Table 1.This illustrates the logical complexity of FOLIO.Table 1 shows that FOLIO also has a much larger number of distinct ASTs than the previous datasets, indicating that FOLIO is much more logically diverse.larger than the previous synthetically constructed datasets for logical reasoning.</p>
<p>Vocabulary and topics</p>
<p>Task Definition</p>
<p>We define two new tasks based on FOLIO, natural language reasoning with first-order logic and NL-FOL translation.</p>
<p>Natural language reasoning with first-order logic</p>
<p>Each natural language (NL) story S in FOLIO consists of n premises: P = {p 1 , p 2 , ..., p n } and m conclusions: H = {h 1 , h 2 , ..., h m }.All NL stories are annotated with parallel FOL stories SF , which are sets of FOL formulas consisting of n premises P F = {pf 1 , pf 2 , ..., pf n } and m conclusions HF = {hf 1 , hf 2 , ..., hf m }. pf i and hf i are logically and semantically similar to p i and h i , respectively.Given P and H, the goal is to determine the truth values of the conclusions: "True", "False" or "Unknown", based on FOL reasoning.</p>
<p>NL-FOL translation</p>
<p>We propose a new natural language to first-order logic translation (NL-FOL translation) task alongside our reasoning dataset.The goal of this task is to translate an NL story S to an FOL story F S.</p>
<p>In particular, each of the NL sentence p i or h i and the parallel FOL formula pf i or hf i should be logically and semantically equivalent.Moreover, the truth values for the conclusions should be the same based on the NL story S and the parallel FOL story F S. In our dataset, the premises and conclusions are set up in such a way to ensure that the inference engine always returns an answer given enough resources such as time and memory.Unlike previous work (Singh et al., 2020) which translates problems with a single premise and a single hypothesis, our task is on translating examples of various lengths with a focus on stories with multiple premises.Thus, it also requires the models to consider discourse-level consistencies as opposed to translation at the sentence level.</p>
<p>NL-FOL evaluation metrics Two metrics are adopted to evaluate NL-FOL translation to capture different aspects of the generation results: 1).Syntactic validity (SynV).The Syntactic Validity score measures whether the FOL formulas are syntactically valid.The score will be 1 if all FOL formulas of an example can pass the syntactic check and 0 otherwise 2).Inference Engine execution accuracy (ExcAcc).The group of translated FOL for premises and conclusions in one story is fed into our inference engine to output the truth value for each conclusion.We define the accuracy of the output labels as the execution accuracy.We leave for future work the design of a more reliable metric of NL-FOL translation.</p>
<p>Experiments</p>
<p>In this section, we describe our experiments and main results.</p>
<p>Experimental setup</p>
<p>Tasks We conduct experiments on the two tasks in Â§4: NL reasoning with first-order logic (logical reasoning) and NL-FOL translation (NL-FOL).</p>
<p>Dataset split We split FOLIO by 70%/15%/15% split for the train/validation/test sets with 1,001/203/226 examples respectively.We split by story so that models are evaluated on unseen stories.</p>
<p>Evaluation metrics</p>
<p>We use accuracy for evaluating logical reasoning performance.For NL-FOL translation, we use the metrics in Section 4.2.</p>
<p>Models</p>
<p>We test the logical reasoning capabilities of LMs using fully supervised fine-tuning and few-shot prompting.We also test NL-FOL translation with few-shot prompting.</p>
<p>Fully supervised fine-tuning As fine-tuning baselines, we experiment with BERT (Devlin et al., 2019), and RoBERTa (Liu et al., 2020).We finetune the base and large versions of both BERT and RoBERTa, with an additional two-layer classification layer to predict the truth values.For the second task, i.e., NL-FOL translation, we only report fewshot prompting methods.Prompting strategies We experiment with incorporating recent prompting strategies into GPT-4 as they have shown improvements in the general reasoning performance of LLMs.The prompting strategies include chain-of-thought (CoT) prompting (Wei et al., 2022b), chain-of-thought prompting with self-consistency (Wang et al., 2023) and treeof-thought prompting (Yao et al., 2023).</p>
<p>Few-shot prompting</p>
<p>Logical reasoning methods</p>
<p>We also test recent methods specifically designed for logical reasoning: Logic-LM (2023), LINC (Olausson et al., 2023) and DetermLR (Sun et al., 2023), using GPT-4 as the base model.For the second task (NL-FOL translation), we use the same examples as in the Few-Shot NL experiments except that all the conclusions are included in each example.</p>
<p>We run experiments on five randomly sampled sets of examples from the training set and report the average accuracy.</p>
<p>Main results</p>
<p>Logical reasoning</p>
<p>The majority baseline of our dataset is 38.5% since in our test set, there are 87, 78 and 61 examples with labels of true, false and unknown respectively.As shown in Table 4, BERTbase and RoBERTa-base have similar performance on FOLIO with 56.83% accuracy.BERT-large has a 2.2% improvement over BERT-base.RoBERTalarge improves 3.1% over BERT-large.Flan-T5-Large achieves the highest performance in the finetuning setting and the accuracy is 65.7%.The model sizes of text-davinci-002, GPT-3.5-Turbo and GPT-4 are hidden from public3 .CoT stands for chain-of-thought prompting (Wei et al., 2022b).SC stands for self-consistency (Wang et al., 2023).ToT stands for tree-of-thought prompting (Yao et al., 2023).</p>
<p>We show that zero-shot prompting GPT-3.5 achieves better results than few-shot prompting text-davinci-002.Under few-shot NL prompting setting, LLama-13B achieves 33.63%, which is only slightly better than chance (33%).LLama-70B achieves 43.97%, around 10% better than LLaMA-13B and obtains improvements of around 4% with Chain-of-thought prompting and Tree of Thought prompting.Text-davinci-002 achieves 49.53% and GPT-3.5 achieves 58.34%.GPT-4 achieves the best results among GPT series models.</p>
<p>Incorporating recent prompting strategies increases the performance of vanilla few-shot prompting.Chain-of-thought prompting achieves more than a 4% increase over GPT-4.Self-consistency (SC) improves chain-of-thought prompting by 0.6% percent.Tree-of-thought prompting achieves slightly better result than self-consistency with chain-of-thought prompting.For the results of recent methods developed for logical reasoning, LINC (Olausson et al., 2023) achieves around a 9% increase over few-shot prompting GPT-4.Both Logic-LM (GPT-4)( 2023) and DetermLR ( 2023) achieves more than a 13% increase over few-shot prompting GPT-4, showing the superiority of the methods on logical reasoning.</p>
<p>NL-FOL translation</p>
<p>Table 5 shows the results of NL-FOL translation.The syntactic validity scores are around 93% with both GPT-3.5-Turbo and GPT-4.This indicates that language models with sufficient scales are good at picking up the patterns for FOL formulas and generating syntactically valid FOL formulas.However, GPT-3.5-Turbo and GPT-4 are not yet good at translating an NL story to a logically or semantically similar FOL counterpart, as indicated by the low inference engine execution accuracy score.</p>
<p>Error Analysis</p>
<p>Below we provide analysis of our results and key findings, providing additional insights into our dataset FOLIO and the current capabilities of LLMs in logical reasoning.example chains.We note that the presence and prevalence of these difficult examples are unique to FOLIO.FOLIO's unique complexity reveals that current LMs are limited in their ability to extrapolate to longer and more complex reasoning chains, and suggests an avenue for further study.Models have higher accuracy on WikiLogic than on HybLogic As shown in Table 6, in logical reasoning, GPT-3.5 and GPT-4 achieve substantially lower results on HybLogic than on WikiLogic and the result is slightly higher than chance.We hypothesize that this is because HybLogic has high logical complexity that the SoTA LLMs like GPT-4 cannot solve yet while WikiLogic examples require shorter reasoning chains which the model is already capable of solving.Moreover, since the examples in WikiLogic are created from scratch by humans, it is possible that LLMs have seen similar texts with similar logical patterns in the training data.However, fine-tuning RoBERTa-large achieves higher performance on HybLogic than on WikiLogic.This is likely because HybLogic is created from templates and some of the logical patterns can be learned during fine-tuning.</p>
<p>Models have higher accuracy on examples with fewer reasoning depths than on those with higher number of reasoing depths</p>
<p>In NL-FOL translation, performs 10 points better on HybLogic than WikiLogic.This could be because WikiLogic has more distinct and diverse sentence-level logical and language patterns and FOL annotations.WikiLogic has 53 ASTs while HybLogic has 33.Despite being more logically complex on a story level, FOL translations for Hy-bLogic stories have simpler logical structures on a statement level.We include case study for one WikiLogic example and one HybLogic example in Appendix I and further analysis on model performance in Appendix J.</p>
<p>Faulty path 65%</p>
<p>Wrong derivation 25%</p>
<p>Wrong syntactic comprehension 5%</p>
<p>Spurious shortcut 5%</p>
<p>GPT-4 Output</p>
<p>We know that all children are human (premise 1) and if someone is underage, they are a child (premise 2).People are either underage or of age (premise 3).If someone is of age, they can vote (premise 4) and get married (premise 5).If Jack is a child and a human, then Jack is neither able to vote nor get married (premise 6).We don't have any information about Jack's age, so we cannot determine if he is a child or of age.Therefore, we cannot determine if Jack is able to vote and get married.</p>
<p>Table 8: Case study for the scenario where a model is unable to form the correct reasoning chain.</p>
<p>Human evaluation on model outputs We conduct human evaluation on the GPT-4 model outputs with wrong truth value predictions.As shown in Table 7, approximately 65% of the time, the model struggles to construct accurate reasoning chains for complex problems with intricate steps, leading to faulty reasoning paths and indicating a limited ability to solve problems with long reasoning chains.In 25% of cases, erroneous derivations occur within certain reasoning steps, highlighting potential inaccuracies and flaws in logical deductions.5% of conclusions in FOLIO have a complex syntactic structure, posing comprehension challenges for GPT-4.5% of outputs show that GPT-4 leverage commonsense reasoning to employ spurious shortcuts that lead to the wrong truth value for the conclusion.We provide a case study for the "Faulty path" scenario in Table 8.In this instance, the model can perform simple derivations from the premises, like "If someone is of age, they can vote and get married."However, because of the problem's complexity, the model struggles to identify the essential intermediate steps and cannot ascertain the truth value of conclusions, such as "Jack is not a child."</p>
<p>Human performance</p>
<p>We collected truth value annotations of logical reasoning for FOLIO test set from expert and nonexpert annotators.Our expert annotators are computer science college students familiar with FOL.Non-expert annotators are community college or high school students who have not taken the SAT.Both expert and non-expert annotators are native English speakers.Expert annotations achieve an accuracy of 95.98% while non-expert annotations achieves 61.82%, with a gap of 34.16%.This shows that sufficient domain knowledge of FOL is necessary for good performance on FOLIO.The expert and GPT-4 gap is 31.82%,suggesting significant room for model improvement.</p>
<p>Conclusion</p>
<p>We introduced FOLIO, an expert-written dataset for logical reasoning equipped with FOL formulas.The examples in FOLIO are created based on real-world knowledge with natural language.It exhibits a large number of distinct logic patterns and a large vocabulary.Experiments show that FOLIO presents a challenge for one of the most capable Large Language Model publicly available.</p>
<p>Limitations</p>
<p>We focus on collecting a very high-quality dataset in evaluating logical reasoning rather than merely a large dataset.Optimizing for quality required us to adopt a rigorous annotation process with domain experts selected based on a few important criteria as mentioned in Appendix A: Annotator Selection.Significantly scaling up this process would have required resources beyond our current means and we are unable further expand our dataset for investigating how the size of training data affects the performance of fine-tuning experiments.We encourage the community to apply our annotation protocol to expand this realistic and complex FOL reasoning story set.</p>
<p>A Annotator Selection</p>
<p>Given the complexities of our annotations, we selected annotators based on a few important criteria 1).Our annotators are either college or graduate students who are native English speakers or possess near-native proficiency in English. 42).They possess formal education in first-order logic, having either completed relevant coursework or undertaken self-directed studies in first-order logic or semantic parsing.At the NL quality check stage, only annotators who are experts in natural language processing or computational linguistics are involved.For the FOL quality check, only annotators who are experts in first-order logic are involved.We also give the annotators several training sessions on how to write a story, by providing them with detailed annotation guidelines.All stories and FOL annotations in FOLIO are written and reviewed by expert annotators, including CS undergraduate and graduate students, and senior researchers, who met the aforementioned criteria.</p>
<p>B HybLogic Template Example</p>
<p>An example the resulting template is as follows:</p>
<p>Conclusions:</p>
<p>[Unknown] a is an S.</p>
<p>[True] If a is either a C or a D, then a is not either an A or a B.</p>
<p>C Factuality and Bias Elimination Protocol</p>
<p>We rewrote those that are not reflective of wellestablished scientific, historical, or legal facts.We took out stories that had strongly opinionated language and contained gender, racial, and classist biases.We accept certain classes of "psychologically fundamental generalizations" (Leslie, 2008), however, such as "Covid is transmitted through the air" or "Tigers eat other animals," that may not be factually invariant but add logical and semantic nuances to the stories.For stories that pertain to generalization, such as "All As are Bs," we have added specifiers like "all Dan knows" to give a degree of reasonable factuality.For example, "All science fiction that Dan knows comes from an imaginative process" has a more reasonable degree of factuality than "All science fiction comes from an imaginative process."</p>
<p>D Language Quality Control</p>
<p>â€¢ We always use "either-or" to express exclusive disjunction.We use either "A or B" or "A or B, or both" to express inclusive disjunction.In English "or" itself can be interpreted as either inclusive disjunction or exclusive disjunction.Adding "or both" cancels the exclusive disjunction distinctly.However, it is less common in the wild than just using "or".we could add "or both" if it is important to emphasize the inclusive part semantically or contextually or for factuality; and do not add "or both" if it is not.We rely on the language model to figure out if it should be inclusive or exclusive, therefore not sacrificing naturalness.</p>
<p>â€¢ It is more natural to say "Some A is B" rather than "there exists an A such that A is B." "All A are B" can be more natural than "If A then B".</p>
<p>â€¢ Writing NL sentences that express negation over exclusive-or ("either both or neither") can be cumbersome but we found one natural ways of expressing these situations: "Each morning, John either works out and stretches, or he does neither".</p>
<p>Other common issues in NL quality include singular/plural issues, especially in statements that deal with both categories and individual members of those categories; as well as ambiguities resulting from improper introduction of, or failure to introduce, proper nouns.</p>
<p>E First-Order Logic E.1 First-Order Logic VS Natural Language FOL enables deriving facts from other facts (Russell and Norvig, 2010).In the context of logical reasoning in modern NLP, FOL, as a logical form, is a more explicit logical representation than its NL counterpart and can be used as input to an FOL prover in order to obtain the exact truth values for the conclusions.FOL has no ambiguity while ambiguity can occur at various levels of NLP.FOL can thus be a good interface between how LMs are trained and how logical conclusions are reasoned.</p>
<p>E.2 FOL definition</p>
<p>We include the following operators: negation Â¬, conjunction âˆ§, disjunction âˆ¨, implication â†’, universal quantifier âˆ€, existential quantifier âˆƒ, equal =.Following (Russell and Norvig, 2010), we consider temporal logic and modal logic as special-purpose logics.Consequently, they are beyond the scope of the definition of first-order logic used in our dataset.</p>
<p>E.3 FOL modeling conventions</p>
<p>We use n-place predicates when applicable for the expressivity of the FOL formulas.However, we do not use the Davidsonian (Davidson, 2001) or neo-Davidsonian semantics (Parsons, 1990) because translating the majority of the FOL formulas in our dataset only requires one-place and twoplace predicates.Therefore the Davidsonian or neo-Davidsonian semantics are not necessary for the expressivity of the FOL formulas.</p>
<p>For example, "Enjoy dressing up in oldfashioned clothing" is rendered as "Enjoy(x, dressingUp, oldFashionedClothing)".</p>
<p>F FOL Annotation Protocol</p>
<p>We therefore design an annotation protocol for first-order logic translation in order to ensure that our FOL translations are as consistent as possible across all examples in our dataset.We highlight a few important strategies used in the annotation protocol.a).First-order logic formulas need to preserve as much as possible the semantics of natural language sentences.b).First-order logic formulas should stay as faithful to the structure of the original NL sentence as possible.c).Semantic decomposition is not needed unless necessary for maintaining the NL expressivity.This means that "John is a bachelor" can be translated into FOL simply as "Bachelor(John)".d).In terms of abstraction, we neglect tense and remove all the plural forms of verbs.</p>
<p>G FOL Inference Engine</p>
<p>Although there are many provers widely used in the community (McCune, 2005(McCune, -2010;;Sutcliffe, 2017;Nipkow et al., 2002) , we adopt the inference engine provided in the Stanford CS221 course page5 , which is a compact module designed specifically for procesing first-order logic statements.The inference engine does not support input in the FOL syntax adopted by standard education material (Russell and Norvig, 2010), which is used in our dataset.We therefore developed a FOL parser in order to convert the FOL formulas written by humans to the input format of the inference engine.The converter is a semantic parser tool written in Python.Although LLMs such as GPT-4 can be utilized to conduct the conversion, it is hard to ensure the GPT-4 outputs are always correct.</p>
<p>Proving a story requires three steps.First, the FOL statements of the premises and conclusions of a story annotated by humans are converted to Python code.Then, the code snippets are used as input to the theorem prover.Finally, the theorem prover outputs whether the conclusions are True / False / Unknown, based on the premises.predictions are wrong for all conclusions.</p>
<p>Table 10 shows a story from HybLogic with a more complex FOL reasoning process.Inferred from premises 4 and 5, James does not perform better than others.With premises 3, 2 and 1, we know that James is not good at time management.Therefore, conclusion B is False.It cannot be determined if James exercises every week, thus the first conclusion is Unknown.The truth value of p â†’ q is the same as Â¬p âˆ¨ q.It is not true that James does not perform better than others.It is also false that James exercises every week and is good at time management.Thus conclusion C is False.For this example, GPT-4 predicted the correct truth value only for conclusion A and RoBERTa made correct predictions for conclusions A and B.</p>
<p>J Model Performance Analysis</p>
<p>Models have more tendency to predict "True" compared with "False" or "Unknown" labels Confusion matrices in Figure 4 for the fine-tuning and 8-shot NL prompt results both show that LLMs are significantly better at making the correct predictions for conclusions with labels of True than the conclusions with labels of False or Unknown.The accuracy on examples with False or Unknown conclusions is 61.9% with fine-tuning and 54.0% with few-shot prompting.They also tend to make more predictions of True than the other labels.</p>
<p>Model performance is not affected by the premise ordering To test if the premise ordering in FOLIO has spurious correlations with the conclusion label which a model can exploit, we shuffle the input premises to evaluate models.We find that accuracy increases or decreases by roughly 1% in most settings compared to our unshuffled premises.This indicates that the ordering of premises in FO-LIO examples does not yield significant information about the label, and thus models will not be able to use the premise ordering as a strong heuris- tic or statistical feature for its predictions.</p>
<p>Using both NL sentences and FOL formulas in the prompt performs better FOL formulas have a clearer and more straightforward logical structure than NL sentences.Therefore, we test GPT-3.5 and GPT-4 with another two settings for truth value prediction using few-shot prompting: 1) using only FOL formulas in the prompt; 2) using both NL sentences and FOL formulas by concatenating each NL sentence and its annotated FOL statement.As shown in Table 11, the performance slightly increases in the NL+FOL setting for GPT-4 while GPT-3.5 performs worse in both the NL+FOL and the FOL-only settings.In other words, FOL always serves as additional useful information for GPT-4, but not for GPT-3.5 regardless of whether FOL is concatenated with NL.This observation resonates with the finding that GPT-4 performs much better than GPT-3.5 on code-related tasks (Ni et al., 2023).</p>
<p>Figure 1 :
1
Figure 1: Distribution of reasoning depths</p>
<p>Figure 1 demonstrates the distribution of the number of examples in the WikiLogic and HybLogic sets versus the number of premises needed to arrive at a conclusion, showing that most of the conclusions from WikiLogic require one to five premises while those from HybLogic require five to eight premises.</p>
<p>Figure</p>
<p>Figure Accuracies of different models categorized into examples with different reasoning depths.</p>
<p>P. All S are M. Either S or A. All A are B. All D are B. No C are B. a is either a C or a P.</p>
<p>Figure 4 :
4
Figure 4: Confusion matrices for the results of finetuning RoBERTa-Large and few-shot prompting GPT-4.</p>
<p>Table 1 :
1
Comparison of FOLIO with other datasets related to logical reasoning.#Distinct AST stands for the number of distinct abstract syntax trees, representing the number of distinct sentence-level logic structures in the corpus.FOLIO is the first expert-written dataset for FOL reasoning equipped with parallel FOL formulas.The examples are mostly aligned with real-world knowledge and use highly natural wordings.It also has a greater variety than the previous datasets in terms of reasoning depths with a larger number of distinct logic patterns and a large vocabulary.
DatasetSizeReasoningText SourceReal-World Resources# Reasoning DepthVocab# Distinct ASTCLUTTER (2019)6k InductiveSyntheticÃ—Ã—-Ã—RECLOR (2020)6k Mixed forms GMAT, LSAT examsâœ“Ã—-Ã—LogiQA (2021)8.6k Mixed forms NCSE examsâœ“Ã—-Ã—RuleTaker (2020)500k DeductiveSyntheticÃ—0 âˆ¼ 510148ProofWriter (2021) 500k DeductiveSyntheticÃ—0 âˆ¼ 510148LogicNLI (2021)20k FOLSyntheticÃ—1 âˆ¼ 5107730BigBench (2022)1300 Mixed forms Human-WrittenPartiallyÃ—--ProntoQA (2023)200 DeductiveSyntheticâœ“1, 3, 5--FOLIO (ours)1,435 FOLExpert-writtenâœ“0 âˆ¼ 7435176</p>
<p>Table 3 shows that examples based on Wikipedia make up the largest portion of FOLIO, with 304 stories, 1,353 NL and FOL premise pairs, and 753 NL and FOL conclusion pairs.Hybrid annotations consist of 183 stories with 1,054 NL and FOL premise pairs, and 682 NL and FOL conclusion pairs in total.</p>
<p>Table 3 :
3
Table 3 shows that our dataset has a vocabulary of 4,351 words, and the examples based on Wikipedia account for 74% of the total vocabulary even though the WikiLogic stories take up only 63% of the total number of stories.The vocabulary of FOLIO is also significantly Statistics based on different data collection methods of FOLIO.#Words is the average number of words per NL sentence.
Source#Stories #Premises #ConclusionsNLLogicVocab #Words Complexity #Depth ASTWikiLogic304135375332508.500 -14 grade1 -551HybLogic1831054682190211.520 -14 grade5 -825Total4872407143543519.860 -14 grade765-8</p>
<p>Table 4 :
4
Logical reasoning results of fully supervised fine-tuning and few-shot prompting on FOLIO test set.
ModelSizeAcc (%)majority baseline-38.5%random probability-33.3 %Fully supervised fine-tuneBERT-base110M56.8BERT-large340M59.0RoBERTa-base110M56.8RoBERTa-large340M62.1Flan-T5-Large783M65.90-shot NL PromptGPT-3.5-Turbo-53.1GPT-4-61.38-shot NL PromptLLama-13B13B33.6LLama-70B70B44.0LLama-70B -CoT70B47.8LLama-70B -ToT70B48.4text-davinci-002-49.5GPT-3.5-Turbo-58.3GPT-4-64.2GPT-4 -CoT (2022b)-68.9GPT-4 -CoT with SC (2023) -69.5GPT-4 ToT (2023)-70.0LR-specific MethodsLogic-LM (2023)-78.1LINC (2023)-73.1DetermLR (2023)-77.5</p>
<p>Table 5 :
5
NL-FOL translation results on FOLIO.SynV measures syntactic validity and ExcAcc measures the inference engine execution accuracy.
ModelZero-ShotFew-ShotSynv ExcAcc Sync ExcAccGPT-3.5-Turbo 68.450.4 93.3 56.0GPT-486.151.7 93.9 63.8</p>
<p>Table 6 :
6
Performance differences on the WikiLogic and HybLogic subset of FOLIO.WikiLogic has more diverse logical structures while HybLogic stories have higher reasoning depths.
MethodModelWikiHybFine-tuningRoBERTa-large 60.71 63.48NL PromptingGPT-3.5-Turbo68.88 47.70GPT-475.43 53.10NL-FOL ExcAcc GPT-3.5-Turbo45.17 61.82GPT-459.12 67.93</p>
<p>Table 7 :
7
Human evaluation on GPT-4 model outputs with incorrect truth value predictions Example Premises 1.All children are human.2. If someone is underage, then they are a child.3.People are either underage or of age. 4. If someone is of age, then they can vote.5.If someone is of age, they can legally get married.6.If Jack is a child and a human, then Jack is neither able to vote nor able to get married.Conclusion -&gt; Label: Jack is able to vote and get married.-&gt; True.</p>
<p>Table 11 :
11
Comparison of the results across different input formats with few-shot prompting.NL, NL-FOL, FOL, NL + FOL stands for NL prompting, execution accuracy of NL-FOL translation, using only FOL in the prompt and using concatenated NL and FOL in the prompt respectively.
ModelNLNL-FOL FOL NL+FOLGPT-3.5 58.3455.9657.9257.75GPT-464.1663.8264.0165.21
In experimenting with different prompts, we found 8 shot examples to perform slightly better. It is also the maximum number of examples that fits in the text-davinci-002 context.
Hereafter, "GPT-3.5" refers to GPT-3.5-Turbo.
By "near-native" we mean with English speaking and understanding ability that closely mirrors that of a native English speakers.
https://stanford-cs221.github.io/spring2022/ assignments/logic/index.html
H Distribution of ReadabilityWe show the distribution of readability in Figure3.I Case studyTable9shows a story from WikiLogic along with the GPT-4 and RoBERTa-Large predictions.Conclusion A is True given premises 5 and 3. From the premises, it cannot be determined if Cerura vinula has thin antennae or if it is a pest.Thus conclusions B and C are Unknown.GPT-4 predictions are correct for conclusions A and C while RoBERTa
HHUplexity at text complexity DE challenge 2022. David Arps, Jan Kels, Florian KrÃ¤mer, Yunus Renz, Regina Stodden, Wiebke Petersen, Proceedings of the GermEval 2022 Workshop on Text Complexity Assessment of German Text. the GermEval 2022 Workshop on Text Complexity Assessment of German TextPotsdam, GermanyAssociation for Computational Linguistics2022</p>
<p>Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle Mcdonell, Jason Phang, Michael Pieler, Shivanshu Usvsn Sai Prashanth, Laria Purohit, Jonathan Reynolds, Ben Tow, Samuel Wang, Weinbach, 10.48550/ARXIV.2204.06745Gpt-neox-20b: An open-source autoregressive language model. 2022arXiv preprint</p>
<p>A large annotated corpus for learning natural language inference. R Samuel, Gabor Bowman, Christopher Angeli, Christopher D Potts, Manning, 10.18653/v1/D15-1075Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational Linguistics2015</p>
<p>Alec Radford, Ilya Sutskever, and Dario Amodei. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlishCurran Associates, Inc202033Language models are few-shot learners</p>
<p>Hy-bridQA: A dataset of multi-hop question answering over tabular and textual data. Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, William Yang, Wang , 10.18653/v1/2020.findings-emnlp.91Findings of the Association for Computational Linguistics: EMNLP 2020. Online. Association for Computational Linguistics2020</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, arXiv:2204.02311Palm: Scaling language modeling with pathways. 2022arXiv preprint</p>
<p>Peter Clark, Oyvind Tafjord, Kyle Richardson, CoRR, abs/2002.05867Transformers as soft reasoners over language. 2020</p>
<p>Transformers as soft reasoners over language. Peter Clark, Oyvind Tafjord, Kyle Richardson, Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence. the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence2021</p>
<p>Using the framework. Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Johan Van Genabith, Jan Jaspars, Hans Kamp, David Milward, Manfred Pinkal, Massimo Poesio, LRE 62-051 D-16The FraCaS Consortium. 1996Technical Report</p>
<p>Selection-inference: Exploiting large language models for interpretable logical reasoning. Antonia Creswell, Murray Shanahan, Irina Higgins, arXiv:2205.097122022arXiv preprint</p>
<p>A formula for predicting readability. Edgar Dale, Jeanne S Chall, Educational Research Bulletin. 2711948</p>
<p>Readability Revisited: The New Dale-Chall Readability Formula. Edgar Dale, Jeanne S Chall, 1995Brookline Books</p>
<p>Ishita Dasgupta, Stephanie Cy Andrew K Lampinen, Antonia Chan, Dharshan Creswell, James L Kumaran, Felix Mcclelland, Hill, arXiv:2207.07051Language models show human-like content effects on reasoning. 2022arXiv preprint</p>
<p>105The Logical Form of Action Sentences. Donald Davidson, 10.1093/0199246270.003.0006Essays on Actions and Events. Oxford University Press2001</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191</p>
<p>David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, 10.48550/ARXIV.2207.10342Language model cascades. Rif A. Saurous; Kevin Murphy, and Charles Sutton2022arXiv preprint</p>
<p>WinoLogic: A zero-shot logic-based diagnostic dataset for Winograd Schema Challenge. Weinan He, Canming Huang, Yongmei Liu, Xiaodan Zhu, 10.18653/v1/2021.emnlp-main.307Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic. Association for Computational Linguistics2021Online and Punta Cana</p>
<p>Evaluating the rationale understanding of critical reasoning in logical reading comprehension. Akira Kawabata, Saku Sugawara, arXiv:2311.183532023Preprint</p>
<p>Boardgameqa: A dataset for natural language reasoning with contradictory information. Mehran Kazemi, Quan Yuan, Deepti Bhatia, Najoung Kim, arXiv:2306.079342023PreprintXin Xu, Vaiva Imbrasaite, and Deepak Ramachandran</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, arXiv:2205.119162022arXiv preprint</p>
<p>Two sets of perfect syllogisms. Anne Lehman, 10.1305/ndjfl/1093891016Notre Dame Journal of Formal Logic. 1431973</p>
<p>Generics: Cognition and Acquisition. Sarah-Jane Leslie, 10.1215/00318108-2007-023The Philosophical Review. 11712008</p>
<p>Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, Weizhu Chen, arXiv:2206.02336On the advance of making language models better reasoners. 2022arXiv preprint</p>
<p>Logiqa: a challenge dataset for machine reading comprehension with logical reasoning. Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, Yue Zhang, Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence. the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence2021</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Ro{bert}a: A robustly optimized {bert} pretraining approach. 2020arXiv preprint</p>
<p>. W Mccune, 2005-2010. Prover9 and mace4</p>
<p>Dragomir Radev, and Arman Cohan. 2023. L2ceval: Evaluating language-to-code generation capabilities of large language models. Ansong Ni, Pengcheng Yin, Yilun Zhao, Martin Riddell, Troy Feng, Rui Shen, Stephen Yin, Ye Liu, Semih Yavuz, Caiming Xiong, Shafiq Joty, Yingbo Zhou, arXiv:2309.17446Preprint</p>
<p>Isabelle/Hol a Proof Assistant for Higher-Order Logic. Tobias Nipkow, Lawrence C Paulson, Markus Wenzel, 2002Springer</p>
<p>LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers. Theo Olausson, Alex Gu, Ben Lipkin, Cedegao Zhang, Armando Solar-Lezama, Joshua Tenenbaum, Roger Levy, 10.18653/v1/2023.emnlp-main.313Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics2023</p>
<p>Josh Openai, Others Achiam, arXiv:2303.08774Gpt-4 technical report. 2023Preprint</p>
<p>Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning. Liangming Pan, Alon Albalak, Xinyi Wang, William Wang, 10.18653/v1/2023.findings-emnlp.248Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023</p>
<p>Events in the Semantics of English. Terence Parsons, 1990MIT PressCambridge, MA, USA</p>
<p>Stuart Russell, Peter Norvig, Artificial Intelligence: A Modern Approach. Prentice Hall20103 edition</p>
<p>RuleBERT: Teaching soft rules to pre-trained language models. Mohammed Saeed, Naser Ahmadi, Preslav Nakov, Paolo Papotti, 10.18653/v1/2021.emnlp-main.110Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic. Association for Computational Linguistics2021Online and Punta Cana</p>
<p>Language models can (kind of) reason: A systematic formal analysis of chain-of-thought. Abulhair Saparov, He He, International Conference on Learning Representations. 2023</p>
<p>Exploring neural models for parsing natural language into first-order logic. Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy, arXiv:2002.065442020arXiv preprint</p>
<p>Misery loves complexity: Exploring linguistic complexity in the context of emotion detection. Pranaydeep Singh, Luna De Bruyne, OrphÃ©e De Clercq, Els Lefever, 10.18653/v1/2023.findings-emnlp.857Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023</p>
<p>CLUTRR: A diagnostic benchmark for inductive reasoning from text. Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L Hamilton, 10.18653/v1/D19-1458Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational Linguistics2019</p>
<p>Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Aarohi Srivastava, +447 AuthorsAbhinav Rastogi, +447 AuthorsarXiv:2206.046152023Preprint</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal, Md Shoeb, Abubakar Abid, Adam Fisch, Adam Adam R Brown, Aditya Santoro, AdriÃ  Gupta, Garriga-Alonso, arXiv:2206.04615Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. 2022arXiv preprint</p>
<p>From indeterminacy to determinacy: Augmenting logical reasoning capabilities with large language models. Hongda Sun, Weikai Xu, Wei Liu, Jian Luan, Bin Wang, Shuo Shang, Ji-Rong Wen, Rui Yan, arXiv:2310.186592023Preprint</p>
<p>G Sutcliffe, The TPTP Problem Library and Associated Infrastructure. From CNF to TH0, TPTP. 201759v6.4.0.</p>
<p>ProofWriter: Generating implications, proofs, and abductive statements over natural language. Oyvind Tafjord, Bhavana Dalvi, Peter Clark, 10.18653/v1/2021.findings-acl.317Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Online. Association for Computational Linguistics2021</p>
<p>CommonsenseQA: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, 10.18653/v1/N19-1421Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191</p>
<p>Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge. Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, Jonathan Berant, Advances in Neural Information Processing Systems. 202033</p>
<p>Diagnosing the firstorder logical reasoning ability through LogicNLI. Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao He, Yaohui Jin, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic. Association for Computational Linguistics2021Online and Punta Cana</p>
<p>Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, TimothÃ©e Lachaux, Baptiste Lacroix, Naman RoziÃ¨re, Eric Goyal, Faisal Hambro, Aurelien Azhar, Armand Rodriguez, Joulin, arXiv:2302.13971Preprint</p>
<p>Superglue: A stickier benchmark for general-purpose language understanding systems. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel Bowman, Advances in Neural Information Processing Systems. Curran Associates, Inc2019a32</p>
<p>Superglue: A stickier benchmark for general-purpose language understanding systems. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel Bowman, Advances in neural information processing systems. 2019b32</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Ed H Quoc V Le, Sharan Chi, Aakanksha Narang, Denny Chowdhery, Zhou, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Linguistic complexity loss in text-based therapy. Jason Wei, Kelly Finn, Emma Templeton, Thalia Wheatley, Soroush Vosoughi, 10.18653/v1/2021.naacl-main.352Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022aarXiv preprint</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, Denny Zhou, arXiv:2201.11903Chain of thought prompting elicits reasoning in large language models. 2022barXiv preprint</p>
<p>HotpotQA: A dataset for diverse, explainable multi-hop question answering. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, Christopher D Manning, 10.18653/v1/D18-1259Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational Linguistics2018</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik R Narasimhan, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Reclor: A reading comprehension dataset requiring logical reasoning. Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng, International Conference on Learning Representations. 2020</p>
<p>Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah D Goodman, 10.48550/ARXIV.2203.14465Star: Bootstrapping reasoning with reasoning. 2022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>