<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9221 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9221</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9221</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-20824719</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1705.09650v1.pdf" target="_blank">Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata</a></p>
                <p><strong>Paper Abstract:</strong> This paper focuses on detecting anomalies in a digital video broadcasting (DVB) system from providers' perspective. We learn a probabilistic deterministic real timed automaton profiling benign behavior of encryption control in the DVB control access system. This profile is used as a one-class classifier. Anomalous items in a testing sequence are detected when the sequence is not accepted by the learned model.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9221.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9221.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PDRTA (RTI+)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Deterministic Real Timed Automaton learned via RTI+</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic deterministic timed automaton learned from positive timed strings using the RTI+ algorithm; models symbol probabilities and time-bin distributions and is used as a one-class classifier by accepting/rejecting timed sequences for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Probabilistic Deterministic Real Timed Automaton (PDRTA) learned with RTI+</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Timed automaton / state-machine (probabilistic deterministic real timed automaton)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Timed discrete event sequences (timed strings: categorical symbols with inter-event time delays)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Digital Video Broadcasting (DVB) control access / encryption scheme sequences (ECM/EMM streams)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Data loss (missing symbols) and timing errors (too large or too small inter-event delays)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Unsupervised / one-class approach: convert raw timestamped symbol logs into timed strings (symbol, integer time-delta), learn a PDRTA using the RTI+ algorithm (construct prefix tree, perform statistical merges/splits with p-value thresholds to produce time guards and symbol/time distributions). At test time, a sequence is flagged anomalous if it is not accepted by the learned automaton (i.e., no valid transition/time guard). Time precision (scaling/magnification of floats to integers) is tuned by comparative trials (they tested 10, 10^3, 10^6).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>No explicit experimental baseline in this paper; related-work mentions SAX+CFG (grammar-based), finite-state automaton for system-call intrusion detection, probabilistic deterministic timed-transition automata (prior work), but these were discussed as related methods rather than run as baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>TP, FN, FP, TN and derived rates: TPR (recall), FNR, FPR, TNR, ACC (accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>The paper reports detection results for two test datasets (data-lost and time-delay) and compares three time-precision magnifications (10, 10^3, 10^6). Reported table entries (as given in paper):
- For one test (time-delay) the paper shows row for magnification 10^6: TP=1, FN=0, FP=0, TN=28, TPR=1.00, FNR=0.00, FPR=0.00, TNR=1.00, ACC=1.00. Other magnifications show higher FPR (e.g., 10^3 had FP>0). The paper states 10^6 scaling performed best overall. (The manuscript prints full TP/FN/FP/TN and derived rates for magnifications 10, 10^3, 10^6 for both the data-lost and time-delay test sets; see paper tables for all numeric rows.)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No direct experimental comparison to other anomaly-detection algorithms is provided; related methods are discussed in related work only. The paper claims high accuracy for PDRTA (especially with fine-grained time scaling) and highlights interpretability advantages versus black-box methods.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>RTI+ does not handle very infrequent transitions well: such rare transitions are routed to a sink state causing false positives; time must be rounded to integers so choice of time precision (magnification) critically affects learned time guards; needs human/expert validation of model and guidance (one-class model accepts/rejects sequences only); remedy suggested: treat training-data strings that map to sink transitions as normal to reduce false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Timed automata act as an interpretable 'language model' over timed symbol sequences: learned time-guards can split states to reveal distinct low-delay vs high-delay behavioral loops; high time magnification (10^6) produced the best detection performance in these DVB experiments; model verification is efficient (transition firing) and suitable for real-time deployment; the approach can detect both structural anomalies (missing symbols) and temporal anomalies (out-of-guard delays).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9221.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9221.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAX + CFG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic Aggregate approXimation (SAX) followed by Context-Free Grammar compression</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that discretizes time series with SAX and uses grammar-based compression (context-free grammars) to find anomalous subsequences by low grammar density / low compressibility (novel patterns).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SAX (symbolic representation) + context-free-grammar based anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Symbolic time-series representation + grammar-based model (context-free grammar)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Time series (continuous-valued) converted to symbolic sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>General time series (related work) — not applied to DVB in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Novel patterns / outliers (low grammar density / low compressibility)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Related work: represent time series with SAX and learn a context-free grammar; anomalies correspond to subsequences that compress poorly (low density). Mentioned as an interpretable language-model-style approach in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Mentioned in related work; not compared experimentally in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not discussed in this paper (only cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Cited as an example of a language-model-like interpretable method for anomaly detection on sequences/time series; motivates interest in interpretable sequence models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9221.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9221.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Automaton-based (Sekar et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Finite-state automaton learning for program-behavior intrusion detection (Sekar et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Learning automata from system-call sequences to model normal program behavior and detect anomalous executions when sequences deviate from learned automaton.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Finite-state automaton learned from positive sequences</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Deterministic finite automaton (state-machine)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Symbolic sequences (system-call traces); applicable to discrete event sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Program behavior / intrusion detection (related work), not applied here</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Deviations from learned execution sequences (intrusions/anomalous behavior)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Related work cited: learn a finite-state automaton from normal sequences and detect anomalies when test sequences are not accepted by the automaton. Mentioned as precedent and motivation for automaton-based anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Cited as foundational prior work; not experimentally compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not detailed in this paper beyond general relation; motivates timed-automaton extension to incorporate timing information which discrete automata lack.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Used in related work to motivate adding timing information (timed automata) because plain discrete automata ignore important temporal aspects of real systems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Experiencing SAX: a novel symbolic representation of time series <em>(Rating: 2)</em></li>
                <li>Time series anomaly discovery with grammar-based compression <em>(Rating: 2)</em></li>
                <li>A fast automaton-based method for detecting anomalous program behaviors <em>(Rating: 2)</em></li>
                <li>A likelihood-ratio test for identifying probabilistic deterministic real-time automata from positive data <em>(Rating: 2)</em></li>
                <li>Model-based anomaly detection for discrete event systems <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9221",
    "paper_id": "paper-20824719",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "PDRTA (RTI+)",
            "name_full": "Probabilistic Deterministic Real Timed Automaton learned via RTI+",
            "brief_description": "A probabilistic deterministic timed automaton learned from positive timed strings using the RTI+ algorithm; models symbol probabilities and time-bin distributions and is used as a one-class classifier by accepting/rejecting timed sequences for anomaly detection.",
            "citation_title": "Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata",
            "mention_or_use": "use",
            "model_name": "Probabilistic Deterministic Real Timed Automaton (PDRTA) learned with RTI+",
            "model_type": "Timed automaton / state-machine (probabilistic deterministic real timed automaton)",
            "model_size": null,
            "data_type": "Timed discrete event sequences (timed strings: categorical symbols with inter-event time delays)",
            "data_domain": "Digital Video Broadcasting (DVB) control access / encryption scheme sequences (ECM/EMM streams)",
            "anomaly_type": "Data loss (missing symbols) and timing errors (too large or too small inter-event delays)",
            "method_description": "Unsupervised / one-class approach: convert raw timestamped symbol logs into timed strings (symbol, integer time-delta), learn a PDRTA using the RTI+ algorithm (construct prefix tree, perform statistical merges/splits with p-value thresholds to produce time guards and symbol/time distributions). At test time, a sequence is flagged anomalous if it is not accepted by the learned automaton (i.e., no valid transition/time guard). Time precision (scaling/magnification of floats to integers) is tuned by comparative trials (they tested 10, 10^3, 10^6).",
            "baseline_methods": "No explicit experimental baseline in this paper; related-work mentions SAX+CFG (grammar-based), finite-state automaton for system-call intrusion detection, probabilistic deterministic timed-transition automata (prior work), but these were discussed as related methods rather than run as baselines.",
            "performance_metrics": "TP, FN, FP, TN and derived rates: TPR (recall), FNR, FPR, TNR, ACC (accuracy).",
            "performance_results": "The paper reports detection results for two test datasets (data-lost and time-delay) and compares three time-precision magnifications (10, 10^3, 10^6). Reported table entries (as given in paper):\n- For one test (time-delay) the paper shows row for magnification 10^6: TP=1, FN=0, FP=0, TN=28, TPR=1.00, FNR=0.00, FPR=0.00, TNR=1.00, ACC=1.00. Other magnifications show higher FPR (e.g., 10^3 had FP&gt;0). The paper states 10^6 scaling performed best overall. (The manuscript prints full TP/FN/FP/TN and derived rates for magnifications 10, 10^3, 10^6 for both the data-lost and time-delay test sets; see paper tables for all numeric rows.)",
            "comparison_to_baseline": "No direct experimental comparison to other anomaly-detection algorithms is provided; related methods are discussed in related work only. The paper claims high accuracy for PDRTA (especially with fine-grained time scaling) and highlights interpretability advantages versus black-box methods.",
            "limitations_or_failure_cases": "RTI+ does not handle very infrequent transitions well: such rare transitions are routed to a sink state causing false positives; time must be rounded to integers so choice of time precision (magnification) critically affects learned time guards; needs human/expert validation of model and guidance (one-class model accepts/rejects sequences only); remedy suggested: treat training-data strings that map to sink transitions as normal to reduce false positives.",
            "unique_insights": "Timed automata act as an interpretable 'language model' over timed symbol sequences: learned time-guards can split states to reveal distinct low-delay vs high-delay behavioral loops; high time magnification (10^6) produced the best detection performance in these DVB experiments; model verification is efficient (transition firing) and suitable for real-time deployment; the approach can detect both structural anomalies (missing symbols) and temporal anomalies (out-of-guard delays).",
            "uuid": "e9221.0",
            "source_info": {
                "paper_title": "Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata",
                "publication_date_yy_mm": "2017-05"
            }
        },
        {
            "name_short": "SAX + CFG",
            "name_full": "Symbolic Aggregate approXimation (SAX) followed by Context-Free Grammar compression",
            "brief_description": "A pipeline that discretizes time series with SAX and uses grammar-based compression (context-free grammars) to find anomalous subsequences by low grammar density / low compressibility (novel patterns).",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "SAX (symbolic representation) + context-free-grammar based anomaly detection",
            "model_type": "Symbolic time-series representation + grammar-based model (context-free grammar)",
            "model_size": null,
            "data_type": "Time series (continuous-valued) converted to symbolic sequences",
            "data_domain": "General time series (related work) — not applied to DVB in this paper",
            "anomaly_type": "Novel patterns / outliers (low grammar density / low compressibility)",
            "method_description": "Related work: represent time series with SAX and learn a context-free grammar; anomalies correspond to subsequences that compress poorly (low density). Mentioned as an interpretable language-model-style approach in related work.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": "Mentioned in related work; not compared experimentally in this paper.",
            "limitations_or_failure_cases": "Not discussed in this paper (only cited as related work).",
            "unique_insights": "Cited as an example of a language-model-like interpretable method for anomaly detection on sequences/time series; motivates interest in interpretable sequence models.",
            "uuid": "e9221.1",
            "source_info": {
                "paper_title": "Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata",
                "publication_date_yy_mm": "2017-05"
            }
        },
        {
            "name_short": "Automaton-based (Sekar et al.)",
            "name_full": "Finite-state automaton learning for program-behavior intrusion detection (Sekar et al.)",
            "brief_description": "Learning automata from system-call sequences to model normal program behavior and detect anomalous executions when sequences deviate from learned automaton.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Finite-state automaton learned from positive sequences",
            "model_type": "Deterministic finite automaton (state-machine)",
            "model_size": null,
            "data_type": "Symbolic sequences (system-call traces); applicable to discrete event sequences",
            "data_domain": "Program behavior / intrusion detection (related work), not applied here",
            "anomaly_type": "Deviations from learned execution sequences (intrusions/anomalous behavior)",
            "method_description": "Related work cited: learn a finite-state automaton from normal sequences and detect anomalies when test sequences are not accepted by the automaton. Mentioned as precedent and motivation for automaton-based anomaly detection.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": "Cited as foundational prior work; not experimentally compared in this paper.",
            "limitations_or_failure_cases": "Not detailed in this paper beyond general relation; motivates timed-automaton extension to incorporate timing information which discrete automata lack.",
            "unique_insights": "Used in related work to motivate adding timing information (timed automata) because plain discrete automata ignore important temporal aspects of real systems.",
            "uuid": "e9221.2",
            "source_info": {
                "paper_title": "Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata",
                "publication_date_yy_mm": "2017-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Experiencing SAX: a novel symbolic representation of time series",
            "rating": 2,
            "sanitized_title": "experiencing_sax_a_novel_symbolic_representation_of_time_series"
        },
        {
            "paper_title": "Time series anomaly discovery with grammar-based compression",
            "rating": 2,
            "sanitized_title": "time_series_anomaly_discovery_with_grammarbased_compression"
        },
        {
            "paper_title": "A fast automaton-based method for detecting anomalous program behaviors",
            "rating": 2,
            "sanitized_title": "a_fast_automatonbased_method_for_detecting_anomalous_program_behaviors"
        },
        {
            "paper_title": "A likelihood-ratio test for identifying probabilistic deterministic real-time automata from positive data",
            "rating": 2,
            "sanitized_title": "a_likelihoodratio_test_for_identifying_probabilistic_deterministic_realtime_automata_from_positive_data"
        },
        {
            "paper_title": "Model-based anomaly detection for discrete event systems",
            "rating": 1,
            "sanitized_title": "modelbased_anomaly_detection_for_discrete_event_systems"
        }
    ],
    "cost": 0.00954325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata</p>
<p>Xiaoran Liu 
Qin Lin †q.lin@tudelft.nl 
Sicco Verwer ‡s.e.verwer@tudelft.nl 
Dmitri Jarnikov djarnikov@irdeto.com </p>
<p>Faculty of Electrical Engineering, Mathematics and Computer Science
Irdeto B.V
Delft University of Technology Delft
the Netherlands, the Netherlands</p>
<p>Eindhoven University of Technology Eindhoven
the Netherlands</p>
<p>Anomaly Detection in a Digital Video Broadcasting System Using Timed Automata
Index Terms-anomaly detectiondigital video broadcasting systemreal-time automaton
This paper focuses on detecting anomalies in a digital video broadcasting (DVB) system from providers' perspective. We learn a probabilistic deterministic real timed automaton profiling benign behavior of encryption control in the DVB control access system. This profile is used as a one-class classifier. Anomalous items in a testing sequence are detected when the sequence is not accepted by the learned model.</p>
<p>I. INTRODUCTION</p>
<p>Nowadays proliferation of accessible data stream happens through various networks such as broadcasting, web page, mobile phone, etc. The large volume and continuously real-time updating characteristics of data streams pose challenges for studying and mining. This work focuses on profiling normal behavior from encryption control stream data generated by a digital video broadcasting (DVB) system. From a providers' perspective, such a profile provides insights about the process generating the data and it can be used for anomaly detection.</p>
<p>A. Digital Video Broadcasting system</p>
<p>The DVB has been adopted in Europe as an open standard for a long time. The DVB standard defines both physical and data link layers for a variety of subsystems, e.g., satellite, cable, terrestrial television, and microwave. Furthermore, the DVB standard formulates how multiple program data are distributed and transported among protocols in format of the MPEG Transport Stream (MPEG-TS). Readers are referred to the official website of the DVB project for more detailed specifications 1 .</p>
<p>The objective of our research lies on a core security component of the DVB, i.e., the control access system. Figure 1 shows how the control access system works from a customer's side. The TS is received from the satellite through the tuner and arrives at the DVB descrambler. The content of the TS is scrambled with a 48-bit secret key, also known as the control word (CW). The CW is further encrypted into an entitlement control message (ECM). Meanwhile an entitlement management message (EMM) contains the authorization for decrypting the ECM. A demultiplexer extracts the ECM and 1 https://www.dvb.org/standards Fig. 1. Example of the control access system from the consumer's side [1]. the EMM from the TS. Valid smart cards are able to decrypt the EMM in order to access the authorization and decrypt the ECM. The decrypted ECM is used to descramble the TS into MPEG-2. The MPEG-2 contains video/audio/context, which is transported to users.</p>
<p>B. Related Work</p>
<p>Anomalies are usually considered as outliers, surprises, exceptions, noises, and novelties [2]. Anomaly detection can be achieved by many pattern recognition techniques. However, in many domains, e.g., medical and financial area, frauds or anomalies detection should be understandable and interpretable. A key reason being that the learned knowledge should be validated by humans before being used. We provide a brief literature review of anomaly detection using language models since they are one of the most understandable models. Lin and et al. represent time series using the Symbolic Aggregate approXimation (SAX) [3], and then use a contextfree grammar for rules' generation [4]. Intuitively, anomalies tend to have low grammar density (novelty patterns are less compressed). Sekar and et al. learn program behaviors from system call sequences using a finite-state automaton for intrusion detection [5]. Timo and et al. propose a tailored behavior model (a probabilistic deterministic timed-transition automaton) to identify anomalies [6]. They first augment the learned automaton with timing information, after which traces of ATM observations are traversed by the model. Aggregated transition probabilities are then compared with a predetermined threshold for detecting anomalies.</p>
<p>In this paper, we study event sequences from a DVB system. These sequences contain the encryption information needed for viewing the stream content. We model these sequences using PDRTAs (Probabilistic Deterministic Real Timed Automata), which we learn unsupervised from a set of input sequences using the RTI+ algorithm (Real-Time Identification from Positive Data) [7]. first, we compute the time difference between two consecutive and distinct events to obtain timed strings. We then segment the time strings into frames. The sequences are fed into the RTI+ algorithm to learn a timed automaton. In the testing phrase, an anomaly of a sequence is identified if the sequence is not accepted by the learned model. This paper makes the following contributions:</p>
<p>• To the best of our knowledge, this paper is the first one using a timed automaton to detect anomalies in the DVB system. Two types of anomalies, i.e., data lost and timing error, are identified with low false positive rate. • The model provides highly interpretable insights for understanding the underlying process generating the data. Experts from the DVB area can easily monitor and validate the system under operation using such a model. This paper is organized as follows. Section II introduces the data preprocessing. Section III discusses the learning algorithm and the experimental results. We make concluding remarks in Section IV.</p>
<p>II. DATA DESCRIPTION</p>
<p>An encryption scheme sequence (ESS) is abstracted from the monitoring records of the MPEG-TS. It is essentially a discrete event sequence of ECM streaming in the control access system.</p>
<p>The alphabet of the ESS is {A, B, 0, 1}. The symbols A and B abstractly stand for two ECMs containing an even and an odd key, respectively. The symbols 0 and 1 are even and odd encryption modes. According to expert knowledge, some known rules are the following: 1) An ESS starts from As, followed by 1s, Bs, then ends with 0s. A complete encryption scheme consists of two aforementioned sequences.</p>
<p>2) The number of symbols are not fixed in an ESS. However, the amount of As is always equal to that of Bs. So are the paired events of 1s and 0s. We can use a simple regular expression to generate the aforementioned rules: (A{m}1{n}B{m}0{n}){2}, where m and n are the legitimate numbers for an ECM pair (A/B) and an encryption mode pair (1/0). Basically there are two kinds of anomalies in practice of the DVB. The first one is data lost and the other one is timing error, e.g., too large or too small time delay.</p>
<p>III. METHODS AND RESULTS</p>
<p>In this section, we will deploy a language model, i.e., a timed automaton for anomaly detection. Timed automata explicitly model the underlying varying-duration behavior of ESS streaming.</p>
<p>A. RTI+</p>
<p>Time constrains are implicit in conventional discrete event systems, e.g., n-grams or hidden Markov models. However, time information is often important for modeling the behavior of such systems. An algorithm for efficient learning of timed automata algorithm named RTI+ (Real-Time Identification from Positive Data) was proposed by [7]. Discrete events are represented by timed strings (a 1 , t 1 )(a 2 , t 2 ) · · · (a n , t n ), where a i is a discrete event occurring with t i time delay since the i − 1th event. A PDRTA (probabilistic deterministic real timed automaton) model defines a probability distribution over such timed strings, having a Markov property in the distribution over events, and a semi-Markov property in the time guards.</p>
<p>Definition 1: A probabilistic DRTA (PDRTA) A is a quadruple A , H, S, T , where A = Q, Σ, ∆, q 0 is a DRTA without final states, H is a finite set of bins (time intervals) [v, v ], v, v ∈ N, known as the histogram, S is a finite set of symbol probability distributions S q = P r(S = a | q) | a ∈ Σ, q ∈ Q, and T is a finite set of time-bin probability distributions T q = P r(T ∈ h | q) | h ∈ H, q ∈ Q. In a PDRTA, the state transition is triggered when both the event and the time guard are satisfied. Table I is an example of how to obtain a timed string. Raw data is formatted in tuples of a symbol and a timestamp. In timed strings, time delay between events represents event transition intervals. Note that since only integer format time is readable for RTI+, the original float time with precision microseconds need to be rounded. An interesting problem what precision (different level of magnification) is "optimal" when learning the time guards. A large magnification intuitively makes time guards more sensitive. We will conduct several comparative trials to find a good precision in the experimental part.  </p>
<p>B. model interpretation</p>
<p>We print out the automaton learned using RTI+ from the DVB data in Figure 2. All the states are depicted using circles. The arcs represent transitions between the states. A transition is triggered when both an event and its timing are valid (inside a time guard). The event and the timing, along with their probability and occurrence, are printed next to the arc. The sink state named S is generated due to some strings with very low occurrence (less then 5). Some interesting knowledge is discovered in such a insightful and structural model. </p>
<p>C. result</p>
<p>The training set contains 280 sequences in total. In the testing phrase, we collect two data sets having a data lost and a timing error, respectively. The number of sequence in each of them is 29. Anomalous items in a sequence will be reported if such a sequence is not accepted by this model. The Table II  We compare three levels of magnification 10, 10 3 , and 10 6 for determining good time precision. The results show that the precision with 10 6 times scaling performs best. We suggest to well address this problem by comparative trials in practice. The false positive is caused by the sink state in our model, i.e., because RTI+ does not handle transitions that occur very infrequently. The sequences firing these transitions provide too little information for RTI+ to obtain reliable statistical tests for computing merge and split scores. To avoid this problem, we suggest to check strings in the training data as well as the model. If it does exist in the training data, even though it traverses to a sink state, we can label it as normal behavior to reduce the false positives.</p>
<p>Two anomalous sequences from the DVB system are listed as follows. The first sequence misses As in the beginning, which leads to a failure triggering the following transitions at the start state. </p>
<p>IV. CONCLUSION</p>
<p>We learn a benign behavioral profile using RTI+. Such a generative model provides insights for the ESSs screaming process. The knowledge we discover is consistent with that of the experts from the DVB system area. In addition, our model provides the valid timing in each transition for behavior duration verification. The experiments demonstrate that our model has high accuracy in anomaly detection. Another advantage of our model is that it is efficient for real-time application because the verification is just firing transitions in our model, which is polynomial in time. </p>
<p>Algorithm 1
1Data identification with RTI+: Input: A (multi-)set of timed strings S + Output: A small PDRTA A for S + Construct a timed prefix A tree from S + , let Q = ∅; for all transitions δ = q, q , a, [m, m ] from A, do Evaluate all possible merges of q with states from Q ; Evaluate all possible splits of δ; if the lowest split p-value&lt; 0.05 then perform this split; end else if the highest merge p-value&gt; 0.05 then perform this merge; end else add q to Q ; end end</p>
<p>1 )
1Loops indicate the cycling behavior of sending ESSs. For example the path S0-S1-S2-S3-S4-S5-...S4-S5 can be expressed as: (A{3}1{2}B{3}0{2})+. 2) Without considering the time information, the legitimate rule can be drawn as (A{3-6}1{2}B{3-6}0{2})+. 3) RTI+ splits at some states, e.g., S0 for distinct time guards: [0, 20], [21, 23], and [24, 25]. RTI+ splits the time in a transition to pull apart distinguished tails. Take the two sequences sharing same symbolic rules (A{5}1{2}B{5}0{2})+: S0-S26-S27-S44-S45-S46-...S41-S26 and S0-S42-S43-S51-...S59-S60 for instance, they are distinguished as low and high delay behaviors (loops) of sending the first ECM key: A.This type of information indicates the possible varyingduration properties of the system, which deserves a further verification by the DVB experts.</p>
<p>and III show the results of data lost and time delay testing data set. True positive (TP), false negative (FN), false positive (FP), and true negative (TN) are listed in the tables. Their corresponding rates i.e., TPR, FNR, FPR, TNR, and accuracy (ACC) are computed as well.</p>
<p>Fig. 2 .
2Experimental process based on RTI+</p>
<p>TABLE I
IDATA PREPROCESSING </p>
<p>Original Data 
A, 0 
A, 1 
A, 3 
1, 13 
1, 13 
B, 15 
B, 15 
B, 16 
0, 16 
0, 17 
Time String 
(A, 0) (A, 1) (A, 2) (1, 10) (1, 0) (B, 2) (B, 0) (B, 1) (0, 0) (0, 1) </p>
<p>THE RESULT OF THREE AUTOMATA WHEN TESTING DATA LOST ANOMALY TP FN FP TN TPR FNR FPR TNR ACC THE RESULT OF THREE AUTOMATA WHEN TESTING TIME DELAY ANOMALYTIn the second sequence, the 4th A is outside the valid time 
guard [0, 0]. </p>
<p>TP FN FP TN TPR FNR FPR TNR ACC 
10 
1 
0 
1 
27 
1.00 
0.00 
0.04 
0.96 
0.97 
10 3 
1 
0 
6 
22 
1.00 
0.00 
0.21 
0.79 
0.79 
10 6 
1 
0 
0 
28 
1.00 
0.00 
0.00 
1.00 
1.00 
TABLE II </p>
<p>10 
1 
0 
1 
27 
1.00 
0.00 
0.04 
0.96 
0.96 
10 3 
1 
0 
5 
23 
1.00 
0.00 
0.18 
0.82 
0.83 
10 6 
1 
0 
1 
27 
1.00 
0.00 
0.04 
0.96 
0.96 
TABLE III </p>
<p>ACKNOWLEDGMENTThis work is partially supported by Technologiestichting STW VENI project 13136 (MANTA) and NWO project
On the detection of card-sharing traffic through wavelet analysis and support vector machines. F Palmieri, U Fiore, A Castiglione, A De Santis, Applied Soft Computing. 131F. Palmieri, U. Fiore, A. Castiglione, and A. De Santis, "On the detec- tion of card-sharing traffic through wavelet analysis and support vector machines," Applied Soft Computing, vol. 13, no. 1, pp. 615-627, 2013.</p>
<p>Anomaly detection: A survey. V Chandola, A Banerjee, V Kumar, ACM computing surveys (CSUR). 41315V. Chandola, A. Banerjee, and V. Kumar, "Anomaly detection: A survey," ACM computing surveys (CSUR), vol. 41, no. 3, p. 15, 2009.</p>
<p>Experiencing sax: a novel symbolic representation of time series. J Lin, E Keogh, L Wei, S Lonardi, Data Mining and Knowledge Discovery. 152J. Lin, E. Keogh, L. Wei, and S. Lonardi, "Experiencing sax: a novel symbolic representation of time series," Data Mining and Knowledge Discovery, vol. 15, no. 2, pp. 107-144, 2007.</p>
<p>Time series anomaly discovery with grammar-based compression. P Senin, J Lin, X Wang, T Oates, S Gandhi, A P Boedihardjo, C Chen, S Frankenstein, EDBT. P. Senin, J. Lin, X. Wang, T. Oates, S. Gandhi, A. P. Boedihardjo, C. Chen, and S. Frankenstein, "Time series anomaly discovery with grammar-based compression." in EDBT, 2015, pp. 481-492.</p>
<p>A fast automatonbased method for detecting anomalous program behaviors. R Sekar, M Bendre, D Dhurjati, P Bollineni, Proceedings. 2001 IEEE Symposium on. 2001 IEEE Symposium onIEEESecurity and PrivacyR. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni, "A fast automaton- based method for detecting anomalous program behaviors," in Security and Privacy, 2001. S&amp;P 2001. Proceedings. 2001 IEEE Symposium on. IEEE, 2001, pp. 144-155.</p>
<p>Modelbased anomaly detection for discrete event systems. T Klerx, M Anderka, H K Büning, S Priesterjahn, Tools with Artificial Intelligence (ICTAI). IEEEIEEE 26th International Conference onT. Klerx, M. Anderka, H. K. Büning, and S. Priesterjahn, "Model- based anomaly detection for discrete event systems," in Tools with Artificial Intelligence (ICTAI), 2014 IEEE 26th International Conference on. IEEE, 2014, pp. 665-672.</p>
<p>A likelihood-ratio test for identifying probabilistic deterministic real-time automata from positive data. S Verwer, M De Weerdt, C Witteveen, International Colloquium on Grammatical Inference. SpringerS. Verwer, M. de Weerdt, and C. Witteveen, "A likelihood-ratio test for identifying probabilistic deterministic real-time automata from positive data," in International Colloquium on Grammatical Inference. Springer, 2010, pp. 203-216.</p>            </div>
        </div>

    </div>
</body>
</html>