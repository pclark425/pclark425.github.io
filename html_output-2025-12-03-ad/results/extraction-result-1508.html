<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1508 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1508</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1508</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-30.html">extraction-schema-30</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-1c8cab1cba88b270ddcc23f586aaac90b6741cb7</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1c8cab1cba88b270ddcc23f586aaac90b6741cb7" target="_blank">Situated language learning via interactive narratives</a></p>
                <p><strong>Paper Venue:</strong> Patterns</p>
                <p><strong>Paper TL;DR:</strong> This paper provides a roadmap that explores the question of how to imbue learning agents with the ability to understand and generate contextually relevant natural language in service of achieving a goal, and hypothesizes that two key components in creating such agents are interactivity and environment grounding.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1508.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1508.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALFWorld</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ALFWorld (Aligning text and embodied environments for interactive learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulator that aligns text-based training environments (TextWorld) with visually grounded embodied environments (ALFRED) so agents can learn abstract, text-based policies and transfer commonsense priors to visual tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ALFWorld: Aligning text and embodied environments for interactive learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>text-based policies (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Policies trained in the TextWorld text-game environment (learned via reinforcement learning / policy learning) that operate over abstract textual observations and actions, later executed or adapted in visually grounded embodied environments (ALFRED). Specific architecture details are not provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (train) -> ALFRED (test) via ALFWorld</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>TextWorld: procedurally generated text-adventure environments where agents interact via text (navigation, object interactions, manipulating inventory, following recipes/quests). ALFRED: visually grounded embodied environment where agents must execute everyday household tasks using vision and low-level actions. ALFWorld provides paired/text-to-visual aligned scenarios to transfer policies.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>commonsense procedures (household tasks / everyday routines)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_examples</strong></td>
                            <td>Cooking/recipe-like tasks, locating common objects, using affordances (e.g., where objects are typically found), multi-step household tasks drawn from TextWorld/ALFRED themes.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_structure</strong></td>
                            <td>Tasks are compositional: high-level tasks decompose into ordered subtasks (e.g., gather ingredients -> use tools -> complete recipe); commonsense priors about object locations and affordances form transferable primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_curriculum</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_name</strong></td>
                            <td>text-to-vision transfer curriculum (modality progression)</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_description</strong></td>
                            <td>Sequential training where agents first learn abstract policies in text-only (TextWorld) scenarios that capture commonsense priors (object locations, affordances, causal relations), and then these learned priors/policies are adapted or executed in corresponding visually grounded embodied scenarios (ALFRED) using ALFWorld alignment. The curriculum stages move from abstract/textual training to concrete/visual execution on similarly themed tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_ordering_principle</strong></td>
                            <td>modality progression and task similarity (train on abstract/textual versions first, then transfer to visually grounded versions of similar tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_curriculum</strong></td>
                            <td>Reported qualitatively: commonsense priors learned in text improved generalization in visually grounded environments; no quantitative metrics provided in this survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_curriculum_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>alternative_curriculum_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization</strong></td>
                            <td>Survey reports that commonsense priors (object locations, affordances, causality) learned from text-games can be adapted to improve generalization in visually grounded environments, indicating positive transfer; no numerical success rates are given here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pretraining on abstract text-based tasks provides transferable commonsense priors that help agents generalize better when moved to visually grounded embodied tasks; the paper presents this as evidence that text-games are useful for abstract reasoning before modality-specific fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Situated language learning via interactive narratives', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1508.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1508.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>X-WLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>X-WLP (Process-level representation of scientific protocols framed as text-game quests)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A corpus and framing that converts complex wet lab biochemistry protocols into quest-like text-game representations, enabling annotation and interactive execution via text-game engines and training of agents on laboratory procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Process-level representation of scientific protocols with interactive annotation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>deep reinforcement learning agents (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Deep RL agents trained on text-game quests derived from wet lab protocols to learn procedural execution and action sequencing; the survey does not provide architecture or parameter details.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>X-WLP framed as a text-game engine</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A corpus of wet lab biochemical protocols represented as quests with stepwise actions; annotations are collected through a text-game-like interface, and the protocols can be executed in a text-game engine to train agents on laboratory procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>science procedures (laboratory / wet lab protocols)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_examples</strong></td>
                            <td>Complex wet lab biochemistry protocols (multi-step experimental procedures framed as ordered quests).</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_structure</strong></td>
                            <td>Procedures are represented as ordered sequences of steps (quests) where each step follows logically from preceding steps; protocols are inherently compositional and partial-order constrained (prerequisite step structure like prepare -> mix -> incubate -> measure).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_curriculum</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_ordering_principle</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_range</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_curriculum_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>alternative_curriculum_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization</strong></td>
                            <td>The paper argues that framing wet lab protocols as text-game quests enables interactive training and could improve procedural text understanding and reproducibility, but the survey does not report quantitative transfer or generalization results.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Framing laboratory protocols as quests lowers annotation cost and enables training of interactive agents on scientific procedures; presented as a promising route to improve procedural text understanding and reproducibility, but explicit curriculum experiments or performance metrics are not reported in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Situated language learning via interactive narratives', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1508.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1508.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Automated Quest Generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated Quest Generation in Text-Adventure Games</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods to algorithmically generate world content and quests (ordered activity sequences) for interactive narratives so that generated quests maintain narrative and commonsense coherence and can be used to evaluate or train agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward automated quest generation in text-adventure games</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Procedurally generated interactive narrative worlds (via quest/world generation methods)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Automatically generated text-adventure worlds and quests where each quest is a partial ordering of activities that must fit the world's genre and affordances; worlds include rooms, objects, characters and narrative constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>both commonsense and structured procedural tasks (quests representing recipes, sequences of actions, narrative goals)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_examples</strong></td>
                            <td>Recipe-like quests (gather ingredients, prepare tools, cook), task sequences constrained by genre affordances (e.g., using magic in fantasy worlds), and other multi-step quests.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_structure</strong></td>
                            <td>Quests are explicitly compositional: they are partial orders of activities/subtasks where each step logically follows from previous steps and must satisfy world constraints; generation enforces thematic commonsense and prerequisite relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_ordering_principle</strong></td>
                            <td>prerequisite skills / logical partial ordering (quests are generated as sequences respecting prerequisites and thematic coherence)</td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_range</strong></td>
                            <td>Implied: ranges from simple ordered recipes to complex multi-step quests, but exact step counts or ranges not specified in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_curriculum_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>alternative_curriculum_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization</strong></td>
                            <td>Automated generation provides a means to create many instances of a domain to test whether agents have learned generalizable commonsense; survey discusses this as a tool for evaluating transfer but reports no quantitative generalization outcomes here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Generating quests that respect commonsense ordering and world affordances yields evaluation scenarios that reveal whether agents learned thematic commonsense; automated quest generation can serve as a mechanism to produce curricula-like distributions of tasks for training and testing, but explicit curriculum strategies and empirical gains are not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Situated language learning via interactive narratives', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1508.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1508.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TextWorld</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TextWorld</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for procedural generation of text-based games and tasks providing a controllable environment for training and evaluating agents on text-based procedural tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Textworld: A learning environment for text-based games</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A procedural text-game generation framework that can produce varied worlds, quests, and tasks (navigation, object manipulation, multi-step quests) for training agents; supports creating families of tasks of varying difficulty and complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>commonsense procedures and household/quest-style tasks</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_examples</strong></td>
                            <td>Recipe completion, multi-room navigation with object collection and use, puzzle-like quests with prerequisite steps.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_structure</strong></td>
                            <td>Tasks can be generated with compositional structure (ordered subtasks, prerequisites, nested object relationships) enabling control over task decomposition and complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_ordering_principle</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_range</strong></td>
                            <td>TextWorld supports producing simple to complex quests, but no specific numeric ranges or curricula are described in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_curriculum</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_curriculum_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>alternative_curriculum_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_generalization</strong></td>
                            <td>TextWorld is used as a source domain for ALFWorld pretraining in the survey; the framework's procedural generation facilitates curricula creation, but the survey does not report explicit curriculum experiments or quantitative generalization metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>TextWorld's procedural generation makes it possible to construct ordered, compositional tasks and to generate curriculum-like task distributions (e.g., varying difficulty or prerequisites), but the surveyed paper references the framework rather than presenting specific curriculum-learning results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Situated language learning via interactive narratives', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ALFWorld: Aligning text and embodied environments for interactive learning <em>(Rating: 2)</em></li>
                <li>Process-level representation of scientific protocols with interactive annotation <em>(Rating: 2)</em></li>
                <li>Toward automated quest generation in text-adventure games <em>(Rating: 2)</em></li>
                <li>Textworld: A learning environment for text-based games <em>(Rating: 2)</em></li>
                <li>ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks <em>(Rating: 1)</em></li>
                <li>Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1508",
    "paper_id": "paper-1c8cab1cba88b270ddcc23f586aaac90b6741cb7",
    "extraction_schema_id": "extraction-schema-30",
    "extracted_data": [
        {
            "name_short": "ALFWorld",
            "name_full": "ALFWorld (Aligning text and embodied environments for interactive learning)",
            "brief_description": "A simulator that aligns text-based training environments (TextWorld) with visually grounded embodied environments (ALFRED) so agents can learn abstract, text-based policies and transfer commonsense priors to visual tasks.",
            "citation_title": "ALFWorld: Aligning text and embodied environments for interactive learning",
            "mention_or_use": "mention",
            "agent_name": "text-based policies (unspecified)",
            "agent_description": "Policies trained in the TextWorld text-game environment (learned via reinforcement learning / policy learning) that operate over abstract textual observations and actions, later executed or adapted in visually grounded embodied environments (ALFRED). Specific architecture details are not provided in this survey.",
            "agent_size": null,
            "environment_name": "TextWorld (train) -&gt; ALFRED (test) via ALFWorld",
            "environment_description": "TextWorld: procedurally generated text-adventure environments where agents interact via text (navigation, object interactions, manipulating inventory, following recipes/quests). ALFRED: visually grounded embodied environment where agents must execute everyday household tasks using vision and low-level actions. ALFWorld provides paired/text-to-visual aligned scenarios to transfer policies.",
            "procedure_type": "commonsense procedures (household tasks / everyday routines)",
            "procedure_examples": "Cooking/recipe-like tasks, locating common objects, using affordances (e.g., where objects are typically found), multi-step household tasks drawn from TextWorld/ALFRED themes.",
            "compositional_structure": "Tasks are compositional: high-level tasks decompose into ordered subtasks (e.g., gather ingredients -&gt; use tools -&gt; complete recipe); commonsense priors about object locations and affordances form transferable primitives.",
            "uses_curriculum": true,
            "curriculum_name": "text-to-vision transfer curriculum (modality progression)",
            "curriculum_description": "Sequential training where agents first learn abstract policies in text-only (TextWorld) scenarios that capture commonsense priors (object locations, affordances, causal relations), and then these learned priors/policies are adapted or executed in corresponding visually grounded embodied scenarios (ALFRED) using ALFWorld alignment. The curriculum stages move from abstract/textual training to concrete/visual execution on similarly themed tasks.",
            "curriculum_ordering_principle": "modality progression and task similarity (train on abstract/textual versions first, then transfer to visually grounded versions of similar tasks)",
            "task_complexity_range": null,
            "performance_with_curriculum": "Reported qualitatively: commonsense priors learned in text improved generalization in visually grounded environments; no quantitative metrics provided in this survey text.",
            "performance_without_curriculum": null,
            "has_curriculum_comparison": null,
            "alternative_curriculum_performance": null,
            "transfer_generalization": "Survey reports that commonsense priors (object locations, affordances, causality) learned from text-games can be adapted to improve generalization in visually grounded environments, indicating positive transfer; no numerical success rates are given here.",
            "key_findings": "Pretraining on abstract text-based tasks provides transferable commonsense priors that help agents generalize better when moved to visually grounded embodied tasks; the paper presents this as evidence that text-games are useful for abstract reasoning before modality-specific fine-tuning.",
            "uuid": "e1508.0",
            "source_info": {
                "paper_title": "Situated language learning via interactive narratives",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "X-WLP",
            "name_full": "X-WLP (Process-level representation of scientific protocols framed as text-game quests)",
            "brief_description": "A corpus and framing that converts complex wet lab biochemistry protocols into quest-like text-game representations, enabling annotation and interactive execution via text-game engines and training of agents on laboratory procedures.",
            "citation_title": "Process-level representation of scientific protocols with interactive annotation",
            "mention_or_use": "mention",
            "agent_name": "deep reinforcement learning agents (unspecified)",
            "agent_description": "Deep RL agents trained on text-game quests derived from wet lab protocols to learn procedural execution and action sequencing; the survey does not provide architecture or parameter details.",
            "agent_size": null,
            "environment_name": "X-WLP framed as a text-game engine",
            "environment_description": "A corpus of wet lab biochemical protocols represented as quests with stepwise actions; annotations are collected through a text-game-like interface, and the protocols can be executed in a text-game engine to train agents on laboratory procedures.",
            "procedure_type": "science procedures (laboratory / wet lab protocols)",
            "procedure_examples": "Complex wet lab biochemistry protocols (multi-step experimental procedures framed as ordered quests).",
            "compositional_structure": "Procedures are represented as ordered sequences of steps (quests) where each step follows logically from preceding steps; protocols are inherently compositional and partial-order constrained (prerequisite step structure like prepare -&gt; mix -&gt; incubate -&gt; measure).",
            "uses_curriculum": false,
            "curriculum_name": null,
            "curriculum_description": null,
            "curriculum_ordering_principle": null,
            "task_complexity_range": null,
            "performance_with_curriculum": null,
            "performance_without_curriculum": null,
            "has_curriculum_comparison": false,
            "alternative_curriculum_performance": null,
            "transfer_generalization": "The paper argues that framing wet lab protocols as text-game quests enables interactive training and could improve procedural text understanding and reproducibility, but the survey does not report quantitative transfer or generalization results.",
            "key_findings": "Framing laboratory protocols as quests lowers annotation cost and enables training of interactive agents on scientific procedures; presented as a promising route to improve procedural text understanding and reproducibility, but explicit curriculum experiments or performance metrics are not reported in this survey.",
            "uuid": "e1508.1",
            "source_info": {
                "paper_title": "Situated language learning via interactive narratives",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Automated Quest Generation",
            "name_full": "Automated Quest Generation in Text-Adventure Games",
            "brief_description": "Methods to algorithmically generate world content and quests (ordered activity sequences) for interactive narratives so that generated quests maintain narrative and commonsense coherence and can be used to evaluate or train agents.",
            "citation_title": "Toward automated quest generation in text-adventure games",
            "mention_or_use": "use",
            "agent_name": null,
            "agent_description": null,
            "agent_size": null,
            "environment_name": "Procedurally generated interactive narrative worlds (via quest/world generation methods)",
            "environment_description": "Automatically generated text-adventure worlds and quests where each quest is a partial ordering of activities that must fit the world's genre and affordances; worlds include rooms, objects, characters and narrative constraints.",
            "procedure_type": "both commonsense and structured procedural tasks (quests representing recipes, sequences of actions, narrative goals)",
            "procedure_examples": "Recipe-like quests (gather ingredients, prepare tools, cook), task sequences constrained by genre affordances (e.g., using magic in fantasy worlds), and other multi-step quests.",
            "compositional_structure": "Quests are explicitly compositional: they are partial orders of activities/subtasks where each step logically follows from previous steps and must satisfy world constraints; generation enforces thematic commonsense and prerequisite relationships.",
            "uses_curriculum": null,
            "curriculum_name": null,
            "curriculum_description": null,
            "curriculum_ordering_principle": "prerequisite skills / logical partial ordering (quests are generated as sequences respecting prerequisites and thematic coherence)",
            "task_complexity_range": "Implied: ranges from simple ordered recipes to complex multi-step quests, but exact step counts or ranges not specified in this survey.",
            "performance_with_curriculum": null,
            "performance_without_curriculum": null,
            "has_curriculum_comparison": false,
            "alternative_curriculum_performance": null,
            "transfer_generalization": "Automated generation provides a means to create many instances of a domain to test whether agents have learned generalizable commonsense; survey discusses this as a tool for evaluating transfer but reports no quantitative generalization outcomes here.",
            "key_findings": "Generating quests that respect commonsense ordering and world affordances yields evaluation scenarios that reveal whether agents learned thematic commonsense; automated quest generation can serve as a mechanism to produce curricula-like distributions of tasks for training and testing, but explicit curriculum strategies and empirical gains are not detailed in this paper.",
            "uuid": "e1508.2",
            "source_info": {
                "paper_title": "Situated language learning via interactive narratives",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "TextWorld",
            "name_full": "TextWorld",
            "brief_description": "A framework for procedural generation of text-based games and tasks providing a controllable environment for training and evaluating agents on text-based procedural tasks.",
            "citation_title": "Textworld: A learning environment for text-based games",
            "mention_or_use": "mention",
            "agent_name": null,
            "agent_description": null,
            "agent_size": null,
            "environment_name": "TextWorld",
            "environment_description": "A procedural text-game generation framework that can produce varied worlds, quests, and tasks (navigation, object manipulation, multi-step quests) for training agents; supports creating families of tasks of varying difficulty and complexity.",
            "procedure_type": "commonsense procedures and household/quest-style tasks",
            "procedure_examples": "Recipe completion, multi-room navigation with object collection and use, puzzle-like quests with prerequisite steps.",
            "compositional_structure": "Tasks can be generated with compositional structure (ordered subtasks, prerequisites, nested object relationships) enabling control over task decomposition and complexity.",
            "uses_curriculum": null,
            "curriculum_name": null,
            "curriculum_description": null,
            "curriculum_ordering_principle": null,
            "task_complexity_range": "TextWorld supports producing simple to complex quests, but no specific numeric ranges or curricula are described in this survey.",
            "performance_with_curriculum": null,
            "performance_without_curriculum": null,
            "has_curriculum_comparison": null,
            "alternative_curriculum_performance": null,
            "transfer_generalization": "TextWorld is used as a source domain for ALFWorld pretraining in the survey; the framework's procedural generation facilitates curricula creation, but the survey does not report explicit curriculum experiments or quantitative generalization metrics.",
            "key_findings": "TextWorld's procedural generation makes it possible to construct ordered, compositional tasks and to generate curriculum-like task distributions (e.g., varying difficulty or prerequisites), but the surveyed paper references the framework rather than presenting specific curriculum-learning results.",
            "uuid": "e1508.3",
            "source_info": {
                "paper_title": "Situated language learning via interactive narratives",
                "publication_date_yy_mm": "2021-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ALFWorld: Aligning text and embodied environments for interactive learning",
            "rating": 2,
            "sanitized_title": "alfworld_aligning_text_and_embodied_environments_for_interactive_learning"
        },
        {
            "paper_title": "Process-level representation of scientific protocols with interactive annotation",
            "rating": 2,
            "sanitized_title": "processlevel_representation_of_scientific_protocols_with_interactive_annotation"
        },
        {
            "paper_title": "Toward automated quest generation in text-adventure games",
            "rating": 2,
            "sanitized_title": "toward_automated_quest_generation_in_textadventure_games"
        },
        {
            "paper_title": "Textworld: A learning environment for text-based games",
            "rating": 2,
            "sanitized_title": "textworld_a_learning_environment_for_textbased_games"
        },
        {
            "paper_title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks",
            "rating": 1,
            "sanitized_title": "alfred_a_benchmark_for_interpreting_grounded_instructions_for_everyday_tasks"
        },
        {
            "paper_title": "Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text",
            "rating": 1,
            "sanitized_title": "playing_by_the_book_an_interactive_game_approach_for_action_graph_extraction_from_text"
        }
    ],
    "cost": 0.013197500000000001,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Situated Language Learning via Interactive Narratives</h1>
<p>Prithviraj Ammanabrolu<br>Georgia Institute of Technology<br>raj.ammanabrolu@gatech.edu</p>
<p>Mark O. Riedl<br>Georgia Institute of Technology<br>riedl@cc.gatech.edu</p>
<h4>Abstract</h4>
<p>This paper provides a roadmap that explores the question of how to imbue learning agents with the ability to understand and generate contextually relevant natural language in service of achieving a goal. We hypothesize that two key components in creating such agents are interactivity and environment grounding, shown to be vital parts of language learning in humans, and posit that interactive narratives should be the environments of choice for such training these agents. These games are simulations in which an agent interacts with the world through natural language-"perceiving", "acting upon", and "talking to" the world using textual descriptions, commands, and dialogue-and as such exist at the intersection of natural language processing, storytelling, and sequential decision making. We discuss the unique challenges a text games' puzzle-like structure combined with natural language state-and-action spaces provides: knowledge representation, commonsense reasoning, and exploration. Beyond the challenges described so far, progress in the realm of interactive narratives can be applied in adjacent problem domains. These applications provide interesting challenges of their own as well as extensions to those discussed so far. We describe three of them in detail: (1) evaluating AI system's commonsense understanding by automatically creating interactive narratives; (2) adapting abstract text-based policies to include other modalities such as vision; and (3) enabling multi-agent and human-AI collaboration in shared, situated worlds.</p>
<h2>1 Introduction</h2>
<p>Natural language communication has long been considered a defining characteristic of human intelligence. In humans, this communication is grounded in experience and real world context-"what" we say or do depends on the current context around us and "why" we say or do something draws on commonsense knowledge gained through experience. So how do we imbue learning agents with the ability to understand and generate contextually relevant natural language in service of achieving a goal?</p>
<p>Two key components in creating such agents are interactivity and environment grounding, shown to be vital parts of language learning in humans. Humans learn various skills such as language, vision, motor skills, etc. more effectively through interactive media [Feldman and Narayanan, 2004, Barsalou, 2008]. In the realm of machines, interactive environments have served as cornerstones in the quest to develop more robust algorithms for learning agents across many machine learning sub-communities. Environments such as the Atari Learning Environment [Bellemare et al., 2013] and Minecraft [Johnson et al., 2016] have enabled the development of game agents that perform complex tasks while operating on raw video inputs, and more recently THOR [Kolve et al., 2017] and Habitat [Manolis Savva* et al., 2019] attempt to do the same with embodied agents in simulated 3D worlds.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An excerpt from Zork1, a typical text-based adventure game.</p>
<p>Despite such progress in modern machine learning and natural language processing, agents that can communicate with humans (and other agents) through natural language in pursuit of their goals are still primitive. One possible reason for this is that many datasets and tasks used for NLP are static, not supporting interaction and language grounding [Brooks, 1991, Feldman and Narayanan, 2004, Barsalou, 2008, Mikolov et al., 2016, Gauthier and Mordatch, 2016, Lake et al., 2017] In other words, there has been a void for such interactive environments for purely language-oriented tasks. Building on recent work in this field, we posit that interactive narratives should be the environments of choice for such language-oriented tasks. Interactive Narratives, in general, is an umbrella term, that refers to any form of digital interactive experience in which users create or influence a dramatic storyline through their actions [Riedl and Bulitko, 2013]-i.e. the overall story progression in the game is not pre-determined and is directly influenced by a player's choices. For the purposes of this work, we consider one particular type of interactive narrative, parser-based interactive fiction (or text-adventure) games-though we note that other forms of interactive narrative, including those with visual components, provide closely related challenges.
Figure 1 showcases Zork [Anderson et al., 1979], one of the earliest and most influential text-based interactive narrative. These games are simulations in which an agent interacts with the world through natural language-"perceiving", "acting upon", and "talking to" the world using textual descriptions, commands, and dialogue. The simulations are partially observable, meaning that the agent never has access to the true underlying world state and has to reason about how to act in the world based only on potentially the incomplete textual observations of its immediate surroundings. They provide tractable, situated environments in which to explore highly complex interactive grounded language learning without the complications that arise when modeling physical motor control and vision-situations that voice assistants such as Siri or Alexa might find themselves in when improvising responses. These games are usually structured as puzzles or quests with long-term dependencies in which a player must complete a sequence of actions and/or dialogues to succeed. This in turn requires navigation and interaction with hundreds of locations, characters, and objects. The interactive narrative community is one of the oldest gaming communities and game developers in this genre are quite creative. Put these two things together and we get very large, complex worlds that contain a multitude of puzzles and quests to solve across many different genres-everything from slice of life simulators where the player cooks a recipe in their home to Lovecraftian horror mysteries. The complexity and diversity of topics enable us to build and test agents that go an extra step towards modeling the difficulty of situated human language communication.
As the excerpt of the text-game in Figure 1 shows, humans bring competencies in natural language understanding, commonsense reasoning, and deduction to bear in order to infer the context and objectives of a game. Beyond games, real-world applications such as voice-activated personal as-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: A map of Zork1 by artist ion_bond.
sistants can also benefit from advances in these capabilities at the intersection of natural language understanding, natural language generation, and sequential decision making. These real world applications require the ability to reason with ungrounded natural language (unlike multimodal environments that provide visual grounding for language) and interactive narratives provide an excellent suite of environments to tackle these challenges.</p>
<p>Currently, three primary open-source platforms and baseline benchmarks have been developed so far to help measure progress in this field: Jericho [Hausknecht et al., 2020] ${ }^{1}$ a learning environment for human-made interactive narrative games; TextWorld [Ct et al., 2018] ${ }^{2}$ a framework for procedural generation in text-games; and LIGHT [Urbanek et al., 2019] ${ }^{3}$ a large-scale crowdsourced multi-user text-game for studying situated dialogue.</p>
<h1>2 Challenges</h1>
<p>Interactive narratives exist at the intersection of natural language processing, storytelling, and sequential decision making. Like many NLP tasks, they require natural language understanding, but unlike most NLP tasks, Interactive narratives are sequential decision making problems in which actions change the subsequent world states of the game and choices made early in a game may have long term effects on the eventual endings. Reinforcement Learning [Sutton and Barto, 1998] studies sequential decision making problems and has shown promise in vision-based [Jaderberg et al., 2016] and control-based [OpenAI et al., 2018] environments, but has less commonly been applied in the context of language-based tasks. Text-based games thus pose a different set of challenges than traditional video games such as StarCraft. Their puzzle-like structure coupled with a partially observable state space and sparse rewards require a greater understanding of previous context to enable more effective exploration-an implicit long-term dependency problem not often found in other domains that agents must overcome.</p>
<h3>2.1 Knowledge Representation</h3>
<p>Interactive narratives span many distinct locations, each with unique descriptions, objects, and characters. An example of a world of a interactive fiction game can be seen in Figure 2. Players move between locations by issuing navigational commands like go West.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>This, in conjunction with the inherent partial observability of interactive narratives, gives rise to the Textual-SLAM problem, a textual variant of Simultaneous localization and mapping (SLAM) [Thrun et al., 2005] problem of constructing a map while navigating a new environment. In particular, because connectivity between locations is not necessarily Euclidean, agents need to detect when a navigational action has succeeded or failed and whether the location reached was previously seen or new. Beyond location connectivity, its also helpful to keep track of the objects present at each location, with the understanding that objects can be nested inside of other objects, such as food in a refrigerator or a sword in a chest.</p>
<p>Due to the large number of locations in many games, humans often create structured memory aids such as maps to navigate efficiently and avoid getting lost. The creation of such memory aids has been shown to be critical in helping automated learning agents operate in these textual worlds [Ammanabrolu and Riedl, 2019, Murugesan et al., 2020, Adhikari et al., 2020, Ammanabrolu and Hausknecht, 2020]</p>
<h3>2.2 Acting and Speaking in Combinatorially-sized State-Action Spaces</h3>
<p>Interactive narratives require the agent to operate in the combinatorial action space of natural language. To realize how difficult a game such as Zork1 is for standard reinforcement learning agents, we need to first understand how large this space really is. In order to solve solve a popular IF game such as Zork1 its necessary to generate actions consisting of up to five-words from a relatively modest vocabulary of 697 words recognized by Zorks parser. Even this modestly sized vocabulary leads to $\mathcal{O}(697^{5})=1.64 \times 10^{14}$ possible actions at every stepa dauntingly-large combinatorially-sized action space for a learning agent to explore. In comparison, board games such as chess and Go or Atari video games have branching factors of the order of $\mathcal{O}(10^{2})$.</p>
<p>Some text-games extend this even further by requiring agents to engage in dialogue to progress in a task, increasing the space of possibilities exponentially and bringing text environments closer to real-world situations. An example of such an environmentdesigned explicitly as a research platformis the large-scale crowdsourced fantasy text-adventure game LIGHT [Urbanek et al., 2019], seen in Figure 3, where characters can act and talk while interacting with other characters. It consists of a set of locations, characters, and objects leading to rich textual worlds in addition to quests demonstrations of humans playing these quests providing natural language descriptions in varying levels of abstraction of motivations for a given character in a particular setting.</p>
<p>On top of the other text-game related challenges, the primary core challenge for the agent here is the recognition that dialogue can also be used to change the environment. With dialogue, an agent can now learn to instruct or convince other characters in the world to achieve the goal for ite.g. convince the pirate through dialogue to give you their treasure instead of just stealing it yourself. The agent needs to learn to balance both its ability to speak as well as act in order to effectively achieve its goals [Ammanabrolu et al., 2021].</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The LIGHT [Urbanek et al., 2019] environment.</p>
<h3>2.3 Commonsense Reasoning</h3>
<p>Text-games cover a wide variety of genres, as mentioned earlier this ranges from slice of life simulators where the player makes a recipe in their home to Lovecraftian horror mysteries. In order to effectively convey the core narrative or puzzle, text-adventure games make ample use of prior commonsense knowledge. Everyday example could be something as mundane as the fact that an axe can be used to cut wood, or that swords are weapons. Different genres also have specific knowledge</p>
<p>attached to them that wouldn't normally be found in mundane settings, e.g. in a horror or fantasy game, we know that a coffin is likely to contain a vampire or other undead monster or that kings are royalty and must be treated respectfully. When a human enters a particular domain, they already possess priors regarding the specific knowledge relevant to the situations likely to be encounteredthis is thematic commonsense knowledge that a learning agent must acquire to ensure successful interactions.</p>
<p>This is closely related to the problem of transfer, the problem of acquiring and adapting these priors in novel environments through interaction. In this sense, we can think of commonsense knowledge as priors regarding environment dynamics. This problem space can be explored using text-based games. What commonsense can be transferred between two different environments, for example, a horror game and a mundane slice of life game? How do you unlearn, or choose not to apply, a piece of commonsense that no longer fits with the current world. What if the perceived environment dynamics change in novel ways? E.g. some vampires actually love garlic instead of being allergic to them or you suddenly find out that bread can be made without yeast and is known as sourdoughwhole new categories of recipes are now possible.</p>
<h1>2.4 Exploration</h1>
<p>Most text-adventure games have relatively linear plots in which players must solve a sequence of puzzles to advance the story and gain score. To solve these puzzles, players have freedom to a explore both new areas and previously unlocked areas of the game, collect clues, and acquire tools needed to solve the next puzzle and unlock the next portion of the game. From a Reinforcement Learning perspective, these puzzles can be viewed as bottlenecks that act as partitions between different regions of the state space. Whereas the relatively linear progression through puzzles may seem to make the problem easier, the opposite is true. The bottlenecks set up a situation where agents get stuck because they do not see the right action sequence enough times to be sufficiently reinforced. We contend that existing Reinforcement Learning agents are unaware of such latent structure and are thus poorly equipped for solving these types of problems.</p>
<p>Overcoming bottlenecks is not as simple as selecting the correct action from the bottleneck state. Most bottlenecks have long-range dependencies that must first be satisfied: Zork1 for instance features a bottleneck in which the agent must pass through the unlit Cellar where a monster known as a Grue lurks, ready to eat unsuspecting players who enter without a light source. To pass this bottleneck the player must have previously acquired and lit the lantern. Reaching the Cellar without acquiring the lantern results in the player reaching an unwinnable state-the player is unable to go back and acquire a lantern but also cannot progress further without a way to combat the darkness. Other bottlenecks don't rely on inventory items and instead require the player to have satisfied an external condition such as visiting the reservoir control to drain water from a submerged room before being able to visit it. In both cases, the actions that fulfill dependencies of the bottleneck, e.g. acquiring the lantern or draining the room, are not rewarded by the game. Thus agents must correctly satisfy all latent dependencies, most of which are unrewarded, then take the right action from the correct location to overcome such bottlenecks. Consequently, most existing agents-regardless of whether they use a reduced action space [Zahavy et al., 2018, Yuan et al., 2018, Yin and May, 2019] or the full space [Hausknecht et al., 2020, Ammanabrolu and Hausknecht, 2020]-have failed to consistently clear these bottlenecks. It is only recently that works have begun explicitly accounting for and surpassing such bottlenecks-using a reduced action space and Monte-Carlo Planning [Jang et al., 2021] and full action space and intrinsic motivation-based structured exploration [Ammanabrolu et al., 2020c].</p>
<h2>3 Applications and Future Directions</h2>
<p>Beyond the challenges described so far, progress in the realm of interactive narratives can be applied in adjacent problem domains. These applications provide interesting challenges of their own as well as extensions to those discussed so far. This section will describe three of them in detail: (1) evaluating AI system's commonsense understanding by creating interactive narratives; (2) adapting abstract text-based policies to include other modalities such as vision; and (3) enabling multi-agent and human-AI collaboration in shared, situated worlds.</p>
<h1>3.1 Automated World and Quest Generation</h1>
<p>A key consideration in modeling communication through a general purpose interactive narrative solver is that an agent trained to solve these games is limited by the scenarios described in them. Although the range of scenarios is vast, this brings about the question of what the agent is actually capable of understanding even if it has learned to solve all the puzzles in a particular game. Deep (reinforcement) learning systems tend to learn to generalize from the head of any particular data distribution, the "common" scenarios, and memorize the tail, the rarely seen cases. We contend that a potential way of testing an AI system's understanding of a domain is to use the knowledge it has gained in a novel way and to create more instances of that domain.</p>
<p>From the perspective of interactive narratives, this involves automatically creating such gamesthe flip side of the problem of creating agents that operate in these environments-and requires anticipating how people will interact with these environments and conforming to such expected commonsense norms to make a creative and engaging experience. The core experience in an interactive narrative revolves the quest, consisting of the partial ordering of activities that an agent must engage in to make progress toward the end of the game. Quest generation requires narrative intelligence and commonsense knowledge as a quest must maintain coherence throughout while progressing towards a goal [Ammanabrolu et al., 2020a]. Each step of the quest follows logically from the preceding steps much like the steps of a cooking recipe. A restaurant cannot serve a batch of cookies without first gathering ingredients, preparing cooking instruments, mixing ingredients, etc. in a particular sequence. Any generated quest that doesn't follow such an ordering will appear random or nonsensical to a human, betraying the AI's lack of commonsense understanding.</p>
<p>Maintaining quest coherence also means following the constraints of the given game world. The quest has to fit within the confines of the world in terms of both genre and given affordances-e.g. using magic in a fantasy world, placing kitchens next to living rooms in mundane worlds, etc. This gives rise to the concept of world generation, the second half of the automated game generation problem. This refers to generating the structure of the world, including the layout of rooms, textual description of rooms, objects, and characters-setting the boundaries for how an agent is allowed to interact with the world [Ammanabrolu et al., 2020b]. Similarly to quests, a world violating thematically relevant commonsense structuring rules will appear random to humans, providing us with a metric to measure an AI system's understanding.</p>
<h3>3.2 Transfer across domains and modalities</h3>
<p>Many of the core challenges presented by text games manifest themselves across domains with different modalities and it may be possible to transfer progress between the domains. Take the example of a slice-of-life walking simulator text game where the main quest is to complete a recipe as given before. What happens when we encounter a similar situation with the added modality of vision? Can we take the knowledge we've gained from learning a textbased policy by completing the recipe in the original text game and use that to learn how to do something similar with a visually embodied agent? To test this idea, Shridhar et al. [2021] built ALFWorld, a simulator that lets you first learn text-based policies in the "home" textgame TextWorld [Ct et al., 2018], and then execute them in similarly themed scenarios from the visual environment ALFRED [Shridhar et al., 2020]. They find that commonsense priors-regarding things like common object locations, affordances, and causality-learned while playing text-games can be adapted to help create agents that generalize better in visually
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: ALFWorld [Shridhar et al., 2021].</p>
<p>grounded environments. This indicates that text games are suitable environments to train agents to reason abstractly through text which can then be refined and adapted to specific instances in an embodied setting.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: A wet lab protocol as a text game from the X-WLP dataset [Tamari et al., 2021].</p>
<p>Another such cross-domain transfer experiment was tested by Tamari et al. [2021], where they collected and built X-WLP, a corpus of complex wet lab biochemistry protocols that are framed as a quest and could thus be executed via a text-game engine. The annotations themselves are collected using a text-game-like interface, reducing overall data collection cost. Tamari et al. [2019] discuss automatically extracting these protocols from raw lab texts and also training deep reinforcement learning agents on the resulting text-game quest. The ability to automatically frame wet lab experiments in the form of text game quests and leverage the latest text-game agent advances to interactively train agents to perform them has implications for significantly improving procedural text understanding [Levy et al., 2017] and in the reproducibility of scientific experiments [Mehr et al., 2020].</p>
<h1>3.3 Multi-agent and Human-AI Collaboration</h1>
<p>Current work on teaching agents to act and speak in situated, shared worlds such as LIGHT opens the doors for exploring multi-agent communication using natural language, i.e. through dialogue. It has been shown how to teach agents to act and talk in pursuit of a goal in this world leads to them learning multiple ways of achieve the goal: acting to do it themselves, or convincing a partner agent to do it for them. We envision this situated learning paradigm extended to to a multi-agent setting, where there are multiple agents progressing through a world in pursuit of their own motivations that learn to communicate with each other, figuring out what others can do for them. This gives rise to a dynamic world within the bounds of a unified decision making framework, a situation autonomous agents are likely to find themselves in. A village led by an ambitious chief seeking expansion will expand into a town via environment dynamics, or narrative, emerging from this multiagent communication. Agents can further be taught which other agents they should cooperate with and which they should compete with on the basis of the alignment of their motivations. A dragon terrorizing a kingdom and a knight may perhaps be at odds, but the kingdom's ruler will have cause to cooperate and explicitly aid the knight in slaying the dragon. A not-so-fantastic example would be two small clothing businesses cooperating and pooling resources to compete against an encroaching large corporation.
A human-AI collaborative system is an instance of such a multi-agent system where one or more of the agents are humans. These works thus have direct implications for human-AI collaborative systems: from agents that act and talk in multi-user worlds, to improvisational and collaborative storytelling, and creative writing assistants for human authors.</p>
<h2>4 Conclusion</h2>
<p>Interactive narratives provide tractable, situated environments in which to explore highly complex interactive grounded language learning without the complications that arise when modeling physical motor control and vision. The unique challenges a text games' puzzle-like structure combined with natural language state-and-action spaces provides is: knowledge representation, commonsense reasoning, and exploration. These challenges create an implicit long-term dependency problem not often found in other domains that agents must overcome. Text-based games thus pose a different set of challenges than traditional video games such as StarCraft. Beyond the challenges described so far, we have seen how progress in the realm of interactive narratives can be applied in adjacent problem domains, specifically: (1) structured environment creation; (2) transfer to other modalities and domains; and (3) enabling multi-agent and human-AI collaboration in shared, situated worlds.</p>
<h1>Acknowledgements</h1>
<p>We thank Matthew Hausknecht, Xingdi Yuan, and Marc-Alexandre Ct of Microsoft Research for useful discussions on text games and their work on the Jericho and TextWorld platforms. Likewise, thanks to Jack Urbanek, Margaret Li, Arthur Szlam, Tim Rocktschel, and Jason Weston of Facebook AI Research for their efforts and guidance in the work on the LIGHT framework. We also would like to thank the corresponding authors Mohit Shridar of the University of Washington and Ronen Tamari of the Hebrew University of Jerusalem for discussions regarding their respective works ALFWorld and X-WLP and the images within reproduced accordingly.</p>
<h2>References</h2>
<p>A. Adhikari, X. Yuan, M.-A. Ct, M. Zelinka, M.-A. Rondeau, R. Laroche, P. Poupart, J. Tang, A. Trischler, and W. L. Hamilton. Learning dynamic knowledge graphs to generalize on textbased games. arXiv preprint arXiv:2002.09127, 2020.
P. Ammanabrolu and M. Hausknecht. Graph Constrained Reinforcement Learning for Natural Language Action Spaces. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=B1x6w0EtwH.
P. Ammanabrolu and M. O. Riedl. Playing text-adventure games with graph-based deep reinforcement learning. In Proceedings of 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, 2019.
P. Ammanabrolu, W. Broniec, A. Mueller, J. Paul, and M. O. Riedl. Toward automated quest generation in text-adventure games. In International Conference on Computational Creativity (ICCC), 2020a. URL https://arxiv.org/abs/1909.06283.
P. Ammanabrolu, W. Cheung, D. Tu, W. Broniec, and M. O. Riedl. Bringing stories alive: Generating interactive fiction worlds. In Proceedings of the Sixteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE-20), 2020b. URL https: //www.aaai.org/ojs/index.php/AIIDE/article/view/7400.
P. Ammanabrolu, E. Tien, M. Hausknecht, and M. O. Riedl. How to avoid being eaten by a grue: Structured exploration strategies for textual worlds. arXiv preprint arXiv:2006.07409, 2020c.
P. Ammanabrolu, J. Urbanek, M. Li, A. Szlam, T. Rocktschel, and J. Weston. How to motivate your dragon: Teaching goal-driven agents to speak and act in fantasy worlds. In Proceedings of 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, 2021. URL https://arxiv.org/ abs/2010.00685.
T. Anderson, M. Blank, B. Daniels, and D. Lebling. Zork. http://ifdb.tads.org/viewgame?id= 4gxk83ja4twckm6j, 1979.
L. W. Barsalou. Grounded cognition. Annual Review of Psychology, 59(1):617-645, 2008. doi: 10. 1146/annurev.psych.59.103006.093639. URL https://doi.org/10.1146/annurev.psych.59.103006. 093639. PMID: 17705682.
M. G. Bellemare, Y. Naddaf, J. Veness, and M. Bowling. The arcade learning environment: An evaluation platform for general agents. Journal of Artificial Intelligence Research, 47:253-279, jun 2013.
R. A. Brooks. Intelligence without representation. Artificial intelligence, 47(1-3):139-159, 1991.
M.-A. Ct, A. Kdr, X. Yuan, B. Kybartas, T. Barnes, E. Fine, J. Moore, M. Hausknecht, L. E. Asri, M. Adada, W. Tay, and A. Trischler. Textworld: A learning environment for text-based games. CoRR, abs/1806.11532, 2018.
J. Feldman and S. Narayanan. Embodied meaning in a neural theory of language. Brain and language, 89:385-92, 06 2004. doi: 10.1016/S0093-934X(03)00355-9.</p>
<p>J. Gauthier and I. Mordatch. A paradigm for situated and goal-driven language learning. arXiv preprint arXiv:1610.03585, 2016.
M. Hausknecht, P. Ammanabrolu, M.-A. Ct, and X. Yuan. Interactive fiction games: A colossal adventure. In Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI), 2020. URL https: //arxiv.org/abs/1909.05398.
M. Jaderberg, V. Mnih, W. M. Czarnecki, T. Schaul, J. Z. Leibo, D. Silver, and K. Kavukcuoglu. Reinforcement learning with unsupervised auxiliary tasks. CoRR, abs/1611.05397, 2016.
Y. Jang, S. Seo, J. Lee, and K.-E. Kim. Monte-carlo planning and learning with language action value estimates. In International Conference on Learning Representations, 2021. URL https: //openreview.net/forum?id=7_G8JySGecm.
M. Johnson, K. Hofmann, T. Hutton, and D. Bignell. The malmo platform for artificial intelligence experimentation. In IJCAI, IJCAI'16, pages 4246-4247. AAAI Press, 2016. ISBN 978-1-57735-770-4.
E. Kolve, R. Mottaghi, W. Han, E. VanderBilt, L. Weihs, A. Herrasti, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. AI2-THOR: An Interactive 3D Environment for Visual AI. arXiv, 2017.
B. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman. Building machines that learn and think like people. Behavioral and brain sciences, 40, 2017.
O. Levy, M. Seo, E. Choi, and L. Zettlemoyer. Zero-shot relation extraction via reading comprehension. In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 333-342, Vancouver, Canada, Aug. 2017. Association for Computational Linguistics. doi: 10.18653/v1/K17-1034. URL https://www.aclweb.org/anthology/K17-1034.</p>
<p>Manolis Savva<em>, Abhishek Kadian</em>, Oleksandr Maksymets*, Y. Zhao, E. Wijmans, B. Jain, J. Straub, J. Liu, V. Koltun, J. Malik, D. Parikh, and D. Batra. Habitat: A Platform for Embodied AI Research. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2019.
S. H. M. Mehr, M. Craven, A. I. Leonov, G. Keenan, and L. Cronin. A universal system for digitization and automatic execution of the chemical synthesis literature. Science, 370(6512):101-108, 2020. ISSN 0036-8075. doi: 10.1126/science.abc2986. URL https://science.sciencemag.org/ content/370/6512/101.
T. Mikolov, A. Joulin, and M. Baroni. A roadmap towards machine intelligence. In International Conference on Intelligent Text Processing and Computational Linguistics, pages 29-61. Springer, 2016.
K. Murugesan, M. Atzeni, P. Shukla, M. Sachan, P. Kapanipathi, and K. Talamadupula. Enhancing text-based reinforcement learning agents with commonsense knowledge. arXiv preprint arXiv:2005.00811, 2020.</p>
<p>OpenAI, M. Andrychowicz, B. Baker, M. Chociej, R. Jzefowicz, B. McGrew, J. W. Pachocki, J. Pachocki, A. Petron, M. Plappert, G. Powell, A. Ray, J. Schneider, S. Sidor, J. Tobin, P. Welinder, L. Weng, and W. Zaremba. Learning dexterous in-hand manipulation. CoRR, abs/1808.00177, 2018.
M. O. Riedl and V. Bulitko. Interactive narrative: An intelligent systems approach. Ai Magazine, 34 (1):67-67, 2013.
M. Shridhar, J. Thomason, D. Gordon, Y. Bisk, W. Han, R. Mottaghi, L. Zettlemoyer, and D. Fox. ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. URL https://arxiv.org/ abs/1912.01734.
M. Shridhar, X. Yuan, M.-A. Cote, Y. Bisk, A. Trischler, and M. Hausknecht. {ALFW}orld: Aligning text and embodied environments for interactive learning. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=0IOX0YcCdTn.</p>
<p>R. S. Sutton and A. G. Barto. Introduction to Reinforcement Learning. MIT Press, Cambridge, MA, USA, 1st edition, 1998. ISBN 0262193981.
R. Tamari, H. Shindo, D. Shahaf, and Y. Matsumoto. Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text. In Proceedings of the Workshop on Extracting Structured Knowledge from Scientific Publications, pages 62-71, Minneapolis, Minnesota, jun 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-2609. URL https:// www.aclweb.org/anthology/W19-2609.
R. Tamari, F. Bai, A. Ritter, and G. Stanovsky. Process-level representation of scientific protocols with interactive annotation. arXiv preprint arXiv:2101.10244, 2021.
S. Thrun, W. Burgard, and D. Fox. Probabilistic Robotics (Intelligent Robotics and Autonomous Agents). The MIT Press, 2005. ISBN 0262201623.
J. Urbanek, A. Fan, S. Karamcheti, S. Jain, S. Humeau, E. Dinan, T. Rocktschel, D. Kiela, A. Szlam, and J. Weston. Learning to speak and act in a fantasy text adventure game. CoRR, abs/1903.03094, 2019.
X. Yin and J. May. Comprehensible context-driven text game playing. CoRR, abs/1905.02265, 2019.
X. Yuan, M. Ct, A. Sordoni, R. Laroche, R. T. des Combes, M. J. Hausknecht, and A. Trischler. Counting to explore and generalize in text-based games. CoRR, abs/1806.11525, 2018.
T. Zahavy, M. Haroush, N. Merlis, D. J. Mankowitz, and S. Mannor. Learn what not to learn: Action elimination with deep reinforcement learning. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 3562-3573. Curran Associates, Inc., 2018.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ https://github.com/microsoft/jericho
${ }^{2}$ https://github.com/microsoft/textworld
${ }^{3}$ https://parl.ai/projects/light&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>