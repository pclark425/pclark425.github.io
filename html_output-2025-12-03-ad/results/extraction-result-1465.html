<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1465 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1465</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1465</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-30.html">extraction-schema-30</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-78edaf9f4609405c38fa98bbd9938afd2fe0018a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/78edaf9f4609405c38fa98bbd9938afd2fe0018a" target="_blank">"What's my model inside of?": Exploring the role of environments for grounded natural language understanding</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This thesis developed novel training and annotation approaches for procedural text understanding based on text-based game environments and integrated theories on the role of environments in collective human intelligence to propose a design for AI-augmented "social thinking environments" for knowledge workers like scientists.</p>
                <p><strong>Paper Abstract:</strong> In contrast to classical cognitive science which studied brains in isolation, ecological approaches focused on the role of the body and environment in shaping cognition. Similarly, in this thesis we adopt an ecological approach to grounded natural language understanding (NLU) research. Grounded language understanding studies language understanding systems situated in the context of events, actions and precepts in naturalistic/simulated virtual environments. Where classic research tends to focus on designing new models and optimization methods while treating environments as given, we explore the potential of environment design for improving data collection and model development. We developed novel training and annotation approaches for procedural text understanding based on text-based game environments. We also drew upon embodied cognitive linguistics literature to propose a roadmap for grounded NLP research, and to inform the development of a new benchmark for measuring the progress of large language models on challenging commonsense reasoning tasks. We leveraged the richer supervision provided by text-based game environments to develop Breakpoint Transformers, a novel approach to modeling intermediate semantic information in long narrative or procedural texts. Finally, we integrated theories on the role of environments in collective human intelligence to propose a design for AI-augmented"social thinking environments"for knowledge workers like scientists.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text <em>(Rating: 2)</em></li>
                <li>Process-Level Representation of Scientific Protocols with Interactive Annotation <em>(Rating: 2)</em></li>
                <li>Dyna-bAbI: unlocking bAbI's potential with dynamic synthetic benchmarking <em>(Rating: 2)</em></li>
                <li>Breakpoint Transformers for Modeling and Tracking Intermediate Beliefs <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1465",
    "paper_id": "paper-78edaf9f4609405c38fa98bbd9938afd2fe0018a",
    "extraction_schema_id": "extraction-schema-30",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text",
            "rating": 2,
            "sanitized_title": "playing_by_the_book_an_interactive_game_approach_for_action_graph_extraction_from_text"
        },
        {
            "paper_title": "Process-Level Representation of Scientific Protocols with Interactive Annotation",
            "rating": 2,
            "sanitized_title": "processlevel_representation_of_scientific_protocols_with_interactive_annotation"
        },
        {
            "paper_title": "Dyna-bAbI: unlocking bAbI's potential with dynamic synthetic benchmarking",
            "rating": 2,
            "sanitized_title": "dynababi_unlocking_babis_potential_with_dynamic_synthetic_benchmarking"
        },
        {
            "paper_title": "Breakpoint Transformers for Modeling and Tracking Intermediate Beliefs",
            "rating": 2,
            "sanitized_title": "breakpoint_transformers_for_modeling_and_tracking_intermediate_beliefs"
        }
    ],
    "cost": 0.003992,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>"What's my model inside of?": Exploring the role of environments for grounded natural language understanding</h1>
<p>Thesis for the degree of<br>"Doctor of Philosophy"</p>
<p>by<br>Ronen Tamari</p>
<p>Submitted to the Senate of the Hebrew University of Jerusalem
October 2023</p>
<p>.</p>
<p>This work was carried out under the supervision of</p>
<p>Prof. Dafna Shahaf and Prof. Reut Tsarfaty</p>
<p>.</p>
<h1>Acknowledgments</h1>
<p>First, I would like to thank my advisors, Prof. Dafna Shahaf and Prof. Reut Tsarfaty. Dafna provided sharp and constructive criticism as well as patience and support. Both aspects have been instrumental to my academic growth. I am especially appreciative of her willingness to let me follow my heart on farranging explorations, and the trust she placed in me. She also inspired me with her super-human clarity during 3am paper writing sessions before submission deadlines. Reut opened my mind to the intriguing concept of semantics, and relations between natural and formal languages. She connected me to mainstream NLP and encouraged me to pay attention to up-and-coming pre-trained models while I was pre-occupied with other topics, and this turned out to be fateful advice. She quite literally helped me ground my thinking around grounding in natural language, and I am grateful to her for her support and "yes, and" approach to research. I am very fortunate to have had the guidance of both Dafna and Reut throughout my PhD.</p>
<p>I am grateful for the support of my committee, Dr. Gabriel (Gabi) Stanovsky and Jason Baldridge. Beyond a committee member, Gabi mentored me during my first internship at the Allen Institute for Artificial Intelligence in Seattle. Gabi taught me to appreciate clarity and simplicity and showed me how to apply the KISS principle in my research. He helped me advance my research far beyond where I could take it alone, and connected me with Prof. Alan Ritter and his PhD student Fan Bai at Georgia Tech, who I am also grateful to have collaborated with. Gabi was very generous to me in and out of the lab, and inspired me to try and pay it forward. Jason was a great inspiration to me as I started my PhD journey. Watching his fantastic keynote at the 2019 NeurIPS conference was a formative experience that deeply shaped my research interests. I especially appreciated his inter-disciplinary approach and ability to skillfully integrate linguistics and cognitive science research with complex computational modelling and engineering challenges.</p>
<p>I also want to extend a special thanks to Dr. Kyle Richardson, who was not officially on my PhD committee but very well could have been - he was also a friend and mentor who I met in Seattle and later collaborated with. From Kyle I learned</p>
<p>what it takes to build NLP pipelines at industrial scale and precision, and I would not have been able to develop and run experiments on large pre-trained models without his significant help. Kyle invested significant time in helping me develop my ideas at both the conceptual and empirical level and I benefited greatly from being able to work closely with him.</p>
<p>I feel very fortunate to have worked with a wide group of collaborators at Hebrew University, especially Dr. Tom Hope, Chen Shani and Oren Sultan. Thanks to Prof. Omri Abend for helping me in my first orientation steps in cognitive science and linguistics. Thanks to all of Dafna Shahaf's Hyadata Lab, which was my home away from home. Indeed, during some stretches of my PhD, I spent more time there than at home. Thanks especially to lab-mates Tom, Chen and Moran Mizrahi for their friendship and inspiration.</p>
<p>I was also very fortunate to begin my PhD journey in a summer internship at the RIKEN Institute in Japan, working with Prof. Yuji Matsumoto at the Nara Institute of Technology (NAIST). In Japan I learnt the haiku "distant minds meet, cherries blossom," which describes well my time there and since. Thanks to Prof. Matsumoto for providing me the generous support, peaceful setting and challenging problem which sowed the seeds of inspiration for the rest of my PhD.</p>
<p>My experiments around the Dyna-bAbI benchmark required large-scale engineering and experimentation efforts I would not have been able to undertake alone. Thanks to Noam Kahlon and Aviad Sar Shalom who volunteered time and effort to help me build the Dyna-bAbI data generator. Thanks also to Nelson Liu at Stanford who pitched in to help with running experiments on the new dataset we created.</p>
<p>Thanks to Prof. Judy Fan and her wonderful cogtools lab at the University of California in San Diego (now Stanford). Judy hosted me generously for an exchange program, and I deeply appreciated the opportunity to gain a cognitive science perspective on NLP.</p>
<p>For the last phase of my thesis, I am very grateful to have partnered with William Fischer and Lauren Hebert from Veeo who inspired me to go all in on collective sensemaking. I am also grateful to Matan Field from DAOstack who supported me and connected me with the wonderful, wild world of decentralized collaboration. Special thanks to Daniel Friedman at UC Davis who introduced me</p>
<p>to the mind-expanding concept of stigmergy and who has continued to expand my mind at a regular basis since then. With the closing of my thesis I have gained new appreciation and wonder at the truly collective nature of intelligence, but a side effect is a feeling of frustration with the incompleteness of acknowledgements. We are but individual "neurons" often pitifully unaware of our role in the larger collective network. Thanks to all those many friends, colleagues and collaborators who have been a part of this network and supported me throughout.</p>
<p>A special thanks to my close and extended family who have supported me faithfully through what at times seemed a never-ending journey. To my parents Cathy and Yoav, who reminded me to get out and breathe fresh air once in a while. To my brother Natan, who got me hooked on simulations and multi-agent systems (SimCity, Civilization, etc) somewhere around preschool. Finally, this thesis owes its existence due to my wife and love of my life, Shiran. We met during an internship in Seattle, and my life has changed forever since, and with it my thesis too. I can't imagine either without you.</p>
<p>.</p>
<h1>Abstract</h1>
<p>In recent years, deep learning based approaches to natural language processing (NLP) have made impressive progress. A particularly important achievement has been the development of Large Language Models (LLMs), massive artificial neural networks trained on internet scale linguistic data. LLMs have demonstrated remarkable performance across a wide variety of tasks, including long standing challenges like few-shot learning and coherent long-form text generation.</p>
<p>LLMs seem to be doing more than just "processing" natural language (NLP), perhaps they are also understanding natural language (NLU)? Indeed, a core ongoing debate being fueled by these advances is the Symbol Grounding Problem; computational models of language process only linguistic input (symbols), so how can their outputs be grounded to the external world to which the language refers to? Or in other words, since meaning also includes extra-linguistic referents (actions, percepts, semantic knowledge), can LLMs reliably understand language, i.e., extract the meaning conveyed by linguistic symbols? The debate is far from settled, and has significant implications for guiding the future of NLP research as well as real-world applications; some are claiming LLM research is climbing the wrong hill altogether, some advocate for more cognitively inspired architectures, while others believe that LLMs are early demonstrations of so-called "Artificial General Intelligence".</p>
<p>This PhD thesis proposes a novel environment-oriented perspective on the language grounding debate and towards NLU research more broadly. Our approach is inspired by ecological accounts of cognition, which provide a more holistic account of the role of the body and environment in shaping cognition, in contrast to classical cognitive science which focused on studying brains in isolation. Similarly, we adopt an ecological approach to NLU research. Where current NLU research tends to focus on models in isolation, we developed a more holistic perspective accounting for the deep yet under-explored coupling between models and the environments with which they interact. Wittgenstein famously wrote that "The limits of my language mean the limits of my world". The thesis can be stated simply, in an inversion of that dictum, that "The limits of my environments mean the limits of my language (models)". Environments are the computational spaces in which</p>
<p>models are embedded, which support data annotation as well as model training, development and evaluation. The ecological perspective provides novel insights on each of those critical components of the NLU research pipeline, and also contributes to the broader debate around how to pursue more reliable and grounded natural language understanding systems.</p>
<p>The thesis is divided into three parts. The first part synthesizes research from cognitive science, linguistics, reinforcement learning and NLU to propose a conceptual framework for the idea of ecological natural language understanding. The framework highlights metaphor comprehension, world model learning and mental simulation as core capacities of importance for achieving human-like natural language understanding. The framework makes predictions about the limitations of statistical language models (such as LLMs) with respect to these abilities, and also about the limitations of benchmarks used to evaluate them. Importantly, the ecological NLU approach suggests that many debates about language grounding are hamstrung by the lack of appropriate benchmarks for evaluation of language understanding, both in terms of complexity and rigor. The framework is used to outline an NLU research roadmap for addressing the described limitations.</p>
<p>The second part of the thesis begins advancing on the roadmap described in the first section, applying the theoretical framework towards more practical applications. We developed text-based game environments supporting novel training and annotation methods for procedural text understanding. We found that the more detailed annotations made possible using text based games enabled more faithful modelling of process-level comprehension tasks, compared with existing approaches that addressed mainly sentence-level comprehension. We also used text-based games to construct a new benchmark for measuring the progress of language models on challenging commonsense reasoning tasks. We used the benchmark to identify limitations of state-of-the-art models in tasks requiring compositional generalization, and explored data augmentation strategies to improve models' generalization. Finally, we leveraged the richer supervision provided by text-based game environments to develop Breakpoint Transformers, an extension of the Transformer architecture designed to model intermediate semantic information in long narrative or procedural texts. We applied Breakpoint Transformers on a challenging common-sense reasoning task and achieved significant improvements</p>
<p>over existing approaches, both in terms of accuracy (close to $300 \%$ performance increase in the primary sub-task) as well as architecture generality.</p>
<p>In the third and final part of the thesis, we explored the implications of ecological cognition for the design of online epistemic environments for humans. If indeed environments play such an integral role in human (and machine) cognition, perhaps many of the "epistemic ills" plaguing societies (e.g., polarization, misinformation) today can be traced back to the online social media environments from which humans increasingly acquire their information about the world? What would healthier epistemic environments look like? We integrated Semantic Web research with theories from epistemology and distributed cognition to provide a novel, ecological perspective, on collective intelligence (or lack thereof). We highlighted risks inherent to current centralized social media platforms and proposed a new kind of epistemic environment addressing their limitations, in the form of decentralized, AI-augmented collective intelligence networks.</p>
<h1>Contents</h1>
<p>1 Introduction ..... 1
1.1 Environments: the cognitive, the computional and the meta ..... 3
1.1.1 Environments in ecological cognitive science ..... 3
1.1.2 Environments in cognitive linguistics ..... 4
1.1.3 Environments in reinforcement learning ..... 5
1.1.4 How are environments seen (or not) in AI research? ..... 7
1.2 Ecological Natural Language Understanding ..... 8
1.2.1 Incorporating environments into NLU theory ..... 8
1.2.2 Empirical applications: putting environments into practice ..... 9
1.3 Environments for AI-augmented collective human thinking ..... 12
2 Language (Re)modelling: Towards Embodied Language Under- standing ..... 14
3 Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text ..... 29
4 Process-Level Representation of Scientific Protocols with Inter- active Annotation ..... 40
5 Dyna-bAbI: unlocking bAbI's potential with dynamic synthetic benchmarking ..... 54
6 Breakpoint Transformers for Modeling and Tracking Intermediate Beliefs ..... 77</p>
<p>7 From Users to (Sense)Makers: On the Pivotal Role of Stigmergic Social Annotation in the Quest for Collective Sensemaking ..... 95
8 Discussion and Conclusions ..... 102
A Ecological Semantics: Programming Environments for Situated Language Understanding ..... 114</p>
<p>vi</p>
<h1>Chapter 1</h1>
<h2>Introduction</h2>
<p>"Ask not what's inside your head, but what your head's inside of." W.M. Mace</p>
<p>In recent years, deep learning based approaches to natural language processing (NLP) have made impressive progress. A particularly important achievement has been the development of Large Language Models (LLMs), massive artificial neural networks trained on internet scale linguistic data. LLMs have demonstrated remarkable performance across a wide variety of tasks, including long standing challenges like few-shot learning and coherent dialog and long-form text generation $[1,2,3]$.</p>
<p>The success of LLMs has significant practical and theoretical implications. On the practical side, LLMs are increasingly capable of performing natural language "understanding" (NLU) tasks, beyond merely natural language processing (NLP). We use "understanding" to distinguish between human-like understanding and the more technical usage of the term in computational linguistics ${ }^{1}$; NLP tasks traditionally focus on simpler supporting operations like part-of-speech tagging or entity recognition, whereas NLU tasks involve extracting some form of meaning from an utterance (e.g., mapping a natural language question to a formal database query) [5]. On the theoretical side, LLMs' success has fueled long-standing debates about the nature of linguistic meaning [6], leading many cognitive scientists and linguists to update their theories of language production and understanding.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>These advances also raise pressing questions. For practical NLU applications, despite their impressive performance, LLMs still display a stubborn tendency for commonsense reasoning failures and hallucination of fake facts [7, 8, 9]. As observed by John Oliver, "The problem with AI isn't that it's smart, but that it is dumb in ways we can't predict." ${ }^{2}$ Can we get better at predicting the limitations of LLMs? In what settings can they be safely deployed, and how can their reliability be improved? These more practical questions are in turn informed by more philosophical and theoretical questions: what is linguistic meaning, and how is meaning conveyed by linguistic utterances? To what degree is meaning reducible to statistical patterns in language? What does it mean to understand language, and are machines capable of human-like language understanding? What model architectures might achieve more human-like NLU capabilities?</p>
<p>Our thesis contributes to both the practical and theoretical questions, by introducing a novel, ecological perspective on natural language understanding. Our approach is inspired by ecological accounts of cognition and linguistics. Common to those theories is a more holistic account of the role of the environment in shaping cognition and language, in contrast to classical cognitive science which focused on studying brains in isolation. We observe a similar parallel in NLU research, where most of the focus in mainstream research is on modelling artifical neural networks, and environments fade unnoticed into the background. In our thesis, we ask what happens when we foreground environments, and treat them as "firstclass research citizens" alongside models. In particular, the thesis addresses the following research questions:</p>
<ul>
<li>Chapter 2: how can we account for the role of the environment in a computational framework of natural language understanding?</li>
<li>Chapters 3,4: how can environments inform more realistic training, evaluation and annotation methods in procedural text understanding tasks? How can such environments be created efficiently?</li>
<li>Chapter 5: what are the world modelling capabilities of neural language models, and how can we judge if a world modelling benchmark is effective?</li>
</ul>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<ul>
<li>Chapter 6: how can existing LLM architectures be extended to better incorporate world-modelling capabilities without harming existing performance or compromising on computational efficiency?</li>
<li>Chapter 7: how can networked annotation tools support AI-augmented collective (human) sensemaking environments, as a healthier and more open alternative to centralized social media platforms with opaque data and algorithms?</li>
</ul>
<p>The following sections provide further background on environments to motivate and contextualize these questions: $\S 1.1$ discusses environments in cognitive science, linguistics and reinforcement learning, as well as from a meta-science perspective asking how environments are seen by AI researchers. $\S 1.2$ discusses how the thesis translates those accounts translate into current NLU research, and $\S 1.3$ discusses environments for social learning and sensemaking in humans.</p>
<h1>1.1 Environments: the cognitive, the computional and the meta</h1>
<h3>1.1.1 Environments in ecological cognitive science</h3>
<p>The human brain is perhaps the most complex object in the known universe, and as a result, has been the focus of intense research spanning many disciplines, from philosophy through cognitive science, neuroscience, and increasingly also artificial intelligence. A realization emerging across these fields is that brains and cognition cannot be understood in isolation; "cognition does not occur exclusively inside the head" [10]. Rather, the explanation of many cognitive phenomena (including language) necessitates a more ecological approach accounting for the role of the body and wider environment. ${ }^{3}$ While the simple observation that bodies and environments matter may seem trivial at first glance (brain need bodies as an</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>energy supply), the ways and degree to which they matter often turn out to be surprising, and with radical implications for both theory and methodology.</p>
<h1>Outfielder Problem: an example of ecological cognition in action</h1>
<p>An illustrative example is the "outfielder problem:" [11, 12] how does a baseball outfielder catch a fly ball? A traditional "in-the-head cognition" approach would attempt to solve the problem assuming that all that was available to solve the problem was the brain. It would break the problem into subproblems corresponding to cognitive modules implemented by the brain: a sensor module to detect the ball, an inference module to calculate its trajectory given a physics world model, and an action planner to produce and execute a motor plan to bring the player to the predicted landing site. Such an approach is plausible on the surface, but requires highly accurate measurements that are difficult to estimate in practice. Ecological cognition takes a radically different perspective (which turns out to be an accurate account for how real baseball players solve the problem), and asks what if the body and the environment were part of the solution? In baseball terms: as long as you keep your eye on the ball and move to keep your gaze steady, then the ball will fall into a glove brought in front of your face. The outfielder is leveraging rich and constant feedback from the environment, as well as the ability to act all the while: simply moving so as to make the world appear a certain way now, which leads them to be in the right place later. This example demonstrates how ecological cognition embodies (literally) a very different approach both in terms of theory and methodology; imagine how different a robot outfielder design would look whether informed by ecological or traditional cognitive science.</p>
<h3>1.1.2 Environments in cognitive linguistics</h3>
<p>The field of linguistics has also been deeply impacted by ecological cognitive theories. George Lakoff's work [13, 14, 15], particularly in cognitive linguistics and conceptual metaphor theory, has been instrumental in this transformation. Lakoff argued that language is deeply rooted in our sensory experiences and bodily interactions with the world. His exploration of metaphors, such as "time is money" or "love is a journey," illustrated how abstract concepts are pervasively structured by</p>
<p>our embodied experiences, highlighting the fundamental role of the body and environment in shaping linguistic expressions. These theories ushered in a paradigm shift that has challenged the traditional views advocated by cognitive scientists like Noam Chomsky and Jerry Fodor, who championed more innate and abstract approaches to language that did not account for the role of the environment [16].</p>
<p>Of particular interest in the context of NLU research, environments feature centrally in the symbol grounding problem, a central debate in AI and cognitive science $[17,6]$. The debate seeks to understand how systems processing only symbols, such as words, come to acquire the meaning, or semantics, of those symbols. Ecological theories of cognition contend that language is grounded through its referring to an extra-linguistic world of objects, actions, events and semantic knowledge. The environment thus provides the context and sensory input that allows symbols to become grounded in real-world experiences. These theories raise significant questions for NLU research: computational models of language exposed only to linguistic data have no direct experience of the world, thus it is unclear whether they can reliably connect between linguistic inputs to the world the language refers to. The degree to which environments are necessary is still an open question: theories of indirect grounding [18] suggest that perhaps only some part of language must be grounded directly to sensorimotor experience, while other language can be grounded indirectly through this base.</p>
<h1>1.1.3 Environments in reinforcement learning</h1>
<p>Reinforcement Learning (RL) is one of the branches of AI in which environments play the most prominent role. Indeed, RL is foundational to the sub-field of embodied AI [19], which focuses on developing agents which can solve tasks involving interaction in real (e.g., production line robots) or virtual environments (e.g., a web browsing agent). As such, RL is a natural starting point for a formal computational account of environments. The standard formulation of RL is given by the Partially Observable Markov Decision Process [20], which describes the agent-environment interaction.</p>
<p>As can be seen from Figure 1.1, the computational core of the environment is the transition function, $T$. The transition function represents the world dynamics:</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1.1: Agent-environment interaction dynamics, modelled by a Partially Observable Markov Decision Process (POMDP). Figure based on [21].
how will the world change given a particular action $a_{t}$ in state $s_{t}$. In partially observable environments, agents may not have access to the full world state; the observation function $O$ is the process by which sensory data (the observation the agent has access to) are generated from the world state $s_{t}$. For example, in a 3 D computer game, $s_{t}$ will contain the full scene specification (objects, locations, physical forces, etc) and $o_{t}$ will contain a rendering of those data as a frame of pixels representing the visual field of the agent. Finally, environments may also include a reward function $R$, providing agents with a reward signal $r_{t}$ based on their current action $a_{t}$ and world state $s_{t}$. Agents interact with the environment by means of a policy function, $\pi$, which generates an action $a_{t}$ given the current world state $s_{t}$. In the case of a partially observable environment, the agent must first employ a recognition function $O^{-1}$ to parse the observation $o_{t}$ into recognizable state $s_{t}$. Model-based reinforcement learning approaches employ a world model $\tilde{T}$ that is learned through interaction with $T$ and can be used for mental simulation and planning with mental states $\tilde{s}$ and actions $\tilde{a}$ [21].</p>
<p>Simulators are a classic kind of environment, used extensively in RL research. Simulators include graphical interfaces (e.g., a 3D game engine) or can be purely text-based (discussed at length in Chapters 2,3,4). Beyond simulators, environ-</p>
<p>ments include any interface that exposes an API (Application Programming Interface) that can be used by an agent.</p>
<p>Note that not all environment functions even need to be implemented to support learning algorithms. The next-word prediction training framework of LLMs can also be framed as an environment, where actions and observations correspond to words, and the learner is exposed to a stream of such observations. There is no meaningful interaction in the sense that the next observation is independent of the learner's action (word prediction). Yet, as discussed in Chapter 5, even this impoverished environment can drive powerful learning algorithms given enough parameters and data.</p>
<h1>1.1.4 How are environments seen (or not) in AI research?</h1>
<p>Similar to traditional "in the head" cognitive science discussed in $\S 1.1 .1$, mainstream AI and NLP research are markedly model-centric [22, 23], focusing on topics such as neural architectures, optimization methods and learning algorithms. Interestingly, this focus is not just due to the perceived relative importance of models, but rather has sociological factors as well. Data work, a close relative of environment work, is "de-glamorised and undervalued" [22]; "everyone wants to do the model work, not the data work," despite wide-spread acknowledgement of the critical importance of data work.</p>
<p>Work on environments by AI researchers is additionally complicated by a high engineering overhead, limiting environment development mainly to industrial labs or large-scale academic efforts. Furthermore, from a narrow academic disciplinary lens, environment design falls outside of AI, and is closer to fields such as game design or human-computer interaction (HCI).</p>
<p>Finally, recent years have seen mainstream AI and NLU research drifting apart from other related fields such as cognitive science and neuroscience [24, 25], possibly leading to under-appreciation of certain insights from those fields. For example, in [25], an inter-disciplinary group of AI and neuroscience researchers recently proposed updating the Turing Test (seen in AI as a canonical test of NLU) to an "Embodied Turing Test," to better reflect the importance of embodied interaction within an environment as a measure of intelligence.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ We use ecological cognitive science for brevity to refer to a range of approaches sharing the ecological focus, including ecological psychology, 4E-cognition (embodied, embedded, extended and enactive), grounded cognition and embodied cognitive linguistics. See Chapter 2 and Appendix A for more background.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>