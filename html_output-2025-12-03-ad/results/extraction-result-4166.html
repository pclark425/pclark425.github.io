<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4166 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4166</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4166</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-97.html">extraction-schema-97</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <p><strong>Paper ID:</strong> paper-281464661</p>
                <p><strong>Paper Title:</strong> Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation</p>
                <p><strong>Paper Abstract:</strong> Objective While Large Language Models (LLMs) show great promise for various medical applications, their black-box nature and the difficulty of reproducing results have been noted as significant challenges. In contrast, conventional text mining is a well-established methodology, yet its mastery remains time-consuming. This study aimed to determine if an LLM could achieve literature analysis outcomes comparable to those from traditional text mining, thereby clarifying both its utility and inherent limitations. Methods We analyzed the abstracts of 5,112 medical papers retrieved from PubMed using the single keyword "text mining." We used Google Gemini 2.5 (Google Inc., Mountain View, CA, USA) and instructed it to extract distinctive words, concepts, trends, and co-occurrence network concepts. These results were then qualitatively compared with those obtained from conventional text mining tools, VOSviewer and KH Coder. Results Google Gemini appeared to conceptually aggregate individual words and identify research trends. The concepts for co-occurrence networks also showed visual similarity to the networks generated by the traditional tools. However, the LLMâ€™s analytical output was based on its own unique interpretation and could not be directly compared with the statistically derived co-occurrence patterns. Furthermore, since this study relied on a visual comparison of network diagrams rather than rigorous quantitative analysis, the conclusions remain qualitative. Conclusion Google Gemini indicated an ability to extract keywords, concepts, and trends. A co-occurrence network visually similar to those generated by conventional text mining tools was created. While it showed particular strengths in conceptual summarization and trend detection, its limitations - including its black-box nature, reproducibility challenges, and subjective interpretations - became apparent. With a proper understanding of these constraints, LLMs may serve as a valuable complementary tool, with the potential to accelerate literature analysis in medical research.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4166.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4166.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google Gemini 2.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial large language model used in this study to analyze a corpus of medical abstracts by extracting distinctive words, grouping them into conceptual clusters, identifying research trends, and producing conceptual designs for co-occurrence network diagrams.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Google Gemini 2.5</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A black-box commercial LLM fed with full-text abstract files (5,112 PubMed abstracts). The authors provided two explicit prompts: (1) "Please analyze the attached text file for distinctive words, concepts, and trends," and (2) "Please create a co-occurrence network from the following text file." Gemini produced lists of distinctive words, aggregated them into higher-order conceptual clusters, described prevailing research trends, and proposed a conceptual co-occurrence network which the authors rendered using Mermaid. The pipeline: convert PubMed results to text files -> submit files to Gemini with prompts -> receive conceptual outputs (distinctive words, concepts, trends, network concepts) -> visualize network concepts with Mermaid.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Google Gemini 2.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical / medical literature (text mining literature)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>5,112</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Qualitative patterns and relationships: semantic/conceptual clusters, co-occurrence patterns and research trends (conceptual relationships), not formal quantitative physical/ mathematical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>No explicit quantitative equations were extracted. Examples of relationships reported qualitatively: aggregation of keywords into conceptual clusters (e.g., a 'biomedical literature' subgraph conceptually aligned with gene-related clusters), identification of recurring themes such as 'human', 'machine learning', 'computational biology', and 'natural language processing', and conceptual co-occurrence network linking these themes.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Direct text-input LLM analysis (prompting) on the corpus of abstracts to produce distinctive words, higher-order conceptual clusters, trend descriptions, and a conceptual specification for a co-occurrence network (no programmatic parsing of equations or numeric tables was reported). Outputs were human-interpreted and visualized via Mermaid.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Qualitative, visual comparison of Gemini's conceptual outputs and co-occurrence diagram with statistically derived co-occurrence networks from VOSviewer and KH Coder; no quantitative validation, cross-validation, or empirical testing was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>None reported. The study did not provide numeric performance metrics (accuracy, precision, recall, F1) for Gemini's outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not reported / not applicable (no ground-truth quantitative labels or numeric evaluation provided).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Black-box nature and undisclosed internals of the commercial model; reproducibility difficulties due to model updates and undisclosed training data/parameters; outputs are based on the model's subjective interpretive framework and cannot be directly equated with statistically derived co-occurrence measures; lack of rigorous quantitative comparison; potential information-granularity mismatch; single-model study (no cross-model comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively against VOSviewer and KH Coder co-occurrence and keyword-density outputs; visual thematic alignment observed (e.g., gene/biomedical themes), but no statistical equivalence established.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4166.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4166.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VOSviewer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>VOSviewer (version 1.6.20)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bibliometric mapping and text-mining tool used here to produce keyword density visualizations and statistically derived co-occurrence networks from the same corpus of 5,112 PubMed abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>VOSviewer 1.6.20</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A specialized text-mining/bibliometric visualization tool that constructs keyword-density maps and statistically-derived co-occurrence networks from extracted keywords and full-text abstracts. In this study it generated density visualizations and network graphs showing frequently co-occurring terms and central nodes based on frequency and co-occurrence statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical / bibliometrics / text mining</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>5,112</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Statistical co-occurrence and association patterns (frequency-based relationships, network centrality measures) rather than formal mathematical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Observed dense keyword regions around 'human' and proximate terms 'machine learning', 'computational biology', 'natural language processing'; co-occurrence networks centered around 'gene' indicating strong statistical association in the corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Automated keyword extraction and frequency/co-occurrence counting from the collected documents, followed by visualization of density and network maps using VOSviewer's built-in algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Served as a conventional baseline compared visually against LLM-derived conceptual outputs; no formal numerical cross-validation against Gemini was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>None reported in this paper for VOSviewer outputs (VOSviewer provides visual/statistical maps but the paper did not report numeric evaluation metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not applicable / not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Focuses on statistical co-occurrence and frequency which may miss higher-order semantic relationships; requires expertise to operate and interpret; visual outputs can be information-dense and require parameter choices that affect results.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as a baseline for comparison with Gemini; VOSviewer produced statistically derived networks (e.g., gene-centric networks) that were visually similar in theme to Gemini's conceptual network but methodologically different.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4166.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4166.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KH Coder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KH Coder (version 3.Beta.07f)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source quantitative content analysis and text-mining tool used to analyze abstracts and generate co-occurrence networks and centrality measures; used here as a complementary conventional baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KH Coder 3.Beta.07f</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A quantitative content analysis/text-mining software that extracts word frequencies, co-occurrence networks, and centrality metrics from text corpora. In the study KH Coder analyzed abstracts and constructed a co-occurrence network showing 'gene' as central and placing 'large' and 'language' near that cluster (suggesting LLM relevance).</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical text mining / content analysis</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>5,112</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Statistical co-occurrence networks and centrality relationships (qualitative/quantitative association measures but not formal continuous laws).</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Identification of 'gene' as a central node in the co-occurrence network; proximity of terms 'large' and 'language' in the network indicating association with LLM-related literature.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Automated parsing of abstracts to compute word co-occurrence and centrality statistics, generating network visualizations and association metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Used as a conventional analytic comparator against Gemini's outputs via visual/interpretive comparison; no quantitative agreement metrics or statistical hypothesis tests reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>None reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not applicable / not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Like other co-occurrence tools, may miss semantic nuances and higher-order conceptual groupings that LLMs infer; outcomes depend on preprocessing/tokenization choices; interpretation of centrality requires domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Served as a baseline and comparator to Gemini; KH Coder's statistically-derived centrality (e.g., 'gene') was used to judge thematic alignment with Gemini's conceptual outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Conexion: concept extraction with large language models <em>(Rating: 2)</em></li>
                <li>Automated analyses of risk of bias and critical appraisal of systematic reviews (ROBIS and AMSTAR 2): a comparison of the performance of 4 large language models <em>(Rating: 2)</em></li>
                <li>Automated gene identification in oncology literature: a comparative evaluation of natural language processing approaches <em>(Rating: 2)</em></li>
                <li>Capabilities of Gemini models in medicine <em>(Rating: 2)</em></li>
                <li>Text mining for systems biology <em>(Rating: 1)</em></li>
                <li>KGG: a fully automated workflow for creating disease-specific knowledge graphs <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4166",
    "paper_id": "paper-281464661",
    "extraction_schema_id": "extraction-schema-97",
    "extracted_data": [
        {
            "name_short": "Gemini",
            "name_full": "Google Gemini 2.5",
            "brief_description": "A commercial large language model used in this study to analyze a corpus of medical abstracts by extracting distinctive words, grouping them into conceptual clusters, identifying research trends, and producing conceptual designs for co-occurrence network diagrams.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Google Gemini 2.5",
            "system_description": "A black-box commercial LLM fed with full-text abstract files (5,112 PubMed abstracts). The authors provided two explicit prompts: (1) \"Please analyze the attached text file for distinctive words, concepts, and trends,\" and (2) \"Please create a co-occurrence network from the following text file.\" Gemini produced lists of distinctive words, aggregated them into higher-order conceptual clusters, described prevailing research trends, and proposed a conceptual co-occurrence network which the authors rendered using Mermaid. The pipeline: convert PubMed results to text files -&gt; submit files to Gemini with prompts -&gt; receive conceptual outputs (distinctive words, concepts, trends, network concepts) -&gt; visualize network concepts with Mermaid.",
            "model_name": "Google Gemini 2.5",
            "model_size": null,
            "scientific_domain": "Biomedical / medical literature (text mining literature)",
            "number_of_papers": "5,112",
            "law_type": "Qualitative patterns and relationships: semantic/conceptual clusters, co-occurrence patterns and research trends (conceptual relationships), not formal quantitative physical/ mathematical laws.",
            "law_examples": "No explicit quantitative equations were extracted. Examples of relationships reported qualitatively: aggregation of keywords into conceptual clusters (e.g., a 'biomedical literature' subgraph conceptually aligned with gene-related clusters), identification of recurring themes such as 'human', 'machine learning', 'computational biology', and 'natural language processing', and conceptual co-occurrence network linking these themes.",
            "extraction_method": "Direct text-input LLM analysis (prompting) on the corpus of abstracts to produce distinctive words, higher-order conceptual clusters, trend descriptions, and a conceptual specification for a co-occurrence network (no programmatic parsing of equations or numeric tables was reported). Outputs were human-interpreted and visualized via Mermaid.",
            "validation_approach": "Qualitative, visual comparison of Gemini's conceptual outputs and co-occurrence diagram with statistically derived co-occurrence networks from VOSviewer and KH Coder; no quantitative validation, cross-validation, or empirical testing was performed.",
            "performance_metrics": "None reported. The study did not provide numeric performance metrics (accuracy, precision, recall, F1) for Gemini's outputs.",
            "success_rate": "Not reported / not applicable (no ground-truth quantitative labels or numeric evaluation provided).",
            "challenges_limitations": "Black-box nature and undisclosed internals of the commercial model; reproducibility difficulties due to model updates and undisclosed training data/parameters; outputs are based on the model's subjective interpretive framework and cannot be directly equated with statistically derived co-occurrence measures; lack of rigorous quantitative comparison; potential information-granularity mismatch; single-model study (no cross-model comparison).",
            "comparison_baseline": "Compared qualitatively against VOSviewer and KH Coder co-occurrence and keyword-density outputs; visual thematic alignment observed (e.g., gene/biomedical themes), but no statistical equivalence established.",
            "uuid": "e4166.0",
            "source_info": {
                "paper_title": "Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "VOSviewer",
            "name_full": "VOSviewer (version 1.6.20)",
            "brief_description": "A bibliometric mapping and text-mining tool used here to produce keyword density visualizations and statistically derived co-occurrence networks from the same corpus of 5,112 PubMed abstracts.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "VOSviewer 1.6.20",
            "system_description": "A specialized text-mining/bibliometric visualization tool that constructs keyword-density maps and statistically-derived co-occurrence networks from extracted keywords and full-text abstracts. In this study it generated density visualizations and network graphs showing frequently co-occurring terms and central nodes based on frequency and co-occurrence statistics.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Biomedical / bibliometrics / text mining",
            "number_of_papers": "5,112",
            "law_type": "Statistical co-occurrence and association patterns (frequency-based relationships, network centrality measures) rather than formal mathematical laws.",
            "law_examples": "Observed dense keyword regions around 'human' and proximate terms 'machine learning', 'computational biology', 'natural language processing'; co-occurrence networks centered around 'gene' indicating strong statistical association in the corpus.",
            "extraction_method": "Automated keyword extraction and frequency/co-occurrence counting from the collected documents, followed by visualization of density and network maps using VOSviewer's built-in algorithms.",
            "validation_approach": "Served as a conventional baseline compared visually against LLM-derived conceptual outputs; no formal numerical cross-validation against Gemini was performed.",
            "performance_metrics": "None reported in this paper for VOSviewer outputs (VOSviewer provides visual/statistical maps but the paper did not report numeric evaluation metrics).",
            "success_rate": "Not applicable / not reported.",
            "challenges_limitations": "Focuses on statistical co-occurrence and frequency which may miss higher-order semantic relationships; requires expertise to operate and interpret; visual outputs can be information-dense and require parameter choices that affect results.",
            "comparison_baseline": "Used as a baseline for comparison with Gemini; VOSviewer produced statistically derived networks (e.g., gene-centric networks) that were visually similar in theme to Gemini's conceptual network but methodologically different.",
            "uuid": "e4166.1",
            "source_info": {
                "paper_title": "Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "KH Coder",
            "name_full": "KH Coder (version 3.Beta.07f)",
            "brief_description": "An open-source quantitative content analysis and text-mining tool used to analyze abstracts and generate co-occurrence networks and centrality measures; used here as a complementary conventional baseline.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "KH Coder 3.Beta.07f",
            "system_description": "A quantitative content analysis/text-mining software that extracts word frequencies, co-occurrence networks, and centrality metrics from text corpora. In the study KH Coder analyzed abstracts and constructed a co-occurrence network showing 'gene' as central and placing 'large' and 'language' near that cluster (suggesting LLM relevance).",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Biomedical text mining / content analysis",
            "number_of_papers": "5,112",
            "law_type": "Statistical co-occurrence networks and centrality relationships (qualitative/quantitative association measures but not formal continuous laws).",
            "law_examples": "Identification of 'gene' as a central node in the co-occurrence network; proximity of terms 'large' and 'language' in the network indicating association with LLM-related literature.",
            "extraction_method": "Automated parsing of abstracts to compute word co-occurrence and centrality statistics, generating network visualizations and association metrics.",
            "validation_approach": "Used as a conventional analytic comparator against Gemini's outputs via visual/interpretive comparison; no quantitative agreement metrics or statistical hypothesis tests reported.",
            "performance_metrics": "None reported in this paper.",
            "success_rate": "Not applicable / not reported.",
            "challenges_limitations": "Like other co-occurrence tools, may miss semantic nuances and higher-order conceptual groupings that LLMs infer; outcomes depend on preprocessing/tokenization choices; interpretation of centrality requires domain knowledge.",
            "comparison_baseline": "Served as a baseline and comparator to Gemini; KH Coder's statistically-derived centrality (e.g., 'gene') was used to judge thematic alignment with Gemini's conceptual outputs.",
            "uuid": "e4166.2",
            "source_info": {
                "paper_title": "Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation",
                "publication_date_yy_mm": "2025-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Conexion: concept extraction with large language models",
            "rating": 2,
            "sanitized_title": "conexion_concept_extraction_with_large_language_models"
        },
        {
            "paper_title": "Automated analyses of risk of bias and critical appraisal of systematic reviews (ROBIS and AMSTAR 2): a comparison of the performance of 4 large language models",
            "rating": 2,
            "sanitized_title": "automated_analyses_of_risk_of_bias_and_critical_appraisal_of_systematic_reviews_robis_and_amstar_2_a_comparison_of_the_performance_of_4_large_language_models"
        },
        {
            "paper_title": "Automated gene identification in oncology literature: a comparative evaluation of natural language processing approaches",
            "rating": 2,
            "sanitized_title": "automated_gene_identification_in_oncology_literature_a_comparative_evaluation_of_natural_language_processing_approaches"
        },
        {
            "paper_title": "Capabilities of Gemini models in medicine",
            "rating": 2,
            "sanitized_title": "capabilities_of_gemini_models_in_medicine"
        },
        {
            "paper_title": "Text mining for systems biology",
            "rating": 1,
            "sanitized_title": "text_mining_for_systems_biology"
        },
        {
            "paper_title": "KGG: a fully automated workflow for creating disease-specific knowledge graphs",
            "rating": 1,
            "sanitized_title": "kgg_a_fully_automated_workflow_for_creating_diseasespecific_knowledge_graphs"
        }
    ],
    "cost": 0.009500999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation
09/17/2025</p>
<p>Takahiro Kamihara kamihara@ncgg.go.jp 
Department of Cardiology
National Center for Geriatrics and Gerontology
ObuJPN</p>
<p>Department of Endocrinology and Metabolism
National Center for Geriatrics and Gerontology
ObuJPN</p>
<p>Takuya Omura 
Department of Cardiology
National Center for Geriatrics and Gerontology
ObuJPN</p>
<p>Atsuya Shimizu 
Department of Cardiology
National Center for Geriatrics and Gerontology
ObuJPN</p>
<p>Potential and Limitations of Large Language Models for Medical Literature Analysis: A Preliminary Investigation
09/17/20253413F44F305AA6138057AA11F1B09A5D10.7759/cureus.92590Review ended 09/13/2025OtherMedical EducationHealthcare Technology co-occurrence networklarge language modelmedical literature analysispubmed databasetext mining
ObjectiveWhile Large Language Models (LLMs) show great promise for various medical applications, their black-box nature and the difficulty of reproducing results have been noted as significant challenges.In contrast, conventional text mining is a well-established methodology, yet its mastery remains time-consuming.This study aimed to determine if an LLM could achieve literature analysis outcomes comparable to those from traditional text mining, thereby clarifying both its utility and inherent limitations.MethodsWe analyzed the abstracts of 5,112 medical papers retrieved from PubMed using the single keyword "text mining."We used Google Gemini 2.5 (Google Inc., Mountain View, CA, USA) and instructed it to extract distinctive words, concepts, trends, and co-occurrence network concepts.These results were then qualitatively compared with those obtained from conventional text mining tools, VOSviewer and KH Coder.ResultsGoogle Gemini appeared to conceptually aggregate individual words and identify research trends.The concepts for co-occurrence networks also showed visual similarity to the networks generated by the traditional tools.However, the LLM's analytical output was based on its own unique interpretation and could not be directly compared with the statistically derived co-occurrence patterns.Furthermore, since this study relied on a visual comparison of network diagrams rather than rigorous quantitative analysis, the conclusions remain qualitative.ConclusionGoogle Gemini indicated an ability to extract keywords, concepts, and trends.A co-occurrence network visually similar to those generated by conventional text mining tools was created.While it showed particular strengths in conceptual summarization and trend detection, its limitations -including its black-box nature, reproducibility challenges, and subjective interpretations -became apparent.With a proper understanding of these constraints, LLMs may serve as a valuable complementary tool, with the potential to accelerate literature analysis in medical research.</p>
<p>Introduction</p>
<p>The remarkable progress in Large Language Models (LLMs) in recent years suggests their diverse applicability within the medical domain [1][2][3].These applications encompass, but are not limited to, analyzing patient complaints [4], assessing pre-surgical risks [5], and reviewing extensive medical literature [6].However, alongside this rapid development, the inherent challenges of applying LLMs to rigorous academic analysis in medicine have been noted -particularly their black-box nature and the difficulty of reproducing results.</p>
<p>Conversely, text mining has long been an established methodology for evaluating and extracting information from written content [7][8][9][10].However, mastering text mining is a time-consuming process.Against this background, our study attempted to validate the initially optimistic hypothesis of whether an LLM could be used by a novice to achieve an outcome comparable to that of an expert using traditional text mining.Through this validation, we aimed to clarify the utility of LLMs in literature analysis while also highlighting their inherent limitations.</p>
<p>This study analyzed medical papers on "text mining" using an LLM and compared its findings with those derived from conventional text mining tools.For this validation, we selected biomedical literature containing the term "text mining," indexed in PubMed.</p>
<p>Materials And Methods</p>
<p>This study involved the analysis of publicly available data and was therefore exempt from review by the Ethics and Conflict of Interest Committee of the National Center for Geriatrics and Gerontology.As this study did not involve the direct use of personal data, approval for the use of LLMs, including Google Gemini, was granted by the Director of the Department of Cardiology at the National Center for Geriatrics and Gerontology.In accordance with institutional regulations, an official application was submitted to the Chief Information Security Officer (submission date: December 28, 2023), and approval for continued use was granted through December 27, 2024.</p>
<p>This study was conducted in accordance with the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses: Scoping Review Extension) guidelines to ensure the transparency of our methods.A PubMed search was performed on July 30, 2025, using the single keyword "text mining," yielding 5,112 documents.These documents were subsequently converted into text files, while preserving both the PubMed and Abstract formats for subsequent analysis.All data obtained from this search were included in the analysis, and the correctness of the data extraction was verified by three independent researchers.The extracted items included PMID, publication date, title, DOI, abstract, author names, affiliations, MeSH terms, and keywords.Since all documents were included, we have opted not to present a flowchart; instead, the total number of documents and the search date are explicitly stated within the Materials &amp; Methods section.In accordance with the PRISMA-ScR guidelines, we have also included a discussion on the methodological limitations of our study.</p>
<p>For the LLM analysis, we utilized Google Gemini 2.5 (Google Inc., Mountain View, CA, USA).The stored text files were provided as input to the LLM, which was instructed to analyze the following aspects: (i) identification of distinctive words and conceptual clusters within the corpus, (ii) elucidation of prevailing research trends, and (iii) conceptual design of a co-occurrence network diagram to visually represent word co-occurrence relationships in the literature.The specific prompts provided to the LLM were: "Please analyze the attached text file for distinctive words, concepts, and trends," and "Please create a co-occurrence network from the following text file."</p>
<p>The figure was generated using Mermaid 11.9.0 (MIT-licensed software, Copyright (c) 2020-2023 Knut Sveidqvist, publicly available at https://github.com/knsv/mermaid).This software is provided free of charge and grants permission to anyone who obtains a copy to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software without restriction.These rights also include permission to allow others to whom the software is provided to do the same, without limitation.</p>
<p>In parallel, text mining analyses were conducted using VOSviewer version 1.6.20 [11] and KH Coder version 3.Beta.07f[12].With VOSviewer, keyword density visualization was performed by including all keywords from the 5,112 collected documents and generating a co-occurrence network diagram using the software's Density visualization function.Additionally, VOSviewer was used to construct co-occurrence networks directly from the full abstracts of the documents.KH Coder was similarly employed to analyze the abstracts and generate corresponding co-occurrence networks.</p>
<p>Finally, the analytical results from Google Gemini were systematically compared with those obtained from VOSviewer and KH Coder to identify commonalities and discrepancies, as well as to explore the limitations and unique characteristics of the LLM.</p>
<p>Results</p>
<p>Analysis of the abstracts of 5,112 "text mining"-related documents from PubMed using Google Gemini revealed that the LLM not only extracts individual words, but also effectively groups them into concepts (Distinctive Words and Concepts) and identifies research trends (Figure 1).</p>
<p>FIGURE 1: Conceptual and Trend Analysis of "Text Mining" Literature Using Large Language Model</p>
<p>This figure summarizes the analytical outcomes derived from 5,112 documents retrieved via a PubMed search for "text mining," subsequently converted into PubMed Abstract format text files, and then processed by Google Gemini for Distinctive Words and Concepts and Trends.Google Gemini demonstrated the capability not only to extract individual words but also to aggregate them into coherent concepts and to discern prevailing trends subjectively.</p>
<p>Furthermore, Google Gemini generated concepts for co-occurrence network diagrams, which were subsequently constructed using Mermaid 11.9.0 (Figure 2).</p>
<p>FIGURE 2: Co-occurrence Network Diagram Generated by Large Language Model</p>
<p>This figure was generated using Mermaid 11.9.0 (https://github.com/knsv/mermaid)based on the co-occurrence network diagram concepts formulated by Google Gemini.These concepts were derived from 5,112 documents obtained through a PubMed search for "text mining," which were converted into PubMed Abstract format text files.</p>
<p>Subsequently, VOSviewer was employed to visualize the keyword density of the 5,112 documents.This visualization indicated a frequent focus on "human"-related research, with terms such as "machine learning," "computational biology," and "natural language processing" appearing in close proximity, thereby facilitating the identification of prevailing research trends (Figure 3).</p>
<p>FIGURE 3: Keyword Density Visualization Using Text Mining</p>
<p>This figure presents a density visualization created with VOSviewer [11], utilizing 5,112 documents obtained from a PubMed search for "text mining" and converted into PubMed format text files.All keywords were selected as targets for analysis.The visualization reveals a focus on "human"-related research, with terms such as "machine learning," "computational biology," and "natural language processing" appearing in its vicinity, thereby enabling the identification of research trends.</p>
<p>Following this, VOSviewer was utilized for a comprehensive text analysis, extending beyond mere keywords to generate a co-occurrence network.This analysis demonstrated the formation of a substantial network primarily centered around the term "gene" (Figure 4A).Additionally, KH Coder was applied to analyze the text and construct a co-occurrence network.The word "gene" consistently appeared at the network's core.Moreover, the terms "large" and "language" were positioned in the upper right quadrant, suggesting an association with LLMs (Figure 4B).</p>
<p>FIGURE 4: Comparison of Co-occurrence Networks Generated by Text Mining Tools</p>
<p>A) This figure illustrates a co-occurrence network, constructed by VOSviewer [11] through text analysis of 5,112 documents retrieved from a PubMed search for "text mining" and converted into PubMed Abstract format text files.A prominent network is observed around the term "gene."B) This figure displays a co-occurrence network generated by KH Coder [12] from the analysis of 5,112 documents obtained from a PubMed search for "text mining" and converted into PubMed Abstract format text files.The term "gene" is central to this network.Additionally, "large" and "language" are positioned in the upper-right quadrant, suggesting a connection to Large Language Models.In this figure, words exhibiting higher centrality are represented by darker-colored circles.</p>
<p>The co-occurrence network diagram concepts presented by Google Gemini (Figure 2) showed a certain degree of correspondence with the diagrams generated by VOSviewer and KH Coder (Figures 3, 4A, 4B) when subjectively compared regarding major themes and associations.However, the specific labeling of these concepts by Google Gemini was based on its unique interpretative framework, and its results cannot be strictly compared with the statistically derived co-occurrence patterns provided by traditional text mining tools (Figures 3, 4).</p>
<p>Discussion</p>
<p>This study subjectively compared the results of medical literature analysis conducted by Google Gemini against those obtained from conventional text mining tools VOSviewer and KH Coder, in order to validate its limitations.These tools have been extensively used in numerous studies [13][14][15][16][17].</p>
<p>Google Gemini indicated the capability to not only extract individual words, but also to conceptually aggregate them as "Distinctive Words and Concepts," based on its unique interpretation (Figure 1).This finding suggests the possibility that LLMs possess the ability to infer higher-order semantic relationships -a contrast to traditional text mining tools, which primarily extract patterns based on word co-occurrence and frequency (Figures 3, 4).Furthermore, the ability of an LLM to analyze "Trends" appears to be valuable for rapidly comprehending the overarching direction of research.</p>
<p>Regarding the conceptualization of co-occurrence network diagrams, a visual similarity was observed between the network diagram presented by Google Gemini (Figure 2) and those generated by VOSviewer and KH Coder (Figures 3, 4), concerning central themes and primary associations.However, this congruence was not based on a strict statistical evaluation.For instance, the central role of "gene" in the co-occurrence network diagrams from VOSviewer and KH Coder showed an interpretative alignment with Google Gemini's conceptualization of "biomedical literature" as a subgraph.Similarly, keywords highlighted by VOSviewer, such as "human," "machine learning," and "natural language processing," subjectively aligned with Google Gemini's concept of "text mining research methods and applications."This degree of alignment may indicate that the capabilities of LLMs are approaching those of conventional text mining tools, but the fundamental differences in their analytical methodologies must be considered.These findings are in agreement with prior studies conducted in other disciplines [18].Furthermore, emerging literature in the medical domain suggests that Gemini may be more useful than other tools, supporting the appropriateness of our decision to utilize Gemini in this study [19].</p>
<p>LLMs offer the advantage of articulating analysis results in natural language and summarizing them as concepts, thereby enhancing information accessibility for non-specialists.However, a caveat exists: the labeling of concepts generated by LLMs is rooted in their unique understanding, which can occasionally render the precise interpretation of their meaning challenging when compared to the statistically derived co-occurrence patterns provided by traditional text mining tools (Figure 1).Moreover, given the substantial disparity in information volume between Figure 2 and Figures 3, 4, the ability of LLMs to appropriately modulate information granularity remains a pertinent future challenge.</p>
<p>As a secondary finding, the predominant themes within the "text mining"-related medical papers analyzed in this study, as illustrated by VOSviewer's density visualization (Figure 3), centered on "human"-related research -particularly its integration with technologies such as "machine learning," "computational biology," and "natural language processing."This reflects the current landscape, where text mining is an indispensable tool for analyzing complex human-derived biomedical data, including clinical, genomic, and epidemiological datasets.Furthermore, the central appearance of "gene" in the co-occurrence network diagrams from VOSviewer and KH Coder (Figures 4A, 4B) clearly demonstrates the broad application of text mining in generelated research, such as analyzing gene expression data, identifying gene-disease associations, and genome annotation.This underscores text mining's critical role in bioinformatics.Text mining has indeed been effectively utilized in numerous bioinformatics studies [20][21][22][23].Additionally, the proximity of terms like "large" and "language" to "gene" in the KH Coder diagram suggests that LLMs themselves are gaining traction as research tools used in conjunction with text mining within contemporary medical research, thereby reinforcing the relevance of this study's chosen theme.</p>
<p>Limitations</p>
<p>This study is significant in demonstrating the potential of LLMs to extract critical information from medical text data at a level comparable to -or even more conceptually nuanced than -conventional text mining tools.The natural language processing capabilities of LLMs could potentially accelerate the process by which researchers efficiently locate necessary information within vast literature and uncover novel insights.However, this study is subject to several significant limitations.</p>
<p>Firstly, the LLM employed was exclusively Google Gemini, precluding a performance comparison with other LLM models.Given that LLM performance varies across models [24,25], further comparative studies are requisite for drawing generalized conclusions.Secondly, it remains an open question whether the LLM's presented concept of "biomedical literature" can be strictly linked to bioinformatics, which was represented by the "gene"-centric word clusters extracted via text mining.Thirdly, the "accuracy" of the LLM's analysis results was subjectively compared.This study was not based on rigorous quantitative analysis but on a visual comparison of network diagrams, and thus, the conclusions are purely qualitative.Therefore, the presentation of quantitative results remains a challenge for future research.</p>
<p>Finally, the most critical limitation of this study is that the protocol for generating figures with LLMs is entirely a black box.We used Google Gemini 2.5, a commercial LLM, which represents the most critical constraint of our research.Commercial LLMs are black-box systems with non-disclosed internal workingsincluding training data, model parameters, and frequent updates -which makes scientific reproducibility difficult at present.Specifically, even with the publication of our prompts and analytical procedures, other researchers would find it challenging to replicate the exact same results.Additionally, our search strategy may have included some irrelevant literature.It is crucial to note that this study demonstrates the utility of LLMs as a methodological tool for grasping academic trends, not as a replacement for a rigorous, systematic literature review.At this stage, it is not possible to directly use an LLM to conduct a systematic review.</p>
<p>Conclusions</p>
<p>This study suggested that Google Gemini is capable of extracting key terms, fundamental concepts, and meaningful trends from medical literature.A co-occurrence network, visually similar to those generated by conventional text mining tools, was created.Notably, the LLM exhibited particular strength in conceptual summarization and trend detection, which suggests its potential for higher-order inferential reasoning beyond the statistical associations typically revealed by traditional methods.The LLM's performance in deriving analytical insights from biomedical literature was qualitatively comparable to that of established text mining approaches.However, a key characteristic of LLMs is their tendency to assign labels to terms and concepts based on internal interpretive mechanisms.This contextdependent labeling can sometimes obscure the intended semantic meaning.When this limitation is properly understood and managed, LLMs may significantly accelerate the process of literature analysis in medical research.These findings highlight the potential for LLMs to evolve into valuable tools for a broad range of healthcare professionals, offering enhanced efficiency and depth in textual data interpretation.</p>
<p>Kamihara et al. Cureus 17(9): e92590. DOI 10.7759/cureus.92590
AcknowledgementsAll data generated or analyzed during this study are included in this article.Further inquiries can be directed to the corresponding author.The authors extend their appreciation to the staff who supported this study and, in particular, to Ms. Shihoko Matsuda (National Center for Geriatrics and Gerontology) for her laboratory assistance.We thank Google AI for providing the Google Gemini language models.Gemini was employed to perform the automated translation of terms retrieved by employing text mining.All original text in this manuscript was conceived and written by the authors.AI generated no concepts, theories, or hypotheses.AI tools, including Google Gemini and Grammarly (introduced to the National Center for Geriatrics and Gerontology by the Japan Health Research Promotion Bureau), were used solely for English proofreading, primarily to correct grammatical errors and typos.The authors reviewed and edited the generated text to ensure the original meaning was not altered.EndNote was employed to manage and format the references in this paper.Additional Information Author ContributionsAll authors have reviewed the final version to be published and agreed to be accountable for all aspects of the work.Concept and design: Takahiro KamiharaAcquisition, analysis, or interpretation of data: Takahiro Kamihara, Takuya Omura, Atsuya ShimizuDrafting of the manuscript: Takahiro KamiharaCritical review of the manuscript for important intellectual content: Takahiro Kamihara, Takuya Omura, Atsuya ShimizuDisclosuresHuman subjects: All authors have confirmed that this study did not involve human participants or tissue.Animal subjects: All authors have confirmed that this study did not involve animal subjects or tissue.Conflicts of interest:In compliance with the ICMJE uniform disclosure form, all authors declare the following: Payment/services info: All authors have declared that no financial support was received from any organization for the submitted work.Financial relationships: Takahiro Kamihara declare(s) a grant from JSPS KAKENHI (grant number: 23K19602 and 24K19046).Other relationships: All authors have declared that there are no other relationships or activities that could appear to have influenced the submitted work.
Testing and evaluation of health care applications of large language models: a systematic review. S Bedi, Y Liu, L Orr-Ewing, 10.1001/jama.2024.21700JAMA. 3332025</p>
<p>Large language model applications for health information extraction in oncology: scoping review. D Chen, S A Alnassar, K E Avison, R S Huang, S Raman, 10.2196/65984JMIR Cancer. 112025</p>
<p>Impact of large language model (ChatGPT) in healthcare: an umbrella review and evidence synthesis. U Iqbal, A Tanweer, A R Rahmanti, D Greenfield, L T Lee, Y J Li, 10.1186/s12929-025-01131-zJ Biomed Sci. 322025</p>
<p>Age-related variations in patient concerns: a text-mining analysis of nursing records in catheter ablation cases. T Kamihara, R Itoh, S Kaneko, 10.1111/ggi.70111Geriatr Gerontol Int. 252025</p>
<p>T Kamihara, M Tabuchi, T Omura, 10.1253/circrep.CR-24-0019Evolution of a large language model for preoperative assessment based on the Japanese Circulation Society 2022 Guideline on perioperative cardiovascular assessment and management for non-cardiac surgery. Circ Rep. 20246</p>
<p>Exploratory bibliometric analysis and text mining to reveal research trends in cardiac aging. T Kamihara, K Tanaka, T Omura, S Kaneko, A Hirashiki, M Kokubo, A Shimizu, 10.1002/agm2.12329Aging Med (Milton). 72024</p>
<p>Text mining for systems biology. J Fluck, M Hofmann-Apitius, 10.1016/j.drudis.2013.09.012Drug Discov Today. 192014</p>
<p>Text mining resources for the life sciences. P PrzybyÅ‚a, M Shardlow, S Aubin, 10.1093/database/baw145Database. 2016. 2016</p>
<p>Integrating text mining into the curation of disease maps. M Voskamp, L Vinhoven, F Stanke, S Hafkemeyer, M M Nietert, 10.3390/biom12091278Biomolecules. 122022</p>
<p>Text mining for drug discovery. S Zheng, S Dharssi, M Wu, J Li, Z Lu, 10.1007/978-1-4939-9089-4_13Methods Mol Biol. 2019</p>
<p>Software survey: VOSviewer, a computer program for bibliometric mapping. N J Van Eck, L Waltman, 10.1007/s11192-009-0146-3Scientometrics. 842010</p>
<p>A two-step approach to quantitative content analysis: KH Coder tutorial using Anne of Green Gables (Part I). K Higuchi, Ritsum Soc Sci Rev. 522016</p>
<p>Mapping research trends in traditional Chinese medicine exercises for anxiety intervention using a knowledge approach. B Cai, M Li, Y Wei, Z Su, 10.2147/JMDH.S533223J Multidiscip Healthc. 182025</p>
<p>Cluster analysis of hotspots and research trends of epirubicin-induced cardiotoxicity: a bibliometric study. D He, W Wang, X Luo, Y Wang, 10.3389/fphar.2025.1616162Front Pharmacol. 2025</p>
<p>Mapping the landscape of epigenetic research in diabetes mellitus: a decadelong bibliometric analysis. Y Tang, H Zhu, L Liu, 10.2174/0115733998389913250807044815Curr Diabetes Rev. 2014-2024. 2025</p>
<p>Analyzing the ecologicality and functionality of kiln architecture in China through KH Coder data mining algorithm and hierarchical event coding. Sci Rep. R Liu, X Wang, L Yuan, Y Gao, Y Zhang, M Yang, W Li, 10.1038/s41598-025-97659-z2025</p>
<p>Nurses' perceptions of clinical education for nursing students in Japan during the COVID-19 pandemic: a cross-sectional study. R Soeda, H Kumai, A Suzuka, 10.7759/cureus.78658Cureus. 172025</p>
<p>Conexion: concept extraction with large language models. E Norouzi, S Hertling, H Sack, 10.48550/arXiv.2504.12915</p>
<p>Capabilities of Gemini models in medicine. K Saab, T Tu, W H Weng, 10.48550/arXiv.2404.18416</p>
<p>Deciphering the relationship between sarcopenia and aging: a combined text mining and bioinformatics approach. T Kamihara, T Omura, A Shimizu, 10.1111/ggi.70042Geriatr Gerontol Int. 252025</p>
<p>KGG: a fully automated workflow for creating disease-specific knowledge graphs. R Karki, Y Gadiya, A Zaliani, 10.1093/bioinformatics/btaf383Bioinformatics. 2025</p>
<p>Low-dose methotrexate as a potential treatment for schizophrenia via astrocytic and neuroimmune modulation. T S Lima, F Corsi-Zuelli, A J Souza, 10.1016/j.schres.2025.07.022Schizophr Res. 2842025</p>
<p>Automated gene identification in oncology literature: a comparative evaluation of natural language processing approaches. Stud Health Technol Inform. M Wosny, J Hastings, 10.3233/SHTI2506732025328</p>
<p>Artificial intelligence in radiology examinations: a psychometric comparison of question generation methods. E Emekli, B N Karahan, 10.4274/dir.2025.253407Diagn Interv Radiol. 2025. 2025</p>
<p>Automated analyses of risk of bias and critical appraisal of systematic reviews (ROBIS and AMSTAR 2): a comparison of the performance of 4 large language models. D A Forero, S E Abreu, B E Tovar, M H Oermann, 10.1093/jamia/ocaf117J Am Med Inform Assoc. 322025</p>
<p>. Kamihara, e92590.DOI10.7759/cureus.925907of7Cureus. 179</p>            </div>
        </div>

    </div>
</body>
</html>