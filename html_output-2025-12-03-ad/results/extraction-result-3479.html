<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3479 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3479</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3479</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-255897921</p>
                <p><strong>Paper Title:</strong> Grounding Mental Representations in a Virtual Multi-Level Functional Framework</p>
                <p><strong>Paper Abstract:</strong> According to the associative theory of learning, reactive behaviors described by stimulus-response pairs result in the progressive wiring of a plastic brain. In contrast, flexible behaviors are supposedly driven by neurologically grounded mental states that involve computations on informational contents. These theories appear complementary, but are generally opposed to each other. The former is favored by neuro-scientists who explore the low-level biological processes supporting cognition, and the later by cognitive psychologists who look for higher-level structures. This situation can be clarified through an analysis that independently defines abstract neurological and informational functionalities, and then relate them through a virtual interface. This framework is validated through a modeling of the first stage of Piaget’s cognitive development theory, whose reported end experiments demonstrate the emergence of mental representations of object displacements. The neural correlates grounding this emergence are given in the isomorphic format of an associative memory. As a child’s exploration of the world progresses, his mental models will eventually include representations of space, time and causality. Only then epistemological concepts, such as beliefs, will give rise to higher level mental representations in a possibly richer propositional format. This raises the question of which additional neurological functionalities, if any, would be required in order to include these extensions into a comprehensive grounded model. We relay previously expressed views, which in summary hypothesize that the ability to learn has evolved from associative reflexes and memories, to suggest that the functionality of associative memories could well provide the sufficient means for grounding cognitive capacities.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3479.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3479.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VMF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Virtual Multi-Level Functional Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional, multi-level account that treats cognition as layered programs interpreted by virtual neurological microcircuits, allowing symbolic (functional) models of representations to be grounded in abstracted neural protocols without requiring low-level physiological details.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Virtual Multi-Level Functional Framework</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge and cognitive processes are encoded as symbolic programs (models) compiled into an intermediate virtual code that is interpreted by a virtual neurological layer (microcircuits/threads). Representational contents get their operational semantics from the transitions they induce on the virtual machine state; low-level biophysics are abstracted away but remain the ultimate substrate.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Implemented in this paper and validated by simulations reproducing Piagetian sensory-motor substages (grasping, tracking, A-not-B, partially and fully invisible displacement). The framework leverages established neurophysiological mechanisms (LTP/LTD, engram literature) as conceptual correlates and shows behavioral-level patterns compatible with developmental observations.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Abstraction omits many low-level neuronal details (continuous dynamics, precise ionic/circuit mechanisms); critics argue such abstraction risks missing crucial algorithmic/circuit-level constraints and may not uniquely map to biological implementations. Also empirical neural data remain complex and not fully matched to the abstracted virtual protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Positioned as a middle-out approach: contrasts with top-down symbolic architectures (which neglect neural grounding) and with bottom-up detailed neural simulations (which often do not connect to cognitive-level constructs); explicitly draws on Marr's levels and implements Newen & Vosgerau's functionalist signature within a virtual-machine metaphor.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to map virtual-machine primitives onto specific biological circuits at scale; whether the abstracted associative mechanisms suffice to ground higher-level propositional contents (beliefs); empirical tests linking microcircuit implementations to measured neural activity remain to be specified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3479.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VM-Formalism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Virtual Neurological / Virtual Machine Formalism</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A concrete formalism used in the paper implementing threads, asynchronous communication protocols, and virtual-machine instructions to model synaptic plasticity and associative operations as interpretable microcircuit computations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Virtual Machine Formalism for Neural Microcircuits</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Neural assemblies are modeled as 'threads' that communicate asynchronously; plasticity and memory operations are captured as protocol primitives (e.g., LTP/LTD threads, LTS/LTR storage and retrieval), and cognitive models compile to implications that the virtual machine uses to perform contextual deductions (sense-react cycles).</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Used to implement and run the Piagetian task simulations (execution traces provided) reproducing characteristic behavioral outcomes (A-not-B error, correct sequential tracking, invisible displacement). The primitive operations are mapped to well-known physiological phenomena (Hebbian LTP/LTD, memory engram data).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Simplifying assumptions (threads as neuron clusters, integer weights, discrete event-driven synchronizations) depart from continuous spiking/dendritic dynamics and detailed synaptic biophysics; may fail to capture temporal precision or graded responses observed empirically.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with continuous neural network and dynamical systems models (e.g., analytic neuron simulations, dynamic field theory), and presented as complementary to symbolic cognitive architectures by providing a meso-level interpreter that links symbolic descriptions to neural-like protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Biological plausibility of specific protocols (e.g., LTR semantics) needs empirical validation; scalability to richer cognitive domains and how virtual instructions map to measured neural signatures (e.g., LFPs, single-unit patterns) are open issues.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3479.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AssociativeMemory-LTS/LTR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Associative Memory implemented via LTS (long-term storage) and LTR (long-term retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An explicit, functional associative-memory mechanism in the virtual formalism that stores traces and enables retrieval across separated threads/streams, used to model memory engrams and to support representational behavior in simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Associative Memory (LTS/LTR engram-style)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Memory traces {P} created by LTS operations link previously separated thread patterns; LTR threads fired by other patterns wait for stored paths from {P} to relate cues to recall actions. Representational format is essentially isomorphic/associative: stored internal images serve as stand-ins that can evoke actions when appropriate cues occur.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Used to implement the transition to Piaget substage 6 (invisible displacement) where an internal image {image(F(I)(X))} drives action; aligned with empirical engram literature (Liu et al. 2012, Ryan et al. 2015, Tonegawa 2015) demonstrating storage/retrieval mechanisms and optogenetic reactivation of engrams.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Piaget-related empirical controversies (e.g., Baillargeon's violation-of-expectation results and alternative dynamic-field explanations) raise alternative accounts that do not require associative images; engram biology is complex and involves multiple interacting mechanisms beyond simple associative protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as a neurally plausible basis for early (perceptual/isomorphic) mental representations and contrasted with propositional/symbolic representations; argued to be potentially sufficient as an evolutionary 'associative cassette' that could support more complex cognition depending on circuit embedding.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Whether associative engram mechanisms alone can support propositional, structured content (e.g., beliefs) remains unresolved; the minimal additional neural primitives required for richer representational formats are not identified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3479.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NewenVosgerau-FW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Newen & Vosgerau functionalist framework (Situated Mental Representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functionalist account that defines behaviors as mappings from stimulus/state to state/response pairs and treats mental representations as substitutes for arguments within templates, with a three-part description including vehicle, content (functional role), and fine-grained structure (correlational/isomorphic/propositional).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Situated Mental Representations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Newen & Vosgerau functionalist framework</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Representations are functionally defined by the roles they play in organismal behavior: they act as placeholders/substitutes in cognitive templates; their coarse-grained content is determined by that functional role, while fine-grained structure can be correlational, isomorphic/perceptual, or propositional.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Provides the formal signature and conceptual scaffolding implemented by the paper's virtual machine (run: I × L → L × O; sense-react cycles) and aligns with observed developmental behaviors the simulations reproduce. The framework is influential and maps cleanly to the program/virtual-machine metaphor.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Framework requires further specification of neural vehicles and fine-grained structure to be fully grounded; deflationary critiques (Egan) challenge whether such functionally ascribed contents are naturalistically determinate without additional grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with deflationary accounts and with purely symbolic/top-down approaches; the paper implements Newen & Vosgerau's ideas in an instantiated virtual microcircuit model to provide the missing grounding they call for.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to specify fine-grained neural correlates of propositional contents; how functionally defined contents relate consistently to variable biological instantiations across contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3479.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IsomorphicFormat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Isomorphic (perceptual) representational format</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where internal models are partially isomorphic to the perceived world and contain primarily perceptual relations; argued to characterize early infant mental models in Piagetian development.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Perceptual Nature of Mental Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Isomorphic (Perceptual) Representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts/representations are structured as internal images or models that are structurally (partially) isomorphic to the external perceptual phenomena they represent, supporting stimulus-free behavior by evoking actions from stored perceptual relations.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Paper's simulations reproduce Piagetian transitions where stored perceptual images ({image(F(I)(X))}) drive actions (substage 6); empirical support cited (Ramsay & Campos 1978) where infants express surprise to changed objects, consistent with perceptual image-like representations.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Alternative empirical interpretations (Baillargeon's violation-of-expectation findings and dynamic-field accounts) suggest some early competencies may not require internal isomorphic representations; the isomorphic account is limited to perceptual relations and may not scale to abstract content.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Treated as an early/developmental representational format contrasted with later propositional representations; presented as compatible with associative memory mechanisms but distinct from purely symbolic propositional formats.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Doesn't by itself explain representation of abstract relations, causality or propositional attitudes; the paper leaves open how isomorphic representations transform into richer propositional formats.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3479.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PropositionalFormat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Propositional representational format (beliefs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A higher-level representational format postulated for epistemic states like beliefs, where mental contents have propositional structure (e.g., declarative sentences) rather than purely perceptual/isomorphic form.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Situated Mental Representations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Propositional Representation (belief format)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is encoded as structured propositions (relations among predicates and arguments) that can support complex inferential operations and epistemic attitudes such as belief, beyond the scope of simple associative/isomorphic images.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>The paper argues this format plausibly emerges later in development after representations of space/time/causality and is consistent with philosophical-functional accounts (Newen & Vosgerau). No direct simulation in this work; argued as theoretically motivated.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>No concrete neurological grounding provided here; authors note skepticism that unique low-level neural mechanisms support propositional content (Heyes 2012) and emphasize the open empirical question of what additional neural functionalities would be required.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with isomorphic/perceptual formats and associative implementations; the paper frames propositional representations as richer and likely requiring additional or distinct neural mechanisms beyond associative engrams.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Which neural operations/mechanisms (if any) are necessary and sufficient to realize propositional content remains unspecified; how to bridge associative meso-level mechanisms to structured propositional forms is an open problem.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3479.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeflationaryAccount</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deflationary account of mental representations (Egan)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A philosophical-functional view denying that mental representations possess intrinsic, naturalistically determinate content; contents are taken to be projections from neural structures to behavior rather than inherent semantic properties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A deflationary account of mental representations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Deflationary Account of Mental Representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Mental 'representations' are not bearers of robust, intrinsic semantic content; instead, what counts as content is pragmatically or functionally defined by the mapping from neural states to behavior, resisting claims of naturalistic determinacy.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Philosophical and conceptual arguments cited; provides an account that avoids positing determinate semantics requiring neural grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Paper argues deflationary views leave open the causal/naturalistic grounding of cognitive computations and that a multi-level formalism (virtual machine approach) can clarify and supply such grounding; empirical findings (e.g., engrams, LTP mechanisms) suggest concrete neural processes that carry content-like roles.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Set against functionalist frameworks (Newen & Vosgerau) and representational realism (Ramsey), with the paper advocating that a layered functional account can reconcile criticisms leveled by deflationists.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Whether deflationary accounts can accommodate complex cognitive phenomena without additional grounding remains contested; how functional projections pick out stable contents across contexts is unresolved.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3479.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3479.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MarrTriLevel</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Marr's tri-level hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A foundational framework proposing three complementary levels of analysis for cognition: computational (what/why), algorithmic (how), and implementational (physical substrate).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Vision: A Computational Approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Marr's tri-level hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Cognitive systems should be analyzed at (1) the computational level specifying the problem, (2) the algorithmic level specifying representations and procedures, and (3) the implementational level specifying physical realization; useful for structuring grounding efforts across levels.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Invoked as methodological guidance: the paper uses Marr's insight to motivate a middle-out virtual-machine interface linking algorithmic/functional descriptions to abstract neural implementations; widely accepted in cognitive science.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Authors and cited commentators note difficulty in mapping algorithms to concrete neural circuits (Frégnac), and that large-scale neural data alone do not yield the necessary algorithmic explanations ("big data is not knowledge").</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Marr's framework is used to justify the virtual machine/multi-level approach as bridging computational/algorithmic and implementational descriptions, contrasted with purely top-down or bottom-up accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Identifying canonical meso-level operations and specific algorithm-to-circuit mappings remains a core challenge; Marr's levels do not by themselves explain how to derive neural circuits from algorithmic descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding Mental Representations in a Virtual Multi-Level Functional Framework', 'publication_date_yy_mm': '2023-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Situated Mental Representations <em>(Rating: 2)</em></li>
                <li>The Perceptual Nature of Mental Models <em>(Rating: 2)</em></li>
                <li>A deflationary account of mental representations <em>(Rating: 2)</em></li>
                <li>Memory engram storage and retrieval <em>(Rating: 2)</em></li>
                <li>Optogenetic stimulation of a hippocampal engram activates fear memory recall <em>(Rating: 2)</em></li>
                <li>Vision: A Computational Approach <em>(Rating: 2)</em></li>
                <li>La construction du réél chez l'enfant <em>(Rating: 2)</em></li>
                <li>Simple minds: a qualified defence of associative learning <em>(Rating: 1)</em></li>
                <li>The Perceptual Nature of Mental Models <em>(Rating: 1)</em></li>
                <li>The physical basis of memory <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3479",
    "paper_id": "paper-255897921",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "VMF",
            "name_full": "Virtual Multi-Level Functional Framework",
            "brief_description": "A functional, multi-level account that treats cognition as layered programs interpreted by virtual neurological microcircuits, allowing symbolic (functional) models of representations to be grounded in abstracted neural protocols without requiring low-level physiological details.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Virtual Multi-Level Functional Framework",
            "theory_description": "Conceptual knowledge and cognitive processes are encoded as symbolic programs (models) compiled into an intermediate virtual code that is interpreted by a virtual neurological layer (microcircuits/threads). Representational contents get their operational semantics from the transitions they induce on the virtual machine state; low-level biophysics are abstracted away but remain the ultimate substrate.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Implemented in this paper and validated by simulations reproducing Piagetian sensory-motor substages (grasping, tracking, A-not-B, partially and fully invisible displacement). The framework leverages established neurophysiological mechanisms (LTP/LTD, engram literature) as conceptual correlates and shows behavioral-level patterns compatible with developmental observations.",
            "counter_evidence_or_challenges": "Abstraction omits many low-level neuronal details (continuous dynamics, precise ionic/circuit mechanisms); critics argue such abstraction risks missing crucial algorithmic/circuit-level constraints and may not uniquely map to biological implementations. Also empirical neural data remain complex and not fully matched to the abstracted virtual protocols.",
            "comparison_to_other_theories": "Positioned as a middle-out approach: contrasts with top-down symbolic architectures (which neglect neural grounding) and with bottom-up detailed neural simulations (which often do not connect to cognitive-level constructs); explicitly draws on Marr's levels and implements Newen & Vosgerau's functionalist signature within a virtual-machine metaphor.",
            "notable_limitations_or_open_questions": "How to map virtual-machine primitives onto specific biological circuits at scale; whether the abstracted associative mechanisms suffice to ground higher-level propositional contents (beliefs); empirical tests linking microcircuit implementations to measured neural activity remain to be specified.",
            "uuid": "e3479.0",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "VM-Formalism",
            "name_full": "Virtual Neurological / Virtual Machine Formalism",
            "brief_description": "A concrete formalism used in the paper implementing threads, asynchronous communication protocols, and virtual-machine instructions to model synaptic plasticity and associative operations as interpretable microcircuit computations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Virtual Machine Formalism for Neural Microcircuits",
            "theory_description": "Neural assemblies are modeled as 'threads' that communicate asynchronously; plasticity and memory operations are captured as protocol primitives (e.g., LTP/LTD threads, LTS/LTR storage and retrieval), and cognitive models compile to implications that the virtual machine uses to perform contextual deductions (sense-react cycles).",
            "level_of_analysis": "functional",
            "supporting_evidence": "Used to implement and run the Piagetian task simulations (execution traces provided) reproducing characteristic behavioral outcomes (A-not-B error, correct sequential tracking, invisible displacement). The primitive operations are mapped to well-known physiological phenomena (Hebbian LTP/LTD, memory engram data).",
            "counter_evidence_or_challenges": "Simplifying assumptions (threads as neuron clusters, integer weights, discrete event-driven synchronizations) depart from continuous spiking/dendritic dynamics and detailed synaptic biophysics; may fail to capture temporal precision or graded responses observed empirically.",
            "comparison_to_other_theories": "Contrasted with continuous neural network and dynamical systems models (e.g., analytic neuron simulations, dynamic field theory), and presented as complementary to symbolic cognitive architectures by providing a meso-level interpreter that links symbolic descriptions to neural-like protocols.",
            "notable_limitations_or_open_questions": "Biological plausibility of specific protocols (e.g., LTR semantics) needs empirical validation; scalability to richer cognitive domains and how virtual instructions map to measured neural signatures (e.g., LFPs, single-unit patterns) are open issues.",
            "uuid": "e3479.1",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "AssociativeMemory-LTS/LTR",
            "name_full": "Associative Memory implemented via LTS (long-term storage) and LTR (long-term retrieval)",
            "brief_description": "An explicit, functional associative-memory mechanism in the virtual formalism that stores traces and enables retrieval across separated threads/streams, used to model memory engrams and to support representational behavior in simulations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Associative Memory (LTS/LTR engram-style)",
            "theory_description": "Memory traces {P} created by LTS operations link previously separated thread patterns; LTR threads fired by other patterns wait for stored paths from {P} to relate cues to recall actions. Representational format is essentially isomorphic/associative: stored internal images serve as stand-ins that can evoke actions when appropriate cues occur.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Used to implement the transition to Piaget substage 6 (invisible displacement) where an internal image {image(F(I)(X))} drives action; aligned with empirical engram literature (Liu et al. 2012, Ryan et al. 2015, Tonegawa 2015) demonstrating storage/retrieval mechanisms and optogenetic reactivation of engrams.",
            "counter_evidence_or_challenges": "Piaget-related empirical controversies (e.g., Baillargeon's violation-of-expectation results and alternative dynamic-field explanations) raise alternative accounts that do not require associative images; engram biology is complex and involves multiple interacting mechanisms beyond simple associative protocols.",
            "comparison_to_other_theories": "Presented as a neurally plausible basis for early (perceptual/isomorphic) mental representations and contrasted with propositional/symbolic representations; argued to be potentially sufficient as an evolutionary 'associative cassette' that could support more complex cognition depending on circuit embedding.",
            "notable_limitations_or_open_questions": "Whether associative engram mechanisms alone can support propositional, structured content (e.g., beliefs) remains unresolved; the minimal additional neural primitives required for richer representational formats are not identified.",
            "uuid": "e3479.2",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "NewenVosgerau-FW",
            "name_full": "Newen & Vosgerau functionalist framework (Situated Mental Representations)",
            "brief_description": "A functionalist account that defines behaviors as mappings from stimulus/state to state/response pairs and treats mental representations as substitutes for arguments within templates, with a three-part description including vehicle, content (functional role), and fine-grained structure (correlational/isomorphic/propositional).",
            "citation_title": "Situated Mental Representations",
            "mention_or_use": "use",
            "theory_name": "Newen & Vosgerau functionalist framework",
            "theory_description": "Representations are functionally defined by the roles they play in organismal behavior: they act as placeholders/substitutes in cognitive templates; their coarse-grained content is determined by that functional role, while fine-grained structure can be correlational, isomorphic/perceptual, or propositional.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Provides the formal signature and conceptual scaffolding implemented by the paper's virtual machine (run: I × L → L × O; sense-react cycles) and aligns with observed developmental behaviors the simulations reproduce. The framework is influential and maps cleanly to the program/virtual-machine metaphor.",
            "counter_evidence_or_challenges": "Framework requires further specification of neural vehicles and fine-grained structure to be fully grounded; deflationary critiques (Egan) challenge whether such functionally ascribed contents are naturalistically determinate without additional grounding.",
            "comparison_to_other_theories": "Contrasted with deflationary accounts and with purely symbolic/top-down approaches; the paper implements Newen & Vosgerau's ideas in an instantiated virtual microcircuit model to provide the missing grounding they call for.",
            "notable_limitations_or_open_questions": "How to specify fine-grained neural correlates of propositional contents; how functionally defined contents relate consistently to variable biological instantiations across contexts.",
            "uuid": "e3479.3",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "IsomorphicFormat",
            "name_full": "Isomorphic (perceptual) representational format",
            "brief_description": "A representational format where internal models are partially isomorphic to the perceived world and contain primarily perceptual relations; argued to characterize early infant mental models in Piagetian development.",
            "citation_title": "The Perceptual Nature of Mental Models",
            "mention_or_use": "use",
            "theory_name": "Isomorphic (Perceptual) Representation",
            "theory_description": "Concepts/representations are structured as internal images or models that are structurally (partially) isomorphic to the external perceptual phenomena they represent, supporting stimulus-free behavior by evoking actions from stored perceptual relations.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Paper's simulations reproduce Piagetian transitions where stored perceptual images ({image(F(I)(X))}) drive actions (substage 6); empirical support cited (Ramsay & Campos 1978) where infants express surprise to changed objects, consistent with perceptual image-like representations.",
            "counter_evidence_or_challenges": "Alternative empirical interpretations (Baillargeon's violation-of-expectation findings and dynamic-field accounts) suggest some early competencies may not require internal isomorphic representations; the isomorphic account is limited to perceptual relations and may not scale to abstract content.",
            "comparison_to_other_theories": "Treated as an early/developmental representational format contrasted with later propositional representations; presented as compatible with associative memory mechanisms but distinct from purely symbolic propositional formats.",
            "notable_limitations_or_open_questions": "Doesn't by itself explain representation of abstract relations, causality or propositional attitudes; the paper leaves open how isomorphic representations transform into richer propositional formats.",
            "uuid": "e3479.4",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "PropositionalFormat",
            "name_full": "Propositional representational format (beliefs)",
            "brief_description": "A higher-level representational format postulated for epistemic states like beliefs, where mental contents have propositional structure (e.g., declarative sentences) rather than purely perceptual/isomorphic form.",
            "citation_title": "Situated Mental Representations",
            "mention_or_use": "mention",
            "theory_name": "Propositional Representation (belief format)",
            "theory_description": "Conceptual knowledge is encoded as structured propositions (relations among predicates and arguments) that can support complex inferential operations and epistemic attitudes such as belief, beyond the scope of simple associative/isomorphic images.",
            "level_of_analysis": "functional",
            "supporting_evidence": "The paper argues this format plausibly emerges later in development after representations of space/time/causality and is consistent with philosophical-functional accounts (Newen & Vosgerau). No direct simulation in this work; argued as theoretically motivated.",
            "counter_evidence_or_challenges": "No concrete neurological grounding provided here; authors note skepticism that unique low-level neural mechanisms support propositional content (Heyes 2012) and emphasize the open empirical question of what additional neural functionalities would be required.",
            "comparison_to_other_theories": "Contrasted with isomorphic/perceptual formats and associative implementations; the paper frames propositional representations as richer and likely requiring additional or distinct neural mechanisms beyond associative engrams.",
            "notable_limitations_or_open_questions": "Which neural operations/mechanisms (if any) are necessary and sufficient to realize propositional content remains unspecified; how to bridge associative meso-level mechanisms to structured propositional forms is an open problem.",
            "uuid": "e3479.5",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "DeflationaryAccount",
            "name_full": "Deflationary account of mental representations (Egan)",
            "brief_description": "A philosophical-functional view denying that mental representations possess intrinsic, naturalistically determinate content; contents are taken to be projections from neural structures to behavior rather than inherent semantic properties.",
            "citation_title": "A deflationary account of mental representations",
            "mention_or_use": "mention",
            "theory_name": "Deflationary Account of Mental Representations",
            "theory_description": "Mental 'representations' are not bearers of robust, intrinsic semantic content; instead, what counts as content is pragmatically or functionally defined by the mapping from neural states to behavior, resisting claims of naturalistic determinacy.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Philosophical and conceptual arguments cited; provides an account that avoids positing determinate semantics requiring neural grounding.",
            "counter_evidence_or_challenges": "Paper argues deflationary views leave open the causal/naturalistic grounding of cognitive computations and that a multi-level formalism (virtual machine approach) can clarify and supply such grounding; empirical findings (e.g., engrams, LTP mechanisms) suggest concrete neural processes that carry content-like roles.",
            "comparison_to_other_theories": "Set against functionalist frameworks (Newen & Vosgerau) and representational realism (Ramsey), with the paper advocating that a layered functional account can reconcile criticisms leveled by deflationists.",
            "notable_limitations_or_open_questions": "Whether deflationary accounts can accommodate complex cognitive phenomena without additional grounding remains contested; how functional projections pick out stable contents across contexts is unresolved.",
            "uuid": "e3479.6",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        },
        {
            "name_short": "MarrTriLevel",
            "name_full": "Marr's tri-level hypothesis",
            "brief_description": "A foundational framework proposing three complementary levels of analysis for cognition: computational (what/why), algorithmic (how), and implementational (physical substrate).",
            "citation_title": "Vision: A Computational Approach",
            "mention_or_use": "mention",
            "theory_name": "Marr's tri-level hypothesis",
            "theory_description": "Cognitive systems should be analyzed at (1) the computational level specifying the problem, (2) the algorithmic level specifying representations and procedures, and (3) the implementational level specifying physical realization; useful for structuring grounding efforts across levels.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Invoked as methodological guidance: the paper uses Marr's insight to motivate a middle-out virtual-machine interface linking algorithmic/functional descriptions to abstract neural implementations; widely accepted in cognitive science.",
            "counter_evidence_or_challenges": "Authors and cited commentators note difficulty in mapping algorithms to concrete neural circuits (Frégnac), and that large-scale neural data alone do not yield the necessary algorithmic explanations (\"big data is not knowledge\").",
            "comparison_to_other_theories": "Marr's framework is used to justify the virtual machine/multi-level approach as bridging computational/algorithmic and implementational descriptions, contrasted with purely top-down or bottom-up accounts.",
            "notable_limitations_or_open_questions": "Identifying canonical meso-level operations and specific algorithm-to-circuit mappings remains a core challenge; Marr's levels do not by themselves explain how to derive neural circuits from algorithmic descriptions.",
            "uuid": "e3479.7",
            "source_info": {
                "paper_title": "Grounding Mental Representations in a Virtual Multi-Level Functional Framework",
                "publication_date_yy_mm": "2023-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Situated Mental Representations",
            "rating": 2,
            "sanitized_title": "situated_mental_representations"
        },
        {
            "paper_title": "The Perceptual Nature of Mental Models",
            "rating": 2,
            "sanitized_title": "the_perceptual_nature_of_mental_models"
        },
        {
            "paper_title": "A deflationary account of mental representations",
            "rating": 2,
            "sanitized_title": "a_deflationary_account_of_mental_representations"
        },
        {
            "paper_title": "Memory engram storage and retrieval",
            "rating": 2,
            "sanitized_title": "memory_engram_storage_and_retrieval"
        },
        {
            "paper_title": "Optogenetic stimulation of a hippocampal engram activates fear memory recall",
            "rating": 2,
            "sanitized_title": "optogenetic_stimulation_of_a_hippocampal_engram_activates_fear_memory_recall"
        },
        {
            "paper_title": "Vision: A Computational Approach",
            "rating": 2,
            "sanitized_title": "vision_a_computational_approach"
        },
        {
            "paper_title": "La construction du réél chez l'enfant",
            "rating": 2,
            "sanitized_title": "la_construction_du_réél_chez_lenfant"
        },
        {
            "paper_title": "Simple minds: a qualified defence of associative learning",
            "rating": 1,
            "sanitized_title": "simple_minds_a_qualified_defence_of_associative_learning"
        },
        {
            "paper_title": "The Perceptual Nature of Mental Models",
            "rating": 1,
            "sanitized_title": "the_perceptual_nature_of_mental_models"
        },
        {
            "paper_title": "The physical basis of memory",
            "rating": 1,
            "sanitized_title": "the_physical_basis_of_memory"
        }
    ],
    "cost": 0.01859325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Grounding Mental Representations in a Virtual Multi-Level Functional Framework
2023</p>
<p>Pierre Bonzon pierre.bonzon@unil.ch 
Faculty of Economics
Dept of Information Systems
University of Lausanne
CH</p>
<p>Pierre Bonzon 
Faculty of Economics
Dept of Information Systems
University of Lausanne
CH</p>
<p>Grounding Mental Representations in a Virtual Multi-Level Functional Framework</p>
<p>Journal of Cognition
61202310.5334/joc.249RESEARCH ARTICLE CORRESPONDING AUTHOR: TO CITE THIS ARTICLE: 2 Bonzon Journal of Cognitioncognitive developmentmental representationrepresentational vehiclerepresentational contentsassociative memoryvirtual machine
According to the associative theory of learning, reactive behaviors described by stimulus-response pairs result in the progressive wiring of a plastic brain. In contrast, flexible behaviors are supposedly driven by neurologically grounded mental states that involve computations on informational contents. These theories appear complementary, but are generally opposed to each other. The former is favored by neuro-scientists who explore the low-level biological processes supporting cognition, and the later by cognitive psychologists who look for higher-level structures. This situation can be clarified through an analysis that independently defines abstract neurological and informational functionalities, and then relate them through a virtual interface.to serve as substitutes for arguments in the processes that support cognition. Finally, these cognitive processes themselves are meant to support flexible behaviors. To formalize this procedural hierarchy, the relation between the brain substrate and cognitive processes on one hand, and between cognitive processes and behaviors, on the other, will be abstracted using tools from the domain of computer science, namely concurrent communicating systems and virtual machines. Concurrent communicating systems model the interaction of objects obeying various communication protocols, and thus reflect a high level view of a neural network i.e., of the brain substrate. The concept of a virtual machine interpreting a compiled code that differs from a processor's native code constitutes the key mechanism that allows for interfacing high level abstract objects i.e., software, with their low level physical support i.e., hardware. Following classical results of computer science, symbolic expressions that have been compiled and then interpreted by a virtual machine get their operational semantics from the transitions they induce on the state of this machine. In the context of a multilevel model of brain structures and processes, this means that low levels physiological details can be ignored, and grounded models of cognition can be formulated by relating input and output (i.e., perception and behavior) at a symbolic level. Furthermore, as a program can modify itself as well as the virtual machine, the whole system is evolutive by virtue of its very nature. As a result, and similarly to software made of successive layers of programs that are dynamically interpreted and ultimately executed on hardware, this formalism allows for modeling behaviors driven by successive layers of cognitive processes that are ultimately grounded in the brain.</p>
<p>This framework is validated through a modeling of the first stage of Piaget's cognitive development theory, whose reported end experiments demonstrate the emergence of mental representations of object displacements. The neural correlates grounding this emergence are given in the isomorphic format of an associative memory. As a child's exploration of the world progresses, his mental models will eventually include representations of space, time and causality. Only then epistemological concepts, such as beliefs, will give rise to higher level mental representations in a possibly richer propositional format. This raises the question of which additional neurological functionalities, if any, would be required in order to include these extensions into a comprehensive grounded model. We relay previously expressed views, which in summary hypothesize that the ability to learn has evolved from associative reflexes and memories, to suggest that the functionality of associative memories could well provide the sufficient means for grounding cognitive capacities.</p>
<p>INTRODUCTION</p>
<p>Following the advent of cognitive science, psychology has come to be described as the study of mental representations, how they are computed, and how they affect behavior (Gallistel, 2001). According to widely accepted views, mental representations are internal brain states and mechanisms that drive flexible behaviors i.e., behaviors that cannot be explained in terms of stimulus-responses only. There is still no consensus however on how mental representations are grounded in the brain, and especially about the nature of the computation they involve (Gallistel, 2017;Smortchkova et al., 2020).</p>
<p>Recent significant contributions in this domain go back to Haugeland (1991), who did characterize a representational system as encompassing substitutes for environmental signals. In the same vein, Vosgerau (2010) calls for a "functionalistic core" in which representations are substituted as arguments in templates that are stored in memory. Bechtel (2016) focuses on the neural processes in which mental representations can be grounded and describes them as vehicles carrying contents e.g., spatial information that can be processed. Ramsey (2016) emphasizes their functional role and specific content, which are related to each other by virtue of causal links. To the contrary, Egan (2020) advocates a "deflationary" account of mental representation, which in summary denies them any intrinsic or naturalistically determinate content, their representational capacity being then defined by a function projecting from the level of neural structures to that of behaviors. Consensually, Orlandi (2020) presents a set of necessary and sufficient conditions for internal states or structures to qualify as mental representations, their role being then essentially to serve as isomorphic stand-ins that produce stimulus-free behavior. To wrap things together, Newen &amp; Vosgerau (2020) first develop a "functionalist framework" in which behaviors are defined as mappings from stimulus/state to state/response pairs; mental representations are then viewed as substitutes for arguments, their coarse grained contents being determined by their functional role, and their vehicle standing as neural correlates; in order to reflect different cognitive explanatory levels, they finally introduce a mental representation's third dimension i.e., its "fine-grained structure", which could be either in a correlational, isomorphic, or propositional format.</p>
<p>In summary, mental representation can be characterized by distinguishing their vehicles from their contents. Whereas it is commonly agreed that these vehicles, which carry some informational contents, are constituted by neural correlates, the true nature of these contents themselves is still a subject of controversy (Egan 2014;Ramsey 2020). So-called "deflationary" accounts of mental representations tend to consider them as void of any intrinsic or naturalistically determinate content. Without grounding them, theories of mental representation postulate the existence of causal structures and processes, which the brain actually progressively constructs in its interaction with the world. The shortcomings of this approach might thus well be to put the cart before the horse. What is needed in contrast is a analysis that allows first for independently abstracting low-level functionalities of the brain, on one hand, and higher-level informational links between these functionalities and behaviors, on the other, and then for relating them through a meso-scale level virtual interface.</p>
<p>GOALS AND RESULTS</p>
<p>This work has the following three goals: 1) clarify the status of mental representations through a model relating their neurological and informational functionalities;</p>
<p>2) validate this model through an effective simulation of reported experiments demonstrating the early emergence of mental representations;</p>
<p>3) address the question of which low-level brain functionalities would be required for grounding this model into biological structures and processes.</p>
<p>Concerning goal 1), we shall argue that the controversy about deflationary accounts of mental representations (Egan 2020;Hutto &amp; Myin 2020;Ramsey 2020) can be clarified by providing a multi-level analysis of foundational concepts. Firstly, the vehicles of mental representations have a physical support constituted by neural correlates that supposedly carry some informational contents. Secondly, these contents have a functional role, which is</p>
<p>To validate this proposition and satisfy goal 2), we shall draw on an implementation of Newen &amp; Vosgerau (2020) overall functionalist framework. Behaviors, which in this framework are defined as mappings from one augmented state of mind to another, explicitly interacts with the environment, and thus allow for dynamically constructing mental representations on the fly. A simulation of the initial sensory-motor stage of Piaget (1937) cognitive development theory is proposed as an illustrative case study. It must be stressed from the onset that this simulation is not meant to be a comprehensive model of the Piagetian theory. The storage and retrieval mechanisms involved in the process demonstrate how, at this stage of cognitive development, neural correlates of representational vehicles implement the functionalities of an associative memory. This supports the hypothesis that, still at this initial stage, "mental models are structures partially isomorphic to what they represent and that they contain exclusively perceptual relations" (Vosgerau 2006). As a child's exploration of the world progresses, his mental models will eventually include representations of space, time and causality. Only then epistemological concepts, such as beliefs, will give rise to higher level mental representations in a possibly richer format. This directly leads to the question raised in goal 3) i.e., which additional low level brain functionality, if any, would be needed in order to accommodate these extensions in a simulation, and thus achieve a comprehensive model of cognitive development. Our answer to this question relays prospective views previously suggested by some authors, and which essentially amount to hypothesize that evolution might have been satisfied with the first and simple solution it did encounter for grounding emergent mental representations.</p>
<p>DEFINING MENTAL REPRESENTATIONS IN A FUNCTIONALIST FRAMEWORK</p>
<p>In order to situate our solution to goal 1), we shall first provide an historical survey of past developments that occurred in related research domains. This will then lead us to formulate in turn two questions related to fundamental methodological issues.</p>
<p>HISTORICAL BACKGROUND</p>
<p>As a result of its cognitive revolution, psychology has moved away from behaviorist explanations towards the study of the mind as a computational device. Behaviorism was founded on the idea that the minds of humans and non-human animals alike have to be considered as black boxes i.e., as systems for which one does not postulate anything about the processes that control them. Behaviors were then defined solely by the input-output relations that associate perceptions and actions, with observed behaviors giving rise to behavioral rules i.e., synthetic ways of expressing specific input/output relations. Behaviorist studies culminated in the throughout exploration of operant conditioning. In contrast, according to cognitivist views, behaviors are driven by mental states, which are themselves defined by brain internal structures and processes. At first sight, these two approaches seem complementary; however, behaviorism was eventually felt incompatible with the concept of a mental state e.g., by arguing that different sets of successive mental states could produce the same input-output relation i.e., would be equivalent without being equal.</p>
<p>In order to reconcile these two approaches, one could try and ground them both in a common abstract biological substrate. This would then allow for answering the question of which neural structure could possibly drive an observed behavior, or other words, which neural structure could possibly be associated with a given behavioral rule. Associate learning has been linked to the neural processes of long term potentiation/depreciation (Bliss &amp; Lomo 1973;Markram et al. 1997;Brette et al. 2007). This provides cues of what cognitive states could be made of, and constitutes a possible starting point for theoretically grounding cognitive computations. It raises in turn two related questions i.e.:</p>
<p>1) what is the right level of analysis for grounding cognitive computations;</p>
<p>2) what might be a suitable formalism for interfacing cognition and behaviors?</p>
<p>WHAT IS THE RIGHT LEVEL OF ANALYSIS FOR GROUNDING COGNITIVE COMPUTATIONS?</p>
<p>As argued by Marr (1982) in his "tri-level" hypothesis, the "what" and "how" of cognitive science can be described in computational, algorithmic and implementation terms. An exploration of this hypothesis and of its relation to Cognitive Science has been intensively studied (see e.g., Cooper &amp; Peebles 2015;Love 2015).</p>
<p>The early computational models of cognition (see e.g., Newell et al. 1989;Anderson et al. 2004) were symbolic information processors originating from the research in Artificial Intelligence.</p>
<p>Based on hypotheses about how humans are supposed to behave, these top down approaches did allow for performing simulations regardless (at least at an earlier stage) of any grounding issues i.e., they did not address the problem of binding behavior to the brain. In parallel, another field of research focused on brain structures and processes. Numerous computational platforms aiming at simulating networks of neurons and ranging from artificial neural networks (see e.g., Rumelhart &amp; McLelland 1986;Hinton et al. 2006) based on a threshold logic (McCulloch &amp; Pitts 1943) to analytical neuron simulations (see e.g., Hines and Carnevale 1997; Markram et al. 2015) based on differential equations (Hodgkin &amp; Huxley 1952) to simulate currents have been proposed. These constitute bottom up approaches detailing the ground level constituents of the brain (i.e., the neuronal cells and their connections), and as such are not explicitly related to the cognitive tasks they support.</p>
<p>So-called "neurally plausible cognitive architectures" later tried to associate cognitive models with some form of brain modeling. Designated as hybrid symbolic connectionist models (see e.g., Shastri &amp; Ajjanagadde 1993;Hummel &amp; Holyoak 2005;Doumas et al. 2008), they constitute an attempt to combine the conceptual simplicity and the computing power of artificial neural networks with the expressive capabilities of the models of Artificial Intelligence, and allow in particular for dealing with symbols. According however to a notable attempt using an analytic neuron model (Jilk et al. 2008), "the incommensurable categories at the various levels of description will remain necessary to explain the full range of phenomena", meaning that it is illusory to try and reduce the complexity of the brain to a single level of description. As pointed by many authors (Carandini 2012;Love 2015;Forstmann &amp; Wagenmakers 2015;Cooper &amp; Peebles 2015), formal models are needed to provide links between the brain substrate and cognitive processes.</p>
<p>The growing availability of neural data from brain imaging techniques has given rise to a new interdisciplinary field i.e., model-based cognitive neuroscience (Mulder et al. 2014;Forstmann &amp; Wagenmakers 2015;Palmieri et al. 2017). Very broadly, these approaches rely on statistical methods to relate data to patterns of neural activity. As an example, Seth et al. (2004) study causal interactions in neural populations by applying a combination of time series analysis and graph theory; Borst &amp; Anderson (2017) use ACT-R with fMRI data to predict the neural correlates of constrained model processes. In order to characterize different such approaches Turner et al. (2017) consider two data domains, namely neural data denoted by N and behavioral data, denoted by B, and distinguish three ways these two domains can interact i.e.,</p>
<p>(1) using the neural data to constrain a behavioral model</p>
<p>(2) using the behavioral model to predict neural data</p>
<p>(3) modeling both neural and behavioral data simultaneously.</p>
<p>All these approaches rely on statistical methods to relate data to patterns of neural activity. Whereas the first two cases use unidirectional statistical influence, the third one relies on a bidirectional link between measures of different modes to formalize a connection between N and B through a cognitive model. As a further characterization of this third case, Turner et al. (2017) distinguish two sub cases, namely the joint modeling and the integrative approaches.</p>
<p>In order to relate the model parameters δ and θ that respectively predicts N and B, the joint modeling approach consider higher level parameters Ω linking δ and θ in a hierarchical Bayesian structure connecting the neural and behavioral levels (Turner 2015). In contrast, the integrative approach relies on a single set of parameters e.g., the sequence of module activations in the ACT-R framework that assumes a predefined set of modules.</p>
<p>At first sight, the joint modeling approach allows for a projection into Marr's three-level analysis concepts i.e., the computational and algorithmic levels being constituted respectively by a Bayesian probabilistic model and an inference rule. The mere existence of a corresponding neuronal implementation is however highly hypothetical. The complexity of the corresponding neural phenomena has so far prevented the definition of models directly relating single neuron dynamics to global brain states (see e.g., Goldman et al. 2019). As an example, whereas neurological measurements (Tomov et al 2018) have validated a computational Bayesian model positing a dedicated neural mechanism for causal learning (Gershman 2017), nothing is known about the corresponding basic neuronal processes.</p>
<p>In any case, as argued thoroughly by Frégnac (2017), "big data is not knowledge". The causal link between sub-cellular/cellular mechanisms and behavior should be achieved through successive levels of analysis, as exemplified by Marr's hypothesis. This means that mappings need to be expressed in algorithmic terms and not just in a correlative way. In order to take into account intermediate levels of circuit integration, canonical operations should be defined as invariant computations. As discussed in (Frégnac &amp; Bathellier, 2015), top-down approaches via analytical and/or abstract mathematical tools such as Bayesian inference rules (see e.g., Ma and Pouget 2008), and for that matter we may add the bottom-up approaches of the classical theories based on artificial neural networks (Kohonen 1982;Hopfield 1982) as well as methods related to dynamical systems theory and neural fields (Thelen &amp; Smith 1994;van Gelder 1998), are well suited for describing computations in Marr's sense, but "fail to identify algorithms and underlying circuits". What is then needed, they conclude, is a ''middle-out'' approach that can identify plausible structures and processes linking biology and cognition across successive levels of integration distinguishing micro-scale and meso-scale functions. Analogous conclusions can be found in the insightful review of van der Velde and de Kamps (2015), who argue that cognitive processes are executed in connection structures that link sensory circuits ( i.e., perception) with motor (i.e., action). What is needed, they add, is "a mechanism that shows how the information (synchrony of activation in this case) can be used by the brain".</p>
<p>In conclusion, there does not seem to be a single level for grounding cognition, and the problem is rather to design an interface between different levels of study.</p>
<p>WHAT MIGHT BE A SUITABLE FORMALISM FOR INTERFACING COGNITION AND BEHAVIORS?</p>
<p>Looking at the brain as a computing device linking neural dynamics to actions has led to the emergence of quite a few related research domains. Whereas computational neuroscience addresses low level neural mechanisms that give rise to higher level processes representing computations, cognitive neuroscience attempts to relate brain and behavior by linking latent cognitive processes to the neural mechanisms that generate them (Frank and Badre 2015). These two disciplines, when taken together, form the computational cognitive neuroscience (or CCN) paradigm (O'Reilly and Munakata 2000; Ashby and Helie 2011; Kriegeskorte &amp; Douglas 2018), in which artificial neural network models and methods serve both to specify and to concretize theories (Herd et al. 2013). A cognitive model however doesn't have to represent its underlying neuronal processes itself, as the present approach to CCN does, but could rather adds an intermediate layer between the neuronal and behavioral layer (Mulder et al. 2014;Frank 2015), using formal models to connect findings from neuroscience to the cognitive processes at hand (Forstmann and Wagenmakers 2015).</p>
<p>The interface between these various layers could be described using computer science methods that allow for a delineation and implementation of successive levels of complexity. Present day computer software methodology follows a two levels approach: application source programs written in a high level language (e.g., Java) get interpreted by an intermediate program constituting a virtual machine, which itself gets executed as an object program written in a processor native code. This mechanism constitutes the key mechanism that allows for interfacing two independent objects i.e., software and hardware. In the context of a multi-level model of brain structures and processes, this means that low levels physiological details could be ignored, and grounded models of cognition be formulated by relating input and output (i.e., perception and behavior) at a symbolic level.</p>
<p>This is the approach that will be illustrated here. As computer applications can be first programmed, then compiled and finally interpreted by a virtual machine running as a native program, cognitive processes will be similarly encoded, compiled and then interpreted by virtual neurological microcircuits representing a brain's innate processes. As a consequence, there will be no reference to any specific neural network model. In contrast to the usual approach of creating neural models of interactive brain areas by quantitatively fitting data (i.e., where latent estimated parameters are being correlated with neural measures), the goal here is to construct a model of how behaviors can be interfaced with neural dynamics in order to try and discover the learning processes involved in the emergence of cognition.</p>
<p>A VIRTUAL NEUROLOGICAL FORMALISM</p>
<p>In the formalism presented in (Bonzon 2017; Bonzon 2019), brain processes representing synaptic plasticity are abstracted through asynchronous communication protocols and implemented as virtual microcircuits. The basic units of these micro-circuits are constituted by threads, which correspond either to a single or to a cluster of connected neurons. Contrary to traditional neuron models in which incoming signals are summed in some integrated value, thread inputs can be processed individually, thus allowing for threads to maintain parallel asynchronous communications reflecting a massively asynchronous organ (Zeki 2015). Threads can be grouped into disjoint sets, or streams to model neural assemblies (Gerstner &amp; Kisler 2002;Huyck &amp; Passmore 2013) and discrete weights (e.g., integer numbers) can be attached to pairs of threads that communicate within the same stream. Meso-scale virtual circuits linking perceptions and actions are built out of microcircuits. Circuits can be compiled into virtual code implications that are used just in time to deduce instructions to be finally interpreted by the virtual machine performing contextual deductions.</p>
<p>BASIC CONCEPTS</p>
<p>To introduce this formalism, let us consider a simple case of synaptic transmission between any two threads P and Q. This can be represented by the microcircuit given in Figure 1, where the symbol -&gt;=&gt;-represents a synapse. This protocol corresponds to an asynchronous communication, where a predefined weight between the sender P and the receiver Q that can be either incremented or decremented. On one side, thread P fires thread Q and sends it a signal. On the other side, Q waits for the reception of a signal from P and proceeds only if the weight between P and Q stands above a given threshold. The overall process allows for passing data through variable parameters.</p>
<p>As a first example, let us consider the classical conditioning of aplysia californica (Kandel &amp; Tauc, 1965). In this experiment, a tactile conditioned stimulus cs elicits a weak defensive reflex, and an electrical unconditioned stimulus us produces a massive withdrawal reflex. After a few pairings of cs and us with cs slightly preceding us, cs alone triggers a significantly enhanced withdrawal reflex. The corresponding circuit, adapted from Carew et al. (1981), is represented in Figure 3. In this circuit, the symbol /|\ represents the modulation of a synaptic transmission, the sign * indicates the conjunction of converging signals, and the sign + either the splitting of a diverging signal, or a choice between converging signals. The variable parameter X in thread motor(X) gets instantiated into either cs or us.</p>
<p>Thread ltp (standing for long term potentiation) acts as an interneuron reinforcing the pathway between sense(cs) and motor(X).</p>
<p>Classical conditioning follows from the application of hebbian learning i.e., "neurons that fire together wire together". Though it is admitted today that classical conditioning in aplysia is mediated by multiple neuronal mechanisms including a postsynaptic retroaction on a presynaptic site (Glanzman et al, 1995;Antonov et al, 2003), the important issue is that this activity depends on the temporal pairing of the conditioned and unconditioned stimuli, which leads to implement the thread ltp as a detector of coincidence.</p>
<p>A MECHANISM FOR SIMULATING LONG TERM POTENTIATION</p>
<p>The microcircuit abstracting the mechanism of long term potentiation is given in Figure 4. As a further theoretical abstraction, our formalism allows to distinguish between a hypothetical weak and a strong synaptic plasticity reflecting brain maturation (Bolton et al 2017). Whereas weak plasticity binds a given sensory input with a unique reaction, a strong synaptic plasticity allows for associating the same input with successive different reactions.</p>
<p>N.B. In our implementation, this abstraction follows from the underlying logical programming framework that distinguishes between the so-called anonymous variables, denoted by the character " _", and named variables, such as X, Y, Z. Whereas anonymous variables, once they get bound, do not retain their value and thus cannot create successive associations, named variables do.</p>
<p>In order to detect the coincidence of P and Q, P fires an ltp thread that calls on join to wait for a signal from Q. In parallel, Q calls on merge to post a signal for ltp and then executes a send(R) command to establish a link with R. After its synchronization with Q, ltp increments the weight between Q and R.  As a further example of long term potentiation implementing a simple form of operant conditioning, implying in this case learning the choice of a preferred action through a possible reinforcement, let us first introduce:</p>
<p>• a watch(I) thread that drives a learning process, where I is a sensory input • a spot(I) thread discriminating perceptions through an excite or an inhibit stimulus • two effector threads accept(I) and reject(I)defining output responses.</p>
<p>Let us then consider the virtual circuit in Figure 5:</p>
<p>• at the start, the pathway from watch to spot is open, and pathways to accept and reject are closed;</p>
<p>• thread spot discriminates inputs through positive and negative stimuli, and thus allows for diverging paths;</p>
<p>• LTP threads open the path to either accept or reject, and LTD threads close the path to spot.</p>
<p>This circuit matches a fundamental principle in circuit neuroscience according to which, as a result of synaptic plasticity (expressed here through LTP/LTD threads), inhibition in neuronal networks during baseline conditions allows in turn for disinhibition and constitutes a key mechanism for learning (Letzkus et al 2015;Zagha et al 2015). As a result, this circuit learns a deterministic behavior driven by two neural populations competing for a response.</p>
<p>AN EXTENDED ASSOCIATIVE MECHANISM FOR MEMORY ENGRAMS</p>
<p>According to experimental results (Liu et al. 2012;Ryan et al., 2015;Tonegawa 2015), memory engrams involve two different circuits and mechanisms i.e., the retention of specific patterns of connectivity between engram cells required for the storage of information, on one hand, and the synaptic strengthening needed for its consolidation and retrieval, on the other.  In order to allow for two threads P and Q attached to separate streams and active at different times to be associated in order to trigger a recall thread R, a new communication protocol involves two complementary long term storage/retrieval (lts/ltr) threads. This new protocol, which leads to the building of a storage trace depicted by -{P}-and its later retrieval, is given in Figure 6. As a distinctive difference from an ltp(Q,R) thread (which gets fired by P and waits for a signal from Q in order to relate Q and R), an ltr(P,Q,R) thread is fired by Q and waits for a path from {P} in order to relate Q and R, thus defining the basic mechanism of an associative memory.</p>
<p>A VIRTUAL MACHINE FORMALISM</p>
<p>The concept of a virtual machine that we shall use allows for emulating the execution of a program given in a symbolic language S on a system having its own logical language L. On the cognitive side, virtual circuits, which somehow correspond to cognitive software written in language S, are compiled into virtual code implications of language L. On the neural side, these implications are used in turn to deduce just in time instructions that get interpreted by the virtual machine i.e., this virtual machine actually performs contextual deductions (Bonzon et al., 2000). In addition, languages I and O define respectively input/output sentences captured by sensors and delivered to effectors. By developing how models are actually constructed, we get the following functional signatures: In the realm of behaviorism, reactive behaviors are described by mappings from inputs (stimuli) to outputs (responses). In the realm of cognitivism, these mappings are extended in order to account for flexible behaviors. According to Newen &amp; Vosgerau (2020), the corresponding functions take two arguments i.e., a stimulus/internal state pair, and produce two values i.e., a resulting internal state/response pair. The reduced signature of the run mapping as defined above corresponds to the one called for by Newen &amp; Vosgerau. Let Model ϵ L, Input ϵ I and Output ϵ O designate respectively an internal state, a stimulus and a response. In its interaction with the outside world, this machine does function as a nondeterministic learning automaton that repeats a sense-react cycle of embodied cognition (Brooks 1991). At the top level, the virtual machine is defined by a run procedure that consists of a loop whose cycle comprises a sense procedure followed by a react procedure:</p>
<p>run(Model) loop sense(Model) react(Model)</p>
<p>At the next level, the sense procedure monitors stimuli directed to sensor threads. After capturing an Input interrupt, it updates Model through a transition function input:
sense(Model) if interrupt(Input) then input(Model, Input)
The react procedure consists of a loop using implications in Model to first deduce a response under the form of a virtual machine instruction Output, and then updates Model through a transition function output corresponding to the execution of this virtual machine instruction:</p>
<p>react(Model)</p>
<p>for each (Instruction) such that ist(Model, Output)</p>
<p>do output(Model, Output)</p>
<p>The ist predicate i.e., "is true", implements contextual deduction. As there is no specified final state, whichever state the machine is in at any given time is acceptable and represents the simulated subject's current state of mind.</p>
<p>CASE STUDY: PIAGET REVISITED</p>
<p>The purpose of this case study is to demonstrate how mental representations arising in the early course of a child's cognitive development can be simulated in a computational framework. These simulations, which reproduce experiments from Piaget (1937), are not intended to be a comprehensive model of the corresponding psychological theory, but merely to explore the possible neurological structures and processes that support this development.</p>
<p>BACKGROUND AND SCOPE</p>
<p>According to Piaget's theory, cognitive development starts with a sensory-motor stage, which itself extends over 6 substages. At the beginning, infant behaviors are driven by elementary action schemas. Substage 4 marked with of object permanence, or objectification i.e., the emergence of objects as autonomous and permanent entities. In Piaget's terminology, assimilation (i.e., the insertion of new perceptions into existing schemas) is followed by accommodation (i.e., the modification and/or extension of existing schemas). His postulate then reads as follows: "The criterion of this objectification, hence of this rupture in continuity between things perceived and the elementary sensory-motor schemata, is the advent of the behavior patterns related to absent pictures: search for the vanished object, belief in its permanence, evocation, etc." (Piaget 1937, p. 5).</p>
<p>This theory has been repeatedly challenged (Bower 1967;Bower &amp; Wishart 1972), especially after the evidence provided by new type of experiments did suggest that infants demonstrate an understanding of object permanence at an earlier age (Baillargeon et al 1985;Baillargeon 1987). This evidence however, which relied on a violation of the expectation paradigm, has been later questioned by a theoretical account of this paradigm that does not invoke object concepts (Schöner &amp; Thelen 2006). It was consequently proposed that infant's failure to achieve Piaget's search tasks should not be attributed to an inadequate level of cognitive development, but rather to an inherent difficulty in coordinating perceptive and motor actions. This controversy raises the issues of how schemas are acquired, coordinated, and eventually give rise to mental representations. Cognitive neuroscience, which aims at linking cognition to brain processes, hasn't succeeded yet in grounding such schemas into actual neural circuits. Our formalism of symbolic neural dynamics is used here to model them as virtual circuits linking sensory inputs with perceptual responses. These circuits will be then interpreted in turn by a virtual machine thus simulating successive the substages of the sensory-motor stage.</p>
<p>MODELING REFLEXES (SENSORY-MOTOR SUBSTAGES 1-2)</p>
<p>The observations related to the first and second sensory-motor substages have been reported in (Piaget 1936). These essentially consist in describing reflex behaviors that are driven by visual attention and culminate in coordinated prehension: the grasping of objects becomes "systematic when the object and the hand are perceived in the same visual field". In other terms, following a reciprocal assimilation, "all that is to be seen is also to be grasped and all that is to be grasped is also to be seen".</p>
<p>The work of Wible et al. (2020) offers a model of visual attention that simulates behavioral and neural correlates as the product of attractor states in a dynamical system. The model proposed here is based on symbolic neural dynamics and distinguishes two intervened steps:</p>
<p>• first sensation i.e., the capture of visual data through sensors</p>
<p>• then perception i.e., the interpretation of these data through virtual circuits linked to effectors. • space will be restricted and defined as a one dimensional axis, with visual sensory inputs defined as P(X), where P and X stand respectively for the stored image of an object and its position on the space axis, which together constitute a numerical identity i.e., a prerequisite for object permanence (Moore &amp; Meltzoff 2004) • neural assemblies processing these inputs will be represented by threads activated through short term potentiation.</p>
<p>Visual input data consist in an object</p>
<p>On this basis, a grasping reflex can be driven by the virtual circuit given in Figure 1. In this circuit, two sensors sense(view(P(X))) and sense(view(hand(X)))converge to signal that an object P and a hand are perceived in the same visual field X. As a result, the effector grasp(P(X)) gets activated through a short term potentiation. In conjunction with this visual drive, a grasping reflex involves other multi-modal perceptions e.g., for controlling motor actions (see e.g., Thelen et al 2001;Bonzon 2020). In the developments that follow, it is assumed that the firing of the circuit in Figure 7 will be followed by the subject's required coordinated motor actions.</p>
<p>A short term potentiation STP opens the path from sense(view(P(X))) to grasp.</p>
<p>MODELING VISUAL OBJECT TRACKING (SENSORY-MOTOR SUBSTAGE 3)</p>
<p>Among others explorations, infant early experiences with the world follow from their visual attention being caught by moving objects. The tracking of moving objects results from eye saccades i.e., target-driven reflex movements. These are driven by expected upcoming data relying on pattern recognition from preceding inputs (Bicanski &amp; Burgess 2019). As noted by   Piaget (1937, p.13), "Visual accommodation to rapid movements makes possible the anticipation of future positions of the object". In the case of a single object, this anticipation relies on the focus of attention (i.e., the position where the object is expected to next hit the eyes). When the actual sensation does not meet the expectation (i.e., if another object actually hit the eyes), visual attention gets suspended, and a default action is taken. This represents a first example of assimilation (i.e., in this case of the inputs produced by the moving object), followed by an accommodation (in this case by giving up tracking and looking instead at the occluding screen).</p>
<p>As an example, let us consider a simple simulation scenario that reproduces a characteristic behavior that can be observed in the third sensory-motor substage, defined as follows:</p>
<p>• a toy is seen moving (e.g., carried or rolling) along a one dimensional axis • if it stands still (e.g., is dropped or stops) in the sight of the observer, he grasps it • if it disappears behind/under a screen/object, the observer looks at the occluding item.</p>
<p>Two successive eye saccades are sketched in Figure 8 together with their sensory input vectors.</p>
<p>As a result of discriminating inputs to eye saccades, a forward propagation of excite/ inhibit stimuli leads to the virtual circuit implementing visual tracking given in Figure 9.</p>
<p>• two parallel sensor threads first process the input move(P(X)) and set the current focus of attention to P;</p>
<p>• these two threads then wait for a sensor thread to process the input see(Q(X+1));</p>
<p>• current focus of attention leads to apply a short term potentiation to one of two threads;</p>
<p>• signal that the toy stands in the observer's visual field leads to a grasp(P(X+1)).</p>
<p>This is illustrated in Figure 10 containing the execution trace of an actual simulation run.</p>
<p>MODELING VISUAL OBJECT TRACKING AND SEARCHING (SENSORY-MOTOR SUBSTAGE 4)</p>
<p>The next substage is marked by a child's ability to search for an object outside of his visual field e.g., behind a screen. At the beginning, the child does not take into account successive object displacements i.e., for him "the place where the object was found for the first time remains the place where it will be found", leading to the so-called A not B error. Piaget proposed a mix of possible explanations for this phenomenon, including a lack of ability to recall the sequence of displacements, to correctly take into account their order, and to separate objects from their context. This has been summarized as resulting from the persistent association binding an Figure 8 Successive eye saccades tracking a moving object.</p>
<p>Figure 9</p>
<p>Virtual circuit implementing the visual tracking of a moving object. Journal of Cognition DOI: 10.5334/joc.249 object with the infant's immediate action (Müller et al 2001), or as reflecting the sustained visual attention that accompanies a first reach (Ruffman 2001). In terms of neural processes, this could result from a failure to inhibit a previous response (Munakata 1998;Diamond 2001) i.e., in other terms to bind successive related sensory inputs and actions. After a while, a correct sequential tracking is steadily observed.</p>
<p>13</p>
<p>Bonzon</p>
<p>A virtual circuit implementing the tracking and searching of a moving object that extends the circuit of Figure 9 is given in Figure 11. This circuit illustrates another example of assimilation and accommodation. The sensation produced by a suspended attention, represented by the sensory input from sense(halt(Q(X+1))), is followed by a new accommodation i.e., a search that gets activated by long time potentiation LTP. Two different LTP models (see Figure 4) reflecting a form of weak vs. strong form of synaptic plasticity (i.e., a brain maturation that allows at the end for binding successive related sensory inputs and actions) are used here to reproduce in turn an A not B error and a correct sequential tracking. Furthermore, the sensation produced by uncovering an object is assimilated by another sensory input from sense(view(P(X+1))that produces a grasping reflex.</p>
<p>In addition to the previous circuit,</p>
<p>• the thread search(Q(X+1))gets driven whenever the toy disappears;</p>
<p>• two different models of LTP can be used to reproduce an A not B error or a correct sequential tracking; Figure 10 Execution trace of tracking a mobile object.</p>
<p>Figure 11</p>
<p>Virtual circuit implementing the visual tracking and searching of a moving object. 14 Bonzon Journal of Cognition DOI: 10.5334/joc.249 • signal that object P has been uncovered at location X+1 drives a grasping reflex;</p>
<p>• this grasping reflex is activated by a potentiation from the search thread.</p>
<p>An execution trace of this circuit implementing a weak LTP potentiation is given in Figure 12.</p>
<p>The unfeasibility of binding a second pair of related inputs at the second screen forced a renewed search at the first screen, thus producing an A not B error. In contrast, the same circuit implemented with a strong long time potentiation allows for successive associations of related sensory inputs and actions and produces the execution trace given in Figure 13, which reflects a correct second search.</p>
<p>MODELING A PARTIALLY INVISIBLE DISPLACEMENT (SENSORY-MOTOR SUBSTAGE 5)</p>
<p>The first acquisition of the next stage is to account for sequential displacements, i.e., to correct the A not B error. As discussed above, this is achieved in our framework by activating the search thread through a long time LTP potentiation implementing a strong from of synaptic plasticity. In order to study the dissociation of objects from their context (e.g., when an object's position is not directly perceived because of some invisible part along its way), Piaget (1937, p. 75) devised a series of experiments: "hiding an object not directly under a screen, but in box without a lid; box and object are made to disappear under a screen and the box brought out empty". He then Figure 12 Execution trace of tracking and searching a mobile object with an A not B error.</p>
<p>Figure 13</p>
<p>Execution trace of a correct tracking and searching a mobile object. 15 Bonzon Journal of Cognition DOI: 10.5334/joc.249 observed what he called an "empirical or practical apprenticeship" which, he argued, does not yet involve any image or representation of spatial relations.</p>
<p>Our developments follow closely observation 55 from . This observation was divided in three phases:</p>
<p>I. An object is put in a box while the infant watches; the box is then placed under a screen and turned down to leave the object hidden under the screen without the infant noticing it; the box is finally brought out empty. The infant then searches for the object in the box, eventually looks around, but doesn't search for the object under the screen II. After a few repetition of this technique followed by the same negative result, the box is left under the screen with the object inside; the infant then immediately looks under the screen and grasps the object (NB. in the original description, the infant finds and grasps the box, opens it, and takes the object out of it; these details will be ignored here for the sake of simplicity, especially since the box was not explicitly said to be closed)</p>
<p>III. Finally, the experiment protocol of phase I is resumed: this time, the infant first looks for the object in the box and not finding it then searches under the screen (NB this positive result is steadily observed only after a few experiments).</p>
<p>The outcome of phase III led Piaget to conclude that mastering partially invisible displacements (NB which are generally but oddly referred to as "visible displacements") could not occur through the awareness of some relation or image, but as a result of a "practical schema" acquired through some kind of learning.</p>
<p>These three stages can be implemented through a further differentiation of the previous schema that gives rise to the schema in Figure 14. In this circuit, the practical learning envisioned by Piaget is implemented as a simple case of operant conditioning, which involves a watch and a spot thread (see Figure 5). This behavior relies on the remembered position where the object equivalently, did disappear, represented in our formalism by a short term memory <look(Q(X+1))>.</p>
<p>In addition to the previous circuit,</p>
<p>• the stop thread activates a learning circuit where I stands for the object contained in box F;</p>
<p>• this sub-circuit is imbedded in the overall circuit such that the search is now driven by the halt thread;</p>
<p>• this search relies on the memorized position <look(Q(X+1))> where the object did disappear;</p>
<p>• the object I captured by the sensory input sense(view(I(X+1))) gets discriminated.</p>
<p>The successive phases of observation 55 have been reproduced in simulation run based on the circuit of Figure 14 (see Figure 16 in the Supplementary information section). </p>
<p>MODELING INVISIBLE DISPLACEMENT (SENSORY-MOTOR SUBSTAGE 6)</p>
<p>The transition between substages 5 and 6 i.e., when a child starts mastering invisible object displacements, demonstrates a shift from perceptual to representational responses i.e. , a capacity that can be invoked in the absence of a perceived reality (McCune 2001). This is summarized as being able to "keep an object in mind" when it is not in sight. This capacity builds up to the sequential tracking of objects that undergo successive invisible displacements. Our developments reproduce here Piaget's observation 64, translated however in a different involving a covered box instead of a closed hand. This observation is divided in three phases retaining their original numbering.</p>
<p>Ia. An object is put in a box and the box is covered by a lid while the infant watches; the box is then placed under a screen and emptied to leave the object hidden under the screen without the infant noticing it; the box is finally brought out empty. The infant searches for the object in the empty box, and then goes on searching for it under the screen Ib. The same experiment is repeated, with the covered box being passed and emptied in a different screen; the infant immediately searches this second screen.</p>
<p>II. The experiment protocol of phase I is resumed, but this time the box passes under two successive screens before stopping; the infant looks for the object under the first screen, and not finding it searches the second screen.</p>
<p>These three phases can be implemented through an ongoing differentiation of the schema in Figure 14 that ends up with the extended circuit in Figure 15.</p>
<p>In addition to the previous circuit,</p>
<p>• sensation gets assimilated by sense(open(F(I)(X))) and sense(close(F(_)(X)));</p>
<p>• this sensation gets accommodated in an internal representation {image(F(I)(X)))};</p>
<p>• a retrieval process leads the watch thread to activate the opening of the closed box after it stopped;</p>
<p>• a LTB process blocks subsequent box openings;</p>
<p>• the sense(spot(F(I)(X))) thread leads to either grasp a wanted item or activate a new search;</p>
<p>• a retrieval from {image(F(I)(X))} drives the view thread to activate a renewed search.</p>
<p>At the start, watching the experimenter while he places a toy in a box (or equivalently takes it in his hand palms) and then covers the box (or closes his hands) produces a new sensation involving a relation between two objects. This gets assimilated by sense(open(F(I)(X))) and sense(close(F(_)(X)))threads, where F and I stand respectively for the box and object, and accommodated by the image(F(I)(X)) thread that creates an internal representation {image(F(I)(X))} implemented via an LTS long term storage process. In our formalism (see  Figure 6), the internal representation {P} of a thread P extends the mechanism of long term potentiation and allows for an LTR(P,Q,R) retrieval process to be fired by Q in order to relate Q and R, thus defining the basic mechanisms of an associative memory. In the present context, this retrieval process drives the watch thread (which stands here for Q ) to activate the open thread (which stands for R) and thus trigger the opening of the box after it stops.</p>
<p>After opening the box, sense(spot(F(I)(X))) drives spot thread to either grasp a desirable item or activate a new search. According to Piaget's observation, infants who at first do open a box and find it empty do not open it again in subsequent trials. This is achieved here through a long term blocking process LTB. Altogether, this new accommodation enlarges the previous operant conditioning learning process by allowing it to be driven by an image evocation.</p>
<p>Finally, in order to take into account successive invisible displacements, an evocation from the {image(F(I)(X))} memory drives an LTR retrieval process that activates a renewed search via the discriminating view thread. In order to recall the sequence of displacements and take into account their order, the memory <look(Q(X+1))> is implemented as a classical first-infirst-out (FIFO) data structure.</p>
<p>This implementation raises the question about possible links between abstract neurological processes and the psychological model they aim to represent. Piaget's early theoretical developments about mental representations can be found in (Piaget 1936, p.242), where he argues as follows:</p>
<p>"Hence the accommodation of this stage is more refined than that of the schemata hitherto under study, since the mobile schema applies to relations between external things and no longer only to things in their mere connection with the activity itself".</p>
<p>He then goes on asking the question "Does this accommodation involve representation?</p>
<p>to which, after a digression, he proposes to add an additional criterion i.e. , that representation must be understood "to mean the capacity to evoke by a sign or a symbolic image an absent object or an action not yet carried out".</p>
<p>According to this argumentation, a criterion for the existence of a mental representation is the capacity of a symbolic image to evoke an action not yet carried out. This capacity is implemented in our virtual neurological framework through the additional functionalities required for tracking invisible displacements recalled above i.e.:</p>
<p>a) assimilating a relation between two things through a symbolic image b) accommodating this relation by enabling its retained image to drive an action.</p>
<p>It can be concluded that these additional functionalities characterize mental representations as opposed to mere action schemas, and thus implement a shift from perceptual to representational responses. As postulated by various authors (e.g., Vosgerau 2006;Orlandi, 2020), these representations are in an isomorphic format. In support of this evolution, Ramsay and Campos (1978) demonstrated that infants who had reached substage 6, and thus kept in mind the hidden object, expressed surprise when the toy they uncovered was different.</p>
<p>The successive phases of observation 64 have been reproduced in a simulation run based on the circuit of Figure 15 (see Figure 17 in the Supplementary information section).</p>
<p>SUMMARY AND CONCLUSION</p>
<p>In his reflection (Poggio 2012, p.7) about the "levels of understanding" framework (Marr &amp; Poggio 1977), Poggio poses the following question: "did intelligence, as the ability to learn, evolve from associative reflexes and memories with the addition of (neurally simple) primitive operations such as composition of different memories?". In order to answer this question, psychological theories should try and relate cognitive concepts to abstract brain structures and processes on which they could be possibly grounded. Failing to do so somehow amounts to putting the cart before the horse. Piaget's theory of cognitive development, which is based on schemas that supposedly drive a child's activity, is detached from any hypothesis about their neurological grounding. Furthermore, this theory is based on his rejection of association as a basic mechanism for cognitive development. He introduced instead the collective effect of assimilation (i.e., the insertion of new perceptions into schemas) followed by accommodation (i.e., the modification and/or extension of schemas), two concepts that are situated at a higher explanatory level than associative memories, and which rely on the preexistence of innate schemas i.e., structures and processes that ultimately have to be grounded at a lower level.</p>
<p>As we have demonstrated in this work, action schemas involved in the sensory-motor stage of this theory can be simulated in a computational framework. These simulations successively allowed for reproducing:</p>
<p>• the grasping of an object in sight (substages 1-2);</p>
<p>• the visual tracking a moving object (substage 3);</p>
<p>• the A not B error and the correct retrieval of a hidden object (substage 4);</p>
<p>• the tracking partially invisible object displacements (substage 5);</p>
<p>• the tracking invisible object displacements (substage 6).</p>
<p>The transition to substage 6 represents a shift from perceptual to representational responses. Whereas the implementation of the first substages relies on short/long term potentiation, this last transition requires the additional abstracted neuronal functionality of an associative memory. As defined in our formalism, the lts/ltr operations precisely allows for two threads P and Q attached to separate streams to be associated in order to trigger a recall thread R, thus enabling the retained image of a previously perceived relation to drive an action, and thus more generally to implement the basic mechanisms of memory engrams (Queenan et al., 2017;Gallistel, 2021).</p>
<p>This raises the question of which additional basic neural functionalities, if any, would be needed in order for an extended framework to accommodate epistemological concepts, such as beliefs, which presumably involves mental representations in a propositional format (Newen and Vosgerau, 2020). It has been argued that such higher level constructions are unlikely to be based on mechanisms directly related to the lowest level of brain structures and processes (Heyes, 2012). Darwin (1871) himself once wrote that "Nevertheless the difference in mind between man and the higher animals, great as is it, certainly is one of degree and not of kind", thus somehow precluding the existence of fundamental neurological mechanisms that would be unique to humans. When discussing the modalities of mental representations associated with beliefs, Newen and Vosgerau (2020) content themselves with noting that "the best we can expect is a cluster of neural correlates embedded in one quite contextually varying mechanism or even embedded in a plurality of mechanisms". Indeed if, as noted in (Carew 2002, p. 806) and supported by (Baxter et Byrne, 2006) as well by the abstract models presented above, classical and operand conditioning "have features in common, an exciting principle might emerge: evolution may have come up with a neural 'associative cassette' that can be used in either type of conditioning, depending of the neural circuit in which it is embedded".</p>
<p>DATA ACCESSIBILITY STATEMENT</p>
<p>I confirm that there is no Data Accessibility statement for this work.</p>
<p>ADDITIONAL FILE</p>
<p>The additional file for this article can be found as follows:</p>
<p>• Supplementary information. Execution traces of actual simulation runs. DOI: https://doi. org/10.5334/joc.249.s1</p>
<p>ETHICS AND CONSENT</p>
<p>There is no ethical approval/consent attached to this work.</p>
<p>Figure 1
1Microcircuit implementing a synaptic transmission.</p>
<p>Figure 2
2Virtual machine instructions for an asynchronous communication.</p>
<p>Figure 3
3Figure 3 A circuit implementing classical conditioning.</p>
<p>Figure 4
4Micro-circuit and virtual machine instructions for ltp.</p>
<p>Figure 5
5Virtual</p>
<p>load: S × (S→ L) × L→ L compile load and run: I × (S× (S → L) × L) → L× O Running a compiled model on a virtual machine then defines the reduced signature: run: I × L → L× O</p>
<p>Figure 6
6Microcircuit</p>
<p>image and its position in space. The capture of an object's image results from multilayered neural processes taking place in the eye's retina. As it has been demonstrated in rodent animals (O'Keefe &amp; Dostrosky 1971; Moser et al., 2008; Moser &amp; Moser 2008), the capture of position data is achieved via multiple receptive fields i.e., place, head direction, grid and border cells. The perception associating these two data results from yet mostly unknown higher level circuits and mechanisms (Lewis et al 2019; Bicanski &amp; Burgess 2019; Anselmi et al 2020). Our model relies on two simplifying hypotheses:</p>
<p>Figure 7
7Virtual circuit implementing the grasping of an object.</p>
<p>Figure 14
14Virtual</p>
<p>Figure 15
15Virtual</p>
<p>An integrated theory of the mind. J R Anderson, 10.1037/0033-295X.111.4.1036Psychological Review. 1114Anderson, J. R., et al. (2004). An integrated theory of the mind. Psychological Review. 111(4), 1036-1060. DOI: https://doi.org/10.1037/0033-295X.111.4.1036</p>
<p>A computational model for grid maps in neural populations. F Anselmi, M Murray, B Franceschiello, 10.1007/s10827-020-00742-9J Comput Neurosci. 48Anselmi, F., Murray, M., &amp; Franceschiello, B. (2020). A computational model for grid maps in neural populations. J Comput Neurosci, 48, 149-159. DOI: https://doi.org/10.1007/s10827-020-00742-9</p>
<p>Activity-Dependent Presynaptic Facilitation &amp; Hebbian ltp Are Both Required &amp; Interact during Classical Conditioning in Aplysia. I Antonov, I Antonova, E R Kandel, R D Hawkins, 10.1016/S0896-6273(02)01129-7Neuron. 1Antonov, I., Antonova, I., Kandel, E. R., &amp; Hawkins, R. D. (2003). Activity-Dependent Presynaptic Facilitation &amp; Hebbian ltp Are Both Required &amp; Interact during Classical Conditioning in Aplysia. Neuron, 37(1). DOI: https://doi.org/10.1016/S0896-6273(02)01129-7</p>
<p>A tutorial on computational cognitive neuroscience, Modeling the neurodynamics of cognition. F Ashby, S Helie, 10.1016/j.jmp.2011.04.003J. Math. Psychol. 55Ashby, F., &amp; Helie, S. (2011). A tutorial on computational cognitive neuroscience, Modeling the neurodynamics of cognition. J. Math. Psychol, 55, 273-289. DOI: https://doi.org/10.1016/j. jmp.2011.04.003</p>
<p>Object permanence in 3½-and 4½-month-old infants. R Baillargeon, 10.1037/0012-1649.23.5.655Develop. Psychol. 235Baillargeon, R. (1987). Object permanence in 3½-and 4½-month-old infants. Develop. Psychol., 23(5), 655-664. DOI: https://doi.org/10.1037/0012-1649.23.5.655</p>
<p>Object permanence in five-month-old infants. R Baillargeon, E Spelke, S Wasserman, Baillargeon, R., Spelke, E., &amp; Wasserman, S. (1985). Object permanence in five-month-old infants.</p>
<p>. 10.1016/0010-0277(85)90008-3Cognition. 20Cognition, 20(1985), 191-208. DOI: https://doi.org/10.1016/0010-0277(85)90008-3</p>
<p>Aplysia Feeding behavior: a model system for comparing cellular mechanisms of classical and operant conditioning. D Baxter, J Byrne, 10.1101/lm.339206Learn. Mem. 13Baxter, D., &amp; Byrne, J. (2006). Aplysia Feeding behavior: a model system for comparing cellular mechanisms of classical and operant conditioning. Learn. Mem, 13, 669-680. DOI: https://doi. org/10.1101/lm.339206</p>
<p>Investigating neural representations: the tale of place cells. W Bechtel, 10.1007/s11229-014-0480-8Synthese. 193Bechtel, W. (2016). Investigating neural representations: the tale of place cells. Synthese, 193, 1287- 1321. DOI: https://doi.org/10.1007/s11229-014-0480-8</p>
<p>A Computational Model of Visual Recognition Memory via Grid Cells. A Bicanski, N Burgess, 10.1016/j.cub.2019.01.077Current Biology. 29Bicanski, A., &amp; Burgess, N. (2019). A Computational Model of Visual Recognition Memory via Grid Cells. Current Biology, 29, 979-990. DOI: https://doi.org/10.1016/j.cub.2019.01.077</p>
<p>Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. T Bliss, T Lomo, 10.1113/jphysiol.1973.sp010273J. Physiol. 232Bliss, T., &amp; Lomo, T. (1973). Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. J. Physiol., 232(1973), 331-356. DOI: https://doi.org/10.1113/jphysiol.1973.sp010273</p>
<p>Cognitive and Brain Development: Executive Functions, Piaget, and the Prefrontal Cortex. S Bolton, J Hattie, Arch. Psychol. 13Bolton, S., &amp; Hattie, J. (2017). Cognitive and Brain Development: Executive Functions, Piaget, and the Prefrontal Cortex. Arch. Psychol, 1, 3.</p>
<p>Towards neuro-inspired symbolic models of cognition: linking neural dynamics to behaviors through asynchronous communications. P Bonzon, 10.1007/s11571-017-9435-3Cogn Neurodyn. 114Bonzon, P. (2017). Towards neuro-inspired symbolic models of cognition: linking neural dynamics to behaviors through asynchronous communications. Cogn Neurodyn, 11(4), 327-353. DOI: https://doi. org/10.1007/s11571-017-9435-3</p>
<p>Symbolic modeling of asychronous neural dynamics reveal potential synchronous roots of awareness. P Bonzon, 10.3389/fncom.2019.00001Front. Comput. Neurosci. DOI. Bonzon, P. (2019). Symbolic modeling of asychronous neural dynamics reveal potential synchronous roots of awareness. Front. Comput. Neurosci. DOI: https://doi.org/10.3389/fncom.2019.00001</p>
<p>Modeling the synchronization of multimodal perceptions as a basis for the emergence of deterministic behaviors. P Bonzon, 10.3389/fnbot.2020.570358Front. Neurorobot. DOI. Bonzon, P. (2020). Modeling the synchronization of multimodal perceptions as a basis for the emergence of deterministic behaviors. Front. Neurorobot. DOI: https://doi.org/10.3389/fnbot.2020.570358</p>
<p>. P Bonzon, M Cavalcanti, 10.1007/978-94-015-9397-7Formal Aspects of Context. Applied Logic Series. &amp; Nossum, R.20Kluver Academic PublBonzon, P., Cavalcanti, M., &amp; Nossum, R. (eds.) (2000). Formal Aspects of Context. Applied Logic Series, 20, Kluver Academic Publ. DOI: https://doi.org/10.1007/978-94-015-9397-7</p>
<p>A step-by-step tutorial on using the cognitive architecture ACT-R in combination with fMRI data. J P Borst, J R Anderson, 10.1016/j.jmp.2016.05.005Journal of Mathematical Psychology. 76Part BBorst, J. P., &amp; Anderson, J. R. (2017). A step-by-step tutorial on using the cognitive architecture ACT-R in combination with fMRI data. Journal of Mathematical Psychology, 76(Part B), 94-103. DOI: https://doi. org/10.1016/j.jmp.2016.05.005</p>
<p>The development of object-permanence: Some studies of existence constancy. T Bower, 10.3758/BF03208778Perception &amp; Psychophysics. 2Bower, T. (1967). The development of object-permanence: Some studies of existence constancy. Perception &amp; Psychophysics, 2, 411-418. DOI: https://doi.org/10.3758/BF03208778</p>
<p>The effects of motor skill on object permanence. T Bower, J Wishart, 10.1016/0010-0277(72)90017-0Cognition. 12-3Bower, T., &amp; Wishart, J. (1972). The effects of motor skill on object permanence. Cognition, 1(2-3), 165- 172. DOI: https://doi.org/10.1016/0010-0277(72)90017-0</p>
<p>Simulation of networks of spiking neurons, A review of tools &amp; strategies. R Brette, 10.1007/s10827-007-0038-6J. Computional Neuroscience. 23Brette, R., et al. (2007). Simulation of networks of spiking neurons, A review of tools &amp; strategies. J. Computional Neuroscience, 23, 349-398. DOI: https://doi.org/10.1007/s10827-007-0038-6</p>
<p>Intelligence without representation. R Brooks, 10.1016/0004-3702(91)90053-M1016/0004-3702(91)90053-MArtificial Intelligence. 47Brooks, R. (1991). Intelligence without representation. Artificial Intelligence, 47, 139-159. DOI: https://doi. org/10.1016/0004-3702(91)90053-M</p>
<p>From circuits to behavior: a bridge too far? Nature neurosci. M Carandini, 10.1038/nn.304315Carandini, M. (2012). From circuits to behavior: a bridge too far? Nature neurosci., 15(4), 505-507. DOI: https://doi.org/10.1038/nn.3043</p>
<p>Understanding the consequences. T J Carew, 10.1038/417803aNature New &amp; Views. 407NeurologyCarew, T. J. (2002). Neurology, Understanding the consequences. Nature New &amp; Views, 407, 803-806. DOI: https://doi.org/10.1038/417803a</p>
<p>Beyond Single-Level Accounts: The Role of Cognitive Architectures in Cognitive Scientific Explanation. R Cooper, D Peebles, 10.1111/tops.12132Topics in Cogn. Sci. 72Cooper, R., &amp; Peebles, D. (2015). Beyond Single-Level Accounts: The Role of Cognitive Architectures in Cognitive Scientific Explanation. Topics in Cogn. Sci., 7(2), 243-258. DOI: https://doi.org/10.1111/tops.12132</p>
<p>The descent of man, and selection in relation to sex. C Darwin, 10.5962/bhl.title.24784Darwin, C. (1871). The descent of man, and selection in relation to sex. John Murray. DOI: https://doi. org/10.5962/bhl.title.24784</p>
<p>Looking closely at infants' performance and experimental procedures in the A-not-B task. A Diamond, 10.1017/S0140525X01253916Behav Brain Sci. 241Diamond, A. (2001). Looking closely at infants' performance and experimental procedures in the A-not-B task. Behav Brain Sci, 24(1), 39-42. DOI: https://doi.org/10.1017/S0140525X01253916</p>
<p>A Theory of the Discovery and Predication of Relational Concepts. L Doumas, J Hummel, C Sandhofer, 10.1037/0033-295X.115.1.1Psychological Review. 115Doumas, L., Hummel, J., &amp; Sandhofer, C. (2008). A Theory of the Discovery and Predication of Relational Concepts. Psychological Review, 115, 1-43. DOI: https://doi.org/10.1037/0033-295X.115.1.1</p>
<p>How to think about mental content. F Egan, 10.1007/s11098-013-0172-0s11098-013-0172-0Philos Stud. 170Egan, F. (2014). How to think about mental content. Philos Stud, 170, 115-135. DOI: https://doi. org/10.1007/s11098-013-0172-0</p>
<p>A deflationary account of mental representations. F Egan, 10.1093/oso/9780190686673.003.0002What are Mental Representations. J. Smortchkova, et al.Oxford Univ. PressEgan, F. (2020). A deflationary account of mental representations. In J. Smortchkova, et al. (Eds.), What are Mental Representations? Oxford Univ. Press. DOI: https://doi.org/10.1093/ oso/9780190686673.003.0002</p>
<p>Model-based cognitive neuroscience, a conceptual introduction. B Forstmann, E Wagenmakers, 10.1007/978-1-4939-2236-9B. Forstmann, &amp; E.-J. WagenmakersSpringerAn introduction to model-based cognitive neuroscienceForstmann, B., &amp; Wagenmakers, E. (2015). Model-based cognitive neuroscience, a conceptual introduction. In B. Forstmann, &amp; E.-J. Wagenmakers, (Eds.), An introduction to model-based cognitive neuroscience, Springer. DOI: https://doi.org/10.1007/978-1-4939-2236-9</p>
<p>Linking across levels of computation in model-based cognitive neuroscience. M J Frank, 10.1007/978-1-4939-2236-9_8B. Forstmann, &amp; E.-J. WagenmakersSpringerAn introduction to model-based cognitive neuroscienceFrank, M. J. (2015). Linking across levels of computation in model-based cognitive neuroscience. In B. Forstmann, &amp; E.-J. Wagenmakers, (Eds.), An introduction to model-based cognitive neuroscience, Springer. DOI: https://doi.org/10.1007/978-1-4939-2236-9_8</p>
<p>How cognitive theory guides neuroscience. M J Frank, D Badre, 10.1016/j.cognition.2014.11.009Cognition. 135Frank, M. J., &amp; Badre, D. (2015). How cognitive theory guides neuroscience. Cognition, 135, 14-20. DOI: https://doi.org/10.1016/j.cognition.2014.11.009</p>
<p>Big data and the industrialization of neuroscience: A safe roadmap for understanding the brain?. Y Frégnac, 10.1126/science.aan8866Science. 3586362Frégnac, Y. (2017). Big data and the industrialization of neuroscience: A safe roadmap for understanding the brain? Science, 358(6362), 470-477. DOI: https://doi.org/10.1126/science.aan8866</p>
<p>Cortical Correlates of Low-Level Perception: From Neural Circuits to Percepts. Y Frégnac, B Bathellier, 10.1016/j.neuron.2015.09.041Neuron. 88Frégnac, Y., &amp; Bathellier, B. (2015). Cortical Correlates of Low-Level Perception: From Neural Circuits to Percepts. Neuron, 88. DOI: https://doi.org/10.1016/j.neuron.2015.09.041</p>
<p>Mental Representations, Psychology of. C Gallistel, 10.1016/B0-08-043076-7/01488-1International Encyclopedia of the Social &amp; Behavioral Sciences. ElsevierGallistel, C. (2001). Mental Representations, Psychology of. In: International Encyclopedia of the Social &amp; Behavioral Sciences, Elsevier. DOI: https://doi.org/10.1016/B0-08-043076-7/01488-1</p>
<p>Learning and Representation. C Gallistel, 10.1016/B978-0-12-809324-5.21009-2Learning and Memory: A Comprehensive Reference. Elsevier2nd ed.Gallistel, C. (2017). Learning and Representation. In: Learning and Memory: A Comprehensive Reference, 2nd ed. Elsevier. DOI: https://doi.org/10.1016/B978-0-12-809324-5.21009-2</p>
<p>The physical basis of memory. C Gallistel, 10.1016/j.cognition.2020.104533Cognition. 213Gallistel, C. (2021). The physical basis of memory. Cognition, 213. DOI: https://doi.org/10.1016/j. cognition.2020.104533</p>
<p>Context-dependent learning and causal structure. S Gershman, 10.3758/s13423-016-1110-xPsychon Bull Rev. 24Gershman, S. (2017) Context-dependent learning and causal structure. Psychon Bull Rev, 24, 557-565. DOI: https://doi.org/10.3758/s13423-016-1110-x</p>
<p>W Gerstner, W Kistler, 10.1017/CBO9780511815706Spiking Neuron Models: Single Neurons, Populations, Plasticity. Cambridge University PressGerstner, W., &amp; Kistler, W. (2002). Spiking Neuron Models: Single Neurons, Populations, Plasticity. Cambridge University Press. DOI: https://doi.org/10.1017/CBO9780511815706</p>
<p>The cellular basis of classical conditioning in Aplysia californica -it's less simple than you think. D L Glanzman, 10.1016/0166-2236(95)93947-VTrends in Neurosciences. 1893947Glanzman, D. L. (1995). The cellular basis of classical conditioning in Aplysia californica -it's less simple than you think. Trends in Neurosciences, 18, 30-36. DOI: https://doi.org/10.1016/0166- 2236(95)93947-V</p>
<p>Bridging Single Neuron Dynamics to Global Brain States. J Goldman, 10.3389/fnsys.2019.00075Front. Syst. Neurosci. DOI. Goldman, J., et al. (2019). Bridging Single Neuron Dynamics to Global Brain States. Front. Syst. Neurosci. DOI: https://doi.org/10.3389/fnsys.2019.00075</p>
<p>Representational Genera. J Haugeland, Philosophy and Connectionist Theory. W. Ramsey, S. Stich &amp; D. RumelhartErlbaum, New JerseyHaugeland, J. (1991). 'Representational Genera'. In W. Ramsey, S. Stich &amp; D. Rumelhart (Eds.), Philosophy and Connectionist Theory, 61-90. Erlbaum, New Jersey.</p>
<p>Strategic Cognitive Sequencing: A Computational Cognitive Neuroscience Approach. S Herd, K Krueger, T Kriete, T R Huang, T Hazy, R C Reilly, 10.1155/2013/149329Computational Intelligence and Neuroscience. Herd, S., Krueger, K., Kriete, T., Huang, T. R., Hazy, T., &amp; O'Reilly, R. C. (2013). Strategic Cognitive Sequencing: A Computational Cognitive Neuroscience Approach. Computational Intelligence and Neuroscience, vol 2013. DOI: https://doi.org/10.1155/2013/149329</p>
<p>Simple minds: a qualified defence of associative learning. C Heyes, 10.1098/rstb.2012.0217Phil. Trans. R. Soc. B. 367Heyes, C. (2012) Simple minds: a qualified defence of associative learning. Phil. Trans. R. Soc. B, 367, 2695-2703. DOI: https://doi.org/10.1098/rstb.2012.0217</p>
<p>A fast learning algorithm for deep beliefs net. G E Hinton, 10.1162/neco.2006.18.7.1527Neural Computation. 187Hinton, G. E., et al. (2006). A fast learning algorithm for deep beliefs net. Neural Computation, 18(7), 1527-1554. DOI: https://doi.org/10.1162/neco.2006.18.7.1527</p>
<p>A quantitative description of membrane current &amp; its application to conduction &amp; excitation in nerve. A L Hodgkin, A F Huxley, 10.1113/jphysiol.1952.sp004764Journal of Physiology. 174Hodgkin, A. L., &amp; Huxley, A. F. (1952). A quantitative description of membrane current &amp; its application to conduction &amp; excitation in nerve. Journal of Physiology, 17(4), 500-544. DOI: https://doi.org/10.1113/ jphysiol.1952.sp004764</p>
<p>Neural networks and physical systems with emergent collective computational abilities. J J Hopfield, 10.1073/pnas.79.8.2554Proceedings of the National Academy of Sciences of the USA. the National Academy of Sciences of the USA79Hopfield, J. J. (1982). Neural networks and physical systems with emergent collective computational abilities", Proceedings of the National Academy of Sciences of the USA, 79(8), 2554-2558. DOI: https://doi.org/10.1073/pnas.79.8.2554</p>
<p>Relational Reasoning in a Neurally Plausible Cognitive Architecture. J E Hummel, K J Holyoak, 10.1111/j.0963-7214.2005.00350.xCurrent Directions in Psychological Science. 14Hummel, J. E., &amp; Holyoak, K. J. (2005). Relational Reasoning in a Neurally Plausible Cognitive Architecture. Current Directions in Psychological Science, 14, 153-157. DOI: https://doi.org/10.1111/j.0963- 7214.2005.00350.x</p>
<p>Deflating Deflationism about Mental Representations. D Hutto, E Myin, 10.1093/oso/9780190686673.003.0004What are Mental Representations. J. Smortchkova, et al.Oxford Univ. PressHutto, D., &amp; Myin, E. (2020). Deflating Deflationism about Mental Representations. In: J. Smortchkova, et al. (Eds.), What are Mental Representations? Oxford Univ. Press. DOI: https://doi.org/10.1093/ oso/9780190686673.003.0004</p>
<p>A review of cell assemblies. C Huyck, P Passmore, 10.1007/s00422-013-0555-5Biol Cybern. 1073Huyck, C., &amp; Passmore, P. (2013). A review of cell assemblies. Biol Cybern, 107(3), 263-288. DOI: https:// doi.org/10.1007/s00422-013-0555-5</p>
<p>SAL: An explicitly pluralistic cognitive architecture. D Jilk, C Lebiere, R O&apos;reilly, J R Anderson, 10.1080/09528130802319128Journal of Experimental and Theoretical Artificial Intelligence. 203Jilk, D., Lebiere, C., O'Reilly, R., &amp; Anderson, J. R. (2008). SAL: An explicitly pluralistic cognitive architecture. Journal of Experimental and Theoretical Artificial Intelligence, 20(3), 197-218. DOI: https://doi.org/10.1080/09528130802319128</p>
<p>. 10.1007/BF003372884343, 59-69. DOI: https://doi.org/10.1007/BF00337288</p>
<p>Cognitive computational neuroscience. N Kriegeskorte, P Douglas, 10.1038/s41593-018-0210-5Nature Neurosci. 21Kriegeskorte, N., &amp; Douglas, P. (2018). Cognitive computational neuroscience. Nature Neurosci., 21, 1148-1160. DOI: https://doi.org/10.1038/s41593-018-0210-5</p>
<p>J Letzkus, S Wolff, A Lüthi, 10.1016/j.neuron.2015.09.024Disinhibition, a Circuit Mechanism for Associative Learning &amp; Memory. 88Letzkus, J., Wolff, S., &amp; Lüthi, A. (2015). Disinhibition, a Circuit Mechanism for Associative Learning &amp; Memory. Neuron, 88(2), 264-276. DOI: https://doi.org/10.1016/j.neuron.2015.09.024</p>
<p>Locations in the Neocortex: A Theory of Sensorimotor Object Recognition Using Cortical Grid Cells. M Lewis, S Purdy, S Ahmad, J Hawkins, 10.3389/fncir.2019.00022Front. Neural Circuits. 1322Lewis, M., Purdy, S., Ahmad, S., &amp; Hawkins, J. (2019). Locations in the Neocortex: A Theory of Sensorimotor Object Recognition Using Cortical Grid Cells. Front. Neural Circuits, 13, 22. DOI: https:// doi.org/10.3389/fncir.2019.00022</p>
<p>Optogenetic stimulation of a hippocampal engram activates fear memory recall. X Liu, 10.1038/nature11028Nature. 4847394Liu, X., et al. (2012). Optogenetic stimulation of a hippocampal engram activates fear memory recall. Nature, 484(7394), 381-5. DOI: https://doi.org/10.1038/nature11028</p>
<p>The algorithmic Level is the Bridge between Computation and Brain. B Love, 10.1111/tops.12131Topics in Cogn. Scie. 72Love, B. (2015). The algorithmic Level is the Bridge between Computation and Brain. Topics in Cogn. Scie, 7(2), 230-242. DOI: https://doi.org/10.1111/tops.12131</p>
<p>Linking Neurons to Behavior in Multisensory Perception: A Computational Review. W Ma, A Pouget, 10.1016/j.brainres.2008.04.082Brain Research. 1242Ma, W., &amp; Pouget, A. (2008). Linking Neurons to Behavior in Multisensory Perception: A Computational Review. Brain Research, 1242, 4-12. DOI: https://doi.org/10.1016/j.brainres.2008.04.082</p>
<p>Regulation of synaptic efficacy by coincidence of postsynaptic. H Markram, J Lubke, M Frotscher, B Sakmann, 10.1126/science.275.5297.213APs &amp; EPSPs. Science. 275Markram, H., Lubke, J., Frotscher, M., &amp; Sakmann, B. (1997). Regulation of synaptic efficacy by coincidence of postsynaptic APs &amp; EPSPs. Science, 275, 213-215. DOI: https://doi.org/10.1126/ science.275.5297.213</p>
<p>Reconstruction &amp; Simulation of Neocortical Microcircuitry. H Markram, 10.1016/j.cell.2015.09.029Cell. 163Markram, H, et al. (2015). Reconstruction &amp; Simulation of Neocortical Microcircuitry. Cell, 163, 456-492. DOI: https://doi.org/10.1016/j.cell.2015.09.029</p>
<p>Vision: A Computational Approach. D Marr, Freeman &amp; CoMarr, D. (1982). Vision: A Computational Approach. Freeman &amp; Co.</p>
<p>From Understanding Computation to Understanding Neural Circuitry" In Neuronal Mechanisms in Visual Perception. D Marr, T Poggio, Neurosciences Res. Prog. Bull. E. Poppel, R. Heldand, J. E. Dowling15Marr, D., &amp; Poggio, T. (1977). "From Understanding Computation to Understanding Neural Circuitry" In Neuronal Mechanisms in Visual Perception. In E. Poppel, R. Heldand, J. E. Dowling (Eds.), Neurosciences Res. Prog. Bull., 15, 470-488.</p>
<p>A logical calculus of the ideas immanent in nervous activity. W Mcculloch, W Pitts, 10.1007/BF02478259Bulletin of Mathematical Biophysics. 7McCulloch, W., &amp; Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. Bulletin of Mathematical Biophysics, 7, 115-133. DOI: https://doi.org/10.1007/BF02478259</p>
<p>Is a field theory of perseverative reaching compatible with a Piagetian view. L Mccune, 10.1017/S0140525X01383917Behav Brain Sci. 24153McCune, L. (2001). Is a field theory of perseverative reaching compatible with a Piagetian view? Behav Brain Sci, 24(1), 53. DOI: https://doi.org/10.1017/S0140525X01383917</p>
<p>Place cells, grid cells, and the brain's spatial representation system. E I Moser, E Kropff, M.-B Moser, 10.1146/annurev.neuro.31.061307.090723Annual. Review Neuroscience. 31Moser, E. I., Kropff, E., &amp; Moser, M.-B. (2008). Place cells, grid cells, and the brain's spatial representation system. Annual. Review Neuroscience, 31. DOI: https://doi.org/10.1146/annurev. neuro.31.061307.090723</p>
<p>A metric for space. E I Moser, M.-B Moser, 10.1002/hipo.20483Hippocampus. 18Moser, E. I., &amp; Moser, M.-B. (2008). A metric for space. Hippocampus, 18, 1142-1156. DOI: https://doi. org/10.1002/hipo.20483</p>
<p>Perceptual decision neurosciences -A modelbased review. M J Mulder, L Van Maanen, B J Forstmann, 10.1016/j.neuroscience.2014.07.031Neuroscience. 277Mulder, M. J., van Maanen, L., &amp; Forstmann, B. J. (2014). Perceptual decision neurosciences -A model- based review. Neuroscience, 277, 872-884. DOI: https://doi.org/10.1016/j.neuroscience.2014.07.031</p>
<p>Objectivity, intentionality, and levels of explanation. U Müller, J Carpendale, 10.1017/S0140525X01413914Behav Brain Sci. 241Müller, U., &amp; Carpendale, J. (2001). Objectivity, intentionality, and levels of explanation. Behav Brain Sci, 24(1), 56-57. DOI: https://doi.org/10.1017/S0140525X01413914</p>
<p>Infant perseverative and implications for object permanence theories: A DP model of the A-not-B task. Y Munakata, 10.1111/1467-7687.00021Develop. Sci. 1Munakata, Y. (1998). Infant perseverative and implications for object permanence theories: A DP model of the A-not-B task. Develop. Sci, 1, 161-84. DOI: https://doi.org/10.1111/1467-7687.00021</p>
<p>Symbolic Architectures for Cognition. A Newell, P Rosenbloom, J Laird, 10.21236/ADA222909Foundations of cognitive sciences. M. PosnerMIT PressNewell, A., Rosenbloom, P., &amp; Laird, J. (1989). Symbolic Architectures for Cognition. In M. Posner (ed), Foundations of cognitive sciences. MIT Press. DOI: https://doi.org/10.21236/ADA222909</p>
<p>Situated Mental Representations. A Newen, G Vosgerau, 10.1093/oso/9780190686673.003.0007What are Mental Representations. J. Smortchkova, et al.Oxford Univ. PressNewen, A., &amp; Vosgerau, G. (2020). Situated Mental Representations. In J. Smortchkova, et al. (Eds.), What are Mental Representations? Oxford Univ. Press. DOI: https://doi.org/10.1093/ oso/9780190686673.003.0007</p>
<p>The hippocampus as a spatial map: Preliminary evidence from unit activity in the freely-moving rat. J O&apos;keefe, J Dostrovsky, 10.1016/0006-8993(71)90358-1Brain Research. 341O'Keefe, J., &amp; Dostrovsky, J. (1971). The hippocampus as a spatial map: Preliminary evidence from unit activity in the freely-moving rat. Brain Research, 34(1), 171-5. DOI: https://doi.org/10.1016/0006- 8993(71)90358-1</p>
<p>Computational Explorations in Cognitive Neuroscience. R O&apos;reilly, Y Munakata, 10.7551/mitpress/2014.001.0001MIT PressO'Reilly, R., &amp; Munakata, Y. (2000). Computational Explorations in Cognitive Neuroscience. MIT Press. DOI: https://doi.org/10.7551/mitpress/2014.001.0001</p>
<p>Representing as Coordinating with Absence. N Orlandi, 10.1093/oso/9780190686673.003.0005J. Smortchkova, et al.Oxford Univ. PressWhat are Mental Representations?Orlandi, N. (2020). Representing as Coordinating with Absence. In J. Smortchkova, et al. (Eds.) What are Mental Representations? Oxford Univ. Press. DOI: https://doi.org/10.1093/ oso/9780190686673.003.0005</p>
<p>Model-based cognitive neuroscience. T Palmieri, 10.1016/j.jmp.2016.10.010J. Math. Psychol. 76Palmieri, T, et al. (2017). Model-based cognitive neuroscience. J. Math. Psychol. 76(B), 59-64. DOI: https:// doi.org/10.1016/j.jmp.2016.10.010</p>
<p>La naissance de l'intelligence chez l'enfant. Delachaux et Niestlé [english translation: Piaget, J (1952). The origins of intelligence in children. J Piaget, New York International Universities PressPiaget, J. (1936). La naissance de l'intelligence chez l'enfant. Delachaux et Niestlé [english translation: Piaget, J (1952). The origins of intelligence in children, New York International Universities Press].</p>
<p>La construction du réél chez l'enfant. Delachaux et Niestlé [english translation: Piaget, J (1954). The construction of reality in the child. J Piaget, Basic BooksPiaget, J. (1937). La construction du réél chez l'enfant. Delachaux et Niestlé [english translation: Piaget, J (1954). The construction of reality in the child, Basic Books].</p>
<p>The level of understandings framework, revised. Perception. T Poggio, 10.1068/p729941Poggio, T. (2012), The level of understandings framework, revised. Perception, 41(9), 1007-23. DOI: https://doi.org/10.1068/p7299</p>
<p>On the research of time past: the hunt for the substrate of memory. J Queenan, 10.1111/nyas.13348Ann. N.Y. Acad. Sci. 1396Queenan, J., et al. (2017). On the research of time past: the hunt for the substrate of memory. Ann. N.Y. Acad. Sci., 1396, 108-125. DOI: https://doi.org/10.1111/nyas.13348</p>
<p>The onset of representation and entry into stage 6 of object permanence development. D Ramsay, J Campos, 10.1037/0012-1649.14.1.79Developmental Psychology. 52Ramsay, D., &amp; Campos, J. (1978) The onset of representation and entry into stage 6 of object permanence development. Developmental Psychology, 52, 785-97. DOI: https://doi. org/10.1037/0012-1649.14.1.79</p>
<p>Untangling two questions about mental representation. W Ramsey, 10.1016/j.newideapsych.2015.01.004New Ideas in Psychol. 40Ramsey, W. (2016). Untangling two questions about mental representation. New Ideas in Psychol., 40, 3-12. DOI: https://doi.org/10.1016/j.newideapsych.2015.01.004</p>
<p>Defending representation realism. W Ramsey, 10.1093/oso/9780190686673.003.0003J. Smortchkova, et al.Oxford Univ. PressWhat are Mental Representations?Ramsey, W. (2020). Defending representation realism. In J. Smortchkova, et al. (Eds.) What are Mental Representations? Oxford Univ. Press. DOI: https://doi.org/10.1093/oso/9780190686673.003.0003</p>
<p>Understanding A-not-B errors as a function of object representation and deficits in attention rather than motor memories. T Ruffman, 10.1017/S0140525X01473912Behav Brain Sci. 24161Ruffman, T. (2001). Understanding A-not-B errors as a function of object representation and deficits in attention rather than motor memories. Behav Brain Sci, 24(1), 61. DOI: https://doi.org/10.1017/ S0140525X01473912</p>
<p>Parallel Distributed Processing: Explorations in the Microstructure of Cognition. D Rumelhart, J Mcclelland, 10.7551/mitpress/5236.001.0001Foundations. 1MIT PressRumelhart, D., &amp; McClelland, J. (1986). Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations. Cambridge, MIT Press. DOI: https://doi.org/10.7551/ mitpress/5236.001.0001</p>
<p>Engram cells retain memory under retrograde amnesia. T J Ryan, D S Roy, M Pignatelli, 10.1126/science.aaa5542Science. 348Ryan, T. J., Roy, D. S., &amp; Pignatelli, M., et al. (2015). Engram cells retain memory under retrograde amnesia. Science, 348, 1007-1013. DOI: https://doi.org/10.1126/science.aaa5542</p>
<p>Using Dynamic Field Theory to Rethink Infant Habituation. E Schöner, G Thelen, 10.1037/0033-295X.113.2.273Psych. Review. 1132Schöner, E., &amp; Thelen, G. (2006). Using Dynamic Field Theory to Rethink Infant Habituation. Psych. Review, 113(2), 273-299. DOI: https://doi.org/10.1037/0033-295X.113.2.273</p>
<p>Visual binding through reentrant connectivity and dynamic synchronization in a brain-based device. A Seth, J Mckinstry, G Edelman, J Krichmar, 10.1093/cercor/bhh079Cerebral Cortex. 14Seth, A., McKinstry, J., Edelman, G., &amp; Krichmar, J. (2004). Visual binding through reentrant connectivity and dynamic synchronization in a brain-based device. Cerebral Cortex, 14, 1185-1199. DOI: https:// doi.org/10.1093/cercor/bhh079</p>
<p>From simple associations to systematic reasoning: A connectionist representation of rules, variables and dynamic bindings using temporal synchrony. L Shastri, V Ajjanagadde, 10.1017/S0140525X00030910Behav. Brain Sci. 163Shastri, L., &amp; Ajjanagadde, V. (1993). From simple associations to systematic reasoning: A connectionist representation of rules, variables and dynamic bindings using temporal synchrony. Behav. Brain Sci, 16(3), 417-494. DOI: https://doi.org/10.1017/S0140525X00030910</p>
<p>The dynamics of embodiment: a field theory of infant perseverative reaching. J Smortchkova, 10.1017/S0140525X01003910Behav Brain Sci. 241Oxford Univ. Press ThelenWhat are Mental Representations?Smortchkova, J, et al., eds. (2020). What are Mental Representations? Oxford Univ. Press Thelen, E., Schöner, G., Scheier, C., &amp; Smith, L. B. (2001). The dynamics of embodiment: a field theory of infant perseverative reaching. Behav Brain Sci, 24(1), 1-34. DOI: https://doi.org/10.1017/ S0140525X01003910</p>
<p>A dynamics systems approach to the development of perception and action. E Thelen, L B. ; M Smith, 10.1523/JNEUROSCI.3336-17.2018J. Neurosci. 3832MIT Press TomovNeural Computations Underlying Causal Structure LearningThelen, E., &amp; Smith, L. B. (1994). A dynamics systems approach to the development of perception and action. MIT Press Tomov, M., et al. (2018). Neural Computations Underlying Causal Structure Learning. J. Neurosci., 38(32), 7143-57. DOI: https://doi.org/10.1523/JNEUROSCI.3336-17.2018</p>
<p>Memory engram storage and retrieval. S Tonegawa, 10.1016/j.conb.2015.07.009Current Opinion in Neurobiology. 35Tonegawa, S., et al. (2015). Memory engram storage and retrieval. Current Opinion in Neurobiology, 35, 109-111. DOI: https://doi.org/10.1016/j.conb.2015.07.009</p>
<p>Constraining cognitive abstractions through Bayesian modeling. B Turner, 10.1007/978-1-4939-2236-9_10B. U. Forstmann, &amp; E.-J. WagenmakersSpringerAn introduction to model-based cognitive neuroscienceTurner, B. (2015). Constraining cognitive abstractions through Bayesian modeling. In B. U. Forstmann, &amp; E.-J. Wagenmakers (Eds.), An introduction to model-based cognitive neuroscience, 199-220 Springer. DOI: https://doi.org/10.1007/978-1-4939-2236-9_10</p>
<p>Approaches to analysis in model-based cognitive neuroscience. B M Turner, 10.1016/j.jmp.2016.01.001J. of Math. Psychol. Feb. 76Turner, B. M., et al. (2017). Approaches to analysis in model-based cognitive neuroscience. J. of Math. Psychol. Feb, 76(B), 65-79. DOI: https://doi.org/10.1016/j.jmp.2016.01.001</p>
<p>The necessity of connection structures in neural models of variable binding. F Van Der Velde, M De Kamps, 10.1007/s11571-015-9331-7Cogn Neurodyn. 9Van der Velde, F., &amp; de Kamps, M. (2015). The necessity of connection structures in neural models of variable binding. Cogn Neurodyn, 9, 359-37. DOI: https://doi.org/10.1007/s11571-015-9331-7</p>
<p>The dynamical hypothesis in cognitive science. T Van Gelder, 10.1017/S0140525X98001733Behav. Brain. Sci. 21Van Gelder, T. (1998). The dynamical hypothesis in cognitive science. Behav. Brain. Sci, 21, 1-14. DOI: https://doi.org/10.1017/S0140525X98001733</p>
<p>The Perceptual Nature of Mental Models. G Vosgerau, 10.1016/S0166-4115(06)80039-7Advances in Psychology. 138Vosgerau, G. (2006). The Perceptual Nature of Mental Models. Advances in Psychology, 138, 255-275. DOI: https://doi.org/10.1016/S0166-4115(06)80039-7</p>
<p>Memory and Content. G Vosgerau, 10.1016/j.concog.2010.06.021Consciousness and Cognition. 19Vosgerau, G. (2010). Memory and Content. Consciousness and Cognition, 19, 838-46. DOI: https://doi. org/10.1016/j.concog.2010.06.021</p>
<p>Understanding Visual Attention With RAGNAROC: A Reflexive Attention Gradient Through Neural AttRactOr Competition. B Wyble, 10.1037/rev0000245Psych. Review. 1266Wyble, B., et al. (2020). Understanding Visual Attention With RAGNAROC: A Reflexive Attention Gradient Through Neural AttRactOr Competition. Psych. Review., 126(6), 1163-1198. DOI: https://doi. org/10.1037/rev0000245</p>
<p>Competing Neural Ensembles in Motor Cortex Gate Goal-Directed Motor Output. E Zagha, X Ge, D Mccormick, 10.1016/j.neuron.2015.09.044Neuron. 883Zagha, E., Ge, X., &amp; McCormick, D. (2015). Competing Neural Ensembles in Motor Cortex Gate Goal- Directed Motor Output. Neuron, 88(3), 565-577. DOI: https://doi.org/10.1016/j.neuron.2015.09.044</p>
<p>A massively asynchronous, parallel brain. S Zeki, 10.1098/rstb.2014.0174Phil. Tran. R. Soc. B. 370Zeki, S. (2015). A massively asynchronous, parallel brain. Phil. Tran. R. Soc. B, 370, 20140174. DOI: https:// doi.org/10.1098/rstb.2014.0174</p>            </div>
        </div>

    </div>
</body>
</html>