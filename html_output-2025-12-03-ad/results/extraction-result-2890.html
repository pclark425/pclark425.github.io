<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2890 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2890</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2890</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-72.html">extraction-schema-72</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-271050358</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2407.04960v1.pdf" target="_blank">MemoCRS: Memory-enhanced Sequential Conversational Recommender Systems with Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues. However, most existing CRS models mainly focus on dialogue comprehension and preferences mining from the current dialogue session, overlooking user preferences in historical dialogue sessions. The preferences embedded in the user's historical dialogue sessions and the current session exhibit continuity and sequentiality, and we refer to CRSs with this characteristic as sequential CRSs. In this work, we leverage memory-enhanced LLMs to model the preference continuity, primarily focusing on addressing two key issues: (1) redundancy and noise in historical dialogue sessions, and (2) the cold-start users problem. To this end, we propose a Memory-enhanced Conversational Recommender System Framework with Large Language Models (dubbed MemoCRS) consisting of user-specific memory and general memory. User-specific memory is tailored to each user for their personalized interests and implemented by an entity-based memory bank to refine preferences and retrieve relevant memory, thereby reducing the redundancy and noise of historical sessions. The general memory, encapsulating collaborative knowledge and reasoning guidelines, can provide shared knowledge for users, especially cold-start users. With the two kinds of memory, LLMs are empowered to deliver more precise and tailored recommendations for each user. Extensive experiments on both Chinese and English datasets demonstrate the effectiveness of MemoCRS.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Expel: Llm agents are experiential learners. <em>(Rating: 2)</em></li>
                <li>Mot: Memory-of-thought enables chatgpt to self-improve. <em>(Rating: 2)</em></li>
                <li>Memorybank: Enhancing large language models with long-term memory. <em>(Rating: 2)</em></li>
                <li>Large Language Models Are Semi-Parametric Reinforcement Learning Agents. <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior. <em>(Rating: 1)</em></li>
                <li>Memgpt: Towards llms as operating systems. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2890",
    "paper_id": "paper-271050358",
    "extraction_schema_id": "extraction-schema-72",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Expel: Llm agents are experiential learners.",
            "rating": 2,
            "sanitized_title": "expel_llm_agents_are_experiential_learners"
        },
        {
            "paper_title": "Mot: Memory-of-thought enables chatgpt to self-improve.",
            "rating": 2,
            "sanitized_title": "mot_memoryofthought_enables_chatgpt_to_selfimprove"
        },
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory.",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents.",
            "rating": 2,
            "sanitized_title": "large_language_models_are_semiparametric_reinforcement_learning_agents"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior.",
            "rating": 1,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Memgpt: Towards llms as operating systems.",
            "rating": 1,
            "sanitized_title": "memgpt_towards_llms_as_operating_systems"
        }
    ],
    "cost": 0.0083035,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MemoCRS: Memory-enhanced Sequential Conversational Recommender Systems with Large Language Models
6 Jul 2024</p>
<p>Yunjia Xi xiyunjia@sjtu.edu.cn 
Shanghai Jiao Tong University Shanghai
China</p>
<p>Weiwen Liu</p>
<p>Huawei Noah's Ark Lab Shenzhen
Jianghao LinChina</p>
<p>Shanghai Jiao Tong University Shanghai
Bo ChenChina</p>
<p>Huawei Noah's Ark Lab Shenzhen
China Ruiming Tang</p>
<p>Weinan Zhang
Huawei Noah's Ark Lab Shenzhen
China</p>
<p>Shanghai Jiao Tong University Shanghai
China</p>
<p>Yong Yu</p>
<p>Shanghai Jiao Tong University Shanghai
China</p>
<p>Conference acronym 'XX
Yunjia Xi et al
03-05, 2018June, WoodstockNY</p>
<p>MemoCRS: Memory-enhanced Sequential Conversational Recommender Systems with Large Language Models
6 Jul 2024862FAAA20EDC7F524BF8EEDAFEF83289arXiv:2407.04960v1[cs.IR]
Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues.However, most existing CRS models mainly focus on dialogue comprehension and preferences mining from the current dialogue session, overlooking user preferences in historical dialogue sessions.The preferences embedded in the user's historical dialogue sessions and the current session exhibit continuity and sequentiality, and we refer to CRSs with this characteristic as sequential CRSs.In this work, we leverage memory-enhanced LLMs to model the preference continuity, primarily focusing on addressing two key issues: (1) redundancy and noise in historical dialogue sessions, and (2) the cold-start users problem.To this end, we propose a Memory-enhanced Conversational Recommender System Framework with Large Language Models (dubbed MemoCRS), consisting of user-specific memory and general memory.User-specific memory is tailored to each user for their personalized interests and implemented by an entity-based memory bank to refine preferences and retrieve relevant memory, thereby reducing the redundancy and noise of historical sessions.The general memory, encapsulating collaborative knowledge and reasoning guidelines, can provide shared knowledge for users, especially cold-start users.With the two kinds of memory, LLMs are empowered to deliver more precise and tailored recommendations for each user.Extensive experiments on both Chinese and English datasets demonstrate the effectiveness of MemoCRS.</p>
<p>INTRODUCTION</p>
<p>Conversational recommender systems (CRSs) engage users in multiturn dialogue, aiming to elicit user preferences and provide personalized recommendations [21,26,50,70,72].Unlike traditional recommendation systems that rely solely on user-item interactions [32,36,64], e.g., clicks and purchases, CRSs can comprehend natural language instructions, gather users' real-time feedback, and figure out user preferences from ongoing conversations.Hence, it is expected to recommend items that exactly match the user's need Figure 1: An example of leveraging the user preference continuity to assist in conversational recommendations.The yellow and green rectangles denote the utterances from the user and the system, respectively.</p>
<p>with human-like responses.To this end, CRSs typically comprise two essential components: a recommender to provide recommendations aligned with user preferences, and a generator to produce natural language responses [9,19,27,56].The completion of both components' functionalities hinges on the system's ability to comprehend dialogue nuances and uncover user preferences accurately.</p>
<p>However, the predominant focus of most CRSs is mainly on dialogue comprehension and preferences mining from the current dialogue session, neglecting user preferences reflected in historical dialogue sessions.Here, a dialogue session refers to a complete multi-turn conversation over a continuous period of time, starting from the user or the system initiating the conversation until the user ends the conversation and leaves [27].As the dialogue serves as the primary medium for communication and recommendation in the conversational recommendation, traditional CRSs typically prioritize enhancing the dialogue comprehension [27] to extract user interests more effectively, such as employing more complex encoders [56,71] or leveraging external information like knowledge graphs (KGs) [7,65,71] and reviews [38,60].However, they tend to overlook the central actors in CRSs, i.e., users, whose behaviors and preferences exhibit continuity across sessions.Actually, preference continuity-the consistent patterns and tendencies in users' behaviors and preferences over time-is critical for recommendation accuracy [27,49].This leads CRSs to exhibit sequentiality and coherence, akin to sequential recommendations [18,23,34,48], which we can refer to as sequential CRSs.In sequential CRSs, users may display varying preferences across sessions, which coexist and interrelate with each other.Incorporating these historical preferences can help us better comprehend the current dialogue session and uncover some nuanced and implicit interests [49].For instance, in Figure 1, if the user's historical sessions reveal a preference for the actress Scarlett Johansson, and now the user asks for sci-fi movies, then sci-fi movies starring Scarlett Johansson, like "Her", would likely align well with the user's demand and preference.</p>
<p>Recently, large language models (LLMs) such as ChatGPT [41] have showcased remarkable proficiency in comprehending and generating natural languages [44,68,74].While there are several explorations of applying LLMs to CRSs, yet none of these works touches upon modeling the user's preference continuity through historical dialogues.They usually focus merely on zero-shot recommendations on the current session [9,55], evaluation of CRSs as user simulators [55,61,62,73], or data augmentation for CRSs [54].Nevertheless, in the realm of conversational agents, researchers leverage the updatable textual memory as a plug-in unit for LLMs to handle long-range dependencies and contexts [35,39,67], as well as modeling user personalities and preferences effectively [37,42,69].Therefore, we, for the first time, propose to bring memory-enhanced LLMs to sequential CRSs, allowing for the modeling of user preference continuity with updatable textual memory mechanisms.</p>
<p>Although the updatable textual memory is a popular choice for plug-and-play, interpretable, transparent, and scalable memory mechanisms of LLMs, it generally suffers from the following two key challenges for LLM-based sequential CRSs.Firstly, the user's historical dialogue sessions usually contain redundant, irrelevant, and noisy information, making it suboptimal to simply build a memory bank over all historical dialogues.As shown in Figure 1, historical sessions can be refined by LLMs into concise preferences knowledge to remove redundancy.Not all the preferences are relevant to the ongoing current conversation where the user is seeking a sci-fi movie.For example, the preference for horror movies may introduce noise as it is irrelevant to the user's current demand.Therefore, it is imperative to refine preferences and retrieve relevant ones.Secondly, the recommendation depends not only on the user's individual preferences but also on the universal knowledge shared among users, e.g., collaborative knowledge.This knowledge necessitates a holistic understanding of data distribution, an aspect LLMs often grapple with.Furthermore, not all users have sufficient historical conversations to establish personalized memory, leading to the problem of cold-start users with limited memory [24].Thus, it is also crucial to preserve general knowledge shared among users.</p>
<p>To tackle the above problems, we propose a Memory-enhanced Conversational Recommender System Framework with Large Language Models (dubbed MemoCRS) to capture the user preference continuity for sequential CRSs.Specifically, we devise two types of textual memory: (1) user-specific memory and (2) general memory.User-specific memory is tailored to each user for individual and personalized preferences.We implement this through an entity-based memory bank, housing entities like item names and attributes mentioned in historical dialogues alongside the associated user attitudes and timestamps.This structured memory bank supports operations such as add, merge, retrieve, and delete.When a new dialogue occurs, LLMs retrieve relevant memories from this bank to assist in recommendations, thereby mitigating redundancy and noise.General memory contains shared and universal knowledge among users that transcends individual dialogues.In our framework, we primarily focus on two core aspects: collaborative knowledge, which contains shared preference patterns among different users, and reasoning guidelines that guide the reasoning process of LLMs.The former is provided by external expert models, while the latter is selfreflectively summarized by LLMs.LLMs can leverage this external and self-summarized knowledge to provide users, especially coldstart users, with suitable recommendations.Finally, incorporating those memories and the current conversation, LLMs are empowered to deliver more precise and tailored recommendations for each user.Our main contributions can be summarized as follows:</p>
<p>â€¢ We emphasize the pivotal role of user preference continuity in sequential CRSs and leverage the textual memory to extract and store user preferences.To the best of our knowledge, this is the first work to explicitly use memory-enhance LLMs to refine and manage user preferences in sequential CRSs.</p>
<p>â€¢ We propose a Memory-enhanced Conversational Recommender</p>
<p>System Framework with Large Language Models (dubbed Mem-oCRS), where two types of memory are devised: user-specific memory for users' personalized preferences and general memory for shared experience and cold-start users, both of which significantly enhance the modeling of user preference continuity.â€¢ The textual memory mechanism in MemoCRS is highly plug-andplay, interpretable, transparent, and scalable for LLMs, ensuring efficient and effective recommendations in sequential CRSs.Extensive experiments on both Chinese and English datasets demonstrate that MemoCRS significantly outperforms traditional and LLM-based baselines.We believe MemoCRS sheds light on a way to model the user preference continuity in sequential CRSs.</p>
<p>RELATED WORK 2.1 Conversational Recommender Systems</p>
<p>CRSs aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues [13].Based on how the response is generated, CRSs can be divided into two categories: attribute-based and generation-based models [11].The former uses pre-defined actions (e.g., asking queries about item attributes and generating responses with pre-defined templates) to interact with users [8,17,25,25].They aim to capture user interests and provide recommendations that users accept in as few rounds as possible [66,70].Conversely, the latter group aims to generate natural and fluent dialogues while delivering high-quality recommendations [26,72].Therefore, models in this line typically have a recommender to generate recommendations and a generator to produce free-form responses.They often utilize knowledge graphs to augment recommender [7,56,60,65,71] and leverage Pre-trained Language Models (PLMs) as generators for more natural responses [53,56,60,65].Early CRSs often used relatively small PLMs, such as DialoGPT for UniCRS [56] and GPT-2 for MESE [60].</p>
<p>The emergence of large language models (LLMs) has brought tremendous success in Natural Language Processing (NLP), and it also shows great potential in other domains like recommendations [6,10,30,31,52,58,59].Recently, some explorations have been conducted to apply LLMs to CRSs and reveal that LLMs exhibit a deep understanding of dialogues and can provide more natural responses and precise recommendations [9,14,55].However, current research predominantly revolves around zero-shot recommendations within current session [9,55], evaluation of CRSs such as user simulators [55,61,62,73], data augmentation for CRSs [54], and sub-task management and planning [11,29].Those works neglect the important role of user preferences and their continuity reflected in users' historical sessions.Some works involving agents involve user memory units [12,20], but they merely propose conceptual designs [12] or utilize historical items without considering how to better manage and leverage memory [20], like redundancy elimination, noise reduction, and general memory management.To the best of our knowledge, we are the first to introduce memory-enhanced LLMs to refine and manage user preferences in the sequential CRSs, enhancing the performance of the recommendation.</p>
<p>Memory</p>
<p>In the development of artificial intelligence, imbuing models with human-like memory has always been a significant research direction.Early studies focused on using parameterized memory in the form of external memory networks [15,16,47,57].They utilize a memory matrix to store historical hidden states, allowing for effective reading and updating of this matrix.While this approach is convenient, its design is overly simplistic and lacks interpretability and scalability.With the rise of LLMs, especially LLM-based agents [43,63], memory has become a crucial component supporting agent-environment interactions.To facilitate input into LLMs, memory is often in natural language form, which enhances interpretability and transparency [35,37,39,67,69].For instance, ExpeL [67] gathers experience and knowledge using natural language from a collection of training tasks.MoT [28] pre-thinks on the unlabeled dataset and saves the high-confidence thoughts as external memory.MemoryBank [69] summarizes relevant memories from previous interactions, evolving through continuous memory updates to adapt to a user's personality.</p>
<p>PRELIMINARIES</p>
<p>Conversational recommender systems (CRSs) aim to elicit user preferences and provide precise item recommendations through multi-turn natural language dialogues.Therefore, CRSs typically consist of a recommender to generate recommendations that match user preferences and a generator to produce natural language responses based on the recommendation [7,27,56,71,72].To achieve this, both the recommender and generator rely on comprehending the dialogue and uncovering user preferences.Previous works primarily focus on dialogue comprehension and preference mining for the user's current dialogue session, overlooking the user's preferences within their historical sessions.In this work, we propose that in the real world, a user may engage in multiple dialogue sessions with CRSs, where the user's historical dialogues and preferences exhibit sequentiality and continuity.We refer to this as Sequential CRSs and present its specific formulation as follows.</p>
<p>Formally, let U, I, and V denote the user set, item set, and the vocabulary.For a user  âˆˆ U who has  conversation sessions with the system, we organize all his/her dialogue sessions in chronological order and refer to them as {  }   =1 .Each dialogue   consists of  utterances denoted as   = {  }  =1 , where   represents the utterance at the -th turn and each utterance   is composed by  words from vocabulary V, i.e.,   = {  }  =1 .In each utterance   , the user or recommender may mention some items denoting I  âˆˆ I.We regard the last session   as the current dialogue session in which we aim to provide recommendations.Then, all the sessions before the current dialogue session are denoted as historical dialogue sessions   = {  }  âˆ’1  =1 for the user .It is worth noting that, following previous work [27], our definition of historical conversation/dialogue sessions differs from the conversation/dialogue history commonly used in most CRSs works [7,56,71].Conversation/dialogue history is historical utterances preceding the current utterance within the same session, pertaining to turn-level.Historical dialogue sessions refer to complete dialogues occurring at different times before the current session.</p>
<p>Based on the above definition, the task of sequential conversational recommendation can be defined as follows.At the -th turn (the turn the recommender should speak), given the historical dialogue sessions   = {  }  âˆ’1  =1 and the current dialogue session before -th turn, i.e., {  }  âˆ’1 =1 , CRSs need to select a candidate set Ã from the entire item candidate set I, such that Ã is as close to the user's current needs and implicit preferences as possible, and generate reasonable responses for the items in Ã .</p>
<p>METHODOLOGY 4.1 Overview of MemoCRS</p>
<p>This framework of MemoCRS, as shown in Figure 2, is modelagnostic and consists of two types of memory: (1) user-specific memory for user's personalized preferences, and (2) general memory for shared and universal knowledge among users.</p>
<p>User-Specific Memory (UM) is a unique entity-based memory bank for each user, designed to store the user's individual and personalized preferences.It is a dynamic memory bank that stores the entities mentioned in the user's historical dialogues (e.g., item names and attributes), along with the associated user attitudes and timestamps.It is also scalable and updatable, supporting multiple memory operations, such as add, merge, retrieve, and delete.</p>
<p>General Memory (GM) preserves shared and universal knowledge among diverse users that cannot be derived from individual dialogues alone.It is primarily composed of collaborative knowledge related to recommendations and reasoning guidelines for the reasoning of LLMs.These two types of knowledge maintain their compactness, enabling direct utilization without memory retrieval.The universality of the knowledge enables LLMs to infer the preferences of cold-start users with limited historical dialogues, thus enhancing recommendations.</p>
<p>General Memory (GM) User-Specific Memory (UM)</p>
<ol>
<li>Similar items: ...  When dealing with conversational recommendations, the general memory and relevant entities and attitudes retrieved from userspecific memory are incorporated into the prompt alongside the current conversation context.This integration enables LLMs to generate recommendations aligned with the user's immediate needs and implicit preferences.</li>
</ol>
<p>User-Specific Memory (UM)</p>
<p>While users exhibit different preferences across various conversations, these preferences are continuous and coexist simultaneously due to the consistency of user behaviors.This preference continuity describes the consistent patterns and tendencies in users' behaviors and preferences over time, which is the key to recommendation tasks [27,49].Understanding the preferences manifested in a user's historical sessions can aid in uncovering their implicit needs in the current conversation, facilitating recommendations that are more aligned with their requirements.For example, if a user's historical dialogues reveal a preference for the actress Scarlett Johansson, and now the user asks for some sci-fi movies, then a sci-fi movie starring Scarlett Johansson, like Her, may be an excellent choice.Inspired by recent studies on memory [37,39,67,69], we propose to leverage an external memory bank to record each user's historical preferences, thereby assisting LLMs in more personalized recommendations.</p>
<p>However, simply preserving all the historical dialogues or items as memory is not practical [20,27].We point out that since user preferences may be multifaceted and the user often has specific needs in the current conversation, not all historical sessions or items will be helpful for the current conversation.This approach may introduce unnecessary redundancy and noise.Moreover, when users have extensive historical dialogues, including all of them may exceed the context windows of LLMs.Some researchers also find that LLMs often fail to extract useful information for the recommendation from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs [33].Therefore, we need to compress and refine the user's historical dialogue sessions and only extract memories relevant to the user's ongoing conversational demands.</p>
<p>Thus, we have devised an entity-based memory bank, which comprises three kinds of crucial information: entity, user's attitudes towards the entity, and timestamp.LLMs extract entities mentioned in users' historical sessions, such as movie titles, actors, directors, and genres for movie scenes, along with users' attitudes toward them.Moreover, this memory bank is dynamic and expandable, supporting operations like add, merge, retrieve, and delete.</p>
<p>Memory Storage.</p>
<p>In user-specific memory, each user  necessitates a separate memory bank M  dedicated to storing their preferences.We extract pivotal information pertinent to user preferences from historical dialogue sessions: entities mentioned by the user, the nuanced attitudes the user holds towards these entities, and timestamp.Here, we formulate memory bank M  as a dictionary, where entity serves as key, and others act as values, i.e.,
M ğ‘¢ = Entity ğ‘– â†’ Attitude ğ‘– , Timestamp ğ‘– | M ğ‘¢ | ğ‘–=1 , ğ‘¢ âˆˆ U. (1)
Since the number of entities mentioned by users is limited, knowledge extracted in this way is more compact and more relevant to recommendations than the whole dialogue.This approach not only removes redundancy to improve storage efficiency but also facilitates updates and retrieval, as we can find relevant attitudes based on entities.Moreover, this design draws inspiration from the intricacies of human memory, which typically involves selective compression and summarization rather than maintaining every detail [3,4].As humans reminisce, specific keywords emerge as vital cues, aiding in recalling specific narratives, thoughts, and feelings.</p>
<p>Entity serves as the key in the memory bank, including the items, attributes, and characteristics of items mentioned by users in historical conversation sessions.Within the domain of recommendation, user interests are primarily reflected in their preferences for items and the attributes of those items.This also constitutes the main content that personalized memory needs to be retained and serves as vital clues guiding our retrieval for specific user preferences.</p>
<p>Attitude refers to a user's specific views and stances towards a particular entity.Retaining just the entity in the memory bank is not sufficient, as a user's preference for a particular entity can be quite complex -it could be liking or disliking, or it might involve nuanced conditional assessments, i.e., the user likes to watch Love Actually during Christmas.For instance, regarding horror movies, a user may dislike those with excessive gore but enjoy psychologically thrilling ones.Moreover, user preferences are dynamic and can evolve over time.Thus, beyond the entity, we need to capture the user's specific and up-to-date attitude toward it.</p>
<p>Timestamp for each entry is the last thing we need to record, denoting the latest moment of operation (comprising add, merge, and retrieval) conducted on each entry.This approach is aimed at facilitating subsequent deletion operations.In situations where storage capacity becomes a concern, we prioritize deletion based on these timestamps, ensuring efficient memory management.</p>
<p>Memory Update.</p>
<p>As users' dialogue sessions accumulate, their preferences may also undergo constant changes, with new preferences emerging and previous ones potentially being overturned.Consequently, we must continually update our memory bank M  of user  as new dialogue sessions come up.To achieve this, we have devised several operations for updating the memory bank, encompassing add, merge, and delete.Apart from the delete operation, the add and merge are all implemented by LLMs.Those prompts, including those used by LLMs thereafter, all consist of three components: task description, context, and format requirements.</p>
<p>The task description provides a comprehensive overview of the instructions for the entire task.The context includes inputs that need to be incorporated into the prompt, such as memory and previous utterances of the current conversation.The format requirements specify certain expectations for the output, e.g., JSON or list format, facilitating results extraction with a post-hoc text parser.Such a prompt design is flexible and can be adapted to various tasks.</p>
<p>Add operation is a primary component of memory updating, involving the extraction of entities and attitudes from dialogues and their inclusion in the memory bank M  .While traditional entity extraction models [2,40] can proficiently handle entity extraction tasks, our work extends to further extracting user attitudes corresponding to these entities, so we adopt LLMs.For a user , upon his/her completion of each conversation session   , we incorporate the dialogue into a prompt   and feed it into LLMs as follows,
{(ğ‘’ ğ‘– , ğ‘ ğ‘– )} ğ¿ ğ‘–=1 = ğ‘“ ğ¿ğ¿ğ‘€ (ğ¶ ğ‘¡ , ğ‘ƒ ğ‘ğ‘‘ğ‘‘ ),(2)
where {(  ,   )}  =1 denotes a collection of entity-attitude pairs of length  with   being the entity and   being the corresponding attitude.For the sake of brevity, we omit the post-processing step on the text generated by LLMs in Eq (2) and only display the final results {(  ,   )}  =1 .Specifically,   is the prompt template for add operation with task descriptions such as "Given a conversation, summarize multiple entities and the user's attitudes towards these entities.Entities include movie titles and related attribute features."and format requirements like "The output format should be in JSON, with the entity as the key and the attitude as the value." Simultaneously, we record a timestamp   for this generation to facilitate subsequent deletion operations.Subsequently, we add each entity   as a key, and its corresponding attitude   and timestamp as a value to M  .For each entity-attitude pairs (  ,   ), we have
M ğ‘¢ [ğ‘’ ğ‘– ] â† Write(ğ‘ ğ‘– , ğ‘¡ğ‘  ğ‘”ğ‘’ğ‘› ),(3)
where Write(â€¢) denotes the write operation to memory bank M  .</p>
<p>Merge operation comes into play when adding the entity   extracted from dialogue and countering a conflict; that is, the extracted entity already exists in the memory bank M  .In such cases, we need to merge the newly generated attitude   with the existing attitude Ã¢ .The LLMs also carry out this merge operation in Eq (4), encapsulating   and Ã¢ into prompt template   ,
ğ‘ * ğ‘– = ğ‘“ ğ¿ğ¿ğ‘€ (ğ‘ ğ‘– , Ã¢ğ‘– , ğ‘ƒ ğ‘šğ‘’ğ‘Ÿğ‘”ğ‘’ ),(4)
where  *  denotes the merged attitude generated by LLMs and the prompt template   contains task description such as, "Given a user's existing and new attitudes, merge these two attitudes, prioritizing the new attitude in case of conflicts." Then the merged attitude  *  is inserted into the memory bank M  , with the timestamp   updated upon the completion of this operation,
M ğ‘¢ [ğ‘’ ğ‘– ] â† Write(ğ‘ * ğ‘– , ğ‘¡ğ‘  ğ‘šğ‘’ğ‘Ÿğ‘”ğ‘’ ).(5)
Furthermore, the merge operation can also be extended from the same entity to several semantically similar entities, such as "phone" and "mobile phone", which further improves storage efficiency.</p>
<p>Delete operation is rule-based and does not require the intervention of LLMs.Additionally, it is considered as an optional procedure.In cases where storage capacity is constrained, we set a time period threshold  and conduct periodic scanning over the entire memory bank.We then delete entities that have not been operated on (i.e., add, merge, or retrieve) for at least a period of time  according to the recorded timestamps.This process is outlined as follows:
M ğ‘¢ â† Delete(M ğ‘¢ , ğ·).(6)
where Delete(â€¢) represents deleting each record in M  whose timestamp has a time difference exceeding  with the current time.Note that this is just one implementation method for the delete operation.</p>
<p>Other strategies, such as usage frequency, can also be considered.</p>
<p>Memory</p>
<p>Retrieval.Now that we have established a personalized memory bank for user  from his/her historical dialogue sessions   , not all memories within it are necessarily conducive to his/her current dialogue session   's -th turn.Utilizing all memories will introduce noise and possibly exceed the context window of LLMs, leading to inferior performance.Therefore, it becomes imperative to retrieve relevant memories from the memory bank based on the current dialogue session.Previous works on memory retrieval mostly use vector similarity retrieval methods like cosine similarity [28,69], which can quickly process large amounts of data but may also retrieve some unrelated content.LLMs perform better in judging relevance [1,51] but have difficulty handling large candidate sets.Thus, we combine the two approaches -first, adopt vector similarity to obtain candidate entities and then leverage LLMs to further discern relevant entities.Specifically, we first utilize vector similarity retrieval methods, e.g., cosine similarity, as a preliminary filtration step [28,69] to obtain a candidate entity list ÃŠ .When the number of entities in the memory bank is relatively limited, we can omit this step and directly use all the entities of M  as ÃŠ .Next, we incorporate ÃŠ and the previous  âˆ’ 1 rounds of utterances {  }  âˆ’1 =1 of the current session into the prompt template   in Eq (7), allowing LLMs to select relevant entities.
E ğ‘¢ = ğ‘“ ğ¿ğ¿ğ‘€ ( ÃŠğ‘¢ , {ğ‘  ğ‘— } ğ‘˜ âˆ’1 ğ‘—=1 , ğ‘ƒ ğ‘Ÿğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ ),(7)
where E  is the retrieved entity list relevant to the ongoing conversation and   includes task description like "Select the  most relevant entities from the entity list based on the user's needs in the conversation, sorted by relevance", with output format being list and  is the hyperparameter.With E  , we can obtain the corresponding attitude list A  for the user from M  as demonstrated in Eq (8).This refined and relevant information will assist the LLMs' recommendations in the subsequent Section 4.4.
A ğ‘¢ = Read(M ğ‘¢ , E ğ‘¢ ),(8)
where Read(â€¢) means reading corresponding attitude from M  for each entity in E  .Note that the read operation also modifies the timestamp of the corresponding entity.</p>
<p>In user-specific memory, the frequency of invoking LLMs is not high.This stems from the limited number of memory update operations.LLMs are usually only called once for an add operation at the end of each dialogue session, and the merge operation is rarely needed except in cases of minimal entity overlap.Not to mention that the delete operation does not involve LLMs at all.Moreover, the memory retrieval operation is exclusively activated upon recommendation, and LLMs are called once on the pre-filtered candidate entities for each retrieval.</p>
<p>General Memory (GM)</p>
<p>Although we have derived user-specific memory from the user's historical dialogues, possessing such memory alone is insufficient for conversational recommendations.On the one hand, previous conversational agents or assistants [35,37,43,69] typically only consider user-specific memory unique to each user because they are not involved in the recommendation task inherent to conversational recommendations.This task relies not only on a user's individual preferences but also on collaborative knowledge, which involves inferring a user's preferences based on the preferences of similar users.Such insights cannot be derived from a single user's historical dialogues; instead, the model needs a comprehensive understanding of the overall data distribution.On the other hand, not all users possess sufficient historical dialogue sessions to form enough userspecific memories.This raises the issue of cold-start users with limited memory.Enhancing the performance on these cold-start users is also a critical concern that warrants consideration.</p>
<p>To this end, beyond user-specific memory, we also need to consider some communal knowledge shared among users, referred to as general memory.Here, we primarily focus on two aspects: collaborative knowledge and LLM-driven reasoning guidelines.Training LLMs to acquire embedded collaborative knowledge incurs significant costs.Hence, we integrate an external, specialized expert model dedicated to extracting collaborative signals, providing LLMs with low-cost collaborative knowledge.The experiential insights derived from the reasoning of LLMs also constitute a crucial part of knowledge shared by users.Thus, we maintain a repository to house the reasoning knowledge and experience LLMs acquire during their reasoning process.Both categories of knowledge are concise and readily usable without retrieval.Their combined effect can enhance the efficacy of recommendations, particularly benefiting recommendations for cold-start users.</p>
<p>Collaborative Knowledge.</p>
<p>A pivotal element in recommendation tasks is collaborative knowledge, which encapsulates shared patterns extracted from a myriad of user behaviors.It facilitates recommender systems in uncovering commonalities and trends among user groups, ensuring precise recommendations.Moreover, it aids in providing tailored recommendations to new users by analyzing the preferences and behaviors of analogous user clusters, effectively mitigating the issue of cold-start users.Collaborative knowledge often requires the model to understand the overall data distribution, typically achieved by training on the entire dataset.Given the substantial costs of training LLMs, we adopt external specialized models for extracting this knowledge, thereby endowing LLMs with cost-effective collaborative insights.</p>
<p>Specifically, for the -th turn of the current session   , the input to the expert model (â€¢) comprises the preceding  âˆ’ 1 turns of utterances {  }  âˆ’1 =1 , and the items mentioned in these turns {I  }  âˆ’1 =1 , where I  represents the set of items mentioned by the user or the recommender in the -th turn of utterance.The expert model's prediction of the recommendations Ã is derived as follows:
Ãğ‘˜ = ğ‘”({ğ‘  ğ‘— } ğ‘˜ âˆ’1 ğ‘—=1 , {I ğ‘— } ğ‘˜ âˆ’1 ğ‘—=1 ).(9)
4.3.2Reasoning Guidelines.Given that we employ LLMs for recommendations, the reasoning guidelines of LLMs are yet another pivotal knowledge that should be shared among users.Previous studies have found that extracting natural language experience from various decision-making tasks can be beneficial for subsequent tasks [63,67].Consequently, we continuously prompt LLMs to reflect on the current reasoning process, extract experience from successful or failed examples, and use them to aid in subsequent reasoning tasks.Specifically, we begin by providing a manually crafted set of simple reasoning guidelines R as an initialization.This set includes basic reasoning rules such as "Let's think step by step" and "Consider user's needs during conversations".Subsequently, we integrate LLMs' reasoning trajectory  and outcomes of recommendation  into a dynamic prompt template     in Eq (10), allowing for iterative updates to the evolving reasoning guideline set R based on LLMs' learning and experience.
R â† ğ‘“ ğ¿ğ¿ğ‘€ (ğ‘¡, ğ‘œ, R, ğ‘ƒ ğ‘Ÿğ‘’ ğ‘“ ğ‘™ğ‘’ğ‘ğ‘¡ ),(10)
where  denotes LLMs' reasoning trajectory on the final recommendation in Section 4.4, encapsulating the original prompt and the step-by-step reasoning process, and  represents the user's text response to the recommendation, indicating whether the user is satisfied with the recommendation.The prompt template     is equipped with the task description like "Given the reasoning process and its result, summarize the experience for successful reasoning and reflect on the experience for the failure of unsuccessful reasoning.Then, update the current reasoning guideline set and keep the total number of experiences within 10. " Collaborative knowledge extraction is conducted through an expert model, independent of LLMs involvement.The extraction of reasoning guidelines does not necessitate frequent updates and can occur at more extended intervals.Consequently, the utilization of general memory does not lead to frequent invocations of LLMs.</p>
<p>Integration with Memory for CRSs</p>
<p>After introducing user-specific memory and general memory, we will integrate the two kinds of knowledge into the prompt to enable LLMs to generate recommendations during conversations.For the -th turn of current session   , we retrieve relevant entity and attitude lists E  and A  from user 's personalized memory bank M  based on the previous  âˆ’ 1 rounds of utterances {  }  âˆ’1 =1 , as described in Section 4.2.3.Next, we obtain collaborative knowledge from the expert model using Eq. ( 9), i.e., the predicted recommendation list Ã .These pieces of information, along with reasoning guideline set R and the previous utterances {  }  âˆ’1 =1 , are combined in prompt   and fed into LLMs to get recommendations,
I ğ‘˜ = ğ‘“ ğ¿ğ¿ğ‘€ {ğ‘  ğ‘— } ğ‘˜ âˆ’1 ğ‘—=1 , E ğ‘¢ , A ğ‘¢ , Ãğ‘˜ , R, ğ‘ƒ ğ‘Ÿğ‘’ğ‘ ,(11)
where I  denotes the recommended item list generated by LLMs.</p>
<p>The prompt template   can leverage the ability of both expert model and LLMs, with the task description such as "Based on the user's conversation, reasoning guidelines, and historical memory, select the top 20 movies from the expert model's recommended movie list that best fit the user's needs.If there are fewer than 20 movies, supplement them with relevant movies based on your own knowledge."</p>
<p>EXPERIMENTS</p>
<p>To gain more insights into MemoCRS, we tend to address the following research questions (RQs) in this section.</p>
<p>â€¢ RQ1: How does MemoCRS perform in recommendation and dialogue generation tasks in sequential CRSs? â€¢ RQ2: What roles do the various modules of MemoCRS play in its performance?â€¢ RQ3: How effective and efficient is the user-specific memory?â€¢ RQ4: Can general memory address the issue of cold-start users?</p>
<p>Experiment Setups</p>
<p>5.1.1Dataset.We conduct experiments on two public datasets, a Chinese dataset TGReDial 1 and an English dataset ReDial2 .TGRe-Dial [72] is a collection of Chinese conversational recommendation sessions constructed in a semi-automatic topic-guided way.It contains 10,000 sessions of 129,392 utterances involving 1,482 users and 33,834 movies.ReDial [26] is an English conversational recommendation dataset built manually by constructed through crowdsourcing workers on Amazon Mechanical Turk (AMT).It includes 10,006 dialogues of 182,150 utterances related to 51,699 movies and 504 users.As we emphasize the crucial role of preferences within historical dialogue sessions, we mainly follow the approach outlined in [27] to resplit the two datasets into train/valid/test sets based on chronological order.We randomly select a subset of users, with their last several sessions as the valid and test sets and the remaining sessions as the training set.Previous works find that repeated items can create shortcuts [9].Therefore, we also filter out conversations with duplicate items, ensuring that recommended items are not mentioned in previous conversation turns.Notably, some users in Redial lack dialogue sessions in the training set, indicating they have no historical dialogue sessions.These users are utilized to evaluate MemoCRS's performance on cold-start users.</p>
<p>Baselines.</p>
<p>To validate the effectiveness of MemoCRS, we select several representative methods in CRSs as our baselines.ReDial [26] adopts an auto-encoder as the recommender and HRED [45] for dialogue generation.KBRD [7] uses external knowledge graph DBPedia [5] for the entities in dialogues to enhance the model's performance.KGSF [71] incorporates two KGs, Con-ceptNet [46] and DBPedia [5] to enhance the representations of words and entities, and uses Mutual Information Maximization to align them.TGReDial [72] is proposed with the TGReDial dataset and incorporates a topic prediction task to enhance performance.UniCRS [56] unifies the recommendation and conversation tasks into the prompt learning paradigm, and utilizes fixed PLMs to fulfill both tasks in a unified approach.UCCR [27] jointly models current dialogue sessions, historical dialogue sessions, and look-alike users via a user-centric manner.ZSCRS [9,55] employs LLMs as zeroshot conversational recommenders.Here, for a fair comparison, we employ GPT4 (gpt-4-1106-preview) as its backbone LLM.</p>
<p>Evaluation Metrics.</p>
<p>In CRSs' evaluation, there are typically two tasks: recommendation and dialogue generation.However, LLMs often exhibit stronger dialogue generation capabilities than the smaller PLMs used in previous methods.Therefore, the comparison often focuses solely on their recommendation abilities in previous works that use LLMs as zero-shot recommenders [9,55].In this work, our main emphasis is also on recommendation performance, but we also touch upon the task of dialogue generation.For recommendation, several widely used metrics, HR@K, NDCG@K [22], and MRR, are adopted, following previous works [7,27,56,71].Here,  âˆˆ {5, 10, 20}.For dialogue generation, we adopt human evaluations, where three annotators score the Fluency and Informativeness of the generated responses following [27,56].The range of scores is from 0 to 2, and the scores of three annotators are averaged.</p>
<p>Implementation Details.</p>
<p>Apart from ZSCRS, all other baselines are implemented with the open-source toolkit CRSLab [70], and we conduct careful hyperparameter tuning to achieve the best performance.Data preprocessing also slightly differs from the original CRSLab; we change the dataset splitting method from random to chronological, using the users' last few sessions as the validation and test sets following [27].Both ZSCRS and MemoCRS utilize GPT-4 (gpt-4-1106-preview) as the LLM backbone for generating recommendations, with a temperature parameter of 0. Their experiments are also conducted based on newly generated data from @5 @10 @20 @5 @10 @20 @5 @10 @20 @5 @10 @20 @5 @10 @20 @5 @10 @20 ReDial 0.0030 0.0055 0.0102 0.0015 0.0018 0.0021 0.0018 0.0027 0.0038 0.</p>
<p>Effectiveness Comparison (RQ1)</p>
<p>5.2.1 Recommendation Task.To validate the effectiveness of our proposed MemoCRS on recommendation task, we compare it with selected state-of-the-art baselines in CRSs.The results are presented in Table 1, from which we have the following observations:</p>
<p>â€¢ Our proposed MemoCRS significantly outperforms the baselines.</p>
<p>For instance, on the TGReDial dataset, MemoCRS shows improvements of 13.04% in HR@20, 23.73% in MRR@20, and 20.41% in NDCG@20 over the strongest baseline.On ReDial, these enhancements are 6.93%, 38.49%, and 24.96%, respectively.This indicates the effectiveness of incorporating memory-enhanced LLMs and modeling the continuity of user preferences in CRSs.â€¢ Methods that utilize user history generally outperform those that do not.Models like TGRedial, which leveraged previously interacted items, and URCC, which uses historical dialogue sessions, achieve better results than other baselines.MemoCRS, which incorporates memory techniques to refine user historical preferences, yields superior outcomes and validates the importance of modeling user preference continuity and sequentiality in CRSs.â€¢ Leveraging larger PLMs often leads to better performance, albeit influenced by the dataset.By incorporating LLMs, simple zero-shot prompting methods (e.g., ZRCRS) are able to outperform carefully designed and fine-tuned small PLMs (e.g., UCCR and UniCRS) on ReDial, which has been corroborated in previous studies as well [9,55].However, this aspect is also subject to dataset influences.On TGReDial, the performance of zeroshot prompting was notably poor, possibly due to LLMs (GPT-4) having a limited understanding of Chinese and Chinese movies, coupled with the dataset primarily featuring niche movies.</p>
<p>Dialogue Generation</p>
<p>Task.Apart from the recommendation task, dialogue generation is also a crucial aspect of conversational recommendation.Considering that LLMs generally exhibit much better language generation capabilities compared to smaller PLMs used in previous works in CRSs [7,27,56,71], most works that</p>
<p>Ablation Study (RQ2)</p>
<p>To investigate the impact of each component in MemoCRS, we design several variants in From the results in Table 3, we can observe that after removing collaborative knowledge, reasoning guidelines, and user-specific memory, the model's performance shows a noticeable decline, indicating that both the user-specific memory and general memory we designed have significant impacts on the model's performance.Additionally, when replacing the reasoning guidelines summarized by LLMs with manually crafted guidelines, there is also a decrease in performance, suggesting that reasoning guidelines generated by LLMs complement missing parts in human summarization and are more suitable for guiding LLMs' reasoning.@5 @10 @20 @5 @10 @20 @5 @10 @20 @5 @10 @20 @5 @10 @20 @5 @10 @20 MemoCRS 0.0162 0.0261 0.0323 0.0095 0.0108 0.0112 0.0111 0.0143 0.0158 0. This section delves into the memory efficiency of user-specific memory.Due to the compact nature of collaborative knowledge and reasoning guidelines utilized without retrieval, general memory is inherently efficient.On the other hand, user-specific memory compresses the information from a user's historical dialogue sessions.Hence, we focus on the efficiency of userspecific memory.Table 4 presents the average number of tokens for each user under different memory scenarios."Total Dialogues" refers to simply including all the user's historical sessions without refinement and retrieval as memory."Total UM" indicates using all user-specific memory refined by our proposed MemoCRS without retrieval."Our" represents the retrieved user-specific memory in our MemoCRS that is relevant to the current conversation.</p>
<p>From Table 4, we can observe that the token count of all userspecific memory refined by MemoCRS is much lower than that of all historical dialogues on both datasets.On ReDial, the difference is even up to 4.6 times, indicating the significant redundancy in the original historical dialogues, and the entity-based memory bank in MemoCRS can reduce this redundancy.Furthermore, retrieving relevant memory with LLMs significantly reduces the token consumption, reducing the input token count for LLMs and thus lowering the inference cost.This also suggests that there is not a large number of relevant memories in the memory bank, so we need to retrieve and extract relevant information to eliminate noise.</p>
<p>Memory</p>
<p>Effectiveness.Next, we analyze the efficacy of userspecific memory design and its retrieval strategies.To this end, we devise several variants with different memory utilization approaches, based on the user-specific memory generated by Memo-CRS."All" denotes the direct utilization of all refined user-specific memories without any retrieval operation."Rand" represents randomly selecting  entity-attitude pairs from the user-specific memory bank to exclude the effect of the input length."Sim" refers to encoding user-specific memory through BERT and employing cosine similarity to retrieve the most relevant  pairs.Lastly, "Ours" signifies our proposed two-stage retrieval, which first adopts cosine similarity to obtain candidate entities and then leverages LLMs to further select the most relevant  pairs.Notably, the number of final entity-attitude pairs  used in the latter three variants is consistent across the same dataset and aligned with the experiments outlined in Table 1.We do not compare inputting all historical dialogue sessions here because their length may exceed the context window of LLMs, and we have already compared the model, i.e., UCCR, equipped with historical sessions in Table 1.We select two metrics, HR@1 and NDCG@20, and plot the performance of different variants on two datasets in Figure 3.  From Figure 3, we can observe that using all historical memory yields the poorest results, indicating significant noise and irrelevant memory in the memory bank for the current conversation session.This underscores the necessity of retrieval mechanisms.Randomly selecting memories exhibits marginally better performance, suggesting that an abundance of tokens across all memories may also impact LLMs' decision-making process.Utilizing cosine similarity for retrieval leads to further enhancements, particularly in NDCG@20, signifying its capability to extract more relevant memories.However, there is a slight decrease in effectiveness in HR@1.Our approach of leveraging LLMs for further memory extraction showcases superior efficacy, highlighting LLMs' ability to accurately assess the relevance of memory, thereby effectively extracting pertinent information while mitigating noise.</p>
<p>Cold-Start Users (RQ4)</p>
<p>Given limited user-specific memory for cold-start users, we design a shared general memory among users to address this issue.In this section, we primarily investigate whether our proposed model, especially the general memory, can improve the recommendations for cold-start users.On the ReDial dataset, we divide the test set into Warm and Cold groups based on whether the user has historical sessions in the training set.Subsequently, we compare the performance of our proposed MemoCRS, the best baseline UCCR, and MemoCRS without general memory, i.e., MemoCRS-GM, on these two groups.We adopt HR@1 and NDCG@20 to assess both recall and ranking performance, with the results depicted in Figure 4. From these results, we draw the following conclusions.Firstly, MemoCRS exhibits notable enhancements over the best baseline UCCR on both warm and cold user groups, with a particularly significant uplift observed on cold-start users.While UCCR demonstrates superior performance in HR@1 and NDCG@20 for warm users, MemoCRS excels in enhancing the experience for cold users.This indicates that MemoCRS's design can benefit both cold and warm users, with a pronounced impact on cold-start users.Secondly, MemoCRS without general memory (MemoCRS-GM) exhibits a decrease in performance compared to MemoCRS across two user groups, particularly pronounced on cold-start users.Although MemoCRS-GM still outperforms UCCR on warm users, its performance of HR@1 for cold-start users lags behind UCCR's.This suggests that general memory can aid both cold and warm user groups, with a more significant impact on cold-start users, demonstrating the effectiveness of general memory in mitigating cold-start issues.</p>
<p>CONCLUSION</p>
<p>In this work, we highlight the importance of user preference continuity for sequential CRSs and, for the first time, introduce memoryenhanced LLM to refine and manage user preference.We propose MemoCRS, which constitutes user-specific memory tailored for each user's personalized preferences and general memory containing universal knowledge shared across different users.On both Chinese and English datasets, MemoCRS shows superior performance compared to baselines.</p>
<p>looking for some sci-fi films.What kind of movies do you like?I recommend Her starring by Scarleet Johansson which offers a poigant explonation of love and technology.</p>
<p>Figure 2 :
2
Figure 2: The overall framework of MemoCRS.</p>
<p>Figure 3 :
3
Figure 3: Comparison between different kinds of memory.</p>
<p>Figure 4 :
4
Figure 4: Performance comparison on cold and warm users.</p>
<p>Table 1 :
1
Comparison of different models on recommendation task.The best result is given in bold, while the second-best value is underlined.The symbol * indicates statistically significant improvement over the best baseline with  &lt; 0.01.
TGReDialModel</p>
<p>CRSLab.For MemoCRS3, we choose UCCR as the expert model.The number of retrieved memories  used in the final recommendation is 3 for TGReDial and 1 for ReDial.The number of candidates, i.e., | Ã |, provided by the expert model is 40, and the length of the final output recommendation list generated by LLMs is set at 20.
0293 0.0413 0.0882 0.0174 0.0190 0.0223 0.0203 0.0242 0.0361KBRD0.0050 0.0112 0.0174 0.0026 0.0035 0.0040 0.0032 0.0053 0.0069 0.0824 0.1395 0.2185 0.0337 0.0418 0.0470 0.0457 0.0646 0.0842KGSF0.0112 0.0149 0.0249 0.0039 0.0044 0.0051 0.0057 0.0068 0.0094 0.0908 0.1378 0.2319 0.0385 0.0445 0.0508 0.0514 0.0663 0.0898TGReDial 0.0075 0.0174 0.0236 0.0055 0.0068 0.0072 0.0059 0.0091 0.0107 0.0874 0.1395 0.2336 0.0433 0.0502 0.0567 0.0543 0.0710 0.0948UCCR0.0087 0.0174 0.0286 0.0071 0.0082 0.0090 0.0075 0.0103 0.0131 0.1059 0.1782 0.2672 0.0443 0.0538 0.0596 0.0594 0.0826 0.1047UniCRS 0.0050 0.0124 0.0236 0.0024 0.0035 0.0042 0.0031 0.0055 0.0083 0.1005 0.1605 0.2480 0.0392 0.0467 0.0528 0.0542 0.0731 0.0952ZSCRS0.0025 0.0087 0.0100 0.0007 0.0016 0.0017 0.0012 0.0032 0.0035 0.1261 0.1882 0.2353 0.0511 0.0594 0.0629 0.0695 0.0896 0.1018MemoCRS 0.0162<em> 0.0261</em> 0.0323<em> 0.0095</em> 0.0108<em> 0.0112</em> 0.0111<em> 0.0143</em> 0.0158<em> 0.1361</em> 0.2151<em> 0.2857</em> 0.0718<em> 0.0821</em> 0.0871<em> 0.0875</em> 0.1128<em> 0.1308</em></p>
<p>Table 2 :
2
Comparison on dialogue generation task.The results from Table2demonstrate that the dialogues generated by LLMs are significantly more fluent and informative than those generated by traditional models in CRSs, and utilizing LLMs for CRSs can produce more natural and accurate responses.One important point to note is that UniCRS yields unsatisfactory results on the Chinese dataset TGReDial because it is built upon DialoGPT, which does not support Chinese well.
ModelTGReDialReDialFluency Informativeness Fluency InformativenessReDial0.450.400.410.40KBRD1.040.990.971.01KGSF1.041.081.131.15TGReDial0.800.840.880.87UCCR1.101.121.111.17UniCRS0.420.431.181.19LLM1.87<em>1.82</em>1.86<em>1.87</em>leverage LLMs for dialogue recommendation only focus on therecommendation task [9, 55]. Some researchers found that LLMsexcel in providing explainable recommendations and creating aninteractive user experience [49]. Here, we quantitatively comparethe quality of dialogues generated by LLMs (gpt-4-1106-preview)using zero-shot prompting with traditional CRSs through humanevaluation.</p>
<p>Table 3 .
3
The model variants w/o UM, w/o CK, and w/o RG represent removing user-specific memory, collaborative knowledge, and reasoning guidelines from MemoCRS, respectively.Manual RG replaces the reasoning guidelines summarized by LLMs with the manually initialized reasoning guidelines.</p>
<p>Table 3 :
3
Ablation study of MemoCRS.The best result is given in bold, while the second-best value is underlined.
TGReDialReDialVariantsHRMRRNDCGHRMRRNDCG</p>
<p>Table 4 :
4
Average number of tokens pre user for different types of memory.UM denotes user-specific memory.
Avg. #Token Per User TGReDial ReDialTotal Dialogues1781.89 7154.07Total UM1026.98 1526.51Ours21.4150.27
https://github.com/RUCAIBox/TG-ReDial
https://redialdata.github.io/website/
Our code will be available at https://github.com/mindspore-lab/models/tree/master/ research/huawei-noah/memocrs</p>
<p>Can We Use Large Language Models to Fill Relevance Judgment Holes?. Zahra Abbasiantaeb, Chuan Meng, Leif Azzopardi, Mohammad Aliannejadi, arXiv:2405.056002024. 2024arXiv preprint</p>
<p>Named entity extraction for knowledge graphs: A literature overview. Tareq Al-Moslmi, Marc GallofrÃ© OcaÃ±a, Andreas L Opdahl, Csaba Veres, IEEE Access. 82020. 2020</p>
<p>Human memory: Theory and practice. Alan D Baddeley, 1997psychology press</p>
<p>Efficient data compression in perception and perceptual memory. J Christopher, Robert A Bates, Jacobs, Psychological review. 1278912020. 2020</p>
<p>Dbpedia-a crystallization point for the web of data. Christian Bizer, Jens Lehmann, Georgi Kobilarov, SÃ¶ren Auer, Christian Becker, Richard Cyganiak, Sebastian Hellmann, Journal of web semantics. 72009. 2009</p>
<p>Jin Chen, Zheng Liu, Xu Huang, Chenwang Wu, Qi Liu, Gangwei Jiang, Yuanhao Pu, Yuxuan Lei, Xiaolong Chen, Xingmei Wang, arXiv:2307.16376When large language models meet personalization: Perspectives of challenges and opportunities. 2023. 2023arXiv preprint</p>
<p>Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia Yang, Jie Tang, arXiv:1908.05391Towards knowledge-based recommender dialog system. 2019. 2019arXiv preprint</p>
<p>Towards conversational recommender systems. Konstantina Christakopoulou, Filip Radlinski, Katja Hofmann, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data mining2016</p>
<p>Zeroshot recommender systems. Yifei Hao Ding, Anoop Ma, Yuyang Deoras, Hao Wang, Wang, arXiv:2105.083182021. 2021arXiv preprint</p>
<p>Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, Qing Li, arXiv:2307.02046Recommender systems in the era of large language models (llms). 2023. 2023arXiv preprint</p>
<p>Yue Feng, Shuchang Liu, Zhenghai Xue, Qingpeng Cai, Lantao Hu, Peng Jiang, Kun Gai, Fei Sun, arXiv:2308.06212A large language model enhanced conversational recommender system. 2023. 2023arXiv preprint</p>
<p>Luke Friedman, Sameer Ahuja, David Allen, Terry Tan, Hakim Sidahmed, Changbo Long, Jun Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, arXiv:2305.07961Leveraging Large Language Models in Conversational Recommender Systems. 2023. 2023arXiv preprint</p>
<p>Advances and challenges in conversational recommender systems: A survey. Chongming Gao, Wenqiang Lei, AI open. 22021. 2021Xiangnan He, Maarten de Rijke, and Tat-Seng Chua</p>
<p>Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, Jiawei Zhang, arXiv:2303.14524Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System. 2023. 2023arXiv preprint</p>
<p>Alex Graves, Greg Wayne, Ivo Danihelka, arXiv:1410.5401Neural turing machines. 2014. 2014arXiv preprint</p>
<p>Hybrid computing using a neural network with dynamic external memory. Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-BarwiÅ„ska, Sergio GÃ³mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Nature. 5382016. 2016</p>
<p>Bundle MCR: Towards conversational bundle recommendation. Zhankui He, Handong Zhao, Tong Yu, Sungchul Kim, Fan Du, Julian Mcauley, Proceedings of the 16th ACM Conference on Recommender Systems. the 16th ACM Conference on Recommender Systems2022</p>
<p>Session-based recommendations with recurrent neural networks. BalÃ¡zs Hidasi, Alexandros Karatzoglou, arXiv:1511.069392015. 2015arXiv preprintLinas Baltrunas, and Domonkos Tikk</p>
<p>Towards Universal Sequence Representation Learning for Recommender Systems. Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, Ji-Rong Wen, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2022</p>
<p>Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, Xing Xie, arXiv:2308.16505Recommender ai agent: Integrating large language models for interactive recommendations. 2023. 2023arXiv preprint</p>
<p>A survey on conversational recommender systems. Dietmar Jannach, Ahtsham Manzoor, Wanling Cai, Li Chen, ACM Computing Surveys (CSUR). 542021. 2021</p>
<p>Cumulated Gain-Based Evaluation of IR Techniques. Kalervo JÃ¤rvelin, Jaana KekÃ¤lÃ¤inen, ACM Trans. Inf. Syst. 2002. 2002</p>
<p>Self-attentive sequential recommendation. Wang-Cheng Kang, Julian Mcauley, 2018 IEEE international conference on data mining (ICDM). IEEE2018</p>
<p>Addressing cold-start problem in recommendation systems. Xuan Nhat Lam, Thuc Vu, Trong Duc Le, Anh Duc Duong, Proceedings of the 2nd international conference on Ubiquitous information management and communication. the 2nd international conference on Ubiquitous information management and communication2008</p>
<p>Estimation-action-reflection: Towards deep interaction between conversational and recommender systems. Wenqiang Lei, Xiangnan He, Yisong Miao, Qingyun Wu, Richang Hong, Min-Yen Kan, Tat-Seng Chua, Proceedings of the 13th International Conference on Web Search and Data Mining. the 13th International Conference on Web Search and Data Mining2020</p>
<p>Towards Deep Conversational Recommendations. Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, Chris Pal, Advances in Neural Information Processing Systems 31. 2018. 2018</p>
<p>User-centric conversational recommendation with multi-aspect user modeling. Shuokai Li, Ruobing Xie, Yongchun Zhu, Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval2022Xiang Ao, Fuzhen Zhuang, and Qing He</p>
<p>Mot: Memory-of-thought enables chatgpt to self-improve. Xiaonan Li, Xipeng Qiu, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Long Short-Term Planning for Conversational Recommendation Systems. Xian Li, Hongguang Shi, Yunfei Wang, Yeqin Zhang, Xubin Li, Cam-Tu Nguyen, International Conference on Neural Information Processing. Springer2023</p>
<p>ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. Jianghao Lin, Bo Chen, Hangyu Wang, Yunjia Xi, Yanru Qu, Xinyi Dai, Kangning Zhang, Ruiming Tang, Yong Yu, Weinan Zhang, Proceedings of the ACM on Web Conference 2024. the ACM on Web Conference 20242024WWW '24</p>
<p>Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong Liu, Chuhan Wu, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, arXiv:2306.05817Ruiming Tang, and Weinan Zhang. 2023. How Can Recommender Systems Benefit from Large Language Models: A Survey. 2023arXiv preprint</p>
<p>MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction. Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, Weinan Zhang, Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2023</p>
<p>ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, Weinan Zhang, Proceedings of the ACM on Web Conference 2024 (WWW '24). the ACM on Web Conference 2024 (WWW '24)2024</p>
<p>Chengkai Liu, Jianghao Lin, Jianling Wang, Hanzhou Liu, James Caverlee, arXiv:2403.03900Mamba4Rec: Towards Efficient Sequential Recommendation with Selective State Space Models. 2024. 2024arXiv preprint</p>
<p>Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, Guannan Zhang, arXiv:2311.08719Think-in-memory: Recalling and post-thinking enable llms with long-term memory. 2023. 2023arXiv preprint</p>
<p>Weiwen Liu, Yunjia Xi, Jiarui Qin, Fei Sun, Bo Chen, Weinan Zhang, Rui Zhang, Ruiming Tang, arXiv:2202.06602Neural Re-ranking in Multi-stage Recommender Systems: A Review. 2022. 2022arXiv preprint</p>
<p>Memochat: Tuning llms to use memos for consistent long-range open-domain conversation. Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, Yunsheng Wu, arXiv:2308.082392023. 2023arXiv preprint</p>
<p>RevCore: Review-augmented conversational recommendation. Yu Lu, Junwei Bao, Yan Song, Zichen Ma, Shuguang Cui, Youzheng Wu, Xiaodong He, arXiv:2106.009572021. 2021arXiv preprint</p>
<p>Retllm: Towards a general read-write memory for large language models. Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, Hinrich SchÃ¼tze, arXiv:2305.143222023. 2023arXiv preprint</p>
<p>Named entity recognition and relation extraction: State-of-the-art. Zara Nasar, Waqar Syed, Muhammad Jaffry, Malik Kamran, ACM Computing Surveys (CSUR). 542021. 2021</p>
<p>. 10.48550/arXiv.2303.08774abs/2303.087742023Technical Report. CoRR</p>
<p>Charles Packer, Vivian Fang, G Shishir, Kevin Patil, Sarah Lin, Joseph E Wooders, Gonzalez, arXiv:2310.08560Memgpt: Towards llms as operating systems. 2023. 2023arXiv preprint</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, Huajun Chen, arXiv:2212.09597[cs.CL]Reasoning with Language Model Prompting: A Survey. 2023</p>
<p>A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, Jian-Yun Nie, proceedings of the 24th ACM international on conference on information and knowledge management. the 24th ACM international on conference on information and knowledge management2015</p>
<p>Conceptnet 5.5: An open multilingual graph of general knowledge. Robyn Speer, Joshua Chin, Catherine Havasi, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201731</p>
<p>End-to-end memory networks. Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, Advances in neural information processing systems. 282015. 2015</p>
<p>BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, Peng Jiang, Proceedings of the 28th ACM international conference on information and knowledge management. the 28th ACM international conference on information and knowledge management2019</p>
<p>Ruixuan Sun, Xinyi Li, Avinash Akella, Joseph A Konstan, arXiv:2404.19093Large Language Models as Conversational Movie Recommenders: A User Study. 2024. 2024arXiv preprint</p>
<p>Conversational recommender system. Yueming Sun, Yi Zhang, The 41st international acm sigir conference on research &amp; development in information retrieval. 2018</p>
<p>Shivani Upadhyay, Ehsan Kamalloo, Jimmy Lin, arXiv:2405.04727LLMs Can Patch Up Missing Relevance Judgments in Evaluation. 2024. 2024arXiv preprint</p>
<p>FLIP: Towards Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction. Hangyu Wang, Jianghao Lin, Xiangyang Li, Bo Chen, Chenxu Zhu, Ruiming Tang, Weinan Zhang, Yong Yu, arXiv-23102023. 2023arXiv e-prints</p>
<p>RecInDial: A unified framework for conversational recommendation with pretrained language models. Lingzhi Wang, Huang Hu, Lei Sha, Can Xu, Kam-Fai Wong, Daxin Jiang, arXiv:2110.074772021. 2021arXiv preprint</p>
<p>Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation. Xi Wang, Hossein A Rahmani, Jiqun Liu, Emine Yilmaz, arXiv:2310.167382023. 2023arXiv preprint</p>
<p>Rethinking the evaluation for conversational recommendation in the era of large language models. Xiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan Wang, Ji-Rong Wen, arXiv:2305.131122023. 2023arXiv preprint</p>
<p>Towards unified conversational recommender systems via knowledge-enhanced prompt learning. Xiaolei Wang, Kun Zhou, Ji-Rong Wen, Wayne Xin Zhao, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2022</p>
<p>. Jason Weston, Sumit Chopra, Antoine Bordes, arXiv:1410.39162014. 2014Memory networks. arXiv preprint</p>
<p>Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, arXiv:2305.19860A Survey on Large Language Models for Recommendation. 2023. 2023arXiv preprint</p>
<p>Towards open-world recommendation with knowledge augmentation from large language models. Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, Yong Yu, arXiv:2306.109332023. 2023arXiv preprint</p>
<p>Improving Conversational Recommendation Systems' Quality with Context-Aware Item Meta Information. Bowen Yang, Cong Han, Yu Li, Lei Zuo, Zhou Yu, arXiv:2112.081402021. 2021arXiv preprint</p>
<p>Dayu Yang, Fumian Chen, Hui Fang, arXiv:2404.11773Behavior Alignment: A New Perspective of Evaluating LLM-based Conversational Recommendation Systems. 2024. 2024arXiv preprint</p>
<p>Zhankui Se-Eun Yoon, Jessica Maria He, Julian Echterhoff, Mcauley, arXiv:2403.09738Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation. 2024. 2024arXiv preprint</p>
<p>Large Language Models Are Semi-Parametric Reinforcement Learning Agents. Danyang Zhang, Lu Chen, Situo Zhang, Hongshen Xu, Zihan Zhao, Kai Yu, Advances in Neural Information Processing Systems. 362024. 2024</p>
<p>Ruiming Tang, and Xiuqiang He. Weinan Zhang, Jiarui Qin, Wei Guo, Deep Learning for Click-Through Rate Estimation (IJCAI '21). 2021</p>
<p>Variational reasoning over incomplete knowledge graphs for conversational recommendation. Xiaoyu Zhang, Xin Xin, Dongdong Li, Wenxuan Liu, Pengjie Ren, Zhumin Chen, Jun Ma, Zhaochun Ren, Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. the Sixteenth ACM International Conference on Web Search and Data Mining2023</p>
<p>Multiple choice questions based multi-interest policy learning for conversational recommendation. Yiming Zhang, Lingfei Wu, Qi Shen, Yitong Pang, Zhihua Wei, Fangli Xu, Bo Long, Jian Pei, Proceedings of the ACM Web Conference 2022. the ACM Web Conference 20222022</p>
<p>Expel: Llm agents are experiential learners. Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, Gao Huang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2024. 19632-1964238</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 2023. 2023arXiv preprint</p>
<p>Memorybank: Enhancing large language models with long-term memory. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2024. 19724-1973138</p>
<p>CRSLab: An opensource toolkit for building conversational recommender system. Kun Zhou, Xiaolei Wang, Yuanhang Zhou, Chenzhan Shang, Yuan Cheng, Wayne Xin Zhao, Yaliang Li, Ji-Rong Wen, arXiv:2101.009392021. 2021arXiv preprint</p>
<p>Improving conversational recommender systems via knowledge graph based semantic fusion. Kun Zhou, Wayne Xin Zhao, Shuqing Bian, Yuanhang Zhou, Ji-Rong Wen, Jingsong Yu, Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining2020</p>
<p>Towards Topic-Guided Conversational Recommender System. Kun Zhou, Yuanhang Zhou, Wayne Xin Zhao, Xiaoke Wang, Ji-Rong Wen, Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020. the 28th International Conference on Computational Linguistics, COLING 2020Barcelona, Spain2020. December 8-11, 2020</p>
<p>How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation. Lixi Zhu, Xiaowen Huang, Jitao Sang, arXiv:2403.164162024. 2024arXiv preprint</p>
<p>Large language models for information retrieval: A survey. Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, Ji-Rong Wen, arXiv:2308.071072023. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>