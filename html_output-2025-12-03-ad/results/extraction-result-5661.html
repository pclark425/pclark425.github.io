<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5661 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5661</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5661</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-270379599</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.07467v4.pdf" target="_blank">LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs</a></p>
                <p><strong>Paper Abstract:</strong> Most log-based anomaly detectors assume logs are stable, though logs are often unstable due to software or environmental changes. Anomaly detection on unstable logs (ULAD) is therefore a more realistic, yet under-investigated challenge. Current approaches predominantly employ machine learning (ML) models, which often require extensive labeled data for training. To mitigate data insufficiency, we propose FlexLog, a novel hybrid approach for ULAD that combines ML models -- decision tree, k-nearest neighbors, and a feedforward neural network -- with a Large Language Model (Mistral) through ensemble learning. FlexLog also incorporates a cache and retrieval-augmented generation (RAG) to further enhance efficiency and effectiveness. To evaluate FlexLog, we configured four datasets for \task, namely ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U. FlexLog outperforms all baselines by at least 1.2 percentage points (pp) in F1 score while using much less labeled data (62.87 pp reduction). When trained on the same amount of data as the baselines, FlexLog achieves up to a 13 pp increase in F1 score on ADFA-U across varying training dataset sizes. Additionally, FlexLog maintains inference time under one second per log sequence, making it suitable for most applications, except latency-sensitive systems. Further analysis reveals the positive impact of FlexLog's key components: cache, RAG and ensemble learning.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5661.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5661.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FlexLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FlexLog (LLM+ML ensemble for Unstable-Log Anomaly Detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid anomaly-detection system that ensembles a fine-tuned LLM with classical ML models, uses retrieval-augmented generation (RAG) and a cache, and applies majority-vote aggregation to detect anomalies in log template sequences while requiring far fewer labeled examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral Small 22B (fine-tuned via QLoRA) + KNN, Decision Tree (DT), Single-layer Feedforward Network (SLFN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Ensemble containing an open-source LLM (Mistral Small, 22B params) fine-tuned via parameter-efficient finetuning (4-bit QLoRA / LoRa settings: rank=16, alpha=16, batch=1, steps tuned 500–2500) together with three ML base models (KNN, DT, SLFN). Inference uses structured prompts (description/instruction/relevant-info/input/output), RAG for optional context, a cache of seen template-sequence→label pairs, deterministic low-temperature decoding and majority-vote aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>22B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>PEFT fine-tuning (QLoRA/LoRa) of an LLM on labeled log-template sequences with structured prompting and optional RAG; ensemble majority-vote with classic ML models; cache-lookup to skip inference for identical sequences. LLM output constrained to 'normal'/'anomalous', regeneration strategy if ambiguous.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Semi-structured ordered log-template sequences (sequence of template IDs produced by log parsing)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log sequences due to environmental or software evolution (novel attack types, unseen templates, sequence-level changes such as template addition/removal/shuffling); sequence-level and template-level anomalies in logs</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ADFA-U, LOGEVOL-U (Hadoop/Spark splits), SynHDFS-U (synthetic HDFS variants), SYNEVOL-U (synthetic LOGEVOL variants)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision / Recall / F1 reported. Representative results: ADFA-U (ULAD average): F1=0.704 (FlexLog) vs LightAD F1=0.677; LOGEVOL-U average F1 reported ~0.928 vs top baseline ~0.910; SynHDFS-U average F1 ~0.971; SYNEVOL-U average F1 ~0.963. When trained on same limited subsets, FlexLog gains up to +13 percentage points F1 on ADFA-U at D#=500. Inference latency per log sequence: 0.771–0.988 s (dataset-dependent). Training time dominated by LLM (hours); ML models train in seconds.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>FlexLog outperforms a suite of traditional and deep-learning baselines (LightAD, NeuralLog, LogRobust, CNN, DeepLog, LogAnomaly, etc.), beating the top baseline by at least 1.2 percentage points in F1 across datasets while using far fewer labeled unique sequences (labeled-data usage reduction between 62.87 and 78.43 percentage points depending on dataset). When compared under identical limited-training subsets, FlexLog consistently exceeds baselines (average F1 improvements up to 13 pp at D#=500).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Higher inference cost than lightweight ML (though <1s per sequence in reported env); sensitivity to extreme class imbalance where poorly-trained ML base models can harm ensemble (on extremely imbalanced LOGEVOL Spark and SYNEVOL-U ensembles, 'w/o ML' Mistral-only performed better); non-deterministic LLM outputs require temperature control and regeneration; potential pretraining-data leakage risk (mitigated by de-duplication and choice of datasets); cache assumes identical sequences map to same label (may fail under extreme evolution); ensemble majority-vote (tie→normal) is simple and may not be optimal in some scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5661.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5661.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral Small (22B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral Small 22B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source large language model used as the LLM base in FlexLog; fine-tuned with PEFT (QLoRA/LoRa) for sequence-level log anomaly classification and used both inside the ensemble and standalone.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral Small 22B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source transformer LLM with ~22 billion parameters (referred to as Mistral Small in the paper). In FlexLog it was fine-tuned with 4-bit QLoRA (rank=16, alpha=16) using Unsloth tooling; inference configured with low temperature (e.g., 0.1) and regeneration attempts for ambiguous outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>22B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Parameter-efficient fine-tuning (QLoRA) on labeled log-template sequence prompts; RAG-augmented prompts when external context exists; prompts structured into description/instruction/relevant information/input/output; output token predicted as 'normal'/'anomalous'. Used as a base model in an ensemble (majority voting) or standalone predictor.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log template sequences (ordered sequences) — semi-structured sequences</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Novel/unseen templates, sequence-level order anomalies, anomalies from injected/simulated attacks and faults in ADFA/LOGEVOL/HDFS datasets</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>As a core base model, removing Mistral produces the largest F1 drop (max reported −6.7 pp on ADFA-U adduser). Standalone Mistral (w/o ML) performed comparably to full FlexLog on some datasets and outperformed the ensemble on extremely imbalanced training sets (LOGEVOL-U Spark and SYNEVOL-U). Overall Mistral-based FlexLog matched GPT-4o performance in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mistral in FlexLog matched the closed-source GPT-4o's effectiveness on these ULAD tasks and outperformed Llama 3.1 (8B) in the paper's comparisons. When combined with ML base models, it yielded better data efficiency and overall F1 than pure ML baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Non-deterministic generation necessitates temperature tuning and regeneration logic; inference cost and latency dominate FlexLog runtime; possible inclusion of dataset sequences in pretraining corpora is a threat to internal validity (mitigated by choosing datasets created after model cutoff where possible).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5661.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5661.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o (closed-source)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-source advanced LLM evaluated as an alternative LLM base in FlexLog; fine-tuned via OpenAI API for the ULAD task and shown to produce comparable effectiveness to Mistral but at monetary and latency cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source multi-billion-parameter family model by OpenAI; in this work GPT-4o was fine-tuned via provider API (API-based fine-tuning) for the ULAD prompts and used as an LLM base in ensemble experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>API-based fine-tuning (OpenAI fine-tune endpoints) on structured prompts (same prompt template as for open-source LLMs), used either as the single LLM base or replacing Mistral in the FlexLog ensemble.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log template sequences (ordered sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Same log sequence anomalies (unseen templates, sequence-level changes, attack-induced anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to achieve comparable F1 to Mistral in the experiments (no statistically significant differences dataset-level between Mistral and GPT-4o in most datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Comparable effectiveness to Mistral; unlike Mistral, GPT-4o incurs API costs and has unpredictable latency and less control over fine-tuning internals.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High financial cost per API use; variable latency; less control for PEFT-style tuning; ethical / data-leakage risk if pretraining overlaps with evaluation data; hidden internals limit experimentation choices.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5661.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5661.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama 3.1 8B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 3.1 8B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source LLM baseline evaluated in FlexLog experiments; smaller-capacity model (8B) fine-tuned with QLoRA but underperformed compared to Mistral and GPT-4o on ULAD.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 3.1 8B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source transformer LLM with ~8 billion parameters; fine-tuned via 4-bit QLoRA and Unsloth in the paper's experiments with the same prompt/RAG setup used for other LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>PEFT fine-tuning (QLoRA) on structured prompts with optional RAG context; evaluated as a replacement for Mistral in the FlexLog ensemble.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log template sequences (ordered sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Same types of log anomalies (unseen templates, sequence-level anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Llama-based FlexLog variants yielded lower F1 than Mistral and GPT-4o across datasets (specific deltas reported in Table 15 of the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Underperformed compared to Mistral and GPT-4o on the ULAD benchmarks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lower capacity correlated with lower detection effectiveness; fine-tuned Llama 3.1 8B did not match higher-capacity LLMs for unseen-template generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5661.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5661.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogPrompt (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior approach that leverages prompting and in-context learning with LLMs (e.g., GPT-3, Vicuna) for online log parsing and anomaly detection via few-shot/zero-shot prompts; mentioned as related work and not used as a baseline here.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 / Vicuna (in-context prompting)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Prior methods used LLMs in in-context learning (ICL) mode (no fine-tuning) for tasks like log parsing and message-level anomaly detection; these methods rely on prompt demonstrations rather than PEFT.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Prompt-based in-context learning (zero-shot / few-shot) for parsing and message-level anomaly detection (different from sequence-level ULAD in FlexLog); not fine-tuned in the referenced work</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log messages and message-level parsing (tokenized text), primarily message-level rather than sequence-level</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Message-level anomalies / parsing errors / detection of abnormal messages; differs from sequence-level anomalies studied in FlexLog</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Referenced in related work; not experimentally compared in this paper (excluded as baseline because it focuses on message-level detection rather than sequence-level labels).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mentioned as promising for in-context solutions but with limitations (cost, latency, poor generalizability of ICL per Mosbach et al.) and therefore not adopted as a main baseline in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>In-context learning can exhibit poor generalizability on challenging tasks and is costly/unreliable with closed-source LLM APIs; moreover, message-level outputs do not directly map to sequence-level ULAD labels used here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5661.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5661.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogBERT / LogGPT / LLMeLog (related LLM methods)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Representative LLM-based log analysis methods (LogBERT, LogGPT, LLMeLog)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior works that adapted LLMs or transformer models for log anomaly detection or log enrichment: LogBERT used BERT to learn semantics of normal logs; LogGPT fine-tuned GPT-2 with RL; LLMeLog enriched log events using LLMs — these are cited as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT, GPT-2, GPT-3.5 variants (depending on the method)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Various transformer-based LLM adaptations: LogBERT (BERT-based encoders), LogGPT (GPT-2 fine-tuned with RL), LLMeLog (LLM-enriched features), typically adapted to log data by fine-tuning or prompt-enrichment.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Approaches vary: pretrain+fine-tune (BERT-style), RL-fine-tuning for generation models, LLM-based retrieval/enrichment; generally used for message- or sequence-level anomaly scoring or representation.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Logs (messages, templates, sequences) — both message-level and sequence-level depending on work</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic deviations, next-event prediction mismatches, message-level anomalies and enriched-event anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cited in related work; concrete metrics depend on each cited study (precision/recall/F1 commonly used).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Cited as prior art that influenced FlexLog's use of RAG, prompt design, and fine-tuning strategies; FlexLog positions itself as combining LLM strength with classical ML detectors to improve data efficiency relative to pure ML or previous LLM-only methods.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Several prior LLM methods focus on message-level detection (not suitable for sequence-level ULAD), or rely on closed-source APIs (cost/latency); also, in-context methods are sometimes inferior to fine-tuned models on hard tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>EvLog: Identifying anomalous logs over software evolution <em>(Rating: 2)</em></li>
                <li>Robust log-based anomaly detection on unstable log data <em>(Rating: 2)</em></li>
                <li>LLMeLog: An approach for anomaly detection based on LLM-enriched log events <em>(Rating: 2)</em></li>
                <li>LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis <em>(Rating: 2)</em></li>
                <li>LogBERT: Log anomaly detection via BERT <em>(Rating: 1)</em></li>
                <li>LogGPT: Log anomaly detection via GPT <em>(Rating: 1)</em></li>
                <li>LogRobust: Robust log-based anomaly detection (Bi-LSTM) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5661",
    "paper_id": "paper-270379599",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "FlexLog",
            "name_full": "FlexLog (LLM+ML ensemble for Unstable-Log Anomaly Detection)",
            "brief_description": "A hybrid anomaly-detection system that ensembles a fine-tuned LLM with classical ML models, uses retrieval-augmented generation (RAG) and a cache, and applies majority-vote aggregation to detect anomalies in log template sequences while requiring far fewer labeled examples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral Small 22B (fine-tuned via QLoRA) + KNN, Decision Tree (DT), Single-layer Feedforward Network (SLFN)",
            "model_description": "Ensemble containing an open-source LLM (Mistral Small, 22B params) fine-tuned via parameter-efficient finetuning (4-bit QLoRA / LoRa settings: rank=16, alpha=16, batch=1, steps tuned 500–2500) together with three ML base models (KNN, DT, SLFN). Inference uses structured prompts (description/instruction/relevant-info/input/output), RAG for optional context, a cache of seen template-sequence→label pairs, deterministic low-temperature decoding and majority-vote aggregation.",
            "model_size": "22B",
            "anomaly_detection_method": "PEFT fine-tuning (QLoRA/LoRa) of an LLM on labeled log-template sequences with structured prompting and optional RAG; ensemble majority-vote with classic ML models; cache-lookup to skip inference for identical sequences. LLM output constrained to 'normal'/'anomalous', regeneration strategy if ambiguous.",
            "data_type": "Semi-structured ordered log-template sequences (sequence of template IDs produced by log parsing)",
            "anomaly_type": "Anomalous log sequences due to environmental or software evolution (novel attack types, unseen templates, sequence-level changes such as template addition/removal/shuffling); sequence-level and template-level anomalies in logs",
            "dataset_name": "ADFA-U, LOGEVOL-U (Hadoop/Spark splits), SynHDFS-U (synthetic HDFS variants), SYNEVOL-U (synthetic LOGEVOL variants)",
            "performance_metrics": "Precision / Recall / F1 reported. Representative results: ADFA-U (ULAD average): F1=0.704 (FlexLog) vs LightAD F1=0.677; LOGEVOL-U average F1 reported ~0.928 vs top baseline ~0.910; SynHDFS-U average F1 ~0.971; SYNEVOL-U average F1 ~0.963. When trained on same limited subsets, FlexLog gains up to +13 percentage points F1 on ADFA-U at D#=500. Inference latency per log sequence: 0.771–0.988 s (dataset-dependent). Training time dominated by LLM (hours); ML models train in seconds.",
            "baseline_comparison": "FlexLog outperforms a suite of traditional and deep-learning baselines (LightAD, NeuralLog, LogRobust, CNN, DeepLog, LogAnomaly, etc.), beating the top baseline by at least 1.2 percentage points in F1 across datasets while using far fewer labeled unique sequences (labeled-data usage reduction between 62.87 and 78.43 percentage points depending on dataset). When compared under identical limited-training subsets, FlexLog consistently exceeds baselines (average F1 improvements up to 13 pp at D#=500).",
            "limitations_or_failure_cases": "Higher inference cost than lightweight ML (though &lt;1s per sequence in reported env); sensitivity to extreme class imbalance where poorly-trained ML base models can harm ensemble (on extremely imbalanced LOGEVOL Spark and SYNEVOL-U ensembles, 'w/o ML' Mistral-only performed better); non-deterministic LLM outputs require temperature control and regeneration; potential pretraining-data leakage risk (mitigated by de-duplication and choice of datasets); cache assumes identical sequences map to same label (may fail under extreme evolution); ensemble majority-vote (tie→normal) is simple and may not be optimal in some scenarios.",
            "uuid": "e5661.0",
            "source_info": {
                "paper_title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Mistral Small (22B)",
            "name_full": "Mistral Small 22B",
            "brief_description": "An open-source large language model used as the LLM base in FlexLog; fine-tuned with PEFT (QLoRA/LoRa) for sequence-level log anomaly classification and used both inside the ensemble and standalone.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mistral Small 22B",
            "model_description": "Open-source transformer LLM with ~22 billion parameters (referred to as Mistral Small in the paper). In FlexLog it was fine-tuned with 4-bit QLoRA (rank=16, alpha=16) using Unsloth tooling; inference configured with low temperature (e.g., 0.1) and regeneration attempts for ambiguous outputs.",
            "model_size": "22B",
            "anomaly_detection_method": "Parameter-efficient fine-tuning (QLoRA) on labeled log-template sequence prompts; RAG-augmented prompts when external context exists; prompts structured into description/instruction/relevant information/input/output; output token predicted as 'normal'/'anomalous'. Used as a base model in an ensemble (majority voting) or standalone predictor.",
            "data_type": "Log template sequences (ordered sequences) — semi-structured sequences",
            "anomaly_type": "Novel/unseen templates, sequence-level order anomalies, anomalies from injected/simulated attacks and faults in ADFA/LOGEVOL/HDFS datasets",
            "dataset_name": "ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U",
            "performance_metrics": "As a core base model, removing Mistral produces the largest F1 drop (max reported −6.7 pp on ADFA-U adduser). Standalone Mistral (w/o ML) performed comparably to full FlexLog on some datasets and outperformed the ensemble on extremely imbalanced training sets (LOGEVOL-U Spark and SYNEVOL-U). Overall Mistral-based FlexLog matched GPT-4o performance in experiments.",
            "baseline_comparison": "Mistral in FlexLog matched the closed-source GPT-4o's effectiveness on these ULAD tasks and outperformed Llama 3.1 (8B) in the paper's comparisons. When combined with ML base models, it yielded better data efficiency and overall F1 than pure ML baselines.",
            "limitations_or_failure_cases": "Non-deterministic generation necessitates temperature tuning and regeneration logic; inference cost and latency dominate FlexLog runtime; possible inclusion of dataset sequences in pretraining corpora is a threat to internal validity (mitigated by choosing datasets created after model cutoff where possible).",
            "uuid": "e5661.1",
            "source_info": {
                "paper_title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GPT-4o (closed-source)",
            "name_full": "GPT-4o (OpenAI)",
            "brief_description": "A closed-source advanced LLM evaluated as an alternative LLM base in FlexLog; fine-tuned via OpenAI API for the ULAD task and shown to produce comparable effectiveness to Mistral but at monetary and latency cost.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_description": "Closed-source multi-billion-parameter family model by OpenAI; in this work GPT-4o was fine-tuned via provider API (API-based fine-tuning) for the ULAD prompts and used as an LLM base in ensemble experiments.",
            "model_size": null,
            "anomaly_detection_method": "API-based fine-tuning (OpenAI fine-tune endpoints) on structured prompts (same prompt template as for open-source LLMs), used either as the single LLM base or replacing Mistral in the FlexLog ensemble.",
            "data_type": "Log template sequences (ordered sequences)",
            "anomaly_type": "Same log sequence anomalies (unseen templates, sequence-level changes, attack-induced anomalies)",
            "dataset_name": "ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U",
            "performance_metrics": "Reported to achieve comparable F1 to Mistral in the experiments (no statistically significant differences dataset-level between Mistral and GPT-4o in most datasets).",
            "baseline_comparison": "Comparable effectiveness to Mistral; unlike Mistral, GPT-4o incurs API costs and has unpredictable latency and less control over fine-tuning internals.",
            "limitations_or_failure_cases": "High financial cost per API use; variable latency; less control for PEFT-style tuning; ethical / data-leakage risk if pretraining overlaps with evaluation data; hidden internals limit experimentation choices.",
            "uuid": "e5661.2",
            "source_info": {
                "paper_title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama 3.1 8B",
            "name_full": "Llama 3.1 8B",
            "brief_description": "An open-source LLM baseline evaluated in FlexLog experiments; smaller-capacity model (8B) fine-tuned with QLoRA but underperformed compared to Mistral and GPT-4o on ULAD.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama 3.1 8B",
            "model_description": "Open-source transformer LLM with ~8 billion parameters; fine-tuned via 4-bit QLoRA and Unsloth in the paper's experiments with the same prompt/RAG setup used for other LLMs.",
            "model_size": "8B",
            "anomaly_detection_method": "PEFT fine-tuning (QLoRA) on structured prompts with optional RAG context; evaluated as a replacement for Mistral in the FlexLog ensemble.",
            "data_type": "Log template sequences (ordered sequences)",
            "anomaly_type": "Same types of log anomalies (unseen templates, sequence-level anomalies)",
            "dataset_name": "ADFA-U, LOGEVOL-U, SynHDFS-U, SYNEVOL-U",
            "performance_metrics": "Llama-based FlexLog variants yielded lower F1 than Mistral and GPT-4o across datasets (specific deltas reported in Table 15 of the paper).",
            "baseline_comparison": "Underperformed compared to Mistral and GPT-4o on the ULAD benchmarks in this paper.",
            "limitations_or_failure_cases": "Lower capacity correlated with lower detection effectiveness; fine-tuned Llama 3.1 8B did not match higher-capacity LLMs for unseen-template generalization.",
            "uuid": "e5661.3",
            "source_info": {
                "paper_title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LogPrompt (related work)",
            "name_full": "LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis",
            "brief_description": "A prior approach that leverages prompting and in-context learning with LLMs (e.g., GPT-3, Vicuna) for online log parsing and anomaly detection via few-shot/zero-shot prompts; mentioned as related work and not used as a baseline here.",
            "citation_title": "LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis",
            "mention_or_use": "mention",
            "model_name": "GPT-3 / Vicuna (in-context prompting)",
            "model_description": "Prior methods used LLMs in in-context learning (ICL) mode (no fine-tuning) for tasks like log parsing and message-level anomaly detection; these methods rely on prompt demonstrations rather than PEFT.",
            "model_size": null,
            "anomaly_detection_method": "Prompt-based in-context learning (zero-shot / few-shot) for parsing and message-level anomaly detection (different from sequence-level ULAD in FlexLog); not fine-tuned in the referenced work",
            "data_type": "Log messages and message-level parsing (tokenized text), primarily message-level rather than sequence-level",
            "anomaly_type": "Message-level anomalies / parsing errors / detection of abnormal messages; differs from sequence-level anomalies studied in FlexLog",
            "dataset_name": null,
            "performance_metrics": "Referenced in related work; not experimentally compared in this paper (excluded as baseline because it focuses on message-level detection rather than sequence-level labels).",
            "baseline_comparison": "Mentioned as promising for in-context solutions but with limitations (cost, latency, poor generalizability of ICL per Mosbach et al.) and therefore not adopted as a main baseline in this study.",
            "limitations_or_failure_cases": "In-context learning can exhibit poor generalizability on challenging tasks and is costly/unreliable with closed-source LLM APIs; moreover, message-level outputs do not directly map to sequence-level ULAD labels used here.",
            "uuid": "e5661.4",
            "source_info": {
                "paper_title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LogBERT / LogGPT / LLMeLog (related LLM methods)",
            "name_full": "Representative LLM-based log analysis methods (LogBERT, LogGPT, LLMeLog)",
            "brief_description": "Prior works that adapted LLMs or transformer models for log anomaly detection or log enrichment: LogBERT used BERT to learn semantics of normal logs; LogGPT fine-tuned GPT-2 with RL; LLMeLog enriched log events using LLMs — these are cited as related work.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "BERT, GPT-2, GPT-3.5 variants (depending on the method)",
            "model_description": "Various transformer-based LLM adaptations: LogBERT (BERT-based encoders), LogGPT (GPT-2 fine-tuned with RL), LLMeLog (LLM-enriched features), typically adapted to log data by fine-tuning or prompt-enrichment.",
            "model_size": null,
            "anomaly_detection_method": "Approaches vary: pretrain+fine-tune (BERT-style), RL-fine-tuning for generation models, LLM-based retrieval/enrichment; generally used for message- or sequence-level anomaly scoring or representation.",
            "data_type": "Logs (messages, templates, sequences) — both message-level and sequence-level depending on work",
            "anomaly_type": "Semantic deviations, next-event prediction mismatches, message-level anomalies and enriched-event anomaly detection",
            "dataset_name": null,
            "performance_metrics": "Cited in related work; concrete metrics depend on each cited study (precision/recall/F1 commonly used).",
            "baseline_comparison": "Cited as prior art that influenced FlexLog's use of RAG, prompt design, and fine-tuning strategies; FlexLog positions itself as combining LLM strength with classical ML detectors to improve data efficiency relative to pure ML or previous LLM-only methods.",
            "limitations_or_failure_cases": "Several prior LLM methods focus on message-level detection (not suitable for sequence-level ULAD), or rely on closed-source APIs (cost/latency); also, in-context methods are sometimes inferior to fine-tuned models on hard tasks.",
            "uuid": "e5661.5",
            "source_info": {
                "paper_title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "EvLog: Identifying anomalous logs over software evolution",
            "rating": 2,
            "sanitized_title": "evlog_identifying_anomalous_logs_over_software_evolution"
        },
        {
            "paper_title": "Robust log-based anomaly detection on unstable log data",
            "rating": 2,
            "sanitized_title": "robust_logbased_anomaly_detection_on_unstable_log_data"
        },
        {
            "paper_title": "LLMeLog: An approach for anomaly detection based on LLM-enriched log events",
            "rating": 2,
            "sanitized_title": "llmelog_an_approach_for_anomaly_detection_based_on_llmenriched_log_events"
        },
        {
            "paper_title": "LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis",
            "rating": 2,
            "sanitized_title": "logprompt_prompt_engineering_towards_zeroshot_and_interpretable_log_analysis"
        },
        {
            "paper_title": "LogBERT: Log anomaly detection via BERT",
            "rating": 1,
            "sanitized_title": "logbert_log_anomaly_detection_via_bert"
        },
        {
            "paper_title": "LogGPT: Log anomaly detection via GPT",
            "rating": 1,
            "sanitized_title": "loggpt_log_anomaly_detection_via_gpt"
        },
        {
            "paper_title": "LogRobust: Robust log-based anomaly detection (Bi-LSTM)",
            "rating": 1,
            "sanitized_title": "logrobust_robust_logbased_anomaly_detection_bilstm"
        }
    ],
    "cost": 0.022032999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs
9 Oct 2025</p>
<p>Fatemeh Hadadi 
Qinghua Xu et.qinghua@gmail.com 
Lero 
Lionel Briand lbriand@uottawa.ca. 
Domenico Bianculli domenico.bianculli@uni.lu </p>
<p>University of Ottawa
Canada</p>
<p>University of Limerick
Ireland</p>
<p>DOMENICO BIANCULLI
University of Luxembourg
Luxembourg</p>
<p>University of Ottawa
Canada</p>
<p>University of Limerick
Ireland</p>
<p>Fatemeh Hadadi
University of Ottawa
OttawaCanada</p>
<p>University of Limerick
Lero, LimerickIreland</p>
<p>Domenico Bianculli
University of Luxembourg
LuxembourgLuxembourg</p>
<p>Lionel Briand
University of Ottawa
OttawaCanada</p>
<p>University of Limerick
LimerickIreland</p>
<p>University of Ottawa
University of Luxembourg University of Ottawa Université d'Ottawa University of Ottawa Université d'Ottawa</p>
<p>LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs
9 Oct 2025280B552A83FECE9C10FE0430D68E0D0410.1145/3771283arXiv:2406.07467v4[cs.SE]Received Block 4 from 12.2.1.6 Received Block &lt;<em>&gt; from &lt;</em>&gt; Header Content Dynamicunstable logsanomaly detectiondata efficiencyensemble learninglarge language models
Most log-based anomaly detectors assume logs are stable, though in reality they are often unstable due to software or environmental changes.Anomaly detection on unstable logs (ULAD) is therefore a more realistic, yet under-investigated challenge.Current approaches predominantly employ machine learning (ML) models, which often require extensive labeled data for training.To mitigate data insufficiency, we propose FlexLog, a novel hybrid approach for ULAD that combines ML models -decision tree, k-nearest neighbors, and a feedforward neural network -with a Large Language Model (Mistral) through ensemble learning.FlexLog also incorporates a cache and retrieval-augmented generation (RAG) to further enhance efficiency and effectiveness.To evaluate FlexLog, we configured four datasets for ULAD, namely ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U.FlexLog outperforms all baselines by at least 1.2 percentage points (pp) in F1 score while using much less labeled data (62.87 pp reduction).When trained on the same amount of data as the baselines, FlexLog achieves up to a 13 pp increase in F1 score on ADFA-U across varying training dataset sizes.Additionally, FlexLog maintains inference time under one second per log sequence, making it suitable for most applications, except latency-sensitive systems.Further analysis reveals the positive impact of FlexLog's key components: cache, RAG and ensemble learning.</p>
<p>Introduction</p>
<p>Various software-intensive systems, such as online service systems and Big Data systems, have permeated every aspect of people's daily lives.As the prevalence of such systems continues to grow, the potential impact of software failures has become increasingly significant.A critical software failure can result in service interruptions, financial losses and, in severe cases, poses threats to human safety [49].</p>
<p>Log-based anomaly detection has emerged as a promising approach to enhancing the dependability of software-intensive systems.An anomaly detector aims to discern anomalous patterns within system logs, which serve as vital indicators of the system's operational state.Early research predominantly employed classical machine learning techniques, such as Principal Component Analysis [90], Isolation Forest [58], and one-class SVM [34] for automated anomaly detection.However, these methods overlook the contextual information of the logs and, as a result, exhibit less effectiveness on more challenging cases [39,51,102].learning) [29,59,101].An alternative to in-context learning is fine-tuning, where extra training on domain-specific data is required.While in-context learning has been more widely studied because it does not require additional training and can be applied directly with prompts, Mosbach et al. [69] highlighted its poor generalizability on challenging tasks.Drawing from this observation, fine-tuning may be a more suitable strategy for ULAD when using LLMs.</p>
<p>Most recent works [29,43,52,87,101,104] in log analysis focused on using closed-source LLMs from OpenAI, due to their user-friendly environment and effective performance.However, these LLMs induce a significant financial cost and show unpredictable latency during training and inference [41].On the other hand, open-source LLMs are free to use, and we have some degree of control in terms of fine-tuning algorithms and inference time.</p>
<p>Though a fine-tuned LLM can address challenges C1, C2, and C3 faced by ML methods, they are inherently designed for textual understanding and generation rather than the detection of anomalous patterns in logs.Conversely, existing anomaly detectors using ML models such as Decision Tree (DT) and Single-layer Feedforward Network (SLFN) have proven to be effective in the SLAD task when abundant data is available for training [96], demonstrating their capacity to detect anomalous patterns.This indicates that combining ML methods with an LLM would leverage the strengths of both approaches, ML models' ability to detect anomalous patterns and fine-tuned LLM's capacity to handle scarce labeled data effectively.</p>
<p>To this end, we propose FlexLog, a novel approach that requires significantly less labeled data for ULAD compared to ML methods.FlexLog integrates ML-based anomaly detectors and an LLM, combining their strengths to enhance effectiveness and data efficiency.We summarize our contributions as follows.</p>
<p>• Dataset configuration for ULAD.Most existing benchmark datasets contain stable logs, used for the SLAD task.In this paper, we selected three of these datasets-HDFS, LOGEVOL, and ADFA-LD (referred to as ADFA for brevity hereafter)-and configured four unstable datasets for ULAD, namely SynHDFS-U, LOGEVOL-U, SYNEVOL-U, and ADFA-U, by deliberately introducing disparities between the training and testing datasets.To eliminate the influence of data leakage (C3) [96] and further increase instability, we performed deduplication on each dataset, ensuring that any data samples included in the testing datasets were excluded from the training datasets.• FlexLog, a novel approach for ULAD equipped with practical strategies to boost effectiveness and efficiency.FlexLog uses average-based ensemble learning to combine the predictive strengths of a fine-tuned LLM and ML methods, capturing intricate anomalous patterns with only limited labeled data for training.Specifically, to address C2, FlexLog employs parameter-efficient fine-tuning (PEFT) of a pretrained LLM, leveraging its vast embedded knowledge to mitigate the constraints of scarce labeled data.To tackle C1, FlexLog integrates retrieval-augmented generation (RAG) to dynamically incorporate external knowledge and enhance the model's adaptability to unstable log distributions.Additionally, a cache mechanism improves computational efficiency by eliminating redundant operations.• State-of-the-art effectiveness and data efficiency for ULAD.To evaluate FlexLog, we first compare it against baselines trained on full datasets, even though FlexLog itself is trained on significantly smaller datasets.This comparison is conducted on two realworld datasets (ADFA-U and LOGEVOL-U) and two synthesized datasets (SynHDFS-U and SYNEVOL-U).Experimental results show that FlexLog achieves state-of-the-art effectiveness, outperforming the top baseline by at least 1.2 percentage points (pp) in terms of F1 score, while reducing the usage of labeled data by more than 62.87 pp.Further, we assess the data efficiency of FlexLog by comparing it with baselines when trained on the same datasets.Experiment results on ADFA-U show that FlexLog consistently outperforms all baselines across varying training dataset sizes, except the extreme data scarcity scenario (the training dataset size is 50), where all methods exhibit poor performance due to insufficient labeled data.FlexLog achieves a maximum gain of 13 pp in F1 score when the training dataset size is 500.This confirms FlexLog is the most effective choice when only limited labeled data is available.The rest of the paper is organized as follows.Section 2 presents the basic definitions and concepts that will be used throughout the paper.Section 3 describes our data-efficient anomaly detection approach, FlexLog.Section 4 presents our experimental design.Section 5 outlines our results, discusses the implications, and describes the threats to the validity of our study.Section 6 presents related works and finally, Section 7 concludes and suggests future directions for research and improvement.</p>
<p>Background</p>
<p>Logs</p>
<p>Logs are semi-structured or unstructured text generated by logging statements (e.g., "logging.info('Received Block %d from %s',id, ip)") in source code [33].The main concepts related to logs are log message, log message sequence, log template, and log template sequence, which we explain below and exemplify in Figure 1.</p>
<p>A log message contains two main components: the header (e.g., timestamp or log level), and the content, depicted as grey-dotted and green boxes in Figure 1, respectively.The content of a log message can be further divided into static and dynamic parts.The static parts refer to the fixed text written by developers in the logging statement, e.g., "Waiting to Receive Block from" and "Received Block from"; the dynamic parts are expressions evaluated at runtime, such as the actual block id "4" and IP address "12.2.1.6".</p>
<p>A log template, also called event template or log key, is usually obtained through log parsing [100], which masks the dynamic parts of the log message content with a special symbol, such as "&lt;*&gt;".Compared to log messages, log templates eliminate the influence of specific values in the dynamic parts, enabling downstream tasks (e.g., anomaly detection [50], log summarization [60]) to focus on analyzing patterns within logs, without being confused by variations in concrete values.</p>
<p>A log message sequence is a log fragment consisting of multiple log messages, which typically records the execution flow of a specific job or process.A log message sequence consists of log messages that either pertain to a specific task (i.e., session-based partitioning) or are grouped within a fixed-size window (i.e., sliding/fixed window partitioning).Session-based partitioning groups log messages based on their session IDs, thereby creating log sequences that encapsulate activities within sessions.On the other hand, sliding/fixed window partitioning employs a fixed-size window to group log messages, generating log sequences that capture a snapshot of system activity over time.</p>
<p>Parsing a log message sequence yields a log template sequence (as shown at the bottom of Figure 1).We remark that "log template sequence" is often referred to simply as "log sequence" in the literature; therefore, for brevity, we adopt the term log sequence throughout this paper.</p>
<p>Anomaly Detection on Logs</p>
<p>Anomalies in logs refer to logs that do not conform to the normal behavior of a system [33].Logbased anomaly detection represents a binary classification task to identify anomalies from logs.Depending on their distributions, logs can be divided into two categories: stable logs (Definition 2.1) and unstable logs (Definition 2.2).Definition 2.1 (Stable Logs).Logs drawn from a single underlying distribution, i.e., their structure and semantics remain consistent in all the logs.Definition 2.2 (Unstable Logs).Logs drawn from more than one underlying distribution.</p>
<p>Stable logs are typically generated from systems whose logging behaviors and operating environment remain unchanged over time, resulting in consistent structure and semantics of logs.In contrast, unstable logs originate from multiple distributions caused by system or environmental changes.System evolution refers to internal changes within a software system, such as version upgrades.Developers often modify source code, including logging statements, resulting in changes to logs.As Kabinna et al. [45] reported, around 24 %-40 % of log statements change during their lifetime.Taking the public dataset LOGEVOL as an example, 24 % of logging statements were modified during the system upgrade from Spark version 2 to 3 [39].As a result, 14 % of logs collected in Spark 3 contain new log templates induced by system evolution.This figure represents a conservative estimate of the percentage of unstable logs, as other causes of instability (e.g., reordering of logging statements during execution) are not accounted for due to the lack of a mapping between execution paths and their log distributions.Nonetheless, these results clearly highlight that unstable logs are common in practice, underscoring the importance of handling instability caused by system evolution.Environmental evolution, on the other hand, represents the changes of external factors, such as a shift of user distribution and the emergence of unseen attack types.These changes affect both normal and abnormal patterns in the logs by altering the structure, content, or frequency of log messages.For example, shifts in user distributions-such as changes in user geographic regions-may introduce new log sequences or alter the frequency of existing ones due to differences in usage patterns, device configurations, or regional preferences.Similarly, novel or previously unseen attacks may generate anomalous logs with sequences or templates that have not been observed in the earlier log distribution.</p>
<p>Built on the definitions of stable and unstable logs, we define two corresponding anomaly detection tasks, namely Anomaly Detection on Stable Logs (SLAD) and Anomaly Detection on Unstable Logs (ULAD) as defined in in Definition 2.3 and 2.4, respectively.Definition 2.3 (Anomaly Detection on Stable Logs).SLAD is a binary classification task that aims to predict anomalies in stable logs, i.e., the training data and testing data follow the same distribution.SLAD is the predominant configuration in the literature [53,102], largely because existing benchmark datasets often assume a stable software system.In this configuration, the training dataset  train = { 1 ,  2 , ...,   } and the testing dataset  test  = { +1 ,  +2 , ...,  + } are sampled from the same distribution.Despite its wide adoption, SLAD does not reflect challenges faced by real-world applications, e.g., evolving systems or operating environments.In contrast, ULAD (Definition 2.4) considers a more challenging yet realistic scenario.Specifically, the training dataset  train consists of stable logs collected under consistent conditions, while the test dataset  test  contains unstable logs resulting from system or environmental evolution.</p>
<p>Evaluation on De-duplicated Datasets.As demonstrated in previous work [96], data leakage is prevalent in existing benchmark datasets, artificially inflating the effectiveness of anomaly detectors.Data leakage entails an overlap between testing and training data, i.e., some log sequences in the testing dataset have already been seen in the training dataset.This phenomenon affects both the SLAD and ULAD tasks.To eliminate the risk of data leakage, we remove seen testing log sequences that are already present in the training dataset  train , yielding a new testing dataset for ULAD and SLAD, denoted as  test  † and  test  † respectively, defined in Equations 1 and 2.
𝐷 test 𝑈 † = 𝐷 test 𝑈 \ 𝐷 train(1)𝐷 test 𝑆 † = 𝐷 test 𝑆 \ 𝐷 train(2)
 test  † and  test  † consist of only unseen log sequences.These sequences differ from the ones in the training dataset at two possible levels: 1) template level (when there is an unseen log template in the sequence), 2) sequence level (when all the log templates are already mentioned in the training data but their order is new).Unseen log sequences can be either stable or unstable, depending on their underlying log distributions.As mentioned by Yu et al. [97], after de-duplication, the effectiveness of anomaly detection models on testing data drops, making it a more challenging task in this realistic scenario.</p>
<p>Illustrative Examples.Figure 2 provides an overview of the de-duplicated ULAD with example log sequences.After system evolution from version 1 to version 2, the first two sequences at the top undergo changes at different levels.In the first sequence,  1 →  2 →  3, template  2 is updated to a new template  2 ′ , representing a change at the template level.The second sequence,  2 →  3 →  1 →  4, experiences a change at the sequence level, where template  1 is no longer present.The last sequence shown,  3 →  1 →  2, is regenerated in the later version without any change, and is therefore marked as a "seen" sequence relative to the training data.During de-duplication, the seen sequence is removed from the test set.The remaining sequences are referred to as unseen log sequences, as they contain no overlapping sequences.</p>
<p>Task Adaptation Strategies for Large Language Models</p>
<p>LLMs typically consist of substantial parameters pretrained on vast and diverse datasets, possessing knowledge across various domains.However, how to effectively adapt pretrained LLMs to domainspecific tasks remains an open problem.Two predominant strategies for task adaptation are in-context learning (ICL) and fine-tuning (FT).</p>
<p>ICL operates without altering the weights of the LLMs [3].Instead, it leverages prompts-structured textual inputs-to guide the model's behavior.These prompts typically include task instructions and, in some cases, a series of demonstrations in a conversation between the user and the assistant.In a classification task, e.g., ULAD, each demonstration consists of an input  paired with its corresponding ground-truth label .When no demonstrations are provided, the approach is referred to as zero-shot ICL, whereas the inclusion of a few demonstrations constitutes a few-shot ICL.</p>
<p>Although ICL is relatively easy to implement, it faces several challenges and limitations, including issues with efficiency, scalability, generalizability, and high financial cost when using closed-source LLMs [20].As an alternative, FT alleviates these issues by training pre-trained LLMs with domainspecific data.In practice, there are two main types of fine-tuning, namely API -based FT and Custom FT.</p>
<p>API-based FT refers to fine-tuning performed through dedicated APIs made available by the LLM provider, e.g., OpenAI [71].This is typically the case for closed-source LLMs, such as GPT-3.5 [73] and GPT-4 [61], for which neither full nor selective fine-tuning is allowed without accessing their APIs.These APIs support fine-tuning a set of prompt-completion pairs or conversations depending on whether LLMs are used in purely generative or conversational settings.</p>
<p>Custom FT, on the other hand, is applicable to open-source LLMs, such as LLama [79] and Mistral [42].Common custom FT techniques include full fine-tuning and parameter-efficient finetuning (PEFT).Let the trainable parameter set of an LLM be denoted as  , the task-specific dataset as , and its associated label set as .</p>
<p>• Full Fine-Tuning: This approach utilizes gradient descent-based optimizer to update  to   , thereby adapting the LLM to a specific task.Specifically, prompts are constructed using  and fed into an LLM.The model's output distribution ŷ is then compared with the corresponding label distribution , using a distribution-level loss, e.g., cross-entropy loss.This loss guides weight updates from  to   through backpropagation.• Parameter-Efficient Fine-Tuning: PEFT preserves original LLM weights while training only a small number of task-specific adapter layers and parameters.There are several types of PEFT methods, including additive, selective, reparameterized, and hybrid PEFT [28].</p>
<p>The predominant PEFT techniques are LoRa [36] and its derivative techniques such as QLoRa [17].Essentially, LoRa uses a low-rank decomposition to reduce computational cost while maintaining performance similar to full fine-tuning as in Equation 3.
𝑊 𝑓 = 𝑊 + Δ𝑊 = 𝑊 + 𝐴𝐵(3)
where  ∈ R and  ∈ R are lower rank matrices compared to  , with dramatically fewer trainable parameters.Such techniques significantly reduce the computational cost while maintaining comparable performance to fully fine-tuned LLMs.In this paper, we propose a novel approach, namely FlexLog, to tackle ULAD by synergizing the capabilities of ML methods and LLMs via ensemble learning.Specifically, FlexLog combines the predictions from trained ML methods and a fine-tuned LLM to make a final decision.This approach leverages the strengths of both paradigms: ML methods excel at capturing anomalous patterns within logs, while LLM brings broad prior knowledge from pretraining, allowing them to adapt to novel log patterns even with limited labeled data.Also, we tackle the three key challenges in ULAD-unstable log distribution (C1), data insufficiency (C2), and data leakage (C3) -by employing ensemble learning of ML and LLM, PEFT, and de-duplication in the testing data, respectively.Additionally, we further tackle unstable log distributions (C1) by using RAG in prompting when relevant external information is available regarding log sequences.</p>
<p>Figure 3 illustrates the architecture of FlexLog, which comprises four main components: preprocessing ( § 3.1), cache-empowered inference ( § 3.2), context-enriched prompting ( § 3.3), and ensemble learning ( § 3.4).FlexLog is designed to predict whether unstable logs-generated by software systems that have undergone software or environmental evolution-are anomalous.Specifically, the preprocessing component converts raw stable and unstable logs into log sequences by extracting log templates and grouping them into log sequences using either window-based or session-based partitioning.For illustrative purposes, consider a log sequence ls  as an example.The cache-empowered inference component first checks if ls  matches an existing entry in the cache.If a match is found, FlexLog retrieves the stored prediction as the output label directly.Otherwise, the context-enriched prompting component uses ls  in a structured prompt enriched with contextual information, such as log event descriptions and Linux system call names.This prompt includes key fields such as description, instructions, relevant information (optional), input, and output.It serves as input both for fine-tuning of and for inference with an LLM, which acts as one of FlexLog's base models.To construct the ensemble, the ensemble learning component fine-tunes the LLM-based model (e.g., Mistral or Llama) and trains the ML-based models (e.g., DT and KNN [97]) on a limited dataset sampled from the preprocessed stable logs to maintain data efficiency and reduce training overhead.During inference, if no matching log sequence is found in the cache, binary anomaly predictions from these base models are aggregated using majority voting to produce the final decision.This prediction is then stored in the cache to optimize future queries.In the following sections, we provide a detailed explanation of each component.</p>
<p>Preprocessing</p>
<p>As illustrated in the first box of Figure 3, the preprocessing component transforms raw log messages to log sequences via two primary processes, namely parsing and partitioning.Given a raw log message (e.g., "12:03 INFO Sent Block 12"), we leverage a log parser (e.g., Drain [30]) to identify the static parts (e.g., "Sent Block") and dynamic parts (e.g., "12") and replace the latter with the symbol "&lt;*&gt;".</p>
<p>The parsing process identifies unique log templates and assigns the same identifier to all their occurrences, enabling the cache-empowered inference component to track processed log sequences and the context-enriched prompting component to incorporate relevant template information during prompt construction.The partitioning process aggregates log templates into log sequences based on their session IDs or a fixed-size window (as described in § 2.1).</p>
<p>Cache-empowered Inference</p>
<p>FlexLog maintains a cache  as illustrated at the bottom of Figure 3.  stores previously seen log sequences along with their predicted labels.Given a log sequence   under detection, FlexLog first queries cache  for a matching entry.If an identical log sequence is found, the corresponding label   is retrieved and used directly, bypassing the need for additional computation by RAG and ensemble learning.Conversely, if no match is found in , FlexLog performs context-enriched prompting ( § 3.3) and leverages ensemble learning ( § 3.4) to predict the label for   and subsequently adds the new log sequence and its label to the cache.To reduce storage overhead and remain independent of template length, each log sequence is represented as an ordered sequence of log template IDs rather than raw log messages.</p>
<p>The maintenance of  involves four core functions, namely query, add, update, and delete.The query function compares the input log sequence against the entries in  and returns the identical entry along with its associated label if a match is found.The add function inserts a new log sequence and its predicted label into  if it is not present.The delete function removes a specific entry from , allowing FlexLog to manage cache size or discard outdated information.The update function modifies an existing entry's label, incorporating human corrections to improve future predictions.By leveraging the delete and update functions, the cache mechanism enables flexibility to adjust to memory constraints and future updates of the sequences' labels, respectively.</p>
<p>Context-enriched Prompting</p>
<p>This component processes the log sequences that are not stored in the cache, preparing them for the LLMs used in FlexLog.Log sequences are inherently challenging for LLMs to understand because these models are primarily designed for natural language processing (NLP) tasks and are better suited to processing and reasoning over textual data.To bridge this gap, we place log sequences with their log templates into semi-structured prompts that resemble natural language, enabling LLMs to leverage their NLP capabilities effectively.The RAG component inside the prompt aims to integrate relevant external information with log sequences acquired from preprocessing, formulating semi-structured prompts.To devise an effective prompt structure for ULAD, we adopt the tactics reported by Winteringham [86].Concretely, as illustrated in Figure 4, each prompt comprises five parts, namely, description, instruction, relevant information, input, and output.Notably, the retrieved context is included only when pertinent information is available.We provide the details of each part next.Description.This part sets the overall context of the task for the LLM.It provides a high-level overview of what the model is expected to accomplish.For instance, as shown in Figure 4, the description explains that the LLM should generate an output that appropriately completes the task request.While this part does not specify the input or output format explicitly, it prepares the LLM by providing a concise summary of the task objective.Instruction.The instruction part formally introduces the task by describing its goal, input format, and output expectations.It specifies how the LLM should process the input and produce the desired label.After experimenting with multiple instruction formats, we present the most effective formulation in Figure 4.In this part, we describe the delimiter for log sequences (i.e., "brackets") and add "No explanation is required", instructing the LLM to output only the label.Relevant Information (Optional).This part includes additional information related to the log sequence, which enhances the LLM's ability to interpret the input.When available, contextual data is retrieved and presented in this part to provide background information.This information can include descriptions of specific log templates, system calls, or other contextual elements relevant to the log sequence under analysis.For example, the right-hand side of Figure 4 includes system call descriptions, such as setxattr or semtimedop, which help clarify the function and purpose of the operations within the log sequence.Including such information allows the LLM to better understand relationships between the components of the log sequence, improving its ability to generate accurate predictions.However, if no relevant external context is available, this part of the prompt is omitted.Input.This part presents the log sequence to be analyzed in the format "log sequence: {log_sequence}", where {log_sequence} is a placeholder dynamically replaced with different log sequences during fine-tuning and inference.For example, the right-hand side of Figure 4 shows the replacement of the placeholder with the log sequence "[io_getevents, setxattr, io_cancel, semtimedop]" from the ADFA-U dataset.Output.The output section guides an LLM in predicting the label of the input log sequence.It provides a formatted prompt that ends with "label:", prompting the LLM to generate the next token as either "normal" or "anomalous", based on its analysis of the log sequence.</p>
<p>Ensemble Learning</p>
<p>The goal of this component is to maximize the utility of limited labeled data by integrating different base models, each offering a unique perspective on performing ULAD effectively.To train the base models, we leverage the stable logs collected from software systems before undergoing the software or environment evolution.A salient feature of FlexLog is employing both ML-and LLM-based models as base models as introduced in § 1. Due to LLMs' pretraining on diverse corpora, they can be effectively fine-tuned with only limited data.Consequently, we sample only a subset from the stable logs to create the training dataset.Using this training dataset, FlexLog fine-tunes an LLM and fits  ML models {ML 0 , . . ., ML −1 }.</p>
<p>For a given LLM LLM, FlexLog adopts (see Equation 4) API-based fine-tuning for closed-source LLMs (e.g., GPT 4o) and LoRa for open-source LLMs (e.g., Llama and Mistral); details about APIbased fine-tuning and LoRa are provided in Section 2. We denote the fine-tuned LLM as LLM  .
LLM 𝑓 = API -based_𝐹𝑇 (LLM, data = 𝑆 train , label = 𝐿) LLM ∈ Closed-source LLMs LoRa(LLM, data = 𝑆 train , label = 𝐿) LLM ∈ Open Source LLMs (4)
For a given ML model ML, gradient descent optimization is applied for neural network-based models, while model-specific fitting methods are used for non-parametric models such as DT (Equation 5).Note that K-Nearest Neighbors (KNN) does not involve a traditional training or fitting process but instead relies on distance-based comparison during inference.The resulting learned ML model is denoted as ML  .
ML 𝑓 =          gradient_descent (ML, data = 𝑆 train , label = 𝐿) ML ∈ Neural Networks fit_dt (ML, data = 𝑆 train , label = 𝐿) ML = DT distance_based_comparison ML = KNN(5)
After training individual models, the next step is to combine their outputs using majority voting, a commonly used, simple yet effective ensemble learning technique in the literature [75,103,106].Formally, let M = { 0 ,  2 , . . .,   −1 } be the set of  learned base models, with M  ∈ M representing either a learned LLM LLM  or an ML-based method ML  .For a given log sequence ls  , each base model M  predicts the label   of , equals 1 if anomalous, and 0 if normal.The final label is determined by a majority voting function MV (•) among all base models, as shown in Equation 6.
𝜙 𝑖 = MV (ls 𝑖 ) = 1, if 𝑁 −1 𝑖=0 𝑦 𝑖 &gt; 𝑁 2 0, otherwise(6)
Here,   represents the final prediction for ls  .In case of a tie (when exactly half of the votes are normal), the sequence is classified as normal, following our assumption that anomalies are rare.RQ4 (configuration impact) How does the performance of FlexLog vary under different configurations, including ablations of base models, RAG, and the cache, as well as alternative LLM choices?RQ1 investigates the overall effectiveness of FlexLog for the ULAD, comprising two sub-RQs.With RQ1.1, we aim to demonstrate the strengths of FlexLog when only limited labeled data is available.Specifically, we compare baselines trained with full datasets against FlexLog trained with much smaller subsets.With RQ1.2, we aim to highlight the distinct advantage of FlexLog in handling gradually increasing instabilities in ULAD.To this end, we assess the effectiveness of FlexLog and baselines on SLAD and under the influence of varying ratios of instability in both log templates and sequence levels.RQ2 focuses on data efficiency by training FlexLog and baselines on progressively larger subsets of ADFA-U (e.g., containing 50, 500, 1000, 1500, and 2000 training samples).Due to computational constraints, we cannot perform data efficiency analysis on all datasets.Hence, we prioritize our most challenging dataset ADFA-U for this analysis.RQ3 investigates the time efficiency of FlexLog during training and inference.While employing LLMbased approaches (e.g., FlexLog) may enhance effectiveness, it often comes at the cost of increased training and inference time.This question aims to evaluate the trade-offs between effectiveness and time efficiency, providing practical insights for those considering the use of LLMs in similar tasks.Additionally, RQ3 examines the memory efficiency of FlexLog 's cache mechanism during inference, demonstrating its scalability in resource-constrained environments.Lastly, RQ4 involves exploring the impact of different configurations of FlexLog.Specifically, we assess how the exclusion of the cache , the exclusion of RAG in context-enriched prompting, and the choices of base models (e.g., removing some base models from the ensemble or replacing Mistral with other LLMs), affect the overall effectiveness or efficiency of FlexLog.4.2.1 Datasets.We configured four datasets for ULAD from three public datasets, namely ADFA [13], LOGEVOL [39], and HDFS [89].We exclude other popular benchmarks (e.g., BGL [70], Thunderbird [70], and Spirit [70]) because they contain only stable logs, and manually injecting instability is not feasible due to the lack of information about their annotation strategies.Table 1 presents relevant statistics for these three datasets; column "Sys" indicates the system from which the logs were collected."#Log Messages", "#Anomalous Messages", "#Sessions", and "#Log Templates" indicate the number of log messages, anomalous log messages, sessions, and unique log templates in each dataset, respectively.Column "Session Length" indicates the average, minimum, and maximum number of log messages in each session.We elaborate on each dataset next.</p>
<p>Experiment Setup</p>
<p>ADFA.Creech and Hu [13] created the Australian Defense Force Academy Linux Dataset by collecting Linux server operation logs and applying contemporary web attacks.ADFA comprises 2,747,550 log messages, i.e., Linux system calls in this context, of which 317,388 are anomalous (11.5 %).The attacks applied to the system include the exploitation of a TIKI WIKI vulnerability using a Java-based Meterpreter ("java"), password brute-forcing with the Hydra tool ("hydra"), deploying a Linux Meterpreter payload via a poisoned executable ("meter"), leveraging a remote file inclusion vulnerability to deploy a C100 webshell ("web") and creating privilege escalation by adding a superuser account with a poisoned executable ("adduser").</p>
<p>LOGEVOL.Huo et al. [39] introduced the LOGEVOL dataset captured from the real-world operations of Hadoop 2, Hadoop 3, Spark 2 and Spark 3 systems1 .All datasets were generated using HiBench [40] during the operation of 22 cloud computing tasks, such as sorting and classification [32,57].To capture real-world anomaly scenarios into logs, they injected 18 fault types into the system, including network fault, process suspension, process killing, and resource occupation.The Hadoop 2 dataset consists of 2,120,739 log messages (including 1.6 % anomalous) while the Hadoop 3 dataset is made up by 2,050,488 log messages (including 1.4 % anomalous).Notably, 104 out of 303 (33.22 %) log templates from the Hadoop 3 dataset are novel and absent from the Hadoop 2 dataset, reflecting its instability and log template evolution.The Spark 2 dataset involves 931,960 log messages, and the Spark 3 dataset is made up of 1,600,273 log messages.Compared to the Hadoop 2 and Hadoop 3 datasets, the proportion of anomalous logs in the Spark 2 and Spark 3 datasets is significantly lower, with both datasets having an anomaly rate of only 0.1 %. [89] were produced by running MapReduce jobs on Amazon EC2 nodes, consisting of 11,197,954 log messages, of which 284,818 (2.9 %) are anomalous.The average number of log messages in a sequence is 19.32.The total number of unique log templates is 48.This dataset includes 11 types of anomalies, such as the deletion of a block that no longer exists or receiving a block that does not belong to any file.For a comprehensive description of the anomalies, we refer readers to the original paper [89].</p>
<p>HDFS. Hadoop Distributed File System (HDFS) logs</p>
<p>ULAD and SLAD Configuration.</p>
<p>Our experiments involve the evaluation of FlexLog on both the ULAD and SLAD, with ULAD being the primary focus of this paper and SLAD serving as a baseline in RQ1 and RQ2.As mentioned in Section 2, ULAD is characterized by the disparity between the training and testing datasets, whereas SLAD involves training and testing data drawn from the same distribution.Each dataset described in § 4.2.1 is configured to be used for both SLAD and ULAD, consisting of a training dataset D train and a testing dataset D  .Additionally, a small, curated subset D is sampled from each full training dataset for the training of FlexLog.We provide details of the SLAD and ULAD configurations on each dataset next, followed by configurations of D for FlexLog.ULAD Configuration.As discussed in Section 2.2, unstable logs result from system or environmental evolution.To simulate these scenarios, we configured the unstable LOGEVOL dataset LOGEVOL-U for system evolution and the unstable ADFA dataset ADFA-U for environmental evolution.To further investigate the influence of different levels of instability, we include two synthesized datasets in our experiments, namely SynHDFS-U and SYNEVOL-U.These datasets are created by injecting different levels of instability into the HDFS and LOGEVOL datasets, respectively.Table 2 summarizes the ULAD configuration for each dataset and presents their statistics, including the full training dataset size (D  # ), FlexLog's training dataset size ( D # ), and the testing dataset size (D  # ).We also report the duplication ratio, which quantifies data leakage, i.e., log sequences appearing in both training and testing datasets.As discussed in § 1, data leakage allows anomaly detectors to memorize the training data, resulting in artificially inflated effectiveness on the testing data.Hence, we addressed the data leakage issues identified by Yu et al. [96] through de-duplication in each configuration.Specifically, we removed log sequences from the testing dataset if they were already included in the training dataset.→ADFA w/ adduser , denoted as "java", "hydraSSH", "hydraFTP", "meter", "web", and "adduser" hereafter for brevity, respectively.As reported in Table 2, the duplication ratio ranges from 0.31 to 0.34 in different training and testing dataset pairs, indicating that, without de-duplication, approximately 31 % to 34 % log sequences in the testing datasets are already included in the training datasets.</p>
<p>LOGEVOL-U.The LOGEVOL dataset naturally captures software evolution, namely the transition from Hadoop 2 to Hadoop 3, as well as from Spark 2 to Spark 3.These transitions result in internal changes at both template and sequence levels (defined in § 2.1).Hence, we use the Hadoop 2 and Spark 2 datasets for training and, correspondingly, the Hadoop 3 and Spark 3 datasets for testing.The duplication ratios for LOGEVOL Hadoop and LOGEVOL-Spark, as shown in Table 2</p>
<p>SYNEVOL-U.</p>
<p>The ULAD configurations in this dataset aim to simulate different levels of instability by applying internal changes of varying percentages to the LOGEVOL dataset.Huo et al. [39] injected log template/sequence-level changes into the LOGEVOL Spark 2 dataset, with varying injection ratio of 5 %, 10 %, 15 %, 20 %, 25 %, and 30 %. Figure 6 demonstrates the three types of log sequence-level changes injected, firstly introduced by Zhang et al. [102], involving removing or duplicating a log template and shuffling a small subsequence.As shown in Figure 5, we introduce three types of log template-level changes, including adding, removing, or replacing a word in a log template.Huo et al. [39] injected changes in the sequences in a way that sequence labels do not flip.The duplication ratio decreases from 0.6 to 0.18 as the testing set becomes more unstable.</p>
<p>SynHDFS-U.Similar to SYNEVOL-U, we created four ULAD configurations for the HDFS dataset, namely SynHDFS 5% , SynHDFS 10% , SynHDFS 20% , and SynHDFS 30% by changing 5%, 10%, 20%, and 30% of log sequences in the HDFS dataset, respectively.The injection ratios are determined by following common practices in the literature [102].Similar to SYNEVOL-U, we are aware that such changes in log sequences can induce changes in their labels.We only apply sequence-level changes, excluding template-level changes due to the lack of implementation details reported by previous studies [38,56,102].At the sequence-level, to obviate the need for re-labeling, we applied changes only to log templates that are less likely to flip the labels of the entire log sequence.These log templates are identified by a strategy proposed by Xu et al. [91], which combines building a decision tree and manual examination.To reduce the cost of manual examination, we sampled and applied changes to a subset of the HDFS dataset instead of the full dataset.Concretely, we SLAD Configuration.For the ADFA dataset, we drew the training and testing data from the full dataset, containing all six types of anomalies.For LOGEVOL Hadoop 2, Spark 2, and HDFS, we adopt the same training datasets as in their ULAD configurations, whereas the testing datasets differ.While ULAD employs unstable testing data, SLAD uses stable testing data collected from the same system as the training data, specifically from Hadoop 2, Spark 2, and HDFS operations, respectively.Notably, the testing dataset for HDFS SLAD configuration is the same as the one used in its ULAD configuration, a subset sampled from the original testing dataset, but without instability injection.This ensures consistency and a fair comparison between the ULAD and SLAD configuration of HDFS.Also, we did not configure LOGEVOL Hadoop 3 and Spark 3 for SLAD as ULAD because the evolution information from Hadoop 3 and Spark 3 to other versions was not available.</p>
<p>Training Dataset Configuration for FlexLog.In RQ1, we compare FlexLog and the baselines with their respective optimal settings.Baselines are trained on the full training datasets D train , following implementations in their original papers, whereas FlexLog is trained on small subsets D randomly sampled from D train .As reported in the second-to-last column (" D # ") of Table 2, their data sizes are determined empirically for each dataset to achieve the optimal performance of FlexLog.For small datasets with low duplication ratios such as ADFA-U, we randomly selected 1,000 log sequences from their full training dataset.For larger datasets with high duplication ratios such as LOGEVOL-U Hadoop, LOGEVOL-U Spark, SYNEVOL-U, and SynHDFS-U, unique anomalous log sequences are rare, accounting for only 0.2 % to 2 % of the full datasets, respectively.To maximize the use of these rare anomalous log sequences, we included all of them in the fine-tuning datasets and sampled 20 % unique normal log sequences from all unique normal log sequences, preventing excessive duplication.</p>
<p>Baselines.</p>
<p>We considered nine ML methods as baselines in this paper, including four unsupervised, one semi-supervised, and four supervised.Among these methods, LightAD [97] achieves the best performance on the SLAD task.However, the leading approach for ULAD remains undetermined as different evaluation datasets are used in reported studies.Our choice of baselines is also determined by source code availability to ensure the reliability of the implementation.Consequently, we had to exclude models such as SwissLog [56], HitAnomaly [38], EvLog [39], and LLMeLog [29].Our implementations are based on the code provided by Yu et al. [97], Le and Zhang [53], and He et al. [31].We have also not included LogPrompt [59] in our evaluation since it relies on anomaly detection at the message level, ignoring sequential characteristics such as temporal dependencies, whereas our datasets are labeled at the sequence level.</p>
<p>Table 3 shows the main characteristics of the baselines; we provide a brief description in the following.Principal Component Analysis (PCA) [91], a dimensionality reduction method, converts logs into count vectors [16] and then uses the PCA algorithm to detect the label of log sequences by assigning them to either the normal or anomalous space.In this paper, by PCA we refer to the PCA-based model introduced by Xu et al. [91] as an anomaly detector.LogCluster [57] clusters log sequences by computing the similarity of log representations to the centroid of normal logs.DeepLog [21] applies two layers of long short-term memories (LSTMs) in their network [35] to predict the next event from a given log sequence and labels sequences as anomalous if the predicted log is different than the actual log template.LogAnomaly [65] has an architecture similar to DeepLog, but is further improved by adopting semantic embeddings for log templates and adding an attention layer between LSTM layers.PLELog [93] is a semi-supervised strategy that uses normal data as well as a small subset of unlabeled data to train.First, it adopts a clustering method (HDBSCAN [64]) to probabilistically predict the labels of unlabeled data and then uses them to train an attention-based GRU [9] to detect anomalies.</p>
<p>LogRobust [102] uses a pre-trained word vectorizer (FastText [44]) to extract semantic information from log templates and utilizes an attention-based BiLSTM model [76] to detect anomalous log sequences.CNN [62] transforms an input log sequence into a trainable matrix and uses this matrix as input to train a Convolutional Neural Network [48,55] for log-based anomaly detection.NeuralLog [51] extracts the semantic meaning of raw log messages and represents them as semantic vectors, which are then used to detect anomalies through a transformer-based classification model [82].LightAD [97] employes Bayesian method to select the most effective model from a heterogeneous pool of ML/DL algorithms-including KNN [22], DT [7], and SLFN [37]-while simultaneously optimizing hyperparameters for the SLAD task.To ensure fair comparisons, we adopted the same model pool and employed a small, held-out validation dataset to identify the optimal model for each dataset as instructed in Yu et al. [97].The performance of the optimal model, evaluated on test data, serves as LightAD's reported effectiveness.</p>
<p>Evaluation Metrics and Statistical</p>
<p>Testing.To provide a comprehensive evaluation, we assess FlexLog in terms of effectiveness, data efficiency, and time efficiency.Further, we investigate the statistical significance of differences (from a point of view of effectiveness and time efficiency) on each dataset.</p>
<p>Effectiveness To measure the effectiveness of FlexLog, we use Precision, Recall, and F1-score as metrics.We consider TP (true positive) as the number of anomalies that are correctly detected by the model, FP (false positive) as the number of normal log sequences that are labeled as anomalous by the model, and FN (false negative) as the number of anomalous log sequences that the model fails to identify.Precision (P) is calculated by TP TP+FP as the percentage of true anomalies among all anomalies detected by the model.Recall (R) is the proportion of actual anomalies detected, computed by TP TP+FN .F1 score (F1) is the harmonic mean of Precision and Recall, i.e., 2 *  *  + .</p>
<p>Data Efficiency We define data efficiency to be the ability of a method to achieve accurate results while minimizing the use of labeled data for training.Considering a training dataset with D # log sequences, we quantify the usage of labeled data using U # , which represents the number of unique log sequences.Each unique log sequence corresponds to a distinct pattern that requires annotation, meaning that a higher U # reflects greater labeling effort.</p>
<p>A data-efficient method, such as FlexLog, requires only a small subset of the full dataset for training, reducing the overall usage of labeled data.To compare data efficiency across different methods, we introduce the relative metric U % as in Equation 7, which measures the percentage of unique log sequences in the subset relative to the total unique log sequences in the full dataset (denoted by U</p>
<p>𝑓 𝑢𝑙𝑙 #</p>
<p>).
U % = U # U 𝑓 𝑢𝑙𝑙 # (7)
To quantify the reduction in labeled data achieved by data-efficient methods compared to methods trained on full datasets, we define the labeled data usage reduction ΔU % as in Equation 8.A higher ΔU % indicates a greater reduction, demonstrating the superior data efficiency of the method under evaluation, and vice versa.
ΔU % = 1 − U % (8)</p>
<p>Memory Efficiency</p>
<p>We evaluate memory efficiency based on the additional memory required by the cache component during inference.Specifically, we measure the memory overhead introduced by the in-memory cache, which stores predictions for all previously seen unique sequences.To approximate this overhead, we compute the memory consumed by the cache in the structure of a dictionary after processing the entire test set.Since the cache grows incrementally with the number of unique sequences, this measurement represents its maximum size at the end of inference.</p>
<p>Statistical Testing To mitigate the potential influence of randomness on our results, we repeat each experiment on each configuration 5 times and report the average performance across the runs.This ensures our analysis is robust and not unduly influenced by any single random sampling or stochastic training and fine-tuning, providing a reliable evaluation.We further perform Mann-Whitney U test as recommended in [1] on each dataset, resulting in test group sizes of 30 for ADFA-U (6 configurations), 10 for LOGEVOL-U (2 configurations), 20 for SynHDFS-U (4 configurations), and 30 for SYNEVOL-U (6 configurations).The Mann-Whitney U test is a non-parametric statistical test that compares two methods, A and B, without any assumption of the data distribution.It computes a p-value, which indicates whether the observed performance difference is statistically significant.The null hypothesis presumes no significant distinction between performance A and B. If the p-value falls below the commonly used threshold of 0.05, we reject the null hypothesis and conclude that the difference is statistically significant.Conversely, if the p-value is greater than or equal to 0.05, the difference is considered non-significant, meaning the observed difference could be due to randomness.</p>
<p>Other Settings.</p>
<p>We conducted all experiments with on a cloud computing environment containing 28 CPU cores for computation, 2 × Nvidia L40S GPU devices, and 256 GB RAM.</p>
<p>Implementation</p>
<p>In this section, we introduce the implementation details of preprocessing, FlexLog, and the baselines.</p>
<p>4.</p>
<p>3.1 Preprocessing.Two primary steps of preprocessing are parsing and partitioning, as described in Section 3.</p>
<p>Log parsing is used to provide structured context for FlexLog (as explained in § 3.1) and logparsing-based baselines such as LogRobust and CNN.For ADFA-U, parsing is not required since each log message is a one-word system call.For datasets with evolving templates-ADFA-U and SYNEVOL-U -we follow their original authors' practice and use the Prefix Graph parser [10].This parser does not require a training set and is more flexible in handling varying template lengths and substructures compared to fixed-depth approaches such as Drain [30].For SynHDFS-U, we use Drain following the common practice for this specific synthetic dataset [38,102] 2 .SynHDFS-U exhibits instability at the sequence level, but its log templates remain stable; hence, the limitations of Drain in handling evolving templates do not apply in this case.Since each log message in ADFA consists of a one-word system call, the subsequent RAG can easily associate a log message with its relevant information, such as the description of that system call.</p>
<p>Applying a smaller window over long sequences facilitates the localization of anomalies when logs are labeled at the message level.Hence, we applied sliding window-based partitioning with a window size of 50 on LOGEVOL-Hadoop.In contrast, sliding window partitioning is not an option for long sequences in the ADFA, LOGEVOL-Spark, SYNEVOL-U, and HDFS datasets due to the absence of message-level labels.For HDFS, most sessions are short, with only 3.5 % sessions exceeding 30 templates.We followed the implementation of Le and Zhang [53] and truncated these long sessions to ensure that all sessions were within the 30-template limit.</p>
<p>FlexLog.</p>
<p>The implementation of FlexLog mainly involves two key aspects, namely, the selection of base models for ensemble learning and the fine-tuning of the LLM base model.Base Model Selection FlexLog combines multiple heterogeneous base models through ensemble learning, including ML/DL models and LLMs.Specifically, the ensemble in FlexLog comprises three ML base models (KNN, DT, and SLFN) with one LLM base model (Mistral [67]).We selected KNN, DT, and SLFN due to their high effectiveness on SLAD task as reported by Yu et al. [97].We selected the LLM base model (Mistral 22B) through the empirical evaluation of multiple open-source and closed-source LLMs.To elaborate, closed-source LLMs like GPT are considered state-of-the-art LLMs in various domains, albeit at a high cost [95].We experimented with a major version-GPT-4o (GPT-4o-turbo version) -based on OpenAI's recommendation in terms of performance [71,72].</p>
<p>In contrast, open-source LLMs incur no cost and offer more flexibility regarding fine-tuning and inference.Within the limit of our computing resources, we explored two open-source LLMs that have shown competitive performance to closed-source LLMs [23,94]: LLama 3.1 8B and Mistral 22B.</p>
<p>Fine-tuning LLMs</p>
<p>For open-source LLMs, we utilized 4-bits QLora [17] for fine-tuning, with the following configurations based on our preliminary experiments: rank=16, alpha=16, and batch=1.We fine-tuned Llama 3.1 8B and Mistral Small 22B using the Unsloth library due to its high efficiency [81].The number of steps is empirically tuned for unique pairs of LLM and dataset separately, using grid-search and cross-validation; values range from 500 to 2500 in steps of 500.For closed-source LLM of GPT-4o, fine-tuning was accomplished through OpenAI API, which incurred an associated cost.Hyperparameters such as the number of epochs and batch size for fine-tuning GPT were optimized and automatically determined by OpenAI fine-tuning APIs on each dataset.</p>
<p>LLMs, even after fine-tuning, tend to generate non-deterministic output, which threatens the reliability of FlexLog for ULAD.To ensure reliable anomaly detection, we instruct the LLMs to generate the response with minimum temperature (e.g., 0.1 for Mistral ).In case the responses deviate from explicit labels (e.g., "normal", "anomalous", "0" or "1"), ambiguous responses trigger up to five regeneration attempts with progressively higher temperatures from 0.2 to 1, in steps of 0.2, to diversify outputs.If no valid label is parsed after all attempts, we classify the sequence as "normal" to reduce false positives, which might trigger alert fatigue and operational disruption unnecessarily.Hyper-parameters settings of ML base models in FlexLog For the DT and SLFN base models, we use the default values provided by Scikit-learn Library across all datasets.Our preliminary experiments suggest that tuning these hyper-parameters with limited data often leads to overfitting and reduced effectiveness compared to the default settings.While further tuning could potentially improve FlexLog's performance, we leave this for future work.Specifically for DT, we set criterion to "gini", max_depth to "None", and min_samples_split to 2. For SLFN, we set hidden_layer_sizes to 100, activation to "relu", solver="adam", and batch_size to "auto".For KNN, since the number of neighbors plays an important role in handling imbalanced datasets [24], we empirically tuned it with grid search and cross-validation on limited training data.We set the number of neighbors to 2 for ADFA and LOGEVOL Hadoop, and 1 for HDFS 3 .For the extremely imbalanced datasets-LOGEVOL Spark and SYNEVOL-U, which share the same training set-KNN performs poorly on the validation set, exhibiting significantly lower effectiveness compared to DT and SLFN.This aligns with known limitations of KNN on highly imbalanced datasets, where the majority class tends to dominate the predictions [99].Therefore, we excluded KNN from FlexLog for LOGEVOL Spark and SYNEVOL-U.</p>
<p>Lastly, for the ensemble strategy, we implemented a majority voting algorithm in which, in the event of a tie, the sequence is labeled as normal, as described in § 3.4.Our preliminary results across all four datasets indicate that this strategy remains the most effective and straightforward compared to alternative ensemble learning approaches, including SNAIL [66] and MetaFormer [98] (see Appendix A.1).</p>
<p>Baselines .</p>
<p>For baselines, we set hyper-parameters as reported in their original papers or suggested by their implementation packages.When hyper-parameters were not available in either of them, particularly for datasets such as ADFA, we empirically tuned the parameters by grid search with a cross-validation approach.For LightAD, we fine-tuned hyper-parameters using Bayesian optimization, available in their implementation code for KNN, DT, and SLFN.LogAnomaly's representation model (template2vec) requires domain-specific antonyms and synonyms for training.This information is unavailable in its original paper and, thus, similar to the method previously adopted [53], we used a pre-trained FastText model [44] to compute the semantic vectors.As LOGEVOL Hadoop and SynHDFS training sets are too large to process on NeuralLog, we used a subset containing the first 200,000 log messages, following the methodology adopted in prior work [53].</p>
<p>Data availability.</p>
<p>The replication package, including our synthesized datasets, additional experiment results, and source code, is publicly available [26]. 5 Results</p>
<p>RQ1: Overall Effectiveness</p>
<p>RQ1 investigates the effectiveness of FlexLog trained with limited data and compares it to baselines trained with full datasets on ULAD and SLAD.This comparison between FlexLog and baselines is particularly less advantageous for FlexLog, as it is trained with less data than the baselines 4 .To prevent inflated effectiveness caused by data leakage, test data is de-duplicated from the training data, as explained in § 3.4; a comparison of model performance evaluated on the test set with and without de-duplication is also provided in Appendix A.2. Table 4 reports the configurations of training datasets for FlexLog and baselines, including the training dataset size (D # ), the number of unique log sequences (U # ), the percentage of unique log sequences relative to the total unique log sequences in the full datasets (U % ) and the reduction in percentage points in labeled data achieved by FlexLog (ΔU % ); please refer to § 4.2.4 for details of these metrics.In the rest of this section, we first report the evaluation of the overall effectiveness of FlexLog and baselines on two real-world unstable datasets, LOGEVOL-U and ADFA-U ( § 5.1.1).To further analyze the influence of instability, we conducted controlled experiments on two synthesized datasets, SYNEVOL-U and SynHDFS-U, where varying levels of instability are systematically introduced ( § 5.1.2).</p>
<p>Effectiveness on</p>
<p>Real-world Datasets.Table 5 and Table 6 report the effectiveness of FlexLog on two real-world datasets, LOGEVOL and ADFA, respectively.Column "Data" specifies different dataset configurations, including SLAD alongside with various ULAD settings.For instance, Hadoop 2→3 represents that logs produced from Hadoop 2 and Hadoop 3 are used as training and testing datasets, respectively.Column "Unstable" indicates whether the data configuration is unstable or not.Column "M" reports the effectiveness metrics introduced in § 4.2.4.We recall in this table that FlexLog is trained with only "limited data" while all baselines are all trained with the "full training dataset", including "supervised", "semi-supervised" and "unsupervised" baselines.</p>
<p>As shown in Table 5, in the SLAD of the ADFA dataset, FlexLog achieves an F1 score of 0.791, second only to LightAD (0.817) among all methods.However, in the ULAD, where log instability arises from environmental changes, i.e., the introduction of novel attack types, FlexLog outperforms all baselines on 5 out of 6 configurations.The only exception occurs in the adduser configuration, where LightAD surpasses FlexLog with a small margin of 0.7 pp (72.5% − 71.8%).Overall, FlexLog yields the highest average F1 score of 0.704 in ULAD configurations, followed by CNN (0.685) and LightAD (0.677).A Mann-Whitney U test indicates that the differences between the average F1 scores of FlexLog and LightAD, as well as the differences between FlexLog and CNN, are statistically insignificant, whereas FlexLog outperforms all other baselines significantly.Moreover, when moving from SLAD to ULAD, the most effective baseline in SLAD (LightAD) experiences an average F1 score decrease of 14 pp, whereas the decrease with FlexLog remains below 9 pp, alleviating the impact of unstable logs on anomaly detection effectiveness.</p>
<p>Notably, FlexLog achieves such high effectiveness on the ADFA dataset with only limited training data, while baselines like LightAD and CNN are trained with full datasets.As shown in Table 4, FlexLog's fine-tuning datasets contain only 21.57 % of unique log sequences relative to the total unique log sequences in the full ADFA datasets, each requiring a dedicated label.This translates to a reduction of 78.43 pp in usage of labeled data while achieving state-of-the-art effectiveness on the ADFA dataset.</p>
<p>We observe similar results on the LOGEVOL-U dataset, where instability is introduced due to system evolution, e.g., software system version updates.As shown in Table 6, we evaluated two SLAD configurations (Hadoop 2→2 and Spark 2→2 ) and two ULAD configurations (Hadoop 2→3 and Spark 2→3 ).In the Hadoop 2→2 SLAD configuration, all supervised approaches achieve a high F1 score (≥ 0.980), including FlexLog, LightAD, NeuralLog, LogRobust, and CNN.In the other SLAD configuration Spark 2→2 , FlexLog surpass baselines, reaching an F1 score of 0.984 by 1.4 pp from the top baseline, LightAD.In the Hadoop 2→3 and Spark 2→3 ULAD configurations, FlexLog yields F1 scores of 0.982 and 0.892, respectively, remaining the best approach compared to all the baselines.On average, FlexLog outperforms all the baselines in terms of F1 score, with a minimum margin of 1.8 pp (0.928 − 0.910).Additionally, when moving from SLAD to ULAD, the most effective baseline in SLAD (LightAD) experiences an average F1 score decrease of 10 pp, whereas the decrease with FlexLog remains below 7 pp, alleviating once again the impact of unstable logs on anomaly detection effectiveness.</p>
<p>Similar to the ADFA-U dataset, FlexLog achieves such high effectiveness on the LOGEVOL dataset by training on a relatively limited dataset instead of the entire LOGEVOL training dataset.Specifically, as depicted in Table 4, FlexLog's fine-tuning dataset contain only 32.51 % of unique log sequences relative to the total unique log sequences in the full LOGEVOL datasets, indicating a reduction in usage of labeled data of 67.49 pp.</p>
<p>Impact of Log Instability.</p>
<p>As detailed in § 4.2.2, we conducted comprehensive experiments on two synthesized datasets, SynHDFS-U and SYNEVOL-U, to analyze the impact of instability at both the log sequence and log template levels.Specifically, SYNEVOL-U exhibits instability at both the sequence and template levels, whereas SynHDFS-U is characterized solely by sequence-level instability.Instability at Log Sequence Level.Table 7 presents the performance of FlexLog and baseline approaches on SynHDFS-U with sequence-level instability.As the injection ratio of changes increases, FlexLog consistently achieves the highest F1 score across all unstable configurations, demonstrating its robustness to varying levels of instability.On average, FlexLog outperforms all baselines, exceeding the top-performing baseline, LightAD, by a margin of 1.2 pp in F1 score.A Mann-Whitney test reveals that the difference in F1 scores between FlexLog and LightAD is statistically insignificant, indicating comparable performance between the two.However, unlike all baselines-including LightAD-which are trained on the full dataset, FlexLog is trained on only a small subset comprising 37.13 % of unique log sequences (Table 4).This means that FlexLog achieves similar effectiveness and robustness while reducing the usage of labeled data by 62.87 pp.Similar to sequence-level changes in SYNEVOL-U, increasing template-level instability negatively impacts the effectiveness of semi-supervised and unsupervised approaches, whereas supervised methods-FlexLog, LightAD, NeuralLog, LogRobust, and CNN-are relatively robust in terms of effectiveness across instability levels.This is likely because many template modifications in SYNEVOL-U involve minor textual variations, such as inserting, removing, or replacing short tokens, which have minimal impact on ULAD, especially in long log sequences with up to 1,818 templates.For instance, a log template stating "SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); ..." was modified by inserting "so" before "users with modify permissions", a minor change that has limited impact on ULAD effectiveness.</p>
<p>The answer to RQ1 is that FlexLog achieves state-of-the-art effectiveness on both real-world and synthesized datasets while exhibiting high data efficiency (with a reduction in labeled data usage ranging between 62.87 pp and 78.43 pp).On synthesized datasets, FlexLog remains effective under up to 30 % sequence-and template-level instability.9 reports statistics for the sampled subsets, including the percentage of unique log sequences (U % ), which is calculated by dividing the number of unique log sequences in each subset by the total number of unique log sequences in the full training dataset.This percentage represents the proportion of labeling effort required for each subset compared to full dataset annotation.The table further provides the percentages of unique log sequences for each class ( U + % and U − % ).Notably, the smallest subset (D # = 50) contains &lt; 1.5% of unique log sequences, representing extreme data scarcity scenarios where the availability of labeled data is highly limited.</p>
<p>Figure 7 depicts the effectiveness of FlexLog and top baselines trained on the sampled subsets of ADFA-U.Less competitive baselines, such as PLELog, LogAnomaly, DeepLog, LogCluster, and PCA, are not illustrated in the figure for brevity.The dashed horizontal line in each figure represents the state-of-the-art results on each dataset, produced by LightAD trained with full datasets.</p>
<p>Table 10 highlights the improvement of FlexLog by calculating F1 score differences in percentage points between FlexLog and baselines.We also report Mann-Whitney U Test results for F1 comparisons across datasets.A " * " symbol is appended to the average F1 score if FlexLog significantly outperforms the baseline in terms of F1 score.</p>
<p>Overall, FlexLog consistently achieves superior performance in terms of average F1 scores compared to the baselines when trained with the same amount of labeled data.As shown in Table 10, the average F1-score improvements over the strongest baseline (i.e., FlexLog minus LightAD) for D # = 50, 500, 1000, 1500, and 2000 are 2 pp, 13 pp, 10 pp, 8 pp, and 7 pp, respectively.Mann-Whitney U tests show the significance of all the improvements, except for the extreme data scarcity scenario with D # = 50.Notably, even when compared to LightAD trained on the full dataset (represented by the dashed horizontal lines in all plots in Figure 7), FlexLog achieves higher or comparable performance with significantly less labeled data.In the remainder of this section, we elaborate on the performance of FlexLog and baselines under different data scarcity scenarios.Under extreme data scarcity (D # = 50), we observe that all approaches exhibit poor performance in terms of F1 score, which are lower than 0.60, respectively, across all six configurations of ADFA-U.This limitation likely stems from insufficient training data diversity.As reported in the first row of Table 9, the 50 samples selected for each configuration of ADFA-U contain less than 1.46 % of total unique log sequences in full datasets.The percentages of unique anomalous log sequences are also low, with a maximum of 4.46 % ( D # = 50, the java configuration).Such low diversity and small size of the labeled datasets tend to be insufficient for the training of all approaches, including FlexLog and baselines.</p>
<p>Under less severe data scarcity (D # = 500, 1000, 1500, 2000), all methods exhibit improved effectiveness compared to the extreme label scarcity scenario (D # = 50).FlexLog outperforms all baselines across all six configurations in terms of F1 score.As reported in Table 10, the maximum percentage points against LightAD are observed at D # = 500, reaching 13 pp on average.The average difference values diminish to 7 pp as data size increases to 2000, underscoring FlexLog's advantage with limited labeled data.Mann-Whitney U tests confirm the significance of all the differences (D # = 500, 1000, 1500, 2000).</p>
<p>The answer to RQ2 is that FlexLog outperforms baselines in F1 scores under varying data scarcity levels of ADFA-U except at D # = 50, where all methods perform poorly due to insufficient data.FlexLog's average inference time, per log sequence, remains below 1 second, ranging from 0.771 on SynHDFS-U to 0.988 on SYNEVOL-U.While this is significantly higher than traditional ML and  are analyzed to detect performance issues; IT infrastructure monitoring (e.g., Prometheus [80]), where server and network health metrics are updated periodically; and industrial IoT monitoring, where manufacturing systems and smart grids detect equipment failures.In these cases, inference time or response time of an anomaly detector within seconds still allows for timely interventions.In contrast, latency-sensitive domains, such as high-frequency trading systems, demand millisecondlevel inference time, as decisions must be made within microseconds to capitalize on market fluctuation [2].In such scenarios, the inference time of FlexLog, which is on the order of seconds, is not acceptable.We remark that although FlexLog is not as efficient as traditional methods, its superior effectiveness justifies its application in scenarios where reliability is paramount.In anomaly detection, false negatives-undetected anomalies-can have far greater consequences than minor delays in inference time.For instance, in high-stakes environments like cybersecurity or critical infrastructure monitoring, failing to detect an anomaly or an intrusion attempt could lead to data breaches, financial losses, or system-wide failures.While simpler models offer faster inference, they often sacrifice effectiveness, leading to unacceptable numbers of false positives and false negatives.</p>
<p>To further explain the time cost of FlexLog, Table 11 shows the training and inference time of its base models, which include one LLM (Mistral) and three ML models (KNN, DT, and SLFN).We find that Mistral requires substantially more training time and average inference time per sequence compared to the three ML base models, accounting for the majority of time needed for FlexLog.Specifically, while Mistral's training and inference time remain under 7 hours and 1 s, respectively, all ML base models take less than 6 s for training and less than 0.001 s for inference per log sequence.This discrepancy is primarily due to Mistral's significantly large number of trainable parameters.As a result, Mistral has the most impact on the time efficiency of FlexLog compared to ML models.However, with parallel computing and more powerful hardware, the efficiency of LLMs can easily be significantly improved, thereby enhancing the overall efficiency of FlexLog.</p>
<p>Memory</p>
<p>Efficiency of FlexLog's Cache Mechanism.FlexLog leverages a caching mechanism to improve efficiency during inference by storing predictions for previous log sequences, as described in § 3.2.The cache improves FlexLog's time efficiency by reducing repetitive computation, although it introduces extra memory overhead.To evaluate the memory efficiency of this caching component, we report the memory usage, defined in § 4.2.4,during inference across our datasets.For ADFA-U, which contains the longest sequences with an average length of 461 templates, FlexLog consumes between 17.16 MB and 19.60 MB of memory.For LOGEVOL-U, which has the largest number of log sequences, the memory usage remains below 4 MB-specifically, 1.75 MB for Hadoop and 3.5 MB for Spark.For our synthetic datasets, memory usage also stays below 1 MB, averaging 576 kB and 2.88 MB for SynHDFS-U and SYNEVOL-U, respectively, across different injection ratios.Overall, this level of memory usage demonstrates the scalability potential of FlexLog 's caching mechanism, especially when balanced against the time savings presented as part of the answer to RQ4 ( § 5.4.1).Regarding scalability in systems with extremely long or highly diverse sequences, we note that the cache's delete function helps keep memory consumption under control (see § 3.2 for details).Further analysis of memory efficiency will depend on the specific memory resources available in the monitoring system during inference.</p>
<p>The answer to RQ3 is that while FlexLog is not the most time-efficient in ULAD inference, it processes each log sequence within 1 s on average.FlexLog's cache memory remains below 4 MB for most datasets (up to 19.6 MB for ADFA-U), confirming its memory efficiency.</p>
<p>RQ4: Configuration Impact</p>
<p>In this section, we investigate the impact of FlexLog's different ablation configurations, such as excluding the cache mechanism ( § 5.4.1),excluding RAG ( § 5.4.2) and different choices of base models in ensemble learning ( § 5.4.3).Additionally, we investigate the impact of alternative LLMs in the configuration of FlexLog ( § 5.4.3) to highlight the advantages of using Mistral Small as the LLM component.5.4.1 Impact of Cache-empowered Inference.FlexLog maintains a cache  to avoid redundant predictions incurred by recurring log sequences, thus improving inference efficiency.To assess the impact of  on inference time, we compare FlexLog and FlexLog without cache (denoted by "w/o cache") in terms of inference time across four datasets: ADFA-U, LOGEVOL-U, SYNEVOL-U, and SynHDFS-U.The results of this comparison are reported in Table 12.Column "Config" indicates the subjects under comparison -FlexLog and FlexLog w/o cache; the following four columns "ADFA-U", "LOGEVOL-U", "SYNEVOL-U" and "SynHDFS-U" report the results of inference time per log sequence (in seconds) for each respective dataset.For the real-world datasets (ADFA-U and LOGEVOL-U), we report inference time for each configuration.In contrast, for the synthetic datasets (SYNEVOL-U and SynHDFS-U), we provide only the average inference time across configurations.This is because different configurations of SYNEVOL-U and SynHDFS-U vary in the injection ratio of changes, which has minimal impact on inference time, leading to similar inference time across configurations.Hence, we report only the average inference time on synthesized datasets for brevity.The last row "Difference" indicates the difference between the inference time of FlexLog and that for FlexLog w/o cache.Similar to RQ1 ( § 5.1), we conducted Mann-Whitney U tests on each dataset to assess the statistical significance of the differences in inference times; the symbol "*" indicates the inference time of FlexLog is significantly lower than that of FlexLog w/o cache.We observe that the introduction of the cache consistently reduces the inference time across all datasets.The reduction on two real-world datasets-ADFA-U and LOGEVOL-U-and SYNEVOL-U are more pronounced than SynHDFS-U, with reductions of 0.052, 0.312, and 0.047, respectively.Mann-Whitney U tests confirm these reductions are statistically significant, whereas the reduction on SynHDFS-U is smaller (0.023) and statistically not significant.However, as discussed in § 5.3, the practical impact of caching is limited in user-oriented monitoring systems, where inference times below 1 second are generally considered acceptable.While caching improves efficiency, the reduction in inference time might be too small to make a noticeable difference in such systems.</p>
<p>That said, we remark that the impact of caching previously seen log sequences depends on how frequently identical log sequences reappear in real-world systems.In our experiments, 6 %, 43 %, 2.7 %, and 2.2 % of log sequences appear more than once in the testing dataset of ADFA-U, LOGEVOL-U, SYNEVOL-U, and SynHDFS-U, respectively.Hence, the average reduction of inference time on each dataset, ordered from the greatest to the least, is as follows: LOGEVOL-U (−0.312 seconds), ADFA-U (−0.052 seconds), SYNEVOL-U (−0.047 seconds), and SynHDFS-U (−0.023 seconds).In practice, in many operational environments, such as distributed cloud computing frameworks (e.g., Hadoop [77] and Spark [14]) and security monitoring systems, certain types of log sequences, such as scheduled job reports and system diagnostics, occur repeatedly over time.In these cases, the cache mechanism of FlexLog can significantly improve inference efficiency, but its impact depends on the extent of redundant computations and the acceptable latency requirements of the system.</p>
<p>Impact of RAG.</p>
<p>FlexLog employs RAG to retrieve context for log sequences, providing relevant information that enriches the prompts.In our experiments, only ADFA-U has available contextual information, specifically Linux system call descriptions.Hence, RAG is only applied in the experiments on the ADFA-U dataset.To assess the impact of RAG, we compare the F1 scores of FlexLog and FlexLog without RAG (denoted by "w/o RAG") on ADFA-U.The results of this comparison are reported in Table 13.Column "Config" represents the subjects under comparison -FlexLog and FlexLog w/o RAG.Column "adduser", "hydraFP", "hydraSSH", "java", "meter", and "web" reports the F1 scores of six different configurations of ADFA-U; configuration details are described in § 4.2.2.The last column "Average" indicates the average F1 score across all six configurations; the last row "Difference (pp)" reports the difference between the F1 scores of FlexLog and those of FlexLog w/o RAG.We performed a Mann-Whitney U test to assess the significance of the differences; however, testing on individual configurations was not feasible since we repeated the experiments on each configuration 5 times, which does not provide sufficient statistical power.Instead, a Mann-Whitney U test was run across all six configurations, increasing the test sample size to 30.</p>
<p>The results in Table 13 show that FlexLog outperforms FlexLog w/o RAG on all six configurations of ADFA-U, with differences ranging from 2 pp to 7.9 pp.On average, RAG improves the F1 score of ULAD from 0.660 to 0.704 (4.4 pp).A Mann-Whitney U test confirms this improvement is statistically significant.We conclude that the RAG component of FlexLog is effective in improving F1 scores on ADFA-U.This suggests that RAG could similarly improve performance on other datasets that have contextually rich log information.For example, in cloud computing platforms (e.g., AWS or Azure), where logs often include metadata such as instance IDs, resource types, or service configurations, RAG could enhance the effectiveness of ULAD by providing context that helps identify patterns or anomalies related to specific resources or services.</p>
<p>Impact of Base Model Choices in Ensemble</p>
<p>Learning.FlexLog employs an ensemble of four base models for ULAD, leveraging diverse perspectives to enhance predictive effectiveness.As described in § 4.3, the ensemble in FlexLog includes one LLM (Mistral) and three ML models (KNN, DT, and SLFN), which were selected empirically due to their superior performance across different datasets.In this section, we present the results of different base model choices on ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U, including ablation studies (e.g., removing individual base models and removing all ML base models) and replacing Mistral with alternative LLMs (Llama 3.1 and GPT-4o).Ablation Study Table 14 reports ablation studies of FlexLog on all ULAD configurations.Column "Config" denotes the configuration of Flexlog; for instance, "w/o SLFP" represents FlexLog without SLFP base model, and "w/o ML" represents FlexLog without the three ML models (KNN, DT, and SLFN), resulting in standalone Mistral.To evaluate the individual contribution of each base model, we first assessed four configurations of FlexLog, each obtained by removing a single base model: FlexLog w/o Mistral, w/o KNN, w/o SLFN, and w/o DT.The results in Table 14 indicate that removing Mistral leads to the most significant drop in F1 scores, with a maximum reduction of 6.7 pp on ADFA-U adduser.Removing any of the ML models (KNN, DT, or SLFN) also results in reduced F1 scores across all configurations in all the datasets.To assess the statistical significance of these reductions, we conducted Mann-Whitney U tests on each dataset.The results confirm that the decreases in F1 scores are statistically significant in all cases, except for FlexLog w/o KNN, w/o DT, and w/o SLFN on LOGEVOL-U.This highlights the effectiveness of each ML base model in contributing to FlexLog 's overall effectiveness.Further, we assess the contribution of all ML models by excluding all three ML models from FlexLog, leaving only Mistral for predictions.This resulted in decreased F1 scores across most datasets, except for LOGEVOL-U Spark and SYNEVOL-U, where "w/o ML" outperformed FlexLog by 7 pp (96.2% − 89.2%) and 0.8 pp (97.9% − 97.1%), respectively.Mann-Whitney U tests show that FlexLog significantly outperforms "w/o ML" in terms of F1 score on ADFA-U and SynHDFS-U.The F1 score difference on SYNEVOL-U between FlexLog and "w/o ML" is statistically not significant, whereas on LOGEVOL-U Spark, "w/o ML" achieves a significantly higher F1 score than FlexLog.These results align with the findings from removing individual ML base models, further suggesting that the ML base models contribute negatively to FlexLog's performance on LOGEVOL-U Spark and , leading to "w/o ML" outperforming the ensemble.A likely explanation for the better performance of FlexLog without any ML base models on LOGEVOL-U Spark and SYNEVOL-U is these datasets' extreme class imbalance.As detailed in § 4.2.1, LOGEVOL-U Spark and SYNEVOL-U share the same training dataset, sampled from LogEvol Spark 2, which is highly imbalanced: only 16 % of log sequences in the sampled training dataset are anomalous, compared to 50 % in ADFA-U and LOGEVOL-U Hadoop, and 57 % in SynHDFS-U.It is well known that traditional ML models, such as KNN, SLFN, and DT, struggle with highly imbalanced datasets [46].Since FlexLog integrates these ML models, its performance is negatively affected.</p>
<p>To mitigate data imbalance, we experimented with both down-sampling and over-sampling techniques [68].Down-sampling by reducing normal logs to match the number of anomalous logs led to a decrease of 5 pp in F1 score.For over-sampling, we applied several standard strategies, including duplicating anomalous logs, adding small perturbations to representation vectors, and using the Synthetic Minority Oversampling Technique (SMOTE) [5] on representation vectors.However, none of these approaches improved the effectiveness of the ML models.The key challenge lies in the representation of log sequences as count vectors.Unlike continuous feature spaces where interpolation can generate plausible synthetic samples, count vector representations encode categorical relationships, making common over-sampling techniques such as SMOTE [4] prone to producing unrealistic or noisy data.In contrast, standalone Mistral ("w/o ML") remains robust in predictive effectiveness, leveraging its pretraining on vast and diverse corpora to mitigate data imbalance.Based on these findings, we recommend using standalone Mistral instead of the full FlexLog when dealing with extremely imbalanced training datasets, eliminating the negative effect of poorly trained ML models.</p>
<p>For future improvements, more advanced data augmentation techniques, such as Generative Adversarial Networks (GANs), could be used to generate synthetic log sequences directly, rather than modifying their count vector representations.This avoids the issue of unrealistic or noisy data caused by over-sampling in a discrete feature space, making the synthetic data more useful for training ML models on imbalanced datasets like LOGEVOL-U Spark.As a result, this could potentially improve FlexLog 's overall performance.Alternative LLMs.Table 15 reports the F1-score of FlexLog with three LLM choices.Column "Config" represents different configurations of FlexLog, wherein Mistral is replaced by Llama 3.1 8B (" → ") and GPT-4o (" →  ").Column "Source" indicates whether the employed LLM is open-source or closed-source.Experimental results indicate that GPT-4o and Mistral achieve comparable effectiveness, both consistently outperforming Llama across all configurations and datasets.Mann-Whitney U tests at the dataset level confirm that the F1 score differences between FlexLog and "  →  " are not significant across all four datasets.However, FlexLog significantly outperforms " → " on ADFA-U, LOGEVOL-U, and SynHDFS-U, while the difference on SYNEVOL-U is not statistically significant.These findings underscore the effectiveness of Mistral for ULAD, demonstrating performance on par with the closed-source GPT-4o while avoiding the financial cost associated with API invoking.Thus, we recommend Mistral as a cost-effective yet competitive base model for FlexLog.</p>
<p>The answer to RQ4 is that the full FlexLog configuration-combining cache, RAG, and an ensemble of KNN, DT, SLFN, and Mistral-performs best, with each component improving efficiency or effectiveness.Among LLMs, Mistral is a cost-effective choice, matching the performance of GPT-4o while outperforming Llama.</p>
<p>Discussion</p>
<p>In this section, to guide AIOps engineers, we highlight the implications of our study for ULAD.5.5.1 Token Consumption of LLMs.In the early times of leveraging attentive language models, language models accepted limited input tokens, such as a maximum of 512 input tokens for BERT [18], making it challenging to apply them to long log sequences.However, as language models expanded into LLMs, the maximum input token limit also increased, both for open-source and closed-source models.Table 16 reports the input token limits of the LLMs used in our work and compares them with the maximum token consumption observed for each dataset.Column "Model" denotes LLMs used in our experiments.Column "Source" indicates whether the LLM is open-sourced or closed-source.Column "Input Token Limit" reports the input token limit specific to each LLM.Column "Maximum Input Token" denotes the maximum token consumption of FlexLog's prompts on each dataset.We note that these values vary across LLMs due to variations in their tokenization processes.Our results show that FlexLog's token consumption remains well within input token limits for all LLMs, indicating that the challenge of input token limits has been alleviated and even eliminated for our datasets.The highest usage is only 37.7 % (24,735 out of the maximum limit of 65,536 tokens), with prompts used by GPT-4o for ADFA-U.Notably, in our experiments, we have included various log datasets with log sequences as long as 4,474 templates (see Table 1), and yet LLMs effectively accommodate them.Moreover, recent advances in LLMs can potentially extend the token limit to one million tokens [78,92], making it no longer a hard limitation for using LLMs.17 reports the error analysis results across all four datasets: ADFA-U, LOGEVOL-U, SYNEVOL-U, and SynHDFS-U.Column "Data" specifies the dataset; Column "Config" reports the configuration of each dataset; Column "Condition" shows the subject of the statistics, including the testing dataset, MIS w/o Mistral , and MIS w/o ML .Column "# Sequences" reports the number of sequences; column "Sequence Length" indicates the average, minimum, and maximum length of the sequences, denoted as "avg", "min", and "max", respectively.Column "% Anomaly" reports the percentage of anomalous log sequences, and column "% Unseen Template" denotes the percentages of log sequences that have at least one unseen log template.Overall, for each dataset, MIS w/o Mistral and MIS w/o ML demonstrate different characteristics in terms of log sequence length, percentage of anomaly, and percentage of unseen templates, highlighting how Flexlog's base models complement each other in an effective prediction.</p>
<p>In terms of unseen templates, in LOGEVOL-U Hadoop and SynHDFS-U, we did not observe any in either MIS w/o ML or MIS w/o Mistral .In ADFA-U, MIS w/o Mistral contains 7.38 % unseen log templates, much higher than that of MIS w/o ML (1.89 %).Similarly, in LOGEVOL-U Spark, the percentage of unseen log templates in MIS w/o Mistral reaches 33.33 %, while MIS w/o ML contains no unseen templaterelated mis-classifications.In SYNEVOL-U, 11.76 % of misclassifications in MIS w/o Mistral are related to unseen templates, higher than that in MIS w/o ML (9.28 %).Overall, we observe a higher percentage of unseen templates in MIS w/o Mistral than MIS w/o ML across most datasets.The higher percentage of unseen log templates in MIS w/o Mistral , across several datasets, indicates that Mistral plays a crucial role in handling unseen log templates.This highlights LLM's adaptability in recognizing new templates, making it particularly valuable for ULAD, where logs are unstable due to environment and system evolution.In contrast, perhaps unsurprisingly, ML models appear to rely more on established patterns, struggling with new templates.</p>
<p>Threats to Validity</p>
<p>5.6.1 Internal Validity.Data Leakage from LLMs.One potential threat to internal validity is data leakage, where test data may inadvertently overlap with training data.Although we performed de-duplication across all test datasets, the risk of data leakage cannot be entirely eliminated, as some test data may have been included in the pretraining corpus of LLMs.This could lead to inflated effectiveness.To mitigate this risk, we evaluated FlexLog not only on publicly available datasets (ADFA, LOGEVOL, and SYNEVOL-U), but also on the SynHDFS-U dataset, which we synthesized ourselves.In addition, the cut-off date of Mistral Small is August 2023, and LOGEVOL and SYNEVOL-U were introduced after this date.Hence, these datasets cannot be part of its pretraining corpus, ensuring a more reliable assessment of FlexLog 's effectiveness.</p>
<p>Selection of Training Dataset Sizes.Another threat to internal validity arises from the selection of training dataset sizes (D # ) for evaluating data efficiency.Since D # directly affects the performance of FlexLog and the baselines, an exhaustive evaluation across all possible values is infeasible.</p>
<p>To address this limitation, we systematically experimented with multiple D # values, as detailed in § 5.2, ranging from 50 to 2,000.This range allows us to provide a comprehensive analysis of data efficiency while remaining within our computational constraints.</p>
<p>Selection of FlexLog's Base Models.Since FlexLog is an ensemble learning-based approach, its effectiveness is significantly influenced by the selection of base models.While it is impractical to evaluate all possible model combinations, we carefully selected representative base models from the literature on log-based anomaly detection, including KNN, DT, SLFN, LightAD [96], NeuralLog [51], CNN [62], LLaMA 3.1, and GPT-4o.Through extensive empirical evaluation, we tested multiple model combinations and ultimately selected KNN, DT, MLP, and Mistral due to their consistently high effectiveness and robustness across both real-world and synthesized datasets.</p>
<p>Synthetic Datasets.The synthetic datasets in our experiments are generated by injecting different levels of instability.One potential threat to internal validity lies in the realism of this injected instability and the validity of labels after injections.To mitigate this threat, we adopted datasets synthesized by experts and applied well-established injection strategies from the literature.Specifically, the SYNEVOL-U dataset, proposed by Huo et al. [39], was annotated by two experienced Spark developers and carefully reviewed after annotation.For SynHDFS-U datasets, which we constructed following the SYNEVOL-U approach, we applied only sequence-level changes that are unlikely to affect the overall label of a log sequence.To guide this process, we leveraged the decision tree analysis [89] of the original dataset to identify low-impact templates.These precautions help maintain the reliability of the labels, despite the synthetic nature of the data.</p>
<p>Consistency of Labels.For faster inference, FlexLog's cache mechanism reuses the prediction for previously seen, identical log sequences.However, the assumption that identical log sequences always correspond to the same label may not hold in extreme log evolution cases, particularly in security-critical domains.This assumption is nevertheless valid for all of our datasets, where each unique log sequence is consistently labeled.To further mitigate this risk, the update function in FlexLog's cache enables label revisions by system administrators if changes are observed over time.</p>
<p>Cascading Effect of Parsing Errors.The use of log parsing introduces a potential risk of parsing errors, which could negatively affect the effectiveness of FlexLog.However, prior work by Khan et al. [47] reports no strong correlation between log parsing accuracy and anomaly detection accuracy, suggesting that minor parsing errors do not necessarily degrade the effectiveness of FlexLog.Our evaluation shows that FlexLog, as a parsing-based approach, achieves significantly higher effectiveness than NeuralLog and LightAD, both of which operate on raw logs.Specifically, LightAD uses some of the same base models as FlexLog but applies them without log parsing.In FlexLog, this risk is further mitigated through two design factors.First, we adopt widely used and reliable parsers to reduce the likelihood of significant parsing errors (see § 4.3.1).Second, the architecture limits error propagation: predictions are aggregated via majority voting across multiple base models, preventing a single erroneous output from dominating the final decision.Additionally, the fine-tuned LLM in FlexLog leverages contextual information, making it resilient to potential inconsistencies introduced by parsing.</p>
<p>Conclusion Validity.</p>
<p>It is widely acknowledged that LLMs often produce non-deterministic responses even when provided with identical prompts, posing a potential threat to the conclusion validity of FlexLog.To address this challenge, as detailed in § 4.3, we configured the LLMs to generate responses with minimal randomness, achieved by setting the temperature parameter to 0.</p>
<p>To further reduce the influence of randomness from our evaluation results, as discussed in § 4.3, we ran each experiment configuration five times and calculated the average value as the final result.We also conducted Mann-Whitney U test to assess the significance of effectiveness and efficiency differences between FlexLog and baselines.To ensure sufficient statistical power, we performed statistical testing at the dataset level rather than the configuration level, since each configuration only has five samples.Aggregation at the dataset level ensures each test includes at least 10 samples.</p>
<p>External Validity.</p>
<p>A potential threat to external validity is the impact of highly unstable logs on anomaly detection performance.While FlexLog achieves state-of-the-art effectiveness, its performance, like that of other methods, may degrade when log instability is extreme.For example, the introduction of YARN for job management in Hadoop 2 resulted in substantial architectural modifications, leading to significant changes in its logs [83].Such drastic shifts pose challenges for all existing methods, potentially limiting their applicability in highly unstable logging environments.</p>
<p>To address this concern, we evaluate FlexLog and the baselines across diverse datasets that capture two primary sources of log instability: software evolution (LOGEVOL-U) and environment change (ADFA-U).Additionally, we conduct experiments on two synthesized datasets (SynHDFS-U and SYNEVOL-U) that simulate instability levels ranging from 0 % to 30 %.Our findings indicate that while all methods experience performance degradation as instability increases, FlexLog remains robust in terms of precision, recall and F1 score.With a minimum F1 score of 0.948 (30 % template level injections on SYNEVOL-U), FlexLog consistently outperforms all the baselines, demonstrating greater robustness in handling highly unstable logs.Nevertheless, further evaluation on a broader range of real-world systems is necessary to fully assess the limitations of its applicability.</p>
<p>6 Related Work</p>
<p>Anomaly Detection on Unstable Logs</p>
<p>Log-based anomaly detection has been extensively studied in the literature to enhance the dependability of software-intensive systems [50,53,96].However, only a few studies have investigated anomaly detection on unstable logs [38,39,56,102], a common situation in practice.Zhang et al. [102] first identified such a challenge and proposed LogRobust (see § 4.2.3) to leverage an attention-based Bi-LSTM as an anomaly detector.They also created a new unstable log dataset called Synthetic HDFS to evaluate the effectiveness and robustness of LogRobust.This inspired a number of follow-up works, including supervised [38,56] and unsupervised approaches [39].Supervised approaches like HitAnomaly [38] and SwissLog [56] require training with a labeled dataset, encompassing both normal and anomalous data.SwissLog adopts the same architecture (i.e., Bi-LSTM) as LogRobust and aims to further improve it by incorporating time embeddings and Bert-based semantic embeddings.HitAnomaly, however, leverages a much larger model based on a hierarchical transformer architecture.The high complexity of the HitAnomaly model allows it to tackle not only the static parts of log messages but also dynamic parts, such as numerical values that have been masked in the log templates.Experiment results demonstrate the superiority of HitAnomaly on stable logs compared to LogRobust, while showing a robust performance for small injection ratios (under 20%) in unstable logs and being outperformed by LogRobust from 20% to 30%.</p>
<p>Huo et al. [39] proposed EvLog, an unsupervised approach leveraging a multi-level semantics extractor and attention mechanism to identify anomalous log messages in unstable logs.Unlike FlexLog, EvLog is a parser-free method to combat potential parsing errors in a dataset.However, by avoiding log parsing, EvLog may face challenges in generalizing to datasets with diverse or domain-specific log formats, as it relies solely on semantic extraction without leveraging structured context.As part of the EvLog study, they also introduced two log datasets: LOGEVOL and SYNEVOL (referred to as SYNEVOL-U in our paper), which serve as valuable benchmarks for ULAD research, including our work.</p>
<p>To summarize, compared to existing ULAD approaches, FlexLog: 1) leverages the synergy of ML models and LLMs through ensemble learning 2) requires significantly less training data, reduces labeling cost, 3) achieves state-of-the-art effectiveness across all datasets, outperforming baselines in terms of F1 scores consistently while being trained on limited labeled data.</p>
<p>Application of LLMs to Log Analysis</p>
<p>Over the past few years, LLMs have been widely adopted on different log-related software engineering tasks to enhance effectiveness and generalizability, including anomaly detection and log parsing [59,63,88].</p>
<p>Anomaly detection.The application of LLMs in the field of anomaly detection started by leveraging BERT [18] to capture contextual information of logs with semantic-based representations.</p>
<p>LogBERT [25] utilizes BERT to learn the semantics of normal log messages and predicts an anomaly where the representation of log messages of an input sequence deviates from the distribution of normal log sequences.Le and Zhang [51] proposed NeuralLog (discussed in § 4.2.3).Han et al. [27] introduced LogGPT, which leverages reinforcement learning to fine-tune GPT-2 for anomaly detection.More recently, Liu et al. [59] proposed LogPrompt, which adopts LLMs such as GPT-3 and Vicuna [8] for online log parsing and anomaly detection via in-context learning; we discussed the reasons for not considering LogPrompt as baseline in § 4.2.3.He et al. [29] proposed LLMeLog, which leverages a BERT model fine-tuned with log sequences enriched with contextual information that was retrieved by GPT-3.5.Inspired by LLMeLog, we further explored RAG with various LLMs, including closed-source and open-source LLMs.Additionally, we equipped LLMs with a cache mechanism and ensemble learning to enhance their effectiveness and data efficiency.Note that we did not consider LLMeLog as a baseline in this work due to the unavailability of their replication package.</p>
<p>Log Parsing.Le and Zhang [52] explored the in-context learning of ChatGPT [73] on log parsing and achieved promising results with zero-shot and few-shot prompts.Xu et al. [88] proposed DivLog, another few-shot, in-context learning method that constructs prompts with five labeled examples for each target log template.DivLog explicitly optimizes the diversity of included examples using the Determinantal Point Process (DPP) [6], reducing the potential biases in the examples by maximizing sample diversity.Jiang et al. [43] proposed a novel parser called LILAC, equipping LLMs with an adaptive cache to reduce the LLM query times and, consequently, the efficiency.Recently, Pei et al. [74] introduced a self-evolutionary LLM-based parser, which identifies new log templates by grouping history log messages.Fewer studies focus on fine-tuning LLMs for log parsing.Le and Zhang [54] introduced LogPPT to fine-tune RoBERTa for log parsing.In addition, an adaptive random sampling strategy was designed to select a small yet diverse training dataset.Ma et al. [63] compared in-context learning and fine-tuning using open-source LLMs such as Flan-T5 [11] and LLaMA [79] on log parsing.Zhi et al. [104] introduced YALP, which leverages the capabilities of ChatGPT (gpt-3.5-turbo) in conjunction with traditional methods -Longest Common Subsequence,without incorporating user labeling (zero-shot learning).Zhong et al. [105] proposed LogParser-LLM, which essentially blends a prefix tree and an LLM-based template extractor.This extractor parses log messages with different LLMs, including GPT-3.5-turbo,GPT-4, and Llama-2-13B, in either ICL or fine-tuning manner; the highest results were obtained using GPT-4 with ICL.Xiao et al. [87] introduced LogBatcher, which is a cost-effective LLM-based log parser based on GPT-3.5-Turbo.Similar to YALP, they control the cost of using closed-source LLM by storing inferred messages in a basic cache.Moreover, it does not require any training by prompting the LLM with a group of high-diversity log messages to ensure that the LLM understands the diversity of the dataset in a zero-shot manner.Overall, the results of the above works align with our findings: the vast pretrained knowledge of LLMs enables data efficiency and robustness on unseen log templates.</p>
<p>Conclusion and future work</p>
<p>This paper proposed a novel approach, FlexLog, for anomaly detection on unstable logs (ULAD), exploiting the synergy between Large Language Models (LLMs) and Machine Learning (ML) models via ensemble learning.FlexLog incorporates four base models, one LLM (Mistral), and three ML models (KNN, DT, and SLFN), which are trained on limited stable logs, reducing the usage of labeled data significantly.To classify unstable logs, FlexLog first processes unstable logs into log sequences through log parsing and partitioning.Then, FlexLog employs Retrieval-Augmented Generation (RAG) to fetch relevant information (if available) for these sequences, constructing context-enriched prompts.The fine-tuned LLM processes these prompts, while ML models use the log sequences directly for prediction.Finally, FlexLog combines the predictions of all the base models using majority voting to produce the final classification.</p>
<p>Our extensive experiments on two real-world and two synthesized datasets show that FlexLog achieves state-of-the-art effectiveness on all datasets while reducing the usage of labeled data by 62.87 pp to 78.43 pp, respectively.Further experiments on ADFA-U with varying limited training data size demonstrate that FlexLog maintains robust effectiveness under varying levels of data scarcity, except the extreme data scarcity scenario (D # = 50), where all methods exhibit poor performance due to insufficient labeled data.FlexLog outperforms the top baseline in terms of F1 by 13 pp when the training dataset contains only 500 samples.However, experiments assessing time efficiency show that FlexLog trades off some time efficiency for this effectiveness but still manages to keep the inference time below one second per log sequence.This suggests FlexLog is applicable for most systems, except those with stringent latency requirements, such as high-frequency trading systems.Furthermore, in terms of memory efficiency, FlexLog 's cache memory remains below 4 MB for most datasets (up to 19.6 MB for ADFA-U) confirming its memory efficiency.Finally, we conducted ablation studies on individual components of FlexLog, as well as evaluating alternative LLM choices.We confirmed the significant contributions of the cache-based inference, RAG, and ensemble learning with Mistral as LLM and KNN, DT, and SLFN as ML models.</p>
<p>In the future, we plan to further enhance the effectiveness of FlexLog by exploring more powerful open-source LLMs as base models, such as DeepSeek R1 [15], along with more advanced prompting techniques such as agent-based prompting [84].Additionally, we wish to investigate different ensemble learning techniques that dynamically decide the optimal ensemble composition for a given log sequence.To enhance the generalizability of our caching mechanism, we plan to incorporate similarity-based retrieval in the future, allowing the model to infer labels from similar seen log sequences instead of identical ones.Furthermore, to address the dataset imbalance observed in certain datasets, we aim to explore techniques like Generative Adversarial Networks (GANs) for data augmentation, potentially improving the performance of ML-based models within the ensemble.traditional meta-learning approaches.We experimented with these methods using their original implementation code.Table 18 reports the F1 scores of FlexLog using different ensemble strategies, including the original majority voting (Majority Voting (alternative)), and two meta-learning approaches, SNAIL and MetaFormer.Experimental results show that FlexLog's majority voting consistently outperforms these alternatives with an average difference of 5 pp, 3 pp, 2 pp, and 3 pp, respectively, for ADFA-U, LOGEVOL-U, SynHDFS-U, and LOGEVOL-U.Mann-Whitney U tests at the dataset level further confirm that the differences in F1 score between FlexLog and the alternative strategies are statistically significant across all four datasets, except for MetaFormer on LOGEVOL-U.Overall, the modified majority voting in FlexLog remains the recommended strategy due to its simplicity and effectiveness.</p>
<p>A.2 Impact of De-duplication</p>
<p>Table 19 reports the F1 scores of FlexLog and baseline models evaluated on both de-duplicated and original test data.The column "dedup" indicates whether the test set was de-duplicated from the training set.Overall, all models exhibit inflated F1 scores when the test set is not de-duplicated from the training set, highlighting the impact of data leakage.For instance, NeuralLog shows an average inflation of 16 pp, 2 pp, 1 pp, and 24 pp on ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U, respectively.Mann-Whitney U tests confirm that the differences are statistically significant for Neurallog.In contrast to the most effective baseline (LightAD), FlexLog keeps the inflation in F1 score below 2 pp across all datasets, where the difference between FlexLog's performance on de-duplicated and original test data is statistically insignificant, confirmed by Mann-Whitney U tests.These results indicate that FlexLog delivers more reliable and robust performance.To avoid any risk of inflated results, all reported performances in this paper are based on de-duplicated test data.</p>
<p>A.3 Baselines with Limited Data</p>
<p>Table 20 presents the effectiveness of FlexLog compared to baselines when all models are trained on the same limited dataset.FlexLog consistently achieves the highest F1 score across all datasets under this setting.For instance, FlexLog outperforms the supervised baselines LightAD, NeuralLog, LogRobust, and CNN by 10 pp, 16 pp, 30 pp, and 14 pp, respectively, on average for ADFA-U.This advantage is important because supervised models such as NeuralLog and CNN depend on large labeled datasets to achieve high accuracy.Mann-Whitney U tests confirm that the observed performance gaps between FlexLog and each baseline are statistically significant across all datasets, demonstrating that none of the baselines match FlexLog 's performance with limited data.Notably, FlexLog trained with limited data even outperforms baselines trained with full datasets in terms of predictive effectiveness.Detailed results are presented and discussed in RQ1 ( § 5.1).</p>
<p>Fig. 1 .
1
Fig. 1.Examples of log Message, Log Message Sequence, Log Template, and Log Template Sequence.</p>
<p>Fig. 2 .
2
Fig. 2. Examples of Unstable Logs Resulting from Log Evolution.</p>
<p>Fig. 3 .
3
Fig. 3. Architecture of FlexLog.</p>
<p>Fig. 4 .
4
Fig. 4. FlexLog's Prompt Design for LLM Fine-tuning and Inference.</p>
<p>Fig. 7 .
7
Fig. 7. F1-scores of FlexLog and top four baselines (LightAD, Neurallog, LogRobust, and CNN) trained on varying data scarcity level on six different ULAD configurations (adduser, hydraFTP, hydraSSH, meter, java, and web) of ADFA-U.</p>
<ol>
<li>3
3
RQ3: Time and Memory Efficiency 5.3.1 Time Efficiency.Table 11 reports the training and inference time of FlexLog and the baselines across different datasets.Column "M" denotes the metric, where "T" represents the training time of full datasets (in seconds) and "I" represents the average inference time of one log sequence (in seconds).Specifically, we include FlexLog's base models-one LLM (Mistral) and three ML models (KNN, DT, and SLFN), which are introduced in § 4.3.2.The reported training and inference times represent the total time aggregated across these models (without considering parallel computation).FlexLog requires substantially more training time than the baselines, with a maximum of 23,706 seconds (6 hours and 35 minutes) on the LOGEVOL-U Spark and SYNEVOL-U datasets.In contrast, the maximum training time of the baselines is recorded as only 1,550 seconds when training NeuralLog on the LOGEVOL-U Hadoop dataset.However, since training is a one-time cost, such a long training time is generally acceptable.</li>
</ol>
<p>Table 1 .
1
Overview of Datasets</p>
<h1>Log#Anomalous#LogSession LengthNameSys#SessionsMessagesMessagesTemplatesavg min maxADFALinux 2,747,550 317,388 (11.5%) 5,951175461.69 75 4,474LOGEVOLHadoop 2 2,120,739 35,072 (1.6%) 333,699 Hadoop 3 2,050,488 30,309 (1.4%) 343,013319 3136.35 1 1,963 5.97 1 1,818Spark 2 931,9601,702 (0.1%)13,89213067.08 1 1125Spark 3 1,600,273 2,430 (0.1%)21,23213475.37 1 1977HDFSHadoop 11,110,850 284,818 (2.9%) 575,0614819.32 230</h1>
<p>Table 2 .
2
ULAD Configurations We derived six ULAD configurations by splitting ADFA based on attack types.Specifically, for each configuration, five out of six attack types are used for training (e.g., ADFA w/o java , in column "train" in Table 2, represents training data containing all attack types except the Java-based Meterpreter attack) and the remaining one for testing (e.g., ADFA w/ java , in the "test" column of Table 2, represents a testing dataset with only the Java-based Meterpreter attack), simulating external changes in real-world scenarios where novel attack types emerge during operation.Consequently, we obtain six ULAD configurations for ADFA-U involving ADFA w/o java →ADFA w/ java , ADFA w/o hydraSSH →ADFA w/ hydraSSH , ADFA w/o hydraFTP →ADFA w/ hydraFTP , ADFA w/o meter →ADFA w/ meter , ADFA w/o web →ADFA w/ web , ADFA w/o adduser
ConfigurationDuplication#Log SequencesDatasettraintestRatioD 𝑡𝑟𝑎𝑖𝑛 #D𝑡𝑟𝑎𝑖𝑛 #D 𝑡𝑒𝑠𝑡 #ADFA w/o javaADFA w/ java0.32478610001165ADFA w/o hydraSSHADFA w/ hydraSSH0.31473410001217ADFA-UADFA w/o hydraFTPADFA w/ hydraFTP0.31474810001203ADFA w/o meterADFA w/ meter0.34483510001116ADFA w/o webADFA w/ web0.33479210001159ADFA w/o adduserADFA w/ adduser0.33481910001132LOGEVOL-UHadoop 2Hadoop 30.84302312 8558 34495Spark 2Spark 30.501111411344246Spark 2 5%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.6Spark 2 10%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.55Spark 2 15%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 Spark 2 20%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.50 0.441111411342778Spark 2 25%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.37SYNEVOL-USpark 2Spark 2 30%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.32Spark 2 5%_𝑡𝑒𝑚𝑝𝑙𝑎𝑡𝑒0.54Spark 2 10%_𝑡𝑒𝑚𝑝𝑙𝑎𝑡𝑒0.45Spark 2 15%_𝑡𝑒𝑚𝑝𝑙𝑎𝑡𝑒 Spark 2 20%_𝑡𝑒𝑚𝑝𝑙𝑎𝑡𝑒0.36 0.281111411342778Spark 2 25%_𝑡𝑒𝑚𝑝𝑙𝑎𝑡𝑒0.22Spark 2 30%_𝑡𝑒𝑚𝑝𝑙𝑎𝑡𝑒0.18SynHDFS 5%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.93SynHDFS-UHDFSSynHDFS 10%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒 SynHDFS 20%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.88 0.78460048 5772 51000SynHDFS 30%_𝑠𝑒𝑞𝑢𝑒𝑛𝑐𝑒0.69ADFA-U.</p>
<p>, are 0.84 and 0.5, respectively; these values indicate that, without de-duplication, 84% of Hadoop and 50% of Spark log sequences in the testing dataset are already included in the training dataset.
Original Log TemplateOriginal Log Sequencereceived block * from * dest: <em>template 1template 2template 3template 4Removing one wordRemoving a templatereceived block * from * dest: </em>template 1template 2template 3template 4Adding one wordDuplicatinga templatetemplate 1template 2template 2template 3template 4Shuffling a small subsequencetemplate 1template 3template 4template 2
received block * from IP * dest: * Replacing one word by another word received got block * from * dest: * Fig. 5. Examples of Template-level Changes Fig. 6.Examples of Sequence-level Changes</p>
<p>Table 3 .
3
[102]iew of Baselines ,000 normal and 1,000 anomalous log sequences, following the study by Zhang et al.[102], to keep the anomaly percentage (2 %) close to that of the original HDFS dataset.The duplication ratio decreases from 0.93 to 0.69 as the testing set becomes more unstable.
Learning Method Approach Parser Log RepresentationML MethodBase ModelPCAYesTemplate IDTraditional MLPCAUnsupervisedLogCluster Yes DeepLog YesTemplate ID Template IDTraditional ML Deep LearningClustering LSTMLogAnomaly YesTemplate2VecDeep LearningLSTMSemi-supervisedPLELogYes FastText and TF-IDFDeep LearningGRULogRobustYes FastText and TF-IDFDeep LearningBiLSTMSupervisedCNNYesLogkey2vecDeep LearningCNNNeuralLogNoBERTDeep LearningTransformerLightADYesTemplateIDTraditional ML &amp; Deep Learning KNN, DT, SLFNrandomly selected 50</p>
<p>Time Efficiency We evaluate the time efficiency in terms of training and inference time for each model.For training time, we calculate the total training time taken for a model.For inference time, we calculate the average inference time for one input sequence in the testing set.</p>
<p>Table 4 .
4
Statistics of training data for FlexLog and baselines used in RQ1 on ADFA-U, LOGEVOL, SYNEVOL-U and SynHDFS-U.
DatasetD #U #U %ΔU %Baselines FlexLog Baselines FlexLog Baselines FlexLogADFA-U4,7851,0003,181686100 %21.57% 78.43 ppLOGEVOL-U 313,4269,69229,8099,692100 %32.51% 67.49 ppSYNEVOL-U 11,1141,1344,9391,134100 %22.96% 77.04 ppSynHDFS-U 460,0485,77215,5455,772100 %37.13% 62.87 pp</p>
<p>Table 5 .
5
Effectiveness of FlexLog and baselines for ULAD and SLAD on the ADFA dataset
limited datafull training setData Unstable MSupervisedSemi-SUnsupervisedFlexLogLightAD NeuralLog LogRobust CNN PLELog LogAnomaly DeepLog LogCluster PCAP0.7080.8200.5380.718 0.666 0.7360.3570.3340.2550.196ADFANoR0.8940.8140.6020.708 0.842 0.2160.4300.5230.9070.139F10.7910.8170.5680.713 0.744 0.3340.3900.4080.3980.162P0.6190.6730.3030.711 0.547 0.5070.2080.1980.2170.139adduserYesR0.8570.7860.6510.415 0.775 0.2810.4830.5620.7250.202F10.7180.7250.4120.524 0.641 0.3610.2910.2920.3340.165P0.6860.7800.5320.612 0.882 0.2470.3450.4110.2680.139hydraFTPYesR0.9130.7310.3060.306 0.653 0.8970.6500.5810.9500.133F10.7840.7540.3880.408 0.750 0.3880.4510.4810.4180.144P0.6570.8330.2980.656 0.882 0.5220.4080.3900.2990.121hydraSSHYesR0.8040.6350.4790.262 0.653 0.4330.5830.5540.9990.121F10.7230.6660.3680.374 0.750 0.4730.4800.4580.4610.140P0.6340.6990.3660.695 0.752 0.3710.3570.2690.2130.169javaYesR0.6500.5900.8490.457 0.549 0.5130.5160.4590.9590.157F10.6420.6390.5110.558 0.635 0.4300.4220.3390.3480.158P0.6390.7880.3300.583 0.786 0.7990.2540.3350.1860.204webYesR0.7090.4870.7410.395 0.513 0.1360.5300.3730.8290.191F10.6720.6020.4570.449 0.621 0.2330.3430.3530.3040.197P0.5640.7100.3120.745 0.642 0.5690.1470.1780.2350.210meterYesR0.8590.7320.8890.577 0.799 0.1630.4250.4360.9430.139F10.6820.6790.4610.651 0.711 0.2530.2180.2530.1750.241P0.6330.7470.3570.667 0.748 0.5030.2860.2970.2360.164averageYesR0.7990.6600.6520.402 0.657 0.4040.5310.4940.9010.157F10.7040.6770.433<em>0.494</em> 0.685 0.356<em>0.368</em>0.363<em>0.340</em> 0.174*
* FlexLog yields a significant higher F1-score than compared baseline.</p>
<p>Table 6 .
6
Effectiveness of FlexLog and baselines for ULAD and SLAD on the LOGEVOL dataset
limited datafull training setDataUnstable MsupervisedSemi-SUnsupervisedFlexLogLightAD NeuralLog LogRobust CNN PLELog LogAnomaly DeepLog LogCluster PCAP0.9990.9990.9970.9840.997 0.6480.2630.3840.9520.267Hadoop 2→2NoR0.9860.9940.9860.9760.997 0.8880.6160.3520.3200.867F10.9930.9970.9920.980 0.997 0.7490.3680.3670.4790.408P0.9990.9990.9990.9410.999 0.1720.5010.5120.7710.072Spark 2→2NoR0.9690.9390.6360.9690.878 0.1290.3930.4430.8180.471F10.9840.9680.7770.9520.935 0.2430.4410.4750.7940.125P0.9980.9980.9140.9050.992 0.6260.2210.3840.5100.225Hadoop 2→3YesR0.9650.9630.9840.9500.968 0.8190.5220.3520.3710.898F10.9820.9800.9480.9270.980 0.7090.3100.3670.4300.360P0.9990.9810.9160.6960.992 0.1050.1410.080.3470.061Spark 2→3YesR0.8050.7080.7660.8320.736 0.3770.4580.6060.8050.484F10.8920.8290.8340.7570.840 0.1650.2160.1220.4850.108AverageP0.9980.990.9150.7860.992 0.3660.1810.2320.4280.143(Spark2→3,YesR0.8710.830.8750.8630.852 0.8870.490.4790.5880.691Hadoop2→3)F10.9280.898<em>0.891</em>0.833<em> 0.910</em> 0.437<em>0.263</em>0.244<em>0.458</em> 0.234*
* FlexLog yields a significant higher F1-score than baseline.</p>
<p>Table 7 .
7
Effectiveness of FlexLog and baselines under different sequence-level injection ratios on SynHDFS-U.
limited datafull training setData Unstable MsupervisedSemi-SUnsupervisedFlexLogLightAD NeuralLog LogRobust CNN PLELog LogAnomaly DeepLog LogCluster PCAP0.9540.97630.9490.9570.933 0.6300.2430.7250.9990.9240%NoR0.9990.9900.9850.9800.951 0.9660.9710.9270.3460.667F10.9760.9830.9660.9690.942 0.7630.3890.8140.5140.762P0.9530.9570.9440.9950.932 0.6020.2360.6780.9860.9765%YesR0.9950.9850.9850.9790.952 0.5540.9610.8940.3460.667F10.9740.9710.9640.8780.944 0.5770.3800.7710.5120.792P0.9540.9660.9140.6920.933 0.4040.2390.6490.9990.22510%YesR0.9950.9800.9800.9740.951 0.8840.9750.9270.3500.673F10.9740.9730.9460.8090.942 0.5550.3850.7640.5190.337P0.9490.9430.9060.5600.933 0.3450.4820.6440.9490.15820%YesR0.9950.9660.9800.9560.951 0.7980.5380.8890.3600.694F10.9710.9540.9420.7070.942 0.4820.5090.7470.5220.258P0.9400.9250.8960.4890.929 0.2430.4640.5480.9150.13730%YesR0.9850.9560.9700.9510.947 0.8770.5720.9030.3650.718F10.9640.9400.9310.6460.938 0.3810.5120.6820.5220.230P0.9490.9480.9150.6840.932 0.3980.3550.630.9620.374AverageYesR0.9920.9720.9790.9650.95 0.7780.7620.9030.3550.688F10.9710.9590.946<em>0.760</em> 0.942<em> 0.499</em>0.446<em>0.741</em>0.519<em> 0.404</em>
* FlexLog yields a significant higher F1-score than compared baseline.The effectiveness of FlexLog and baselines on SYNEVOL-U under varying log sequence instability demonstrated similar results to SynHDFS-U that we have provided in Appendix A.4. Instability at Log Template Level.Table8reports the effectiveness of FlexLog compared with baselines on SYNEVOL-U under varying template-level changes.Once again, FlexLog achieves the highest precision, recall and F1 score across all injection ratios, outperforming the top-performing baseline-LightAD-by 1.9 pp (96.3% − 94.4%) in terms of average F1 score while reducing usage of labeled data by 77.04 pp.A Mann-Whitney U test suggests this difference is statistically significant.</p>
<p>Table 8 .
8
Effectiveness of FlexLog and baselines under different template-level injection ratios on SYNEVOL-U.Specifically, for each configuration, we randomly sample five training subsets (50, 500, 1000, 1500, and 2000 samples) to simulate different levels of data scarcity.Table
limited datafull training setData Unstable MsupervisedSemi-SUnsupervisedFlexLogLightAD NeuralLog LogRobust CNN PLELog LogAnomaly DeepLog LogCluster PCAP0.9990.9990.9990.9410.999 0.1720.5010.5120.7710.0720%NoR0.9690.9390.6360.9690.878 0.1290.3930.4430.8180.471F10.9840.9680.7770.9520.935 0.2430.4410.4750.7940.125P0.9990.9990.9990.9430.999 0.1270.3510.2820.6510.0625%YesR0.9700.9410.6470.9710.882 0.3150.3930.3820.8230.500F10.9850.9690.7850.9560.937 0.1810.4400.3250.7270.111P0.9990.9990.9990.9210.937 0.1200.2600.1810.6220.05410%YesR0.9420.9140.6000.9690.857 0.3160.3710.4000.8000.457F10.9700.9550.7500.9440.895 0.1740.3050.2500.7000.097P0.9990.9990.9990.9440.916 0.1170.2650.1800.6040.05415%YesR0.9210.8940.6050.9180.891 0.3150.4470.4470.7630.447F10.9580.9440.7540.9310.904 0.1710.3330.2570.6740.097P0.9990.9990.9160.9430.906 0.1120.1800.0950.4570.04720%YesR0.9410.9110.6470.9510.852 0.3150.3820.4110.7940.470F10.9690.9530.7580.9460.878 0.1650.2450.1550.5800.085P0.9990.9990.9990.9080.916 0.1270.1880.1000.5070.05125%YesR0.9040.8500.6250.9540.846 0.2390.4000.4000.8000.475F10.9500.9180.7690.9300.880 0.1660.2560.1600.6210.093P0.9730.9990.9310.9230.947 0.1210.1800.0960.4380.05330%YesR0.9250.8570.6420.9540.857 0.2420.4040.4760.7610.476F10.9480.9230.7600.9380.900 0.1610.2500.1600.5560.095P0.9950.9990.9740.930.937 0.1210.2370.1560.5470.053AverageYesR0.9340.8940.6280.9530.864 0.290.3990.4190.790.471F10.9630.944<em>0.763</em>0.941<em> 0.899</em> 0.17<em>0.305</em>0.218<em>0.643</em> 0.096*</p>
<p>Table 10 .
10
F1 score differences (in percentage points) and statistical testing results when comparing FlexLog to baseline methods on the ADFA-U dataset.
Configuration D #SupervisedSemi-SUnsupervisedLightAD NeuralLog LogRobust CNN PLELog LogAnomaly DeepLog LogCluster PCA504221313310102319500113328212436444255adduser10001311321822404549641500712291640474747642000102321182347504867502272820202222263850019162964833353858hydraFTP100061423832424244641500512207473839426320003191672835343764501352119617192228500161031104032293652hydraSSH1000882911563731365315007412235313030522000121898333431375750311831551117500113739235141474848java100067251050293536471500671518462935354820005141012332936365150−4552701510500113933305145464753meter10001523372458505249651500133033155350524863200062227553484646675084120414131322205009292381737363447web1000123530133540404160150013243220454342445820009171711423231375350223<em>18</em>10<em>11</em>11<em>11</em>18<em>20</em>50013<em>273016</em>38<em>37</em>39<em>41</em>52<em>average1000 10</em>16<em>29</em>14<em>42</em>40<em>41</em>42<em>59</em>15008<em>15</em>23<em>13</em>44<em>40</em>41<em>41</em>58<em>20007</em>19<em>17</em>10<em>35</em>37<em>38</em>40<em>60</em>
[12]exLog yields a significant higher F1-score than compared baseline.DL baselines-some of which make one prediction in milliseconds-it reflects the inherent trade-off between model complexity and efficiency.Simpler models such as PCA and LogCluster achieve near instantaneous inference but suffer from low detection effectiveness, failing to detect critical anomalies ( § 5.1).The inference time of FlexLog is acceptable in user-oriented monitoring systems, where inference times on the order of seconds are generally tolerable.Examples include cloud service monitoring (e.g., AWS CloudWatch[19], Microsoft Azure Monitor[12]), where system logs</p>
<p>Table 11 .
11
Training (T) and Inference (I) time of FlexLog and the baselines (in seconds) on ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U.
SupervisedSemi-SUnsupervisedConfig MFlexLog Mistral KNNDTSLFN LightAD NeuralLog LogRobust CNN PLELog LogAnomaly DeepLog LogCluster PCAADFA-UadduserT 16,161 16,160 I 0.836 &lt;0.001 &lt;0.001 0.005 0.842 0.012 2 &lt;0.001 &lt;0.001 5922 0.664221 0.234 0.164 0.211 271 285276 0.025184 0.0124 &lt;0.001 ≪ 0.001 0.017hydraFTPT 15,906 15,906 I 0.818 0.813 &lt;0.001 &lt;0.001 0.005 0.014 1 &lt;0.001 &lt;0.001 4920 0.635220 0.229 0.165 0.211 269 285276 0.024181 0.0114 &lt;0.001 ≪ 0.001 0.017hydraSSHT 14,147 14,146 I 0.832 0.832 &lt;0.001 &lt;0.001 0.004 0.014 1 &lt;0.001 &lt;0.001 5923 0.655220 0.232 0.164 0.211 269 285275 0.025183 0.0124 &lt;0.001 ≪ 0.001 0.017javaT 13,933 13,932 I 0.875 0.870 &lt;0.001 &lt;0.001 0.005 0.014 1 &lt;0.001 &lt;0.001 6921 0.673220 0.236 0.164 0.211 270 285275 0.025180 0.0114 &lt;0.001 ≪ 0.001 0.017webT 14,079 14,078 I 0.864 0.860 &lt;0.001 &lt;0.001 0.004 0.013 1 &lt;0.001 &lt;0.001 5918 0.679220 0.231 0.165 0.211 270 285276 0.025181 0.0124 &lt;0.001 ≪ 0.001 0.017meterT 15,324 15,323 I 0.888 0.885 &lt;0.001 &lt;0.001 0.003 0.014 1 &lt;0.001 &lt;0.001 3921 0.682220 0.238 0.165 0.211 269 285276 0.025182 0.0124 &lt;0.001 ≪ 0.001 0.017LOGEVOL-UHadoopT 4,031 4,031 I 0.435 0.414 0.003 0.001 0.017 0.067 6 &lt;0.001 &lt;0.001 301,550 0.275178 0.078 0.077 0.072 316 481,340 0.0041,020 0.00121 &lt;0.001 ≪ 0.001 0.180SparkT 23,706 23,706 N/A ≪0.001 ≪0.001 0.2 I 0.844 0.838 N/A &lt;0.001 0.006 0.038712 0.564232 0.082 0.072 0.006 136 220944 0.007514 0.0039 &lt; 0.001 ≪ 0.001 0.015SynHDFS-UaverageT 13,587 13,583 I 0.771 0.771 ≪0.001 ≪0.001 &lt;0.001 0.005 4 &lt;0.001 &lt;0.001 221,260 0.259293 0.008 0.016 0.007 355 42976 0.0041,110 0.00220 &lt; 0.001 ≪ 0.001 0.067SYNEVOL-UaverageT 23,706 23,706 N/A &lt;0.001 &lt;0.001 I 0.988 0.979 N/A &lt;0.001 0.009 0.038 0.2712 0.703232 0.116 0.076 0.008 136 220944 0.013514 0.0049 &lt; 0.001 ≪ 0.001 0.015</p>
<p>Table 12 .
12
FlexLog vs. FlexLog w/o cache -Comparisons of inference time per log sequence (in seconds) on ADFA-U, LOGEVOL-U, SYNEVOL-U, and SynHDFS-U FlexLog yields a significant lower inference time than FlexLog without cache.
ADFA-ULOGEVOL-USYNEVOL-U SynHDFS-UConfigadduser hydraFTP hydraSSH java meter web average Hadoop Spark averageaverageaverageFlexLog0.8420.8180.8320.875 0.864 0.888 0.8530.435 0.844 0.6280.9410.771FlexLog w/o cache 0.8960.8610.8980.916 0.909 0.952 0.9050.793 1.086 0.9400.9880.794Difference (s)-0.054-0.043-0.066-0.041 -0.045 -0.064 -0.052  *  -0.358 -0.242 -0.312  <em>-0.047  </em>-0.023*</p>
<p>Table 13 .
13
FlexLog vs. FlexLog w/o RAG -Comparisons in terms of F1 score (in percentage points) on the ADFA-U dataset.
Configadduser hydraFTP hydraSSH java meter web AverageFlexLog71.878.472.364.268.267.270.4FlexLog w/o RAG68.870.564.862.265.964.166.0Difference (pp)3.07.97.52.02.33.14.4  **  FlexLog yields a significant higher F1-score than FlexLog without RAG.</p>
<p>Table 14 .
14
Ablation studies of FlexLog on all unstable datasets.FlexLog yields a significant higher F1-score than the ablation configuration.†FlexLog yields a significant lower F1-score than the ablation configuration.N/ANot applicable.KNN is excluded from FlexLog on the SynHDFS-U and LOGEVOL-U datasets (see § 4.3.2)
ADFA-ULOGEVOL-USynHDFS-U SYNEVOL-UConfigadduser hydraFTP hydraSSH java meter web average Hadoop Spark average averageaverageFlexLog 0.7180.7840.723 0.642 0.682 0.672 0.704 0.982 0.892 0.9370.9720.971w/o Mistral 0.6450.7690.692 0.628 0.639 0.616 0.664<em> 0.975 0.841 0.908</em>0.939<em>0.936</em>w/o KNN 0.6830.7680.654 0.621 0.651 0.579 0.659<em> 0.980 N/A 0.9800.945</em>N/Aw/o DT0.6670.7490.690 0.640 0.654 0.623 0.670<em> 0.973 0.875 0.9240.948</em>0.959<em>w/o SLFN 0.6770.6910.613 0.641 0.647 0.556 0.637</em> 0.978 0.871 0.9240.934<em>0.948</em>w/o ML0.5790.5910.630 0.628 0.674 0.571 0.612<em> 0.998 0.962 0.980  †0.928</em>0.979*</p>
<p>Table 15 .
15
F1 scores of using alternative LLMs in FlexLog.FlexLog yields a significant higher F1 score compared to using the alternative LLM.
ConfigSourceADFA-ULOGEVOL-USynHDFS-U SYNEVOL-Uadduser hydraFTP hydraSSH java meter web average Hadoop Spark averageaverageaverageFlexLogopen0.7180.7840.7230.642 0.682 0.672 0.7040.982 0.892 0.9370.9720.971𝑀𝑖𝑠𝑡𝑟𝑎𝑙 → 𝐿𝑙𝑎𝑚𝑎 open0.6790.7430.7070.593 0.669 0.591 0.664<em>0.941 0.850 0.895</em>0.949<em>0.970𝑀𝑖𝑠𝑡𝑟𝑎𝑙 → 𝐺𝑃𝑇 closed 0.7210.7860.7180.648 0.690 0.696 0.7100.981 0.886 0.9330.9760.971</em></p>
<p>5.5.2Error Analysis.In RQ4, we observed that removing any base model from FlexLog generally decreases effectiveness.To better understand the role of the LLM base model (i.e., Mistral) and ML base models (i.e., KNN, DT, and SLFN), in this section, we analyze the log sequences that FlexLog correctly classify but mis-classify when either Mistral or ML models are removed.We denote these mis-classified log sequences as MIS w/o Mistral and MIS w/o ML , respectively.We investigate, for each dataset, whether MIS w/o Mistral and MIS w/o ML differ in various characteristics to highlight the unique contribution of LLM and ML to the effectiveness of FlexLog.Specifically, we focus</p>
<p>Table 16 .
16
Overview of token consumption of ADFA-U, LOGEVOL-U, SYNEVOL-U, and SynHDFS-U on opensource and closed-source LLMs log templates in MIS w/o Mistral and MIS w/o ML because unseen log templates pose a key challenge in ULAD.Traditional anomaly detectors often rely on predefined patterns and struggle with generalization; in contrast, FlexLog, by means of the integration of LLM, may be better at detecting anomalies involving novel log templates.By analyzing the misclassified cases in MIS w/o Mistral and MIS w/o ML , we can determine whether the LLM (Mistral) or ML models (KNN, DT, and SLFN) contribute more to handling novel log templates, helping us understand their complementary strengths in FlexLog.Table
InputMaximum Input TokenModelAccessibilityToken LimitADFA-U LOGEVOL-U SynHDFS-U SYNEVOL-UMistral Smallopen128,00025,84828,9341,24316,840Llama 3.1 8Bopen128,00021,37124,79886212,533GPT-4oclosed65,53621,38324,73586012,479on the unseen</p>
<p>Table 17 .
17
Overview of Error Analysis of ADFA-U, LOGEVOL-U, SYNEVOL-U, and SynHDFS-U when Mistral or ML models are removed from FlexLog
DataConfigCondition # SequenceSequence Length avg min max% Anomaly% Unseen TemplateTesting Dataset5,146523.98 75 4,49414.343.54ADFA-Uall ULADMIS w/o Mistral149476.74 82 2,51307.38MIS w/o ML264610.48 80 3,08911.741.89Testing Dataset5,32913.41 1509.874.37Hadoop ULADMIS w/o Mistral541.8 95000MIS w/o ML0N/A N/A N/AN/AN/ALOGEVOL-USpark ULADTesting Dataset MIS w/o Mistral4,045 681.70 1 15.33 41,977 351.78 10038.07 33.33MIS w/o ML12626261000Testing Dataset9,37442.88 11,9776.3458.70all ULADMIS w/o Mistral1129.83 45054.5418.18MIS w/o ML12626261000Testing Dataset3,74426.91 105722.220.43SynHDFS-Uall ULADMIS w/o Mistral2440.08 354800MIS w/o ML9232.43 19525.430Testing Dataset15,406151.07 11,0222.9691.3SYNEVOL-Uall ULADMIS w/o Mistral34135.03 632310011.76MIS w/o ML2339.04 417709.28
N/A Not applicable as no prediction errors were observed in this configuration</p>
<p>Table 18 .
18
F1 scores of using alternative Ensembling Strategies in FlexLog.FlexLog yields a significant higher F1 score compared to using the alternative ensembling strategy.
EnsemblingADFA-ULOGEVOL-USynHDFS-U SYNEVOL-UConfigadduser hydraFTP hydraSSH java meter web average Hadoop Spark averageaverageaverageMajority Voting (FlexLog)0.7180.7840.7230.642 0.682 0.672 0.7040.982 0.892 0.9370.9720.971Majority Voting (alternative) 0.6410.7110.6910.615 0.656 0.635 0.650<em>0.964 0.840 0.902</em>0.936<em>0.929</em>SNAIL0.6710.7140.6830.624 0.628 0.651 0.661<em>0.965 0.854 0.909</em>0.958<em>0.949</em>MetaFormer0.6660.7060.6910.615 0.607 0.663 0.658<em>0.976 0.866 0.9210.954</em>0.951**
Hadoop versions
.10.2 and
.3.3 are referred to as Hadoop 2 and 3, respectively, and Spark versions 2.4.0 and 3.0.3 are denoted as Spark 2 and Spark 3, respectively.
We acknowledge that on the original HDFS dataset, more recent log parsers[43,63] demonstrated higher parsing effectiveness than Drain. However, as a recent study[47] demonstrated, there is no correlation between parsing accuracy and anomaly detection accuracy.
Overall, due to the limited training data, we recommend using default parameters and tuning only those that are highly sensitive to imbalanced data, as anomalies are often rare in real-world datasets, using cross-validation. In the future, we plan to conduct more experiments to explore the correlation between the percentage of anomalous data and the optimal number of neighbors.
The effectiveness of baselines when trained on the same limited data as FlexLog is reported in Appendix A.3.
https://alliancecan.ca/en
AcknowledgmentsThis work was partly supported by the Natural Sciences and Engineering Research Council of Canada (NSERC), through the Canada Research Chairs and discovery programs, the Research Ireland grant 13/RC/2094-2, the Luxembourg National Research Fund (FNR), grant reference C22/IS/17373407/LOGODOR.The experiments conducted in this work were enabled in part by the computation support provided by the Digital Research Alliance of Canada.5RQ2: Data Efficiency on the ADFA-U DatasetRQ2 focuses on the data efficiency analysis of FlexLog and baselines.As mentioned in § 4.1, computational constraints preclude us from investigating the data efficiency on all the datasets.Hence, we focus on ADFA-U in this RQ since it includes six diverse configurations, enabling a robust evaluation under different real-world ULAD scenarios.As shown in RQ1, these diverse configurations make it the most challenging dataset in our experiments in terms of detectionA AppendixA.1 Alternative Ensembling StrategiesFlexLog employs a majority voting strategy, where in the case of a tie between base models, the label is set to normal, as anomalies are rare.This ensemble approach uses binary labels for voting rather than anomaly confidence scores, allowing us to adopt base models that directly output the final label, such as our fine-tuned version of Mistral.Alternative ensembling strategies include the alternative majority voting method, which assigns a random label in the case of a tie, and state-of-the-art meta-learning approaches that adaptively learn from base model performance on validation data.Specifically, SNAIL[66]is an attentive CNN-based meta-learner, while MetaFormer[98]introduces a novel attention module called token mixer; both have shown significant improvements over  where only LightAD and FlexLog remain robust across instability levels, all supervised methodsincluding FlexLog, LightAD, NeuralLog, LogRobust, and CNN-do not show a strong correlation between performance and increasing log instability in SYNEVOL-U.In contrast, semi-supervised and unsupervised methods exhibit a clear decline in precision, recall, and F1 score as instability increases.One possible reason is that changes at the log sequence level in SYNEVOL-U often involve minor modifications, such as adding or removing a single template, which may have a limited impact on ULAD.For instance, at a 30 % injection ratio, 55 % of changes involve just one template, making the overall sequence structure relatively stable despite modifications.
A practical guide for using statistical tests to assess randomized algorithms in software engineering. Andrea Arcuri, Lionel Briand, 10.1145/1985793.1985795Proceedings of the 33rd International Conference on Software Engineering, ICSE '11. the 33rd International Conference on Software Engineering, ICSE '11New York, NY, USAAssociation for Computing Machinery2011</p>
<p>Deep learning in high-frequency trading: conceptual challenges and solutions for real-time fraud detection. Oluwabunmi Halima, Adebimpe Bello, Maxwell Bolatito Ige, Ameyaw Nana, World Journal of Advanced Engineering Technology and Sciences. 12022024</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Smote: Synthetic minority over-sampling technique. N V Chawla, K W Bowyer, L O Hall, W P Kegelmeyer, 10.1613/jair.953Journal of Artificial Intelligence Research. 1076-975716June 2002</p>
<p>Smote: synthetic minority oversampling technique. Kevin W Nitesh V Chawla, Lawrence O Bowyer, Philip Hall, Kegelmeyer, Journal of artificial intelligence research. 162002</p>
<p>Fast greedy map inference for determinantal point process to improve recommendation diversity. Laming Chen, Guoxin Zhang, Hanning Zhou, 2018</p>
<p>Failure diagnosis using decision trees. Mike Y Chen, Alice X Zheng, Jesper Lloyd, Michael I Jordan, Eric Brewer, International Conference on Autonomic Computing. 2004. 200456849250</p>
<p>Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, Eric P Xing, March 2023</p>
<p>Learning phrase representations using RNN encoder-decoder for statistical machine translation. Kyunghyun Cho, Bart Van Merrienboer, Çaglar Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio, 10.3115/v1/d14-1179Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. Alessandro Moschitti, Bo Pang, Walter Daelemans, the 2014 Conference on Empirical Methods in Natural Language ProcessingDoha, Qatar2014. October 25-29, 2014. 2014A meeting of SIGDAT, a Special Interest Group of the ACL</p>
<p>Prefix-graph: A versatile log parsing approach merging prefix tree with probabilistic graph. Guohao Chu, Jiaqi Wang, Qi Qi, Haiyang Sun, Shengtao Tao, Jun Liao, Proceedings of the 37th International Conference on Data Engineering (ICDE). the 37th International Conference on Data Engineering (ICDE)Virtual Event, 2021. IEEE</p>
<p>. Chung Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shane Shixiang, Zhuyun Gu, Mirac Dai, Xinyun Suzgun, Aakanksha Chen, Alex Chowdhery, Marie Castro-Ros, Kevin Pellat, Dasha Robinson, Sharan Valter, Gaurav Narang, Adams Mishra, Vincent Yu, Yanping Zhao, Andrew Huang, Hongkun Dai, Slav Yu, Ed H Petrov, Jeff Chi, Jacob Dean, Adam Devlin, Denny Roberts, Quoc V Zhou, Jason Le, Wei, 2022Scaling instruction-finetuned language models</p>
<p>Microsoft azure essentials-fundamentals of azure. Michael Collier, Robin Shahan, 2015Microsoft Press</p>
<p>Generation of a new ids test dataset: Time to retire the kdd collection. Gideon Creech, Jiankun Hu, 10.1109/WCNC.2013.65553012013 IEEE Wireless Communications and Networking Conference (WCNC). 2013</p>
<p>Mapreduce: Simplified data processing on large clusters. Jeffrey Dean, Sanjay Ghemawat, 10.1145/1327452.1327492Communications of the ACM. 5112008</p>
<p>Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. Deepseek-Ai , Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, 2025</p>
<p>Indexing by latent semantic analysis. Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, Richard Harshman, Journal of the American society for information science. 4161990</p>
<p>Qlora: Efficient finetuning of quantized llms. Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer, 2023</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/n19-14232019</p>
<p>Infrastructure Monitoring with Amazon CloudWatch: Effectively monitor your AWS infrastructure to optimize resource allocation, detect anomalies, and set automated actions. Ewere Diagboya, 2021Packt Publishing Ltd</p>
<p>A survey on in-context learning. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Tianyu Liu, arXiv:2301.002342022arXiv preprint</p>
<p>DeepLog: Anomaly detection and diagnosis from system logs through deep learning. Min Du, Feifei Li, Guineng Zheng, Vivek Srikumar, 2017</p>
<p>Discriminatory analysis -nonparametric discrimination: Consistency properties. Evelyn Fix, Joseph L Hodges, International Statistical Review. 572381989</p>
<p>The llama 3 herd of models. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, 2024</p>
<p>Knn model-based approach in classification. Gongde Guo, Hui Wang, David Bell, Yaxin Bi, Kieran Greer, On The Move to Meaningful Internet Systems 2003: CoopIS, DOA, and ODBASE. Robert Meersman, Zahir Tari, Douglas C Schmidt, Berlin, Heidelberg; Berlin HeidelbergSpringer2003</p>
<p>Logbert: Log anomaly detection via bert. Haixuan Guo, Shuhan Yuan, Xintao Wu, 10.1109/IJCNN52387.2021.95341132021 International Joint Conference on Neural Networks (IJCNN). 2021</p>
<p>. Fatemeh Hadadi, Replication PackageQinghua Xu, Replication PackageDomenico Bianculli, Replication PackageLionel Briand, Replication Package10 2025</p>
<p>Loggpt: Log anomaly detection via gpt. Xiao Han, Shuhan Yuan, Mohamed Trabelsi, 10.1109/BigData59044.2023.103865432023 IEEE International Conference on Big Data (BigData). 2023</p>
<p>Parameter-efficient fine-tuning for large models: A comprehensive survey. Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang, 2024</p>
<p>Llmelog: An approach for anomaly detection based on llm-enriched log events. M He, T Jia, C Duan, Y Cai, G Li, Huang, 2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE). Tsukuba, JapanIEEE Computer Society2024</p>
<p>Drain: An online log parsing approach with fixed depth tree. Pinjia He, Jieming Zhu, Zibin Zheng, Michael R Lyu, 2017</p>
<p>Experience report: System log analysis for anomaly detection. Shilin He, Jieming Zhu, Pinjia He, Michael R Lyu, 10.1109/ISSRE.2016.212016</p>
<p>Loghub: A Large Collection of System Log Datasets Towards Automated Log Analytics. Shilin He, Jieming Zhu, Pinjia He, Michael R Lyu, CoRR, abs/2008.064482020</p>
<p>A survey on automated log analysis for reliability engineering. Shilin He, Pinjia He, Zhuangbin Chen, Tianyi Yang, Yuxin Su, Michael R Lyu, 10.1145/3460345ACM Comput. Surv. 0360-0300546jul 2021</p>
<p>One-class support vector machines approach to anomaly detection. Maryamsadat Hejazi, Yashwant Prasad Singh, Applied Artificial Intelligence. 2752013</p>
<p>Long short-term memory. Sepp Hochreiter, Jürgen Schmidhuber, 10.1162/neco.1997.9.8.1735Neural Comput. 0899-766798nov 1997</p>
<p>Lora: Low-rank adaptation of large language models. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, 2021</p>
<p>Classification ability of single hidden layer feedforward neural networks. Guangbin Huang, Yan Qiu Chen, Haroon Atique Babri, IEEE transactions on neural networks. 1132000</p>
<p>Hitanomaly: Hierarchical transformers for anomaly detection in system log. Shaohan Huang, Yi Liu, Carol Fung, Rong He, Yining Zhao, Hailong Yang, Zhongzhi Luan, 10.1109/TNSM.2020.3034647IEEE Transactions on Network and Service Management. 1742020</p>
<p>Evlog: Identifying anomalous logs over software evolution. Y Huo, C Lee, Y Su, S Shan, J Liu, M R Lyu, 10.1109/ISSRE59848.2023.000182023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE). Los Alamitos, CA, USAIEEE Computer Societyoct 2023</p>
<p>. Intel, Hibench, 2021</p>
<p>Scaling down to scale up: A cost-benefit analysis of replacing openai's llm with open source slms in production. Chandra Irugalbandara, Ashish Mahendra, Roland Daynauth, Tharuka Kasthuri Arachchige, Jayanaka Dantanarayana, Krisztian Flautner, Lingjia Tang, Yiping Kang, Jason Mars, 10.1109/ISPASS61541.2024.000342024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). 2024</p>
<p>Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego De Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Mistral 7b. Renard Lélio, Marie-Anne Lavaud, Pierre Lachaux, Teven Stock, Thibaut Le Scao, Thomas Lavril, Timothée Wang, William El Lacroix, Sayed, 2023</p>
<p>Lilac: Log parsing using llms with adaptive parsing cache. Zhihan Jiang, Jinyang Liu, Zhuangbin Chen, Yichen Li, Junjie Huang, Yintong Huo, Pinjia He, Jiazhen Gu, Michael R Lyu, 2024</p>
<p>Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, Tomas Mikolov, Fasttext.zip: Compressing text classification models. 2016</p>
<p>Examining the stability of logging statements. Suhas Kabinna, Weiyi Shang, Cor-Paul Bezemer, Ahmed E Hassan, 10.1109/SANER.2016.292016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER). 20161</p>
<p>A systematic review on imbalanced data challenges in machine learning: Applications and solutions. Harsurinder Kaur, Husanbir Singh Pannu, Avleen Kaur Malhi, ACM computing surveys (CSUR). 5242019</p>
<p>Impact of log parsing on deep learningbased anomaly detection. Zanis Ali Khan, Donghwan Shin, Domenico Bianculli, Lionel C Briand, 10.1007/s10664-024-10533-wEmpirical Software Engineering. 1573-7616296August 2024</p>
<p>Convolutional neural networks for sentence classification. Yoon Kim, 10.3115/v1/D14-1181Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Alessandro Moschitti, Bo Pang, Walter Daelemans, the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarAssociation for Computational LinguisticsOctober 2014</p>
<p>Herb Krasner, The cost of poor software quality in the us: A 2020 report. Proc. Consortium Inf. Softw. QualityTM (CISQTM). 2021</p>
<p>Deep learning for anomaly detection in log data: A survey. Max Landauer, Sebastian Onder, Florian Skopik, Markus Wurzenberger, 10.1016/j.mlwa.2023.100470.URLhttps://www.sciencedirect.com/science/article/pii/S2666827023000233Machine Learning with Applications. 2666-8270121004702023</p>
<p>Log-based anomaly detection without log parsing. V Le, H Zhang, 10.1109/ASE51524.2021.9678773nov 2021</p>
<p>Log parsing: How far can chatgpt go?. V Le, H Zhang, 10.1109/ASE56229.2023.002062023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE). Los Alamitos, CA, USAIEEE Computer Societysep 2023</p>
<p>Log-based anomaly detection with deep learning: how far are we?. Van-Hoang Le, Hongyu Zhang, 10.1145/3510003.3510155Proceedings of the 44th International Conference on Software Engineering, ICSE '22. the 44th International Conference on Software Engineering, ICSE '22New York, NY, USAAssociation for Computing Machinery2022</p>
<p>Log parsing with prompt-based few-shot learning. Van-Hoang Le, Hongyu Zhang, 10.1109/ICSE48619.2023.00204Proceedings of the 45th International Conference on Software Engineering, ICSE '23. the 45th International Conference on Software Engineering, ICSE '23IEEE Press</p>
<p>Deep learning. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, nature. 52175534362015</p>
<p>Swisslog: Robust and unified deep learning based log anomaly detection for diverse faults. Xiaoyun Li, Pengfei Chen, Linxiao Jing, Zilong He, Guangba Yu, 10.1109/ISSRE5003.2020.00018Proceedings -International Symposium on Software Reliability Engineering, ISSRE, 2020-Octob. -International Symposium on Software Reliability Engineering, ISSRE, 2020-Octob2020</p>
<p>Log Clustering Based Problem Identification for Online Service Systems. Qingwei Lin, Hongyu Zhang, Jian-Guang Lou, Yu Zhang, Xuewei Chen, 10.1145/2889160.2889232Proceedings of the 38th International Conference on Software Engineering, ICSE -Companion Volume. the 38th International Conference on Software Engineering, ICSE -Companion VolumeAustin, TX, USAACM2016</p>
<p>Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, 10.1109/ICDM.2008.172008 Eighth IEEE International Conference on Data Mining. 2008Isolation forest</p>
<p>Logprompt: Prompt engineering towards zero-shot and interpretable log analysis. Yilun Liu, Shimin Tao, Weibin Meng, Feiyu Yao, Xiaofeng Zhao, Hao Yang, 10.1145/3639478.3643108Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings, ICSE-Companion '24. the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings, ICSE-Companion '24New York, NY, USAAssociation for Computing Machinery20249798400705021</p>
<p>Logassist: Assisting log analysis through log summarization. Steven Locke, Heng Li, Tse-Hsun Peter Chen, Weiyi Shang, Wei Liu, 10.1109/TSE.2021.3083715IEEE Transactions on Software Engineering. 4892022</p>
<p>Long Ouyang, Jeff Wu Xu, Jiang Diogo, Almeida Carroll, L Wainwright, Pamela Mishkin, Paul Christiano, Jan Leike, Ryan Lowe, Gpt-4 technical report. 2023</p>
<p>Detecting anomaly in big data system logs using convolutional neural network. Siyang Lu, Xiang Wei, Yandong Li, Liqiang Wang, 10.1109/ACCESS.2018.2811530IEEE Access. 62018</p>
<p>Llmparser: An exploratory study on using large language models for log parsing. Zeyang Ma, An Ran Chen, Dong Jae Kim, Tse-Hsun Chen, Shaowei Wang, 10.1145/3597503.3639150Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24. the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>hdbscan: Hierarchical density based clustering. Leland Mcinnes, John Healy, Steve Astels, J. Open Source Softw. 2112052017</p>
<p>Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs. Weibin Meng, Ying Liu, Yichen Zhu, Shenglin Zhang, Dan Pei, Yuqing Liu, Yihao Chen, Ruizhi Zhang, Shimin Tao, Pei Sun, IJCAI. 201919</p>
<p>A simple neural attentive meta-learner. Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel, 2018</p>
<p>Mistralai, Mistral technologies. 2024. 2024-09-24</p>
<p>Machine learning with oversampling and undersampling techniques: overview study and experimental results. Roweida Mohammed, Jumanah Rawashdeh, Malak Abdullah, 2020 11th international conference on information and communication systems (ICICS). IEEE2020</p>
<p>Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation. Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, Yanai Elazar, 10.18653/v1/2023.findings-acl.779Findings of the Association for Computational Linguistics: ACL 2023. Anna Rogers, Jordan Boyd-Graber, Naoaki Okazaki, Toronto, CanadaAssociation for Computational LinguisticsJuly 2023</p>
<p>What supercomputers say: A study of five system logs. Adam Oliner, Jon Stearley, 2007</p>
<p>Fine-tuning: preparing your dataset. 2024. 2024-01-02OpenAI</p>
<p>Openai models. 2024. 2024-05-10OpenAI</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, Ryan J Lowe, ArXiv, abs/2203.021552022</p>
<p>Self-evolutionary group-wise log parsing based on large language model. C Pei, Z Liu, Jianhui Li, E Zhang, L Zhang, H Zhang, W Chen, D Pei, G Xie, 2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE). Tsukuba, JapanIEEE Computer Society2024</p>
<p>Ensemble learning. Ensemble machine learning: Methods and applications. Robi Polikar, 2012</p>
<p>Bidirectional recurrent neural networks. M Schuster, K K Paliwal, 10.1109/78.650093IEEE Transactions on Signal Processing. 45111997</p>
<p>The hadoop distributed file system. Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, 2010</p>
<p>Qwen2.5-1m: Deploy your own qwen with context length up to 1m tokens. Qwen Team, January 2025</p>
<p>Llama 2: Open foundation and fine-tuned chat models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, 2023</p>
<p>Monitoring with Prometheus. James Turnbull, 2018Turnbull Press</p>
<p>Unsloth fine-tuning package. Unsloth, 2024. 2024-11-30</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17. the 31st International Conference on Neural Information Processing Systems, NIPS'17Red Hook, NY, USACurran Associates Inc2017ISBN 9781510860964</p>
<p>Apache hadoop yarn: Yet another resource negotiator. Vinod Kumar Vavilapalli, Arun C Murthy, Chris Douglas, Sharad Agarwal, Mahadev Konar, Robert Evans, Thomas Graves, Jason Lowe, Hitesh Shah, Siddharth Seth, Proceedings of the 4th annual Symposium on Cloud Computing. the 4th annual Symposium on Cloud Computing2013</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Frontiers of Computer Science. 1861863452024</p>
<p>Maddc: Multi-scale anomaly detection, diagnosis and correction for discrete event logs. Xiaolei Wang, Lin Yang, Dongyang Li, Linru Ma, Yongzhong He, Junchao Xiao, Jiyuan Liu, Yuexiang Yang, 10.1145/3564625.3567972Proceedings of the 38th Annual Computer Security Applications Conference, ACSAC '22. the 38th Annual Computer Security Applications Conference, ACSAC '22New York, NY, USAAssociation for Computing Machinery2022</p>
<p>Software testing with generative ai. Mark Winteringham, 2024</p>
<p>Demonstration-free: Towards more practical log parsing with large language models. Yi Xiao, Hongyu Van-Hoang Le, Zhang, 10.1145/3691620.3694994Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering, ASE '24. the 39th IEEE/ACM International Conference on Automated Software Engineering, ASE '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Divlog: Log parsing with prompt enhanced in-context learning. Junjielong Xu, Ruichun Yang, Yintong Huo, Chengyu Zhang, Pinjia He, 10.1145/3597503.3639155Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24. the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Online system problem detection by mining patterns of console logs. Wei Xu, Ling Huang, Armando Fox, David Patterson, Michael Jordan, 200912</p>
<p>Detecting large-scale system problems by mining console logs. Wei Xu, Ling Huang, Armando Fox, David Patterson, Michael I Jordan, 10.1145/1629575.1629587Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, SOSP '09. the ACM SIGOPS 22nd Symposium on Operating Systems Principles, SOSP '09New York, NY, USAAssociation for Computing Machinery2009</p>
<p>Detecting large-scale system problems by mining console logs. Wei Xu, Ling Huang, Armando Fox, David Patterson, Michael I Jordan, 2010</p>
<p>An Yang, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoyan Huang, Jiandong Jiang, Jianhong Tu, Jianwei Zhang, Jingren Zhou, Junyang Lin, Kai Dang, Kexin Yang, Le Yu, Mei Li, Minmin Sun, Qin Zhu, Rui Men, Tao He, Weijia Xu, Wenbiao Yin, Wenyuan Yu, Xiafei Qiu, Xingzhang Ren, Xinlong Yang, Yong Li, arXiv:2501.15383Zhiying Xu, and Zipeng Zhang. Qwen2.5-1m technical report. 2025arXiv preprint</p>
<p>Semi-supervised log-based anomaly detection via probabilistic label estimation. Lin Yang, Junjie Chen, Zan Wang, Weijing Wang, Jiajun Jiang, Xuyuan Dong, Wenbin Zhang, 2021</p>
<p>Do large language models perform latent multi-hop reasoning without exploiting shortcuts?. Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva, 2024</p>
<p>Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, Yue Zhang, A survey on large language model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing. 2024100211</p>
<p>Deep learning or classical machine learning? an empirical study on log-based anomaly detection. Boxi Yu, Jiayi Yao, Qiuai Fu, Zhiqing Zhong, Haotian Xie, Yaoliang Wu, Yuchi Ma, Pinjia He, 10.1145/3597503.3623308Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24. the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Deep learning or classical machine learning? an empirical study on log-based anomaly detection. Boxi Yu, Jiayi Yao, Qiuai Fu, Zhiqing Zhong, Haotian Xie, Yaoliang Wu, Yuchi Ma, Pinjia He, 10.1145/3597503.3623308Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24. the IEEE/ACM 46th International Conference on Software Engineering, ICSE '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Metaformer is actually what you need for vision. Weihao Yu, Mi Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi Feng, Shuicheng Yan, 2022</p>
<p>Challenges in knn classification. Shichao Zhang, IEEE Transactions on Knowledge and Data Engineering. 34102021</p>
<p>System log parsing: A survey. T Zhang, H Qiu, G Castellano, M Rifai, C Chen, F Pianese, 10.1109/TKDE.2022.3222417IEEE Transactions on Knowledge &amp; Data Engineering. 1558-21913508aug 2023</p>
<p>Leveraging rag-enhanced large language model for semisupervised log anomaly detection. W Zhang, T Jia, C Duan, Y Cai, G Li, Huang, 2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE). Tsukuba, JapanIEEE Computer Society2024</p>
<p>Robust log-based anomaly detection on unstable log data. Xu Zhang, Yong Xu, Qingwei Lin, Bo Qiao, Hongyu Zhang, Yingnong Dang, Chunyu Xie, Xinsheng Yang, Qian Cheng, Ze Li, Junjie Chen, Xiaoting He, Randolph Yao, Jian-Guang Lou, Murali Chintalapati, Furao Shen, Dongmei Zhang, 10.1145/3338906.3338931Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019New York, NY, USAAssociation for Computing Machinery2019</p>
<p>A review of ensemble learning algorithms used in remote sensing applications. Yuzhen Zhang, Jingjing Liu, Wenjuan Shen, Applied Sciences. 121786542022</p>
<p>Llm-powered zero-shot online log parsing. Chen Zhi, Liye Cheng, Meilin Liu, Xinkui Zhao, Yueshen Xu, Shuiguang Deng, 10.1109/ICWS62655.2024.001062024 IEEE International Conference on Web Services (ICWS). 2024</p>
<p>Logparser-llm: Advancing efficient log parsing with large language models. Aoxiao Zhong, Dengyao Mo, Guiyang Liu, Jinbu Liu, Qingda Lu, Qi Zhou, Jiesheng Wu, Quanzheng Li, Qingsong Wen, 2024</p>
<p>. Zhi-Hua Zhou, Zhi-Hua Zhou, 2021Springer</p>            </div>
        </div>

    </div>
</body>
</html>