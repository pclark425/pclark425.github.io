<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5273 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5273</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5273</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-108.html">extraction-schema-108</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-b33577b6624da43765d215d9954531e3c7e48e52</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/b33577b6624da43765d215d9954531e3c7e48e52" target="_blank">ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis</a></p>
                <p><strong>Paper Venue:</strong> Journal of the American Chemical Society</p>
                <p><strong>Paper TL;DR:</strong> This work uses prompt engineering to guide ChatGPT in the automation of text mining of metal-organic framework (MOF) synthesis conditions from diverse formats and styles of the scientific literature, and constructed a machine-learning model with over 87% accuracy in predicting MOF experimental crystallization outcomes and preliminarily identifying important factors in MOF crystallization.</p>
                <p><strong>Paper Abstract:</strong> We use prompt engineering to guide ChatGPT in the automation of text mining of metal-organic framework (MOF) synthesis conditions from diverse formats and styles of the scientific literature. This effectively mitigates ChatGPT's tendency to hallucinate information, an issue that previously made the use of large language models (LLMs) in scientific fields challenging. Our approach involves the development of a workflow implementing three different processes for text mining, programmed by ChatGPT itself. All of them enable parsing, searching, filtering, classification, summarization, and data unification with different trade-offs among labor, speed, and accuracy. We deploy this system to extract 26 257 distinct synthesis parameters pertaining to approximately 800 MOFs sourced from peer-reviewed research articles. This process incorporates our ChemPrompt Engineering strategy to instruct ChatGPT in text mining, resulting in impressive precision, recall, and F1 scores of 90-99%. Furthermore, with the data set built by text mining, we constructed a machine-learning model with over 87% accuracy in predicting MOF experimental crystallization outcomes and preliminarily identifying important factors in MOF crystallization. We also developed a reliable data-grounded MOF chatbot to answer questions about chemical reactions and synthesis procedures. Given that the process of using ChatGPT reliably mines and tabulates diverse MOF synthesis information in a unified format while using only narrative language requiring no coding expertise, we anticipate that our ChatGPT Chemistry Assistant will be very useful across various other chemistry subdisciplines.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Is GPT-3 all you need for low-data discovery in chemistry? <em>(Rating: 2)</em></li>
                <li>Automatic chemical design using a data-driven continuous representation of molecules. <em>(Rating: 2)</em></li>
                <li>The rise of deep learning in drug discovery. <em>(Rating: 2)</em></li>
                <li>Topologically guided, automated construction of metal-organic frameworks and their evaluation for energy-related applications. <em>(Rating: 1)</em></li>
                <li>Sparks of artificial general intelligence: Early experiments with gpt-4. <em>(Rating: 1)</em></li>
                <li>A database of ultrastable MOFs reassembled from stable fragments with machine learning models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5273",
    "paper_id": "paper-b33577b6624da43765d215d9954531e3c7e48e52",
    "extraction_schema_id": "extraction-schema-108",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Is GPT-3 all you need for low-data discovery in chemistry?",
            "rating": 2
        },
        {
            "paper_title": "Automatic chemical design using a data-driven continuous representation of molecules.",
            "rating": 2
        },
        {
            "paper_title": "The rise of deep learning in drug discovery.",
            "rating": 2
        },
        {
            "paper_title": "Topologically guided, automated construction of metal-organic frameworks and their evaluation for energy-related applications.",
            "rating": 1
        },
        {
            "paper_title": "Sparks of artificial general intelligence: Early experiments with gpt-4.",
            "rating": 1
        },
        {
            "paper_title": "A database of ultrastable MOFs reassembled from stable fragments with machine learning models.",
            "rating": 1
        }
    ],
    "cost": 0.00892875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis</h1>
<p>Zhiling Zheng, ${ }^{\dagger, \ddagger, \S}$ Oufan Zhang, ${ }^{\dagger}$ Christian Borgs, ${ }^{\S, \S}$ Jennifer T. Chayes, ${ }^{\S, \S, \dagger \dagger, \ddagger, \S \S}$ Omar M. Yaghi ${ }^{\dagger, \ddagger, \S, \S, *}$<br>${ }^{\dagger}$ Department of Chemistry, University of California, Berkeley, California 94720, United States<br>${ }^{\ddagger}$ Kavli Energy Nanoscience Institute, University of California, Berkeley, California 94720, United States<br>${ }^{\S}$ Bakar Institute of Digital Materials for the Planet, College of Computing, Data Science, and Society, University of California, Berkeley, California 94720, United States<br>${ }^{\S}$ Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, California 94720, United States<br>${ }^{\dagger \dagger}$ Department of Mathematics, University of California, Berkeley, California 94720, United States<br>${ }^{\S \S}$ Department of Statistics, University of California, Berkeley, California 94720, United States<br>${ }^{\S \S}$ School of Information, University of California, Berkeley, California 94720, United States<br>${ }^{8}$ KACST-UC Berkeley Center of Excellence for Nanomaterials for Clean Energy Applications, King Abdulaziz City for Science and Technology, Riyadh 11442, Saudi Arabia</p>
<p>KEYWORDS: ChatGPT, data mining, metal-organic frameworks, synthesis, crystals.</p>
<h4>Abstract</h4>
<p>We use prompt engineering to guide ChatGPT in the automation of text mining of metal-organic frameworks (MOFs) synthesis conditions from diverse formats and styles of the scientific literature. This effectively mitigates ChatGPT's tendency to hallucinate information-an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging. Our approach involves the development of a workflow implementing three different processes for text mining, programmed by ChatGPT itself. All of them enable parsing, searching, filtering, classification, summarization, and data unification with different tradeoffs between labor, speed, and accuracy. We deploy this system to extract 26,257 distinct synthesis parameters pertaining to approximately 800 MOFs sourced from peer-reviewed research articles. This process incorporates our ChemPrompt Engineering strategy to instruct ChatGPT in text mining, resulting in impressive precision, recall, and F1 scores of $90-99 \%$. Furthermore, with the dataset built by text mining, we constructed a machine-learning model with over $87 \%$ accuracy in predicting MOF experimental crystallization outcomes and preliminarily identifying important factors in MOF crystallization. We also developed a reliable data-grounded MOF chatbot to answer questions on chemical reactions and synthesis procedures. Given that the process of using ChatGPT reliably mines and tabulates diverse MOF synthesis information in a unified format, while using only narrative language requiring no coding expertise, we anticipate that our ChatGPT Chemistry Assistant will be</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" />
very useful across various other chemistry subdisciplines.</p>
<h1>INTRODUCTION</h1>
<p>The dream of chemists is to create matter in the hope of advancing human knowledge for the betterment of society. ${ }^{1,2}$ As we stand on the precipice of the age of Artificial General Intelligence (AGI), the potential for synergy between AI and chemistry is vast and promising. ${ }^{3,4}$ The idea of creating AI-powered chemistry assistants offers unprecedented opportunities to revolutionize the landscape of chemistry research by applying knowledge across various disciplines, efficiently processing laborintensive and time-consuming tasks, such as literature searches, compound screening and data analysis. AI-powered chemistry may ultimately transcend the limits of human cognition. ${ }^{5-8}$
Identifying chemical information for compounds, including ideal synthesis conditions and physical and chemical properties, has been a critical endeavor in chemistry research. The comprehensive summary of chemical information from literature reports, such as publications and patents, and their subsequent storage in an organized database format is the next logical and necessary step toward discovery of materials. ${ }^{9}$ The challenge lies in efficiently mining the vast amount of available literature to obtain valuable information and insights. Traditionally, specialized natural language processing (NLP) models have been employed to address this issue. ${ }^{10-14}$ However, these approaches can be labor-intensive and necessitate expertise in coding, computer science, and data science. Furthermore, they are less generalizable, requiring rewriting the program when the target changes. The advent of large language models (LLMs), such as GPT-3, GPT-3.5 and GPT-4, has the potential to fundamentally transform this process and revolutionize the routine of chemistry research in the next decade. ${ }^{9,15-18}$
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 1. Schematics of ChatGPT Chemistry Assistant workflow having three different processes employing ChatGPT and ChemPrompt for efficient text mining and summarization of MOF synthesis conditions from a diverse set of published research articles. Each process is distinctively labeled with red, blue, and green dots respectively. To illustrate, Process 1 initiates with "Published Research Articles", proceeds to "Human Preselection", moves onto the "Synthesis Paragraph", integrates "ChatGPT with ChemPrompt", and culminates in "Tabulated Data". Steps shared among multiple processes are indicated with corresponding color-coded dots. The two-snakes logo of Python is included to indicate the use of the Python programming language, with the logo's credit attributed to the Python Software Foundation (PSF).</p>
<p>Herein, we demonstrate that LLMs, including ChatGPT based on the GPT-3.5 and GPT-4 model, can act as chemistry assistants to collaborate with human researchers, facilitating text mining and data analysis to accelerate the research process. To harness the power of what we termed as the ChatGPT Chemistry Assistant (CCA), we provide a comprehensive guide on ChatGPT prompt engineering for chemistry-related tasks, making it accessible to researchers regardless of their familiarity with machine learning, thus bridging the gap between chemists and computer scientists. In this report, we present (1) A novel approach to using ChatGPT for text mining the synthesis conditions of metal-organic frameworks (MOFs), which can be easily</p>
<p>generalizable to other contexts requiring minimal coding knowledge and operating primarily on verbal instructions. (2) Assessment of ChatGPT's intelligence in literature text mining through accuracy evaluation and its ability for data refinement. (3) Utilization of the chemical synthesis reaction dataset obtained from text mining to train a model capable of predicting reaction results as crystalline powder or single crystals. Furthermore, we demonstrate that the CCA chatbot can be tuned to specialize in answering questions related to MOF synthesis based on literature conditions, with minimal hallucinations. This study underscores the transformative potential of ChatGPT and other LLMs in the realm of chemistry research, offering new avenues for collaboration and accelerating scientific discovery.</p>
<h1>MATERIALS AND METHODS</h1>
<p>Design Considerations for ChatGPT-Based Text Mining. In curating research papers for ChatGPT to read and extract information, it is imperative to account for the diversity in MOF synthesis conditions, such as variations in metal sources, linkers, solvents, and equipment, as well as the different writing styles employed. Notably, the absence of a standardized format for reporting MOF synthesis conditions leads to variable reporting templates by research groups and journals. Indeed, by incorporating a broad spectrum of narrative styles, we can examine ChatGPT's robustness in processing information from heterogeneous sources. On the other hand, it is essential to recognize that the challenge of establishing unambiguous criteria to identify MOF compounds in the literature may lead to the inadvertent inclusion of some non-MOF compounds reported in earlier publications that are non-porous inorganic complexes and amorphous coordination polymers (included in some MOF datasets). As such, maintaining a balance between quality and quantity is vital, and prioritizing the selection of high-quality and well-cited papers, rather than incorporating all associated papers indiscriminately can ensure that the text mining of MOF synthesis conditions yields reliable and accurate data.</p>
<p>Moreover, papers discussing post-synthetic modifications, catalytic reactions of MOFs, and MOF composites are not directly pertinent to our objective of identifying MOF synthesis conditions. Hence, such papers have been excluded. Another consideration is that MOFs can be synthesized as both microcrystalline powders and single crystals, both of which should be regarded as valid candidates for our dataset. Utilizing the above-mentioned selection criteria, we narrowed our selection to 228 papers from an extensive pool of MOF papers, retrieved from Web of Science, Cambridge Structure Database MOF subset, ${ }^{19}$ and the CoreMOF database. ${ }^{20,21}$ This sample represents a diverse range of MOF synthesis conditions and narrative styles.</p>
<p>To enable ChatGPT to process each paper, we devised three different approaches analogous to human paper reading: (1) locating potential sections containing synthesis conditions within the document, (2) confirming the presence of synthesis conditions in the identified sections, and (3) extracting synthesis parameters one by one. For our ChatGPT Chemistry Assistant, these steps are accomplished through filtering, classification, and summarization (Figure 1).</p>
<h2>ChemPrompt Engineering</h2>
<h2>Prompt:</h2>
<p>Answer the question as truthfully as possible using the provided context.
Please summarize the following details in a table: compound name or chemical formula (if the name is not provided), metal source, organic linker(s), solvent(s), reaction temperature, and reaction time. If any information is not provided or you are unsure, use "N/A". Please ignore information related to organic linker synthesis, MOF postsynthetic modification or metalation.</p>
<p>The table should have 6 columns, all in lowercase:| compound name | metal source | linker| solvent | reaction temperature | reaction time |
| :-- | :-- | :-- | :-- | :-- | :-- |</p>
<p>Input:
In a 100 mL media bottle were dissolved 1,3,5-benzenetricarboxylic acid (210 mg) and 2tOCl2-BH2O ( 970 mg ) in a solution containing DMF (30 $\mathrm{mL})$ and formic acid ( 30 mL ). The bottle was sealed and heated in a 100 ${ }^{\circ} \mathrm{C}$ isothermal oven for a day. White powder of MOF-808 was collected by centrifugation.</p>
<p>Output:
<img alt="img-2.jpeg" src="img-2.jpeg" />
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 2. Illustration of a carefully designed ChemPrompt (shown on the left), encapsulating all three fundamental principles of ChemPrompt Engineering (shown on the right). The prompt guides ChatGPT to systematically extract and summarize synthesis conditions from a specified section in a research article, organizing the data into a well-structured table.</p>
<p>In Process 1, we developed prompts to guide ChatGPT in summarizing text from designated experimental sections contained in those papers. To replace the need for human intervention to obtain synthesis sections, in Process 2, we designed a method for ChatGPT to categorize text inputs as either "experimental section" or "non-experimental section", enabling it to generate experimental sections for summarization. In Process 3, we further devised a technique to swiftly eliminate irrelevant paper sections, such as references, titles, and acknowledgments, which are unlikely to encompass comprehensive synthesis conditions. This accelerates processing speed for the later classification task. As such, in Process 1, ChatGPT is solely responsible for summarizing and tabulating synthesis conditions and requires one or more paragraphs of experimental text as input, while Process 2 and 3 can be considered as an "automated paper reading system". While Process 2 entails a thorough examination of the entire paper to scrutinize each section, the more efficient Process 3 rapidly scans the entire paper, removing the least relevant portions, thereby reducing the number of paragraphs that ChatGPT must meticulously analyze.</p>
<p>Prompt Engineering. In the realm of chemistry-related tasks, ChatGPT's performance can be significantly enhanced by employing prompt engineering (PE)—a meticulous approach to designing prompts that steer ChatGPT towards generating precise and pertinent information. We propose three fundamental principles in prompt engineering for chemistry-focused applications, denoted as ChemPrompt Engineering:
(1) Minimizing Hallucination, which entails the formulation of prompts to avoid eliciting fabricated or misleading content from ChatGPT. This is particularly important in the field of chemistry, where the accuracy of information can have significant implications on research outcomes and safety. For instance, when asked to provide synthesis conditions for MOFs without any additional prompt or context, ChatGPT may recognize that MOF-99999 does not exist but will generate fabricated conditions for existing compounds with names like MOF-41, MOF-419, and MOF-519. We should note that with additional prompts followed after the question, it is possible to minimize hallucination and enforce ChatGPT to answer the questions based on its knowledge (Table 1 and Table 2). Furthermore, we demonstrate that with well-designed prompts and context, hallucination occurrences can be minimized (Supporting Information, Section S2.1). We note that this should be the first and foremost principle to follow when designing prompts for ChatGPT to perform in handling text and questions relevant to chemical information.
(2) Implementing Detailed Instructions, whereby explicit directions are provided in the prompt to assist ChatGPT in understanding the context and desired response format. By incorporating detailed guidance and context into the prompts, we can facilitate a more focused and accurate response from ChatGPT. In chemistry-related tasks, this approach narrows down the</p>
<p>Table 1. Assessment of hallucination in ChatGPT response without prompt engineering.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Query</th>
<th style="text-align: left;">ChatGPT Response ${ }^{(a)}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Which metal is used in the synthesis of MOF-5?</td>
<td style="text-align: left;">Zinc (Correct)</td>
</tr>
<tr>
<td style="text-align: left;">Which metal is used in the synthesis of MOF-519?</td>
<td style="text-align: left;">Zirconium (Incorrect)</td>
</tr>
<tr>
<td style="text-align: left;">What is the linker used in the synthesis of MOF-99999?</td>
<td style="text-align: left;">I don't know (Correct)</td>
</tr>
<tr>
<td style="text-align: left;">What is the linker used in the synthesis of MOF-419?</td>
<td style="text-align: left;">Terephthalic acid (Incorrect)</td>
</tr>
<tr>
<td style="text-align: left;">What is the linker used in the synthesis of ZIF-8?</td>
<td style="text-align: left;">2-methylimidazole (Correct)</td>
</tr>
</tbody>
</table>
<p>Table 2. Improvements in ChatGPT response accuracy utilizing a basic prompt engineering strategy.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Initial Query</th>
<th style="text-align: center;">Guided Prompt</th>
<th style="text-align: center;">ChatGPT <br> Response ${ }^{(a)}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Which metal is used in the synthesis of MOF-5?</td>
<td style="text-align: center;">If you're uncertain, please reply with 'I do not know'.</td>
<td style="text-align: center;">Zinc <br> (Correct)</td>
</tr>
<tr>
<td style="text-align: center;">Which metal is used in the synthesis of MOF-519?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">I don't know <br> (Correct)</td>
</tr>
<tr>
<td style="text-align: center;">What is the linker used in the synthesis of MOF-99999?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">I don't know <br> (Correct)</td>
</tr>
<tr>
<td style="text-align: center;">What is the linker used in the synthesis of MOF-419?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">I don't know <br> (Correct)</td>
</tr>
<tr>
<td style="text-align: center;">What is the linker used in the synthesis of ZIF-8?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2-methylimidazole (Correct)</td>
</tr>
</tbody>
</table>
<p>a) Responses are representative answers selected from a series of 100 repeated queries, followed by parenthetical indications of their correctness, which is based on the established facts concerning the respective compounds referenced in the queries.</p>
<p>potential answer space and reduces the likelihood of irrelevant or ambiguous responses. For example, we can specify not to include any organic linker synthesis conditions and focus solely on MOF synthesis (Supporting Information, Figure S8). In this case, we found that ChatGPT can recognize the features of organic linker synthesis and differentiate them from MOF synthesis. With proper prompts, information from organic linker synthesis will not be included. Additionally, instructions can provide step-by-step guidance, which has proven effective when multiple tasks are included in one prompt (Supporting Information, Section S2.2).
(3) Requesting Structured Output, which includes the incorporation of an organized and well-defined response template or instruction to facilitate data extraction. We emphasize that this principle is particularly valuable in the context of chemistry, where data can often be complex and multifaceted. Structured output enables the efficient extraction and interpretation of critical information, which in turn can significantly contribute to the advancement of research and knowledge in the field. Take synthesis condition extraction as an example, without clear instructions on the formatted output, ChatGPT can generate a table, list-like bullet points, or a paragraph, with the order of parameters such as reaction temperature, reaction time, and solvent volume not being uniform, making it challenging for later sorting and storage of the data. This can be easily improved by explicitly asking it to generate a table and providing a fixed header to start with prompt (Supporting Information, Section S2.3). By incorporating these principles, the resulting prompt can ensure that ChatGPT yields accurate and reliable results, ultimately enhancing its utility in tackling complex chemistry-related tasks (Figure 2). We further employ the idea of interactive prompt refinement, in which we start with asking ChatGPT to write a prompt to instruct itself by giving it preliminary descriptions and information (Supporting Information, Figure S15). Through conversation, we add more specific details and considerations to the prompt, testing it with some texts, and once we obtain output, we provide feedback to ChatGPT and ask it to improve the quality of the prompt (Supporting Information, Section S2.4).</p>
<p>As there has been almost no literature systematically discussing prompt engineering in Chemistry, and the fact that this field is relatively new, we provide a comprehensive step-by-step ChemPrompt Engineering guide for beginners to start with, including numerous chemistry-related examples in the Supporting Information, Section S2. At present, everyone is at the same starting point, and no one possesses exclusive expertise in this area. It is our hope that this work will stimulate the development of more powerful prompt engineering skills and help every chemist quickly understand the art of ChemPrompt Engineering, thereby advancing the field of chemistry at large.</p>
<p>Process 1: Synthesis Conditions Summarization. One revolutionary aspect of ChatGPT is its specialized domain knowledge due to its extensive pre-trained text corpus, which enables an understanding of chemical nomenclature and reaction conditions. ${ }^{18}$ In contrast to traditional NLP methods, ChatGPT requires no additional training for named entity recognition, and can readily identify inorganic metal sources, organic linkers, solvents, and other compounds within a given experimental text. Another notable feature is ChatGPT's ability to recognize and associate compound abbreviations (e.g., DMF) with their full names ( $N, N$-dimethylformamide) within the context of MOF synthesis (Supporting Information, Figure S5). This capability is crucial as the use of different abbreviations for the same compound can inflate the number of "unique compounds" in the dataset post text mining, leading to redundancy without providing new information. This challenge is difficult to address using traditional NLP methods or packages, as no model can inherently discern that DMF and $N, N$-dimethylformamide are the same compound without a manually curated dictionary of chemical abbreviations. Although ChatGPT may not cover all abbreviations, its proficiency in identifying and associating the most common ones such as DEF, DI water, EtOH, and $\mathrm{CH}_{3} \mathrm{CN}$ with their full names enhances data consistency and reduces redundancy. This, in turn, facilitates data retrieval and analysis, ensuring that different names of the same compound are treated as a single entity with its unique chemical identity and information.</p>
<p>Our first goal is to develop a ChatGPT-based AI assistant that demonstrates high performance in converting a given experimental section paragraph into a table containing all synthesis parameters (Supporting Information, Figure S22). To design the prompt for this purpose, we incorporate the three principles discussed earlier into ChemPrompt Engineering (Figure 2). The rationale for using tabulation as the output for synthesis condition summarization is that the tabular format simplifies subsequent data sorting, analysis, and storage. In terms of the choice of 11 synthesis parameters, we include those deemed most important and non-negligible for each MOF synthesis. Specifically, these parameters encompass metal sources and quantities, dictating metal centers in the framework and their relative concentrations; the linker and its quantity, which affect connectivity and pore size within the MOF; the modulator and its quantity or volume, which can fine-tune the MOF's structure by impacting the nucleation and growth of the MOF in the reaction; the solvent and its volume, which can influence both the crystallization process and the final MOF structure; and the reaction temperature and duration, which are vital parameters governing the kinetics and thermodynamics of MOF formation in each synthesis. In our prompt, we also account for the fact that some papers may report multiple synthesis conditions for the same compound and instruct ChatGPT to use multiple rows to include each variation. For multiple units of the same synthesis parameters, such as when molarity mass and weight mass are both reported, we encourage ChatGPT to include them in the same cell, separated by a comma, which can be later streamlined depending on the needs. If any information is not provided in the sections, e.g., most MOF reactions may not involve the use of modulators and some papers may not specify the reaction time, we expect ChatGPT to answer "N/A" for that parameter. Importantly, to eliminate non-MOF synthesis conditions such as organic linker synthesis, post-synthetic modification, or catalysis reactions, which are not helpful for studying MOF synthesis reactions, we simply add one line of narrative instruction, asking ChatGPT to ignore these types of reactions and focus solely on MOF synthesis parameters. Notably, this natural</p>
<p>language-based instruction is highly convenient, requiring no complex and laborious rule-based code to identify unwanted cases and filter them out, and is friendly to researchers without coding experience.</p>
<p>The finalized prompts for Process 1 consist of three parts: (i) a request for ChatGPT to summarize and tabulate the reaction conditions, and only use the text or information provided by humans, which adheres to Principle 1 to minimize hallucination; (ii) a specification of the output table's structure, enumerating expectations and handling instructions, which follows Principles 2 and 3 for detailed instructions and structured output requests; and (iii) the context, consisting of MOF synthesis reaction condition paragraphs from experimental sections or supporting information in research articles. Note that parts (i) and (ii) are fixed prompts, while part (iii) is considered as "input." The combined prompt results in a single question-and-answer interaction, allowing ChatGPT to generate a summarization of the given synthesis conditions as output.</p>
<p>Process 2: Synthesis Paragraph Classification. The next question to be answered is, "if ChatGPT is given an entire research article, can it correctly locate the sections of experimental sections?" The objective of Process 2 is to accept an entire research paper as input and selectively forward paragraphs containing chemical experiment details to the next assistant for summarization. However, locating the experimental synthesis section within a research paper is a complex task, as simple techniques such as keyword searches often prove insufficient. For instance, the synthesis of MOFs may be embedded within the supporting information or combined with organic linker synthesis. In earlier publications, synthesis information might appear as a footnote. Furthermore, different journals or research groups utilize varying section titles, including "Experimental," "Methods," "General Methods and Materials," "Experimental methods," "Synthesis and Characterization," "Synthetic Procedures," "Methods Summary," and more. Manually enumerating each case is labor-intensive, especially when synthesis paragraphs may be dispersed with non-MOF synthesis, characterization conditions, or instrument details. Even a human might take considerable time to identify the correct section.</p>
<p>To address this challenge and enable ChatGPT to accurately discern synthesis details within a lengthy research paper, we draw inspiration from the human process. A chemistry Ph.D. student, when asked to locate the MOF synthesis section in a new research paper, would typically start with the first paragraph and ask themselves if it contains synthesis parameters. They would then draw upon prior knowledge from previously read papers to determine if the section is experimental. This process is repeated paragraph by paragraph until the end of the supporting information is reached, with no guarantee that additional synthesis details will not be encountered later. To train ChatGPT similarly, we prompt it to read paper sections incrementally, focusing on one or two paragraphs at a time. Using a few-shot prompt strategy, we provided ChatGPT with a couple of example cases of both synthesis and non-synthesis paragraphs and asked it to classify the sections it reads as either "Yes" (synthesis paragraph) or "No" (non-synthesis paragraph). The ChatGPT Chemistry Assistant would then continue processing the research paper section by section, passing only the paragraphs labeled as "Yes" to the following assistant for summarization.</p>
<p>This few-shot prompt strategy is more convenient than traditional approaches, which require researchers to manually identify and label a large number of paragraphs as "Synthesis Paragraphs" and train their models accordingly. In fact, ChatGPT can even perform such classification using a zero-shot prompt strategy with detailed descriptions of what a "Synthesis Paragraph" should look like and contain. However, we have found that providing four or five short examples in a few-shot prompt strategy enables ChatGPT to identify the features of synthesis paragraphs more effectively, streamlining the classification process (Supporting Information, Figure S24).</p>
<p>The finalized prompt for Process 2 comprises three parts: (i) a request for ChatGPT to determine whether the provided context includes a comprehensive MOF synthesis, answering only with "Yes" or "No"; (ii) some example contexts labeled as "Yes" and other labeled as "No"; (iii) the context to be classified, consisting of one or more research article paragraphs. Similar to Process 1's prompt, parts (i) and (ii) are fixed, while part (iii) is replaced with independent sections from the paper to be classified. The entire research article is parsed into sections of 100-500 words, which are iteratively incorporated into the prompt and sent separately to ChatGPT for a "Yes" or "No" response. Each prompt represents a one-time conversation, and ChatGPT cannot view answers from previous prompts, preventing potential bias in its decision-making for the current prompt.</p>
<p>Process 3: Text Embeddings for Search and Filtering. Text embeddings are high-dimensional vector representations of text that capture semantic information, enabling quantification of the relatedness of textual content. ${ }^{22,23}$ The distance between these vectors in the embedded space correlates with the semantic similarity between corresponding text strings, with smaller distances indicating greater relatedness. ${ }^{24,25}$ While Process 2 can automatically read and summarize papers, it must evaluate every section to identify synthesis paragraphs. To expedite this process, we developed Process 3, which filters sections least likely to contain synthesis parameters using OpenAI embeddings before exposing the article to classification assistant in Process 2. To achieve this, we employed a two-step approach to construct Process 3: first, parsing all papers and converting each segment into embeddings; and second, calculating and ranking the similarity scores of each segment based on their relevance to a predefined prompt encapsulating synthesis parameter.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 3. Two-dimensional visualization of 18,248 text segment embeddings, with each point representing a text segment from the research articles selected. Color coding denotes thematic categories: red for "synthesis", green for "gas sorption", yellow for "literature reference", blue for "crystallographic data", purple for "structural analysis", orange for "characterization", and grey for other text segments not emphasized in this study.</p>
<p>In particular, we partitioned the 228 research articles into 18,248 individual text segments (Supporting Information, Figure S30-S32). Each segment was converted into a 1536-dimensional text embedding using OpenAI's text-embedding-ada-002, a simple but efficient model for this process (Supporting Information, Figure S33-S35). These vectors were stored for future use. To identify segments
most and least likely to contain synthesis parameters, we employed interactive prompt refinement strategy (Supporting Information, Section S2.4), consulting with ChatGPT to optimize the prompt. The prompt used in Process 3, unlike previous prompts, served as a text segment for search and similarity comparison rather than instructing ChatGPT (Supporting Information, Figure S25). Next, the embeddings of all 18,248 text segments were compared with the prompt's embedding, and a relevance score was assigned to each segment based on the cosine similarity between the two embeddings. Highly relevant segments were passed on to classification assistant for further processing, while low similarity segments were filtered out (Figure 1).</p>
<p>To evaluate the effectiveness of this approach, we conducted a visual exploration of our embedding data (Figure 3). By reducing the vectors' dimensionality, we observed distinct clusters corresponding to different topics. Notably, we identified distinct clusters related to topics like "gas sorption", "literature reference", "characterization", "structural analysis" and "crystallographic data", which were separate from the "synthesis" cluster. This observation strongly supports the efficiency of our embedding-based filtering strategy. However, this strategy, while effective at filtering out less relevant text and passing segments of mid to high relevance to the subsequent classification assistant, cannot directly search for synthesis paragraphs to feed to the summarization assistant, thus bypassing the classification assistant. In other words, the searching-to-classifying-to-summarizing pipeline cannot be simplified to a searching-to-summarizing pathway due to the inherent search limitations of the embeddings. As shown in Figure 3, embeddings alone may not accurately identify all relevant "synthesis" sections, particularly when they contain additional information such as characterization and sorption data. The presence of these elements in a synthesis section can reduce its similarity score and its proximity to the center of the "synthesis" cluster. Points between the "synthesis" and "characterization" or "crystallographic data" clusters may not have the highest similarity scores and could be missed. However, by filtering only the lowest scores, mid-relevance points are retained and passed to the classification assistant, which can more accurately classify ambiguous content.</p>
<p>ChatGPT-Assisted Python Code Generation and Data Processing. Rather than relying on singular, time-consuming conversations with web-based ChatGPT to process textual data from a multitude of research articles, OpenAI's GPT-3.5-turbo, which is identical to the one underpinning the ChatGPT product, facilitates a more efficient approach, as it incorporates an Application Programming Interface (API), enabling batch processing of text from an extensive array of articles. This is achieved through iterative context and prompt submissions to ChatGPT, followed by the collection of its responses (Supporting Information, Section S3.4).</p>
<p>Specifically, our approach involves having ChatGPT to create Python scripts for parsing academic papers, generating prompts, executing text processing through Processes 1, 2, and 3, and collating the responses into cleaned, tabulated data (Supporting Information, Figures S28-S39). Traditionally, such a process could necessitate substantial coding experience and be time-consuming. However, we leverage the code generation capabilities of ChatGPT to establish Processes 1, 2, and 3 for batch processing using OpenAI's APIs, namely, gpt-3.5-turbo and text-embedding-ada-002. In essence, researchers only need to express their requirements for each model in natural language - specifying inputs and desired outputs - and ChatGPT will generate the appropriate Python code (Supporting Information, Section S3.5). This code can be copied, pasted, and executed in the relevant environment. Notably, even in the event of an error, ChatGPT, especially when equipped with the GPT-4 model, can assist in code revision. We note that while coding assistance from ChatGPT may not be necessary for those with coding experience, it does provide an accessible platform for individuals lacking such experience to engage in the process. Given the simplicity and straightforwardness of the logic involved in Processes 1, 2, and 3, ChatGPT-generated Python code exhibits minimal errors and significantly accelerates the programming process.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 4. Schematic representation of the diverse data unification tasks managed either directly by ChatGPT or through Python code written by ChatGPT. The figure distinguishes between simpler tasks handled directly by ChatGPT, such as standardizing chemical notation, and converting time and temperature units in reactions. More complex tasks, such as matching linker abbreviations to their full names, converting these to SMILES codes, classifying product morphology, and calculating metal amounts, are accomplished via Python code generated by ChatGPT. The Python logo displayed is credited to PSF.</p>
<p>ChatGPT also aids in entity resolution post text mining (Figure 4). This step involves standardizing data formats including units, notation, and compound representations. For each task, we designed a specific prompt for ChatGPT to handle data directly or a specialized Python code generated by ChatGPT. More details on designing prompts to handle different synthesis parameters are available in a cookbook style in Supporting Information, Section S4. In simpler cases, ChatGPT can directly handle conversions such as time and reaction temperature. For complex calculations, we take advantage of ChatGPT in generating Python code. For instance, to calculate the molar mass of each metal source, ChatGPT can generate the appropriate Python code based on the given compound formulas. For harmonizing notation of compound pairs or mixtures, ChatGPT can standardize different notations to a unified format, facilitating subsequent data processing.</p>
<p>To standardize compound representations, we employ the Simplified Molecular Input Line Entry System (SMILES). We faced challenges with some synthesis procedures, where only abbreviations were provided. To overcome this, we designed prompts for ChatGPT to search for the full names of given abbreviations. We then created a dictionary linking each unique PubChem Compound identification number (CID) or Chemical Abstracts Service (CAS) number to multiple full names and abbreviations and generated the corresponding SMILES code. We note that for complicated linkers or those with missing full</p>
<p>names, inappropriate nomenclature or non-existent CID or CAS numbers, ${ }^{26-33}$ manual intervention was occasionally necessary to generate SMILES codes for such chemicals (Supporting Information, Figure S50-S54). However, most straightforward cases were handled efficiently by ChatGPT's generated Python code. As a result, we achieved uniformly formatted data, ready for subsequent evaluation and utilization.</p>
<h1>RESULTS AND DISCUSSION</h1>
<p>Evaluation of Text Mining Performance. We began our performance analysis by first evaluating the execution time consumption for each process (Figure 5a). As previously outlined, the ChatGPT assistant in Process 1 exclusively accepts preselected experimental sections for summarization. Consequently, Process 1 requires human intervention for the identification and extraction of the synthesis section from a paper to operate autonomously. As illustrated in Figure 5a, this process can vary in duration based on the length and structure of the document and its supporting information file. In our study, the complete selection procedure spanned 12 hours for 228 papers, averaging around 2.5 minutes per paper. This period must be considered as the requisite time for Process 1's execution. For summarization tasks, ChatGPT Chemistry Assistant demonstrated an impressive performance, taking an average of 13 seconds per paper. This is noteworthy considering that certain papers in the dataset contained more than 20 MOF compounds, and human summarization in the traditional way without AI might consume a significantly larger duration. By accelerating the summarization process, we alleviate the burden of repetitive work and free up valuable time for researchers.</p>
<p>In contrast, Process 2 operates in a fully automated manner, integrating the classification and result-passing processes to the next assistant for summarization. There is no doubt that it outperforms the manual identification and summarization combination of Process 1 in terms of speed due to ChatGPT's superior text processing capabilities. Lastly, Process 3, as anticipated, is the fastest due to the incorporation of section filtering powered by embedding, reducing the classification tasks, and subsequently enhancing the speed. The efficiency of Process 3 can be further optimized by storing the embeddings locally as a CSV file during the first reading of a paper, which reduces the processing time by 15-20 seconds ( $28 \%-37 \%$ faster) in subsequent readings. This provides a convenient solution in scenarios necessitating repeated readings for comparison or extraction of diverse information.</p>
<p>To evaluate the accuracy of the three processes in text mining, instead of sampling, we conducted a comprehensive analysis of the entire result dataset. In particular, we manually wrote down the ground truth for all 11 parameters for approximately 800 compounds reported in all papers across the three processes, which was used to judge the text mining output. This involved the grading of nearly 26,000 synthesis parameters by us. Each synthesis parameter was assigned one of three labels: True Positive (TP, correct identification of synthesis parameters by ChatGPT), False Positive (FP, incorrect assignment of a compound to the wrong synthesis parameter or extraction of irrelevant information), and False Negative (FN, failure of ChatGPT to extract some synthesis parameters). Notably, a special rule for assigning labels on modulators, most of which were anticipated to be acid and base, was introduced to accommodate the neutral solvents in a mixed solvent system, due to the inherent challenges in distinguishing between co-solvents and modulators. For instance, in a DMF: $\mathrm{H}<em 2="2">{2} \mathrm{O}=10: 1$ solution, the role of $\mathrm{H}</em>$ was considered either as a solvent or modulator. However, we labeled it as FP or FN if it appeared or was absent in both solvent and modulator columns. Nevertheless, acids and bases were still classified as modulators, and if labeled as solvents, they were graded as FP.} \mathrm{O}$ becomes ambiguous. In such situations, we labeled the result as a TP if $\mathrm{H}_{2} \mathrm{O</p>
<p>The distribution of TP labels counted for each of the 11 synthesis parameters across all papers is presented in Figure 5b. It should be noted that not all MOF synthesis conditions necessitate reporting of all 11 parameters; for instance, some syntheses do not involve modulators, and in such cases, we asked ChatGPT to assign an "N/A" to the corresponding column and its amount. Subsequently, we computed the precision, recall, and F1 scores for each parameter across all three processes, illustrated in Figure 5c and d. All processes demonstrated commendable performance in identifying compound names, metal source names, linker names, modulator names, and solvent names. However, they encountered difficulties in accurately determining the quantities or volumes of the chemicals involved. Meanwhile, parameters like reaction temperature and reaction time, which usually have fixed patterns (e.g., units such as ${ }^{\circ} \mathrm{C}$, hours), were accurately identified by all processes, resulting in high recall, precision, and F1 scores. The lowest scores were associated with the recall of solvent volumes. This is because ChatGPT often captured only one volume in mixed solvent systems instead of multiple volumes. Moreover, in some literatures, the stock solution was used for dissolving metals and linkers, and in principle these volumes should be added to the total volume and unfortunately, ChatGPT lacked the ability to report the volume for each portion in these cases.</p>
<p>Nevertheless, it should be noted that our instructions did not intend for ChatGPT to perform arithmetic operations in these cases, as the mathematical reasoning of the large languages models is limited, and the diminishment of the recall scores is unavoidable. In other instances, only one exemplary synthesis condition for MOF was reported, and then for similar MOFs, the paper would only state "following similar procedures". In such cases, while occasionally ChatGPT could duplicate conditions, most of the time it recognized solvents, reaction temperature, and reaction time as "N/A", which was graded as a FN, thus reducing the recall scores across all processes.</p>
<p>Despite these irregularities, which were primarily attributable to informal synthesis reporting styles, the precision, recall, and F1 scores for all three processes remained impressively high, with less than $9.8 \%$ of NP and 0 cases of hallucination detected by human evaluators. We further calculated the average and standard deviation of each process on precision, recall,</p>
<p>and F1 scores, respectively, as shown in Figure 5c. By considering and averaging precision, recall, and F1 scores across the 11 parameters, given their equal importance in evaluating overall performance of the process, we found that all three processes achieved impressive precision ( $&gt;95 \%$ ), recall ( $&gt;90 \%$ ), and F1 scores ( $&gt;92 \%$ ).
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 5. Multifaceted performance analysis of ChatGPT-based text mining processes. (a) Comparison of the average execution time required by each process to read and process a single paper, highlighting their relative efficiency. (b) Distribution of true positive counts for each of the 11 synthesis parameters, derived from the cumulative results of Processes 1, 2, and 3 based on a total of 2387 synthesis conditions. Despite minor discrepancies, the counts are closely aligned, demonstrating the assistants' proficiency in effectively extracting the selected parameters. (c) Aggregate average precision, recall, and F1 scores for each process, indicating their overall accuracy and reliability. Standard deviations are represented by grey error bars in the chart. (d) Heatmap illustrating the detailed percentage precision, recall, and F1 scores for each synthesis parameter across the three processes, providing a nuanced understanding of the ChatGPT-based assistants' performance in accurately identifying specific synthesis parameters.</p>
<p>The performance metrics of Process 1 substantiated our hypothesis that ChatGPT excels in summarization tasks. Upon comparing the performance of Processes 2 and 3 - both of which are fully automated paper-reading systems capable of generating datasets from PDFs with a single click - we observed that Process 2, by meticulously examining every paragraph across all papers, ensures high precision and recall by circumventing the omission of any synthesis paragraphs or extraction of incorrect data from irrelevant sections. Conversely, while Process 3's accuracy is marginally lower than that of Process 2, it provides a significant reduction in processing time, thus enabling faster paper reading while maintaining acceptable accuracy, courtesy of its useful filtration process.</p>
<p>To the best of our knowledge, these scores surpass most of other models in text mining in the MOF-related domain. ${ }^{11,13,14,}$ ${ }^{34,35}$ Notably, the entire workflow, established via code and programs generated from ChatGPT, can be assembled by one or two researchers with only basic coding proficiency in a period as brief as a week, whilst maintaining remarkable performance. The successful establishment of this innovative ChatGPT Chemistry Assistant workflow including the ChemPrompt</p>
<p>Engineering system, which harnesses AI for processing chemistry-related tasks, promises to significantly streamline scientific research. It liberates researchers from routine laborious work, enabling them to concentrate on more focused and innovative tasks. Consequently, we anticipate that this approach will catalyze potentially revolutionary shifts in research practices through the integration of AI-powered tools.</p>
<p>Prediction Modeling of MOF Synthesis Outcomes. Given the large quantity of synthesis conditions obtained through our ChatGPT-based text mining programs, our aim is to utilize this data to investigate, comprehend, and predict the crystallization conditions of a material of interest. Specifically, our goal was to determine the crystalline state based on synthesis conditions - we seek to discern which synthesis conditions will yield MOFs in the form of single crystals, and which conditions are likely to yield non-single crystal forms of MOFs, such as microcrystalline powder or solids.</p>
<p>With this objective in mind, we identified the need for a label signifying the crystalline state of the resulting MOF for each synthesis condition, thereby forming a target variable for prediction. Fortunately, nearly all research papers in the MOF field consistently include the description of crystal morphological characteristics such as the color and shape of as-synthesized MOFs (e.g. yellow needle crystals, red solid, sky-blue powdered product). This facilitated in re-running our processes with the same synthesis paragraphs as input and modifying the prompt to instruct ChatGPT to extract the description of reaction products, summarizing and categorizing them (Supporting Information, Figure S23 and Figure S47). The final label for each condition will either be Single-Crystal (SC) or Polycrystalline (P), and our objective is to construct a machine learning model capable of accurately predicting whether a given condition will yield SC or P. Furthermore, we recognized that the crystallization process is intrinsically linked with the synthesis method (e.g., vapor diffusion, solvothermal, conventional, microwaveassisted method). Thus, we incorporated an additional synthesis variable, "Synthesis Method", to categorize each synthesis condition into four distinct groups. Extracting the reaction type variable for each synthesis condition can be achieved using the same input but a different few-shot prompt to guide our ChatGPT-based assistants for classification and summarization, subsequently merging this data with the existing dataset. This process parallels the method for obtaining MOF crystalline state outcomes, and both processes can be unified in a single prompt. Moreover, as the name of the MOF is a user-defined term and does not influence the synthesis result, we have excluded this variable for the purposes of prediction modeling.</p>
<p>After unifying and organizing the data to incorporate 11 synthesis parameter variables and 1 synthesis outcome target variable, we designed respective descriptors for each synthesis parameter capable of robustly representing the diversity and complexity in the synthesis conditions and facilitating the transformation of these variables into features suitable for machine learning algorithms. A total of six sets of chemical descriptors were formulated for the metal node(s), linker(s), modulator(s), solvent(s), their respective molar ratios, and the reaction condition(s) - aligning with the extracted synthesis parameters (Supporting Information, Section S5). ${ }^{36-40}$ These MOF-tailored, hierarchical descriptors have been previously shown to perform well in various prediction tasks. ${ }^{13,41}$ To distill the most pertinent features and streamline the model, a recursive feature elimination (REF) with 5-fold cross-validation was performed on $80 \%$ of the total data. The rest was preserved as a held out set unseen during the learning process for independent evaluation (Figure 6a). This down-selection process reduced the number of descriptors from 70 to 33, thereby preserving comparative model performance on the held out set while removing the non-informative features that can lead to overfitting (Supporting Information Section S5).</p>
<p>Subsequently, we constructed a machine learning model to train for synthesis conditions to predict if a given synthesis condition can yield single crystals. A binary classifier was trained based on a random forest model (Supporting Information, Section S5). The random forest (RF) is an ensemble of decision trees, whose independent predictions are max voted in the classification case to arrive at the more precise prediction. ${ }^{42}$ In our study, we trained an RF classifier to predict crystalline states from synthesis parameters, given its ability to work with both continuous and categorical data, its advantage in ranking important features towards prediction, its robustness against noisy data, ${ }^{43}$ and its demonstrated efficacy in various chemistry applications such as chemical property estimation, ${ }^{44-47}$ spectroscopic analysis, ${ }^{48-51}$ and material characterization and discovery. ${ }^{52}$</p>
<p>The dimension-reduced data was randomly divided into different training sizes; for each train test split, optimal hyperparameters, in particular, number of tree estimators and minimum samples required for leaf split, were determined with 5-fold cross validation of the training set. Model performance was gauged in terms of class weighted accuracy, precision, recall, and F1 score over 10 runs on the held out set and test set (Figure 6b and Supporting Information, Figure S64). The model converged to an average accuracy of $87 \%$ and an F1 score of $92 \%$ on the held out set, indicating a reasonable performance in the presence of the imbalanced classification challenge.</p>
<p>Following the creation of the predictive model, our objective was to apply this model for descriptor analysis to illuminate the factors impacting MOF crystalline outcomes. This aids in discerning which features in the synthesis protocol are more crucial in determining whether a synthesis condition will yield MOF single crystals. Although the random forest model is not inherently interpretable, we probed the relative importance of descriptors used in building the model. One potential measure of a descriptor's importance is the percent decrease in the model's accuracy score when values for that descriptor are randomly shuffled and the model is retrained. We found that among the descriptors involved, the top ten most influential descriptors are key in predicting MOF crystallization outcomes (Figure 6c). In fact, these descriptors broadly align with the chemical intuition and our understanding on MOF crystal growth. ${ }^{53,54}$ For example, the descriptors related to stoichiometry of the MOF synthesis, namely the "modulator to metal ratio", "solvent to metal ratio", and "linker to metal ratio", take</p>
<p>precedence in the ranking. These descriptors reflect the vital role of precise stoichiometric control in MOF crystal formation, and they directly impact the crystallization process, playing critical roles in determining the quality and morphology of the MOF crystals.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 6. Performance of the classification models in predicting the crystalline state of MOFs from synthesis. (a) Learning curves of the classifier model with $1 \sigma$ standard deviation error bars. (b) Model performance evaluation through the F1 Score, Precision, Recall, and Area Under the Curve metrics. The training set fraction was in ratio to the data excluding the held out set. (c) The ten most significant descriptors of the trained random forest model, determined by accuracy score increase. (d) Six examples of MOFs, MOF520, MOF-74, ZIF-8, Al-fum, CAU-32, and MOF-808, along with their synthesis conditions derived from the literature. ${ }^{55-60}$ Circle positions on the bar represent the likelihood of resulting in single-crystal or polycrystalline states predicted by the model. The model's predictions for these six examples aligned with actual experimental results.</p>
<p>Following closely is the descriptor "time", and it highlights the significant role of reaction duration in the crystallization process. Additionally, the "metal valence" descriptor emphasizes the key role of the nature and reactivity of the metal ions used in MOF synthesis. The valence directly influences the secondary building units (SBUs) and the final crystalline state of the MOF. In the meantime, descriptors related to the molecular and the linker can impact the kinetics of the synthesis, influencing the orderliness of crystal growth. Together, this result provides a greater understanding of the crucial factors affecting</p>
<p>the crystallization of MOFs and will aid in the design and optimization of synthesis conditions for the targeted preparation of single-crystal or polycrystalline MOFs (Figure 6d).</p>
<p>Interrogating the Synthesis Dataset via a Chatbot. Having utilized text mining techniques to construct a comprehensive MOF Synthesis Dataset, our aim was to leverage this resource to its fullest potential. To enhance data accessibility and aid in the interpretation of its intricate contents, we embarked on a journey to convert this dataset into an interactive and userfriendly dialogue system, which effectively converts the dataset to dialogue. The resulting chatbot is part of the umbrella concept of ChatGPT Chemistry Assistant thus serving as a reliable and fact-based assistant in chemistry, proficient in addressing a broad spectrum of queries pertaining to chemical reactions, in particular MOF synthesis. Unlike typical and more general web-based ChatGPT provided by OpenAI, which may suffer from limitations such as the inability to access the most recent data and a propensity for hallucinatory errors. This chatbot is grounded firmly in the factual data contained within the MOF synthesis dataset from text mining and is engineered to ensure that responses during conversations are based on accurate information and synthesis conditions derived from text mining the literature (Supporting Information, Section S6).</p>
<p>In particular, to construct the chemistry chatbot, our initial step was the creation of distinct entries corresponding to each MOF we identified from the text mining, which encompasses a comprehensive array of synthesis parameters, such as the reaction time, temperature, metal, and linker, among others, using the dataset we have. Recognizing the value of bibliographic context, we compiled a list of paper information, such as authors, DOI, and publication years, collated from Web of Science, into each section (Supporting Information, Table S3). Subsequently, we generated embeddings for each of these information cards of different compounds, thereby constructing an embedding dataset (Figure 7). When a user asks a question, if it is the first query, the system first navigates to the embedding dataset to locate the most relevant information card using the question's embedding, which is based on a similarity score calculation and is similar to the foundation of Process 3 in text mining. The information of the highest-ranking entry is then dispatched to the prompt engineering module of MOF chatbot, guiding it to construct responses centered solely around the given synthesis information.</p>
<p>To mitigate the possibility of hallucination, the chatbot is programmed to refrain from addressing queries that fall outside the scope of the dataset. Instead, it encourages the user to rephrase the question (Supporting Information, Figure S69). It's worth noting that, following the initial query, the chatbot 'memorizes' the conversation context by being presented with the context of prior interactions between user and itself. This includes the synthesis context and paper information identified from the initial query, ensuring that the answers to subsequent queries are also based on factual information from the dataset. Consequently, this strategy guarantees that responses to ensuing queries are contextually accurate, being grounded in the facts outlined in the synthesis dataset and corresponding paper information (Figure 7 and Supporting Information, Figures S71-S74).</p>
<p>By virtue of its design, the chatbot addresses the challenge of enhancing data accessibility and interpretation. It accomplishes this by delivering synthesis parameters and procedures in a clear and comprehensible manner. Furthermore, it ensures data integrity and traceability by providing DOI links to the original papers, guiding users directly to the source of information. This functionality proves particularly beneficial for newcomers to the field. By leveraging ChatGPT's general knowledge base, they can receive guided instructions through the synthesis process, even when faced with a procedure in a journal that is ambiguously or vaguely described. In this case, the user can consult ChatGPT to "chat with the paper" for a more precise explanation, thereby simplifying the learning process and facilitating a more efficient understanding of complex synthesis procedures. This capability fosters independent learning and expedites comprehension of intricate synthesis procedures, reinforcing ChatGPT's role as a valuable assistant in the field of chemistry research.</p>
<p>Exploring Adaptability and Versatility in Large Language Models. The adaptability of LLM-based programs, a hallmark feature distinguishing them from traditional NLP programs, lies in their inherent ability to modify search targets or tasks simply by adjusting the input prompt. Whereas traditional NLP models may necessitate a complete overhaul of rules and coding in the event of task modifications, programs powered by ChatGPT and some other LLMs utilize a more intuitive approach. A simple change in narrative language within the prompt can adequately steer the model towards the intended task, obviating the need for elaborate code adjustments.
However, we do recognize limitations within the current workflow, particularly concerning token limitations. Research articles for text mining were parsed into short snippets due to 4096 token limit from GPT-3.5-turbo, since longer research articles can extend to $20,000-40,000$ tokens. This fragmentation may inadvertently result in the undesirable segmentation of synthesis paragraphs or other sections containing pertinent information. To alleviate this, we envision that a large language model that can process higher token memory ${ }^{61,62}$ such as GPT-4-32K (OpenAI), or Claude-v1 (Anthropic) will be very helpful, since each time it reads the entire paper rather than just sections, which can further increase its accuracy by avoiding undesirable segmentation of the synthesis paragraph or other targeted paragraph containing information. Longer reading capabilities will also have the added benefit of reducing the number of tokens used in repeated questions, thus enhancing processing times. As we continue to refine our workflow, we believe that there are further opportunities for improvement. For instance, parts of the fixed prompt could be more concise to save tokens, and the examples in the few-shot prompt can be further optimized to reduce total tokens. Given that each paper may have around 100 segments, such refinements could dramatically reduce time and costs, particularly for classification and summarization tasks, which must process every section with the same fixed prompt, especially for few-shot instructions.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 7. Integrated workflow of the MOF chatbot transforming comprehensive synthesis datasets into contextually accurate dialogue systems and demonstration of conversation with the data-driven chatbot. The process ensures enhanced data accessibility, interpretation, and facilitates independent learning in the field of chemistry research.</p>
<p>Furthermore, language versatility, a crucial aspect in the realm of text mining, is seamlessly addressed by LLMs. Traditional NLP models, trained in a specific language, often struggle when the task requires processing text data in another language. For example, if the model is trained on English data, it may require substantial adjustments or even a complete rewrite to process text data in Arabic, Chinese, French, German, French, Japanese, Korean and some other languages. However, with LLMs that can handle multiple languages, such as ChatGPT, we showed that researchers just need to slightly alter the instructions or prompts to achieve the goal, without the necessity of substantial code modifications (Supporting Information, Figure S55-S58).</p>
<p>The adaptable nature of LLMs can further extend versatility in handling diverse tasks. We demonstrated how prompts can be changed to direct ChatGPT to parse and summarize different types of information from the same pool of research articles. For instance, with minor modification of the prompts, we show that our ChatGPT Chemistry Assistants have the potential to be instructed to summarize diverse information such as thermal stability, BET surface area, $\mathrm{CO}_{2}$ uptake, crystal parameters, water stability, and even MOF structure or topology (Supporting Information, Section S4). This adaptability was previously a labor-intensive process, requiring experienced specialists to manually collect or establish training sets for text mining each type of information. ${ }^{11,13,35,41,63-66}$</p>
<p>Moreover, the utility of this approach can benefit the broader chemistry domain: it is capable of not only facilitating data mining in research papers addressing MOF synthesis but also extending to all chemistry papers with the accorded modifications. By fine-tuning the prompt, the ChatGPT Chemistry Assistant can effectively extract and tabulate data from diverse fields such as organic synthesis, biochemistry preparations, perovskite preparations, polymer synthesis, and more. This capability underscores the versatility of the ChatGPT-based assistant, not only in terms of subject matter but also in the level of detail it can handle. In the event that key parameters for data extraction are not explicitly defined, ChatGPT can be prompted to suggest parameters based on its trained understanding of the text. This level of adaptability and interactivity is unparalleled in traditional NLP models, highlighting a key advantage of the ChatGPT approach. The shift from a code-intensive approach to a natural language instruction approach democratizes the process of data mining, making it accessible even to those with less coding expertise, makes it an innovative and powerful solution for diverse data mining challenges.</p>
<h1>CONCLUDING REMARKS</h1>
<p>Our research has successfully demonstrated the potential of LLMs, particularly GPT models, in the domain of chemistry research. We presented a ChatGPT Chemistry Assistant, which includes three different but connected approaches to text mining with ChemPrompt Engineering: Process 3 is capable of conducting search and filtration, Processes 2 and 3 both classify synthesis paragraphs, and Processes 1, 2 and 3 are capable of summarizing synthesis conditions into structured datasets. Enhanced by three fundamental principles of prompt engineering specific to chemistry text processing, coupled with the interactive prompt refinement strategy, the ChatGPT-based assistant have substantially advanced the extraction and analysis of MOF synthesis literature, with precision, recall, and F1 scores exceeding $90 \%$.</p>
<p>We elucidated two crucial insights from the dataset of synthesis conditions. First, the data can be employed to construct predictive models for reaction outcomes, which shed light into the key experimental factors that influence the MOF crystallization process. Second, it is possible to create a MOF chatbot that can provide accurate answers based on text mining, thereby improving access to the synthesis dataset, and achieving a data-to-dialogue transition. This investigation illustrates the potential for rapid advancement inherent to ChatGPT and other LLMs as a proof-of-concept.</p>
<p>On a fundamental level, this study provides guidance on interacting with LLMs to serve as AI assistants for chemists, accelerating research with minimal prerequisite coding expertise and thus bridging the gap between chemistry and the realms of computational and data science more effectively. Through interaction and chatting, the code and design of experiments can be modified, democratizing data mining and enhancing the landscape of scientific research. Our work sets a foundation for further exploration and application of LLMs across various scientific domains, paving the way for a new era of AI-assisted chemistry research.</p>
<h2>ASSOCIATED CONTENT</h2>
<p>Supporting Information. Detailed instructions and design principles for ChemPrompt Engineering, as well as the specifics of the prompts employed in the ChatGPT Chemistry Assistant for text mining and other chemistry-related tasks. Additional information on the ChatGPT-assisted coding and data processing methods. An extensive explanation of the machine learning models and methods used, as well as the steps involved in setting up the MOF chatbot based on the MOF synthesis condition dataset. This material is available free of charge via the Internet at http://pubs.acs.org.</p>
<h2>AUTHOR INFORMATION</h2>
<h2>Corresponding Author</h2>
<p>Omar M. Yaghi - Department of Chemistry; Kavli Energy Nanoscience Institute; and Bakar Institute of Digital Materials for the Planet, College of Computing, Data Science, and Society, University of California, Berkeley, California 94720, United States; UC Berkeley-KACST Joint Center of Excellence for Nanomaterials for Clean Energy Applications, King Abdulaziz City for Science and Technology, Riyadh 11442, Saudi Arabia; orcid.org/0000-0002-5611-3325; Email: yaghi@berkeley.edu</p>
<h1>Other Authors</h1>
<p>Zhiling Zheng - Department of Chemistry; Kavli Energy Nanoscience Institute; and Bakar Institute of Digital Materials for the Planet, College of Computing, Data Science, and Society, University of California, Berkeley, California 94720, United States; orcid.org/0000-0001-6090-2258</p>
<p>Oufan Zhang - Department of Chemistry, University of California, Berkeley, California 94720, United States
Christian Borgs - Bakar Institute of Digital Materials for the Planet, College of Computing, Data Science, and Society; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, California 94720, United States; orcid.org/0000-0001-5653-0498</p>
<p>Jennifer T. Chayes - Bakar Institute of Digital Materials for the Planet, College of Computing, Data Science, and Society; Department of Electrical Engineering and Computer Sciences; Department of Mathematics; Department of Statistics; and School of Information, University of California, Berkeley, California 94720, United States; orcid.org/0000-0003-4020-8618</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>Z.Z. extends special gratitude to Jiayi Weng (OpenAI) for valuable discussions on harnessing the potential of ChatGPT. In addition, Z.Z. acknowledges the inspiring guidance and input from Kefan Dong (Stanford University), Long Lian (University of California, Berkeley), and Yifan Deng (Carnegie Mellon University), all of whom contributed to shaping the study's design and enhancing the performance of ChatGPT. We express our appreciation to Dr. Nakul Rampal from the Yaghi Lab for insightful discussions. Our gratitude is also extended for the financial support received from the Defense Advanced Research Projects Agency (DARPA) under contract HR0011-21-C-0020. O.Z. acknowledges funding and extends thanks for the support provided by the National Institute of Health (NIH) under Grant 5R01GM127627-04. Additionally, Z.Z. thanks for the financial support received through a Kavli ENSI Graduate Student Fellowship and the Bakar Institute of Digital Materials for the Planet (BIDMaP). his work is independently developed by the University of California, Berkeley research team and not affiliated, endorsed, or sponsored by OpenAI.</p>
<h2>REFERENCES</h2>
<ol>
<li>Yaghi, O. M.; O'Keeffe, M.; Ockwig, N. W.; Chae, H. K.; Eddaoudi, M.; Kim, J., Reticular synthesis and the design of new materials. Nature 2003, 423 (6941), 705-714.</li>
<li>Matlin, S. A.; Mehta, G.; Hopf, H.; Krief, A., The role of chemistry in inventing a sustainable future. Nat. Chem. 2015, 7 (12), 941-943.</li>
<li>Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y. T.; Li, Y.; Lundberg, S. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv 10.48550/arXiv.2303.12712 (accessed 2023-04-13).</li>
<li>Aspuru-Guzik, A.; Lindh, R.; Reiher, M., The matter simulation (r) evolution. ACS Cent. Sci. 2018, 4 (2), 144-152.</li>
<li>Chen, H.; Engkvist, O.; Wang, Y.; Olivecrona, M.; Blaschke, T., The rise of deep learning in drug discovery. Drug Discov. Today 2018, 23 (6), 1241-1250.</li>
<li>Kaspar, C.; Ravoo, B.; van der Wiel, W. G.; Wegner, S.; Pernice, W., The rise of intelligent matter. Nature 2021, 594 (7863), 345-355.</li>
<li>Gómez-Bombarelli, R.; Wei, J. N.; Duvenaud, D.; Hernández-Lobato, J. M.; Sánchez-Lengeling, B.; Sheberla, D.; Aguilera-Iparraguirre, J.; Hirzel, T. D.; Adams, R. P.; Aspuru-Guzik, A., Automatic chemical design using a data-driven continuous representation of molecules. ACS Cent. Sci. 2018, 4 (2), 268-276.</li>
<li>Firat, M., What ChatGPT means for universities: Perceptions of scholars and students. J. Appl. Learn. Teach. 2023, 6 (1), 1-7.</li>
<li>Lyu, H.; Ji, Z.; Wuttke, S.; Yaghi, O. M., Digital reticular chemistry. Chem 2020, 6 (9), 2219-2241.</li>
<li>Jensen, Z.; Kim, E.; Kwon, S.; Gani, T. Z.; Román-Leshkov, Y.; Moliner, M.; Corma, A.; Olivetti, E., A machine learning approach to zeolite synthesis enabled by automatic literature data extraction. ACS Cent. Sci. 2019, 5 (5), 892-899.</li>
<li>Park, S.; Kim, B.; Choi, S.; Boyd, P. G.; Smit, B.; Kim, J., Text mining metal-organic framework papers. J. Chem. Inf. Model. 2018, 58 (2), 244-251.</li>
<li>He, T.; Sun, W.; Huo, H.; Kononova, O.; Rong, Z.; Tshitoyan, V.; Botari, T.; Ceder, G., Similarity of precursors in solid-state synthesis as text-mined from scientific literature. Chem. Mater. 2020, 32 (18), 7861-7873.</li>
<li>Park, H.; Kang, Y.; Choe, W.; Kim, J., Mining Insights on Metal-Organic Framework Synthesis from Scientific Literature Texts. J. Chem. Inf. Model. 2022, 62 (5), 1190-1198.</li>
<li>Luo, Y.; Bag, S.; Zaremba, O.; Cierpka, A.; Andreo, J.; Wuttke, S.; Friederich, P.; Tsotsalas, M., MOF synthesis prediction enabled by automatic data mining and machine learning. Angew. Chem. Int. Ed. 2022, 61 (19), e202200242.</li>
<li>Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A., Language models are few-shot learners. NIPS 2020, 33, 1877-1901.</li>
<li>Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I., Language models are unsupervised multitask learners. OpenAI blog 2019, 1 (8), 9.</li>
<li>Radford, A.; Narasimhan, K.; Salimans, T.; Sutskever, I., Improving language understanding by generative pre-training. 2018.</li>
<li>Jablonka, K. M.; Schwaller, P.; Ortega-Guerrero, A.; Smit, B. Is GPT-3 all you need for low-data discovery in chemistry? ChemRxiv 10.26434/chemrxiv-2023-fw8n4 (accessed 2023-02-14).</li>
<li>Moghadam, P. Z.; Li, A.; Wiggin, S. B.; Tao, A.; Maloney, A. G.; Wood, P. A.; Ward, S. C.; Fairen-Jimenez, D., Development of a Cambridge Structural Database subset: a collection of metal-organic frameworks for past, present, and future. Chem. Mater. 2017, 29 (7), 2618-2625.</li>
<li>Chung, Y. G.; Camp, J.; Haranczyk, M.; Sikora, B. J.; Bury, W.; Krungleviciute, V.; Yildirim, T.; Farha, O. K.; Sholl, D. S.; Snurr, R. Q., Computation-ready, experimental metal-organic frameworks: A tool to enable high-throughput screening of nanoporous crystals. Chem. Mater. 2014, 26 (21), 6185-6192.</li>
<li>
<p>Chung, Y. G.; Haldoupis, E.; Bucior, B. J.; Haranczyk, M.; Lee, S.; Zhang, H.; Vogiatzis, K. D.; Milisavljevic, M.; Ling, S.; Camp, J. S., Advances, updates, and analytics for the computation-ready, experimental metal-organic framework database: CoRE MOF 2019. J. Chem. Eng. Data 2019, 64 (12), 5985-5998.</p>
</li>
<li>
<p>Mikolov, T.; Chen, K.; Corrado, G.; Dean, J. Efficient estimation of word representations in vector space. arXiv 10.48550/arXiv.1301.3781 (accessed 2013-09-07).</p>
</li>
<li>Le, Q.; Mikolov, T. In Distributed representations of sentences and documents, International conference on machine learning, PMLR: 2014; pp 1188-1196.</li>
<li>Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; Dean, J., Distributed representations of words and phrases and their compositionality. NIPS 2013, 26.</li>
<li>Kusner, M.; Sun, Y.; Kolkin, N.; Weinberger, K. In From word embeddings to document distances, International conference on machine learning, PMLR: 2015; pp 957-966.</li>
<li>Gong, W.; Xie, H.; Idrees, K. B.; Son, F. A.; Chen, Z.; Sha, F.; Liu, Y.; Cui, Y.; Farha, O. K., Water sorption evolution enabled by reticular construction of zirconium metal-organic frameworks based on a unique [2.2] paracyclophane scaffold. J. Am. Chem. Soc. 2022, 144 (4), 18261834 .</li>
<li>Hanikel, N.; Kurandina, D.; Chheda, S.; Zheng, Z.; Rong, Z.; Neumann, S. E.; Sauer, J.; Siepmann, J. I.; Gagliardi, L.; Yaghi, O. M., MOF Linker Extension Strategy for Enhanced Atmospheric Water Harvesting. ACS Cent. Sci. 2023, 9 (3), 551-557.</li>
<li>Liu, T.-F.; Feng, D.; Chen, Y.-P.; Zou, L.; Bosch, M.; Yuan, S.; Wei, Z.; Fordham, S.; Wang, K.; Zhou, H.-C., Topology-guided design and syntheses of highly stable mesoporous porphyrinic zirconium metal-organic frameworks with high surface area. J. Am. Chem. Soc. 2015, 137 (1), 413-419.</li>
<li>Bloch, E. D.; Murray, L. J.; Queen, W. L.; Chavan, S.; Maximoff, S. N.; Bigi, J. P.; Krishna, R.; Peterson, V. K.; Grandjean, F.; Long, G. J., Selective binding of O 2 over N 2 in a redox-active metal-organic framework with open iron (II) coordination sites. J. Am. Chem. Soc. 2011, 133 (37), 14814-14822.</li>
<li>Furukawa, H.; Go, Y. B.; Ko, N.; Park, Y. K.; Uribe-Romo, F. J.; Kim, J.; O'Keeffe, M.; Yaghi, O. M., Isoreticular expansion of metal-organic frameworks with triangular and square building units and the lowest calculated density for porous crystals. Inorg. Chem. 2011, 50 (18), $9147-9152$.</li>
<li>Zheng, Z.; Rong, Z.; Iu-Fan Chen, O.; Yaghi, O. M., Metal-Organic Frameworks with Rod Yttrium Secondary Building Units. Isr. J. Chem. 2023, e202300017.</li>
<li>Reinsch, H.; van der Veen, M. A.; Gil, B.; Marszalek, B.; Verbiest, T.; De Vos, D.; Stock, N., Structures, sorption characteristics, and nonlinear optical properties of a new series of highly stable aluminum MOFs. Chem. Mater. 2013, 25 (1), 17-26.</li>
<li>Hu, Z.; Pramanik, S.; Tan, K.; Zheng, C.; Liu, W.; Zhang, X.; Chabal, Y. J.; Li, J., Selective, sensitive, and reversible detection of vapor-phase high explosives via two-dimensional mapping: A new strategy for MOF-based sensors. Cryst. Growth Des. 2013, 13 (10), 4204-4207.</li>
<li>Glasby, L. T.; Gubsch, K.; Bence, R.; Oktavian, R.; Isoko, K.; Moosavi, S. M.; Cordiner, J. L.; Cole, J. C.; Moghadam, P. Z., DigiMOF: A Database of Metal-Organic Framework Synthesis Information Generated via Text Mining. Chem. Mater. 2023.</li>
<li>Nandy, A.; Duan, C.; Kulik, H. J., Using machine learning and data mining to leverage community knowledge for the engineering of stable metal-organic frameworks. J. Am. Chem. Soc. 2021, 143 (42), 17535-17547.</li>
<li>Shannon, R. D., Revised effective ionic radii and systematic studies of interatomic distances in halides and chalcogenides. Acta Crystallogr. A. 1976, 32 (5), 751-767.</li>
<li>Haynes, W. M., CRC handbook of chemistry and physics. CRC press: Boca Raton, FL, 2016.</li>
<li>Pauling, L., The nature of the chemical bond. IV. The energy of single bonds and the relative electronegativity of atoms. J. Am. Chem. Soc. 1932, 54 (9), 3570-3582.</li>
<li>Nguyen, K. T.; Blum, L. C.; Van Deursen, R.; Reymond, J. L., Classification of organic molecules by molecular quantum numbers. ChemMedChem 2009, 4 (11), 1803-1805.</li>
<li>Deursen, R. v.; Blum, L. C.; Reymond, J.-L., A searchable map of PubChem. J. Chem. Inf. Model. 2010, 50 (11), 1924-1934.</li>
<li>Batra, R.; Chen, C.; Evans, T. G.; Walton, K. S.; Ramprasad, R., Prediction of water stability of metal-organic frameworks using machine learning. Nat. Mach. 2020, 2 (11), 704-710.</li>
<li>Ho, T. K. In Random decision forests, Proceedings of 3rd international conference on document analysis and recognition, IEEE: 1995; pp 278-282.</li>
<li>Kaiser, T. M.; Burger, P. B., Error tolerance of machine learning algorithms across contemporary biological targets. Molecules 2019, 24 (11), 2115.</li>
<li>Meyer, J. G.; Liu, S.; Miller, I. J.; Coon, J. J.; Gitter, A., Learning drug functions from chemical structures with convolutional neural networks and random forests. J. Chem. Inf. Model. 2019, 59 (10), 4438-4449.</li>
<li>Rajappan, R.; Shingade, P. D.; Natarajan, R.; Jayaraman, V. K., Quantitative Structure- Property Relationship (QSPR) Prediction of Liquid Viscosities of Pure Organic Compounds Employing Random Forest Regression. Ind. Eng. Chem. Res. 2009, 48 (21), 9708-9712.</li>
<li>Kapsiani, S.; Howlin, B. J., Random forest classification for predicting lifespan-extending chemical compounds. Sci. Rep. 2021, 11 (1), 113 .</li>
<li>Svetnik, V.; Liaw, A.; Tong, C.; Culberson, J. C.; Sheridan, R. P.; Feuston, B. P., Random forest: a classification and regression tool for compound classification and QSAR modeling. J. Chem. Inf. Comput. Sci. 2003, 43 (6), 1947-1958.</li>
<li>Franklin, E. B.; Yee, L. D.; Aumont, B.; Weber, R. J.; Grigas, P.; Goldstein, A. H., Ch3MS-RF: a random forest model for chemical characterization and improved quantification of unidentified atmospheric organics detected by chromatography-mass spectrometry techniques. Atmos. Meas. Tech. 2022, 15 (12), 3779-3803.</li>
<li>de Santana, F. B.; Neto, W. B.; Poppi, R. J., Random forest as one-class classifier and infrared spectroscopy for food adulteration detection. Food Chem. 2019, 293, 323-332.</li>
<li>Seifert, S., Application of random forest based approaches to surface-enhanced Raman scattering data. Sci. Rep. 2020, 10 (1), 1-11.</li>
<li>Torrisi, S. B.; Carbone, M. R.; Rohr, B. A.; Montoya, J. H.; Ha, Y.; Yano, J.; Suram, S. K.; Hung, L., Random forest machine learning models for interpretable X-ray absorption near-edge structure spectrum-property relationships. Npj Comput. Mater. 2020, 6 (1), 109.</li>
<li>Ahneman, D. T.; Estrada, J. G.; Lin, S.; Dreher, S. D.; Doyle, A. G., Predicting reaction performance in C-N cross-coupling using machine learning. Science 2018, 360 (6385), 186-190.</li>
<li>Yaghi, O. M.; Kalmutzki, M. J.; Diercks, C. S., Introduction to reticular chemistry: metal-organic frameworks and covalent organic frameworks. John Wiley \&amp; Sons: 2019.</li>
<li>
<p>Han, Y.; Yang, H.; Guo, X., Synthesis methods and crystallization of MOFs. Synthesis Methods and Crystallization 2020, 1-23.</p>
</li>
<li>
<p>Gándara, F.; Furukawa, H.; Lee, S.; Yaghi, O. M., High methane storage capacity in aluminum metal-organic frameworks. J. Am. Chem. Soc. 2014, 136 (14), 5271-5274.</p>
</li>
<li>Rowsell, J. L.; Yaghi, O. M., Effects of functionalization, catenation, and variation of the metal oxide and organic linking units on the lowpressure hydrogen adsorption properties of metal-organic frameworks. J. Am. Chem. Soc. 2006, 128 (4), 1304-1315.</li>
<li>Li, M.-Y.; Wang, F.; Zhang, J., Zeolitic tetrazolate-imidazolate frameworks with SOD topology for room temperature fixation of CO2 to cyclic carbonates. Cryst. Growth Des. 2020, 20 (5), 2866-2870.</li>
<li>Zheng, Z.; Alawadhi, A. H.; Yaghi, O. M., Green Synthesis and Scale-Up of MOFs for Water Harvesting from Air. Mol. Front. J. 2023, 1-20.</li>
<li>Köppen, M.; Meyer, V.; Ångström, J.; Inge, A. K.; Stock, N., Solvent-dependent formation of three new Bi-metal-organic frameworks using a tetracarboxylic acid. Cryst. Growth Des. 2018, 18 (7), 4060-4067.</li>
<li>Ma, K.; Cheung, Y. H.; Xie, H.; Wang, X.; Evangelopoulos, M.; Kirlikovali, K. O.; Su, S.; Wang, X.; Mirkin, C. A.; Xin, J. H., Zirconium-Based Metal-Organic Frameworks as Reusable Antibacterial Peroxide Carriers for Protective Textiles. Chem. Mater. 2023, 35 (6), 2342-2352.</li>
<li>Bulatov, A.; Kuratov, Y.; Burtsev, M. S. Scaling Transformer to 1M tokens and beyond with RMT. arXiv 10.48550/arXiv.2304.11062 (accessed 2023-04-19).</li>
<li>Dao, T.; Fu, D.; Ermon, S.; Rudra, A.; Ré, C., Flashattention: Fast and memory-efficient exact attention with io-awareness. NIPS 2022, 35, $16344-16359$.</li>
<li>Colón, Y. J.; Gomez-Gualdron, D. A.; Snurr, R. Q., Topologically guided, automated construction of metal-organic frameworks and their evaluation for energy-related applications. Cryst. Growth Des. 2017, 17 (11), 5801-5810.</li>
<li>Nandy, A.; Yue, S.; Oh, C.; Duan, C.; Terrones, G. G.; Chung, Y. G.; Kulik, H. J., A database of ultrastable MOFs reassembled from stable fragments with machine learning models. Matter 2023, 6 (5), 1585-1603.</li>
<li>Suyetin, M., The application of machine learning for predicting the methane uptake and working capacity of MOFs. Faraday Discuss. 2021, 231, 224-234.</li>
<li>Nandy, A.; Terrones, G.; Arunachalam, N.; Duan, C.; Kastner, D. W.; Kulik, H. J., MOFSimplify, machine learning models with extracted stability data of three thousand metal-organic frameworks. Sci. Data 2022, 9 (1), 74.</li>
</ol>
<h1>Supporting Information</h1>
<h2>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis</h2>
<p>Zhiling Zheng, ${ }^{\dagger, \ddagger, \S}$ Oufan Zhang, ${ }^{\dagger}$ Christian Borgs, ${ }^{\S, \S}$ Jennifer T. Chayes, ${ }^{\S, \S, \dagger \dagger, \ddagger, \S \S}$<br>Omar M. Yaghi ${ }^{\dagger, \ddagger, \S, \phi, <em>}$<br>${ }^{\dagger}$ Department of Chemistry, University of California, Berkeley, California 94720, United States<br>${ }^{\ddagger}$ Kavli Energy Nanoscience Institute, University of California, Berkeley, California 94720, United States<br>${ }^{\S}$ Bakar Institute of Digital Materials for the Planet, College of Computing, Data Science, and Society, University of California, Berkeley, California 94720, United States<br>${ }^{\S}$ Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, California 94720, United States<br>${ }^{\dagger \dagger}$ Department of Mathematics, University of California, Berkeley, California 94720, United States<br>${ }^{\ddagger \ddagger}$ Department of Statistics, University of California, Berkeley, California 94720, United States<br>${ }^{\S \S}$ School of Information, University of California, Berkeley, California 94720, United States<br>${ }^{\text {II }}$ KACST-UC Berkeley Center of Excellence for Nanomaterials for Clean Energy Applications, King Abdulaziz City for Science and Technology, Riyadh 11442, Saudi Arabia<br></em> To whom correspondence should be addressed: yaghi@berkeley.edu</p>
<h2>Table of Contents</h2>
<p>Section S1. General Information ..... 3
Section S2. Chemistry ChatGPT Prompt Engineering (ChemPrompt Engineering) ..... 4
S2.1. Principle 1: Minimizing Hallucination ..... 4
S2.2. Principle 2: Implementing Detailed Instructions ..... 11
S2.3. Principle 3: Requesting Structured Output ..... 15
S2.4. Interactive Prompt Refinement ..... 18
Section S3. Text Mining with ChatGPT API ..... 25
S3.1. Summarizing Synthesis Conditions with ChatGPT ..... 25
S3.2. Classifying Research Article Sections with ChatGPT ..... 27
S3.3. Filtering Text using OpenAI Embeddings ..... 28
S3.4. Batch Text Processing with ChatGPT API ..... 29
S3.5. Generating Python Code with ChatGPT ..... 33</p>
<p>Section S4. ChatGPT-Assisted Chemistry Data Processing Cookbook ..... 45
Section S5. Prediction Modeling ..... 67
Section S6. Dataset to Dialogue: The Creation of a MOF Synthesis Chatbot ..... 74
References ..... 84</p>
<h1>Section S1. General Information</h1>
<h2>Large Language Models</h2>
<p>Three prominent large language models (LLMs) were involved in this study: GPT-3, ${ }^{1}$ ChatGPT (GPT-3.5), and GPT-4. These models are developed and maintained by OpenAI, and although the comprehensive specifics of their training data and architectural design are proprietary, each model is an instantiation of an autoregressive language model that operates on the transformer architecture. ${ }^{2}$ For clarity, in this study, we refer to the default GPT-3.5 based chatbot as "ChatGPT", whereas we explicitly denote the GPT-4 based chatbot as "ChatGPT (GPT-4)" when referenced. Both of these are web-based chatbots and accessible through the OpenAI website chat.openai.com.</p>
<h2>Application Programming Interface (API)</h2>
<p>Two LLM APIs were involved in this study: text-embedding-ada-002 and gpt-3.5-turbo. It should be noted that the model gpt-3.5-turbo is essentially the same model as that supporting the default web-based ChatGPT, so we refer to GPT-3.5 API as the ChatGPT API. We note that as of May 2023, access to the GPT-4 API is limited and requires being on a waitlist, and its cost surpasses that of GPT-3.5 significantly. Therefore, our research does not incorporate any usage of the GPT4 API. In this study, we used text-embedding-ada-002 for the Text Mining step in Process 3, whereas gpt-3.5-turbo served the Text Mining steps in Processes 1 and 2.</p>
<h2>Article Retrieval</h2>
<p>We obtained 228 papers and their corresponding 225 supporting documents from 32 different journals with the authorization from eight distinct publisher groups: American Chemical Society (ACS), Elsevier, Royal Society of Chemistry (RSC), American Association for the Advancement of Science (AAAS), World Scientific, De Gruyter, Springer Nature, and Wiley. The papers, published between May 2004 and March 2023, were downloaded in PDF format.</p>
<h2>Prompt Engineering</h2>
<p>The prompts utilized in this study were developed through a process of interactive prompt refinement. For additional details, please refer to Supporting Information Section S2.</p>
<h2>Python Code</h2>
<p>The majority of the code for text mining, data preprocessing, and chatbot operation was generated by ChatGPT and tested on a Jupyter notebook. Comprehensive code and instructions can be found in Supporting Information Sections S3, S4, and S6. Details of code and data can be found at https://github.com/zach-zhiling-zheng/ChatGPT_Chemistry_Assistant.</p>
<h2>Machine Learning Methods</h2>
<p>The machine learning model implemented in this study was based on the random forest algorithm, as made available through the scikit-learn library in Python. For additional details, please refer to Supporting Information Section S5.</p>            </div>
        </div>

    </div>
</body>
</html>