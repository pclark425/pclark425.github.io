<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8794 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8794</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8794</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-158.html">extraction-schema-158</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-83fb274ca565544743c4cdc7abe58db88a163ae2</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/83fb274ca565544743c4cdc7abe58db88a163ae2" target="_blank">Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This work proposes DualEnc, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text, demonstrating that dual encoding can significantly improve the quality of the generated text.</p>
                <p><strong>Paper Abstract:</strong> Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DualEnc, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8794.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8794.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DualENC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DuALENC (Dual Encoding Model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dual-encoder data-to-text model that jointly conditions an LSTM decoder on (1) a relational GCN encoding of the input RDF graph and (2) an LSTM encoding of a serialized content plan produced by a GCN-based planner, aiming to bridge the structural gap between graph inputs and linear text outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>dual encoding (graph + serialized content plan)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>The input RDF triple-set is represented both as a graph (entities and predicates as nodes; relational edges) encoded with a relational GCN, and as a serialized content plan (ordered triples with explicit role delimiters) encoded with an LSTM; the decoder attends to both encoder contexts and uses a copy mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>RDF knowledge graphs (DBpedia triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>A GCN-based neural planner produces an ordered sequence of predicates (content plan) via sequential selection (softmax over remaining predicate embeddings); each selected predicate's subject and object are appended with special tokens (<S>,<P>,<O>) to form a serialized sequence which is encoded by an LSTM; the original graph is kept as an R-GCN encoding in parallel.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Data-to-text generation (WebNLG: generate natural language descriptions from RDF triple-sets).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Generation (Table 2): BLEU SEEN=63.45, Unseen=36.73, All=51.42; METEOR SEEN=0.46, All=0.41; TER SEEN=0.34, All=0.44. Human evaluation (Table 4): Coverage=94.5%, Faithfulness=91.8% (absolute percentages). Statistical significance reported vs prior SOTA (bootstrap, p<0.05).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Outperforms prior published systems and graph-only encoders on overall metrics and human-evaluated faithfulness/coverage; compared to PlanENC it attains slightly lower BLEU but higher METEOR and better human-preference overall; outperforms GCN-only (graph encoder without plan) which suffers coverage issues.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Integrates explicit graph structure and a linear content plan, improving faithfulness and coverage; better generalization to unseen domains; combines complementary strengths of graph and sequential encoders.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>More complex architecture (two encoders + decoder fusion) than single-encoder models; slight decrease in BLEU relative to PlanENC reported in experiments (automatic metrics not uniformly higher).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No catastrophic failure mode specifically reported; limitations noted include that planning only orders triples (subjects/objects ordering not addressed), and automatic metrics may not fully reflect human-preferred gains (PlanENC sometimes scores higher on BLEU).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8794.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8794.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PlanENC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PlanENC (Plan Encoder only)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generation approach that uses a neural planner to produce a serialized ordered plan of the input RDF triples which is encoded by an LSTM and used as the sole context for an LSTM decoder to generate text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>serialization via content planning (ordered triple sequence with role delimiters)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>A relational GCN planner selects an ordering of predicates (triples); after ordering, each triple is serialized with explicit role delimiters (<S>, <P>, <O>) and concatenated into a sequence which is encoded by a (bi-)LSTM that the decoder attends to.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>RDF knowledge graphs (DBpedia triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>GCN produces predicate embeddings; sequential decision-making chooses the next predicate using softmax over remaining predicate embeddings (conditioned on visited flags and last-visited); after ordering, subjects and objects are inserted to form a linear plan with delimiters.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Data-to-text generation (WebNLG).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Generation (Table 2): BLEU SEEN=64.42, Unseen=38.23, All=52.78; METEOR SEEN=0.45, All=0.41; TER SEEN=0.33, All=0.42. Ablation: removing planning (-plan) drops BLEU by 6.61 on SEEN (from 64.42 to 57.81). Human evaluation (Table 4): Coverage=92.3%, Faithfulness=88.2%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Outperforms GCN-only and prior state-of-the-art systems on BLEU and TER measures; yields better generalization on UnSEEN than linearized Seq2Seq baselines (GRU/Transformer). PlanENC achieves slightly higher BLEU than DualENC in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>High BLEU and TER improvements; planning increases stability (lower std dev across runs) and is essential for generation quality; better generalization to unseen domains because planning is derived from graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Since PlanENC relies solely on the serialized plan, it cannot preserve all information of the original graph and may lose some structural relations; LSTM plan encoder may struggle to capture semantic roles fully.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Reported examples where PlanENC omits entities (e.g., misses 'Buzz Aldrin') or assigns incorrect semantic roles (e.g., wrong subject for 'dateOfRetirement'), indicating LSTM-serialized-plan encoding can lose role information.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8794.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8794.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GCN Planner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GCN-based Neural Planner (relational GCN planner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A planner that formulates content planning as a sequential decision-making problem and uses a relational GCN to encode graph nodes and select an ordered sequence of predicates/triples to form a content plan.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>graph-to-sequence planning (R-GCN -> ordered predicate sequence)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>R-GCN (relational GCN) encodes the reconstructed RDF graph (entities and predicate nodes); predicate node embeddings (with extra flags for visited/last-visited) are used at each step to compute a softmax over remaining predicates to pick the next triple, iterating until all predicates are visited.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>RDF knowledge graphs (DBpedia triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Construct nodes for subjects, predicates (unique per triple), and objects; build directed edges s->p, p->s, o->p, p->o and self-loops; run R-GCN for T iterations to get predicate embeddings; sequentially select predicates via softmax over h_r * W * avg_pool(h_R); append subject/object to form plan.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Content planning for data-to-text generation; evaluated standalone as plan generation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Planning (Table 1): Accuracy SEEN=0.63, UnSEEN=0.61, ALL=0.62; BLEU-2 SEEN=80.8, UnSEEN=79.3, ALL=80.1. Efficiency: solved 4,928 instances in <10s vs Step-By-Step taking ~250s for a single 7-triple instance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Significantly outperforms baselines (Random, Structure-Random, Transformer, GRU, Step-By-Step II, Step-By-Step) in accuracy and BLEU-2 across SEEN/UNSEEN/ALL; shows much smaller performance drop on UnSEEN compared to GRU/Transformer linearized planners.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>High planning accuracy and BLEU-2; very time-efficient compared to prior planning methods; better generalization to unseen domains due to modeling graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Only orders triples (does not order subjects/objects); accuracy declines as graph size grows (e.g., seven-triple cases harder; accuracy for 7-triple = 0.19).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Performance degrades with increasing triple-set size (notably seven-triple instances remain challenging although method still outperforms baselines); planner does not model ordering of entities within triples (subjects/objects), which is a noted limitation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8794.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8794.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RDF Reified Graph</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RDF graph with entities and predicates as nodes (edge scheme s↔p, o↔p)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specific graph construction used to represent RDF triples where subjects, predicates (unique per triple), and objects are all treated as nodes connected via four directed edges per triple plus self-loops to facilitate relational GCN message passing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>node-centered RDF graph with predicate nodes and directed edges</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>For each triple (s,p,o) create three nodes (subject, predicate, object), treat predicates with same surface mention but different triples as distinct nodes; add directed edges s->p, p->s, o->p, p->o and a self-loop n->n for each node; node input features are average embeddings of node mentions.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>RDF knowledge graphs (DBpedia triples used in WebNLG)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Direct conversion from set of RDF triples into the described node/edge graph structure as input to an R-GCN encoder; subsequently the graph is used either directly for decoding (GCN encoder) or as input to a planner that serializes triples.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Input representation for graph encoders in data-to-text generation and for planning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No isolated metric for representation alone; used by models whose reported end-to-end metrics include the planner and generator: planner accuracy/ BLEU-2 and generation BLEU/METEOR/TER as reported for GCN-based models and DualENC/PlanENC.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Compared implicitly to sequence linearizations: preserves graph-level structural information enabling better generalization to unseen domains; however when used alone (GCN encoder only) it can exacerbate the structural gap with sequence decoder and reduce coverage in generation.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Preserves relational and structural graph information explicitly, supports relational-specific message transforms (R-GCN), and enables better modeling of shared graph-level patterns for generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>By itself widens the structural mismatch with a linear decoder (sequence generator), which can make alignment and faithful realization harder (observed lower coverage for GCN-only generation).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>GCN-only generation using this representation shows lower coverage according to human evaluation (structural gap causing omissions); the representation alone does not solve sequential ordering required for fluent linear text realization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8794.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8794.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Seq2Seq Linearization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sequence-to-sequence serialization of graph inputs (linearization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used baseline approach that flattens graph-structured inputs (triples) into a linear sequence and uses standard Seq2Seq encoders (e.g., GRU or Transformer) to generate text, at the cost of losing explicit graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sequence to sequence learning with neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>linearization / serialization of triples for Seq2Seq encoders</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Graph is converted to a sequence by concatenating triples or their tokens into a linear input (optionally with delexicalization); sequential encoders (GRU/Transformer) consume this serialized input and the decoder generates text.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>RDF knowledge graphs (DBpedia triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Flatten triples into a token sequence (often with delexicalization or sub-word tokenization). Some baselines also extract plans via heuristics or pipeline steps before Seq2Seq encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Data-to-text generation (WebNLG) and also used in planning baselines when treating plan generation as sequence generation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported baseline generation metrics: GRU (Table 2) BLEU SEEN=56.09, Unseen=25.12, All=42.73; Transformer BLEU SEEN=56.28, Unseen=23.04, All=42.41. In planning, GRU/Transformer planners had low UnSEEN accuracies (drop of ~0.46).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Generally outperformed by graph-aware methods (GCN-based planners/encoders and DualENC/PlanENC) on generalization to UnSEEN domains and some generation metrics; linearized Seq2Seq shows larger performance drop on unseen domains.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Simple, leverages mature Seq2Seq architectures and training pipelines; can produce fluent text when training data covers target patterns (high SEEN performance for some systems).</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Loses explicit structural relations from the graph, leading to poorer generalization to unseen domains and issues like repetition, omission, and unfaithfulness in generated text.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Marked drop in UnSEEN performance and planning accuracy when surface forms differ between train and test due to missing structural cues (e.g., large accuracy drop for GRU/Transformer planners on UnSEEN).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8794.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8794.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STEP-BY-STEP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>step-by-step: Separating planning from realization in neural data-to-text generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline approach that first extracts or predicts content plans (via transition-based ranking or DFS-based neural controllers) and then realizes each planned subset separately with a Seq2Seq generator, prioritizing coverage and faithfulness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>step-by-step: Separating planning from realization in neural data-to-text generation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>pipeline planning + realization (heuristic/statistical plan extraction followed by Seq2Seq realization)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Plans are produced (via heuristic string matching or a neural controller) that partition triples into subsets; each subset is realized separately by a generator (e.g., OpenNMT with copy), reducing long-range generation difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>RDF knowledge graphs (DBpedia triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Heuristic plan extraction from references or DFS-based planning to order/partition triples, then OpenNMT-based realization with copy mechanism per partition.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Data-to-text generation (WebNLG).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Generation (Table 2): BLEU SEEN=53.30, Unseen=34.41, All=47.24. Human eval (Table 4): Coverage=96.1%, Faithfulness=89.3% (high), but Fluency worst among baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>High coverage and faithfulness compared to end-to-end methods, but lower fluency; PlanENC and DuALENC achieve better overall balances (fluency + faithfulness).</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>High coverage and faithfulness because planning splits difficult tasks into smaller realizations; reduces long-term generation errors.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Significant loss in fluency compared to end-to-end models; pipeline may require heuristics to extract plans, and separate modules can propagate errors.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Generated text judged least fluent in human evaluations despite high coverage/faithfulness, demonstrating tradeoff between dividing generation into parts and producing natural overall text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Graph-to-sequence learning using gated graph neural networks <em>(Rating: 2)</em></li>
                <li>Deep graph convolutional encoders for structured data to text generation <em>(Rating: 2)</em></li>
                <li>step-by-step: Separating planning from realization in neural data-to-text generation <em>(Rating: 2)</em></li>
                <li>Neural data-to-text generation: A comparison between pipeline and end-to-end architectures <em>(Rating: 2)</em></li>
                <li>Modeling relational data with graph convolutional networks <em>(Rating: 2)</em></li>
                <li>GTR-LSTM: A triple encoder for sentence generation from rdf data <em>(Rating: 2)</em></li>
                <li>Neural text generation from structured data with application to the biography domain <em>(Rating: 1)</em></li>
                <li>Plan-and-write: Towards better automatic storytelling <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8794",
    "paper_id": "paper-83fb274ca565544743c4cdc7abe58db88a163ae2",
    "extraction_schema_id": "extraction-schema-158",
    "extracted_data": [
        {
            "name_short": "DualENC",
            "name_full": "DuALENC (Dual Encoding Model)",
            "brief_description": "A dual-encoder data-to-text model that jointly conditions an LSTM decoder on (1) a relational GCN encoding of the input RDF graph and (2) an LSTM encoding of a serialized content plan produced by a GCN-based planner, aiming to bridge the structural gap between graph inputs and linear text outputs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "dual encoding (graph + serialized content plan)",
            "representation_description": "The input RDF triple-set is represented both as a graph (entities and predicates as nodes; relational edges) encoded with a relational GCN, and as a serialized content plan (ordered triples with explicit role delimiters) encoded with an LSTM; the decoder attends to both encoder contexts and uses a copy mechanism.",
            "graph_type": "RDF knowledge graphs (DBpedia triples)",
            "conversion_method": "A GCN-based neural planner produces an ordered sequence of predicates (content plan) via sequential selection (softmax over remaining predicate embeddings); each selected predicate's subject and object are appended with special tokens (&lt;S&gt;,&lt;P&gt;,&lt;O&gt;) to form a serialized sequence which is encoded by an LSTM; the original graph is kept as an R-GCN encoding in parallel.",
            "downstream_task": "Data-to-text generation (WebNLG: generate natural language descriptions from RDF triple-sets).",
            "performance_metrics": "Generation (Table 2): BLEU SEEN=63.45, Unseen=36.73, All=51.42; METEOR SEEN=0.46, All=0.41; TER SEEN=0.34, All=0.44. Human evaluation (Table 4): Coverage=94.5%, Faithfulness=91.8% (absolute percentages). Statistical significance reported vs prior SOTA (bootstrap, p&lt;0.05).",
            "comparison_to_others": "Outperforms prior published systems and graph-only encoders on overall metrics and human-evaluated faithfulness/coverage; compared to PlanENC it attains slightly lower BLEU but higher METEOR and better human-preference overall; outperforms GCN-only (graph encoder without plan) which suffers coverage issues.",
            "advantages": "Integrates explicit graph structure and a linear content plan, improving faithfulness and coverage; better generalization to unseen domains; combines complementary strengths of graph and sequential encoders.",
            "disadvantages": "More complex architecture (two encoders + decoder fusion) than single-encoder models; slight decrease in BLEU relative to PlanENC reported in experiments (automatic metrics not uniformly higher).",
            "failure_cases": "No catastrophic failure mode specifically reported; limitations noted include that planning only orders triples (subjects/objects ordering not addressed), and automatic metrics may not fully reflect human-preferred gains (PlanENC sometimes scores higher on BLEU).",
            "uuid": "e8794.0",
            "source_info": {
                "paper_title": "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "PlanENC",
            "name_full": "PlanENC (Plan Encoder only)",
            "brief_description": "A generation approach that uses a neural planner to produce a serialized ordered plan of the input RDF triples which is encoded by an LSTM and used as the sole context for an LSTM decoder to generate text.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "serialization via content planning (ordered triple sequence with role delimiters)",
            "representation_description": "A relational GCN planner selects an ordering of predicates (triples); after ordering, each triple is serialized with explicit role delimiters (&lt;S&gt;, &lt;P&gt;, &lt;O&gt;) and concatenated into a sequence which is encoded by a (bi-)LSTM that the decoder attends to.",
            "graph_type": "RDF knowledge graphs (DBpedia triples)",
            "conversion_method": "GCN produces predicate embeddings; sequential decision-making chooses the next predicate using softmax over remaining predicate embeddings (conditioned on visited flags and last-visited); after ordering, subjects and objects are inserted to form a linear plan with delimiters.",
            "downstream_task": "Data-to-text generation (WebNLG).",
            "performance_metrics": "Generation (Table 2): BLEU SEEN=64.42, Unseen=38.23, All=52.78; METEOR SEEN=0.45, All=0.41; TER SEEN=0.33, All=0.42. Ablation: removing planning (-plan) drops BLEU by 6.61 on SEEN (from 64.42 to 57.81). Human evaluation (Table 4): Coverage=92.3%, Faithfulness=88.2%.",
            "comparison_to_others": "Outperforms GCN-only and prior state-of-the-art systems on BLEU and TER measures; yields better generalization on UnSEEN than linearized Seq2Seq baselines (GRU/Transformer). PlanENC achieves slightly higher BLEU than DualENC in experiments.",
            "advantages": "High BLEU and TER improvements; planning increases stability (lower std dev across runs) and is essential for generation quality; better generalization to unseen domains because planning is derived from graph structure.",
            "disadvantages": "Since PlanENC relies solely on the serialized plan, it cannot preserve all information of the original graph and may lose some structural relations; LSTM plan encoder may struggle to capture semantic roles fully.",
            "failure_cases": "Reported examples where PlanENC omits entities (e.g., misses 'Buzz Aldrin') or assigns incorrect semantic roles (e.g., wrong subject for 'dateOfRetirement'), indicating LSTM-serialized-plan encoding can lose role information.",
            "uuid": "e8794.1",
            "source_info": {
                "paper_title": "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "GCN Planner",
            "name_full": "GCN-based Neural Planner (relational GCN planner)",
            "brief_description": "A planner that formulates content planning as a sequential decision-making problem and uses a relational GCN to encode graph nodes and select an ordered sequence of predicates/triples to form a content plan.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "graph-to-sequence planning (R-GCN -&gt; ordered predicate sequence)",
            "representation_description": "R-GCN (relational GCN) encodes the reconstructed RDF graph (entities and predicate nodes); predicate node embeddings (with extra flags for visited/last-visited) are used at each step to compute a softmax over remaining predicates to pick the next triple, iterating until all predicates are visited.",
            "graph_type": "RDF knowledge graphs (DBpedia triples)",
            "conversion_method": "Construct nodes for subjects, predicates (unique per triple), and objects; build directed edges s-&gt;p, p-&gt;s, o-&gt;p, p-&gt;o and self-loops; run R-GCN for T iterations to get predicate embeddings; sequentially select predicates via softmax over h_r * W * avg_pool(h_R); append subject/object to form plan.",
            "downstream_task": "Content planning for data-to-text generation; evaluated standalone as plan generation.",
            "performance_metrics": "Planning (Table 1): Accuracy SEEN=0.63, UnSEEN=0.61, ALL=0.62; BLEU-2 SEEN=80.8, UnSEEN=79.3, ALL=80.1. Efficiency: solved 4,928 instances in &lt;10s vs Step-By-Step taking ~250s for a single 7-triple instance.",
            "comparison_to_others": "Significantly outperforms baselines (Random, Structure-Random, Transformer, GRU, Step-By-Step II, Step-By-Step) in accuracy and BLEU-2 across SEEN/UNSEEN/ALL; shows much smaller performance drop on UnSEEN compared to GRU/Transformer linearized planners.",
            "advantages": "High planning accuracy and BLEU-2; very time-efficient compared to prior planning methods; better generalization to unseen domains due to modeling graph structure.",
            "disadvantages": "Only orders triples (does not order subjects/objects); accuracy declines as graph size grows (e.g., seven-triple cases harder; accuracy for 7-triple = 0.19).",
            "failure_cases": "Performance degrades with increasing triple-set size (notably seven-triple instances remain challenging although method still outperforms baselines); planner does not model ordering of entities within triples (subjects/objects), which is a noted limitation.",
            "uuid": "e8794.2",
            "source_info": {
                "paper_title": "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "RDF Reified Graph",
            "name_full": "RDF graph with entities and predicates as nodes (edge scheme s↔p, o↔p)",
            "brief_description": "A specific graph construction used to represent RDF triples where subjects, predicates (unique per triple), and objects are all treated as nodes connected via four directed edges per triple plus self-loops to facilitate relational GCN message passing.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "node-centered RDF graph with predicate nodes and directed edges",
            "representation_description": "For each triple (s,p,o) create three nodes (subject, predicate, object), treat predicates with same surface mention but different triples as distinct nodes; add directed edges s-&gt;p, p-&gt;s, o-&gt;p, p-&gt;o and a self-loop n-&gt;n for each node; node input features are average embeddings of node mentions.",
            "graph_type": "RDF knowledge graphs (DBpedia triples used in WebNLG)",
            "conversion_method": "Direct conversion from set of RDF triples into the described node/edge graph structure as input to an R-GCN encoder; subsequently the graph is used either directly for decoding (GCN encoder) or as input to a planner that serializes triples.",
            "downstream_task": "Input representation for graph encoders in data-to-text generation and for planning.",
            "performance_metrics": "No isolated metric for representation alone; used by models whose reported end-to-end metrics include the planner and generator: planner accuracy/ BLEU-2 and generation BLEU/METEOR/TER as reported for GCN-based models and DualENC/PlanENC.",
            "comparison_to_others": "Compared implicitly to sequence linearizations: preserves graph-level structural information enabling better generalization to unseen domains; however when used alone (GCN encoder only) it can exacerbate the structural gap with sequence decoder and reduce coverage in generation.",
            "advantages": "Preserves relational and structural graph information explicitly, supports relational-specific message transforms (R-GCN), and enables better modeling of shared graph-level patterns for generalization.",
            "disadvantages": "By itself widens the structural mismatch with a linear decoder (sequence generator), which can make alignment and faithful realization harder (observed lower coverage for GCN-only generation).",
            "failure_cases": "GCN-only generation using this representation shows lower coverage according to human evaluation (structural gap causing omissions); the representation alone does not solve sequential ordering required for fluent linear text realization.",
            "uuid": "e8794.3",
            "source_info": {
                "paper_title": "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "Seq2Seq Linearization",
            "name_full": "Sequence-to-sequence serialization of graph inputs (linearization)",
            "brief_description": "A widely-used baseline approach that flattens graph-structured inputs (triples) into a linear sequence and uses standard Seq2Seq encoders (e.g., GRU or Transformer) to generate text, at the cost of losing explicit graph structure.",
            "citation_title": "Sequence to sequence learning with neural networks",
            "mention_or_use": "mention",
            "representation_name": "linearization / serialization of triples for Seq2Seq encoders",
            "representation_description": "Graph is converted to a sequence by concatenating triples or their tokens into a linear input (optionally with delexicalization); sequential encoders (GRU/Transformer) consume this serialized input and the decoder generates text.",
            "graph_type": "RDF knowledge graphs (DBpedia triples)",
            "conversion_method": "Flatten triples into a token sequence (often with delexicalization or sub-word tokenization). Some baselines also extract plans via heuristics or pipeline steps before Seq2Seq encoding.",
            "downstream_task": "Data-to-text generation (WebNLG) and also used in planning baselines when treating plan generation as sequence generation.",
            "performance_metrics": "Reported baseline generation metrics: GRU (Table 2) BLEU SEEN=56.09, Unseen=25.12, All=42.73; Transformer BLEU SEEN=56.28, Unseen=23.04, All=42.41. In planning, GRU/Transformer planners had low UnSEEN accuracies (drop of ~0.46).",
            "comparison_to_others": "Generally outperformed by graph-aware methods (GCN-based planners/encoders and DualENC/PlanENC) on generalization to UnSEEN domains and some generation metrics; linearized Seq2Seq shows larger performance drop on unseen domains.",
            "advantages": "Simple, leverages mature Seq2Seq architectures and training pipelines; can produce fluent text when training data covers target patterns (high SEEN performance for some systems).",
            "disadvantages": "Loses explicit structural relations from the graph, leading to poorer generalization to unseen domains and issues like repetition, omission, and unfaithfulness in generated text.",
            "failure_cases": "Marked drop in UnSEEN performance and planning accuracy when surface forms differ between train and test due to missing structural cues (e.g., large accuracy drop for GRU/Transformer planners on UnSEEN).",
            "uuid": "e8794.4",
            "source_info": {
                "paper_title": "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "STEP-BY-STEP",
            "name_full": "step-by-step: Separating planning from realization in neural data-to-text generation",
            "brief_description": "A pipeline approach that first extracts or predicts content plans (via transition-based ranking or DFS-based neural controllers) and then realizes each planned subset separately with a Seq2Seq generator, prioritizing coverage and faithfulness.",
            "citation_title": "step-by-step: Separating planning from realization in neural data-to-text generation",
            "mention_or_use": "mention",
            "representation_name": "pipeline planning + realization (heuristic/statistical plan extraction followed by Seq2Seq realization)",
            "representation_description": "Plans are produced (via heuristic string matching or a neural controller) that partition triples into subsets; each subset is realized separately by a generator (e.g., OpenNMT with copy), reducing long-range generation difficulty.",
            "graph_type": "RDF knowledge graphs (DBpedia triples)",
            "conversion_method": "Heuristic plan extraction from references or DFS-based planning to order/partition triples, then OpenNMT-based realization with copy mechanism per partition.",
            "downstream_task": "Data-to-text generation (WebNLG).",
            "performance_metrics": "Generation (Table 2): BLEU SEEN=53.30, Unseen=34.41, All=47.24. Human eval (Table 4): Coverage=96.1%, Faithfulness=89.3% (high), but Fluency worst among baselines.",
            "comparison_to_others": "High coverage and faithfulness compared to end-to-end methods, but lower fluency; PlanENC and DuALENC achieve better overall balances (fluency + faithfulness).",
            "advantages": "High coverage and faithfulness because planning splits difficult tasks into smaller realizations; reduces long-term generation errors.",
            "disadvantages": "Significant loss in fluency compared to end-to-end models; pipeline may require heuristics to extract plans, and separate modules can propagate errors.",
            "failure_cases": "Generated text judged least fluent in human evaluations despite high coverage/faithfulness, demonstrating tradeoff between dividing generation into parts and producing natural overall text.",
            "uuid": "e8794.5",
            "source_info": {
                "paper_title": "Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation",
                "publication_date_yy_mm": "2020-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Graph-to-sequence learning using gated graph neural networks",
            "rating": 2,
            "sanitized_title": "graphtosequence_learning_using_gated_graph_neural_networks"
        },
        {
            "paper_title": "Deep graph convolutional encoders for structured data to text generation",
            "rating": 2,
            "sanitized_title": "deep_graph_convolutional_encoders_for_structured_data_to_text_generation"
        },
        {
            "paper_title": "step-by-step: Separating planning from realization in neural data-to-text generation",
            "rating": 2,
            "sanitized_title": "stepbystep_separating_planning_from_realization_in_neural_datatotext_generation"
        },
        {
            "paper_title": "Neural data-to-text generation: A comparison between pipeline and end-to-end architectures",
            "rating": 2,
            "sanitized_title": "neural_datatotext_generation_a_comparison_between_pipeline_and_endtoend_architectures"
        },
        {
            "paper_title": "Modeling relational data with graph convolutional networks",
            "rating": 2,
            "sanitized_title": "modeling_relational_data_with_graph_convolutional_networks"
        },
        {
            "paper_title": "GTR-LSTM: A triple encoder for sentence generation from rdf data",
            "rating": 2,
            "sanitized_title": "gtrlstm_a_triple_encoder_for_sentence_generation_from_rdf_data"
        },
        {
            "paper_title": "Neural text generation from structured data with application to the biography domain",
            "rating": 1,
            "sanitized_title": "neural_text_generation_from_structured_data_with_application_to_the_biography_domain"
        },
        {
            "paper_title": "Plan-and-write: Towards better automatic storytelling",
            "rating": 1,
            "sanitized_title": "planandwrite_towards_better_automatic_storytelling"
        }
    ],
    "cost": 0.018251,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation</h1>
<p>Chao Zhao ${ }^{\dagger}$, Marilyn Walker ${ }^{\ddagger}$ and Snigdha Chaturvedi ${ }^{\dagger}$<br>${ }^{\dagger}$ Department of Computer Science, University of North Carolina at Chapel Hill<br>${ }^{\ddagger}$ Natural Language and Dialog Systems Lab, University of California, Santa Cruz<br>{zhaochao, snigdha}@cs.unc.edu mawalker@ucsc.edu</p>
<h4>Abstract</h4>
<p>Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DuALENC, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.</p>
<h2>1 Introduction</h2>
<p>Data-to-text generation aims to create natural language text to describe the input data (Reiter and Dale, 2000). Here we focus on structured text input in a particular form such as a tree or a graph. Figure 1 shows an example where the input data is a mini knowledge graph, and the output text is its corresponding natural language description. Generating text from such data is helpful for many NLP tasks, such as question answering and dialogue (He et al., 2017; Liu et al., 2018; Moon et al., 2019).</p>
<p>During generation, the structure of the data as well as the content inside the structure jointly determine the generated text. For example, the direction of the edge "capital" in Figure 1 determines that "London is the capital of U.K." is an accurate description, but not vice versa. Current generation methods are based on sequence-to-sequence (Seq2Seq) encoder-decoder architecture (Sutskever et al., 2014), which requires the input data to be
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Illustration of the WebNLG challenge: the source data is an RDF graph and the target output is a text description of the graph.
serialized as a sequence, resulting in a loss of structural information.</p>
<p>Recent research has shown the utility of incorporating structural information during generation. By replacing the sequential encoder with a structureaware graph encoder, such as a graph convolutional network (GCNs) (Kipf and Welling, 2017) or graph-state LSTMs (Song et al., 2018), the resulting graph-to-sequence (Graph2Seq) methods can encode the structural information of the input and thus outperform Seq2Seq models on certain tasks. However, these architectures broaden the structural gap between the encoder and decoder. That is, while the encoder receives the input data as a graph, the decoder has to create the output text as a linear chain structure.</p>
<p>This structural gap increases the difficulty of establishing alignments between source and target, which is believed to play a key role in text generation. For example, in machine translation, pre-reordering the source words into a word order that is close to that of the target sentence can yield significant improvements in translation quality (Bisazza and Federico, 2016). This suggests a need for an intermediate "planning" stage (Reiter</p>
<p>and Dale, 2000; Puduppully et al., 2019) to help with organizing the output.</p>
<p>In this work, we present a dual encoding model that is not only aware of the input graph structure but also incorporates a content planning stage. To encode the structural information in the input graph, we use a GCN based graph encoder. To narrow the ensuing structural gap, we use another GCN-based neural planner to create a sequential content plan of this graph, which is represented as a re-ordered sequence of its nodes. The plan is then encoded by an LSTM based sequential encoder. During generation, an LSTM based decoder simultaneously conditions on the two encoders, which helps it in capturing both the graph structure of the input data and the linear structure of the plan. We expect such a dual encoding (DualEnc) structure can integrate the advantages of both graph and sequential encoders while narrowing the structural gap present in single-encoder methods.</p>
<p>We evaluate the proposed planning and generation models on the WebNLG dataset (Colin et al., 2016; Gardent et al., 2017) - a widely used benchmark for data-to-text generation. Experimental results show that our neural planner achieves a $15 \%$ absolute improvement on accuracy compared to the previous best planning method. Furthermore, DualEnc significantly outperforms the previous start-of-the-art on the generation task. The human evaluation confirms that the texts generated by our model are preferred over strong baselines.</p>
<p>The contributions of this paper are three-fold:</p>
<ul>
<li>We propose a dual encoding method to narrow the structural gap between data encoder and text decoder for data-to-text generation;</li>
<li>We propose a neural planner, which is more efficient and effective than previous methods;</li>
<li>Experiments show that our method outperforms all baselines on a variety of measures.</li>
</ul>
<h2>2 Related Work</h2>
<p>This work is inspired by two lines of research: Seq2Seq generation and Graph2Seq generation.</p>
<h3>2.1 Seq2Seq Generation</h3>
<p>Traditional data-to-text generation follows a planning and realization pipeline (Reiter and Dale, 2000; Stent et al., 2004). More recent methods use Seq2Seq architecture (Sutskever et al., 2014) to combine planning and realization into an end-toend network and have achieved the state-of-the-art
on a variety of generation tasks (Lebret et al., 2016; Trisedya et al., 2018; Juraska et al., 2018; Reed et al., 2018). Despite the fair fluency and grammatical correctness, the generated text suffers from several problems such as repetition, omission, and unfaithfulness, which are less likely to happen in traditional planning-and-realization frameworks.</p>
<p>Recent work has shown that neural models can also benefit from an explicit planning step to alleviate the above-mentioned problems. The input of these planners ranges from unstructured keyphrases (Hua and Wang, 2019) to structured tables (Puduppully et al., 2019) and graphs (Ferreira et al., 2019; Moryossef et al., 2019a). Our work also focuses on planning from graph data. Compared with previous methods, we show that our neural planning method is more feasible and accurate. More importantly, rather than serializing the planning and realization stages in a pipeline, our dual encoding method simultaneously captures information from the original data and the corresponding plan.</p>
<h3>2.2 Graph2Seq Generation</h3>
<p>Graph neural networks (GNN) (Scarselli et al., 2009) aim to learn a latent state representation for each node in a graph by aggregating local information from its neighbors and the connected edges. Previous work has explored different ways of aggregating this local information, such as in GCNs (Kipf and Welling, 2017), gated graph neural networks (GGNNs) (Li et al., 2016), and Graph attention networks (GANs) (Veličković et al., 2018)</p>
<p>Several works have applied GNNs instead of Seq2Seq models for text generation (Beck et al., 2018; Marcheggiani and Perez-Beltrachini, 2018; Guo et al., 2019; Li et al., 2019), and some of them outperform Seq2Seq models. However, Damonte and Cohen (2019) use both types of encoders and show that GCN can help LSTM capture reentrant structures and long-range dependencies, albeit on a different problem than ours. Our method also uses the two types of encoders but instead of using one to assist the other, it combines them simultaneously to capture their complementary effects.</p>
<h2>3 Problem Statement</h2>
<p>In this work we focus on text generation from RDF data. ${ }^{1}$ The input for this task is a set of RDF triples, where each triple $(s, p, o)$ contains a subject, a predicate, and an object. For example, ("U.K.", "cap-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The architecture of the proposed DUALENC model. The input triples are converted as a graph and then fed to two GCN encoders for plan and text generation (Planner and Graph Encoder, top center). The plan is then encoded by an LSTM network (Plan Encoder, bottom center). Finally an LSTM decoder combines the hidden states from both the encoders to generate the text (Text Decoder, middle right).
ital", "London") is a RDF triple. The output is a natural language text with one or more sentences to describe the facts represented by this graph. Figure 1 shows an example of this task.</p>
<h2>4 Dual Encoding Model</h2>
<p>For a given input RDF graph, the aim of our method is not only to capture its structural information, but also to facilitate the information alignment between the input and output. The first goal can be achieved by employing a GCN encoder. To achieve the second goal, we first serialize and re-order the nodes of the graph as an intermediate plan using another GCN, and then feed the plan into an LSTM encoder. Finally, an LSTM decoder is used to generate the output by incorporating the context representations of both encoders. Notice that the graph and the plan are dual representations of the same input data. We encode them with two independent encoders, which can provide complementary information for decoding. The architecture of our dual encoding method is shown in Figure 2. We describe the two encoders and the decoder in the following three subsections.</p>
<h3>4.1 Graph Representation and Encoding</h3>
<p>To make it easier for GCNs to encode information from both entities and predicates, we reconstruct the input graph by regarding both entities and predicates as nodes, which is different from Figure 1.</p>
<p>Formally, for each RDF triple $(s, p, o)$, we regard the $s, p$, and $o$ as three kinds of nodes. $s$ and $o$ are identified by their entity mentions, and $p$ is identified by a unique ID. That is, two entities from different triples that have the same mentions will
be regarded as the same node. However, since we want to use predicates to distinguish between different triples, two predicates with the same mentions will be regarded as separate nodes. ${ }^{2}$
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The graph obtained from an RDF triple.</p>
<p>We use the same edge structure as Beck et al. (2018). As Figure 3 shows, a triple contains four directed edges to connect its nodes: $s \rightarrow p, p \rightarrow s$, $o \rightarrow p$, and $p \rightarrow o$. These edges help in information exchange between arbitrary neighbor pairs. There is also a special self-loop edge $n \rightarrow n$ for each node $n$ to enable information flow between adjacent iterations during feature aggregation.</p>
<p>After building the graph $\mathcal{G}=(\mathcal{V}, \mathcal{E})$ from the RDF data, we use a relational GCN (R-GCN) (Schlichtkrull et al., 2018) to encode the graph and learn a state representation $\mathbf{h}_{v} \in \mathbb{R}^{d}$ for each node $v \in \mathcal{V}$ using the following iterative method:</p>
<p>$$
\mathbf{h}<em _in="\in" _mathcal_R="\mathcal{R" r="r">{v}^{t}=\rho\left(\sum</em>}} \sum_{u \in \mathcal{N<em r="r" v_="v,">{v}^{r}} \frac{1}{c</em>}} \mathbf{W<em u="u">{r} \mathbf{h}</em>\right)
$$}^{(t-1)}+\mathbf{b}_{r</p>
<p>where $\mathbf{h}<em v="v">{v}^{0}=\mathbf{x}</em>}$ is the input embedding of the node $v$, and $\mathbf{h<em v="v">{v}^{t}$ is its hidden state at time-step $t$. We use the average embedding of the node mentions as $\mathbf{x}</em>$ is the set of in-neighbors of node $v$ with the edge} . \mathcal{R}$ is the set of all possible edge types, and $\mathcal{N}_{v}^{r</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The sequential decision-making process of the planning stage.
type as $r . \mathbf{W}<em r="r">{r}$ and $\mathbf{b}</em>\right|$ is a normalization term and $\rho()$ is an activation function.}$ are parameters for each edge type, which allow transformations of message to become relational-specific. $c_{v, r}=1 /\left|\mathcal{N}_{v}^{r</p>
<h3>4.2 Planning Creation and Encoding</h3>
<p>In the planning stage, we determine the content plan or order of triples (identified by their predicates) for text realization. For example, the content plan for the text in Figure 1 is: "assembly $\rightarrow$ capital $\rightarrow$ successor $\rightarrow$ manufacturer ". ${ }^{3}$</p>
<p>Learning a plan can be naturally regarded as a sequential decision-making process. That is, given a set of triples, we first determine which triple to mention/visit first, and then select the second triple from the remaining triples that have not been visited so far. This process continues until all the triples have been visited. During each decision step, the selection of the next triple can be regarded as a classification task, where the output space is all the remaining unvisited triples.</p>
<p>Figure 4 shows how our model implements this process. We first utilize the GCN encoder described in Section 4.1 to get the state representation of each node. However, while obtaining a predicate's representation, we concatenate two extra bits to the input feature $\mathbf{X}^{t}$. One is to indicate whether or not the predicate has been visited, the other to indicate the last predicate that has been visited. After the encoding, we get the final hidden state $\mathbf{h}<em i="i">{r</em>}}=\mathbf{h<em i="i">{r</em>$ as its representation, and calculate its probability of being selected as}}^{\langle T\rangle}$ for each predicate $r_{i} \in \mathcal{R</p>
<p>$$
P\left(r_{i}\right)=\operatorname{softmax}\left(\mathbf{h}<em i="i">{r</em>\right)
$$}}^{T} \mathbf{W} \overline{\mathbf{h}}_{\mathcal{R}</p>
<p>where $\overline{\mathbf{h}}_{\mathcal{R}}$ is the average pooling of all the predicate embeddings. For obtaining a plan, we select the predicate with the highest probability, append it onto the plan sequence, and then repeat the above process until all the predicates have been visited.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>After determining an order of input predicates, we complete the plan's triples by adding the corresponding subjects and objects. To better help the plan encoder (described below) capture the semantic roles of each entity and predicate, we add special tokens before Subjects, Predicates, and Objects as delimiters. For example, the plan of the example in Figure 1 will be:</p>
<div class="codehilite"><pre><span></span><code>&lt;S&gt; Aston Martin V8 &lt;P&gt; assembly &lt;O&gt; United King-
dom &lt;S&gt; United Kingdom &lt;P&gt; capital &lt;O&gt; London
&lt;S&gt; Aston Martin V8 &lt;P&gt; successor &lt;O&gt; Aston Mar-
tin Virage &lt;S&gt; Aston Martin Virage &lt;P&gt; manufacturer
&lt;O&gt; Aston Martin
</code></pre></div>

<p>Finally, we use an LSTM to encode the plan obtained above. We choose LSTM because it excels at capturing sequential information.</p>
<h3>4.3 Decoding</h3>
<p>During decoding, we adopt an LSTM-based decoder with an attention and copy mechanism. Since we have two representations of the input triple-set: the original graph and the serialized plan, we adopt two strategies for inputting context to the decoder.</p>
<p>The first strategy is to only use hidden states of the plan encoder as context. We refer to this strategy as PlanENc.</p>
<p>While the serialized plan may contain some structural information, it cannot preserve all the information of the original graph. We therefore propose a second strategy, DuALENC, to incorporate the information from both the graph and the plan. More concretely, when calculating the context state $\mathbf{m}<em t-1="t-1">{t}$ of the LSTM decoder at time step $t$, we concatenate the previous hidden state $\mathbf{z}</em>}$ and the two context vectors $\mathbf{c<em t="t">{t}^{1}$ and $\mathbf{c}</em>$ as:}^{2}$, and then update the current hidden state, $\mathbf{z}_{t</p>
<p>$$
\begin{array}{r}
\mathbf{m}<em t-1="t-1">{t}=\operatorname{MLP}\left(\left[\mathbf{z}</em>} ; \mathbf{c<em t="t">{t}^{1} ; \mathbf{c}</em>\right]\right) \
\mathbf{z}}^{2<em t-1="t-1">{t}=\operatorname{LSTM}\left(\mathbf{z}</em>},\left[\left(\mathbf{y<em t="t">{t-1} ; \mathbf{m}</em>\right]\right)\right.
\end{array}
$$</p>
<p>where $\mathbf{c}<em t="t">{t}^{1}$ and $\mathbf{c}</em>}^{2}$ are the attention-based weighted sum of the context memories from GCN and RNN encoders, respectively, and $\mathbf{y<em 0="0">{t-1}$ is the embedding of the previously generated token. The initial hidden state $\mathbf{z}</em>$ of LSTM as the context representation. For the graph encoder, we use an average of all the hidden states following a two-layer perceptron to produce the final state.}$ is the summation of the final states from the two encoders. For the plan encoder, we use the final state $\mathbf{H}^{T</p>
<h2>5 Experiments</h2>
<p>We conduct experiments to evaluate our Planner (Section 5.2) and the overall generation system (Section 5.3). ${ }^{4}$</p>
<h3>5.1 Dataset</h3>
<p>We conduct experiments on the WebNLG dataset (Gardent et al., 2017; Castro Ferreira et al., 2018) used in the WebNLG challenge. ${ }^{5}$ For each instance, the input is a set of up to 7 RDF triples from DBPedia, and the output is their text descriptions. Each triple-set is paired with a set of (up to three) humangenerated reference texts. Each reference is also paired with the order of triples it realized. We use them to train and evaluate our Planner. Overall, the dataset contains 9,674 unique triple-sets and 25,298 text references, and is divided into training, development, and test set. The test set contains two subsets, the SEEN part where the instances belong to one of the nine domains that are seen in the training and development set (such as Astronaut and Food), and the UnSEEN part where the instances are from the other five unseen domains. The UnSEEN part is designed to evaluate models' generalizability to out-of-domain instances.</p>
<h3>5.2 Experiments on Plan Generation</h3>
<p>As previous work suggests, planning plays a crucial role in text generation. We, therefore, first investigate the performance of our planner.</p>
<h3>5.2.1 Setup</h3>
<p>During the graph encoding, we initialize the node embeddings with 100-dimensional random vectors. Our GCN model has two layers, with the hidden size of each layer as 100 . The activation function is ReLU (Nair and Hinton, 2010). We optimize the training objective using Adam (Kingma and Ba, 2015) with a learning rate of 0.001 and an early stopping on the development set. The batch size is 100. We compare our results with the following six baseline planners:</p>
<ul>
<li>Random: returns a random permutation of the input triples as a plan;</li>
<li>Structure-Random: returns a random traversal over the input graph. We report the highest score among three random strategies: random walk, random BFS, and random DFS;</li>
</ul>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>- Step-By-Step (Moryossef et al., 2019a): a transition-based statistical ranking method;
- Step-By-Step II (Moryossef et al., 2019b): a DFS-based method with a neural controller;
- GRU \&amp; Transformer (Ferreira et al., 2019): two neural Seq2Seq methods with attention;
We report the performance on three test sets: SEEN, UnSEEN, and All (SEEN \&amp; UnSEEN). We remove all one-triple instances for planner's evaluation since the planning for these instances is trivial. Results are evaluated with accuracy and BLEU-n (Papineni et al., 2002). For accuracy, we regard a plan as correct only if it exactly matches one of the human-generated plans. BLEU-n is more forgiving than accuracy. It is also adopted in Yao et al. (2019) for plan evaluation. Here we choose $n=2$.</p>
<h3>5.2.2 Results</h3>
<p>Table 1 shows results of the planning experiments. Our GCN method significantly outperforms all the baselines (approximate randomization (Noreen, 1989; Chinchor, 1992), $p&lt;0.05$ ) by a large margin on all the test sets and both measures, indicating the effectiveness of our planner. The most competitive baseline on All and UnSEEN sets is Step-By-Step, but our method is more time-efficient. For example, Step-By-Step needs 250 seconds to solve one 7-triple instance, but our method solves all 4928 instances in less than 10 seconds. For the SEEN set, the most competitive models are GRU and Transformer. However, while their accuracies drop by 0.46 on UnSEEN test set, our method drops only slightly by 0.02 , indicating our method's better generalization power.</p>
<p>We believe that this superior generalization capacity comes from the modeling of the graph structure. While the surface forms of triples in UnSEEN set do not overlap with those in the training data, the graph-level structural features are still shared, making it a key factor for generalization. GRU and Transformer linearize the graph as a sequential input, making them miss the structural information and resulting in poorer generalization capacity. Step-By-Step II also considers graph structure, but our model achieves better performance because we use GCN to encode the node representation, which can aggregate richer information from both the graph structure and the surface information.</p>
<p>We also investigated the effect of the graph size on the plan quality. In Figure 5, we separate the All test set into six subsets according to the size of input triple-sets, to reflect the model's capacity</p>
<table>
<thead>
<tr>
<th></th>
<th>Accuracy</th>
<th></th>
<th></th>
<th>BLEU-2</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>SEEN</td>
<td>UnSEEN</td>
<td>ALL</td>
<td>SEEN</td>
<td>UNSEEN</td>
<td>ALL</td>
</tr>
<tr>
<td>Random</td>
<td>0.28</td>
<td>0.34</td>
<td>0.31</td>
<td>54.1</td>
<td>62.1</td>
<td>57.9</td>
</tr>
<tr>
<td>Structure-random</td>
<td>0.32</td>
<td>0.38</td>
<td>0.34</td>
<td>56.6</td>
<td>62.9</td>
<td>59.5</td>
</tr>
<tr>
<td>Transformer (Ferreira et al., 2019)</td>
<td>0.56</td>
<td>0.09</td>
<td>0.34</td>
<td>74.3</td>
<td>20.9</td>
<td>49.3</td>
</tr>
<tr>
<td>GRU (Ferreira et al., 2019)</td>
<td>0.56</td>
<td>0.10</td>
<td>0.35</td>
<td>75.8</td>
<td>25.4</td>
<td>52.2</td>
</tr>
<tr>
<td>Step-By-Step II (Moryossef et al., 2019b)</td>
<td>0.45</td>
<td>0.44</td>
<td>0.44</td>
<td>67.7</td>
<td>67.3</td>
<td>67.5</td>
</tr>
<tr>
<td>Step-By-Step (Moryossef et al., 2019a)</td>
<td>0.49</td>
<td>0.44</td>
<td>0.47</td>
<td>73.2</td>
<td>68.0</td>
<td>70.8</td>
</tr>
<tr>
<td>GCN</td>
<td>$\mathbf{0 . 6 3}$</td>
<td>$\mathbf{0 . 6 1}$</td>
<td>$\mathbf{0 . 6 2}$</td>
<td>$\mathbf{8 0 . 8}$</td>
<td>$\mathbf{7 9 . 3}$</td>
<td>$\mathbf{8 0 . 1}$</td>
</tr>
</tbody>
</table>
<p>Table 1: Planning results of three test sets evaluated by accuracy and BLEU-2.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Fine-grained planning results for the ALL test set. Our method outperforms all the baselines regardless of the triple size.
at a fine-grained level. Fewer input triples make the planning task easier, while the 7-triple case is the most difficult one. The accuracy of seven out of eight baselines drops to around 0 in this case, while our method achieves an accuracy of 0.19 . Besides this, our method consistently outperforms all the baselines for all the triple-set sizes.</p>
<h3>5.3 Experiments on Text Generation</h3>
<p>This section investigates the ability of our models to improve the generation quality.</p>
<h3>5.3.1 Setup</h3>
<p>We implement the generator based on the OpenNMT toolkit. ${ }^{6}$ For the graph encoder, we use a similar setting as above. Since the generation task is more complicated than planning, we increase the dimension of the input and the hidden states to 256 . The plan encoder is a 2-layer bidirectional LSTM with the same dimension setting of the GCN to ease the information fusion. During encoding, for UnSEEN test set, we adopt delexicalization (Gardent et al., 2017) to enhance the model's generalizability to unseen domains.</p>
<p>We use Adam with a batch size of 64 . The initial learning rate is set to 0.001 and is decayed with a rate of 0.7 after the eighth epoch. We continue the</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>training until the perplexity of the development set does not decrease. We also apply dropout on the decoding output layer with a rate of 0.3 .</p>
<p>The quality of the generated text (as well as those of the baselines) is evaluated through a variety of automatic measures, such as BLEU, METEOR, and TER, which are strictly the same as those applied in the official challenge. ${ }^{7}$ Following Marcheggiani and Perez-Beltrachini (2018), we report averaged performances over ten runs of the models.</p>
<p>We compare our method with the top systems of the WebNLG challenge and published state-of-theart systems. The WebNLG systems are:</p>
<ul>
<li>ADAPT: a neural system with sub-word representations to deal with rare words and sparsity.</li>
<li>TILB-SMT: a statistical machine translation method using Moses and delexicalization.</li>
<li>MELBOURNE: a Seq2Seq model with enriched delexicalization from DBPedia.
The published research models are:</li>
<li>GTR-LSTM (Trisedya et al., 2018): a graphbased triple encoder;</li>
<li>GCN-EC (Marcheggiani and PerezBeltrachini, 2018): a GCN-based triple encoder with glove embedding and copy;</li>
<li>GRU \&amp; Transformer (Ferreira et al., 2019): two pipeline methods with 5 sequential steps and GRU or Transformer as the encoder;</li>
<li>STEP-BY-STEP (Moryossef et al., 2019a): a pipeline method that generates the text from plans with OpenNMT and a copy mechanism.</li>
</ul>
<h3>5.3.2 Qualitative Results</h3>
<p>Table 2 shows the results of the automatic evaluation on the generation task. Our PlanENC achieves the best performance on BLEU and TER, while DuALENC performs best under METEOR. Both PlanENC and DuALENC significantly out-</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">BLEU $(\uparrow)$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">METEOR $(\uparrow)$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">TER $(\downarrow)$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SEEN</td>
<td style="text-align: center;">Unseen</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">SEEN</td>
<td style="text-align: center;">Unseen</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">SEEN</td>
<td style="text-align: center;">Unseen</td>
<td style="text-align: center;">All</td>
</tr>
<tr>
<td style="text-align: center;">TILB-SMT</td>
<td style="text-align: center;">54.29</td>
<td style="text-align: center;">29.88</td>
<td style="text-align: center;">44.28</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.53</td>
</tr>
<tr>
<td style="text-align: center;">ADAPT</td>
<td style="text-align: center;">60.59</td>
<td style="text-align: center;">10.53</td>
<td style="text-align: center;">31.06</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">1.40</td>
<td style="text-align: center;">0.84</td>
</tr>
<tr>
<td style="text-align: center;">MELBOURNE</td>
<td style="text-align: center;">54.52</td>
<td style="text-align: center;">33.27</td>
<td style="text-align: center;">45.13</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.47</td>
</tr>
<tr>
<td style="text-align: center;">GTR-LSTM (2018)</td>
<td style="text-align: center;">54.00</td>
<td style="text-align: center;">29.20</td>
<td style="text-align: center;">37.10</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.55</td>
</tr>
<tr>
<td style="text-align: center;">GCN-EC (2018)</td>
<td style="text-align: center;">55.90</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">GRU (2019)</td>
<td style="text-align: center;">56.09</td>
<td style="text-align: center;">25.12</td>
<td style="text-align: center;">42.73</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.51</td>
</tr>
<tr>
<td style="text-align: center;">Transformer (2019)</td>
<td style="text-align: center;">56.28</td>
<td style="text-align: center;">23.04</td>
<td style="text-align: center;">42.41</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.50</td>
</tr>
<tr>
<td style="text-align: center;">Step-By-Step (2019a)</td>
<td style="text-align: center;">53.30</td>
<td style="text-align: center;">34.41</td>
<td style="text-align: center;">47.24</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.51</td>
</tr>
<tr>
<td style="text-align: center;">PlanENC</td>
<td style="text-align: center;">64.42</td>
<td style="text-align: center;">38.23</td>
<td style="text-align: center;">52.78</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.42</td>
</tr>
<tr>
<td style="text-align: center;">DualENC</td>
<td style="text-align: center;">63.45</td>
<td style="text-align: center;">36.73</td>
<td style="text-align: center;">51.42</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.44</td>
</tr>
</tbody>
</table>
<p>Table 2: Generation results evaluated by BLEU, METEOR, and TER. We compare our methods with different generation systems (SMT, Sequential NMT, Graph NMT, Pipeline). Both of our methods outperform all the baselines on all three measures. We highlight both results if there is no significant difference.
perform the previous state-of-the-art (bootstrapping (Koehn and Monz, 2006), $p&lt;0.05$ ). For the SEEN part, while no existing published work performed better than ADAPT, our PlanENC achieves a 3.83 performance gain on BLEU. It also outperforms the single GCN encoder by 8.52 BLEU , which confirms the advantage of the planning stage for bridging the structural gap between the encoder and decoder. For the UnSEEN part, PlanENC and DualENC improve BLEU by 3.82 and 2.32 compared with the previous state-of-the-art. While it is difficult to distinguish the performance of DuALENC and PlanENC by automatic measures, our human experiments (see Section 5.3.4) show that dual encoding generates better text compared with PlanENC.</p>
<p>When comparing with the pipeline methods, one difference from the data perspective is how to obtain the plans of each instance to train the planner. While Step-By-Step uses heuristic string matching to extract plans from the referenced sentences, other methods (GRU and transformer), as well as ours, use plans provided in the enriched WebNLG dataset (Castro Ferreira et al., 2018). However, Step-By-Step reported worse BLEU results on these plans.</p>
<h3>5.3.3 Ablation Study</h3>
<p>To further analyze what factors contribute to the performance gain, we conduct an ablation study by removing the following components:</p>
<ul>
<li>Copy mechanism: The text is generated without copying from the source;</li>
<li>Triple planning: The input triples are shuffled before feeding into RNN, but the $(s, p, o)$</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: center;">BLEU $(\uparrow)$</th>
<th style="text-align: center;">METEOR $(\uparrow)$</th>
<th style="text-align: center;">TER $(\downarrow)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PlanENC</td>
<td style="text-align: center;">$\mathbf{6 4 . 4 2} \pm 0.17$</td>
<td style="text-align: center;">$\mathbf{0 . 4 5} \pm 0.00$</td>
<td style="text-align: center;">$\mathbf{0 . 3 3} \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">-plan</td>
<td style="text-align: center;">$57.81 \pm 0.82$</td>
<td style="text-align: center;">$0.40 \pm 0.00$</td>
<td style="text-align: center;">$0.40 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">-copy</td>
<td style="text-align: center;">$61.64 \pm 0.53$</td>
<td style="text-align: center;">$0.43 \pm 0.01$</td>
<td style="text-align: center;">$0.36 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">-mention</td>
<td style="text-align: center;">$61.49 \pm 0.35$</td>
<td style="text-align: center;">$0.43 \pm 0.00$</td>
<td style="text-align: center;">$0.36 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">-delimiter</td>
<td style="text-align: center;">$63.26 \pm 0.33$</td>
<td style="text-align: center;">$0.44 \pm 0.00$</td>
<td style="text-align: center;">$0.34 \pm 0.00$</td>
</tr>
</tbody>
</table>
<p>Table 3: Results of the ablation study.
inside a triple are not shuffled.</p>
<ul>
<li>Entity mentions: We join the words in a node mention with underlines (e.g., Aston-Martin instead of Aston Martin).</li>
<li>Plan delimiter: We concatenate the $(s, p, o)$ without separating them with role delimiters.
We conduct the ablation study on the SEEN testset using our PlanENC. Table 3 shows the average performance and standard deviations. Compared with PlanENC, replacing plans with a random sequence of triples hurts the BLEU score by 6.61 points, indicating that the accuracy of planning is essential for the quality of generation. Our planning also makes the model more stable to random seeds (by decreasing the standard deviation from 0.82 to 0.17 ). Removing the copy mechanism also decreases the BLEU score by 2.78 points. It demonstrates the effectiveness of copying words from the source triples rather than generating them from the vocabulary set. Removing the mention information, decreases the BLEU score by 2.93. It reflects two benefits of word mentions: to alleviate data sparsity and to coordinate with the copy mechanism. However, removing delimiters does not affect the BLEU much. Intuitively, we expected the delimiters to</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Absolute(\%)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Pairwise(\%)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">CVGE FAITH</td>
<td style="text-align: center;">CVGE FAITH</td>
<td style="text-align: center;">FLCY</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">MELBOURNE</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">75.2</td>
<td style="text-align: center;">-35.0</td>
<td style="text-align: center;">-42.5</td>
<td style="text-align: center;">-38.8</td>
</tr>
<tr>
<td style="text-align: left;">STEP</td>
<td style="text-align: center;">$\mathbf{9 6 . 1}$</td>
<td style="text-align: center;">$\mathbf{8 9 . 3}$</td>
<td style="text-align: center;">$\mathbf{5 . 0}$</td>
<td style="text-align: center;">$\mathbf{- 3 . 7}$</td>
<td style="text-align: center;">-45.0</td>
</tr>
<tr>
<td style="text-align: left;">E2E-TRANS</td>
<td style="text-align: center;">85.5</td>
<td style="text-align: center;">78.0</td>
<td style="text-align: center;">-21.2</td>
<td style="text-align: center;">-32.5</td>
<td style="text-align: center;">-21.2</td>
</tr>
<tr>
<td style="text-align: left;">GCN</td>
<td style="text-align: center;">79.8</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">-48.7</td>
<td style="text-align: center;">-50.0</td>
<td style="text-align: center;">-26.3</td>
</tr>
<tr>
<td style="text-align: left;">PlanENC</td>
<td style="text-align: center;">$\mathbf{9 2 . 3}$</td>
<td style="text-align: center;">$\mathbf{8 8 . 2}$</td>
<td style="text-align: center;">$\mathbf{- 7 . 5}$</td>
<td style="text-align: center;">$\mathbf{- 1 2 . 5}$</td>
<td style="text-align: center;">$\mathbf{- 7 . 5}$</td>
</tr>
<tr>
<td style="text-align: left;">DUALENC</td>
<td style="text-align: center;">$\mathbf{9 4 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 8}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>Table 4: Results of human evaluation. DuALENC outperforms most of the baselines on all measures.
help the LSTM capture the boundaries and semantic roles of each node, but the ablation study does not support it. We provide an example in Table 5 to show that the LSTM indeed has trouble learning such semantic roles.</p>
<h3>5.3.4 Human Evaluation</h3>
<p>Automatic measures are based on lexical similarities and are not good measures of text quality in general. We therefore further conduct a human evaluation on Amazon Mechanical Turk to better access the quality of the generated texts. We evaluate the results for MELBOURNE, Step-By-Step, Transformer, GCN, as well as our PlanENC and DuALENC. We randomly select 80 test instances (440 triples in total) with the size of tripleset between 4 to 7 , since they are more challenging than those with fewer triples. Then we evaluate the generation quality of each system with the following three measures:</p>
<ul>
<li>Coverage: the percentage of triples that are covered by the generated text (all $<s, p, o>$ values in the triples are realized);</li>
<li>Faithfulness: the percentage of triples that are faithfully described by the text (the text correctly expresses the predicate and also the subject and object as its arguments. No substitutions or hallucinations);</li>
<li>Fluency: a measure of the fluency or naturalness of the generated text.
For coverage and faithfulness, workers are asked to check each triple of an instance, and judge whether the triple is covered and faithfully described by the generated text. For fluency, we ask another group of workers to compare between two outputs of the same instance and identify which one is more fluent. Table 5 shows examples where these qualities are compromised.</li>
</ul>
<p>In Table 4, we report the absolute scores of
coverage and faithfulness, which range from 0 to $100 \%$. We also provide pairwise scores of all three measures by comparing the outputs of DuALENC with each of the other five systems. We report the percentage of instances that were judged to be worse/better/same than those of DuALENC, yielding a score ranging from $-100 \%$ (unanimously worse) to $100 \%$ (unanimously better). For example, MELBOURNE performs better/worse/same than DuALENC for $10 \% / 45 \% / 45 \%$ of the instances, yielding a pairwise score as $10 \%-45 \%=-0.35 \%$. We also report an overall pairwise score combining all three measures. For each instance, the overall score of one output is higher than the other iff it outperforms the other on at least one of the three measures and has a better or equal vote on the other two.</p>
<p>Our PlanENC and DuALENC outperform most of the baselines on all of the measures by a large margin (approximate randomization, $p&lt;0.05$. ), which is consistent with the automatic results. The only exception is Step-By-Step, which has high Coverage and Faithfulness (not significant). It first separates the input triples into smaller subsets and then realizes them separately. This greatly reduces the difficulty of long-term generation but at the expense of Fluency (worst among all the baselines). GCN does not perform well on Coverage, which demonstrates that the structural gap between encoding and decoding indeed makes generation more difficult. However, it has the smallest difference between Coverage and Faithfulness among all the baselines, indicating that the fidelity of generation can benefit from the encoding of graph-level structural information. By combining GCN and PLANENC, our DuALENC incorporates the advantages of both encoders while ameliorating their weaknesses, and therefore achieves the best OVERALL performance on human evaluation.</p>
<h3>5.4 Qualitative Analysis</h3>
<p>Table 5 shows examples of generated texts by various systems for an input of six triples. Colored fonts represent missing, unfaithful, and unfluent information. For example, PlanENC misses "Buzz Aldrin" and also wrongly expresses the subject of "retirement" as "Frank Borman", indicating that LSTM is less powerful at capturing the semantic roles of entities. This disadvantage can be well complemented by GCN, which is designed to capture the graph structure and the relations between entities. Hence, by incorporating information from</p>
<p>| Tripleset | (William Anders | birthPlace | British Hong Kong), (William Anders | was a crew member of | Apollo 8), <br> (Apollo 8 | crewMembers | Frank Borman), (Apollo 8 | backup pilot | Buzz Aldrin), (Apollo 8 | operator | <br> NASA), (William Anders | dateOfRetirement | 1969-09-01) |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- |</p>
<p>Table 5: Sample texts generated by our methods and baselines, compared with a human-provided reference. We highlight in different color the [missing], unfaithful, and unfluent parts of each text. Only the results of our DuALENC correctly mention all the input triples.
both GCN and LSTM, DuALENC correctly expresses the subject argument of "retirement".</p>
<h2>6 Conclusion</h2>
<p>This paper proposes DuALENC, a dual encoding method to bridge the structural gap between encoder and decoder for data-to-text generation. We use GCN encoders to capture the structural information of the data, which is essential for accurate planning and faithful generation. We also introduce an intermediate content planning stage to serialize the data and then encode it with an LSTM network. This serialized plan is more compatible with the output sequence, making the information alignment between the input and output easier. Experiments on WebNLG dataset demonstrate the effectiveness of our planner and generator by outperforming the previous state-of-the-art by a large margin. Future work will validate the effectiveness of this method on more varied data-to-text generation tasks.</p>
<h2>References</h2>
<p>Daniel Beck, Gholamreza Haffari, and Trevor Cohn. 2018. Graph-to-sequence learning using gated graph neural networks. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 273-283.</p>
<p>Arianna Bisazza and Marcello Federico. 2016. A survey of word reordering in statistical machine translation: Computational models and language phenomena. Computational Linguistics, 42(2):163-205.</p>
<p>Thiago Castro Ferreira, Diego Moussallem, Sander Wubben, and Emiel Krahmer. 2018. Enriching the
webnlg corpus. In Proceedings of the 11th International Conference on Natural Language Generation, INLG'18, Tilburg, The Netherlands. Association for Computational Linguistics.</p>
<p>Nancy Chinchor. 1992. The statistical significance of the muc-4 results. In Proceedings of the 4th conference on Message understanding, pages 30-50. Association for Computational Linguistics.</p>
<p>Emilie Colin, Claire Gardent, Yassine M’rabet, Shashi Narayan, and Laura Perez-Beltrachini. 2016. The webnlg challenge: Generating text from dbpedia data. In Proceedings of the 9th International Natural Language Generation conference, pages 163167.</p>
<p>Marco Damonte and Shay B Cohen. 2019. Structural neural encoders for amr-to-text generation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 3649-3658.</p>
<p>Thiago Castro Ferreira, Chris van der Lee, Emiel van Miltenburg, and Emiel Krahmer. 2019. Neural data-to-text generation: A comparison between pipeline and end-to-end architectures. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 552-562.</p>
<p>Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. 2017. The webnlg challenge: Generating text from rdf data. In Proceedings of the 10th International Conference on Natural Language Generation, pages 124-133.</p>
<p>Zhijiang Guo, Yan Zhang, Zhiyang Teng, and Wei Lu. 2019. Densely connected graph convolutional networks for graph-to-sequence learning. Transactions of the Association for Computational Linguistics, 7:297-312.</p>
<p>Shizhu He, Cao Liu, Kang Liu, and Jun Zhao. 2017. Generating natural answers by incorporating copying and retrieving mechanisms in sequence-tosequence learning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 199208.</p>
<p>Xinyu Hua and Lu Wang. 2019. Sentence-level content planning and style specification for neural text generation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 591-602.</p>
<p>Juraj Juraska, Panagiotis Karagiannis, Kevin Bowden, and Marilyn Walker. 2018. A deep ensemble model with slot alignment for sequence-to-sequence natural language generation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages $152-162$.</p>
<p>Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.</p>
<p>Thomas N. Kipf and Max Welling. 2017. Semisupervised classification with graph convolutional networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings.</p>
<p>Philipp Koehn and Christof Monz. 2006. Manual and automatic evaluation of machine translation between european languages. In Proceedings on the Workshop on Statistical Machine Translation, pages 102121 .</p>
<p>Rémi Lebret, David Grangier, and Michael Auli. 2016. Neural text generation from structured data with application to the biography domain. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1203-1213.</p>
<p>Wei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, et al. 2019. Coherent comment generation for chinese articles with a graph-to-sequence model. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4843-4852.</p>
<p>Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. 2016. Gated graph sequence neural networks. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings.</p>
<p>Shuman Liu, Hongshen Chen, Zhaochun Ren, Yang Feng, Qun Liu, and Dawei Yin. 2018. Knowledge
diffusion for neural dialogue generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1489-1498.</p>
<p>Diego Marcheggiani and Laura Perez-Beltrachini. 2018. Deep graph convolutional encoders for structured data to text generation. In Proceedings of the 11th International Conference on Natural Language Generation, pages 1-9.</p>
<p>Seungwhan Moon, Pararth Shah, Anuj Kumar, and Rajen Subba. 2019. Opendialkg: Explainable conversational reasoning with attention-based walks over knowledge graphs. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 845-854.</p>
<p>Amit Moryossef, Yoav Goldberg, and Ido Dagan. 2019a. step-by-step: Separating planning from realization in neural data-to-text generation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2267-2277.</p>
<p>Amit Moryossef, Yoav Goldberg, and Ido Dagan. 2019b. improving quality and efficiency in planbased neural data-to-text generation. In Proceedings of the 12th International Conference on Natural Language Generation, pages 377-382.</p>
<p>Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10), pages 807-814.</p>
<p>Eric W Noreen. 1989. Computer-intensive methods for testing hypotheses. Wiley New York.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311-318. Association for Computational Linguistics.</p>
<p>Ratish Puduppully, Li Dong, and Mirella Lapata. 2019. Data-to-text generation with content selection and planning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6908-6915.</p>
<p>Lena Reed, Shereen Oraby, and Marilyn Walker. 2018. Can neural generators for dialogue learn sentence planning and discourse structuring? INLG 2018, page 284 .</p>
<p>Ehud Reiter and Robert Dale. 2000. Building natural language generation systems. Cambridge university press.</p>
<p>Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80.</p>
<p>Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference, pages 593-607. Springer.</p>
<p>Linfeng Song, Yue Zhang, Zhiguo Wang, and Daniel Gildea. 2018. A graph-to-sequence model for amr-to-text generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 16161626 .</p>
<p>Amanda Stent, Rashmi Prassad, and Marilyn Walker. 2004. Trainable sentence planning for complex information presentations in spoken dialog systems. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL04), pages $79-86$.</p>
<p>Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104-3112.</p>
<p>Bayu Distiawan Trisedya, Jianzhong Qi, Rui Zhang, and Wei Wang. 2018. Gtr-lstm: A triple encoder for sentence generation from rdf data. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 1627-1637.</p>
<p>Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. International Conference on Learning Representations. Accepted as poster.</p>
<p>Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight, Dongyan Zhao, and Rui Yan. 2019. Plan-and-write: Towards better automatic storytelling. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 7378-7385.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ https://github.com/OpenNMT/OpenNMT-py&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{7}$ That is why some of the numbers in our table are not exactly the same as those in the cited works.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>