<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-751 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-751</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-751</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-267759715</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.12715v4.pdf" target="_blank">The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning</a></p>
                <p><strong>Paper Abstract:</strong> Back in the early 20th century, a horse named Hans appeared to perform arithmetic and other intellectual tasks during exhibitions in Germany, while it actually relied solely on involuntary cues in the body language from the human trainer. Modern machine learning models are no different. These models are known to be sensitive to spurious correlations between non-essential features of the inputs (e.g., background, texture, and secondary objects) and the corresponding labels. Such features and their correlations with the labels are known as"spurious"because they tend to change with shifts in real-world data distributions, which can negatively impact the model's generalization and robustness. In this paper, we provide a comprehensive survey of this emerging issue, along with a fine-grained taxonomy of existing state-of-the-art methods for addressing spurious correlations in machine learning models. Additionally, we summarize existing datasets, benchmarks, and metrics to facilitate future research. The paper concludes with a discussion of the broader impacts, the recent advancements, and future challenges in the era of generative AI, aiming to provide valuable insights for researchers in the related domains of the machine learning community.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e751.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e751.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CaaM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Attention Module</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A causal-intervention module integrated into Vision Transformer architectures that self-annotates potential confounders in an unsupervised manner and seeks to mitigate their confounding effects on visual recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal attention for unbiased visual recognition</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Attention Module (CaaM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Integrates a causal attention mechanism into a Vision Transformer to identify and reduce influence of confounding features; uses unsupervised self-annotation to surface confounders and modulates attention to downweight confounding signals during representation learning.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Vision classification / image datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Standard vision classification benchmarks (static image datasets); not described as open-ended or interactive in the survey â€” applied to image recognition tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Self-annotation of confounders combined with attention modulation to reduce reliance on confounding visual features (attention-based reweighting).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding visual attributes (backgrounds, textures, spurious co-occurring objects).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Unsupervised self-annotation via the causal attention mechanism to surface likely confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Attention modulation within the transformer to reduce weight on identified confounding features.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey reports CaaM as an example of causal-intervention integrated into model architectures that can self-annotate and mitigate confounding effects in visual recognition, thereby aiming to reduce spurious background/texture reliance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e751.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal VQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Visual Question Answering (Causal VQA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semantic-editing-based causal intervention approach for VQA that reveals and mitigates spurious correlations by editing images/text along covariant/invariant axes and measuring model robustness to such edits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal VQA (semantic editing approach)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses semantic edits (counterfactual or covariant edits) to probe VQA models, revealing when models rely on spurious visual-text correlations; uses these edits to train or evaluate models for invariance to non-causal changes.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>VQA / multimodal question-answering datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Multimodal (image + question) evaluation settings; not interactive in the sense of active experimentation but supports semantic counterfactual edits to inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Semantic editing (counterfactual/covariant manipulation) to identify and break spurious vision-language associations.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Co-occurring visual/text cues, spurious cross-modal correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Apply invariant/covariant semantic edits and observe prediction changes to detect reliance on spurious cues.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Retraining or robustness evaluation on semantically edited data to reduce reliance on spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Counterfactual edits provide a form of refutation by demonstrating prediction change when putative non-causal features are altered.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Systematic semantic/counterfactual edits of image or text features to probe invariance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey highlights Causal VQA as a causal-intervention style method that assesses and reduces spurious vision-language correlations through semantic edits and counterfactual invariance tests.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e751.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Veitch counterfactual invariance</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Counterfactual Invariance (Veitch et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A principled criterion measuring whether model predictions are invariant to changes in irrelevant portions of inputs, used to evaluate whether models have captured causal structure rather than spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Counterfactual invariance to spurious correlations in text classification</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Counterfactual Invariance</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Defines and measures invariance of predictions under counterfactual edits to non-causal parts of a sample; if predictions change under edits that should be irrelevant, the model is relying on spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Text classification / general supervised tasks</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applies to datasets where counterfactual edits can be generated (text or other modalities); evaluation-style (diagnostic), not an interactive experimental lab per se.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Counterfactual editing to detect and then enforce invariance (diagnostic and training via counterfactual data).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Non-causal textual features, annotation artifacts, and other irrelevant portions of input.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Generate counterfactual versions of inputs and test for prediction changes to detect reliance on spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Train for invariance by including counterfactual examples or by penalizing prediction changes across edits.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Use counterfactual invariance checks to refute causal claims by showing predictions depend on altered non-causal features.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Systematic generation of counterfactuals to probe invariance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey presents counterfactual invariance as a way to evaluate causal structure in models and to detect/refute spurious reliance by checking prediction stability under edits to irrelevant parts of inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e751.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal Feature Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Feature Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method using a trained ERM classifier to extract core (causal) features from images and align features to reduce spurious background influence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal feature alignment: Learning to ignore spurious background features</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Feature Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses ERM classifier outputs to identify core features and align representations so that the model focuses on causal image content rather than spurious background signals, effectively separating core and spurious factors in representation space.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Image classification</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Static image datasets with background/foreground confounders; not interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Representation alignment / feature extraction to isolate and prioritize core (causal) features over spurious background features.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Background textures, co-occurring objects acting as spurious cues.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Use comparison of ERM classifier feature contributions to infer spurious vs core features.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Align or reweight representations towards extracted core features to reduce background influence.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey cites Causal Feature Alignment as a representation-level causal intervention that leverages ERM classifiers to isolate core features and reduce reliance on spurious backgrounds.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e751.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>De-confound-TDE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>De-confound TDE (Total Direct Effect)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A causal modeling approach that estimates and removes confounding effects (e.g., momentum in long-tailed classification) using causal decomposition techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>De-confound-TDE</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Applies causal modeling to decompose effects and identify confounding contributions, isolating the direct causal effect by adjusting for confounders in problems like long-tailed classification.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Long-tailed classification / general supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Static supervised tasks where confounding effects (e.g., momentum) can be modeled and adjusted; not interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Causal decomposition (estimating and removing confounding components such as momentum effects).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding variables, systemic biases like momentum effects in optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Causal model specification to identify confounders via structural assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Subtract or adjust confounding contributions (TDE estimation) to isolate causal signal.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey lists De-confound-TDE as an example of causal modeling used to pinpoint non-causal contributions and improve robustness in tasks affected by confounding dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e751.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MT-CRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Task Causal Representation Learning (MT-CRL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-task causal representation method that identifies causal structure across tasks and regularizes learning to prevent sharing of non-causal spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>MT-CRL</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Identifies causal relationships between tasks and uses that causal structure as a regularizer so that shared but non-causal spurious features across tasks are not exploited, improving robustness in multi-task settings.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multi-task learning settings</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Joint learning across multiple related tasks (static datasets); not necessarily interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Causal structure discovery across tasks and regularization to prevent reliance on shared spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Shared non-causal features across tasks, task-specific confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Discover causal structure between tasks (method specifics not detailed in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Regularization informed by discovered causal structure to reduce weight on shared spurious components.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey mentions MT-CRL as a causal-structure-aware approach to prevent multi-task models from exploiting spurious shared signals.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e751.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RaVL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RaVL (Region-aware Vision-Language mitigation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A region-aware loss method for fine-tuned vision-language models that identifies spurious co-occurring visual features via local image features and trains models to focus on non-spurious regions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Ravl: Discovering and mitigating spurious correlations in fine-tuned vision-language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>RaVL</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Creates a region-aware loss based on local image features to detect spurious co-occurring objects/regions and then trains the VLM to place more attention and predictive weight on regions that do not include those spurious indicators.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Vision-Language Models (VLM) fine-tuning / multimodal datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Fine-tuning scenarios for VLMs on paired vision-language datasets; not an interactive virtual lab but relevant to embodied settings when VLMs feed into agents.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Local-region feature analysis to detect spurious co-occurrences and region-aware loss to downweight/ignore spurious regions.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Co-occurring objects and local image regions that spuriously correlate with text/action labels.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Analysis of local image features to find regions indicative of spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Region-aware loss that encourages model to rely less on spurious regions and more on non-spurious regions.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey notes RaVL as an approach that uses local region cues to both detect spurious visual-text correlations and mitigate them by shifting model attention away from spurious regions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e751.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>InSpire</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intrinsic Spatial Reasoning (InSpire)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach for Vision-Language-Action models that extends textual inputs to inspire spatial reasoning and reduce reliance on spurious visual correlations when generating actions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Inspire: Visionlanguage-action models with intrinsic spatial reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>InSpire</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Augments VLA model inputs (text prompts) to include spatial reasoning cues so the model learns to rely on intrinsic spatial relationships rather than spurious co-occurring objects or textures that would otherwise drive incorrect action outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Vision-Language-Action (VLA) for embodied agents / robotic control</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive embodied-action environments where VLA outputs actions as text tokens to control agents; open-ended and interactive in the sense of sequential actions and environment interaction.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Augmenting inputs with spatial-reasoning prompts to encourage attention to causal spatial relations over spurious visual cues.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Task-irrelevant objects/textures and contextual co-occurrences that mislead action outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit â€” encourage model to attend to different (spatially relevant) tokens/features by modifying prompts/input structure.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey highlights InSpire as an input-level mitigation for VLA that reduces spurious correlations (e.g., approaching irrelevant objects) by inspiring spatial reasoning through extended textual inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e751.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PCD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Policy Contrastive Decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An inference-time method for robotic foundation models that shifts agent attention away from spurious visual cues to objective-relevant features, improving action selection robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Policy contrastive decoding for robotic foundation models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Policy Contrastive Decoding (PCD)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>At inference time, contrasts policy attentions between examples to transfer attention away from spurious cues and towards features more relevant to the task, thereby reducing spurious-driven actions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Robotic foundation models / embodied agent inference</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive inference for embodied agents (control/action generation) where model attention can be adjusted during decoding; operates at inference rather than training.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Inference-time attention transfer using contrastive comparisons to suppress spurious-region attention.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Task-irrelevant objects or textures that spuriously correlate with desired actions.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Contrastive attention transfer at decoding to downweight spurious attention patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey describes PCD as an inference-stage mechanism that can reallocate attention away from spurious cues for embodied agents, mitigating incorrect actions triggered by shortcuts in training data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e751.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RSC-MDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RSC-MDPs (Robust Spurious Correlation in MDPs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specialized method addressing spurious dependencies in reinforcement learning Markov Decision Processes to improve policy robustness against non-causal correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>RSC-MDP</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Targets spurious state-action correlations in RL by designing methods (architectural/training) tailored to MDPs that prevent policies from exploiting non-causal visual or state shortcuts.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Reinforcement learning / MDP environments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive sequential-decision environments where policies interact and can exploit spurious cues; supports active experimentation through policy rollouts.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Specialized RL-level interventions to prevent reliance on spurious state features (details not expanded in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious state or observation features correlated with reward or success in training but non-causal in deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey lists RSC-MDP as a specialized RL approach for addressing spurious dependencies in MDPs, highlighting the need for methods in sequential/interacting settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e751.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPARE / LLS / Evidential Alignment / FACTS / EvA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Identification-then-mitigation post-hoc methods (SPARE, LLS, Evidential Alignment, FACTS, EvA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of post-hoc methods that first identify bias-conflicting or spurious-indicated samples (via simplicity-bias signals, overconfidence, or latent feature probing) and then mitigate their influence through reweighting, importance sampling, or targeted tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Identification-then-mitigation (SPARE, LLS, Evidential Alignment, FACTS, EvA)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>These approaches detect spurious reliance via signals such as simplicity-bias, model overconfidence on biased examples, or latent feature probes; after detection they mitigate by reweighting/upweighting bias-conflicting samples, importance sampling, calibration, or slicing and targeted correction in representation space.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Pretrained classifiers / fine-tuning scenarios (vision, text, multimodal)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Post-training or fine-tuning environments where a pretrained model is available and can be probed and corrected; typically static datasets but applicable in fine-tuning for embodied agents too.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Identification via simplicity-bias signals, overconfidence, or latent probes; mitigation via importance sampling, reweighting, calibration, and targeted retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious correlations manifesting as easy-to-learn shortcuts, overconfident predictions on biased examples, and latent representation encodings of spuriosity.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Simplicity-bias analysis (e.g., identifying early-learned features), second-order risk minimization to find overconfident samples, latent feature probing and mixture-model slicing.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Importance sampling, sample reweighting, upsampling bias-conflicting examples, calibration-based tuning, and slice-specific correction.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey groups these methods as practical post-hoc pipelines: identify candidate spurious-influenced examples via model-centric signals, then mitigate using reweighting/finetuning/calibration; useful when full retraining or group labels are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e751.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e751.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mulchandani & Kim pruning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Data Pruning for Severing Spurious Correlations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pruning-based method that identifies a small subset of training examples responsible for spurious correlations and removes them to improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Data pruning to sever spurious correlations</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Finds and removes the small subset of examples that induce spurious correlations (via an identification mechanism described by the authors) to reduce the model's exposure to misleading shortcuts during training.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Supervised training datasets (vision/text)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Training-phase dataset curation/pruning; static datasets rather than interactive labs.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Data pruning/removal of identified spurious-inducing samples.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Samples that disproportionately encode spurious correlations; dataset artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Pruning technique that locates examples responsible for spurious correlations (survey does not detail exact detection algorithm).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Hard removal (pruning) or implicit downweighting by excluding examples from training.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey notes that spurious correlations often arise from a small subset of data and that pruning these examples can be an effective mitigation strategy, though details and limitations depend on the pruning method.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Causal attention for unbiased visual recognition <em>(Rating: 2)</em></li>
                <li>Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing <em>(Rating: 2)</em></li>
                <li>Ravl: Discovering and mitigating spurious correlations in fine-tuned vision-language models <em>(Rating: 2)</em></li>
                <li>Inspire: Visionlanguage-action models with intrinsic spatial reasoning <em>(Rating: 2)</em></li>
                <li>Policy contrastive decoding for robotic foundation models <em>(Rating: 2)</em></li>
                <li>Counterfactual invariance to spurious correlations in text classification <em>(Rating: 2)</em></li>
                <li>De-confound-TDE <em>(Rating: 1)</em></li>
                <li>Multi-Task Causal Representation Learning (MT-CRL) <em>(Rating: 1)</em></li>
                <li>Identifying spurious biases early in training through the lens of simplicity bias <em>(Rating: 1)</em></li>
                <li>Severing spurious correlations with data pruning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-751",
    "paper_id": "paper-267759715",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "CaaM",
            "name_full": "Causal Attention Module",
            "brief_description": "A causal-intervention module integrated into Vision Transformer architectures that self-annotates potential confounders in an unsupervised manner and seeks to mitigate their confounding effects on visual recognition.",
            "citation_title": "Causal attention for unbiased visual recognition",
            "mention_or_use": "mention",
            "method_name": "Causal Attention Module (CaaM)",
            "method_description": "Integrates a causal attention mechanism into a Vision Transformer to identify and reduce influence of confounding features; uses unsupervised self-annotation to surface confounders and modulates attention to downweight confounding signals during representation learning.",
            "environment_name": "Vision classification / image datasets",
            "environment_description": "Standard vision classification benchmarks (static image datasets); not described as open-ended or interactive in the survey â€” applied to image recognition tasks.",
            "handles_distractors": true,
            "distractor_handling_technique": "Self-annotation of confounders combined with attention modulation to reduce reliance on confounding visual features (attention-based reweighting).",
            "spurious_signal_types": "Confounding visual attributes (backgrounds, textures, spurious co-occurring objects).",
            "detection_method": "Unsupervised self-annotation via the causal attention mechanism to surface likely confounders.",
            "downweighting_method": "Attention modulation within the transformer to reduce weight on identified confounding features.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey reports CaaM as an example of causal-intervention integrated into model architectures that can self-annotate and mitigate confounding effects in visual recognition, thereby aiming to reduce spurious background/texture reliance.",
            "uuid": "e751.0",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Causal VQA",
            "name_full": "Causal Visual Question Answering (Causal VQA)",
            "brief_description": "A semantic-editing-based causal intervention approach for VQA that reveals and mitigates spurious correlations by editing images/text along covariant/invariant axes and measuring model robustness to such edits.",
            "citation_title": "Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing",
            "mention_or_use": "mention",
            "method_name": "Causal VQA (semantic editing approach)",
            "method_description": "Uses semantic edits (counterfactual or covariant edits) to probe VQA models, revealing when models rely on spurious visual-text correlations; uses these edits to train or evaluate models for invariance to non-causal changes.",
            "environment_name": "VQA / multimodal question-answering datasets",
            "environment_description": "Multimodal (image + question) evaluation settings; not interactive in the sense of active experimentation but supports semantic counterfactual edits to inputs.",
            "handles_distractors": true,
            "distractor_handling_technique": "Semantic editing (counterfactual/covariant manipulation) to identify and break spurious vision-language associations.",
            "spurious_signal_types": "Co-occurring visual/text cues, spurious cross-modal correlations.",
            "detection_method": "Apply invariant/covariant semantic edits and observe prediction changes to detect reliance on spurious cues.",
            "downweighting_method": "Retraining or robustness evaluation on semantically edited data to reduce reliance on spurious associations.",
            "refutation_method": "Counterfactual edits provide a form of refutation by demonstrating prediction change when putative non-causal features are altered.",
            "uses_active_learning": false,
            "inquiry_strategy": "Systematic semantic/counterfactual edits of image or text features to probe invariance.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey highlights Causal VQA as a causal-intervention style method that assesses and reduces spurious vision-language correlations through semantic edits and counterfactual invariance tests.",
            "uuid": "e751.1",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Veitch counterfactual invariance",
            "name_full": "Counterfactual Invariance (Veitch et al.)",
            "brief_description": "A principled criterion measuring whether model predictions are invariant to changes in irrelevant portions of inputs, used to evaluate whether models have captured causal structure rather than spurious associations.",
            "citation_title": "Counterfactual invariance to spurious correlations in text classification",
            "mention_or_use": "mention",
            "method_name": "Counterfactual Invariance",
            "method_description": "Defines and measures invariance of predictions under counterfactual edits to non-causal parts of a sample; if predictions change under edits that should be irrelevant, the model is relying on spurious signals.",
            "environment_name": "Text classification / general supervised tasks",
            "environment_description": "Applies to datasets where counterfactual edits can be generated (text or other modalities); evaluation-style (diagnostic), not an interactive experimental lab per se.",
            "handles_distractors": true,
            "distractor_handling_technique": "Counterfactual editing to detect and then enforce invariance (diagnostic and training via counterfactual data).",
            "spurious_signal_types": "Non-causal textual features, annotation artifacts, and other irrelevant portions of input.",
            "detection_method": "Generate counterfactual versions of inputs and test for prediction changes to detect reliance on spurious features.",
            "downweighting_method": "Train for invariance by including counterfactual examples or by penalizing prediction changes across edits.",
            "refutation_method": "Use counterfactual invariance checks to refute causal claims by showing predictions depend on altered non-causal features.",
            "uses_active_learning": false,
            "inquiry_strategy": "Systematic generation of counterfactuals to probe invariance.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey presents counterfactual invariance as a way to evaluate causal structure in models and to detect/refute spurious reliance by checking prediction stability under edits to irrelevant parts of inputs.",
            "uuid": "e751.2",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Causal Feature Alignment",
            "name_full": "Causal Feature Alignment",
            "brief_description": "A method using a trained ERM classifier to extract core (causal) features from images and align features to reduce spurious background influence.",
            "citation_title": "Causal feature alignment: Learning to ignore spurious background features",
            "mention_or_use": "mention",
            "method_name": "Causal Feature Alignment",
            "method_description": "Uses ERM classifier outputs to identify core features and align representations so that the model focuses on causal image content rather than spurious background signals, effectively separating core and spurious factors in representation space.",
            "environment_name": "Image classification",
            "environment_description": "Static image datasets with background/foreground confounders; not interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Representation alignment / feature extraction to isolate and prioritize core (causal) features over spurious background features.",
            "spurious_signal_types": "Background textures, co-occurring objects acting as spurious cues.",
            "detection_method": "Use comparison of ERM classifier feature contributions to infer spurious vs core features.",
            "downweighting_method": "Align or reweight representations towards extracted core features to reduce background influence.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey cites Causal Feature Alignment as a representation-level causal intervention that leverages ERM classifiers to isolate core features and reduce reliance on spurious backgrounds.",
            "uuid": "e751.3",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "De-confound-TDE",
            "name_full": "De-confound TDE (Total Direct Effect)",
            "brief_description": "A causal modeling approach that estimates and removes confounding effects (e.g., momentum in long-tailed classification) using causal decomposition techniques.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "De-confound-TDE",
            "method_description": "Applies causal modeling to decompose effects and identify confounding contributions, isolating the direct causal effect by adjusting for confounders in problems like long-tailed classification.",
            "environment_name": "Long-tailed classification / general supervised learning",
            "environment_description": "Static supervised tasks where confounding effects (e.g., momentum) can be modeled and adjusted; not interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Causal decomposition (estimating and removing confounding components such as momentum effects).",
            "spurious_signal_types": "Confounding variables, systemic biases like momentum effects in optimization.",
            "detection_method": "Causal model specification to identify confounders via structural assumptions.",
            "downweighting_method": "Subtract or adjust confounding contributions (TDE estimation) to isolate causal signal.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey lists De-confound-TDE as an example of causal modeling used to pinpoint non-causal contributions and improve robustness in tasks affected by confounding dynamics.",
            "uuid": "e751.4",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "MT-CRL",
            "name_full": "Multi-Task Causal Representation Learning (MT-CRL)",
            "brief_description": "A multi-task causal representation method that identifies causal structure across tasks and regularizes learning to prevent sharing of non-causal spurious features.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "MT-CRL",
            "method_description": "Identifies causal relationships between tasks and uses that causal structure as a regularizer so that shared but non-causal spurious features across tasks are not exploited, improving robustness in multi-task settings.",
            "environment_name": "Multi-task learning settings",
            "environment_description": "Joint learning across multiple related tasks (static datasets); not necessarily interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Causal structure discovery across tasks and regularization to prevent reliance on shared spurious features.",
            "spurious_signal_types": "Shared non-causal features across tasks, task-specific confounders.",
            "detection_method": "Discover causal structure between tasks (method specifics not detailed in survey).",
            "downweighting_method": "Regularization informed by discovered causal structure to reduce weight on shared spurious components.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey mentions MT-CRL as a causal-structure-aware approach to prevent multi-task models from exploiting spurious shared signals.",
            "uuid": "e751.5",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RaVL",
            "name_full": "RaVL (Region-aware Vision-Language mitigation)",
            "brief_description": "A region-aware loss method for fine-tuned vision-language models that identifies spurious co-occurring visual features via local image features and trains models to focus on non-spurious regions.",
            "citation_title": "Ravl: Discovering and mitigating spurious correlations in fine-tuned vision-language models",
            "mention_or_use": "mention",
            "method_name": "RaVL",
            "method_description": "Creates a region-aware loss based on local image features to detect spurious co-occurring objects/regions and then trains the VLM to place more attention and predictive weight on regions that do not include those spurious indicators.",
            "environment_name": "Vision-Language Models (VLM) fine-tuning / multimodal datasets",
            "environment_description": "Fine-tuning scenarios for VLMs on paired vision-language datasets; not an interactive virtual lab but relevant to embodied settings when VLMs feed into agents.",
            "handles_distractors": true,
            "distractor_handling_technique": "Local-region feature analysis to detect spurious co-occurrences and region-aware loss to downweight/ignore spurious regions.",
            "spurious_signal_types": "Co-occurring objects and local image regions that spuriously correlate with text/action labels.",
            "detection_method": "Analysis of local image features to find regions indicative of spurious correlations.",
            "downweighting_method": "Region-aware loss that encourages model to rely less on spurious regions and more on non-spurious regions.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey notes RaVL as an approach that uses local region cues to both detect spurious visual-text correlations and mitigate them by shifting model attention away from spurious regions.",
            "uuid": "e751.6",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "InSpire",
            "name_full": "Intrinsic Spatial Reasoning (InSpire)",
            "brief_description": "An approach for Vision-Language-Action models that extends textual inputs to inspire spatial reasoning and reduce reliance on spurious visual correlations when generating actions.",
            "citation_title": "Inspire: Visionlanguage-action models with intrinsic spatial reasoning",
            "mention_or_use": "mention",
            "method_name": "InSpire",
            "method_description": "Augments VLA model inputs (text prompts) to include spatial reasoning cues so the model learns to rely on intrinsic spatial relationships rather than spurious co-occurring objects or textures that would otherwise drive incorrect action outputs.",
            "environment_name": "Vision-Language-Action (VLA) for embodied agents / robotic control",
            "environment_description": "Interactive embodied-action environments where VLA outputs actions as text tokens to control agents; open-ended and interactive in the sense of sequential actions and environment interaction.",
            "handles_distractors": true,
            "distractor_handling_technique": "Augmenting inputs with spatial-reasoning prompts to encourage attention to causal spatial relations over spurious visual cues.",
            "spurious_signal_types": "Task-irrelevant objects/textures and contextual co-occurrences that mislead action outputs.",
            "detection_method": null,
            "downweighting_method": "Implicit â€” encourage model to attend to different (spatially relevant) tokens/features by modifying prompts/input structure.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey highlights InSpire as an input-level mitigation for VLA that reduces spurious correlations (e.g., approaching irrelevant objects) by inspiring spatial reasoning through extended textual inputs.",
            "uuid": "e751.7",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "PCD",
            "name_full": "Policy Contrastive Decoding",
            "brief_description": "An inference-time method for robotic foundation models that shifts agent attention away from spurious visual cues to objective-relevant features, improving action selection robustness.",
            "citation_title": "Policy contrastive decoding for robotic foundation models",
            "mention_or_use": "mention",
            "method_name": "Policy Contrastive Decoding (PCD)",
            "method_description": "At inference time, contrasts policy attentions between examples to transfer attention away from spurious cues and towards features more relevant to the task, thereby reducing spurious-driven actions.",
            "environment_name": "Robotic foundation models / embodied agent inference",
            "environment_description": "Interactive inference for embodied agents (control/action generation) where model attention can be adjusted during decoding; operates at inference rather than training.",
            "handles_distractors": true,
            "distractor_handling_technique": "Inference-time attention transfer using contrastive comparisons to suppress spurious-region attention.",
            "spurious_signal_types": "Task-irrelevant objects or textures that spuriously correlate with desired actions.",
            "detection_method": null,
            "downweighting_method": "Contrastive attention transfer at decoding to downweight spurious attention patterns.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey describes PCD as an inference-stage mechanism that can reallocate attention away from spurious cues for embodied agents, mitigating incorrect actions triggered by shortcuts in training data.",
            "uuid": "e751.8",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RSC-MDP",
            "name_full": "RSC-MDPs (Robust Spurious Correlation in MDPs)",
            "brief_description": "A specialized method addressing spurious dependencies in reinforcement learning Markov Decision Processes to improve policy robustness against non-causal correlations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "RSC-MDP",
            "method_description": "Targets spurious state-action correlations in RL by designing methods (architectural/training) tailored to MDPs that prevent policies from exploiting non-causal visual or state shortcuts.",
            "environment_name": "Reinforcement learning / MDP environments",
            "environment_description": "Interactive sequential-decision environments where policies interact and can exploit spurious cues; supports active experimentation through policy rollouts.",
            "handles_distractors": true,
            "distractor_handling_technique": "Specialized RL-level interventions to prevent reliance on spurious state features (details not expanded in survey).",
            "spurious_signal_types": "Spurious state or observation features correlated with reward or success in training but non-causal in deployment.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey lists RSC-MDP as a specialized RL approach for addressing spurious dependencies in MDPs, highlighting the need for methods in sequential/interacting settings.",
            "uuid": "e751.9",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "SPARE / LLS / Evidential Alignment / FACTS / EvA",
            "name_full": "Identification-then-mitigation post-hoc methods (SPARE, LLS, Evidential Alignment, FACTS, EvA)",
            "brief_description": "A class of post-hoc methods that first identify bias-conflicting or spurious-indicated samples (via simplicity-bias signals, overconfidence, or latent feature probing) and then mitigate their influence through reweighting, importance sampling, or targeted tuning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Identification-then-mitigation (SPARE, LLS, Evidential Alignment, FACTS, EvA)",
            "method_description": "These approaches detect spurious reliance via signals such as simplicity-bias, model overconfidence on biased examples, or latent feature probes; after detection they mitigate by reweighting/upweighting bias-conflicting samples, importance sampling, calibration, or slicing and targeted correction in representation space.",
            "environment_name": "Pretrained classifiers / fine-tuning scenarios (vision, text, multimodal)",
            "environment_description": "Post-training or fine-tuning environments where a pretrained model is available and can be probed and corrected; typically static datasets but applicable in fine-tuning for embodied agents too.",
            "handles_distractors": true,
            "distractor_handling_technique": "Identification via simplicity-bias signals, overconfidence, or latent probes; mitigation via importance sampling, reweighting, calibration, and targeted retraining.",
            "spurious_signal_types": "Spurious correlations manifesting as easy-to-learn shortcuts, overconfident predictions on biased examples, and latent representation encodings of spuriosity.",
            "detection_method": "Simplicity-bias analysis (e.g., identifying early-learned features), second-order risk minimization to find overconfident samples, latent feature probing and mixture-model slicing.",
            "downweighting_method": "Importance sampling, sample reweighting, upsampling bias-conflicting examples, calibration-based tuning, and slice-specific correction.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey groups these methods as practical post-hoc pipelines: identify candidate spurious-influenced examples via model-centric signals, then mitigate using reweighting/finetuning/calibration; useful when full retraining or group labels are unavailable.",
            "uuid": "e751.10",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Mulchandani & Kim pruning",
            "name_full": "Data Pruning for Severing Spurious Correlations",
            "brief_description": "A pruning-based method that identifies a small subset of training examples responsible for spurious correlations and removes them to improve robustness.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Data pruning to sever spurious correlations",
            "method_description": "Finds and removes the small subset of examples that induce spurious correlations (via an identification mechanism described by the authors) to reduce the model's exposure to misleading shortcuts during training.",
            "environment_name": "Supervised training datasets (vision/text)",
            "environment_description": "Training-phase dataset curation/pruning; static datasets rather than interactive labs.",
            "handles_distractors": true,
            "distractor_handling_technique": "Data pruning/removal of identified spurious-inducing samples.",
            "spurious_signal_types": "Samples that disproportionately encode spurious correlations; dataset artifacts.",
            "detection_method": "Pruning technique that locates examples responsible for spurious correlations (survey does not detail exact detection algorithm).",
            "downweighting_method": "Hard removal (pruning) or implicit downweighting by excluding examples from training.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey notes that spurious correlations often arise from a small subset of data and that pruning these examples can be an effective mitigation strategy, though details and limitations depend on the pruning method.",
            "uuid": "e751.11",
            "source_info": {
                "paper_title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Causal attention for unbiased visual recognition",
            "rating": 2,
            "sanitized_title": "causal_attention_for_unbiased_visual_recognition"
        },
        {
            "paper_title": "Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing",
            "rating": 2,
            "sanitized_title": "towards_causal_vqa_revealing_and_reducing_spurious_correlations_by_invariant_and_covariant_semantic_editing"
        },
        {
            "paper_title": "Ravl: Discovering and mitigating spurious correlations in fine-tuned vision-language models",
            "rating": 2,
            "sanitized_title": "ravl_discovering_and_mitigating_spurious_correlations_in_finetuned_visionlanguage_models"
        },
        {
            "paper_title": "Inspire: Visionlanguage-action models with intrinsic spatial reasoning",
            "rating": 2,
            "sanitized_title": "inspire_visionlanguageaction_models_with_intrinsic_spatial_reasoning"
        },
        {
            "paper_title": "Policy contrastive decoding for robotic foundation models",
            "rating": 2,
            "sanitized_title": "policy_contrastive_decoding_for_robotic_foundation_models"
        },
        {
            "paper_title": "Counterfactual invariance to spurious correlations in text classification",
            "rating": 2,
            "sanitized_title": "counterfactual_invariance_to_spurious_correlations_in_text_classification"
        },
        {
            "paper_title": "De-confound-TDE",
            "rating": 1,
            "sanitized_title": "deconfoundtde"
        },
        {
            "paper_title": "Multi-Task Causal Representation Learning (MT-CRL)",
            "rating": 1,
            "sanitized_title": "multitask_causal_representation_learning_mtcrl"
        },
        {
            "paper_title": "Identifying spurious biases early in training through the lens of simplicity bias",
            "rating": 1,
            "sanitized_title": "identifying_spurious_biases_early_in_training_through_the_lens_of_simplicity_bias"
        },
        {
            "paper_title": "Severing spurious correlations with data pruning",
            "rating": 1,
            "sanitized_title": "severing_spurious_correlations_with_data_pruning"
        }
    ],
    "cost": 0.0220885,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning
1 Oct 2025</p>
<p>Wenqian Ye 
University of Virginia</p>
<p>Luyang Jiang 
Purdue University</p>
<p>Eric Xie 
University of Virginia</p>
<p>Guangtao Zheng 
University of Virginia</p>
<p>Yunsheng Ma 
Purdue University</p>
<p>Xu Cao 
University of Illinois Urbana-Champaign</p>
<p>Dongliang Guo 
University of Virginia</p>
<p>Daiqing Qi 
University of Virginia</p>
<p>Zeyu He 
Pennsylvania State University</p>
<p>Yijun Tian 
Megan Coffee 
New York University</p>
<p>Zhe Zeng 
University of Virginia</p>
<p>Sheng Li 
University of Virginia</p>
<p>Kenneth Huang 
Pennsylvania State University</p>
<p>Ziran Wang 
Purdue University</p>
<p>James M Rehg 
University of Illinois Urbana-Champaign</p>
<p>Henry Kautz 
University of Virginia</p>
<p>Aidong Zhang 
University of Virginia</p>
<p>The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning
1 Oct 2025BF96827EA78DDB4F84C64CAEB5BA91E0arXiv:2402.12715v4[cs.LG]
Back in the early 20th century, a horse named Hans appeared to perform arithmetic and other intellectual tasks during exhibitions in Germany, while it actually relied solely on involuntary cues in the body language from the human trainer.Modern machine learning models are no different.These models are known to be sensitive to spurious correlations between non-essential features of the inputs (e.g., background, texture, and secondary objects) and the corresponding labels.Such features and their correlations with the labels are known as "spurious" because they tend to change with shifts in real-world data distributions, which can negatively impact the model's generalization and robustness.In this paper, we provide a comprehensive survey of this emerging issue, along with a fine-grained taxonomy of existing state-of-the-art methods for addressing spurious correlations in machine learning models.Additionally, we summarize existing datasets, benchmarks, and metrics to facilitate future research.The paper concludes with a discussion of the broader impacts, the recent advancements, and future challenges in the era of generative AI, aiming to provide valuable insights for researchers in the related domains of the machine learning community.</p>
<p>Introduction</p>
<p>While machine learning (ML) systems have achieved remarkable strides, distribution shifts and adversarial examples have become critical issues (Taori et al., 2020).It is increasingly evident that one of the major causes behind these issues is the severe reliance on spurious correlations between superficial features of the inputs (e.g., background, texture, and secondary objects) and the corresponding labels.When these correlations captured during training no longer hold in the test data, the performance of ML models deteriorates, leading to robustness issues and negative social impact in critical domains such as healthcare.For instance, studies in pneumonia detection with Convolutional Neural Networks (CNNs) have shown that the models often depend on extraneous cues, like metal tokens in chest X-ray scans from different hospitals, instead of learning the actual pathological features of the disease (Kirichenko et al., 2023;Zech et al., 2018).Therefore, addressing spurious correlations is of vital importance.</p>
<p>In recent years, spurious correlations have been referred to under various terms, such as shortcut learning, group robustness, and simplicity bias.Significant progress has been made in both detecting and mitigating these phenomena in fields such as computer vision (Wang et al., 2021;Yang et al., 2022b), natural language processing (Du et al., 2022b), and healthcare (Huang et al., 2022).Despite these advances, a comprehensive survey that formally defines spurious correlations and systematically reviews associated learning algorithms and challenges has yet to be published.</p>
<p>In this paper, we present the first comprehensive survey on spurious correlations, providing a formal definition, a taxonomy of current state-of-the-art methods for addressing spurious correlations in machine learning models, and an overview of relevant datasets, benchmarks, and evaluation metrics.We further discuss future research challenges and explore the potential role of foundation models in mitigating the adverse effects of spurious correlations.We hope this survey serves as a comprehensive reference and inspires further research in robust machine learning.</p>
<p>Spurious Correlations</p>
<p>Figure 1: An illustration of the Clever Hans effect as an analogy for spurious correlations in machine learning.Just as Clever Hans appeared to solve arithmetic problems by responding to subtle cues from his trainer, machine learning models can achieve high accuracy by exploiting spurious features, e.g., associating grass with cows rather than learning true underlying concepts.(Image generated by  In statistics, spurious correlation, namely "correlations that do not imply causation," refers to two variables that appear related to each other, but their true relationship is either coincidental or confounded by an external variable.This phenomenon leads to misleading or incorrect interpretations of data and models.</p>
<p>A classic historical analogy is Clever Hans (Figure 1), a horse in early 20th-century Germany that drew worldwide attention for performing arithmetic and other intellectual tasks (Lapuschkin et al., 2019).However, Hans did not actually understand these concepts; instead, he responded based on subtle, unintentional cues in his trainer's posture.Today, machine learning agents tend to exhibit similar behavior, relying on non-semantic, spurious features that correlate with the correct answer during training, but fail to generalize to broader or shifted distributions.We first give a formal definition.Definition 2.1 (Spurious Correlation).Let D tr = {(x i , y i )} n i=1 be the training set with x i âˆˆ X and y i âˆˆ Y, where X denotes the set of all possible inputs and Y denotes the set of K classes.For each data point x i with class label y i , there exists a spurious attribute a i âˆˆ A that is non-predictive of y i , where A denotes the set of all possible spurious attributes.A spurious correlation, denoted as âŸ¨y, aâŸ©, is the association between y âˆˆ Y and a âˆˆ A, where y and a exist in a one-to-many mapping Ï• : A â†’ Y K â€² conditioned on D tr (with 1 &lt; K â€² â‰¤ K).A set of data exhibiting the spurious correlation âŸ¨y, aâŸ© is annotated with the group label g = (y, a), where G := Y Ã—A is the set of combinations of class labels and spurious attributes.</p>
<p>For example, in the training set D tr , one might observe two spurious correlations, âŸ¨y, aâŸ© and âŸ¨y â€² , aâŸ©, meaning that the same spurious attribute a appears in two classes.A model trained on D tr might simply use a to predict y, which would lead to incorrect predictions on samples with the correlation âŸ¨y â€² , aâŸ©.This failure to generalize across environments due to reliance on a is visualized in Figure 2, where a spurious correlation between background and label (e.g., cows appearing on green grass) breaks under an environment shift (e.g., cows in the desert), while the true label remains unchanged.</p>
<p>Where do Spurious Correlations Come From?</p>
<p>Spurious correlations often stem from selection biases in datasets.Datasets with limited data are often underspecified, such that multiple plausible hypotheses can describe the data equally well; following Occam's Razor, the simplest hypothesis may be preferred even if it relies on spurious patterns.This tendency reflects a more general phenomenon known as simplicity bias, where models develop an over-reliance on highly available but less predictive features, as opposed to less available but highly predictive features (Hermann et al., 2023).Moreover, imbalanced group labels can lead to over-representation of certain groups, causing the model to depend on correlations that do not hold for minority groups.Finally, sampling noise-i.e., random variations inherent in collected samples-can cause the dataset to misrepresent the true data distribution, leading the model to interpret noise as a meaningful correlation.</p>
<p>Why Are Machine Learning Models Sensitive to Spurious Correlations?</p>
<p>Inductive Biases from Learning Algorithms.The "no free lunch" theorem underscores that no single model is universally optimal and that each model incorporates an inductive bias (i.e., a set of assumptions about unseen data) that influences its predictions (Wolpert &amp; Macready, 1997).For example, CNNs are inherently biased toward local connectivity and spatial invariance-properties that are suitable for image data.However, when the training data is biased, such inductive biases may lead the model to latch onto spurious patterns, resulting in overfitting and poor generalization.</p>
<p>Optimization.In the classical Empirical Risk Minimization (ERM) framework (Vapnik, 1991), let a sample (x, y, a) be drawn from a distribution conditioned on a group label g = (y, a).Given a model with parameters Î¸, denoted f Î¸ : X â†’ R K , and a loss function â„“ : R K Ã— Y â†’ R (e.g., softmax cross-entropy), the training objective is to minimize
L avg (f Î¸ ) := E gâˆ¼Pg E (x,y,a)âˆ¼P x|g [â„“(f Î¸ (x), y)]. (1)
Because the optimization process does not take the spurious attribute a into account, if there is a strong correlation between y and a, the model may learn to rely on a when predicting y.In testing scenarios where the correlation does not hold, this reliance results in poor performance.It has been shown that models trained via ERM exhibit high worst-group errors, as measured by
L wg (f Î¸ ) := max gâˆˆG E (x,y,a)âˆ¼P x|g [â„“(f Î¸ (x), y)].
(2)</p>
<p>Methods such as Group DRO (Sagawa et al., 2019a) have been proposed to mitigate this effect by modifying the training objective to minimize the training loss within the worst-performing groups.</p>
<p>Theoretical Insights</p>
<p>Recent theoretical works have expanded our understanding of how spurious correlations emerge and persist within the latent space.Analyzing the latent space of a model can reveal how core and spurious features interact during training.The presence of spurious correlations alters not only what features are learned, but also the temporal dynamics of learning.Models often embed spurious features early during the training process due to their simplicity or strong correlation with the label.If we denote the learned representation of an input x as Ï•(x), then during early training, the model's prediction for class y often satisfies:
âŸ¨Ï•(x), w y âŸ© â‰ˆ âŸ¨Ï•(a), w y âŸ© â‰« âŸ¨Ï•(x c ), w y âŸ©,(3)
assuming our input x can be decomposed into core features x c and spurious feature a, i.e., x = (x c , a). w y is the classifier weight vector for class y.The model's prediction relies on a instead of x c when minimizing L avg because a provides a more immediately predictive signal for y in the training distribution.Not only does this delay the learning of core features, remnants of Ï•(a) are retained in the representation space even as generalizable features are eventually learned (Qiu et al., 2024).Late-stage learning can even reinforce simplified representations that encode spurious patterns (Tsoy &amp; Konstantinov, 2024).</p>
<p>Building on this, Bombari &amp; Mondelli (2023) demonstrates that the degree of memorization of a spurious correlation can be geometrically characterized by the feature alignment between the spurious pattern and the training sample within the learned representation.Subsequent studies have challenged the reliability of post-hoc mitigation strategies.For instance, in two-agent rationale-predictor settings, spurious cues can originate from the rationale generator rather than the dataset (Liu et al., 2025a), while the effectiveness of regularization methods highly depends on the alignment between spurious attributes and both known and unknown concepts, as regularizers can suppress useful signals when concept correlations are entangled (Hong et al., 2025).Together, these works characterize spurious correlations as a structural and persistent phenomenon within the learned representation that indirectly results from the training objective.</p>
<p>Related Areas</p>
<p>We provide an overview of research fields closely related to spurious correlations, offering a broader context and complementary perspectives.Domain Generalization is a wider goal that aims to improve model performance on unseen distributions, and it often fails when models rely on spurious correlations that do not hold across domains.Group Robustness focuses on ensuring consistent performance across subgroups, and spurious correlations that vary between groups can cause severe performance drops in minority groups.Shortcut Learning arises when models exploit spurious correlations as easy-to-learn signals instead of capturing the underlying causal features.Simplicity Bias leads models to favor spurious correlations because they often correspond to low-complexity patterns that are easier to optimize.We discuss each term as follows.</p>
<p>Domain Generalization.Also known as out-of-distribution (OOD) generalization, domain generalization aims to train models on one or more related domains such that they generalize well to unseen test domains (Wang et al., 2023).However, spurious correlations are a significant threat to domain generalization (Yang et al., 2022a).The core challenge in DG arises because models can easily learn features that are predictive in the source domain but become unreliable or irrelevant in a new, unseen target domain.These learned, non-causal associations are spurious correlations.</p>
<p>The relationship between DG and spurious correlation is inverse and adversarial.The success of any DG method is contingent on its ability to avoid or mitigate spurious correlations.For instance, in Multi-Source Domain Generalization (MSDG) (Li et al., 2018;Ahuja et al., 2021;Gulrajani &amp; Lopez-Paz, 2020;Zhu et al., 2024), a model might learn a feature that happens to be correlated with a label across several, but not all, possible domains.While this feature may improve performance on the available source data, it is a spurious shortcut that will likely fail on a target domain where the correlation does not exist.The problem is even more acute in Single Domain Generalization (SDG) (Li et al., 2021;Wan et al., 2022;Ilke et al., 2022;Guo et al.), where the model has even less data diversity to learn from, making it highly susceptible to latching onto spurious features specific to that one domain.</p>
<p>Group Robustness.Group robustness methods seek to ensure a model performs consistently well across different predefined groups or subpopulations (Yang et al., 2023c) in the data, rather than achieving high overall accuracy at the expense of minority groups (Sagawa et al., 2019a).This concept is closely related to fairness and worst-case optimization: if a model latches onto a spurious feature that is prevalent in a majority group, its performance can degrade sharply on a minority group where that correlation does not hold.Spurious correlations often manifest as such group-dependent performance gaps.For instance, in the Waterbirds dataset (Sagawa et al., 2020b), a bird classification model may learn to associate "water background" with the label waterbird (since most training images of waterbirds have water in the background), which leads to poor accuracy on the minority group of waterbirds on land.Group robustness techniques address this by actively discouraging the model from exploiting these group-specific shortcuts.One prominent approach is Group Distributionally Robust Optimization (Group DRO), which minimizes the worst-case loss over all groups rather than the average loss (Sagawa et al., 2020b).By focusing on the worst-performing group during training, the model is pushed to learn features that work for all groups, thereby reducing its reliance on spurious cues present only in the majority group.Follow-up research has proposed various improvements, such as up-weighting under-represented group examples or using two-stage training to identify and then rectify bias against minority groups (Liu et al., 2021;Idrissi et al., 2022) Shortcut Learning.Shortcut learning refers to this phenomenon where models rely on spurious correlations (often easier to learn) as opposed to the more relevant but complex features.These shortcuts are essentially spurious correlations that hold in the training set.For example, a vision model might classify images by background or texture instead of recognizing the animal itself, a classic Clever Hans behavior that breaks when the context changes.Empirical studies have shown that ImageNet-trained convolutional networks tend to prefer texture over object shape as a recognition cue, which is one type of shortcut.This bias leads to poor generalization on shape-distorted images or domain-shifted images (Geirhos et al., 2020).In NLP, a model might learn to rely on the presence of specific keywords as a shortcut for sentiment or entailment, rather than truly understanding language, causing errors on examples where those keywords appear in an unrelated context (Du et al., 2022a).Shortcut learning is particularly pernicious under standard ERM training because the learner will gravitate to any discriminative feature that improves training accuracy, without regard for causal relevance.Research in this area often evaluates models on "counterfactually" adjusted or stress-test datasets.For instance, testing the camel vs. cow classifier on images where camels appear on grass or cows on sand reveals the shortcut reliance.Approaches to mitigate shortcut learning overlap with those for spurious correlation in general, including data augmentation to break the spurious association, specialized training objectives, or interpretability-driven methods to detect when a model focuses on the wrong features.In summary, shortcut learning encapsulates the model's temptation to "cheat" by using easy correlations, underscoring why robust evaluation beyond the i.i.d.test set is crucial for detecting spurious reasoning.</p>
<p>Simplicity Bias.Simplicity bias (SB) is the tendency of deep neural networks (especially when trained with standard gradient-based optimization) to preferentially learn simple patterns or heuristics first, often to the exclusion of more complex but relevant features (Shah et al., 2020).In other words, given multiple predictive signals in the data, networks biased by simplicity will latch onto the easiest-to-fit signal (e.g., a low-level texture or an easily segregated background color) before considering more intricate structures (like shape combinations or abstract relations).This bias provides a fundamental reason why spurious correlations can dominate a model's predictions: if a spurious feature offers a simpler decision rule that fits the training data (even if it's not fundamentally causal), the model is likely to adopt it due to SB. Shah et al. (2020) demonstrates that neural nets can indeed entirely ignore more informative features and instead rely on a less informative but simpler feature, resulting in poor generalization whenever the simple feature's correlation with the label changes.In the context of spurious correlations, SB means the model might, for example, focus on background scenery to classify objects because backgrounds are simpler to learn (roughly uniform for each class), even if object-specific features would be more reliable outside the training distribution (Tiwari &amp; Shenoy, 2023).This predisposition is closely linked with the model's vulnerability to distribution shifts and even adversarial perturbations: a network that heavily relies on a few simple features can be brittle, as small input changes can disrupt those features.UV-DRO (Srivastava et al., 2020), Nuisances via Negativa (Puli et al., 2022), Counterfactual Generator (Zeng et al., 2020) (Wang &amp; Culotta, 2021), LISA (Yao et al., 2022), FedGR (Yue et al., 2024), Decompose-and-Compose (Noohdani et al., 2024) Data Balancing ( Â§4.1.2)Balanced Greedy Sampling (Lee et al., 2024), Reweighting (Li et al., 2025) (Cui et al., 2024), Mixture balancing (LaBonte et al., 2024), Subsampling (Sagawa et al., 2020a) Concept and Pseudo-label Discovery ( Â§4.1.3)DISC (Wu et al., 2023a), SSA (Nam et al., 2022), CoBalT (Arefin et al., 2024), RoboShot (Adila et al., 2023) Representation Learning ( Â§4.2)</p>
<p>Causal Intervention ( Â§4.2.1)</p>
<p>CaaM (Wang et al., 2021), Causal VQA (Agarwal et al., 2020), TIE (Lu et al., 2025), Counterfactual invariance (Veitch et al., 2021), Causal Feature Alignment (Venkataramani et al., 2024), De-confound-TDE (Tang et al., 2020), MT-CRL (Hu et al., 2022), Latent Causal Invariance Models (LaCIM) (Sun et al., 2021) Invariant Learning ( Â§4.2.2)</p>
<p>IRM (Arjovsky et al., 2019b;Rosenfeld et al., 2021), REx (Krueger et al., 2021), EIIL (Creager et al., 2021), SCILL (Chen et al., 2022), SFB (Eastwood et al., 2023), ElRep (Wen et al., 2025), DropTop (Kim et al., 2024a), Position ID manipulation (Wang et al., 2025), Tail interaction (Wang et al., 2024a), Multi-domain calibration (Wald et al., 2021) Feature Disentanglement ( Â§4.2.3)</p>
<p>Debiasing with disentangled feature augmentation (Lee et al., 2021), StableNet (Zhang et al., 2021), RE-SORT (Wu et al., 2023b), Chroma-VAE (Yang et al., 2022a), JSE (Holstege et al., 2023), NeuronTune (Zheng et al., 2025) Contrastive Learning ( Â§4.2.4) Correct-n-Contrast (CnC) (Zhang et al., 2022) Post-hoc Methods ( Â§4.3)</p>
<p>Identification then Mitigation ( Â§4.3.1)SPARE (Yang et al., 2023a), LLS (Du et al., 2023), Evidential Alignment (Ye et al., 2025), FACTS (Yenamandra et al., 2023), RaVL (Varma et al., 2024), EvA (He et al., 2025), LBC (Zheng et al., 2024b), EQuAD (Yao et al., 2024), Spuriosity Rankings (Moayeri et al., 2023), GIC (Han &amp; Zou, 2024), PfR (Setlur et al., 2024), Subset pruning (Mulchandani &amp; Kim, 2025), DPR (Han et al., 2024), Tsetlin Machine (Yadav et al., 2022)
Finetuning ( Â§4.3.2)
MaskTune (Asgari et al., 2022), Influence tuning (Han &amp; Tsvetkov, 2021), Explanation-Based Finetuning (Ludan et al., 2023), CAPT (Gui &amp; Ji, 2025), DFR (Kirichenko et al., 2023), AFR (Qiu et al., 2023), SELF (LaBonte et al., 2023) Optimization-based Methods ( Â§4.3.3)</p>
<p>Group DRO (Sagawa et al., 2019a), GC-DRO (Zhou et al., 2021), CVaR DRO (Levy et al., 2020), JTT (Liu et al., 2021), LC (Liu et al., 2023), Multi-Objective Optimization with group policies (Kim et al., 2024b), TAP (Zhang et al., 2024a), LoT (Jin et al., 2024) Ensemble Learning ( Â§4.3.4)LWBC (Kim et al., 2022), ReBias (Bahng et al., 2020), DIVE (Sun et al., 2024), DivDis (Lee et al., 2023), LfF (Nam et al., 2020) Adversarial Training ( Â§4.3.5)Backdoor Poisoning Attacks (He et al., 2023) Specialized Methods ( Â§4.4) TTLSA (Sun et al., 2023), RSC-MDPs (Ding et al., 2023), Multi-modal Models during fine-tuning (Yang et al., 2023b) Figure 3: A comprehensive taxonomy of approaches to address spurious correlation in machine learning.</p>
<p>Shenoy, 2023).Nonetheless, SB remains a double-edged sword.It may help find a decision rule consistent with training data (an Occam's Razor effect), but it often aligns tightly with spurious correlations, thereby undermining robustness.Recognizing and mitigating simplicity bias is thus important for developing models that resist spurious correlations, ensuring that they do not overly prefer "easy" but misleading patterns at the cost of true generalization.</p>
<p>Methods</p>
<p>In this section, we discuss how various machine learning techniques address the issue of spurious correlation.</p>
<p>To provide a clear framework, we organize these methods based on their stages in the machine learning model training pipeline: Data-Centric Methods (Section 4.1), which modify the training data itself; Representation Learning (Section 4.2) approaches, which alter the model's training objective or architecture to learn more robust features; Post-hoc Methods (Section 4.3), which are applied to correct or refine an already trained model; and Specialized Methods (Section 4.4) tailored to non-standard settings.Figure 3 illustrates a comprehensive taxonomy of the surveyed approaches.</p>
<p>Data-Centric Methods</p>
<p>Data-centric methods address spurious correlations at their source: the training data itself.Based on the principle that biases are learned from flawed or imbalanced data distributions, these techniques aim to modify the input data before or during training to break the harmful associations between spurious attributes and labels.This category encompasses a range of strategies, from Data Augmentation (Section 4.1.1)techniques that create new examples to expose the model to more diverse contexts, to Data Balancing (Section 4.1.2)methods that correct for distributional imbalances, such as reweighting and subsampling.</p>
<p>Other approaches focus on Concept and Pseudo-label Discovery (Section 4.1.3)to explicitly identify and manage spurious attributes using labeled or unlabeled data.</p>
<p>Data Augmentation</p>
<p>Data augmentation increases the diversity of a dataset without the need for new data collection.Techniques such as image rotation, cropping, and noise injection are used to produce varied training samples, thereby improving model generalization by mitigating the impact of spurious correlations.For example, UV-DRO (Srivastava et al., 2020) leverages human annotations to augment training examples with potential unmeasured variables, reducing the spurious correlation problem to a covariate shift problem.When additional annotations are unavailable, methods such as Nuisances via Negativa (Puli et al., 2022) corrupt semantic information to highlight nuisances, while LISA (Yao et al., 2022) employs a mixup-based technique for selective augmentation.In graph settings, FedGR (Yue et al., 2024) introduces anti-shortcut augmentations by partitioning the graph into rationale and non-rationale subgraphs, perturbing the latter to dissociate spurious cues from the target signal, while also leveraging differences between local and global models within a federated learning paradigm.</p>
<p>Data Balancing</p>
<p>Spurious correlations are often caused by distributional imbalances in the training data, where spurious features consistently co-occur with target labels despite having no causal relationship.These issues can be addressed across various domains by modifying how existing data is sampled or weighted during training.For example, Balanced Greedy Sampling (Lee et al., 2024) is found to prevent such biases in continual learning tasks by retraining the final layer of the model using a balanced training subset.Reweighting has been used to mitigate dataset bias resulting from dataset condensation (Cui et al., 2024) and shortcut bias in multimodal settings (Li et al., 2025).However, LaBonte et al. ( 2024) warns that common group-balancing techniques can fail in specific scenarios: mini-batch upsampling and loss upweighting can observe a decrease in worst-group accuracy in later training epochs, and the effectiveness of data pruning varies depending on the group structure.Instead, they find that a combination of the two methods achieves a higher worst-group accuracy than each method individually.Similarly, Sagawa et al. (2020a) found that on overparameterized models, the subsampling on the majority group of data brings lower worst-group error instead of upweighting the minority group.</p>
<p>Concept and Pseudo-label Discovery</p>
<p>Another line of work in data manipulation involves predefining concepts and generating pseudo-labels to enhance the conceptual structure of the training data.This process helps to break intrinsic spurious correlations and improve model robustness.For instance, DISC (Wu et al., 2023a) discovers unstable predefined concepts across different environments, which are then used to augment the training data.Similarly, SSA (Nam et al., 2022) generates pseudo-labels for spurious attributes using a limited amount of annotated data, and the pseudo-labeled attributes are then combined with the training data to train a robust model using worst-case loss minimization.Recent methods have explored unsupervised or zero-shot discovery of latent concepts to avoid the need for human labeling.CoBalT (Arefin et al., 2024) uses various clustering techniques to identify concepts, while RoboShot (Adila et al., 2023) uses a language model to generate concept subspaces by extracting the embedding of the task description from within a language model.</p>
<p>Representation Learning</p>
<p>In contrast to data-centric approaches, representation learning methods shift the focus from the data itself to the model's internal learning process and the quality of its learned features.By modifying the training objective or model architecture, these approaches allow the model to identify features that are inherently robust and causally linked to the outcome, rather than just statistically correlated.Key strategies include Causal Intervention (Section 4.2.1), which explicitly models the data's causal structure, and Invariant Learning (Section 4.2.2), which seeks features that remain stable across diverse environments.Other techniques focus on altering the latent space directly, such as Feature Disentanglement (Section 4.2.3), which aims to separate spurious and core features, and Contrastive Learning (Section 4.2.4), which enforces representational similarity for inputs that differ only in their spurious attributes.</p>
<p>Causal Intervention</p>
<p>Causal intervention methods focus on explicitly addressing the causal relationships between the input, label, and potential spurious attributes, aiming to improve model robustness and fairness by reducing the influence of spurious features.For example, CaaM (Wang et al., 2021) integrates a Causal Attention Module within the Vision Transformer architecture, using unsupervised learning to self-annotate and mitigate confounding effects.Similarly, Causal VQA (Agarwal et al., 2020) applies a semantic editing-based approach to assess and improve the robustness of Visual Question Answering (VQA) models, and TIE (Lu et al., 2025) leverages a translation operation within image embeddings based on text embeddings along a given spurious vector.Venkataramani et al. (2024) proposes Causal Feature Alignment, which uses a trained ERM classifier to extract core features within an image.Veitch et al. (2021) and Sun et al. (2021) incorporate structured causal graphs to reflect true relationships in the data, while De-confound-TDE (Tang et al., 2020) employs causal modeling to pinpoint the effect of momentum in long-tailed classification tasks.In multi-task settings, Multi-Task Causal Representation Learning (MT-CRL) (Hu et al., 2022) identifies the causal structure between different tasks to regularize the learning process, preventing the model from relying on spurious features that are shared across non-causally related tasks.In a similar vein, Veitch et al. ( 2021) introduces counterfactual invariance to evaluate the causal structure captured within the model by measuring whether predictions are influenced when changing irrelevant portions of a sample.</p>
<p>Invariant Learning</p>
<p>Invariant learning methods aim to train models to identify and focus on features that remain stable across different training environments, based upon the assumption that truly predictive features are invariant to environmental shifts.This strategy is supported by Wald et al. (2021), which establishes that models achieving multi-domain calibration are provably free of spurious correlations.Early work such as IRM (Arjovsky et al., 2019b) formulates an objective to learn deep invariant features that capture complex relationships between latent variables.Methods like REx (Krueger et al., 2021) and EIIL (Creager et al., 2021) further this goal by focusing on risk-level consistency and automatic environment inference, respectively, and SCILL (Chen et al., 2022) establishes theoretical group criteria to ensure group-invariant learning.Recent works emphasize enforcing invariance at the feature level.SFB (Eastwood et al., 2023) selectively amplifies features that are stable across domains.ElRep (Wen et al., 2025) introduces nuclear and Frobenius norm penalties on the representation matrix to balance sparsity and smoothness, improving generalization while avoiding over-regularization.DropTop (Kim et al., 2024a) dynamically identifies and debiases shortcut features in continual learning by selecting top-k activations that correlate with spurious behavior.In the LLM setting, Wang et al. (2025) demonstrates how manipulating position encodings can eliminate hidden shortcuts in role separation tasks, reinforcing invariant structure.Wang et al. (2024a) disentangles spurious and beneficial correlations by combining frequency-restriction and interaction-based modules, enhancing the model's ability to learn domain-invariant representations.</p>
<p>Feature Disentanglement</p>
<p>Feature disentanglement methods aim to separate spurious representations from general representations in the latent space.These approaches often use dual-branch architectures.For example, StableNet (Zhang et al., 2021) removes both linear and non-linear dependencies using random Fourier features combined with a standard classifier, while Lee et al. (2021) trains two encoders to extract bias and intrinsic features separately.Disentanglement can be further enhanced through high-or low-dimensional projections.RE-SORT (Wu et al., 2023b) utilizes a Laplacian kernel function to project feature interactions to a higher dimension from within a multilevel stacked recurrent structure before targeted elimination through sample reweighting.</p>
<p>In contrast, Chroma-VAE (Yang et al., 2022a) employs a dual-pronged VAE to disentangle latent representations in a low-dimensional subspace, ensuring that shortcut features do not dominate the learning process, while Holstege et al. ( 2023) jointly identifies two low-dimensional orthogonal subspaces within a vector representation to locate encoded spurious features prior to removal (JSE).Similarly, NeuronTune (Zheng et al., 2025) identifies the neurons in latent space that are affected by spurious correlations, and zeros out these neurons during the retraining process.</p>
<p>Contrastive Learning</p>
<p>Contrastive learning, a popular approach within self-supervised learning, has shown promise in addressing spurious correlations.The Correct-n-Contrast (CnC) method (Zhang et al., 2022) first trains an ERM model to identify samples within the same class that vary in spurious features, and then uses contrastive learning to encourage similar representations for these samples.The resulting model is better able to distinguish between essential and non-essential features.</p>
<p>Post-hoc Methods</p>
<p>Post-hoc methods are designed to mitigate spurious correlations in models that have already been trained, or during a secondary training stage like fine-tuning.Rather than building a robust model from scratch, these techniques typically operate on a pre-existing, potentially biased model, aiming to diagnose and correct its reliance on spurious features without full retraining.This diverse category includes Identification then Mitigation (Section 4.3.1)strategies that first find bias-conflicting samples and then reduce their influence; Finetuning (Section 4.3.2) approaches that refine a pre-trained model on carefully selected or transformed data; and Optimization-based Methods (Section 4.3.3)like Group DRO that modify the training objective to improve worst-group performance.Other prominent techniques involve Ensemble Learning (Section 4.3.4) to combine multiple biased models for a more robust prediction, and Adversarial Training (Section 4.3.5) to improve model resilience.</p>
<p>Identification then Mitigation</p>
<p>A number of methods follow an "identification then mitigation" strategy.These approaches first identify samples that are likely affected by spurious correlations and then mitigate their impact.SPARE (Yang et al., 2023a) and LLS (Du et al., 2023) both identify spurious correlations based on signs of simplicity bias, and use importance sampling or reweighting to reduce bias.Evidential Alignment (Ye et al., 2025) utilizes second-order risk minimization to identify and quantify the spurious correlations in pretrained models, then tunes the biased model based on overconfident samples from a calibration dataset.Spurious correlations can also be identified in the model's representations through latent feature probing.FACTS (Yenamandra et al., 2023) amplifies correlations to fit a bias-aligned hypothesis and then uses slicing via mixture modeling in the corresponding feature space to address underperforming data slices.RaVL (Varma et al., 2024) creates a region-aware loss function based on local image features, and EvA (He et al., 2025) learns classspecific spurious indicators within the model.LBC (Zheng et al., 2024b) and EQuAD (Yao et al., 2024) both quantify the likelihood and strength of spurious features through projection into a spurious embedding space and into a low-dimensional latent space, respectively.Mulchandani &amp; Kim (2025) finds that spurious correlations result from a small subset of the data and introduces a novel pruning technique that identifies and removes such samples.Disagreement Probability-based Resampling (DPR) (Han et al., 2024) takes the reverse approach, identifying and upsampling training examples that do not align with spurious correlations.</p>
<p>In addition, Yadav et al. ( 2022) transforms natural language data into rule-based logic formulations and employs logical negation via a Tsetlin Machine to achieve explainable debiasing.Other methods like GIC, Spuriosity Rankings, and PfR infer group membership using auxiliary models or heuristic signals.GIC trains a classifier to predict group labels from spurious-label correlations, PfR uses zero-shot vision-language model predictions to identify spurious features, and Spuriosity Rankings proxies spuriosity using interpretable neural features to rank examples within each class and fine-tune on less biased data (Han &amp; Zou, 2024;Moayeri et al., 2023;Setlur et al., 2024).</p>
<p>Finetuning</p>
<p>Finetuning strategies focus on refining a pre-trained general model by selectively adjusting sections of either the model or the dataset to reduce reliance on spurious features.For instance, MaskTune (Asgari et al., 2022) encourages the model to consider a wider array of input variables by mapping them to the same target, while Influence Tuning (Han &amp; Tsvetkov, 2021) backpropagates attribution information for targeted refinement.In the text domain, Explanation-Based Finetuning (Ludan et al., 2023) trains models on artificially constructed datasets containing spurious cues, then tests on clean sets.Similarly, Causality-Aware Post-Training (CAPT) (Gui &amp; Ji, 2025) fine-tunes models on a transformed dataset where specific events are first identified and then replaced with randomized, abstract symbols to break spurious correlations acquired during pre-training.Moreover, last-layer finetuning strategies such as Deep Feature Reweighting (DFR) (Kirichenko et al., 2023;Izmailov et al., 2022), Automatic Feature Reweighting (AFR) (Qiu et al., 2023), and Selective Last-Layer Finetuning (SELF) (LaBonte et al., 2023) have been shown to improve worst-group performance with minimal group annotations.Shuieh et al. (2025) compares various fine-tuning techniques, finding Supervised Fine-tuning to excel in complex, context-intensive tasks, while Direct Preference and Kahneman-Tversky Optimization both perform well in mathematical reasoning tasks.</p>
<p>Optimization-based Methods</p>
<p>Optimization-based strategies modify the training objective to promote better performance under spurious correlations.Group DRO (Sagawa et al., 2019a)</p>
<p>Ensemble Learning</p>
<p>Ensemble learning methods combine multiple independently trained biased models to produce an overall debiased prediction.For instance, LWBC (Kim et al., 2022) uses a committee of classifiers to identify bias-conflicting data and then emphasizes these samples during the main classifier's training.Similarly, ReBias (Bahng et al., 2020) trains de-biased representations by enforcing statistical independence from intentionally biased representations.DIVE (Sun et al., 2024) trains a collection of models on diverging subgraphs to encourage learning distinct patterns from the overall predictive graph.Some methods, such as DivDis (Lee et al., 2023) and LfF (Nam et al., 2020), adopt a two-stage ensemble strategy to identify and mitigate reliance on spurious features.</p>
<p>Adversarial Training</p>
<p>Adversarial training methods strengthen the model against adversarial inputs, thereby reducing reliance on spurious correlations.For instance, methods addressing backdoor poisoning attacks consider the spurious correlations introduced by watermarked, mislabeled training examples and propose mitigation strategies based on adversarial training (He et al., 2023).</p>
<p>Specialized Methods</p>
<p>This category includes approaches designed for specific settings.Test-Time Label-Shift Adaptation (TTLSA) (Sun et al., 2023) addresses label shifts at test time, and RSC-MDP (Ding et al., 2023) tackles spurious dependencies in reinforcement learning contexts.Additional work (Yang et al., 2023b) explores the use of multi-modal models to explicitly separate spurious attributes from the main class.</p>
<p>Datasets and Metrics</p>
<p>Datasets</p>
<p>This subsection provides an overview of benchmark datasets used for studying spurious correlations in machine learning, as summarized in Table 1.In these datasets, the correlation between the label y and a spurious attribute a observed during training is not guaranteed to hold during testing.The reviewed benchmarks, which are publicly available via the hyperlinks in Table 1, are categorized into five domains: Vision, Text, Graph, Multimodal, and Health.These datasets are constructed using both realistic and synthetic data, with synthetic generation being an increasingly prevalent approach (Qian et al., 2023).The distinct methodologies used to create both synthetic and realistic datasets are discussed below.</p>
<p>Synthetic Datasets</p>
<p>Synthetic datasets are created to enable a more controllable analysis of spurious correlations in machine learning models.Since spurious features do not appear systematically or easily isolated in standard benchmarks, manually synthesizing spurious features improves the efficiency of creating relevant datasets.Different types of spurious attributes could be manipulated to create challenging datasets targeting the model's robustness.In this subsection, common methodologies used to create synthetic datasets are categorized into four primary techniques: data composition, feature and noise injection, and style transfer.</p>
<p>Data Composition A primary method for synthetic dataset creation is the composition of data from multiple sources.For instance, to analyze the spurious correlation between a foreground object and its background, images from different datasets can be combined.An example of this is the UrbanCars dataset (Li et al., 2023), where the authors integrated foreground vehicle images from the StanfordCars dataset (Krause et al., 2013) with background scenes from the Places dataset (Zhou et al., 2017).Another common practice involves placing different object types onto a shared background.This technique is used to analyze potential spurious correlations between co-occurring objects or to study shortcut learning, as demonstrated in the ImageNet-W dataset (Li et al., 2023).</p>
<p>Pixel-Level Manipulation</p>
<p>Manipulating existing datasets at the pixel level could also introduce desired spurious cues.While the target features still remain, the model might get biased towards the manipulation pattern.A notable example is the Colored MNIST dataset (Arjovsky et al., 2019a).In this work, the authors applied color filters to the original MNIST images to test whether a model learns the digit itself or relies on the color as a shortcut.In addition, noise injection is also a common method to introduce spurious attributes.In CIFAR-10-C and ImageNet-C, Hendrycks &amp; Dietterich (2019) applied perturbations such as noise, blurring, weather filters, and image manipulations (e.g., brightness, contrast, etc.) to the CIFAR-10 and ImageNet datasets to evaluate the robustness of models.Similarly, in the SpuCoMNIST dataset (Joshi et al., 2023), varying levels of noise are injected into MNIST images to establish different spurious correlations.</p>
<p>Style Transfer Machine learning models can exhibit biases toward object texture or style rather than shape.Style transfer is used to create datasets that test for this phenomenon.For example, the Stylized-ImageNet dataset (Geirhos et al., 2019) was generated by applying various artistic styles to images from ImageNet.The style transfer was performed using the AdaIN algorithm, which was trained on images from Kaggle's "Painter by Numbers" dataset (Huang &amp; Belongie, 2017).The resulting dataset is instrumental in identifying whether a model exhibits a "shape bias" or a "texture bias".</p>
<p>Realistic Datasets</p>
<p>In contrast to synthetic datasets, which are engineered for controlled analysis, realistic datasets are curated from real-world sources to capture the natural, often subtle and unexpected, spurious correlations that models are likely to encounter in deployment.While they may not offer the same level of granular control as their synthetic counterparts, these benchmarks are indispensable for evaluating a model's performance on authentic data distributions.The curation of such datasets involves diverse methodologies, which we discuss below based on their primary data sourcing strategy.</p>
<p>Data Curation from Existing Sources</p>
<p>A common strategy for creating new benchmarks is to curate and fuse data from existing sources, such as public datasets or search engines.This approach is prevalent in domain generalization, where datasets are constructed by combining data from different domains.For instance, the PACS dataset (Li et al., 2017) aggregates images of the same object classes from four distinct domains, ranging from photorealistic sources like Caltech256 (Griffin et al., 2022) to sketch-based sources like TU-Berlin (Eitz et al., 2012).In other cases, datasets are curated by sub-sampling or re-annotating a single source.An example is bFFHQ (Lee et al., 2021), which was created by adding new annotations for a protected attribute to the original FFHQ dataset (Karras et al., 2019).</p>
<p>Collection from Scratch Beyond leveraging existing data, some benchmarks are constructed by collecting and annotating data directly from real-world environments.This approach is critical for capturing authentic data distributions and task-specific nuances that may be absent in pre-existing datasets.This methodology is applied across various fields: the FMOW dataset (Christie et al., 2018) contains satellite imagery for land use classification; the CivilComments dataset (Borkan et al., 2019) comprises user-generated comments for toxicity detection; and the PadChest dataset (Bustos et al., 2020) includes chest x-ray images and corresponding radiological reports from a hospital.A defining characteristic of these datasets is the significant manual annotation effort they require, which is essential for establishing ground-truth labels.</p>
<p>Mining Challenging Example A specialized curation method involves mining a large benchmark for examples that are inherently challenging for standard machine learning models.Unlike methods that select data based on class or domain, this technique specifically retrieves instances that are likely to elicit incorrect predictions due to strong spurious cues or other adversarial properties.For example, the Hard ImageNet dataset (Moayeri et al., 2022) consists of images from ImageNet (Russakovsky et al., 2015) that were identified as containing potent spurious features.Similarly, the ImageNet-A dataset (Hendrycks et al., 2021b) is composed of naturally occurring adversarial examples from ImageNet that consistently fool well-established classification models.</p>
<p>Metrics</p>
<p>A commonly used metric for quantifying robustness to spurious correlations is the worst-group accuracy Acc wg (f Î¸ ) (Idrissi et al., 2022;Chaudhuri et al., 2023), defined as the minimum accuracy across group-labeled test sets:
Acc wg (f Î¸ ) := min gâˆˆG E (x,y)âˆ¼D g test 1 f Î¸ (x) = y ,(4)
where g = (y, a) is a group label determined by the target y and the spurious attribute a.</p>
<p>Other relevant metrics include:</p>
<p>Average-group accuracy.This measures the mean accuracy across all groups:
Acc ag (f Î¸ ) := 1 |G| gâˆˆG E (x,y)âˆ¼D g test 1 f Î¸ (x) = y .
(5)</p>
<p>Unlike worst-group accuracy, this metric is less sensitive to the hardest subgroup and instead reflects whether performance is balanced across groups on average.</p>
<p>Bias-conflicting accuracy.This is defined on a subset of groups G bc âŠ† G where the spurious attribute a does not align with the majority correlation observed during training:
Acc bc (f Î¸ ) := 1 |G bc | gâˆˆG bc E (x,y)âˆ¼D g test 1 f Î¸ (x) = y . (6)
This metric isolates model performance on the challenging bias-conflicting cases, where reliance on spurious features is most detrimental.</p>
<p>Finally, regular average accuracy across the entire test set remains useful for capturing overall utility, though it does not directly reflect robustness to spurious correlations.Together, these complementary metrics provide a more holistic view of a model's dependence on spurious features.Recent advancements in LLMs have significantly expanded their capabilities and revolutionized agentic AI assistants for challenging tasks, such as mathematical reasoning, tool use, code generation, and interactive communication.Compared to traditional machine learning settings, the length of tasks that current AI models can solve has increased exponentially from several tokens (e.g., classification) to millions of tokens (e.g., long Chain-of-Thought (CoT) reasoning and agentic workflows).However, spurious correlations in traditional machine learning still persist.For instance, image classification models have been found to use correlations between textures and image classes (Geirhos et al., 2019) for object recognition instead of focusing on defining features of objects.To solve this problem, many approaches (Kirichenko et al., 2023;Zheng et al., 2024b;c) and benchmarks (Sagawa et al., 2020a;Zheng et al., 2024a) have been proposed to mitigate the spurious biases in the classification tasks.</p>
<p>Broader Impacts of Spurious Correlations</p>
<p>AI assistants are typically trained to generate outputs that align with human ratings/preferences using methods such as reinforcement learning from human feedback (RLHF) or preference optimization (PO).These techniques depend on explicit or implicit reward modeling to guide LLMs to learn human preferences in a helpful, harmless, and honest (HHH) manner (Askell et al., 2021;Bai et al., 2022).However, the spurious correlations remain a significant issue and may introduce severe threats.It has been evident that the learned reward within the AI assistants may exhibit spurious correlations that cause them to favor unintended behaviors.Here are several observed biases incurred by the spurious correlations, from mild to severe.The most common spurious bias is length bias (Park et al., 2024b;a;Chen et al., 2024), which describes the tendency of reward models to favor longer responses regardless of their accuracy or instruction following.Additionally, concept biases (Zhou et al., 2024b) cause LLMs to associate textual concepts with specific sentiments.More recently, sycophancy biases (Sharma et al., 2023;Denison et al., 2024;Greenblatt et al., 2024) have been observed, in which models align their responses with user opinions even when those opinions are incorrect or harmful, shown in Figure 4.These biases encourage undesired yet highly rewarded behaviors, including tampering with the reward directly.Since AI assistants serve as agents between users and information, their biases may influence human belief formation and decision-making across numerous domains.Moreover, as these systems are increasingly integrated into agentic workflows in healthcare, education, legal contexts, and other high-stakes domains, their trustworthiness becomes a matter of significant practical importance.</p>
<p>Existing studies have provided initial and preliminary insights into these issues; however, there are still several key challenges to solve: (1) There is no unified framework for studying spurious biases.Current works typically examine one type of bias at a time, which limits our understanding of their combined effects.</p>
<p>(2) The non-transparent nature of deep neural networks makes it difficult to identify which parts of the model architecture or training process contribute to these biases.This complexity hinders the development of precise bias mitigation strategies.</p>
<p>(3) The alignment signals (e.g.reward models) cannot fully describe human preferences.Existing alignment signals are often noisy and imbalanced, which leads to unintended prioritization of behaviors that are highly rewarded but misaligned with human values.The existing literature (Sagawa et al., 2020a;Rafailov et al., 2024) has proved that simply increasing the model parameters will not solve this problem and could even exacerbate spurious biases.</p>
<p>Healthcare</p>
<p>AI is increasingly adopted across healthcare domains due to its ability to assist clinicians, and in some cases, rival expert performance across complex diagnostic tasks (Shahamatdar et al., 2024).However, models can rely on dataset-specific spurious correlations, compromising generalizability and fairness.These spurious correlations often emerge as a result of clinical data collection methods.For example, deep learning methods can easily identify the original submission site within samples from The Cancer Genome Atlas (Weinstein et al., 2013), one of the largest digital biorepositories, despite common data augmentation and normalization strategies due to substantial variation across samples.Site-specific signatures not only act as spurious cues, but also lead to biased accuracy in downstream tasks (Howard et al., 2021).Other signals, such as surgical skin markings in dermatology images (Winkler et al., 2019), visual artifacts tied to hospital-specific systems in radiology (Zech et al., 2018), or clinical heuristics that correlate disease subtypes and genetic markers in pathology (Shahamatdar et al., 2024), and arguably the most troubling, protected attributes such as demographics (Banerjee et al., 2023).Spurious correlations in healthcare AI systems often stem not just from individual visual or statistical artifacts, but from deeper structural issues in how clinical data are collected.For example, convolutional neural networks trained to detect pneumonia from X-rays can instead infer the source hospital or department with high accuracy, adjusting predictions accordingly and failing to generalize to unseen clinical environments (Zech et al., 2018).These learned shortcuts are not limited to image data.Widely used commercial risk prediction models that estimate and minimize healthcare costs can systematically disadvantage minority groups as a result of their optimization goal, as cost is an imperfect heuristic for actual health needs due to disparities in access and treatment (Obermeyer et al., 2019).Furthermore, AI systems are capable of detecting protected attributes, even when those attributes are not explicitly included in the input features, and subsequently generating biased outputs (Banerjee et al., 2023).Even with consistent data processing methods, performance can vary sharply within minority groups.Both deep learning systems and expert dermatologists underperform on images of patients from minority backgrounds due to uneven data coverage and skin tone representation in training data (Daneshjou et al., 2022).Together, these findings highlight that spurious signals often arise as a result of the overall design and curation of medical datasets.</p>
<p>To address the risks posed by spurious correlations in clinical AI systems, several mitigation strategies have been proposed.To reduce site-specific biases, Howard et al. ( 2021) demonstrates that using preservedsite cross-validation, where entire data collection sites are held out during training, can effectively stratify patients by outcomes of interest.During inference, models can be guided towards medically insightful features, such as through the use of spatial annotations to indicate the location of abnormalities (Saab et al., 2022).However, such strategies may incur substantial annotation costs.Beyond supervision, rigorous model auditing is essential.DeGrave et al. ( 2021) emphasizes that models that exploit spurious cues may still appear accurate when evaluated using external test sets, highlighting the importance of deeper evaluation strategies that use both domain knowledge and technical expertise, as well as the broader integration of explainable AI.</p>
<p>Embodied AI</p>
<p>Figure 6: Example images from the ProcTHOR dataset.In both groups of images, the color of the sofa remains the same, but the color and texture of other objects have been changed, which could mislead the robot.</p>
<p>The recent advances in MLLMs and World Models (Liu et al., 2025b) have shown strong capability of perceiving and understanding various types of information from the physical world, proving the possibility of creating AI agents that can interact with the real world, which is defined as Embodied AI (EmAI).The key components of an EmAI are perception, learning, memory, and action (Paolo et al., 2024), where the perception module receives multi-modal information from the physical world, and the action module interacts with the physical world with decisions made from AI models.The application of EmAI is mostly achieved through robots, but in various fields such as industry manufacturing, healthcare, and autonomous driving.However, although modern AI models can understand the physical world under most scenarios, they are still easily biased by spurious features hidden in the data captured from the real world.For example in general robotics, the performance of the robots in unseen scenarios can be largely affected by the position of lights or objects in the scene (Wu et al., 2025).Similarly, in autonomous driving, the EmAI agent would rely on the spurious correlation between brightness and the traffic density, which causes accidents when the causal relationship does not present (Ding et al., 2023).</p>
<p>Most spurious correlations originate from the dataset used to train the model.Unbalanced or biased datasets would usually cause st rong spurious correlations that mislead the model to learn undesired patterns.Figure 6 shows example images from the ProcTHOR dataset (Deitke et al., 2022), where different wall colors and textures could be spuriously correlated with the object navigation policies of robots, such as navigating to find the sofa.Therefore, Hoftijzer et al. (2023) intentionally colored different rooms in the dataset with different colors, which caused the robot to navigate to the wrong position.While in autonomous driving, Li et al. (2023) synthesizes an Urbancars dataset that composites images of vehicles with different backgrounds as well as co-occurring objects, which is proven in experiments to affect the accuracy of models greatly.It has also been shown that such shortcuts could be mitigated by an ensemble method.Meanwhile, spurious cues not only exist in these synthetic datasets but also appear in datasets from the real world.Hamscher et al. (2025) point out that conventional CNN models and transformers trained on ImageNet are largely biased by the texture of objects, instead of the global shape and features.Therefore, it is still essential to mitigate the effect of spurious correlation through building more robust datasets, such as WEDGE (Marathe et al., 2023).</p>
<p>As EmAI starts to integrate more advanced multimodality models, the input from vision has been one of the most crucial components in the lifecycle of an EmAI agent.However, spurious correlations from vision inputs such as images or videos could cause degraded performance.More importantly, spurious cues from vision input would expose a shortcut for the Vision-Language Models (VLM) to falsely correlate some vision features with text features.A recent study (Varma et al., 2024) has pointed out that co-occurring objects (e.g., flowers and butterflies) could mislead the fine-tuned VLMs.To mitigate spurious cues in VLM, Varma et al. (2024) have proposed RaVL, which utilizes local image features to identify the spurious correlation, then mitigates them by training the VLM to focus more on regions that do not include these spurious features.However, a standard VLM only outputs text descriptions based on vision and language inputs, which is not directly usable by most EmAI agents.Therefore, there was a new architecture invented called Vision-Language-Action models (VLA) (Zitkovich et al., 2023).Instead of output descriptions, VLA outputs actions that the EmAI agent should do next to control the movements.As actions are incorporated into the training process as text tokens, spurious correlation between the vision and the action could result in undesired behavior.Zhang et al. (2025) discovered that the fine-tuned VLA would approach the drawer while it has been given an instruction that is completely irrelevant to the drawer.(3) Due to the existence of spurious correlation, the behavior of EmAI agents do not always align with the demand from humans, resulting in undesired behavior.Tian et al. (2023) states that to better align robots with humans, utilizing human feedback would be one of the important solutions.</p>
<p>Discussion</p>
<p>Prospective in the Era of Generative AI</p>
<p>The recent surge in generative AI has put foundation models in the spotlight.These large-scale models, trained on massive datasets, are capable of performing a wide range of tasks and better reflecting realworld data distributions.One promising direction is leveraging the parametric knowledge in foundation models as tools to address spurious correlations, for example, by designing prompt optimization techniques that guide these models to detect or generate more diverse data, thereby reducing reliance on spurious correlations.Another promising direction is to investigate the spurious correlations within foundation models themselves.Given that these models are overparameterized, there is concern that their overparameterization may exacerbate spurious correlations (Sagawa et al., 2020a).Although foundation models are powerful, they might amplify unintended spurious associations, particularly on unseen data.For instance, hallucinations in Large Language Models (LLMs) often reflect spurious content that diverges from user inputs or contradicts established facts.Introducing structured knowledge, such as knowledge graphs, into foundation models may provide a pathway to mitigate these issues.</p>
<p>Unresolved Challenges in Spurious Correlation Mitigation</p>
<p>Despite significant progress, spurious correlation mitigation remains a complex and unsolved problem in machine learning.Many existing approaches depend on group annotations or human-defined spurious attributes, limiting their applicability in real-world settings where such information is unavailable or incomplete.In practice, the assumption of accessible group labels or environment partitions is often unrealistic, especially in domains like healthcare, where defining subgroup boundaries may require expert domain knowledge and labor-intensive labeling.</p>
<p>Additionally, a recurring tradeoff emerges between optimizing worst-group accuracy and maintaining high average performance.While group-aware objectives like Group DRO improve fairness across subpopulations, they frequently degrade overall accuracy or increase variance.This tension complicates deployment decisions and underscores the need for methods that can flexibly navigate performance tradeoffs.</p>
<p>Furthermore, most benchmarks focus on a narrow set of predefined spurious correlations, potentially masking vulnerabilities to other spurious signals in the data.This lack of comprehensive evaluation protocols makes it difficult to assess the generalization of debiasing techniques across modalities, domains, and forms of shortcut learning.At the same time, scalability remains an open challenge-manually identifying, labeling, or simulating every possible spurious correlation becomes infeasible at the scale of modern datasets and models.</p>
<p>Finally, while some techniques have incorporated interpretable representations or causal principles, the field lacks consistent methods for understanding why a model depends on certain features, how interventions affect outcomes, and whether mitigation was successful for the right reasons.</p>
<p>Open Questions and Future Directions</p>
<p>We outline several open directions to address persistent limitations in spurious correlation mitigation:</p>
<p>Group-Label-Free Mitigation.Many existing approaches still rely on at least partial group annotations to formulate training objectives.A critical future goal is to design learning algorithms that can identify and mitigate spurious correlations without requiring any group supervision, enabling broader applicability in realworld scenarios.Progress here would make methods more realistic for deployment, since group information is rarely available outside research datasets.It also raises the question of how to validate robustness when ground-truth groups are absent, which itself is an open challenge.</p>
<p>Automated Detection of Spurious Correlations.Mitigation depends on first identifying spurious patterns.Future work should prioritize fully automated detection pipelines that surface hidden biases across modalities and learning objectives, including in reward signals, feedback-aligned models, and cross-modal inputs, without relying on human-defined attributes or labels.An important step is to develop principled criteria for deciding what counts as a spurious correlation rather than a useful context.Automated detection also needs to scale to foundation models, where out-of-the-box detection of spurious correlations is not directly applicable.</p>
<p>Balancing Robustness and Utility.Improving worst-group performance often comes at the expense of average accuracy.However, spurious features can provide useful contextual signals in some settings.Developing flexible optimization techniques that balance the model robustness and overall utility remains a key challenge for practical deployment.Understanding which contexts are genuinely harmful and which are benign is important, since discarding all correlations may unnecessarily limit model capacity.This trade-off is particularly relevant in safety-critical settings where both robustness and accuracy are needed.</p>
<p>Scalable and Comprehensive Evaluation.Current benchmarks only probe specific, predefined forms of bias.There is a need for scalable, diverse, and comprehensive evaluation protocols that test models against a broader spectrum of spurious correlations.These include simulation-based environments, adversarial or synthetic datasets, and diagnostic tools for identifying shortcut learning.Without this, robustness claims risk being benchmark-specific and not transferable.More systematic evaluations would also help clarify whether different mitigation methods address the same or distinct failure modes.</p>
<p>Interpretable Representations and Concept Discovery.As models grow more complex, understanding their internal decision processes is essential.Future research should build on recent progress in unsupervised concept discovery, probing techniques, and causal modeling to explain and verify when, why, and how spurious correlations emerge and are mitigated.A more interpretable view of the representation space could also help connect detection and mitigation, making interventions more targeted.This line of work may further reveal structural reasons why spurious features persist even after extensive training.</p>
<p>Multimodal and Cross-Domain Generalization.Spurious correlations extend beyond unimodal datasets.Models trained on multimodal, sequential, or embodied tasks often exhibit domain-specific shortcuts.Future work should explore debiasing techniques that generalize across input modalities, tasks, and deployment environments.Such methods will need to handle correlations that appear in one modality but not another, or that shift differently across domains.Achieving this would move the field closer to real-world deployment, where spurious cues are diverse and hard to predict.</p>
<p>Final Remarks</p>
<p>Spurious correlations represent a ubiquitous challenge in machine learning, particularly as they contribute to model brittleness and poor performance under domain shifts.In this survey, we thoroughly review the issue by presenting a detailed taxonomy of current methods, datasets, and metrics designed to evaluate model robustness against spurious correlations.We summarize the current state of the field and highlight several promising challenges for future research.Moving forward, particularly in the era of generative AI and larger foundational models, our discussion lays the groundwork for further progress in this domain.We hope that this survey inspires continued research in addressing spurious correlations and advances the broader machine learning community.</p>
<p>Figure 2 :
2
Figure 2: Depiction of a spurious correlation between spurious attribute A (e.g., grass) and target Y (e.g., cow).In environment E, input X contains both core features (invariant across environments) from Y , and spurious features from A. When shifting to a new environment E â€² , the spurious attribute changes (e.g., desert background A â€² ), causing the spurious correlation to break.The core features remain predictive of Y , but models trained on E may fail to generalize if they overly rely on A.</p>
<ol>
<li>1 Figure 4 :
14
Figure 4: Example of sycophancy as spurious attributes in an LLM-based reward model.</li>
</ol>
<p>Figure 5 :
5
Figure 5: Hospital tags, strips, and medical devices exemplify several unknown group labels in the MIMIC-CXR dataset, which can spuriously correlate with the ground truth diagnosis results.</p>
<p>Recent work has begun to address simplicity bias by altering training curricula or model architectures to force the learning of more complex features(Tiwari &amp;
Data Augmentation( Â§4.1.1)Data-CentricMethods( Â§4.1)Taxonomy of Methods against Spurious Correlations</p>
<p>Table 1 :
1
Datasets used to study spurious correlations in machine learning.Datasets are grouped by domain.The Synthetic column indicates whether a dataset is synthetic (âœ“) or derived from natural data (âœ—).
DatasetSource Paper#Class #Attributes #Sample Brief DescriptionSynthetic DomainUrbanCarsLi et al. (2023)228,000Compositional vehicle scenesâœ“VisionColored MNISTArjovsky et al. (2019a)-260,000Color-injected digitsâœ“VisionCIFAR-10-CHendrycks &amp; Dietterich (2019) -1560,000Corruption on CIFAR-10âœ“VisionSpuCoJoshi et al. (2023)44118,100Mixed synthetic + natural dataâœ“VisionWaterbirdsSagawa et al. (2019b)2211,788Composite birds + backgroundsâœ“VisionImageNet-CHendrycks &amp; Dietterich (2019) 75--Corruption benchmark (Variant of ImageNet)âœ“VisionImageNet-RHendrycks et al. (2021a)2001630,000Artistic renditions (Variant of ImageNet)âœ“VisionImageNet-WLi et al. (2023)-2-ImageNet with Watermark (Variant of ImageNet) âœ“VisionImageNet-9Xiao et al. (2020)9-5,495Background-altered (Variant of ImageNet)âœ“VisionStylized-ImageNetGeirhos et al. (2019)---AdaIN stylised variant (Variant of ImageNet)âœ“VisionHard ImageNetMoayeri et al. (2022)15-19,847Spurious correlation specific (Subset of ImageNet) âœ—VisionImageNet-AHendrycks et al. (2021b)200-7,500Natural adversarial images (Subset of ImageNet)âœ—VisionPACSLi et al. (2017)749,991Multi-domain real imagesâœ—VisionVLCSTorralba &amp; Efros (2011)5410,729Aggregated real domainsâœ—VisionOffice-HomeVenkateswara et al. (2017)65415,500Multi-domain real imagesâœ—VisionCelebALiu et al. (2015)22202,599Face attributesâœ—VisionMetaCoCoZhang et al. (2024b)100155175,637Few-shot data for spurious correlationsâœ—VisionBARNam et al. (2020)662,595Biased action recognitionâœ—VisionNICOHe et al. (2021)1918824,214Context-shift animalsâœ—VisionMetaShiftLiang &amp; Zou (2022)410-12,868Dataset-of-datasets shiftâœ—VisionFMOWChristie et al. (2018)63-1,047,691 Satellite imageryâœ—VisionbFFHQLee et al. (2021)22-Balanced FFHQ facesâœ—VisionCounterAnimalWang et al. (2024b)451413,100Counterfactual animalsâœ—VisionWILDS-iWildCamKoh et al. (2021)182-203,029Wildlife camera trapsâœ—VisionWILDS-GlobalWheat Koh et al. (2021)1126,515Wheat imagesâœ—VisionWILDS-PovertyMapKoh et al. (2021)-23 Ã— 29,669Satellite imagesâœ—VisionQuACChoi et al. (2018)--98,407Conversational QAâœ—TextPOVIDZhou et al. (2024a)--17,000VLM prompt-responseâœ—TextCivilCommentsBorkan et al. (2019)2241,999,514 Online commentsâœ—TextMultiNLIWilliams et al. (2017)32206,175Natural language inferenceâœ—TextFDCL18Founta et al. (2018)7-80,000Offensive speechâœ—TextWILDS-AmazonKoh et al. (2021)-2539,502Customer reviews on Amazonâœ—TextShortcutSuiteYuan et al. (2024)---Shortcut in LLMâœ—TextSpurious-MotifWu et al. (2022)3318, 000Compositional motif-based graphâœ“GraphGOOD-MotifGui et al. (2022)5330,000Compositional motif-based graphâœ“GraphGOOD-HIVGui et al. (2022)2241,127Molecule datasetâœ—GraphGOOD-SST2Gui et al. (2022)2-70,042Sentence polarityâœ—GraphDrugOODJi et al. (2023)-558,000Drug discoveryâœ—GraphIV/CV-VQAAgarwal et al. (2020)--716,603Causal VQAâœ—MultimodalMM-SpuBenchYe et al. (2024)--2,400Multimodal spurious correlationsâœ—MultimodalChestX-ray14Wang et al. (2017)14-112,120Chest X-rayâœ—HealthMIMIC-CXRJohnson et al. (2019)14-377,110Chest X-rayâœ—HealthCheXpertIrvin et al. (2019)14-224,316Chest X-rayâœ—HealthPadChestBustos et al. (2020)19-160,868Chest X-rayâœ—HealthCOVID-19Cohen et al. (2020)2-21,165Chest X-rayâœ—Health</p>
<p>Wu et al. (2025)at the VLA model has seen the drawer frequently during training, thus learned a shortcut that is not causally related to any input.To mitigate this spurious correlation, the authors have proposed Intrinsic Spatial Reasoning (InSpire), which extends the text input of the VLA to inspire more spatial reasoning during the process.Besides input solutions, other methods are also proposed to mitigate spurious correlation during different modules of VLA.Wu et al. (2025)observed that VLA relies on the task-irrelevant objects or textures to output actions, so a new method Policy Contrastive Decoding (PCD) transfers the attention of the EmAI agent from those spurious cues to more objective-relevant features during the inference stage.Although various methods have been developed to mitigate the impact of spurious correlation in EmAI, certain questions still remain: (1) existing methods either focus more on datasets, inputs, or inference time modifications, and the improvements during the training stage require further experiments and research.(2) Lack of research in spurious correlation among other modalities, such as audio.</p>
<p>Zero-shot robustification of zero-shot models. Dyah Adila, Changho Shin, Linrong Cai, Frederic Sala, arXiv:2309.043442023arXiv preprint</p>
<p>Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing. Vedika Agarwal, Rakshith Shetty, Mario Fritz, CVPR. 2020</p>
<p>Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-distribution generalization. Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Advances in Neural Information Processing Systems. 202134</p>
<p>Unsupervised concept discovery mitigates spurious correlations. Md Rifat Arefin, Yan Zhang, Aristide Baratin, Francesco Locatello, Irina Rish, Dianbo Liu, Kenji Kawaguchi, arXiv:2402.133682024arXiv preprint</p>
<p>. Martin Arjovsky, LÃ©on Bottou, Ishaan Gulrajani, David Lopez-Paz, 2019aInvariant risk minimization. arXiv</p>
<p>. Martin Arjovsky, LÃ©on Bottou, Ishaan Gulrajani, David Lopez-Paz, 10.48550/arXiv.1907.02893Invariant Risk Minimization. arXiv. 2019b</p>
<p>Masktune: Mitigating spurious correlations by forcing to explore. Saeid Asgari, Aliasghar Khani, Fereshte Khani, Ali Gholami, Linh Tran, Ali Mahdavi-Amiri, Ghassan Hamarneh, NeurIPS2022</p>
<p>A general language assistant as a laboratory for alignment. Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova Dassarma, arXiv:2112.008612021arXiv preprint</p>
<p>Learning de-biased representations with biased representations. Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, Seong Joon Oh, ICML. 2020</p>
<p>Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron Mckinnon, arXiv:2212.08073Constitutional ai: Harmlessness from ai feedback. 2022arXiv preprint</p>
<p>shortcuts" causing bias in radiology artificial intelligence: causes, evaluation, and mitigation. Imon Banerjee, Kamanasish Bhattacharjee, John L Burns, Hari Trivedi, Saptarshi Purkayastha, Laleh Seyyed-Kalantari, N Bhavik, Rakesh Patel, Judy Shiradkar, Gichoya, Journal of the American College of Radiology. 2092023</p>
<p>How spurious features are memorized. Simone Bombari, Marco Mondelli, arXiv:2305.12100Precise analysis for random and ntk features. 2023arXiv preprint</p>
<p>Nuanced metrics for measuring unintended bias with real data for text classification. Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, Lucy Vasserman, 2019WWW</p>
<p>Aurelia Bustos, Antonio Pertusa, Jose-Maria Salinas, Maria De, La Iglesia-Vaya, Padchest: A large chest x-ray image dataset with multi-label annotated reports. Medical image analysis. 2020</p>
<p>Why does throwing away data improve worst-group error. Kamalika Chaudhuri, Kartik Ahuja, Martin Arjovsky, David Lopez-Paz, ICML. 2023</p>
<p>Odin: Disentangled reward mitigates hacking in rlhf. Lichang Chen, Chen Zhu, Jiuhai Chen, Davit Soselia, Tianyi Zhou, Tom Goldstein, Heng Huang, Mohammad Shoeybi, Bryan Catanzaro, International Conference on Machine Learning. PMLR2024</p>
<p>When does group invariant learning survive spurious correlations? In NeurIPS. Yimeng Chen, Ruibin Xiong, Zhi-Ming Ma, Yanyan Lan, 2022</p>
<p>Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-Tau Yih, Yejin Choi, Percy Liang, Luke Zettlemoyer, Quac, arXiv:1808.07036Question answering in context. 2018arXiv preprint</p>
<p>Functional map of the world. Gordon Christie, Neil Fendley, James Wilson, Ryan Mukherjee, CVPR. 2018</p>
<p>Joseph Paul Cohen, Paul Morrison, Lan Dao, arXiv:2003.11597Covid-19 image data collection. 2020arXiv preprint</p>
<p>Environment inference for invariant learning. Elliot Creager, JÃ¶rn-Henrik Jacobsen, Richard Zemel, ICLR. 2021</p>
<p>Ameliorate spurious correlations in dataset condensation. Justin Cui, Ruochen Wang, Yuanhao Xiong, Cho-Jui Hsieh, Forty-first International Conference on Machine Learning. 2024</p>
<p>Disparities in dermatology ai performance on a diverse, curated clinical image set. Roxana Daneshjou, Kailas Vodrahalli, Roberto A Novoa, Melissa Jenkins, Weixin Liang, Veronica Rotemberg, Justin Ko, Susan M Swetter, Elizabeth E Bailey, Olivier Gevaert, Science advances. 83161472022</p>
<p>Ai for radiographic covid-19 detection selects shortcuts over signal. Alex J Degrave, Joseph D Janizek, Su-In Lee, Nature Machine Intelligence. 372021</p>
<p>Procthor: Large-scale embodied ai using procedural generation. Matt Deitke, Eli Vanderbilt, Alvaro Herrasti, Luca Weihs, Kiana Ehsani, Jordi Salvador, Winson Han, Eric Kolve, Aniruddha Kembhavi, Roozbeh Mottaghi, Advances in Neural Information Processing Systems. 202235</p>
<p>Carson Denison, Monte Macdiarmid, Fazl Barez, David Duvenaud, Shauna Kravec, Samuel Marks, Nicholas Schiefer, Ryan Soklaski, Alex Tamkin, Jared Kaplan, arXiv:2406.10162Sycophancy to subterfuge: Investigating reward-tampering in large language models. 2024arXiv preprint</p>
<p>Seeing is not believing: Robust reinforcement learning against spurious correlation. Wenhao Ding, Laixi Shi, Yuejie Chi, Ding Zhao, NeurIPS2023</p>
<p>Shortcut learning of large language models in natural language understanding: A survey. Mengnan Du, Fengxiang He, Na Zou, Dacheng Tao, Xia Hu, 2022aarXiv</p>
<p>Towards debiasing dnn models from spurious feature influence. Mengnan Du, Ruixiang Tang, Weijie Fu, Xia Hu, AAAI. 2022b</p>
<p>Less learn shortcut: Analyzing and mitigating learning of spurious feature-label correlation. Yanrui Du, Jing Yan, Yan Chen, Jing Liu, Sendong Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Bing Qin, IJCAI. 2023</p>
<p>Spuriosity didn't kill the classifier: Using invariant predictions to harness spurious features. Cian Eastwood, Shashank Singh, Andrei Liviu Nicolicioiu, Marin Vlastelica, Julius Von KÃ¼gelgen, Bernhard SchÃ¶lkopf, NeurIPS2023</p>
<p>How do humans sketch objects?. Mathias Eitz, James Hays, Marc Alexa, 10.1145/2185520.2185540ACM Trans. Graph. 0730-0301314July 2012</p>
<p>Large scale crowdsourcing and characterization of twitter abusive behavior. Antigoni Founta, Constantinos Djouvas, Despoina Chatzakou, Ilias Leontiadis, Jeremy Blackburn, Gianluca Stringhini, Athena Vakali, Michael Sirivianos, Nicolas Kourtellis, ICWSM. 2018</p>
<p>Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A Wichmann, Wieland Brendel, International Conference on Learning Representations. 2019</p>
<p>Shortcut learning in deep neural networks. Nature Machine Intelligence. Robert Geirhos, JÃ¶rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix A Wichmann, 10.1038/s42256-020-00257-z2020</p>
<p>Alignment faking in large language models. Ryan Greenblatt, Carson Denison, Benjamin Wright, Fabien Roger, Monte Macdiarmid, Sam Marks, Johannes Treutlein, Tim Belonax, Jack Chen, David Duvenaud, arXiv:2412.140932024arXiv preprint</p>
<p>. Gregory Griffin, Alex Holub, Pietro Perona, Caltech. 256Apr 2022</p>
<p>Mitigating spurious correlations in llms via causality-aware post-training. Shurui Gui, Shuiwang Ji, arXiv:2506.094332025arXiv preprint</p>
<p>Good: A graph out-of-distribution benchmark. Shurui Gui, Xiner Li, Limei Wang, Shuiwang Ji, Advances in Neural Information Processing Systems. 202235</p>
<p>In search of lost domain generalization. Ishaan Gulrajani, David Lopez-Paz, International Conference on Learning Representations. 2020</p>
<p>Ada-VAD: Domain Adaptable Video Anomaly Detection. Dongliang Guo, Yun Fu, Sheng Li, 10.1137/1.9781611978032.73</p>
<p>Transferring styles for reduced texture bias and improved robustness in semantic segmentation networks. Ben Hamscher, Edgar Heinert, Annika MÃ¼tze, Kira Maag, Matthias Rottmann, arXiv:2507.102392025arXiv preprint</p>
<p>Mitigating spurious correlations via disagreement probability. Hyeonggeun Han, Sehwan Kim, Hyungjun Joo, Sangwoo Hong, Jungwoo Lee, Advances in Neural Information Processing Systems. 202437</p>
<p>Influence tuning: Demoting spurious correlations via instance attribution and instance-driven updates. Xiaochuang Han, Yulia Tsvetkov, EMNLP 2021. 2021</p>
<p>Improving group robustness on spurious correlation requires preciser group inference. Yujin Han, Difan Zou, arXiv:2404.138152024arXiv preprint</p>
<p>Erasing spurious correlations with activations. Qiyuan He, Kai Xu, Angela Yao, Eva, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Mitigating backdoor poisoning attacks through the lens of spurious correlation. Xuanli He, Qiongkai Xu, Jun Wang, I P Benjamin, Trevor Rubinstein, Cohn, EMNLP. 2023</p>
<p>Towards non-iid image classification: A dataset and baselines. Yue He, Zheyan Shen, Peng Cui, Pattern Recognition. 2021</p>
<p>Benchmarking neural network robustness to common corruptions and perturbations. Dan Hendrycks, Thomas Dietterich, International Conference on Learning Representations. 2019</p>
<p>The many faces of robustness: A critical analysis of out-ofdistribution generalization. Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer vision2021a</p>
<p>Natural adversarial examples. Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song, CVPR. 2021b</p>
<p>Hossein Katherine L Hermann, Thomas Mobahi, Michael C Fel, Mozer, arXiv:2310.16228On the foundations of shortcut learning. 2023arXiv preprint</p>
<p>Language-based augmentation to address shortcut learning in object-goal navigation. Dennis Hoftijzer, Gertjan Burghouts, Luuk Spreeuwers, 2023 Seventh IEEE International Conference on Robotic Computing (IRC). IEEE2023</p>
<p>Removing spurious concepts from neural network representations via joint subspace estimation. Floris Holstege, Bram Wouters, arXiv:2310.119912023arXiv preprintNoud Van Giersbergen, and Cees Diks</p>
<p>Haoyang Hong, Ioanna Papanikolaou, Sonali Parbhoo, arXiv:2503.17015Do regularization methods for shortcut mitigation work as intended?. 2025arXiv preprint</p>
<p>The impact of site-specific digital histology signatures on deep learning model accuracy and bias. James Frederick M Howard, Sara Dolezal, Jefree Kochanny, Heather Schulte, Lara Chen, Dezheng Heij, Rita Huo, Nanda, Jakob N Olufunmilayo I Olopade, Kather, Nature communications. 12144232021</p>
<p>Improving multitask generalization via regularizing spurious correlation. Ziniu Hu, Zhe Zhao, Xinyang Yi, Tiansheng Yao, Lichan Hong, Yizhou Sun, Ed Chi, NeurIPS2022</p>
<p>Developing medical imaging ai for emerging infectious diseases. Shih-Cheng Huang, Akshay S Chaudhari, Curtis P Langlotz, Nigam Shah, Serena Yeung, Matthew P Lungren, Nature Communications. 2022</p>
<p>Arbitrary style transfer in real-time with adaptive instance normalization. Xun Huang, Serge Belongie, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision2017</p>
<p>Simple data balancing achieves competitive worst-group-accuracy. Youbi Badr, Martin Idrissi, Mohammad Arjovsky, David Pezeshki, Lopez-Paz, CLeaR. 2022</p>
<p>Attention consistency on visual corruptions for single-source domain generalization. Cugu Ilke, Massimiliano Mancini, Yanbei Chen, Zeynep Akata, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, AAAI. 2019</p>
<p>On feature learning in the presence of spurious correlations. Pavel Izmailov, Polina Kirichenko, Nate Gruver, Andrew G Wilson, NeurIPS2022</p>
<p>Drugood: Out-of-distribution dataset curator and benchmark for ai-aided drug discovery-a focus on affinity prediction problems with noise annotations. Yuanfeng Ji, Lu Zhang, Jiaxiang Wu, Bingzhe Wu, Lanqing Li, Long-Kai Huang, Tingyang Xu, Yu Rong, Jie Ren, Ding Xue, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Learning from teaching regularization: Generalizable correlations should be easy to imitate. Can Jin, Tong Che, Hongwu Peng, Yiyuan Li, Dimitris Metaxas, Marco Pavone, Advances in Neural Information Processing Systems. 372024</p>
<p>Tom J Alistair Ew Johnson, Seth J Pollard, Nathaniel R Berkowitz, Greenbaum, Chih-Ying Matthew P Lungren, Roger G Deng, Steven Mark, Horng, Mimic-cxr, a de-identified publicly available database of chest radiographs with free-text reports. Scientific data. 2019</p>
<p>Siddharth Joshi, Yu Yang, Yihao Xue, Wenhan Yang, Baharan Mirzasoleiman, arXiv:2306.11957Towards mitigating more challenging spurious correlations: A benchmark &amp; new datasets. 2023arXiv preprint</p>
<p>A style-based generator architecture for generative adversarial networks. Tero Karras, Samuli Laine, Timo Aila, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2019</p>
<p>Adaptive shortcut debiasing for online continual learning. Doyoung Kim, Dongmin Park, Yooju Shin, Jihwan Bang, Hwanjun Song, Jae-Gil Lee, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2024a38</p>
<p>Learning debiased classifier with biased committee. Nayeong Kim, Sehyun Hwang, Sungsoo Ahn, Jaesik Park, Suha Kwak, NeurIPS2022</p>
<p>Improving robustness to multiple spurious correlations by multi-objective optimization. Nayeong Kim, Juwon Kang, Sungsoo Ahn, Jungseul Ok, Suha Kwak, arXiv:2409.033032024barXiv preprint</p>
<p>Last layer re-training is sufficient for robustness to spurious correlations. Polina Kirichenko, Pavel Izmailov, Andrew Gordon, Wilson , ICLR2023</p>
<p>Wilds: A benchmark of in-the-wild distribution shifts. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etiene David, Ian Stavness, Wei Guo, Berton A Earnshaw, Imran S Haque, Meghan Sara, Jure Beery, Anshul Leskovec, Emma Kundaje, Sergey Pierson, Chelsea Levine, Percy Finn, Liang, International Conference on Machine Learning. 2020</p>
<p>Wilds: A benchmark of in-the-wild distribution shifts. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, International conference on machine learning. PMLR2021</p>
<p>3d object representations for fine-grained categorization. Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei, Proceedings of the IEEE international conference on computer vision workshops. the IEEE international conference on computer vision workshops2013</p>
<p>Out-of-distribution generalization via risk extrapolation (rex). David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville, ICML. 2021</p>
<p>Towards last-layer retraining for group robustness with fewer annotations. Tyler Labonte, Vidya Muthukumar, Abhishek Kumar, NeurIPS2023</p>
<p>The group robustness is in the details: Revisiting finetuning under spurious correlations. Tyler Labonte, John Hill, Xinchen Zhang, Vidya Muthukumar, Abhishek Kumar, Advances in Neural Information Processing Systems. 202437</p>
<p>Unmasking clever hans predictors and assessing what machines really learn. Sebastian Lapuschkin, Stephan WÃ¤ldchen, Alexander Binder, GrÃ©goire Montavon, Wojciech Samek, Klaus-Robert MÃ¼ller, Nature communications. 10110962019</p>
<p>Continual learning in the presence of spurious correlations: Analyses and a simple baseline. Donggyu Lee, Sangwon Jung, Taesup Moon, The Twelfth International Conference on Learning Representations. Jungsoo Lee, Eungyeup Kim, Juyoung Lee, Jihyeon Lee, Jaegul Choo, 2024. 2021NeurIPS</p>
<p>Diversify and disambiguate: Out-of-distribution robustness via disagreement. Yoonho Lee, Huaxiu Yao, Chelsea Finn, ICLR2023</p>
<p>Large-scale methods for distributionally robust optimization. Daniel Levy, Yair Carmon, John C Duchi, Aaron Sidford, NeurIPS2020</p>
<p>Deeper, broader and artier domain generalization. Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M Hospedales, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision2017</p>
<p>Domain generalization with adversarial feature learning. Haoliang Li, Sinno Jialin Pan, Shiqi Wang, Alex C Kot, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2018</p>
<p>Progressive domain expansion network for single domain generalization. Lei Li, Ke Gao, Juan Cao, Ziyao Huang, Yepeng Weng, Xiaoyue Mi, Zhengze Yu, Xiaoya Li, Boyang Xia, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2021</p>
<p>A whac-a-mole dilemma: Shortcuts come in multiples where mitigating one amplifies others. Zhiheng Li, Ivan Evtimov, Albert Gordo, Caner Hazirbas, Tal Hassner, Cristian Canton Ferrer, Chenliang Xu, Mark Ibrahim, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)June 2023</p>
<p>The devil is in the details: Tackling unimodal spurious correlations for generalizable multimodal reward models. Zichao Li, Xueru Wen, Jie Lou, Yuqiu Ji, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun, arXiv:2503.031222025arXiv preprint</p>
<p>Metashift: A dataset of datasets for evaluating contextual distribution shifts and training conflicts. Weixin Liang, James Zou, International Conference on Learning Representations. 2022</p>
<p>Just Train Twice: Improving Group Robustness without Training Group Information. Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn, ICML. 2021</p>
<p>Avoiding spurious correlations via logit correction. Sheng Liu, Xu Zhang, Nitesh Sekhar, Yue Wu, Prateek Singhal, Carlos Fernandez-Granda, ICLR2023</p>
<p>Adversarial cooperative rationalization: The risk of spurious correlations in even clean datasets. Wei Liu, Zhongyu Niu, Lang Gao, Zhiying Deng, Jun Wang, Haozhao Wang, Ruixuan Li, arXiv:2505.021182025aarXiv preprint</p>
<p>From screens to scenes: A survey of embodied ai in healthcare. Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen, Information Fusion. 1191030332025b</p>
<p>Deep learning face attributes in the wild. Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang, Proceedings of International Conference on Computer Vision (ICCV). International Conference on Computer Vision (ICCV)2015</p>
<p>Mitigating spurious correlations in zero-shot multimodal models. Shenyu Lu, Junyi Chai, Xiaoqian Wang, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Explanation-based finetuning makes models more robust to spurious cues. Josh Magnus Ludan, Yixuan Meng, Tai Nguyen, Saurabh Shah, Qing Lyu, Marianna Apidianaki, Chris Callison-Burch, ACL. 2023</p>
<p>Wedge: A multi-weather autonomous driving dataset built from generative vision-language models. Aboli Marathe, Deva Ramanan, Rahee Walambe, Ketan Kotecha, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2023</p>
<p>Hard imagenet: Segmentations for objects with strong spurious cues. Mazda Moayeri, Sahil Singla, Soheil Feizi, Advances in Neural Information Processing Systems. S Koyejo, S Mohamed, A Agarwal, D Belgrave, K Cho, A Oh, Curran Associates, Inc202235</p>
<p>Spuriosity rankings: Sorting data to measure and mitigate biases. Mazda Moayeri, Wenxiao Wang, Sahil Singla, Soheil Feizi, NeurIPS2023</p>
<p>Varun Mulchandani, Jung-Eun Kim, arXiv:2503.18258Severing spurious correlations with data pruning. 2025arXiv preprint</p>
<p>Learning from failure: De-biasing classifier from biased classifier. Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, Jinwoo Shin, 2020NeurIPS</p>
<p>Spread spurious attribute: Improving worstgroup accuracy with spurious attribute estimation. Junhyun Nam, Jaehyung Kim, Jaeho Lee, Jinwoo Shin, ICLR2022</p>
<p>Aryan Yazdan Parast, Hamidreza Yaghoubi Araghi, and Mahdieh Soleymani Baghshah. Decompose-and-compose: A compositional approach to mitigating spurious correlation. Fahimeh Hosseini Noohdani, Parsa Hosseini, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2024</p>
<p>Dissecting racial bias in an algorithm used to manage the health of populations. Ziad Obermeyer, Brian Powers, Christine Vogeli, Sendhil Mullainathan, Science. 36664642019</p>
<p>Position: A call for embodied AI. Giuseppe Paolo, Jonas Gonzalez-Billandon, BalÃ¡zs KÃ©gl, Fortyfirst International Conference on Machine Learning. 2024</p>
<p>Offsetbias: Leveraging debiased data for tuning evaluators. Junsoo Park, Seungyeon Jwa, Ren Meiying, Daeyoung Kim, Sanghyuk Choi, Findings of the Association for Computational Linguistics: EMNLP 2024. 2024a</p>
<p>Disentangling length from quality in direct preference optimization. Ryan Park, Rafael Rafailov, Stefano Ermon, Chelsea Finn, Findings of the Association for Computational Linguistics ACL 2024. 2024b</p>
<p>Nuisances via negativa: Adjusting for spurious correlations via data augmentation. Aahlad Puli, Nitish Joshi, 2022arXivHe He, and Rajesh Ranganath</p>
<p>Synthcity: a benchmark framework for diverse use cases of tabular synthetic data. Zhaozhi Qian, Rob Davis, Mihaela Van Der Schaar, Advances in Neural Information Processing Systems. A Oh, T Naumann, A Globerson, K Saenko, M Hardt, S Levine, Curran Associates, Inc202336</p>
<p>Complexity matters: feature learning in the presence of spurious correlations. Guanwen Qiu, Da Kuang, Surbhi Goel, Forty-first International Conference on Machine Learning. 2024</p>
<p>Simple and fast group robustness by automatic feature reweighting. Shikai Qiu, Andres Potapczynski, Pavel Izmailov, Andrew Gordon, Wilson , International Conference on Machine Learning. PMLR2023</p>
<p>Scaling laws for reward model overoptimization in direct alignment algorithms. Rafael Rafailov, Yaswanth Chittepu, Ryan Park, Harshit Sikchi, Joey Hejna, Bradley Knox, Chelsea Finn, Scott Niekum, The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024</p>
<p>The risks of invariant risk minimization. Elan Rosenfeld, Pradeep Kumar Ravikumar, Andrej Risteski, ICLR. 2021</p>
<p>ImageNet Large Scale Visual Recognition Challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C Berg, Li Fei-Fei, 10.1007/s11263-015-0816-yInternational Journal of Computer Vision (IJCV). 11532015</p>
<p>Reducing reliance on spurious features in medical image classification with spatial specificity. Khaled Saab, Sarah Hooper, Mayee Chen, Michael Zhang, Daniel Rubin, Christopher RÃ©, Machine Learning for Healthcare Conference. PMLR2022</p>
<p>Distributionally robust neural networks. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, Percy Liang, In ICLR. 2019a</p>
<p>Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, Percy Liang, arXiv:1911.087312019barXiv preprint</p>
<p>An investigation of why overparameterization exacerbates spurious correlations. Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, Percy Liang, ICML. 2020a</p>
<p>An Investigation of Why Overparameterization Exacerbates Spurious Correlations. Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, Percy Liang, ICML. 2020b</p>
<p>Prompting is a double-edged sword: improving worst-group robustness of foundation models. Amrith Setlur, Saurabh Garg, Virginia Smith, Sergey Levine, Forty-first International Conference on Machine Learning. 2024</p>
<p>The Pitfalls of Simplicity Bias in Neural Networks. Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, Praneeth Netrapalli, NeurIPS2020</p>
<p>Deceptive learning in histopathology. Sahar Shahamatdar, Daryoush Saeed-Vafa, Drew Linsley, Farah Khalil, Katherine Lovinger, Lester Li, Howard T Mcleod, Sohini Ramachandran, Thomas Serre, Histopathology. 8512024</p>
<p>Towards understanding sycophancy in language models. Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R Bowman, Durmus Esin, Zac Hatfield-Dodds, Shauna M Scott R Johnston, Kravec, The Twelfth International Conference on Learning Representations. 2023</p>
<p>Assessing robustness to spurious correlations in post-training language models. Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton, arXiv:2505.057042025arXiv preprint</p>
<p>Robustness to spurious correlations via human annotations. Megha Srivastava, Tatsunori Hashimoto, Percy Liang, ICML. 2020</p>
<p>Beyond invariance: Testtime label-shift adaptation for addressing "spurious" correlations. Qingyao Sun, Kevin Patrick Murphy, Sayna Ebrahimi, Alexander D' Amour, NeurIPS2023</p>
<p>Dive: subgraph disagreement for graph out-of-distribution generalization. Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang, Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2024</p>
<p>Recovering latent causal factor for generalization to distributional shifts. Xinwei Sun, Botong Wu, Xiangyu Zheng, Chang Liu, Wei Chen, Tao Qin, Tie-Yan Liu, NeurIPS2021</p>
<p>Long-tailed classification by keeping the good and removing the bad momentum causal effect. Kaihua Tang, Jianqiang Huang, Hanwang Zhang, NeurIPS2020</p>
<p>Measuring robustness to natural distribution shifts in image classification. Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, Ludwig Schmidt, NeurIPS. 2020</p>
<p>What matters to you? towards visual representation alignment for robot learning. Ran Tian, Chenfeng Xu, Masayoshi Tomizuka, Jitendra Malik, Andrea Bajcsy, arXiv:2310.079322023arXiv preprint</p>
<p>Overcoming Simplicity Bias in Deep Networks using a Feature Sieve. Rishabh Tiwari, Pradeep Shenoy, ICML. 2023</p>
<p>Unbiased look at dataset bias. Antonio Torralba, Alexei A Efros, 10.1109/CVPR.2011.5995347CVPR 2011. 2011</p>
<p>Nikita Tsoy, Nikola Konstantinov, arXiv:2405.17299Simplicity bias of two-layer networks beyond linearly separable data. 2024arXiv preprint</p>
<p>Principles of risk minimization for learning theory. Vladimir Vapnik, 1991NeurIPS</p>
<p>Ravl: Discovering and mitigating spurious correlations in fine-tuned vision-language models. Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz, Advances in Neural Information Processing Systems. 202437</p>
<p>Counterfactual invariance to spurious correlations in text classification. Victor Veitch, D' Alexander, Steve Amour, Jacob Yadlowsky, Eisenstein, NeurIPS2021</p>
<p>Causal feature alignment: Learning to ignore spurious background features. Rahul Venkataramani, Parag Dutta, Vikram Melapudi, Ambedkar Dukkipati, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. the IEEE/CVF Winter Conference on Applications of Computer Vision2024</p>
<p>Deep hashing network for unsupervised domain adaptation. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, Sethuraman Panchanathan, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2017</p>
<p>On calibration and out-of-domain generalization. Yoav Wald, Amir Feder, Daniel Greenfeld, Uri Shalit, NeurIPS2021</p>
<p>Meta convolutional neural networks for single domain generalization. Chaoqun Wan, Xu Shen, Yonggang Zhang, Zhiheng Yin, Xinmei Tian, Feng Gao, Jianqiang Huang, Xian-Sheng Hua, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Generalizing to Unseen Domains: A Survey on Domain Generalization. Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, Philip S Yu, 10.1109/TKDE.2022.3178128TKDE. 1558-2191358August 2023</p>
<p>Learning generalizable models via disentangling spurious and enhancing potential correlations. Na Wang, Lei Qi, Jintao Guo, Yinghuan Shi, Yang Gao, IEEE Transactions on Image Processing. 332024a</p>
<p>A sober look at the robustness of clips to spurious features. Qizhou Wang, Yong Lin, Yongqiang Chen, Ludwig Schmidt, Bo Han, Tong Zhang, arXiv:2403.114972024barXiv preprint</p>
<p>Causal attention for unbiased visual recognition. Tan Wang, Chang Zhou, Qianru Sun, Hanwang Zhang, ICCV. 2021</p>
<p>Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald M Summers, CVPR. 2017</p>
<p>Robustness to spurious correlations in text classification via automatically generated counterfactuals. Zhao Wang, Aron Culotta, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>The illusion of role separation: Hidden shortcuts in llm role learning (and how to fix them). Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang, arXiv:2505.006262025arXiv preprint</p>
<p>The cancer genome atlas pan-cancer analysis project. Eric A John N Weinstein, Gordon B Collisson, Kenna R Mills, Brad A Shaw, Kyle Ozenberger, Ilya Ellrott, Chris Shmulevich, Joshua M Sander, Stuart, Nature genetics. 45102013</p>
<p>Elastic representation: Mitigating spurious correlations for group robustness. Tao Wen, Zihan Wang, Quan Zhang, Qi Lei, arXiv:2502.098502025arXiv preprint</p>
<p>A broad-coverage challenge corpus for sentence understanding through inference. Adina Williams, Nikita Nangia, Samuel R Bowman, arXiv:1704.054262017arXiv preprint</p>
<p>Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition. Julia K Winkler, Christine Fink, Ferdinand Toberer, Alexander H Enk, Teresa Deinlein, Rainer Hofmann-Wellenhof, Luc Thomas, Aimilios Lallas, Andreas Blum, Wilhelm Stolz, Holger A Haenssle, JAMA dermatology. 2019. 199574483</p>
<p>No free lunch theorems for optimization. H David, William G Wolpert, Macready, IEEE transactions on evolutionary computation. 111997</p>
<p>Policy contrastive decoding for robotic foundation models. Shihan Wu, Ji Zhang, Xu Luo, Junlin Xie, Jingkuan Song, Heng Tao Shen, Lianli Gao, arXiv:2505.132552025arXiv preprint</p>
<p>Discover and cure: Concept-aware mitigation of spurious correlation. Shirley Wu, Mert Yuksekgonul, Linjun Zhang, James Zou, ICML. 2023a</p>
<p>Re-sort: Removing spurious correlation in multilevel interaction for ctr prediction. Song-Li Wu, Liang Du, Jia-Qi Yang, Yu-Ai Wang, Shuang De-Chuan Zhan, Zi-Xun Zhao, Sun, arXiv:2309.14891arXiv:2201.12872Xiang Wang, An Zhang, Xiangnan He, and Tat-Seng Chua. Discovering invariant rationales for graph neural networks. 2023b. 2022arXiv preprint</p>
<p>Noise or signal: The role of image backgrounds in object recognition. Kai Yuanqing, Xiao , Logan Engstrom, Andrew Ilyas, Aleksander Madry, ICLR2020</p>
<p>Robust interpretable text classification against spurious correlations using and-rules with negation. Rohan Kumar Yadav, Jiao Lei, Ole-Christoffer Granmo, Morten Goodwin, IJCAI. 2022</p>
<p>Chroma-vae: Mitigating shortcut learning with generative classifiers. Wanqian Yang, Polina Kirichenko, Micah Goldblum, Andrew G Wilson, NeurIPS2022a</p>
<p>Understanding rare spurious correlations in neural networks. Yao-Yuan, Chi-Ning Yang, Kamalika Chou, Chaudhuri, ICML 2022: Workshop on Spurious Correlations, Invariance and Stability. 2022b</p>
<p>Identifying spurious biases early in training through the lens of simplicity bias. Yu Yang, Eric Gan, Gintare Karolina Dziugaite, Baharan Mirzasoleiman, 2023aarXiv</p>
<p>Mitigating spurious correlations in multi-modal models during fine-tuning. Yu Yang, Besmira Nushi, Hamid Palangi, Baharan Mirzasoleiman, ICML. 2023b</p>
<p>Change is Hard: A Closer Look at Subpopulation Shift. Yuzhe Yang, Haoran Zhang, Dina Katabi, Marzyeh Ghassemi, ICML. arXiv. 2023c</p>
<p>Improving out-of-distribution robustness via selective augmentation. Huaxiu Yao, Yu Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, Chelsea Finn, ICML. 2022</p>
<p>Empowering graph invariance learning with deep spurious infomax. Tianjun Yao, Yongqiang Chen, Zhenhao Chen, Kai Hu, Zhiqiang Shen, Kun Zhang, arXiv:2407.110832024arXiv preprint</p>
<p>Mm-spubench: Towards better understanding of spurious biases in multimodal llms. Wenqian Ye, Guangtao Zheng, Yunsheng Ma, Xu Cao, Bolin Lai, James M Rehg, Aidong Zhang, arXiv:2406.171262024arXiv preprint</p>
<p>Improving group robustness on spurious correlation via evidential alignment. Wenqian Ye, Guangtao Zheng, Aidong Zhang, arXiv:2506.113472025arXiv preprint</p>
<p>Facts: First amplify correlations and then slice to discover bias. Sriram Yenamandra, Pratik Ramesh, Viraj Prabhu, Judy Hoffman, ICCV. 2023</p>
<p>Do llms overcome shortcut learning? an evaluation of shortcut challenges in large language models. Yu Yuan, Lili Zhao, Kai Zhang, Guangting Zheng, Qi Liu, arXiv:2410.133432024arXiv preprint</p>
<p>Federated self-explaining gnns with anti-shortcut augmentations. Linan Yue, Qi Liu, Weibo Gao, Ye Liu, Kai Zhang, Yichao Du, Li Wang, Fangzhou Yao, Forty-first International Conference on Machine Learning. 2024</p>
<p>Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study. Marcus A John R Zech, Manway Badgeley, Anthony B Liu, Joseph J Costa, Eric Titano, Karl Oermann, PLoS medicine. 2018</p>
<p>Counterfactual generator: A weakly-supervised method for named entity recognition. Xiangji Zeng, Yunliang Li, Yuchen Zhai, Yin Zhang, EMNLP. 2020</p>
<p>Targeted activation penalties help cnns ignore spurious signals. Dekai Zhang, Matt Williams, Francesca Toni, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2024a38</p>
<p>Inspire: Visionlanguage-action models with intrinsic spatial reasoning. Ji Zhang, Shihan Wu, Xu Luo, Hao Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song, arXiv:2505.138882025arXiv preprint</p>
<p>Correct-n-contrast: a contrastive approach for improving robustness to spurious correlations. Michael Zhang, S Nimit, Sohoni, Chelsea Hongyang R Zhang, Christopher Finn, Re, ICML. 2022</p>
<p>Metacoco: A new few-shot classification benchmark with spurious correlation. Min Zhang, Haoxuan Li, Fei Wu, Kun Kuang, The Twelfth International Conference on Learning Representations. 2024b</p>
<p>Deep stable learning for out-of-distribution generalization. Xingxuan Zhang, Peng Cui, Renzhe Xu, Linjun Zhou, Yue He, Zheyan Shen, CVPR. 2021</p>
<p>Benchmarking spurious bias in few-shot image classifiers. Guangtao Zheng, Wenqian Ye, Aidong Zhang, European Conference on Computer Vision. Springer2024a</p>
<p>Learning robust classifiers with self-guided spurious correlation mitigation. Guangtao Zheng, Wenqian Ye, Aidong Zhang, arXiv:2405.036492024barXiv preprint</p>
<p>Spuriousness-aware meta-learning for learning robust classifiers. Guangtao Zheng, Wenqian Ye, Aidong Zhang, KDD. 2024c</p>
<p>Neurontune: Towards self-guided spurious bias mitigation. Guangtao Zheng, Wenqian Ye, Aidong Zhang, arXiv:2505.240482025arXiv preprint</p>
<p>Places: A 10 million image database for scene recognition. Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, Antonio Torralba, IEEE transactions on pattern analysis and machine intelligence. 201740</p>
<p>Examining and combating spurious features under distribution shift. Chunting Zhou, Xuezhe Ma, Paul Michel, Graham Neubig, ICML. 2021</p>
<p>Aligning modalities in vision large language models via preference fine-tuning. Yiyang Zhou, Chenhang Cui, Rafael Rafailov, Chelsea Finn, Huaxiu Yao, arXiv:2402.114112024aarXiv preprint</p>
<p>Explore spurious correlations at the concept level in language models for text classification. Yuhang Zhou, Paiheng Xu, Xiaoyu Liu, Bang An, Wei Ai, Furong Huang, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics2024b1</p>
<p>A survey of trustworthy representation learning across domains. Ronghang Zhu, Dongliang Guo, Daiqing Qi, Zhixuan Chu, Xiang Yu, Sheng Li, 10.1145/3657301ACM Trans. Knowl. Discov. Data. 1556- 4681187June 2024</p>
<p>Rt-2: Vision-language-action models transfer web knowledge to robotic control. Brianna Zitkovich, Tianhe Yu, Sichun Xu, Peng Xu, Ted Xiao, Fei Xia, Jialin Wu, Paul Wohlhart, Stefan Welker, Ayzaan Wahid, Conference on Robot Learning. PMLR2023</p>            </div>
        </div>

    </div>
</body>
</html>