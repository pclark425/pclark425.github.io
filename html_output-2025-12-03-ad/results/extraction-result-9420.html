<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9420 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9420</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9420</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-bac292286c7d12df6863c7ca8dec720ed6288302</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/bac292286c7d12df6863c7ca8dec720ed6288302" target="_blank">Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams</a></p>
                <p><strong>Paper Venue:</strong> AAAI Workshops</p>
                <p><strong>Paper TL;DR:</strong> This work presents an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time, and shows the approach's potential to greatly reduce analyst workloads.</p>
                <p><strong>Paper Abstract:</strong> Analysis of an organization's computer network activity is a key component of early detection and mitigation of insider threat, a growing concern for many organizations. Raw system logs are a prototypical example of streaming data that can quickly scale beyond the cognitive power of a human analyst. As a prospective filter for the human analyst, we present an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time. Our models decompose anomaly scores into the contributions of individual user behavior features for increased interpretability to aid analysts reviewing potential cases of insider threat. Using the CERT Insider Threat Dataset v6.2 and threat detection recall as our performance metric, our novel deep and recurrent neural network models outperform Principal Component Analysis, Support Vector Machine and Isolation Forest based anomaly detection baselines. For our best model, the events labeled as insider threat activity in our dataset had an average anomaly score in the 95.53 percentile, demonstrating our approach's potential to greatly reduce analyst workloads.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9420.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9420.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Neural Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A feedforward deep neural network trained online to model per-user daily feature vectors and score anomalies via prediction / reconstruction error on structured security telemetry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>custom DNN (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>feedforward deep neural network</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>mixed-type tabular vectors (408 continuous count features + 6 categorical features; experiments ultimately used counts only)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2), aggregated to user-day</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>rare/novel insider-threat events (outliers / anomalous user-days)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Trains a shared-parameter DNN (online) to predict / reconstruct per-user daily feature vectors; anomaly is negative log-probability of observation under predicted distribution (equivalently squared error when using identity covariance). Both 'same time step' reconstruction (autoencoder-like) and 'next time step' prediction modes evaluated; diagonal covariance Gaussian output used for continuous counts in best models.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Isolation Forest, one-class SVM, PCA</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k (CR-400, CR-1000) computed from ranked anomaly scores; recall curves at different daily analyst budgets</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>DNN-Diag (counts only): CR-400 = 11.7, CR-1000 = 35.7. DNN-Diag-NextTime: CR-400 = 9.4, CR-1000 = 32.5. With daily budget 425, DNN-Diag achieved 100% recall on test set.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Slightly outperforms Isolation Forest, PCA, and one-class SVM on CR-k metrics; Isolation Forest was the strongest baseline and performed nearly as well (Isolation Forest CR-400 = 10.8, CR-1000 = 34.8).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Per-day aggregation may miss intra-day anomalous sequences; performance depends on choice of covariance (identity vs diagonal); initial online cold-start yields large anomaly scores; adding categorical metadata harmed performance in this dataset (increased complexity and reduced trainability); DNN and LSTM performed similarly, likely due to limited temporal patterns in the synthetic dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Same-time-step reconstruction (autoencoder-style) yielded better detection than next-time-step prediction for this task; diagonal covariance output (conditioning variance on context) improved performance over identity covariance; model decomposes anomaly into per-feature contributions for interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9420.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory Recurrent Neural Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep LSTM RNN trained online with per-user hidden states (shared weights) to model temporal patterns in user behavior and assign anomaly scores based on prediction/reconstruction likelihood.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>custom LSTM (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM recurrent neural network</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>mixed-type tabular time series (daily vectors of counts and categorical attributes; experiments used counts only)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2), aggregated to user-day</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>rare/novel insider-threat events (outliers / anomalous user-days / anomalous sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Shared-weight multi-user deep LSTM with per-user hidden and cell states stored and updated online; model produces parameters for per-day conditional distributions (categorical via softmax, counts via Gaussian with identity or diagonal covariance) and anomaly is negative log-likelihood of the observed vector given previous hidden state (next-step) or given current hidden state (same-step reconstruction).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Isolation Forest, one-class SVM, PCA</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k (CR-400, CR-1000); recall vs analyst daily budget</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>LSTM-Diag (counts only): CR-400 = 11.6, CR-1000 = 35.6. LSTM-Diag-NextTime: CR-400 = 5.9, CR-1000 = 25.1. With daily budget 425, LSTM-Diag achieved 100% recall; 90% recall reached with budget ≈250.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Slightly outperforms baselines (Isolation Forest, PCA, one-class SVM) on CR-k; performance similar to DNN in these experiments. Diagonal-covariance LSTM outperformed identity-covariance LSTM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>On the CERT dataset LSTM did not significantly beat DNN—authors attribute this to insufficient multi-day temporal patterns in the synthetic data; per-day aggregation may reduce advantage of sequence modeling; storage and management of per-user hidden states required for online training; warm-up / burn-in period causes high initial anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Online training with stored per-user hidden/cell states enables per-user sequence modeling at streaming scale; same-time-step reconstruction benefits LSTM more than next-time-step prediction; dynamic (context-dependent) diagonal covariance can normalize features more effectively than a fixed identity covariance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9420.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SameTime_Reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Same-time-step reconstruction (auto-encoder style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Anomaly detection mode where the model predicts/reconstructs the current input given a compressed hidden representation (autoencoder-like); anomaly is negative log-probability of reconstructing the current input.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>same-time-step reconstruction mode (implemented with DNN/LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>reconstruction / autoencoder-style using DNN or LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>mixed-type tabular (daily user aggregated counts + categorical metadata)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / anomalous user-day feature vectors</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train network to reproduce input vector given current hidden representation; anomaly is -log P(x_t | h_t). This functions like an auto-encoder where reconstruction error indicates novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>compared with 'next time step' prediction and classical baselines (Isolation Forest, SVM, PCA)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Same-time-step (DNN / LSTM diagonal covariance) outperformed next-time-step: e.g., DNN-Diag vs DNN-Diag-NextTime (11.7 vs 9.4 CR-400; 35.7 vs 32.5 CR-1000). LSTM benefit was larger.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Same-time-step reconstruction with DNN/LSTM outperformed baselines and next-step prediction variants.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>May reconstruct frequent but maliciously subtle patterns if model capacity is large; constrained by per-day aggregation which can miss within-day anomalies; no explicit exploration of deeper autoencoder architectures beyond the reconstruction vs prediction dichotomy.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>For this dataset, autoencoder-style reconstruction is more effective than next-step prediction for detecting anomalous user-days; treating counts with a diagonal Gaussian output (estimating per-dimension variance) further improves detection capability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9420.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Diag-Gaussian-Output</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Context-dependent diagonal Gaussian output (MDN-like)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Output parameterization for continuous count features where model predicts both per-dimension mean and log-variance (diagonal covariance Gaussian), enabling probabilistic anomaly scoring and per-feature decomposition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>diagonal-covariance Gaussian output (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>probabilistic output layer (Gaussian with diagonal covariance), MDN-like</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>continuous count vectors (408 dims), part of mixed-type tabular data</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / unexpected count magnitudes per feature</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Seven small predictor networks output parameters: for counts the network outputs mean vector and log of diagonal covariance; anomaly computed as -log N(x; mu, Sigma). This conditions variance on context and allows per-feature contribution decomposition.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>identity-covariance variant, standard reconstruction (MSE)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Diagonal covariance models (DNN-Diag, LSTM-Diag) outperformed identity covariance variants (DNN-Ident, LSTM-Ident): e.g., DNN-Diag CR-400=11.7 vs DNN-Ident CR-400=9.8.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Diagonal covariance provided better normalization and detection than identity covariance; also contributed to outperforming classical baselines when used with DNN/LSTM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Assumes conditional independence between categorical and continuous groups for joint probability approximation; diagonal covariance ignores cross-feature covariance (no full covariance modeling), which may limit detection of anomalies that manifest in correlated feature patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Conditioning per-dimension variance on context improves anomaly detection compared to fixed identity covariance; it also enables meaningful per-feature anomaly decomposition for interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9420.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IsolationForest</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Isolation Forest</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised tree-based anomaly detection algorithm that isolates anomalies via random partitioning; used here as a baseline on the same feature vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Isolation forest</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Isolation Forest (scikit-learn implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>ensemble of randomized trees / isolation-based anomaly detector</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>mixed-type tabular vectors (counts; authors used counts only for baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / anomalous user-days</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Applied to per-user-per-day aggregated feature vectors; hyperparameters (n_estimators, contamination) tuned on development set; anomaly score is isolation-based path length metric.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>compared against DNN and LSTM models, one-class SVM, PCA</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k; recall vs analyst budget</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Isolation Forest: CR-400 = 10.8, CR-1000 = 34.8. With daily budget 425, Isolation Forest achieved 100% recall.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Strongest classical baseline; performance close to best DNN/LSTM models but slightly worse on CR metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Does not provide per-feature probabilistic decomposition in the same natural way as the probabilistic neural outputs; hyperparameter sensitivity; like other baselines, performance may degrade for temporal patterns since it treats aggregated vectors statically.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>A well-tuned isolation forest can be competitive with online deep models on aggregated daily feature vectors for insider-threat detection in this dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9420.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OneClassSVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>One-Class Support Vector Machine</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A novelty detection SVM variant used as a baseline; attempts to estimate the support of the distribution of normal data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Estimating the support of a high-dimensional distribution</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>one-class SVM (scikit-learn implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>kernel-based novelty detection (SVM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>mixed-type tabular vectors (counts only used)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / anomalous user-days</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Trained on per-user-day aggregated feature vectors; kernel and ν hyperparameters tuned on development set; anomaly score derived from distance to learned support boundary.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>compared with Isolation Forest, PCA, DNN, LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>One-class SVM: CR-400 = 5.3, CR-1000 = 24.2 (worst among baselines reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Performed worse than isolation forest, PCA, DNN and LSTM on CR metrics in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lower recall in this application; may be sensitive to kernel choice and scaling; not as effective on high-dimensional sparse count vectors aggregated per day.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Classical kernel-based novelty detection underperformed relative to tree-based and deep learning approaches on CERT aggregated daily features.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9420.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PCA-Reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Principal Component Analysis (reconstruction error)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A linear dimensionality reduction baseline: project onto top-k principal components and measure reconstruction error as anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A novel anomaly detection scheme based on principal component classifier</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PCA-based reconstruction (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>linear projection / reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>mixed-type tabular vectors (counts only used)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>synthetic cybersecurity system logs (CERT Insider Threat v6.2)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / anomalous user-days</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Project feature vectors onto first k principal components and compute reconstruction error; k tuned on development set; anomaly proportional to reconstruction error.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>compared with Isolation Forest, one-class SVM, DNN, LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cumulative Recall CR-k</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>PCA: CR-400 = 9.4, CR-1000 = 32.8.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Better than one-class SVM, worse than best DNN/LSTM and slightly worse than Isolation Forest.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Linear model cannot capture complex non-linear correlations; reconstruction-based PCA less powerful than diagonal-Gaussian probabilistic DNN/LSTM in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Provides a simple baseline; performance indicates much of the signal can be captured by low-dimensional linear structure but non-linear models provide improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9420.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9420.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Related-RNN-Anomaly</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RNN / LSTM anomaly detection references (prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior studies that applied recurrent neural networks (including LSTM encoder-decoder architectures) to anomaly detection in sequential sensor, ECG, and acoustic data are cited and discussed as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM-based encoder-decoder and RNN anomaly detectors (cited works)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM / RNN</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>time series / sequential sensor signals (multivariate time series, ECG, acoustic signals)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>machinery sensor data, ECG, acoustic novelty detection (domains of cited works)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>novelty / anomaly in temporal sequences</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cited works (e.g., Malhotra et al. 2016; Chauhan & Vig 2015; Marchi et al. 2015) use LSTM encoder-decoder or prediction-based RNNs for anomaly scoring via reconstruction or prediction error.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>These prior works focus on continuous sensor-like signals and do not directly address mixed categorical/count structured logs; the paper notes difference in data types.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Authors reference these works to justify sequence-modeling approach and to contrast data modalities (their problem includes categorical + counts aggregated into tabular vectors).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams', 'publication_date_yy_mm': '2017-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LSTM-based encoder-decoder for multi-sensor anomaly detection <em>(Rating: 2)</em></li>
                <li>Anomaly detection in ecg time signals via deep long short-term memory networks <em>(Rating: 1)</em></li>
                <li>A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks <em>(Rating: 1)</em></li>
                <li>Isolation forest <em>(Rating: 2)</em></li>
                <li>Supervised and unsupervised methods to detect insider threat from enterprise social and online activity data <em>(Rating: 1)</em></li>
                <li>Mixture density networks <em>(Rating: 1)</em></li>
                <li>A I^2 : Training a big data machine to defend <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9420",
    "paper_id": "paper-bac292286c7d12df6863c7ca8dec720ed6288302",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "DNN",
            "name_full": "Deep Neural Network",
            "brief_description": "A feedforward deep neural network trained online to model per-user daily feature vectors and score anomalies via prediction / reconstruction error on structured security telemetry.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "custom DNN (this paper)",
            "model_type": "feedforward deep neural network",
            "model_size": null,
            "data_type": "mixed-type tabular vectors (408 continuous count features + 6 categorical features; experiments ultimately used counts only)",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2), aggregated to user-day",
            "anomaly_type": "rare/novel insider-threat events (outliers / anomalous user-days)",
            "method_description": "Trains a shared-parameter DNN (online) to predict / reconstruct per-user daily feature vectors; anomaly is negative log-probability of observation under predicted distribution (equivalently squared error when using identity covariance). Both 'same time step' reconstruction (autoencoder-like) and 'next time step' prediction modes evaluated; diagonal covariance Gaussian output used for continuous counts in best models.",
            "baseline_methods": "Isolation Forest, one-class SVM, PCA",
            "performance_metrics": "Cumulative Recall CR-k (CR-400, CR-1000) computed from ranked anomaly scores; recall curves at different daily analyst budgets",
            "performance_results": "DNN-Diag (counts only): CR-400 = 11.7, CR-1000 = 35.7. DNN-Diag-NextTime: CR-400 = 9.4, CR-1000 = 32.5. With daily budget 425, DNN-Diag achieved 100% recall on test set.",
            "comparison_to_baseline": "Slightly outperforms Isolation Forest, PCA, and one-class SVM on CR-k metrics; Isolation Forest was the strongest baseline and performed nearly as well (Isolation Forest CR-400 = 10.8, CR-1000 = 34.8).",
            "limitations_or_failure_cases": "Per-day aggregation may miss intra-day anomalous sequences; performance depends on choice of covariance (identity vs diagonal); initial online cold-start yields large anomaly scores; adding categorical metadata harmed performance in this dataset (increased complexity and reduced trainability); DNN and LSTM performed similarly, likely due to limited temporal patterns in the synthetic dataset.",
            "unique_insights": "Same-time-step reconstruction (autoencoder-style) yielded better detection than next-time-step prediction for this task; diagonal covariance output (conditioning variance on context) improved performance over identity covariance; model decomposes anomaly into per-feature contributions for interpretability.",
            "uuid": "e9420.0",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "LSTM",
            "name_full": "Long Short-Term Memory Recurrent Neural Network",
            "brief_description": "A deep LSTM RNN trained online with per-user hidden states (shared weights) to model temporal patterns in user behavior and assign anomaly scores based on prediction/reconstruction likelihood.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "custom LSTM (this paper)",
            "model_type": "LSTM recurrent neural network",
            "model_size": null,
            "data_type": "mixed-type tabular time series (daily vectors of counts and categorical attributes; experiments used counts only)",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2), aggregated to user-day",
            "anomaly_type": "rare/novel insider-threat events (outliers / anomalous user-days / anomalous sequences)",
            "method_description": "Shared-weight multi-user deep LSTM with per-user hidden and cell states stored and updated online; model produces parameters for per-day conditional distributions (categorical via softmax, counts via Gaussian with identity or diagonal covariance) and anomaly is negative log-likelihood of the observed vector given previous hidden state (next-step) or given current hidden state (same-step reconstruction).",
            "baseline_methods": "Isolation Forest, one-class SVM, PCA",
            "performance_metrics": "Cumulative Recall CR-k (CR-400, CR-1000); recall vs analyst daily budget",
            "performance_results": "LSTM-Diag (counts only): CR-400 = 11.6, CR-1000 = 35.6. LSTM-Diag-NextTime: CR-400 = 5.9, CR-1000 = 25.1. With daily budget 425, LSTM-Diag achieved 100% recall; 90% recall reached with budget ≈250.",
            "comparison_to_baseline": "Slightly outperforms baselines (Isolation Forest, PCA, one-class SVM) on CR-k; performance similar to DNN in these experiments. Diagonal-covariance LSTM outperformed identity-covariance LSTM.",
            "limitations_or_failure_cases": "On the CERT dataset LSTM did not significantly beat DNN—authors attribute this to insufficient multi-day temporal patterns in the synthetic data; per-day aggregation may reduce advantage of sequence modeling; storage and management of per-user hidden states required for online training; warm-up / burn-in period causes high initial anomaly scores.",
            "unique_insights": "Online training with stored per-user hidden/cell states enables per-user sequence modeling at streaming scale; same-time-step reconstruction benefits LSTM more than next-time-step prediction; dynamic (context-dependent) diagonal covariance can normalize features more effectively than a fixed identity covariance.",
            "uuid": "e9420.1",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "SameTime_Reconstruction",
            "name_full": "Same-time-step reconstruction (auto-encoder style)",
            "brief_description": "Anomaly detection mode where the model predicts/reconstructs the current input given a compressed hidden representation (autoencoder-like); anomaly is negative log-probability of reconstructing the current input.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "same-time-step reconstruction mode (implemented with DNN/LSTM)",
            "model_type": "reconstruction / autoencoder-style using DNN or LSTM",
            "model_size": null,
            "data_type": "mixed-type tabular (daily user aggregated counts + categorical metadata)",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2)",
            "anomaly_type": "outliers / anomalous user-day feature vectors",
            "method_description": "Train network to reproduce input vector given current hidden representation; anomaly is -log P(x_t | h_t). This functions like an auto-encoder where reconstruction error indicates novelty.",
            "baseline_methods": "compared with 'next time step' prediction and classical baselines (Isolation Forest, SVM, PCA)",
            "performance_metrics": "Cumulative Recall CR-k",
            "performance_results": "Same-time-step (DNN / LSTM diagonal covariance) outperformed next-time-step: e.g., DNN-Diag vs DNN-Diag-NextTime (11.7 vs 9.4 CR-400; 35.7 vs 32.5 CR-1000). LSTM benefit was larger.",
            "comparison_to_baseline": "Same-time-step reconstruction with DNN/LSTM outperformed baselines and next-step prediction variants.",
            "limitations_or_failure_cases": "May reconstruct frequent but maliciously subtle patterns if model capacity is large; constrained by per-day aggregation which can miss within-day anomalies; no explicit exploration of deeper autoencoder architectures beyond the reconstruction vs prediction dichotomy.",
            "unique_insights": "For this dataset, autoencoder-style reconstruction is more effective than next-step prediction for detecting anomalous user-days; treating counts with a diagonal Gaussian output (estimating per-dimension variance) further improves detection capability.",
            "uuid": "e9420.2",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "Diag-Gaussian-Output",
            "name_full": "Context-dependent diagonal Gaussian output (MDN-like)",
            "brief_description": "Output parameterization for continuous count features where model predicts both per-dimension mean and log-variance (diagonal covariance Gaussian), enabling probabilistic anomaly scoring and per-feature decomposition.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "diagonal-covariance Gaussian output (this paper)",
            "model_type": "probabilistic output layer (Gaussian with diagonal covariance), MDN-like",
            "model_size": null,
            "data_type": "continuous count vectors (408 dims), part of mixed-type tabular data",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2)",
            "anomaly_type": "outliers / unexpected count magnitudes per feature",
            "method_description": "Seven small predictor networks output parameters: for counts the network outputs mean vector and log of diagonal covariance; anomaly computed as -log N(x; mu, Sigma). This conditions variance on context and allows per-feature contribution decomposition.",
            "baseline_methods": "identity-covariance variant, standard reconstruction (MSE)",
            "performance_metrics": "Cumulative Recall CR-k",
            "performance_results": "Diagonal covariance models (DNN-Diag, LSTM-Diag) outperformed identity covariance variants (DNN-Ident, LSTM-Ident): e.g., DNN-Diag CR-400=11.7 vs DNN-Ident CR-400=9.8.",
            "comparison_to_baseline": "Diagonal covariance provided better normalization and detection than identity covariance; also contributed to outperforming classical baselines when used with DNN/LSTM.",
            "limitations_or_failure_cases": "Assumes conditional independence between categorical and continuous groups for joint probability approximation; diagonal covariance ignores cross-feature covariance (no full covariance modeling), which may limit detection of anomalies that manifest in correlated feature patterns.",
            "unique_insights": "Conditioning per-dimension variance on context improves anomaly detection compared to fixed identity covariance; it also enables meaningful per-feature anomaly decomposition for interpretability.",
            "uuid": "e9420.3",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "IsolationForest",
            "name_full": "Isolation Forest",
            "brief_description": "An unsupervised tree-based anomaly detection algorithm that isolates anomalies via random partitioning; used here as a baseline on the same feature vectors.",
            "citation_title": "Isolation forest",
            "mention_or_use": "use",
            "model_name": "Isolation Forest (scikit-learn implementation)",
            "model_type": "ensemble of randomized trees / isolation-based anomaly detector",
            "model_size": null,
            "data_type": "mixed-type tabular vectors (counts; authors used counts only for baselines)",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2)",
            "anomaly_type": "outliers / anomalous user-days",
            "method_description": "Applied to per-user-per-day aggregated feature vectors; hyperparameters (n_estimators, contamination) tuned on development set; anomaly score is isolation-based path length metric.",
            "baseline_methods": "compared against DNN and LSTM models, one-class SVM, PCA",
            "performance_metrics": "Cumulative Recall CR-k; recall vs analyst budget",
            "performance_results": "Isolation Forest: CR-400 = 10.8, CR-1000 = 34.8. With daily budget 425, Isolation Forest achieved 100% recall.",
            "comparison_to_baseline": "Strongest classical baseline; performance close to best DNN/LSTM models but slightly worse on CR metrics.",
            "limitations_or_failure_cases": "Does not provide per-feature probabilistic decomposition in the same natural way as the probabilistic neural outputs; hyperparameter sensitivity; like other baselines, performance may degrade for temporal patterns since it treats aggregated vectors statically.",
            "unique_insights": "A well-tuned isolation forest can be competitive with online deep models on aggregated daily feature vectors for insider-threat detection in this dataset.",
            "uuid": "e9420.4",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "OneClassSVM",
            "name_full": "One-Class Support Vector Machine",
            "brief_description": "A novelty detection SVM variant used as a baseline; attempts to estimate the support of the distribution of normal data.",
            "citation_title": "Estimating the support of a high-dimensional distribution",
            "mention_or_use": "use",
            "model_name": "one-class SVM (scikit-learn implementation)",
            "model_type": "kernel-based novelty detection (SVM)",
            "model_size": null,
            "data_type": "mixed-type tabular vectors (counts only used)",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2)",
            "anomaly_type": "outliers / anomalous user-days",
            "method_description": "Trained on per-user-day aggregated feature vectors; kernel and ν hyperparameters tuned on development set; anomaly score derived from distance to learned support boundary.",
            "baseline_methods": "compared with Isolation Forest, PCA, DNN, LSTM",
            "performance_metrics": "Cumulative Recall CR-k",
            "performance_results": "One-class SVM: CR-400 = 5.3, CR-1000 = 24.2 (worst among baselines reported).",
            "comparison_to_baseline": "Performed worse than isolation forest, PCA, DNN and LSTM on CR metrics in these experiments.",
            "limitations_or_failure_cases": "Lower recall in this application; may be sensitive to kernel choice and scaling; not as effective on high-dimensional sparse count vectors aggregated per day.",
            "unique_insights": "Classical kernel-based novelty detection underperformed relative to tree-based and deep learning approaches on CERT aggregated daily features.",
            "uuid": "e9420.5",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "PCA-Reconstruction",
            "name_full": "Principal Component Analysis (reconstruction error)",
            "brief_description": "A linear dimensionality reduction baseline: project onto top-k principal components and measure reconstruction error as anomaly score.",
            "citation_title": "A novel anomaly detection scheme based on principal component classifier",
            "mention_or_use": "use",
            "model_name": "PCA-based reconstruction (baseline)",
            "model_type": "linear projection / reconstruction",
            "model_size": null,
            "data_type": "mixed-type tabular vectors (counts only used)",
            "data_domain": "synthetic cybersecurity system logs (CERT Insider Threat v6.2)",
            "anomaly_type": "outliers / anomalous user-days",
            "method_description": "Project feature vectors onto first k principal components and compute reconstruction error; k tuned on development set; anomaly proportional to reconstruction error.",
            "baseline_methods": "compared with Isolation Forest, one-class SVM, DNN, LSTM",
            "performance_metrics": "Cumulative Recall CR-k",
            "performance_results": "PCA: CR-400 = 9.4, CR-1000 = 32.8.",
            "comparison_to_baseline": "Better than one-class SVM, worse than best DNN/LSTM and slightly worse than Isolation Forest.",
            "limitations_or_failure_cases": "Linear model cannot capture complex non-linear correlations; reconstruction-based PCA less powerful than diagonal-Gaussian probabilistic DNN/LSTM in these experiments.",
            "unique_insights": "Provides a simple baseline; performance indicates much of the signal can be captured by low-dimensional linear structure but non-linear models provide improvements.",
            "uuid": "e9420.6",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        },
        {
            "name_short": "Related-RNN-Anomaly",
            "name_full": "RNN / LSTM anomaly detection references (prior work)",
            "brief_description": "Prior studies that applied recurrent neural networks (including LSTM encoder-decoder architectures) to anomaly detection in sequential sensor, ECG, and acoustic data are cited and discussed as related work.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LSTM-based encoder-decoder and RNN anomaly detectors (cited works)",
            "model_type": "LSTM / RNN",
            "model_size": null,
            "data_type": "time series / sequential sensor signals (multivariate time series, ECG, acoustic signals)",
            "data_domain": "machinery sensor data, ECG, acoustic novelty detection (domains of cited works)",
            "anomaly_type": "novelty / anomaly in temporal sequences",
            "method_description": "Cited works (e.g., Malhotra et al. 2016; Chauhan & Vig 2015; Marchi et al. 2015) use LSTM encoder-decoder or prediction-based RNNs for anomaly scoring via reconstruction or prediction error.",
            "baseline_methods": "",
            "performance_metrics": "",
            "performance_results": "",
            "comparison_to_baseline": "",
            "limitations_or_failure_cases": "These prior works focus on continuous sensor-like signals and do not directly address mixed categorical/count structured logs; the paper notes difference in data types.",
            "unique_insights": "Authors reference these works to justify sequence-modeling approach and to contrast data modalities (their problem includes categorical + counts aggregated into tabular vectors).",
            "uuid": "e9420.7",
            "source_info": {
                "paper_title": "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams",
                "publication_date_yy_mm": "2017-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LSTM-based encoder-decoder for multi-sensor anomaly detection",
            "rating": 2
        },
        {
            "paper_title": "Anomaly detection in ecg time signals via deep long short-term memory networks",
            "rating": 1
        },
        {
            "paper_title": "A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks",
            "rating": 1
        },
        {
            "paper_title": "Isolation forest",
            "rating": 2
        },
        {
            "paper_title": "Supervised and unsupervised methods to detect insider threat from enterprise social and online activity data",
            "rating": 1
        },
        {
            "paper_title": "Mixture density networks",
            "rating": 1
        },
        {
            "paper_title": "A I^2 : Training a big data machine to defend",
            "rating": 2
        }
    ],
    "cost": 0.013849999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams</h1>
<p>Aaron Tuor and Samuel Kaplan and Brian Hutchinson*<br>Western Washington University<br>Bellingham, WA<br>Nicole Nichols and Sean Robinson<br>Pacific Northwest National Laboratory<br>Seattle, WA</p>
<h4>Abstract</h4>
<p>Analysis of an organization's computer network activity is a key component of early detection and mitigation of insider threat, a growing concern for many organizations. Raw system logs are a prototypical example of streaming data that can quickly scale beyond the cognitive power of a human analyst. As a prospective filter for the human analyst, we present an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time. Our models decompose anomaly scores into the contributions of individual user behavior features for increased interpretability to aid analysts reviewing potential cases of insider threat. Using the CERT Insider Threat Dataset v6.2 and threat detection recall as our performance metric, our novel deep and recurrent neural network models outperform Principal Component Analysis, Support Vector Machine and Isolation Forest based anomaly detection baselines. For our best model, the events labeled as insider threat activity in our dataset had an average anomaly score in the 95.53 percentile, demonstrating our approach's potential to greatly reduce analyst workloads.</p>
<h2>Introduction</h2>
<p>Insider threat is a complex and growing challenge for employers. It is generally defined as any actions taken by an employee which are potentially harmful to the organization; e.g., unsanctioned data transfer or sabotage of resources. Insider threat may manifest in various and novel forms motivated by differing goals, ranging from a disgruntled employee subverting the prestige of an employer to advanced persistent threats (APT), orchestrated multi-year campaigns to access and retrieve intelligence data (Hutchins, Cloppert, and Amin 2011).</p>
<p>Cyber defenders are tasked with assessing a large volume of real-time data. These datasets are high velocity, heterogeneous streams generated by a large set of possible entities (workstations, servers, routers) and activities (DNS requests, logons, file accesses). With the goal of efficient utilization of human resources, automated methods for filtering system log data for an analyst have been the focus of much past and current research, this work included.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>We present an online unsupervised deep learning system to filter system log data for analyst review. Because insider threat behavior is widely varying, we do not attempt to explicitly model threat behavior. Instead, novel variants of Deep Neural Networks (DNNs) and Recurrent Neural Networks (RNNs) are trained to recognize activity that is characteristic of each user on a network and concurrently assess whether user behavior is normal or anomalous, all in real time. With the streaming scenario in mind, the time and space complexity of our methods are constant as a function of stream duration; that is, no data is cached indefinitely and detections are made as rapidly as new data is fed into our DNN and RNN models. To aid analysts in interpreting system decisions, our model decomposes anomaly scores into a human readable summary of the major factors contributing to the detected anomaly (e.g. that the user copied an abnormally large number of files to removable media between 12am and 6am).</p>
<p>There are several key difficulties in applying machine learning to the cyber security domain (Sommer and Paxson 2010) that our model attempts to address. User activity on a network is often unpredictable over seconds to hours and contributes to the difficulty in finding a stable model of "normal" behavior. Our model trains continuously in an online fashion to adapt to changing patterns in the data. Also, anomaly detection for malicious events is particularly challenging because attackers often try to closely mimic typical behavior. We model the stream of system logs as interleaved user sequences with user-metadata to provide precise context for activity on the network; this allows our model, for example, to identify what is truly typical behavior for the user, employees in the same role, employees on the same project team, etc. We assess the effectiveness of our models on the synthetic CERT Insider Threat v6.2 dataset (Lindauer et al. 2014; Glasser and Lindauer 2013) which includes system logs with line-level annotations of insider threat activity. The ground truth threat labels are used only for evaluation.</p>
<h2>Prior Work</h2>
<p>A frequent approach to insider threat detection is to frame the problem as an anomaly detection task. A comprehensive overview of anomaly detection provided by Chandola et al. (2012) concludes that anomaly detection techniques for online and multivariate sequences are underdeveloped;</p>
<p>both issues are addressed in this paper. A real world system for anomaly detection in system logs should address the set of constraints given by the real time nature of the task and provide a set of features suitable for the application domain: concurrent tracking of multiple entities, analysis of structured multivariate data, adaptation to shifting distribution of activities, and interpretable judgments. While each work surveyed below addresses some subset of these components, our work addresses all of these constraints and features.</p>
<p>As mentioned above, it is common to approach tasks like intrusion detection or insider threat as anomaly detection. Carter and Streilein (2012) demonstrate a probabilistic extension of an exponentially weighted moving average for the application of anomaly detection in a streaming environment. This method learns a parametric statistical model that adapts to the changing distribution of streaming data. An advantage of our present approach using deep learning architectures is the ability to model a wider range of distributions with fewer underlying assumptions. Gavai et al. (2015) compare a supervised approach, from an expert-developed classifier, with an unsupervised approach using the Isolation Forest method at the task of detecting insider threat from network logs. They also aggregate information about which features contribute to the isolation of a point within the tree to produce motivation for why a user was flagged as anomalous. Considering this to be a reasonable approach, we include Isolation Forests as one of our baselines.</p>
<p>Researchers have also applied neural network-based approaches to cybersecurity tasks. Ryan et al. (1998) train a standard neural network with one hidden layer to predict the probabilities that each of a set of ten users created a distribution of Unix commands for a given day. They detect a network intrusion when the probability is less than 0.5 for all ten users of the network. Differing from our work, their input features are not structured, and they do not train the network in an online fashion. Early work on modeling normal user activity on a network using RNNs was performed by Debar et al. (1992). They train an RNN to convergence on a representative sequence of Unix command line arguments (from login to logout) and predict network intrusion when the trained network for that user does poorly at predicting the login to logout sequence. While this work partially addresses online training it does not continuously train the network to take into account changing user habits over time. Veeramachananeni et al. (2016) present work using a neural network auto-encoder in an online setting. They aggregate numeric features over a time window from web and firewall logs which are fed to an ensemble of unsupervised anomaly detection methods: principal component reconstruction of the signal, auto-encoder neural network, and a multivariate probabilistic model over the feature space. They additionally incorporate analyst feedback to continually improve with time, but do not explicitly model individual user activity over time.</p>
<p>Recurrent neural networks have, of course, been successfully applied to anomaly detection in various alternative domains; e.g., Malhotra et al. (2016) in the domain of signals from mechanical sensors for machinery such as engines, and vehicles, Chuahan et al. (2015) in the domain of ECG heart data, and Marchi et al. (2015a; 2015b) in the acoustic signal processing domain. In contrast to the present work, these applications are not faced with the task of processing a multivariate combination of categorical and continuous features.</p>
<h2>System Description</h2>
<p>Figure 1 provides an overview of our anomaly detection system. First, raw events from system user logs are fed into our feature extraction system, which aggregates their counts and outputs one vector for each user for each day. A user’s feature vectors are then fed into a neural network, creating a set of networks, one per user. In one variant of our system, these are DNNs; in the other, they are RNNs. In either case, the different user models share parameters, but for the RNN they maintain separate hidden states. These neural networks are tasked with predicting the next vector in the sequence; in effect, they learn to model users’ “normal” behavior. Anomaly is proportional to the prediction error, with sufficiently anomalous behavior being flagged for an analyst to investigate. The components in the system are described in greater detail below.</p>
<h3>Feature Extraction</h3>
<p>One practical consideration that a deep learning anomaly detection system must address is the transformation of system log lines from heterogeneous tracking sources into numeric features suitable as input. Our system extracts two kinds of information from these sources: categorical user attribute features and continuous “count” features. The categorical user features refer to attributes such as a user’s role, department, and supervisor in the organization. See Table 1 for a list of categorical features used in our experiments (along with the number of distinct values in each category). In addition to these categorical features, we also accumulate counts of 408 “activities” a user has performed over some fixed time window (e.g. 24 hours). An example of a counted activity is the number of uncommon non-decoy file copies from removable media between the hours of 12:00 p.m. and 6:00 p.m. Figure 2 visually enumerates the set of count features: simply follow a path from right to left, choosing one item in each set along the way. The set of all such traversals is the set of count features. For each user $u$, for each time period, $t$, the categorical values and activity counts are concatenated into a 414 dimensional numeric feature vector $\mathbf{x}_{t}^{u}$.</p>
<table>
<thead>
<tr>
<th>Categorical Var.</th>
<th># Unique Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>Role</td>
<td>46</td>
</tr>
<tr>
<td>Project</td>
<td>366</td>
</tr>
<tr>
<td>Functional Unit</td>
<td>11</td>
</tr>
<tr>
<td>Department</td>
<td>23</td>
</tr>
<tr>
<td>Team</td>
<td>90</td>
</tr>
<tr>
<td>Supervisor</td>
<td>246</td>
</tr>
</tbody>
</table>
<p>Table 1: Categorical Variables
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 2: Enumeration of count features.</p>
<h3>Structured Stream Neural Network</h3>
<p>At the core of our system is one of two neural network models that map a series of feature vectors for a given user, one per day, to a probability distribution over the next vector in the user's sequence. This model is trained jointly over all users simultaneously and in an online fashion. First, we describe our DNN model, which does not explicitly model any temporal behavior, followed by the RNN, which does. We then discuss the remaining components for making predictions of structured feature vectors and identification of anomaly in the stream of feature vectors.</p>
<h4>Deep Neural Network Model</h4>
<p>Our model takes as input a series of $T$ feature vectors $\mathbf{x}<em 2="2">{1}^{u}, \mathbf{x}</em>}^{u}, \ldots, \mathbf{x<em 1="1">{T}^{u}$ for a user $u$ and produces as output a series of $T$ hidden state vectors $\mathbf{h}</em>}^{u}, \mathbf{h<em T="T">{2}^{u}, \ldots, \mathbf{h}</em>}^{u}$ (each to be later fed into the structured prediction network). In a DNN with $L$ hidden layers $(l=1, \ldots, L)$, our final hidden state, the output of hidden layer $L, \mathbf{h<em L_="L," t="t">{t}^{u}=\mathbf{h}</em>$ as follows:}^{u}$ is a function of $\mathbf{x}_{t}^{u</p>
<p>$$
\mathbf{h}<em l="l">{l, t}^{u}=g\left(\mathbf{W}</em>} \mathbf{h<em l="l">{l-1, t}^{u}+\mathbf{b}</em>\right)
$$</p>
<p>Where $g$ is a non-linear activation function, typically ReLU, $\tanh$, or the logistic sigmoid, and $\mathbf{h}<em _mathbf_t="\mathbf{t">{0, t}^{u}=\mathbf{x}</em>$. The trainable parameters are the $L$ weight matrices (W), and $L$ bias vectors (b).}}^{\mathbf{u}</p>
<h4>Recurrent Neural Network Model</h4>
<p>Like the DNN, the RNN model maps an input sequence $\mathbf{x}<em 2="2">{1}^{u}, \mathbf{x}</em>}^{u}, \ldots, \mathbf{x<em 1="1">{t}^{u}$ to a hidden state sequence $\mathbf{h}</em>}^{u}, \mathbf{h<em T="T">{2}^{u}, \ldots, \mathbf{h}</em>}^{u}$. Unlike the DNN, here the hidden state $\mathbf{h<em 1="1">{t}^{u}$ is computed as a function of $\mathbf{x}</em>}^{u}, \mathbf{x<em t="t">{2}^{u}, \ldots, \mathbf{x}</em>}^{u}$, and not on $\mathbf{x<em t="t">{t}^{u}$ alone. Conditioning $\mathbf{h}</em>$ on a sequence rather than the current input alone allows us to}^{u</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Unrolled LSTM Network with $N$ Layers</p>
<p>capture temporal patterns in user behavior, and to build an increasingly accurate model of the user's behavior over time.</p>
<p>We use the popular Long Short-Term Memory (LSTM) RNN architecture (Hochreiter and Schmidhuber 1997), in which the hidden state $\mathbf{h}<em t="t">{t}^{u}$ at time $t$ is a function of a long-term memory cell, $\mathbf{c}</em>}^{u}$. In a deep LSTM with $L$ hidden layers, our final hidden state, the output of hidden layer $L$, $\mathbf{h<em L_="L," t="t">{t}^{u}=\mathbf{h}</em>$, depends on the input sequence and cell states as follows:}^{u</p>
<p>$$
\begin{aligned}
\mathbf{h}<em l_="l," t="t">{l, t}^{u} &amp; =\mathbf{o}</em>}^{u} \odot \tanh \left(\mathbf{c<em l_="l," t="t">{l, t}^{u}\right) \
\mathbf{c}</em>}^{u} &amp; =\mathbf{f<em l_="l," t-1="t-1">{l, t}^{u} \odot \mathbf{c}</em>}^{u}+\mathbf{i<em l_="l," t="t">{l, t}^{u} \odot \mathbf{g}</em> \
\mathbf{g}}^{u}, \text { and <em l="l">{l, t}^{u} &amp; =\tanh \left(\mathbf{W}</em>}^{(g, x)} \mathbf{h<em l="l">{l-1, t}^{u}+\mathbf{W}</em>}^{(g, h)} \mathbf{h<em l="l">{l, t-1}^{u}+\mathbf{b}</em>\right) \
\mathbf{f}}^{g<em l="l">{l, t}^{u} &amp; =\sigma\left(\mathbf{W}</em>}^{(f, x)} \mathbf{h<em l="l">{l-1, t}^{u}+\mathbf{W}</em>}^{(f, h)} \mathbf{h<em l="l">{l, t-1}^{u}+\mathbf{b}</em>\right) \
\mathbf{i}}^{f<em l="l">{l, t}^{u} &amp; =\sigma\left(\mathbf{W}</em>}^{(i, x)} \mathbf{h<em l="l">{l-1, t}^{u}+\mathbf{W}</em>}^{(i, h)} \mathbf{h<em l="l">{l, t-1}^{u}+\mathbf{b}</em>\right) \
\mathbf{o}}^{i<em l="l">{l, t}^{u} &amp; =\sigma\left(\mathbf{W}</em>}^{(o, x)} \mathbf{h<em l="l">{l-1, t}^{u}+\mathbf{W}</em>}^{(o, h)} \mathbf{h<em l="l">{l, t-1}^{u}+\mathbf{b}</em>\right)
\end{aligned}
$$}^{v</p>
<p>Where $\mathbf{h}<em _mathbf_t="\mathbf{t">{0, t}^{u}=\mathbf{x}</em>}}^{\mathbf{u}}$, and $\mathbf{c<em 0="0" l_="l,">{l, 0}^{u}$, $\mathbf{h}</em>}^{u}$ are set to zero vectors for all $1 \leq l \leq L$. We use $\odot$ and $\sigma$ to denote element-wise multiplication and the (element-wise) logistic sigmoid function, respectively. Vector $\mathbf{g<em l_="l," t="t">{l, t}^{u}$ is a hidden representation based on the current input and previous hidden state, while vectors $\mathbf{f}</em>}^{u}$, $\mathbf{i<em l_="l," t="t">{l, t}^{u}$ and $\mathbf{o}</em>$, modulate how cell-state information is propagated across time, how the input is incorporated into the cell state, and how the the hidden state relates to the cell state, respectively. The trainable parameters for the LSTM are the $8 L$ weight matrices (W) and the $4 L$ bias vectors (b); these weights are shared among all users.}^{u</p>
<h4>Probability Decomposition</h4>
<p>Given the hidden state at time $t-1$, $\mathbf{h}<em t="t">{t-1}^{u}$, our model outputs the parameters $\theta$ for a probability distribution over the next observation, $\mathbf{x}</em>$, is then:}^{u}$. The anomaly for user $u$ at time $t$, $a_{t}^{u</p>
<p>$$
a_{t}^{u}=-\log P_{\theta}\left(\mathbf{x}<em t-1="t-1">{t}^{u} \mid \mathbf{h}</em>\right)
$$}^{u</p>
<p>This probability is complicated by the fact that our feature vectors, and thus the predictions our model makes, include six categorical variables in addition to the 408 dimensional count vector. Therefore, $P_{\theta}\left(\mathbf{x}<em t-1="t-1">{t}^{u} \mid \mathbf{h}</em>\right)$ is actually the joint probability over the count vector (x̂t) and each of the categorical variables: role (R), project (P), functional}^{u</p>
<p>unit (F), department (D), team (T) and supervisor (S). Let $\mathcal{C}={R, P, F, D, T, S}$ denote the set of categorical variables; e.g., let $R_{t}^{u}$ denote the role of user $u$ at time $t$. Then</p>
<p>$$
P_{\theta}\left(\mathbf{x}<em t-1="t-1">{t}^{u} \mid \mathbf{h}</em>}^{u}\right)=P_{\theta}\left(\hat{\mathbf{x}<em t="t">{t}^{u}, R</em>\right)
$$}^{u}, \ldots, S_{t}^{u} \mid \mathbf{h}_{t-1}^{u</p>
<p>For computational simplicity, we approximate this joint probability by assuming conditional independence:</p>
<p>$$
P_{\theta}\left(\mathbf{x}<em t-1="t-1">{t}^{u} \mid \mathbf{h}</em>}^{u}\right) \approx P_{\theta^{(k)}}\left(\hat{\mathbf{x}<em t-1="t-1">{t}^{u} \mid \mathbf{h}</em>\right)
$$}^{u}\right) \prod_{V \in \mathcal{C}} P_{\theta^{(V)}}\left(V_{t}^{u} \mid \mathbf{h}_{t-1}^{u</p>
<p>The seven parameter vectors, parameters $\theta^{(\hat{\mathbf{x}})}$ and $\theta^{(V)}$ for $V \in \mathcal{C}$, are produced by seven single hidden layer neural networks:</p>
<p>$$
\begin{aligned}
\theta_{t}^{(\hat{\mathbf{x}})} &amp; =\mathbf{U}<em _hat_mathbf_x="\hat{\mathbf{x">{\hat{\mathbf{x}}}^{\prime} \tanh \left(\mathbf{U}</em>}}} \mathbf{h<em _hat_mathbf_x="\hat{\mathbf{x">{t-1}+\mathbf{b}</em>}}}\right)+\mathbf{b<em t="t">{\hat{\mathbf{x}}}^{\prime} \
\theta</em>}^{(V)} &amp; =f\left(\mathbf{U<em V="V">{V}^{\prime} \tanh \left(\mathbf{U}</em>} \mathbf{h<em V="V">{t-1}+\mathbf{b}</em>\right)
\end{aligned}
$$}\right)+\mathbf{b}_{V}^{\prime</p>
<p>Here $f$ denotes the softmax function. Two additional weight matrices $(\mathbf{U})$ and two additional bias vectors $(\mathbf{b})$ are introduced for each of the seven variables we are predicting. Like the LSTM weights, these parameters are shared among all users. The parametric forms for the conditional probabilities are described next.</p>
<p>Conditional Probabilities We model the conditional probabilities for the six categorical variables as discrete, while we model the conditional probability of the counts as continuous. For the discrete models, we use the standard approach: the probability of category $k$ is simply the $k$ th element of vector $\theta^{(V)}$, whose dimension is equal to the number of categories. For example, there are 47 roles, so $\theta^{(R)} \in \mathbb{R}^{47}$. Because we use a softmax output activation to produce $\theta^{(V)}$, the elements are non-negative and sum-toone.</p>
<p>For the count vector, we use the multivariate normal density: $P_{\theta^{(R)}}\left(\hat{\mathbf{x}}<em t-1="t-1">{t}^{u} \mid \mathbf{h}</em>$. In the second, we assume diagonal covariance, and our model outputs both the mean vector and the log of the diagonal of $\Sigma$. This portion of the model can be seen as a simplified Mixture Density Network (Bishop 1994).
Prediction Targets We define two prediction target approaches, "next time step" and "same time step". Recall from Eqn. 8, anomaly is inversely proportional to the log probability of the observation at time $t$ given the hidden representation at time $t-1$; that is, given everything we know up to and including time $t-1$, predict the outcome at time $t$. This approach fits the normal paradigm for RNNs on sequential data; in our experiments, we will refer to this approach as "next time step" prediction.}^{u}\right)=\mathcal{N}(\hat{\mathbf{x}} ; \mu, \Sigma)$. We consider two variants. In the first, our model outputs the mean vector $\mu$ $\left(\theta^{(\hat{\mathbf{x}})}=\mu\right)$ and we assume the covariance $\Sigma$ to be the identity. With identity covariance, maximizing the log-likelihood of the true data is equivalent to minimizing the squared error $\left|\hat{\mathbf{x}}_{t}^{u}-\mu\right|^{2</p>
<p>However, it is common in anomaly detection literature (Malhotra et al. 2016) to use an auto-encoder to detect anomaly. An auto-encoder is a parametric function trained to reproduce the input features as output. Its complexity is typically constrained to prevent it from learning the trivial
identity function; instead, the network must exploit statistical regularities in the data to achieve low reconstruction error for commonly found patterns, at the expense of high reconstruction error for uncommon patterns (anomalous activity). Networks trained in this unsupervised fashion have been demonstrated to be very effective in several anomaly detection application domains (Markou and Singh 2003).</p>
<p>In the context of our present application, both techniques may be applicable. Formally, we consider an alternative definition of anomaly:</p>
<p>$$
\hat{a}<em _theta="\theta">{t}^{u}=-\log P</em>}\left(\mathbf{x<em t="t">{t}^{u} \mid \mathbf{h}</em>\right)
$$}^{u</p>
<p>That is, given everything we know up to and including time $t$, predict the input counts $\mathbf{x}<em t="t">{t}^{u}$. If $\mathbf{x}</em>$ is anomalous, we are unlikely to produce a distribution that assigns a large density to it. We refer to this approach as "same time step" prediction.}^{u</p>
<p>Detecting Insider Threat Ultimately, the goal of our model is to detect insider threat. We assume the following conditions: our model produces anomaly scores, which are used to rank user-days from most anomalous to least, we then provide the highest ranked user-day pairs to analysts who judge whether the anomalous behavior is indicative of insider threat. We assume that there is a daily budget which imposes a maximum number of user-day pairs that can be judged each day, and that if an actual case of insider threat is presented to an analyst, he or she will correctly detect it.</p>
<p>Because our model is trained in an online fashion, the anomaly scores start out quite large (when the model knows nothing about normal behavior) and trend lower over time (as normal behavior patterns are learned). To place the anomaly score for user $u$ at time $t$ in the proper context, we compute an exponentially weighted moving average estimate of the mean and variance of these anomaly scores and standardize each score as it arrives.</p>
<p>One key feature of our model is that the anomaly score decomposes as the sum over the negative log probabilities of our variables; the continuous count random variable further decomposes over the sum of individual feature terms: $\left(x_{i}-\mu_{i}\right) / \sigma_{i}$. This allows us to identify which features are largest contributors to any anomaly score; for example, our model could indicate that a particular user-day is flagged as anomalous primarily due to an abnormal number of emails sent with attachments to uncommon recipients between 12am and 6am. Providing insight into why a user-day was flagged may improve both the speed and accuracy of analysts' judgments about insider threat behavior.</p>
<h2>Online Training</h2>
<p>In a standard training scenario for RNNs, individual or mini-batches of sequences are fed to the RNN, gradients of the training objective are computed via Back Propagation Through Time, and then weights are adjusted via a gradient-descent-like algorithm. For DNNs, individual or mini-batches of samples are fed into the DNN, and weights are updated with gradients computed by standard backpropagation. In either case, this process usually iterates over the fixed-size dataset until the model converges, and only then is the model applied to new data to make predictions. This</p>
<p>approach faces a few key challenges for the online anomaly detection setting: 1) the dataset is streaming and effectively unbounded and 2) the model is tasked with making predictions on new data as it learns. Attempting to shoehorn this scenario into a standard training setup is impractical: it is infeasible to either store or repeatedly to train on an unbounded streaming dataset and periodically retraining the model on a fixed-size set of recent events risks excluding important past events.</p>
<p>To accommodate an online scenario, we make important adjustments to the standard training regimen. For DNNs, the primary difference is the restriction of observing each sample only once. For the RNN, the situation is more complicated. We train on multiple user sequences concurrently, backpropagating and adjusting weights each time we see a new feature vector from a user. Logically, this corresponds to training one RNN per user, where the weights are shared between all users but hidden state sequences are per-user. In practice, we accomplish this by training a single RNN with a supplementary data structure that stores a finite window of past inputs and hidden and cell states for each user. Each time a new feature vector for a user is fed into the model, the hidden and cell states for that user are then used for context when calculating the forward pass and backpropagating error.</p>
<h2>Baseline Models</h2>
<p>To assess the effectiveness of our DNN and RNN models, we compare against popular anomaly/novelty/outlier detection methods. Specifically, we compare against one-class support vector machine (SVM) (Schlkopf et al. 2001), isolation forest (Liu, Ting, and Zhou 2008) and principle component analysis (PCA) baselines (Shyu et al. 2003). We use scikit-learn's ${ }^{1}$ implementation of one-class SVM and isolation forest, both included as part of its novelty and outlier detection functionality (Pedregosa et al. 2011). For the PCA baseline, we project the feature vector onto the first $k$ principle components and then map it back into the original feature space. Anomaly is proportional to the error in this reconstruction. Hyperparameter $k$ is tuned on the development set.</p>
<h2>Experiments</h2>
<p>We assess the effectiveness of our model, which we implemented in Tensorflow ${ }^{2}$ (Abadi et al. 2015) on a series of experiments. In this section we describe the data used, hyperparameters tuned, and present our results and analysis.</p>
<h2>Data</h2>
<p>Given security and privacy concerns surrounding network data, real world datasets must undergo an anonymization process before being publicly released for research purposes. The anonymization process may obscure potentially relevant factors in system logs. Particularly, user attribute metadata that may be available to a system administrator</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 2: Dataset statistics.
is typically absent in an open release data set. We perform experiments on the synthetic CERT Insider Threat Dataset v6.2, which includes such categorical information.</p>
<p>CERT consists of event log lines from a simulated organization's computer network, generated with sophisticated user models. We use five sources of events: logon/logoff activity, http traffic, email traffic, file operations, and external storage device usage. Over the course of 516 days, 4,000 users generate 135,117,169 events (log lines). Among these are events manually injected by domain experts, representing five insider threat scenarios taking place. Additionally, user attribute metadata is included; namely, the six categorical attributes listed in Table 1.</p>
<p>Since this is an unsupervised task, no supervised training set is required. We therefore split the entire dataset chronologically into two subsets: development and test. The former subset ( $\sim 85 \%$ of the data) is used for model selection and hyper-parameter tuning, while the latter subset ( $\sim 15 \%$ of the data) is held out for assessing generalization performance. Table 2 summarizes the dataset statistics. Our predictions are made at the granularity of user-day; there are fewer threat user-days than raw events because malicious users often conduct several threat events over the course of a single day. Note that although the test set includes only $15 \%$ of the events, it has over $40 \%$ of the threat user-days. One final note is that we filtered our data to keep only weekdays, because what is normal is qualitatively different for weekdays and weekends. If desired, a second system could be trained to model normal weekend behavior.</p>
<h2>Tuning</h2>
<p>We tune our models and baselines on the development set using random hyper-parameter search. For the DNN, we tune the number of hidden layers (between 1 and 6) and the hidden layer dimension (between 20 and 500). We fix the batch size to 256 samples (user-days) and the learning rate to 0.01 . For the RNN, we tune the hidden layers and hidden layer dimension over the same ranges as the DNN, and also fix the learning rate to 0.01 . The batch size is tuned (between 256 and 8092 samples); larger batch sizes speed up model training, which is more important for the RNN than the DNN. We also tune the number of time steps to back propagate over (between 3 and 40). When our inputs and outputs include the categorical variables, we additionally tune a hyper-parameter which determines the size of</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>CR-400</th>
<th>CR-1000</th>
</tr>
</thead>
<tbody>
<tr>
<td>LSTM-Diag</td>
<td>11.6</td>
<td>35.6</td>
</tr>
<tr>
<td>LSTM-Diag-Cat</td>
<td>9.2</td>
<td>32.3</td>
</tr>
</tbody>
</table>
<p>Table 3: Cumulative Recall (CR-k) for budgets of 400 and 1000. Comparing the performance of diagonal covariance LSTM models with (Cat) and without categorical features included.
the input embedding vector of a category in relation to how many classes in that category (between 0.25 and 1). Both neural network models use tanh for the hidden activation function and are trained using the ADAM (Kingma and Ba 2014) variant of gradient descent.</p>
<p>We also tune our baseline models. For the PCA baseline, we tune over the number of principal components (between 1 and 20). For the Isolation Forest baseline, we tune the number of estimators (between 20 and 300), the contamination (between 0 and 0.5), and whether we bootstrap (true or false). The max feature hyper-parameter is fixed at the default of 1.0 (use all features). For the SVM baseline, we tune the kernel (in the set ${\mathrm{rbf}$, linear, poly, sigmoid $}$ ), $\nu$ (between 0 and 1) and whether to use the shrinking heuristic (true or false). For the polynomial kernel, we tune the degree (between 1 and 10) while for all other kernels we use the default value for the remaining hyper-parameters.</p>
<p>For all models, our tuning criteria is Cumulative Recall $k$ (CR-k), which we define to be the sum of the recalls for all budgets up to and including $k$. For computational efficiency, we only evaluate budgets at increments of 25 , so if we defined $R(i)$ to be the recall with a budget of $i$, CR- $k$ is actually $R(25)+R(50)+\cdots+R(k)$. CR- $k$ can be thought of as an approximation to an area under the recall curve. For each model, we picked the hyper-parameters that maximized CR1000, for which the maximum value achievable is 40 . Given the assumptions that 1) we have a fixed daily analyst budget which cannot be carried over from one day to the next, 2) true positives are rare, and 3) the cost of a missed detection is substantially larger than the cost of a false positive, we feel that recall-oriented metrics such as CR- $k$ are a more suitable measurement of performance than precision-oriented ones.</p>
<h2>Results</h2>
<p>We present three sets of experimental results, each designed to answer a specific question about our model's performance.</p>
<p>First, we assess the effect of including or excluding the categorical variables in our model input and output. Table 3 shows the comparison between two LSTM models, differing only in whether they include or exclude the categorical information. It shows that while the difference is not huge, the model clearly performs better without the categorical information. While the original intention of including categorical features was to provide context to the model, we hypothesize that our dataset may be simple enough that such context is not necessary (or that the model does not need explicit context: it can infer it). It may also be that the added model complexity hinders trainability, leading to a net loss in perfor-</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>CR-400</th>
<th>CR-1000</th>
</tr>
</thead>
<tbody>
<tr>
<td>LSTM-Diag</td>
<td>11.6</td>
<td>35.6</td>
</tr>
<tr>
<td>LSTM-Diag-NextTime</td>
<td>5.9</td>
<td>25.1</td>
</tr>
<tr>
<td>DNN-Diag</td>
<td>11.7</td>
<td>35.7</td>
</tr>
<tr>
<td>DNN-Diag-NextTime</td>
<td>9.4</td>
<td>32.5</td>
</tr>
</tbody>
</table>
<p>Table 4: Cumulative Recall (CR-k) for daily budgets of 400 and 1000. Comparing the performance of the diagonal covariance DNN and LSTM models predicting counts at the next time steps (NextTime) vs the current time step.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>CR-400</th>
<th>CR-1000</th>
</tr>
</thead>
<tbody>
<tr>
<td>Isolation Forest</td>
<td>10.8</td>
<td>34.8</td>
</tr>
<tr>
<td>SVM</td>
<td>5.3</td>
<td>24.2</td>
</tr>
<tr>
<td>PCA</td>
<td>9.4</td>
<td>32.8</td>
</tr>
<tr>
<td>DNN-Ident</td>
<td>9.8</td>
<td>32.4</td>
</tr>
<tr>
<td>DNN-Diag</td>
<td>11.7</td>
<td>35.7</td>
</tr>
<tr>
<td>LSTM-Ident</td>
<td>10.8</td>
<td>33.0</td>
</tr>
<tr>
<td>LSTM-Diag</td>
<td>11.6</td>
<td>35.6</td>
</tr>
</tbody>
</table>
<p>Table 5: Cumulative Recall (CR-k) for daily budgets of 400 and 1000. All results are based on count features only. For the DNN and LSTM, diagonal (Diag) and identity (Ident) covariances are contrasted.
mance. Because inclusion of categorical features adds computational complexity to the model and harms performance, all of the remaining experiments reported in this paper use count features only.</p>
<p>Our second set of experiments is designed to determine which of the prediction modes work best for our task: "same time step" (Eqn. 13) or "next time step" (Eqn. 8). Table 4 shows these results, comparing two DNN and two LSTM models. The "same time step" approach yields better performance for both models, although the difference is more dramatic for the LSTM. Based on this result, we only use "same time step" for our remaining set of experiments. Interestingly, the DNN and LSTM perform equivalently. We suspect that the CERT dataset does not contain enough temporal patterns unfolding over multiple days to offer any real advantage to the LSTM, though we would expect it to offer advantages on real-world datasets.</p>
<p>Our final set of experiments is designed to assess the effect of covariance type for our continuous features (identity versus diagonal) and to contrast with our baseline models. Table 5 shows these results. Among the baselines, the Isolation Forest model is the strongest, giving the third best performance after DNN-Diag and LSTM-Diag. These results also show that diagonal covariance leads to better performance than identity covariance. One obvious advantage of diagonal covariance is that it is capable of more effectively normalizing the data (by accounting for trends in variance). Wondering how well the identity model would perform if the data was normalized ahead of time, we conducted a pilot study where the counts were standardized with an exponentially weighted moving average estimate of the mean and variance, and found no improvement for either the iden-</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Percentile ranges of user-day anomaly as a function of days for the DNN-Diag model. The vertical bar denotes the split between the development and test sets.</p>
<p>tity or diagonal covariance models. In contrast to a "global" normalization scheme, our diagonal covariance model is capable of conditioning the mean and variance on local context (when either "next time step" or the LSTM are used); for example, it might expect greater mean or variance in the number of emails sent on the day after an abnormally large number of emails were received. That said, it is not clear whether our data exhibits patterns that our models can take advantage of with this dynamic normalization.</p>
<h3>Analysis</h3>
<p>We perform two analyses to better understand our system's behavior, using our best DNN model to illustrate. In the first, we look at the effect of time on the model's notion of anomaly. Because the model begins completely untrained, anomaly scores for all users are very high for the first few days. As the model sees examples of user behavior, it quickly learns what is "normal." Fig. 4 shows anomaly as a function of day, (starting after the "burn in" period of the first few days, to keep the y-axis scale manageable). Percentile ranges are shown (computed over the users in the day), and malicious (insider threat) user-days are overlayed as red dots. Notice that all malicious events are above the 50th percentile for anomaly, with most above the 95th percentile.</p>
<p>In our second analysis, we study the effect of daily budget on recall for best DNN, best LSTM and the three baseline models. Fig. 5 plots these recall curves. Impressively, with a daily budget of 425, DNN-Diag, LSTM-Diag and the Isolation Forest model all obtain 100% recall. It also shows that with our LSTM-Diag system, 90% recall can be obtained with a budget of only 250 (a 93.5% reduction in the amount of data analysts need to consider).</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Test set recall curves.</p>
<h3>Conclusions</h3>
<p>We have presented a system employing an online deep learning architecture that produces interpretable assessments of anomaly for the task of insider threat detection in streaming system user logs. Because insider threat takes new and different forms, it is not practical to explicitly model it; our system instead models "normal" behavior and uses anomaly as an indicator of potential malicious behavior. Our approach is designed to support the streaming scenario, allowing high volume streams to be filtered down to a manageable number of events for analysts to review. Further, our probabilistic anomaly scores also allow our system to convey <em>why</em> it felt a given user was anomalous on a given day (e.g. because the user had an abnormal number of file uploads between 6pm and 12am). We hope that this interpretability will improve human analysts' speed and accuracy.</p>
<p>In our evaluation using the CERT Insider Threat v6.2 dataset, our DNN and LSTM models outperformed three standard anomaly detection technique baselines (based on Isolation Forest, SVMs and PCA). When our probabilistic output model uses a context-dependent diagonal covariance matrix (as a function of the input) rather than a fixed identity covariance matrix, it provides better performance. We also contrasted two prediction scenarios: 1) probabilistically reconstructing the current input given a compressed hidden representation ("same time step") and 2) probabilistically predicting the next time step ("next time step"). In our experiments, we found that the first works slightly better.</p>
<p>There are many ways one could extend this work. First, we would like to apply this to a wider range of streaming tasks. Although our focus here is on insider threat, our underlying model offers a domain agnostic approach to anomaly detection. In our experiments, the LSTM performed equivalently to the DNN, but we suspect that the LSTM will yield superior performance when applied to large-scale real-world problems with more complicated temporal patterns.</p>
<p>Another promising angle is to explore different granular-</p>
<p>ities of times. The current work aggregates features over individual users for each day; this has the potential to miss anomalous patterns happening within a single day. Again, our LSTM model has the greatest potential to generalize: the model could be applied to individual events / log-lines, using its hidden state as memory to detect anomalous sequences of actions. Doing so would reduce or eliminate the "feature engineering" required for aggregate count-style features. It could also dramatically narrow the set of individual events an analyst must inspect to determine whether anomalous behavior constitutes insider threat.</p>
<h2>Acknowledgments.</h2>
<p>The research described in this paper is part of the Analysis in Motion Initiative at Pacific Northwest National Laboratory. It was conducted under the Laboratory Directed Research and Development Program at PNNL, a multi-program national laboratory operated by Battelle for the U.S. Department of Energy, and supported in part by the U.S. Department of Energy, Office of Science, Office of Workforce Development for Teachers and Scientists (WDTS) under the Visiting Faculty Program (VFP).</p>
<h2>References</h2>
<p>[Abadi et al. 2015] Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.; Dean, J.; Devin, M.; Ghemawat, S.; Goodfellow, I.; Harp, A.; Irving, G.; Isard, M.; Jia, Y.; Jozefowicz, R.; Kaiser, L.; Kudlur, M.; Levenberg, J.; Mané, D.; Monga, R.; Moore, S.; Murray, D.; Olah, C.; Schuster, M.; Shlens, J.; Steiner, B.; Sutskever, I.; Talwar, K.; Tucker, P.; Vanhoucke, V.; Vasudevan, V.; Viégas, F.; Vinyals, O.; Warden, P.; Wattenberg, M.; Wicke, M.; Yu, Y.; and Zheng, X. 2015. TensorFlow: Largescale machine learning on heterogeneous systems. Software available from tensorflow.org.
[Bishop 1994] Bishop, C. 1994. Mixture density networks. Technical Report NCRG/94/004, Neural Computing Research Group, Aston University.
[Carter and Streilein 2012] Carter, K. M., and Streilein, W. W. 2012. Probabilistic reasoning for streaming anomaly detection. In Proc. SSP, 377-380.
[Chandola, Banerjee, and Kumar 2012] Chandola, V.; Banerjee, A.; and Kumar, V. 2012. Anomaly detection for discrete sequences: A survey. IEEE TKDE 24(5):823-839.
[Chauhan and Vig 2015] Chauhan, S., and Vig, L. 2015. Anomaly detection in ecg time signals via deep long shortterm memory networks. In Proc. DSAA, 1-7.
[Debar, Becker, and Siboni 1992] Debar, H.; Becker, M.; and Siboni, D. 1992. A neural network component for an intrusion detection system. In Proc. IEEE Symposium on Research in Security and Privacy, 240-250.
[Gavai et al. 2015] Gavai, G.; Sricharan, K.; Gunning, D.; Hanley, J.; Singhal, M.; and Rolleston, R. 2015. Supervised and unsupervised methods to detect insider threat from enterprise social and online activity data. Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications 6(4):47-63.
[Glasser and Lindauer 2013] Glasser, J., and Lindauer, B. 2013. Bridging the gap: A pragmatic approach to generating insider threat data. In Proc. SPW, 98-104.
[Hochreiter and Schmidhuber 1997] Hochreiter, S., and Schmidhuber, J. 1997. Long short-term memory. Neural computation 9(8):1735-1780.
[Hutchins, Cloppert, and Amin 2011] Hutchins, E. M.; Cloppert, M. J.; and Amin, R. M. 2011. Intelligence-driven computer network defense informed by analysis of adversary campaigns and intrusion kill chains. Leading Issues in Information Warfare \&amp; Security Research 1:80.
[Kingma and Ba 2014] Kingma, D., and Ba, J. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.
[Lindauer et al. 2014] Lindauer, B.; Glasser, J.; Rosen, M.; Wallnau, K. C.; and ExactData, L. 2014. Generating test data for insider threat detectors. Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications 5(2):80-94.
[Liu, Ting, and Zhou 2008] Liu, F. T.; Ting, K. M.; and Zhou, Z.-H. 2008. Isolation forest. In Proc. ICDM.
[Malhotra et al. 2016] Malhotra, P.; Ramakrishnan, A.; Anand, G.; Vig, L.; Agarwal, P.; and Shroff, G. 2016. LSTM-based encoder-decoder for multi-sensor anomaly detection. arXiv preprint arXiv:1607.00148.
[Marchi et al. 2015a] Marchi, E.; Vesperini, F.; Eyben, F.; Squartini, S.; and Schuller, B. 2015a. A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks. In Proc. ICASSP, 1996-2000.
[Marchi et al. 2015b] Marchi, E.; Vesperini, F.; Weninger, F.; Eyben, F.; Squartini, S.; and Schuller, B. 2015b. Non-linear prediction with LSTM recurrent neural networks for acoustic novelty detection. In Proc. IJCNN, 1-7.
[Markou and Singh 2003] Markou, M., and Singh, S. 2003. Novelty detection: a reviewpart 2:: neural network based approaches. Signal processing 83(12):2499-2521.
[Pedregosa et al. 2011] Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss, R.; Dubourg, V.; Vanderplas, J.; Passos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12:2825-2830.
[Ryan, Lin, and Miikkulainen 1998] Ryan, J.; Lin, M.-J.; and Miikkulainen, R. 1998. Intrusion detection with neural networks. Advances in neural information processing systems 943-949.
[Schlkopf et al. 2001] Schlkopf, B.; J. Platt and, J. S.-T.; Smola, A. J.; and Williamson, R. C. 2001. Estimating the support of a high-dimensional distribution. Neural Computation 13:1443-1471.
[Shyu et al. 2003] Shyu, M.-L.; Chen, S.-C.; Sarinnapakorn, K.; and Chang, L. 2003. A novel anomaly detection scheme based on principal component classifier. In Proc. ICDM.
[Sommer and Paxson 2010] Sommer, R., and Paxson, V. 2010. Outside the closed world: On using machine learn-</p>
<p>ing for network intrusion detection. In Proc. Symposium on Security and Privacy.
[Veeramachaneni and Arnaldo 2016] Veeramachaneni, K., and Arnaldo, I. 2016. $A I^{2}$ : Training a big data machine to defend. In Proc. HPSC and IDS.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ http://scikit-learn.org/stable/modules/outlier_detection.html
${ }^{2}$ Code will be available at https://github.com/pnnl/safekit&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>