<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7628 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7628</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7628</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‚Äëtuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-266053652</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.03749v2.pdf" target="_blank">Conceptual Engineering Using Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> We describe a method, based on Jennifer Nado's proposal for classification procedures as targets of conceptual engineering, that implements such procedures by prompting a large language model. We apply this method, using data from the Wikidata knowledge graph, to evaluate stipulative definitions related to two paradigmatic conceptual engineering projects: the International Astronomical Union's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN. Our results show that classification procedures built using our approach can exhibit good classification performance and, through the generation of rationales for their classifications, can contribute to the identification of issues in either the definitions or the data against which they are being evaluated. We consider objections to this method, and discuss implications of this work for three aspects of theory and practice of conceptual engineering: the definition of its targets, empirical methods for their investigation, and their practical roles. The data and code used for our experiments, together with the experimental results, are available in a Github repository.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7628",
    "paper_id": "paper-266053652",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00392875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Conceptual engineering using large language models
2 Nov 2024</p>
<p>Bradley P Allen 
Conceptual engineering using large language models
2 Nov 2024B7F06823C5E6A22F09F293198FF9BB41arXiv:2312.03749v2[cs.CL]
We describe a method, based on Jennifer Nado's proposal for classification procedures as targets of conceptual engineering, that implements such procedures by prompting a large language model.We apply this method, using data from the Wikidata knowledge graph, to evaluate stipulative definitions related to two paradigmatic conceptual engineering projects: the International Astronomical Union's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.Our results show that classification procedures built using our approach can exhibit good classification performance and, through the generation of rationales for their classifications, can contribute to the identification of issues in either the definitions or the data against which they are being evaluated.We consider objections to this method, and discuss implications of this work for three aspects of theory and practice of conceptual engineering: the definition of its targets, empirical methods for their investigation, and their practical roles.The data and code used for our experiments, together with the experimental results, are available in a Github repository1.</p>
<p>Introduction</p>
<p>Conceptual engineering is a philosophical methodology concerned with "the design, implementation, and evaluation of concepts" (Chalmers, 2020).The goals of conceptual engineering are varied, e.g., achieving greater clarity and precision in argumentation and scientific discourse (Dutilh Novaes &amp; Reck, 2017;Justus, 2012), or altering terminology to advance the cause of social justice (Haslanger, 2000;Manne, 2017;Podosky, 2022).Conceptual engineering projects often begin with an examination of the meaning and connotations of one or more natural language terms denoting a specific concept, addressing how those terms are used in the context Bradley P. Allen University of Amsterdam, Amsterdam, The Netherlands, e-mail: b.p.allen@uva.nl 1 https://github.com/bradleypallen/zero-shot-classifiers-for-conceptual-engineering of communicative exchanges between speakers of a given language (Etta Rudolph, 2021) and identifying how and why the concept is in need of revision.Proposals for new concepts, or for changes to an existing concept, are expressed and argued for in natural language.One major criterion for the success of a conceptual engineering project is if it leads to speakers using terms in a manner that reflects the engineered concept (Pinder, 2022).The methodological debates about the proper conduct of conceptual engineering are conducted through linguistic analysis and argumentation (Burgess et al., 2020).Philosophers have proposed differing theories as to how conceptual engineering is best defined and practiced, but it is clearly an activity where the use and analysis of natural language plays a significant role.</p>
<p>In recent years, large language models (LLMs) have emerged as a technology that promises to be of "substantial value in the scientific study of language learning and processing" (Mahowald et al., 2023).Given this, we ask the question: might LLMs be useful in the conduct of conceptual engineering projects?In this paper, we argue that that is the case.</p>
<p>The structure of this paper is as follows: we begin by describing different theories about the targets of conceptual engineering, focusing on a specific theory of Jennifer Nado.We then show how prompt programming of an LLM can be used to implement a classification procedure.We then show a way to evaluate such classification procedures using data from a knowledge graph, and conduct experiments based on two paradigmatic examples of conceptual engineering projects.We then discuss the results of the experiments from several perspectives: objections that could be raised to the use of LLMs in this manner, and ways in which our method could address several issues in the theory and practice of conceptual engineering.</p>
<p>2 Classification procedures as targets of conceptual engineering Koch et al. (2023) surveys recent work on the theory of conceptual engineering, and identifies two core components of any such theory:</p>
<p>‚Ä¢ A theory of targets: what conceptual engineering creates or changes.</p>
<p>‚Ä¢ A theory of engineering: how conceptual engineering is performed.</p>
<p>Much of the discussion in recent years around the theory of conceptual engineering has centered on responses to Herman Cappelen's Austerity Framework (Cappelen, 2018), in which he defines conceptual engineering as "the practice of trying to change the extensions of linguistic items via changes in their intension" (Jorem &amp; L√∂hr, 2024), i.e., that the targets of conceptual engineering are intensions.Alternative proposals for the targets of conceptual engineering range from the meanings speakers assign to terms (Pinder, 2021), psychological structures such as prototypes (Isaac et al., 2022), pluralistic approaches integrating both semantic meanings and psychological concepts (Koch, 2021), and social norms such as entitlements (K√∂hler &amp; Veluwenkamp, 2024;Thomasson, 2020).2Belleri (2021) suggests that, given this range of proposals, a pluralist stance towards the targets of conceptual engineering is appropriate.</p>
<p>In this work we focus on the proposal for targets of conceptual engineering in Nado (2023a):</p>
<p>A classification procedure is any procedure that, when followed, allows the user to sort a set of entities into two groups-those 'in' the category delineated by the procedure, and those 'out' of that category.'Procedure' here is used in the ordinary English sense; a procedure is a method, a process, a set of steps aimed at achieving a goal (Nado, 2023a, p. 12).</p>
<p>From the perspective of a practitioner of artificial intelligence or machine learning, this is a very general way of describing a binary classifier.There are a plethora of ways in which one can create binary classifiers, but in the context of conceptual engineering, concepts are usually described using stipulative definitions in natural language.The natural language processing capabilities of LLMs and their successful application to text classification tasks (Fields et al., 2024) suggests the possibility of implementing classification procedures as computational artifacts in a manner consistent with this practice, i.e., that conceptual engineers could create a classification procedure simply by providing an intensional definition of a concept in natural language.To accomplish this, we define a classification procedure as a zero-shot chainof-thought classifier (Kojima et al., 2022).Figure 1 shows an example of such a classification procedure.Given a concept's name and intensional definition and an entity's name and description, we prompt an LLM to generate a rationale arguing for or against the entity as an element of the concept's extension, followed by a final 'positive' or 'negative' answer.</p>
<p>Constructing classification procedures using LLMs</p>
<p>A large language model (LLM) is a probabilistic model trained on a natural language corpus that, given a sequence of tokens from a vocabulary occurring in the corpus, generates a continuation of the input sequence.LLMs exhibit remarkable capabilities for natural language processing and generation (Brown et al., 2020).</p>
<p>Let T be the set of sequences of tokens   =  1 ,  2 , . . .,   such that   is a token in a predefined vocabulary .Given a corpus C ‚äÜ T , a language model L C is a probabilistic model trained on a sample of C that defines a distribution over sequences of tokens.</p>
<p>L
ùëá out = arg max ùëá L C (ùëá |ùëÉ)(2)
is the output sequence generated by the language model, conditioned on .</p>
<p>We define a function instantiate such that:
ùëÉ ‚Ä≤ = instantiate(ùëÉ, ùúÉ)(3)
where  is a prompt template,  is a substitution, and  ‚Ä≤ is the prompt produced by applying  to .Given an language model L C , we define a function classify as follows:
(ùëá ùëÖ , ùëá B ) = classify(ùëê, ùëí)(4)
where   () is the name of ,   is a natural language definition of ,   () is the name of ,   is a natural language description of ,   is a sequence of tokens that represents a rationale for a classification decision, and  B ‚àà {positive, negative} are tokens that represent classification decisions, i.e., whether or not  is in the extension of .</p>
<p>We compute   and  B as follows:
ùëá ùëÖ = arg max ùëá L C (ùëá |instantiate(ùëÉ ùëü ùëéùë°ùëñùëúùëõùëéùëôùëí ùëîùëíùëõùëíùëü ùëéùë°ùëñùëúùëõ , ùúÉ 0 ))(5</p>
<p>Evaluating classification procedures using knowledge graphs</p>
<p>Now that we have defined an approach to implementing classification procedures, we turn to the question of how such procedures can be evaluated.To this end, we leverage knowledge graphs as a source of entities to use to evaluate classification procedures for a given concept.</p>
<p>A knowledge graph represents knowledge using nodes for entities and edges for relations (Hogan et al., 2021).Knowledge graphs are key information infrastructure for many Web applications (Heist et al., 2020).Following Angles et al. (2020), we use the RDF data model to describe knowledge graphs.</p>
<p>Let  be an infinite set of IRIs (Internationalized Resource Identifiers (D√ºrst &amp; Suignard, 2005)),  be an infinite set of blank nodes (Hogan et al., 2014), and  an infinite set of literals (Beek et al., 2018) We define a function ext  () that computes the extension in  of a concept  ‚àà  recursively, such that:
ext ùê∫ (ùëê) = ùëñ ‚ààN ext ùëñ (ùëê)(9)
where
ext 0 (ùëê) = {ùëí | ‚àÉ(ùëí, instanceOf, ùëê) ‚àà ùê∫} (10) ext ùëñ+1 (ùëê) = ext ùëñ (ùëê) ‚à™ {ùëí | ùëí ‚àà ext(ùëê ‚Ä≤ ) ‚àß ‚àÉ(ùëê ‚Ä≤ , subClassOf, ùëê) ‚àà ùê∫} (11)
Our evaluation workflow is implemented as follows.We sample positive and negative examples of a concept from a given knowledge graph, using the extension of the concept computed as above as the source of positive examples, and the set difference of that extension and that of a concept related to it by a subClassOf relation as the source of negative examples.We then apply the classification procedure for a given definition of the concept to each example, and compute a confusion matrix from the classifications, which provides performance metrics for the classification procedure.</p>
<p>Figure 2 shows the evaluation workflow, and Algorithm 1 describes the procedure in pseudo-code.3input : a pair of classes ,  from  | (, subClassOf, ) ‚àà  output : a confusion matrix  ( ,  ,   ,   ) ‚Üê (0, 0, 0, 0);  + ‚Üê a uniform random sample from ext  ();
ùê∏ ‚àí ‚Üê a uniform random sample from ext ùê∫ (ùëë) \ ext ùê∫ (ùëê); foreach ùëí ‚àà ùê∏ + do (ùëá ùëÖ , ùëá B ) ‚Üê classify(ùëê, ùëí); if ùëá B = positive then ùëá ùëÉ ‚Üê ùëá ùëÉ + 1; else ùêπ ùëÉ ‚Üê ùêπ ùëÉ + 1; end foreach ùëí ‚àà ùê∏ ‚àí do (ùëá ùëÖ , ùëá B ) ‚Üê classify(ùëê, ùëí); if ùëá B = negative then ùëá ùëÅ ‚Üê ùëá ùëÅ + 1; else ùêπ ùëÅ ‚Üê ùêπ ùëÅ + 1; end ùëÄ ‚Üê [ [ùëá ùëÉ, ùêπ ùëÉ], [ùêπ ùëÅ , ùëá ùëÅ ] ];
Algorithm 1: Evaluation procedure</p>
<p>Experiments</p>
<p>Much of what has been written on the theory and practice of conceptual engineering makes reference to two specific paradigmatic projects: the International Astronomical Union's redefinition of PLANET ("planet", 2006a), and Sally Haslanger's ameliorative analysis of WOMAN (Haslanger, 2000).We now describe a set of experiments applying the above defined implementation of classification procedures and evaluation workflow to different stipulative definitions of these two concepts.</p>
<p>Data</p>
<p>For our experiments, we evaluated three definitions for PLANET: one from the Oxford English Dictionary (OED) ("planet", 2023) and two from the 2006 International Astronomical Union (IAU) General Assembly ("planet", 2006a; "planet", 2006b)).We evaluated three definitions for WOMAN: one from the OED ("woman", 2023), the definition provided in Haslanger's 2000 paper (Haslanger, 2000), and one from the Homosaurus vocabulary of LGBTQ+ terms (Cifor &amp; Rawson, 2022;"women", 2013).The definitions are shown in Table 2.We used the Wikidata collaborative knowledge graph (Vrandeƒçiƒá &amp; Kr√∂tzsch, 2014) as a source of entities.For PLANET, we sampled 50 positive examples that are instances (P31) of planet (Q634), and 50 negative examples that are instances of substellar object (Q3132741), but not of planet.For WOMAN, we sampled 50 positive examples whose sex or gender (P21) is either female (Q6581072) or trans woman (Q1052281), and 50 negative examples whose sex or gender is either male (Q6581097), non-binary (Q48270), or trans man (Q2449503).For entity descriptions, we use a summary retrieved from Wikipedia of the page corresponding to the Wikidata entity.</p>
<p>We used GPT-4 (OpenAI, 2023) with a temperature setting of 0.1 as the LLM in these experiments.LLM inference API calls were made between 20th and 21st October 2023.</p>
<p>Results</p>
<p>Table 3 provides a summary of the performance metrics from the experiments.For PLANET, all three classification procedures performed well, with the final (24 August 2006) IAU definition performing best.All three definitions resulted in a classification procedure exhibiting almost perfect agreement with the knowledge graph, as estimated by F1 Macro and Cohen's kappa metrics.For WOMAN, all three classification procedures also performed well, again with high F1 scores, and Cohen's kappa values indicating almost perfect agreement with the knowledge graph.</p>
<p>Table 4 provides details on the errors made by the classification procedures.We reviewed the errors to determine if a given error arises from the concept's definition or the entity's description.In addition, we reviewed the rationales generated by the classification procedures to determine if their classifications were unfaithful to their rationales, and if they exhibited hallucination, i.e., exhibited incorrect reasoning or false assertions (Ji et al., 2023).</p>
<p>For PLANET, the majority of errors were false positives relating to trans-Neptunian objects, the problematic classification of which was a motivation for the IAU redefinition of PLANET.All of the PLANET classification procedures had 2MASS J03552337+1133437 (Q222246) as a false negative, which was rejected due to its identification as a brown dwarf.Table 5 shows the false positive error for this entity by the classification procedure for PLANET based on the IAU 2006-08-24 definition.This is arguably a case where the knowledge graph is mistaken, for reasons that are described in the classification procedure's rationale.The rationale raises two issues with the knowledge graph's classification.It first correctly asserts that a brown dwarf is not a planet and then, applying a literal interpretation of the concept source of definition definition PLANET OED ("planet", 2023) Any of various rocky or gaseous bodies that revolve in approximately elliptical orbits around the sun and are visible by its reflected light; esp. each of the planets Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, and (until 2006) Pluto (in order of increasing distance from the sun); a similar body revolving around another star.Also: any of various smaller bodies that revolve around these (cf.satellite .2a).IAU 2006-08-16 ("planet", 2006a) A planet is a celestial body that (a) has sufficient mass for its self-gravity to overcome rigid body forces so that it assumes a hydrostatic equilibrium (nearly round) shape, and (b) is in orbit around a star, and is neither a star nor a satellite of a planet.IAU 2006-08-24 ("planet", 2006b) A planet [1] is a celestial body that (a) is in orbit around the Sun, (b) has sufficient mass for its self-gravity to overcome rigid body forces so that it assumes a hydrostatic equilibrium (nearly round) shape, and (c) has cleared the neighbourhood around its orbit.WOMAN OED ("woman", 2023)</p>
<p>An adult female human being.The counterpart of man (see man, . 1 II.4.)Haslanger (Haslanger, 2000) S is a woman iff (i) S is regularly and for the most part observed or imagined to have certain bodily features presumed to be evidence of a female's biological role in reproduction;</p>
<p>(ii) that S has these features marks S within the dominant ideology of S's society as someone who ought to occupy certain kinds of social position that are in fact subordinate (and so motivates and justifies S's occupying such a position); and (iii) the fact that S satisfies (I) and (ii) plays a role in S's systematic subordination, that is, along some dimension, S's social position is oppressive, and S's satisfying (i) and (ii) plays a role in that dimension of subordination Homosaurus ("women", 2013) Adults who self-identify as women and understand their gender in terms of Western conceptions of womanness, femaleness, and/or femininity.The term has typically been defined as adult female humans, though not all women identify with the term 'female' depending on the context in which it is used.4 Error analysis.The error column indicates the type of error (FN = false negative, FP = false positive), the cause column indicates the author's opinion as to the source of the error (KG = knowledge graph, LLM = large language model), the unfaithful column is the author's opinion as to whether the classification is unfaithful to the rational, and the hallucination column is the author's opinion as to whether the rational exhibits hallucination.</p>
<p>IAU definition's problematic use of the term "Sun" instead of e.g."star" (Sarma et al., 2008), notes that it is not orbiting the Sun.It is worth noting that in several other rationales produced by the classification procedure For WOMAN, five of the nine errors were false positives that in the author's judgement reflected errors in the knowledge graph around two specific entities.Table 6 shows two of these false positive errors occurring in the evaluation of the Homosaurus definition of WOMAN.In these instances, the classification procedure's rationale indicate that the pronouns used and social roles mentioned in the entity descriptions provide evidence that the entities are in fact women.In contrast, Table 7 shows a false negative error by the classification procedure using the Haslanger definition of WOMAN.This is an error due to the LLM, and the rationale provided exhibits hallucination in that it provides a misinterpretation of clause (ii) of Haslanger's definition.In addition, the classification procedure does not acknowl- The given definition cannot support the assertion that 2MASS J03552337+1133437 is a planet.The description of 2MASS J03552337+1133437 identifies it as a brown dwarf, not a planet.Furthermore, the definition requires a planet to be in orbit around the Sun, and there is no information provided that 2MASS J03552337+1133437 orbits the Sun.Therefore, based on the provided definition and information, we cannot argue that 2MASS J03552337+1133437 is a planet.The description of Michelle Rojas does not explicitly state her gender identity.However, it does use female pronouns ("her") to refer to her, which typically aligns with a selfidentification as a woman.Furthermore, she has taken on roles that are typically associated with women, such as female characters in various shows.Therefore, based on the information provided and the definition of a woman, it can be argued that Michelle Rojas is a woman.</p>
<p>Linden A. Lewis Linden A. Lewis is a science fiction author, best known for their debut novel The First Sister.Lewis is queer and uses she/they pronouns.</p>
<p>The definition of a woman includes adults who self-identify as women.Linden A. Lewis uses she/they pronouns, which indicates that they may identify as a woman.Therefore, based on the provided definition, it can be argued that Linden A. Lewis is a woman.The definition of a woman provided includes three main criteria: (i) having certain bodily features associated with the female biological role in reproduction, (ii) being marked within the dominant ideology of one's society as someone who should occupy certain subordinate social positions, and (iii) the fact that satisfying (i) and (ii) contributes to one's systematic subordination.In the case of Waltraud Klasnic, while the description does not explicitly state her biological features or her societal role, it does mention that she is an Austrian politician who served as the governor of Styria.This implies that she is recognized and accepted in a significant societal role, which suggests that she likely satisfies criteria (ii).However, the description does not provide enough information to definitively assert that Waltraud Klasnic satisfies all the criteria in the definition of a woman.For instance, it does not provide information about her biological features or whether she experiences systematic subordination due to her gender.Therefore, based solely on the provided definition and description, we cannot conclusively argue that Waltraud Klasnic is a woman.In summary, our method performed well in performing classifications using the provided definitions, as evaluated against the sampled data using F1 Macro and Cohen's kappa as measures of accuracy and alignment.Although our experimental setup assumed the knowledge graph as ground truth, our error analysis shows that, in twelve of the eighteen errors encountered in the experiments, rationales produced by the classification procedures provided arguments with which the author was in agreement that the knowledge graph was itself incorrect, as opposed to the LLM hallucinating or being mistaken in its classification.</p>
<p>Discussion</p>
<p>We now discuss the above approach and experimental results, raising and addressing a number of potential objections to the use of LLMs for implementing classification procedures.In doing so, we touch on three aspects of theory and practice of conceptual engineering: the definition of its targets, empirical methods, and their practical roles.</p>
<p>Classifiers as intensions</p>
<p>Our work provides evidence that the program suggested by Nado in her Practical Role Account (Nado, 2023b) is realizable in practice, in a way that allows conceptual engineers to use stipulative definitions verbatim to construct classification procedures.Classification procedures thus realized are "inferentialist devices" (Jorem &amp; L√∂hr, 2024), concrete computational artifacts that can be applied in the context of classification and categorization tasks.</p>
<p>However, in relating classification procedures to Cappelen's proposal of intensions and extensions as targets of conceptual engineering, Nado makes the following distinction:</p>
<p>If a classification procedure is sufficiently consistent and thorough, it will determinately 'pick out' a function from worlds to sets of entities within that world.This 'corresponding function' will characterize the results of applying the procedure (at the actual world) to each possible world.The output of a procedure's corresponding function when we input a given world is the set of members, at that world, of the category that the classification procedure generates. . . .Some such procedures -'well-defined' ones -will determinately pick out an intensionlike function from worlds to sets of entities, and multiple procedures may pick out the same function.Non-well-defined procedures will generate either incomplete or inconsistent classifications, and thus will not determinately fix a world-to-set function.Nonetheless, some non-well-defined procedures may be perfectly reasonable tools for classification.(Nado, 2023b, p. 13) Because our definition of classify does not provide a way to use a description of a possible world to provide additional context in generating a classification decision, classification procedures as we have implemented them are, by Nado's account, nonwell-defined.We assert that our experiments provide evidence that our approach shows that, in spite of this, classification procedures defined using our method are "perfectly reasonable tools".</p>
<p>That said, there is a way to make our classification procedures well-defined in the above sense.Consider an intensional semantics (Von Fintel &amp; Heim, 2021) for a first-order language, where  and  are non-empty sets of possible worlds and individuals, respectively.If we extend the definition of classify to take a natural language description of a possible world as an additional argument, then we can define an intension ‚ü¶‚üß of a concept  as follows: for each  ‚àà  and  ‚àà ,  ‚àà ‚ü¶‚üß() if and only if (  ,  B ) = classify(, , ) and  B = positive.This extension of our method is related to similar proposals for defining intensions as classifiers; e.g., Muskens (2005) defines intensions as logic programs, and Larsson (2015) defines intensions using perceptron-based classifiers.</p>
<p>Trustworthiness</p>
<p>We have seen in our experimental results that the rationales produced by our classification procedures in some instances exhibit hallucinations.Therefore an objection could be made to our approach based on this observed behavior.</p>
<p>A large amount of work has been performed on different prompt engineering approaches to reduce hallucination in general to improve the ability of LLMs to generate natural language that exhibits consistent and sound reasoning (Besta et al., 2023;Creswell et al., 2022;Dhuliawala et al., 2023;Madaan et al., 2023;Marasoviƒá et al., 2021;Miao et al., 2023;Wei et al., 2022;Yao et al., 2023).Additionally, a variety of approaches to hallucination detection as a means of flagging when an LLM is producing them have been put forward (B.Allen et al., 2024;L. Huang et al., 2023;Ji et al., 2023).Additional work specifically addresses the reliability and faithfulness of rationales (Ye &amp; Durrett, 2022), as well as evolving approaches to rationale refinement, exploration and verification (J.Huang &amp; Chang, 2022).An additional concern stems from evidence that that humans can be misled by erroneous rationales generated by LLMs (Heersmink et al., n.d.;Si et al., 2023).A number of researchers have proposed that the challenges in this research area are such that the concept of interpretability of LLMs and machine learning models in general needs to be reconsidered (Jacovi &amp; Goldberg, 2020;Singh et al., 2024).</p>
<p>Research into the mitigation of hallucination is at an early stage.The current continued rapid growth in LLM capabilities makes the trustworthiness of LLMs a moving target.We are optimistic that conceptual engineers, working with an modicum of epistemic vigilance (Sperber et al., 2010), can fruitfully apply LLM-based classification procedures in conceptual engineering projects in a manner touched on in Section 6.4, even given these concerns4.</p>
<p>Groundedness</p>
<p>Another objection arises if one maintains that an understanding of the meaning of the word or phrase used to communicate a concept is important for effective conceptual engineering, as it is an open question at this time as to whether or not LLMs capture and use meaning (Bender et al., 2021;Lederman &amp; Mahowald, 2024).Mandelkern and Linzen (2024) argue that LLMs are indirectly verbally grounded in the language present in their training corpora, and thus capable of a limited form of meaning.Beyond that, it is also the case that our method can be said to ground the LLM through the prompt, by incorporating language provided by the conceptual engineer in the definition of the concept, and by the knowledge graph in the summary description of the entity presented during evaluation.This is the approach used in retrieval-augmented generation (Gao et al., 2023) and knowledge-graph-enhanced LLMs (Dai et al., 2024) to reduce hallucination and improve accuracy.</p>
<p>The question of the groundedness of LLMs is a fascinating one, but from the perspective of Nado's Practical Role Account, it is not clear that this question has any bearing on the utility of our approach:</p>
<p>Though there is a fairly strong correlation between words and procedures, conceptual engineering isn't about what our words should mean, or even about how we should use our words.It is about how we should classify. . . .If we want our conceptual engineering interventions to affect how people infer and behave, then changing the meaning of a term seems a rather inefficient stratagem.Why not target the classificatory practice directly?(Nado, 2023b(Nado, , p. 1993) ) Our approach indeed targets the classificatory practice directly, and our experimental results show evidence of useful levels of performance.</p>
<p>Empirical methods</p>
<p>We assert that the evaluation procedure we have defined shows how a conceptual engineering project can incorporate an empirical, data-driven activity (Andow, 2020).Applying classification procedures to large numbers of positive and negative examples of a concept's extension can help conceptual engineers evaluate different definitions for a concept at a scale that "armchair-based conceptual engineering" (Landes, 2023) cannot.Rationales generated by classification procedures can help conceptual engineers refine their definitions.This raises the possibility that generative AI assistants (Weisz et al., 2023) could support philosophers in the conduct of conceptual engineering projects.</p>
<p>In addition, recent work on using LLMs as models of human linguistic behavior or judgment, and their use in simulating linguistic subpopulations (Aher et al., 2023;Argyle et al., 2023;Dillion et al., 2023;Horton, 2023;Simmons &amp; Hare, 2023), further suggests that our proposed method could be combined with that work to yield a corpus method for experimental philosophy (Fischer &amp; Sytsma, 2022;Sytsma, 2023).Cappelen (2018) and others have argued that conceptual engineering is difficult, as it is hard to see how the natural language (re)definition of a concept can be effectively adopted by a population of human speakers.This has come to be known as the implementation problem (Cappelen, 2018;Jorem, 2021).We assert that our approach, used as a means for semantically aligning intensional knowledge expressed in natural language and extensional knowledge represented in a knowledge base (B.P. Allen &amp; Groth, 2024), can play a practical role in providing a new set of success conditions for conceptual engineering (Andow, 2021;Pinder, 2022).</p>
<p>The implementation problem</p>
<p>Knowledge bases such as Wikidata have an impact on society by virtue of their use in online search, discovery, and recommendation (Peng et al., 2023).Using classification procedures to evaluate and improve the alignment between natural language definitions of concepts and the representation of their extensions in knowledge graphs can be of practical value in knowledge graph refinement, which is the process of improving an existing knowledge graph by adding missing knowledge or identifying and removing errors (Paulheim, 2017).Engineering concepts represented in such resources using the above method can aid understanding within a specific linguistic subgroup, i.e., the users of applications built on top of such knowledge bases, as proposed in (Matsui, 2024).As an example use case closely related to the experiments described above, the Wikidata community is working to improve the modeling of gender in Wikidata (Wikidata, 2023); we hypothesize that our approach would be useful in efforts of that sort.</p>
<p>Related to the task of knowledge graph refinement are socially responsible data management (Stoyanovich et al., 2022) and data governance (Khatri &amp; Brown, 2010).Khatri and Brown (2010) describe principles for data governance, touching on issues of the alignment of natural language concepts and their realization in databases.These concerns are echoed in the FAIR principles (Wilkinson et al., 2016), specifically with respect to the requirement for clear documentation of metadata that aligns natural language concepts and metadata in scientific data resources.More recently, Vogt et al. (2024) have proposed additional to the FAIR principles to specifically address the issue of semantic interoperability.Given the increasing use of knowledge graphs in scientific research and commercial applications, these principles are important to apply in the context of knowledge graph creation and refinement.We believe that our approach could be useful in this context as well.</p>
<p>Limitations</p>
<p>A limitation of our work is its reliance on a specific, proprietary LLM inference API (OpenAI, 2023), which raises transparency, reproducibility and safety concerns (Bender et al., 2021;Hu &amp; Levy, 2023).Reproducing these experiments using other inference APIs, including ones based on open-source or open weight LLMs, would provide useful information with respect to the variation in performance due to the use of other LLMs.Recently, we have shown that our approach, applied to the task of knowledge graph refinement, has good performance across seven different LLMs (B.P. Allen &amp; Groth, 2024).</p>
<p>Another limitation in our experiments is that error analysis was performed solely by the author.More reviewers, reviewing a larger set of examples and classifications, would provide a stronger statistical estimate of the level of agreement between human evaluators, the classification procedure, and the knowledge graph.</p>
<p>Finally, we did not investigate the effect of two specific choices made in the prompt engineering of the classifier.First, the      prompt explicitly provided instruction to ignore background information present in the training corpus for the LLM in considering the intensional definition, and second, the     prompt explicitly provided instruction intended to ensure that a binary classification was made.In the case of the latter, another implementation could instead use a ternary-valued logic, such as a weak Kleene logic (Beall, 2016;Ciuni &amp; Carrara, 2019;Zamperlin, 2019), with an additional truth value of undefined.Ablation studies would provide insight into the validity of these two prompt design choices.</p>
<p>Conclusion</p>
<p>In this work, we have shown how to construct a conceptual engineering target as a computational artifact, and apply it to provide an empirical method for use in conceptual engineering projects.We view this as an initial step in an investigation of the potential utility of large language models in the practice of conceptual engineering.</p>
<p>Much has been written of late on the impact that large language models will on society.There is clearly much work to be done to address issues of their trustworthiness, safety, ethics, and environmental impact.That being said, we hope that the work here suggests that LLMs, through their use in the context of ameliorative and normative projects of conceptual engineering (Haslanger, 2000;K√∂hler &amp; Veluwenkamp, 2024), can play a positive role in the future.</p>
<p>Fig. 1
1
Fig. 1 A classification procedure using the 24 August 2006 version of the IAU definition of PLANET, implemented as a zero-shot chain-of-thought classifier, and being applied to the description of the entity 2MASS J03552337+1133437.</p>
<p>Fig. 2
2
Fig.2A workflow for evaluating classification procedures using a knowledge graph.</p>
<p>. A knowledge graph  is a set of triples {(, , ) |  ‚àà ,  ‚àà ,  ‚àà }, where  ‚äÇ  ‚à™  is the set of subjects in ,  ‚äÇ  is the set of properties in , and  ‚äÇ  ‚à™  ‚à™  is the set of objects in .Let instanceOf, subClassOf, label ‚àà  denote an instance-of relation, a subclass-of relation, and a label property in , respectively.A concept  ‚àà  ‚à™  is an entity such that ‚àÉ(, subClassOf, ) ‚àà  |  =  ‚à®  = .</p>
<p>C (  ) = ( 1 ,  2 , . ..,   ) (1)is an estimate of the probability of a sequence   , given a corpus C. A prompt template  = (, ) is a pair of a sequence of tokens  and an set of free tokens  ‚äÜ {  1 ,  2 , . . .,   }.A substitution  with respect to a prompt  is a set of pairs (   ,   ) such that   ‚àà  and   ‚àà T .A prompt is a sequence of tokens  ‚Ä≤ ‚àà T such that ‚àÄ(   ,   ) ‚àà  every occurrence of   in a prompt template  is replaced with   .Given a prompt , the goal of a language model L C is to generate a sequence of tokens that maximizes the conditional probability under L C .</p>
<p>Table 1
1
Prompt templates used to generate classification procedures.
)</p>
<p>Table 2
2
Definitions for concepts used in the experiments.
conceptdefinitionCohen's kappaF1 macroFNFPPLANETIAU 2006-08-240.960.9811IAU 2006-08-160.940.9712OED0.920.9613WOMANHomosaurus0.960.9802Haslanger0.940.9721OED0.920.9622</p>
<p>Table 3
3
Performance metrics for classification procedures over samples of Wikidata entities (for each concept, N=100, positives=50, negatives=50).
concept definitionentityerror cause unfaithful hallucinationPLANET OED2MASS J03552337+1133437 FN KG nono(613100) 2005 TN74FPKG nono2010 GB174FPKG nono(35671) 1998 SN165FPKG nonoIAU 2006-08-16 2MASS J03552337+1133437 FN KG nono2010 GB174FPLLM nono(35671) 1998 SN165FPKG nonoIAU 2006-08-24 2MASS J03552337+1133437 FN KG nono2010 GB174FPLLM yesnoWOMAN OEDNemesisFN LLM yesyesBrianna GheyFN LLM yesyesMichelle RojasFPKG nonoLinden A. LewisFPKG nonoHaslangerWaltraud KlasnicFN LLM noyesMichaela KirchgasserFN LLM nonoMichelle RojasFPKG nonoHomosaurusMichelle RojasFPKG nonoLinden A. LewisFPKG nono</p>
<p>Table</p>
<p>Table 5
5
A false positive (FP) error for the IAU 2006-08-24 definition of PLANET.
entitydescriptionrationaleMichelle RojasMichelle Rojas (n√©e Pennington; bornDecember 16, 1987) is an Ameri-can voice actress from Dallas, Texas.Affiliated with Funimation and BangZoom! Entertainment, some of hermajor roles are Tohka Yatogami inDate A Live, Zuikaku in Azur Lane,Kanade Sakurada in Castle Town Dan-delion, Mikoto Sakuragawa in Gonnabe the Twin-Tail!!, K≈ç Yagami in NewGame!, Nashiro Yasuhisa in TokyoGhoul, Maya Sato in Classroom ofthe Elite, Toka Yada in AssassinationClassroom, Shion in That Time I GotReincarnated as a Slime, Roxy Migur-dia in Mushoku Tensei: Jobless Rein-carnation, and Yamato in One Piece.</p>
<p>Table 6
6
False positive (FP) errors for the Homosaurus definition of WOMAN.edgelinguistic cues in the entity description that the entity is a woman, i.e., the use of the terms n√©e and Landeshauptfrau.
entitydescriptionrationaleWaltraud KlasnicWaltraud Klasnic (n√©e Tschiltsch,born 27 October 1945) is an Austrianpolitician who was Landeshauptfrau(governor) of Styria from 1996 until2005.</p>
<p>Table 7
7
A false negative (FN) error for the Haslanger definition of WOMAN.</p>
<p>It is beyond the scope of this paper to provide a thorough discussion of these alternatives; for that, seeKoch et al. (2023) andBurgess et al. (2020).
In his 1955 essay "Meaning and synonymy in natural languages"(Carnap, 1955), Rudolf Carnap presents a thought experiment wherein an investigator provides a hypothetical robot with a definition of a concept together with a description of an individual, and then asks the robot if the individual is in the extension of the concept. Our evaluation workflow can be viewed as an instantiation of Carnap's experimental framework, with a classification procedure playing the role of Carnap's robot.
Bradley P. Allen
After all, "Philosophers are (usually) competent natural language speakers and especially keen to subtle differences in meaning."(Justus, 2012, p. 172) <br />
AcknowledgementsThe author wishes to thank Paul Groth, Corey Harper, Filip Ilievski, J√ºrgen Lipps, and Lise Stork for useful conversations and suggestions with respect to the topics discussed above, and Nathaniel Gan and Nikhil Mahant for their thorough review and valuable feedback, which improved the manuscript.
Using large language models to simulate multiple humans and replicate human subject studies. G V Aher, R I Arriaga, A T Kalai, International Conference on Machine Learning. 2023</p>
<p>Shroom-indelab at semeval-2024 task 6: Zero-and few-shot llm-based classification for hallucination detection. B Allen, F Polat, P Groth, 10.48550/arXiv.2404.03732Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024. the 18th International Workshop on Semantic Evaluation (SemEval-20242024</p>
<p>Evaluating class membership relations in knowledge graphs using large language models. B P Allen, P T Groth, 2024European Semantic Web ConferenceTo appear.</p>
<p>Fully experimental conceptual engineering. J Andow, 10.1080/0020174X.2020.1850339Inquiry. 2020</p>
<p>Conceptual engineering is extremely unlikely to work. so what?. J Andow, Inquiry. 641-22021</p>
<p>Mapping rdf databases to property graph databases. R Angles, H Thakkar, D Tomaszuk, IEEE Access. 82020</p>
<p>Out of one, many: Using language models to simulate human samples. L P Argyle, E C Busby, N Fulda, J R Gubler, C Rytting, D Wingate, Political Analysis. 3132023</p>
<p>Off-topic: A new interpretation of weak-kleene logic. J Beall, The Australasian Journal of Logic. 6132016</p>
<p>Literally better: Analyzing and improving the quality of literals. W Beek, F Ilievski, J Debattista, S Schlobach, J Wielemaker, Semantic Web. 912018</p>
<p>On pluralism and conceptual engineering: Introduction and overview. D Belleri, Inquiry. 2021</p>
<p>On the dangers of stochastic parrots: Can language models be too big?. E M Bender, T Gebru, A Mcmillan-Major, S Shmitchell, 10.1145/3442188.3445922Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. the 2021 ACM Conference on Fairness, Accountability, and Transparency2021</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. M Besta, N Blach, A Kubicek, R Gerstenberger, L Gianinazzi, J Gajda, T Lehmann, M Podstawski, H Niewiadomski, P Nyczyk, arXiv:2308.096872023arXiv preprint</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in neural information processing systems. 202033</p>
<p>A Burgess, H Cappelen, D Plunkett, Conceptual engineering and conceptual ethics. Oxford University Press2020</p>
<p>Fixing language: An essay on conceptual engineering. H Cappelen, 2018Oxford University Press</p>
<p>Meaning and synonymy in natural languages. R Carnap, Philosophical studies. 61955</p>
<p>What is conceptual engineering and what should it be? Inquiry. D J Chalmers, 2020</p>
<p>Mediating queer and trans pasts: The homosaurus as queer information activism. Information. M Cifor, K Rawson, Communication &amp; Society. 2022</p>
<p>Semantical analysis of weak kleene logics. R Ciuni, M Carrara, Journal of Applied Non-Classical Logics. 2912019</p>
<p>A Creswell, M Shanahan, I Higgins, arXiv:2205.09712Selection-inference: Exploiting large language models for interpretable logical reasoning. 2022arXiv preprint</p>
<p>X Dai, Y Hua, T Wu, Y Sheng, G Qi, arXiv:2402.11541Counter-intuitive: Large language models can better understand knowledge graphs than we thought. 2024arXiv preprint</p>
<p>S Dhuliawala, M Komeili, J Xu, R Raileanu, X Li, A Celikyilmaz, J Weston, arXiv:2309.11495Chain-of-verification reduces hallucination in large language arXiv preprint. 2023</p>
<p>Can ai language models replace human participants?. D Dillion, N Tandon, Y Gu, K Gray, Trends in Cognitive Sciences. 2023</p>
<p>. M D√ºrst, M Suignard, 2005RFC EditorInternationalized resource identifiers (iris) (tech. rep</p>
<p>Carnapian explication, formalisms as cognitive tools, and the paradox of adequate formalization. C Dutilh Novaes, E Reck, Synthese. 1942017</p>
<p>Conceptual exploration. Inquiry. Etta Rudolph, R , 2021</p>
<p>A survey of text classification with transformers: How wide?. J Fields, K Chovanec, P Madiraju, 2024how large? how long? how accurate? how expensive? how safe? IEEE Access</p>
<p>Projects and methods of experimental philosophy. E Fischer, J Sytsma, The Compact Compendium of Experimental Philosophy. 392022</p>
<p>Retrieval-augmented generation for large language models: A survey. Y Gao, Y Xiong, X Gao, K Jia, J Pan, Y Bi, Y Dai, J Sun, H Wang, arXiv:2312.109972023arXiv preprint</p>
<p>Gender and race:(what) are they? (what) do we want them to be?. S Haslanger, No√ªs. 3412000</p>
<p>R Heersmink, B De Rooij, M J C V√°zquez, M Colombo, A phenomenology and epistemology of large language models: Transparency, trust, and trustworthiness. </p>
<p>Knowledge graphs on the web-an overview. N Heist, S Hertling, D Ringler, H Paulheim, Knowledge Graphs for eXplainable Artificial Intelligence. 2020</p>
<p>Everything you always wanted to know about blank nodes. A Hogan, M Arenas, A Mallea, A Polleres, Journal of Web Semantics. 272014</p>
<p>Knowledge graphs. A Hogan, E Blomqvist, M Cochez, C D'amato, G D Melo, C Gutierrez, S Kirrane, J E L Gayo, R Navigli, S Neumaier, A.-C N Ngomo, A Polleres, S M Rashid, A Rula, L Schmelzeisen, J Sequeda, S Staab, A Zimmermann, 10.1145/3447772ACM Comput. Surv. 5442021</p>
<p>Large language models as simulated economic agents: What can we learn from homo silicus?. J J Horton, 2023National Bureau of Economic ResearchTech. rep.</p>
<p>Prompting is not a substitute for probability measurements in large language models. J Hu, R Levy, arXiv:2305.132642023arXiv preprint</p>
<p>J Huang, K C Chang, -C , arXiv:2212.10403Towards reasoning in large language models: A survey. 2022arXiv preprint</p>
<p>L Huang, W Yu, W Ma, W Zhong, Z Feng, H Wang, Q Chen, W Peng, X Feng, B Qin, arXiv:2311.05232A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. 2023arXiv preprint</p>
<p>Conceptual engineering: A road map to practice. M G Isaac, S Koch, R Nefdt, Philosophy Compass. 1710e128792022</p>
<p>A Jacovi, Y Goldberg, arXiv:2004.03685Towards faithfully interpretable nlp systems: How should we define and evaluate faithfulness?. 2020arXiv preprint</p>
<p>Survey of hallucination in natural language generation. Z Ji, N Lee, R Frieske, T Yu, D Su, Y Xu, E Ishii, Y J Bang, A Madotto, P Fung, ACM Computing Surveys. 55122023</p>
<p>Conceptual engineering and the implementation problem. S Jorem, Inquiry. 641-22021</p>
<p>Inferentialist conceptual engineering. S Jorem, G L√∂hr, Inquiry. 6732024</p>
<p>Carnap on concept determination: Methodology for philosophy of science. J Justus, European Journal for Philosophy of Science. 22012</p>
<p>Designing data governance. V Khatri, C V Brown, Communications of the ACM. 5312010</p>
<p>Engineering what? on concepts in conceptual engineering. S Koch, Synthese. 19912021</p>
<p>Recent work in the theory of conceptual engineering. S Koch, G L√∂hr, M Pinder, Analysis. 2023</p>
<p>Large language models are zero-shot reasoners. S K√∂hler, H Veluwenkamp, T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Advances in neural information processing systems. 2024. 202235Conceptual engineering: For what matters</p>
<p>Conceptual engineering should be empirical. E Landes, 2023</p>
<p>Formal semantics for perceptual classification. S Larsson, Journal of logic and computation. 2522015</p>
<p>Are language models more like libraries or like librarians? bibliotechnism, the novel reference problem, and the attitudes of llms. H Lederman, K Mahowald, arXiv:2401.048542024arXiv preprint</p>
<p>A Madaan, N Tandon, P Gupta, S Hallinan, L Gao, S Wiegreffe, U Alon, N Dziri, S Prabhumoye, Y Yang, arXiv:2303.17651Self-refine: Iterative refinement with self-feedback. 2023arXiv preprint</p>
<p>K Mahowald, A A Ivanova, I A Blank, N Kanwisher, J B Tenenbaum, E Fedorenko, arXiv:2301.06627Dissociating language and thought in large language models: A cognitive perspective. 2023arXiv preprint</p>
<p>M Mandelkern, T Linzen, arXiv:2308.05576Do language models' words refer?. 2024arXiv preprint</p>
<p>Few-shot selfrationalization with natural language prompts. K Manne, A Marasoviƒá, I Beltagy, D Downey, M E Peters, arXiv:2111.082842017. 2021Oxford University PressarXiv preprintDown girl: The logic of misogyny</p>
<p>Local conceptual engineering in a linguistic subgroup and the implementation problem. T Matsui, 2024Preprint at</p>
<p>N Miao, Y W Teh, T Rainforth, arXiv:2308.00436Selfcheck: Using llms to zero-shot check their own step-by-step reasoning. 2023arXiv preprint</p>
<p>Sense and the computation of reference. Linguistics and philosophy. R Muskens, 200528</p>
<p>Classification procedures as the targets of conceptual engineering. J Nado, 10.1111/phpr.12843Philosophy and Phenomenological Research. 10612023a</p>
<p>Taking control: Conceptual engineering without (much) metasemantics. J Nado, Inquiry. 66102023b</p>
<p>Openai, Gpt-4 technical report. 2023</p>
<p>Knowledge graph refinement: A survey of approaches and evaluation methods. H Paulheim, Semantic web. 20178</p>
<p>Knowledge graphs: Opportunities and challenges. C Peng, F Xia, M Naseriparsa, F Osborne, Artificial Intelligence Review. 2023</p>
<p>Conceptual engineering, metasemantic externalism and speakermeaning. M Pinder, Mind. 1305172021</p>
<p>Is haslanger's ameliorative project a successful conceptual engineering project? Synthese. M Pinder, 2022200334</p>
<p>The IAU draft definition of "planet" and "plutons". International Astronomical Union. 2006a. October 16, 2023. 2006b. October 16. 2023Result of the IAU resolution votes. International Astronomical Union</p>
<p>The Oxford English Dictionary. Oxford University Press2023. October 17, 2023</p>
<p>Can conceptual engineering actually promote social justice?. P.-M C Podosky, Synthese. 20021602022</p>
<p>Iau planet definition: Some confusions and their modifications. R Sarma, K Baruah, J K Sarma, 2008</p>
<p>Large language models help humans verify truthfulness-except when they are convincingly wrong. C Si, N Goyal, S T Wu, C Zhao, S Feng, Iii Daum√©, H Boyd-Graber, J , arXiv:2310.125582023arXiv preprint</p>
<p>Large language models as subpopulation representative models: A review. G Simmons, C Hare, arXiv:2310.178882023arXiv preprint</p>
<p>C Singh, J P Inala, M Galley, R Caruana, J Gao, arXiv:2402.01761Rethinking interpretability in the era of large language models. 2024arXiv preprint</p>
<p>D Sperber, F Cl√©ment, C Heintz, O Mascaro, H Mercier, G Origgi, D Wilson, Epistemic vigilance. Mind &amp; language. 201025</p>
<p>Responsible data management. J Stoyanovich, S Abiteboul, B Howe, H Jagadish, S Schelter, Communications of the ACM. 6562022</p>
<p>Ordinary meaning and consilience of evidence. J Sytsma, Advances in experimental philosophy of law. 2023171</p>
<p>A pragmatic method for normative conceptual work. Conceptual engineering and conceptual ethics. A L Thomasson, 2020</p>
<p>Fair 2.0: Extending the fair guiding principles to address semantic interoperability. L Vogt, P Str√∂mert, N Matentzoglu, N Karam, M Konrad, M Prinz, R Baum, arXiv:2405.033452024arXiv preprint</p>
<p>. Von Fintel, K Heim, I , 2021Intensional semantics [MIT</p>
<p>Wikidata: A free collaborative knowledgebase. D Vrandeƒçiƒá, M Kr√∂tzsch, Communications of the ACM. 57102014</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Toward general design principles for generative ai applications. J D Weisz, M Muller, J He, S Houde, arXiv:2301.055782023arXiv preprint</p>
<p>Wikidata, 2023-10-15wikidata:wikiproject lgbt/gender. 2023</p>
<p>The fair guiding principles for scientific data management and stewardship. M D Wilkinson, M Dumontier, I J Aalbersberg, G Appleton, M Axton, A Baak, N Blomberg, J.-W Boiten, L B Da Silva Santos, P E Bourne, Scientific data. 312016</p>
<p>Retrieved. Woman, Homosaurus. Homosaurus Editorial Board. Oxford University Press2023. October 17, 2023. 2013. October 17, 2023The Oxford English Dictionary</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T L Griffiths, Y Cao, K Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>The unreliability of explanations in few-shot prompting for textual reasoning. X Ye, G Durrett, Advances in neural information processing systems. 352022</p>
<p>Intensional kleene logics for vagueness. N Zamperlin, 2019Master's thesis, University of Amsterdam</p>            </div>
        </div>

    </div>
</body>
</html>