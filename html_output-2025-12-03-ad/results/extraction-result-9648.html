<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9648 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9648</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9648</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-167.html">extraction-schema-167</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-263830470</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.05036v4.pdf" target="_blank">Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs), such as ChatGPT and GPT-4, are gaining wide-spread real world use. Yet, these LLMs are closed source, and little is known about their performance in real-world use cases. In this paper, we apply and evaluate the combination of ChatGPT and GPT-4 for the real-world task of mining insights from a text corpus in order to identify research challenges in the field of HCI. We extract 4,392 research challenges in over 100 topics from the 2023~CHI conference proceedings and visualize the research challenges for interactive exploration. We critically evaluate the LLMs on this practical task and conclude that the combination of ChatGPT and GPT-4 makes an excellent cost-efficient means for analyzing a text corpus at scale. Cost-efficiency is key for flexibly prototyping research ideas and analyzing text corpora from different perspectives, with implications for applying LLMs for mining insights in academia and practice.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9648.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9648.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT+GPT-4 pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Two-step insight-mining pipeline using ChatGPT (gpt-3.5-turbo-0301) and GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cost‑efficient two-step pipeline that first extracts candidate research-challenge statements from each document using ChatGPT (gpt-3.5-turbo-0301) and then filters/ranks those candidates using GPT-4 to produce up to five high‑priority challenges per paper; outputs are clustered and visualized with embedding-based topic modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo-0301) and GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source autoregressive large language models from OpenAI. The paper uses gpt-3.5-turbo-0301 (referred to as ChatGPT) for large-scale candidate extraction and GPT-4 for filtering/ranking; models were accessed via the OpenAI API with deterministic decoding (temperature=0). The training corpora and exact architectural/training details are not specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>CH I 2023 main proceedings: 879 full research papers downloaded from the ACM Digital Library; text was extracted (textract), references and appendices removed (truncate after last 'References'), normalized (lowercased, citations removed), then processed in sentence batches for API queries. Corpus contained ~11,894 pages of substantive content.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>879</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Extract the current research challenges for researchers in the field of Human–Computer Interaction (HCI) from the CHI 2023 proceedings (i.e., identify difficulties/questions that remain unresolved or noted as open problems in each paper).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>A two-step, prompt-driven distillation. Step 1 (candidate extraction): split paper text into sentences (NLTK), batch sentences (typically up to 90, reduced when hitting context or request errors), and prompt gpt-3.5-turbo-0301 with an expert persona prompt ('InfoMinerGPT... output a list of challenges, one per line, without explanations'). Temperature set to 0 for deterministic outputs. Step 2 (filtering/ranking): provide GPT-4 with the JSON list of ChatGPT-extracted candidates and prompt it to remove duplicates and keep only the 5 most important challenges per paper (output one per line). Post-processing: convert final challenges to sentence embeddings (all-mpnet-base-v2), cluster with BERTopic (uses UMAP + HDBSCAN + c-TF-IDF), label topics (manual + ChatGPT-assisted), and visualize with UMAP and Vega-Altair. Quantitative metrics (BLEU, ROUGE, METEOR, Exact Match, BERTScore, BLANC, etc.) were computed by matching extracted statements to best-matching source sentences via embedding cosine similarity; a qualitative human evaluation on a random sample was also performed.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Unstructured lists of research-challenge statements (final set: filtered list of ~5 challenges per paper), plus clustered topic labels and an interactive visualization (2D UMAP projection) grouping challenges into topics/themes.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td>ChatGPT produced 34,638 candidate 'challenges' across 879 papers; GPT-4 filtered these to 4,392 final challenges (~5 per paper). Example extracted challenge (from sample): 'Improving findability and actionability of privacy controls for online behavioral advertising.'</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Mixed quantitative and qualitative evaluation. Quantitative: computed canonical NLP metrics (Exact Match, BLEU, ROUGE-1/ L, METEOR, BLANC, BERTScore, BLEURT) by pairing each generated statement to the best-matching sentence in the source via embedding cosine similarity. Qualitative (task-specific human evaluation): a Postdoctoral HCI researcher blind-annotated 45 randomly sampled papers (~5% of corpus), listing five most important challenges per paper; two authors compared human lists to GPT-4 lists counting semantic/lexical matches (>=3 matches counted as equivalent); inter-rater agreement measured with Cohen's kappa; manual inspection for hallucinations and noise; embedding-distance analyses to assess semantic proximity to source sentences; manual review of ChatGPT artifacts/noise.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Quantitative metrics (computed vs. best-matching source sentences) showed low Exact Match in Step 1 (EM ≈ 0.0878) and higher in Step 2 (EM ≈ 0.4571); BLEU/ROUGE etc. reported but judged by authors as limited for this task. BERTScore was high (≈0.936 Step 1; ≈0.962 Step 2). Human evaluation: near-perfect agreement (κ = 0.97) that outputs were plausible research challenges; high inter-rater agreement (κ = 0.86) on alignment between human-identified and GPT-4 lists; in ~65% of sampled papers raters judged the GPT-4 list matched perfectly to human lists (authors discuss reasons for mismatches). Manual review of 45 sampled papers found no evidence of hallucinations in the sample; ChatGPT produced a small amount of extraneous template-like lines (~317/34,638 ≈ 0.9%) that were easily filtered; GPT-4 reproduced Step-1 items verbatim in 4,333/4,392 cases, deviating wording in only 60 cases (~1.38%).</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Scalability (processed entire CHI 2023 proceedings in ≈17.5 hours), cost-efficiency (total cost ≈ US$49.95 using ChatGPT for extraction and GPT-4 only for filtering; using GPT-4 for all steps would be ~10x costlier), ability to extract structured insight across a large heterogeneous scholarly corpus, deterministic and reproducible outputs via temperature=0 and stable prompts, integration with embedding-based clustering (Sentence-BERT, BERTopic) and interactive visualization for exploration, and strong alignment with human judgment in qualitative evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on closed-source LLMs with opaque training data; sensitivity to prompt design (requires iterative prompt engineering); requires that the target information (here: 'research challenges') is actually present in documents (otherwise models may hallucinate); context-window/token limits required batching and occasional batch-size reductions; ambiguous extracted items (e.g., acronyms) may lack context; potential for bias encoded in model weights not fully ruled out; outputs are limited by models' pretraining (cannot invent genuinely novel theories beyond available textual evidence); evaluation with canonical NLP metrics is imperfect for this qualitative task.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Observed issues and edge cases: 1) About one-third of sampled papers had partial mismatch with human lists (attributed to AI selecting broader challenges, humans focusing narrowly, or human annotation quality/fatigue). 2) Some extracted challenges lacked context and initially looked like hallucinations (e.g., 'Addressing scalability issues for large-scale text data') but could be traced to source paper limitations sections. 3) Minor template/noise lines from ChatGPT (~0.9% of candidates) required simple filtering. 4) API errors (InvalidRequestError) occurred for oversized batches; authors reduced batch sizes iteratively. 5) Using only GPT-4 for all steps would raise cost substantially (~US$512 estimated). 6) Model opaqueness and unknown training data remain unresolved risks for downstream interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9648.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9648.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Petridis et al. 2023 (Anglekindling)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anglekindling: Supporting journalistic angle ideation with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned in this paper as an example where LLMs are used to analyze a document from multiple perspectives (supporting journalistic angle ideation); used as context motivating LLMs' ability to provide varied perspectives on text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Anglekindling: Supporting journalistic angle ideation with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Referenced as prior work demonstrating LLMs' capacity to dissect a single text from various viewpoints; paper does not provide technical details about the models used (within the context of this review paper).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9648.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9648.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gao et al. 2023 (Collabcoder)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Collabcoder: A GPT-powered workflow for collaborative qualitative analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as related work showing GPT-powered workflows to assist qualitative analysis (collaborative coding); used as background to situate LLMs for qualitative tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Collabcoder: A GPT-powered workflow for collaborative qualitative analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mentioned as prior work demonstrating GPT-based assistance for qualitative coding; no implementation specifics provided in this paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9648.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9648.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Xiao et al. 2023</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced as evidence that GPT-style models can assist deductive coding processes in qualitative research; used to justify applying LLMs to qualitative insight mining.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Cited as prior demonstration of GPT-3 assisting qualitative coding; this paper only references the work and does not detail model parameters or methods.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9648.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9648.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto‑GPT / BabyAGI (examples)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT and BabyAGI (experimental LLMOps agents)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as examples of LLM-based autonomous/problem-solving agents (LLMOps) that use GPT-4 for multi-step autonomous workflows; cited to illustrate broader ecosystem and applications of foundation models beyond manual prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Referenced as experimental prototypes that orchestrate multi-step LLM-driven agents; the paper cites them as examples but does not use or evaluate them.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9648.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9648.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hämäläinen et al. 2023</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evaluating large language models in generating synthetic HCI research data: A case study</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited in related work / references as an HCI study that evaluates LLMs for generating synthetic research data; listed among works exploring LLM use in HCI contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evaluating large language models in generating synthetic HCI research data: A case study</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Referenced as a related study; this paper does not reproduce its methods or results but points to it as further evidence of LLMs' utility in HCI research tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Anglekindling: Supporting journalistic angle ideation with large language models <em>(Rating: 2)</em></li>
                <li>Collabcoder: A GPT-powered workflow for collaborative qualitative analysis <em>(Rating: 2)</em></li>
                <li>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding <em>(Rating: 2)</em></li>
                <li>Evaluating large language models in generating synthetic HCI research data: A case study <em>(Rating: 2)</em></li>
                <li>Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9648",
    "paper_id": "paper-263830470",
    "extraction_schema_id": "extraction-schema-167",
    "extracted_data": [
        {
            "name_short": "ChatGPT+GPT-4 pipeline",
            "name_full": "Two-step insight-mining pipeline using ChatGPT (gpt-3.5-turbo-0301) and GPT-4",
            "brief_description": "A cost‑efficient two-step pipeline that first extracts candidate research-challenge statements from each document using ChatGPT (gpt-3.5-turbo-0301) and then filters/ranks those candidates using GPT-4 to produce up to five high‑priority challenges per paper; outputs are clustered and visualized with embedding-based topic modeling.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT (gpt-3.5-turbo-0301) and GPT-4 (OpenAI)",
            "model_description": "Closed-source autoregressive large language models from OpenAI. The paper uses gpt-3.5-turbo-0301 (referred to as ChatGPT) for large-scale candidate extraction and GPT-4 for filtering/ranking; models were accessed via the OpenAI API with deterministic decoding (temperature=0). The training corpora and exact architectural/training details are not specified in the paper.",
            "model_size": null,
            "input_corpus_description": "CH I 2023 main proceedings: 879 full research papers downloaded from the ACM Digital Library; text was extracted (textract), references and appendices removed (truncate after last 'References'), normalized (lowercased, citations removed), then processed in sentence batches for API queries. Corpus contained ~11,894 pages of substantive content.",
            "input_corpus_size": 879,
            "topic_query_description": "Extract the current research challenges for researchers in the field of Human–Computer Interaction (HCI) from the CHI 2023 proceedings (i.e., identify difficulties/questions that remain unresolved or noted as open problems in each paper).",
            "distillation_method": "A two-step, prompt-driven distillation. Step 1 (candidate extraction): split paper text into sentences (NLTK), batch sentences (typically up to 90, reduced when hitting context or request errors), and prompt gpt-3.5-turbo-0301 with an expert persona prompt ('InfoMinerGPT... output a list of challenges, one per line, without explanations'). Temperature set to 0 for deterministic outputs. Step 2 (filtering/ranking): provide GPT-4 with the JSON list of ChatGPT-extracted candidates and prompt it to remove duplicates and keep only the 5 most important challenges per paper (output one per line). Post-processing: convert final challenges to sentence embeddings (all-mpnet-base-v2), cluster with BERTopic (uses UMAP + HDBSCAN + c-TF-IDF), label topics (manual + ChatGPT-assisted), and visualize with UMAP and Vega-Altair. Quantitative metrics (BLEU, ROUGE, METEOR, Exact Match, BERTScore, BLANC, etc.) were computed by matching extracted statements to best-matching source sentences via embedding cosine similarity; a qualitative human evaluation on a random sample was also performed.",
            "output_type": "Unstructured lists of research-challenge statements (final set: filtered list of ~5 challenges per paper), plus clustered topic labels and an interactive visualization (2D UMAP projection) grouping challenges into topics/themes.",
            "output_example": "ChatGPT produced 34,638 candidate 'challenges' across 879 papers; GPT-4 filtered these to 4,392 final challenges (~5 per paper). Example extracted challenge (from sample): 'Improving findability and actionability of privacy controls for online behavioral advertising.'",
            "evaluation_method": "Mixed quantitative and qualitative evaluation. Quantitative: computed canonical NLP metrics (Exact Match, BLEU, ROUGE-1/ L, METEOR, BLANC, BERTScore, BLEURT) by pairing each generated statement to the best-matching sentence in the source via embedding cosine similarity. Qualitative (task-specific human evaluation): a Postdoctoral HCI researcher blind-annotated 45 randomly sampled papers (~5% of corpus), listing five most important challenges per paper; two authors compared human lists to GPT-4 lists counting semantic/lexical matches (&gt;=3 matches counted as equivalent); inter-rater agreement measured with Cohen's kappa; manual inspection for hallucinations and noise; embedding-distance analyses to assess semantic proximity to source sentences; manual review of ChatGPT artifacts/noise.",
            "evaluation_results": "Quantitative metrics (computed vs. best-matching source sentences) showed low Exact Match in Step 1 (EM ≈ 0.0878) and higher in Step 2 (EM ≈ 0.4571); BLEU/ROUGE etc. reported but judged by authors as limited for this task. BERTScore was high (≈0.936 Step 1; ≈0.962 Step 2). Human evaluation: near-perfect agreement (κ = 0.97) that outputs were plausible research challenges; high inter-rater agreement (κ = 0.86) on alignment between human-identified and GPT-4 lists; in ~65% of sampled papers raters judged the GPT-4 list matched perfectly to human lists (authors discuss reasons for mismatches). Manual review of 45 sampled papers found no evidence of hallucinations in the sample; ChatGPT produced a small amount of extraneous template-like lines (~317/34,638 ≈ 0.9%) that were easily filtered; GPT-4 reproduced Step-1 items verbatim in 4,333/4,392 cases, deviating wording in only 60 cases (~1.38%).",
            "strengths": "Scalability (processed entire CHI 2023 proceedings in ≈17.5 hours), cost-efficiency (total cost ≈ US$49.95 using ChatGPT for extraction and GPT-4 only for filtering; using GPT-4 for all steps would be ~10x costlier), ability to extract structured insight across a large heterogeneous scholarly corpus, deterministic and reproducible outputs via temperature=0 and stable prompts, integration with embedding-based clustering (Sentence-BERT, BERTopic) and interactive visualization for exploration, and strong alignment with human judgment in qualitative evaluation.",
            "limitations": "Relies on closed-source LLMs with opaque training data; sensitivity to prompt design (requires iterative prompt engineering); requires that the target information (here: 'research challenges') is actually present in documents (otherwise models may hallucinate); context-window/token limits required batching and occasional batch-size reductions; ambiguous extracted items (e.g., acronyms) may lack context; potential for bias encoded in model weights not fully ruled out; outputs are limited by models' pretraining (cannot invent genuinely novel theories beyond available textual evidence); evaluation with canonical NLP metrics is imperfect for this qualitative task.",
            "failure_cases": "Observed issues and edge cases: 1) About one-third of sampled papers had partial mismatch with human lists (attributed to AI selecting broader challenges, humans focusing narrowly, or human annotation quality/fatigue). 2) Some extracted challenges lacked context and initially looked like hallucinations (e.g., 'Addressing scalability issues for large-scale text data') but could be traced to source paper limitations sections. 3) Minor template/noise lines from ChatGPT (~0.9% of candidates) required simple filtering. 4) API errors (InvalidRequestError) occurred for oversized batches; authors reduced batch sizes iteratively. 5) Using only GPT-4 for all steps would raise cost substantially (~US$512 estimated). 6) Model opaqueness and unknown training data remain unresolved risks for downstream interpretation.",
            "uuid": "e9648.0",
            "source_info": {
                "paper_title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Petridis et al. 2023 (Anglekindling)",
            "name_full": "Anglekindling: Supporting journalistic angle ideation with large language models",
            "brief_description": "Mentioned in this paper as an example where LLMs are used to analyze a document from multiple perspectives (supporting journalistic angle ideation); used as context motivating LLMs' ability to provide varied perspectives on text.",
            "citation_title": "Anglekindling: Supporting journalistic angle ideation with large language models",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Referenced as prior work demonstrating LLMs' capacity to dissect a single text from various viewpoints; paper does not provide technical details about the models used (within the context of this review paper).",
            "model_size": null,
            "input_corpus_description": null,
            "input_corpus_size": null,
            "topic_query_description": null,
            "distillation_method": null,
            "output_type": null,
            "output_example": null,
            "evaluation_method": null,
            "evaluation_results": null,
            "strengths": null,
            "limitations": null,
            "failure_cases": null,
            "uuid": "e9648.1",
            "source_info": {
                "paper_title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Gao et al. 2023 (Collabcoder)",
            "name_full": "Collabcoder: A GPT-powered workflow for collaborative qualitative analysis",
            "brief_description": "Cited as related work showing GPT-powered workflows to assist qualitative analysis (collaborative coding); used as background to situate LLMs for qualitative tasks.",
            "citation_title": "Collabcoder: A GPT-powered workflow for collaborative qualitative analysis",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Mentioned as prior work demonstrating GPT-based assistance for qualitative coding; no implementation specifics provided in this paper's discussion.",
            "model_size": null,
            "input_corpus_description": null,
            "input_corpus_size": null,
            "topic_query_description": null,
            "distillation_method": null,
            "output_type": null,
            "output_example": null,
            "evaluation_method": null,
            "evaluation_results": null,
            "strengths": null,
            "limitations": null,
            "failure_cases": null,
            "uuid": "e9648.2",
            "source_info": {
                "paper_title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Xiao et al. 2023",
            "name_full": "Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding",
            "brief_description": "Referenced as evidence that GPT-style models can assist deductive coding processes in qualitative research; used to justify applying LLMs to qualitative insight mining.",
            "citation_title": "Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Cited as prior demonstration of GPT-3 assisting qualitative coding; this paper only references the work and does not detail model parameters or methods.",
            "model_size": null,
            "input_corpus_description": null,
            "input_corpus_size": null,
            "topic_query_description": null,
            "distillation_method": null,
            "output_type": null,
            "output_example": null,
            "evaluation_method": null,
            "evaluation_results": null,
            "strengths": null,
            "limitations": null,
            "failure_cases": null,
            "uuid": "e9648.3",
            "source_info": {
                "paper_title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Auto‑GPT / BabyAGI (examples)",
            "name_full": "Auto-GPT and BabyAGI (experimental LLMOps agents)",
            "brief_description": "Mentioned as examples of LLM-based autonomous/problem-solving agents (LLMOps) that use GPT-4 for multi-step autonomous workflows; cited to illustrate broader ecosystem and applications of foundation models beyond manual prompting.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Referenced as experimental prototypes that orchestrate multi-step LLM-driven agents; the paper cites them as examples but does not use or evaluate them.",
            "model_size": null,
            "input_corpus_description": null,
            "input_corpus_size": null,
            "topic_query_description": null,
            "distillation_method": null,
            "output_type": null,
            "output_example": null,
            "evaluation_method": null,
            "evaluation_results": null,
            "strengths": null,
            "limitations": null,
            "failure_cases": null,
            "uuid": "e9648.4",
            "source_info": {
                "paper_title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Hämäläinen et al. 2023",
            "name_full": "Evaluating large language models in generating synthetic HCI research data: A case study",
            "brief_description": "Cited in related work / references as an HCI study that evaluates LLMs for generating synthetic research data; listed among works exploring LLM use in HCI contexts.",
            "citation_title": "Evaluating large language models in generating synthetic HCI research data: A case study",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": "Referenced as a related study; this paper does not reproduce its methods or results but points to it as further evidence of LLMs' utility in HCI research tasks.",
            "model_size": null,
            "input_corpus_description": null,
            "input_corpus_size": null,
            "topic_query_description": null,
            "distillation_method": null,
            "output_type": null,
            "output_example": null,
            "evaluation_method": null,
            "evaluation_results": null,
            "strengths": null,
            "limitations": null,
            "failure_cases": null,
            "uuid": "e9648.5",
            "source_info": {
                "paper_title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Anglekindling: Supporting journalistic angle ideation with large language models",
            "rating": 2,
            "sanitized_title": "anglekindling_supporting_journalistic_angle_ideation_with_large_language_models"
        },
        {
            "paper_title": "Collabcoder: A GPT-powered workflow for collaborative qualitative analysis",
            "rating": 2,
            "sanitized_title": "collabcoder_a_gptpowered_workflow_for_collaborative_qualitative_analysis"
        },
        {
            "paper_title": "Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding",
            "rating": 2,
            "sanitized_title": "supporting_qualitative_analysis_with_large_language_models_combining_codebook_with_gpt3_for_deductive_coding"
        },
        {
            "paper_title": "Evaluating large language models in generating synthetic HCI research data: A case study",
            "rating": 2,
            "sanitized_title": "evaluating_large_language_models_in_generating_synthetic_hci_research_data_a_case_study"
        },
        {
            "paper_title": "Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous",
            "rating": 1,
            "sanitized_title": "autogpt_an_experimental_opensource_attempt_to_make_gpt4_fully_autonomous"
        }
    ],
    "cost": 0.0197315,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale
4 Jul 2024</p>
<p>Jonas Oppenlaender oppenlaenderj@acm.org 
Independent Researcher
Finland</p>
<p>Joonas Hämäläinen joonas.k.hamalainen@jyu.fi 
University of Jyväskylä
Finland</p>
<p>Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Mining Insights at Scale
4 Jul 20244F53EF399461F05CD24092376D27637FarXiv:2306.05036v4[cs.HC]
Large language models (LLMs), such as ChatGPT and GPT-4, are gaining wide-spread real world use.Yet, these LLMs are closed source, and little is known about their performance in real-world use cases.In this paper, we apply and evaluate the combination of ChatGPT and GPT-4 for the real-world task of mining insights from a text corpus in order to identify research challenges in the field of HCI.We extract 4,392 research challenges in over 100 topics from the 2023 CHI conference proceedings and visualize the research challenges for interactive exploration.We critically evaluate the LLMs on this practical task and conclude that the combination of ChatGPT and GPT-4 makes an excellent cost-efficient means for analyzing a text corpus at scale.Cost-efficiency is key for flexibly prototyping research ideas and analyzing text corpora from different perspectives, with implications for applying LLMs for mining insights in academia and practice.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs), such as ChatGPT (OpenAI, 2022) and GPT-4 (OpenAI, 2023), have begun to impact a multitude of academic fields.An intriguing utility of LLMs is their ability for discovering insights in a given text corpus and examining the corpus from different perspectives (e.g., Petridis et al. (2023)).</p>
<p>This capability for open-domain information mining with the goal of retrieving answers to a given question from a text corpus is enabled by the LLMs' ability to follow instructions (Christiano et al., 2017;Dubois et al., 2023;Ouyang et al., 2022;Wei et al., 2022) and learn in-context (Brown et al., 2020;Dai et al., 2023;Kojima, Gu, Reid, Matsuo, &amp; Iwasawa, 2022;Olsson et al., 2022).LLMs could, therefore, be used for qualitative analysis of text corpora from one or several perspectives.However, concerns have been raised about the ability of LLMs to accomplish this task.Despite the impressive capabilities demonstrated by LLMs today, the depth of our understanding of their operation is limited.A significant aspect of this ambiguity stems from the opaqueness of the state-of-the-art LLMs.In particular, little is known about the training data utilized for OpenAI's ChatGPT (OpenAI, 2022) and GPT-4 (OpenAI, 2023).This situation invites legitimate questions about potential data leakage from benchmarks into the training data (Brown et al., 2020;Wei et al., 2022), and the extent of the models' reliance on memorization versus comprehension and reasoning (Bubeck et al., 2023;Carlini et al., 2021).Typically, LLMs are evaluated on canonical benchmarks (with few exceptions, e.g., Bubeck et al. (2023)).While benchmark datasets provide a reference point against which the performance of language models can be assessed, the reliance on standard benchmarks in the evaluation of LLMs is a growing concern (Thomas &amp; Uminsky, 2022).For researchers in academia and industry, the wide-spread re-use and concentration on few benchmark datasets and standard metrics risks missing opportunities for applying language models in real-world tasks (Bubeck et al., 2023;Koch, Denton, Hanna, &amp; Foster, 2021;Paullada, Raji, Bender, Denton, &amp; Hanna, 2021).</p>
<p>One such real-world task is mining insights from an entire field of research.The field of Human-Computer-Interaction (HCI) is vast and fragmented into many extremely diverse sub-communities (Liu et al., 2014).</p>
<p>Each year, several thousand researchers come together at the ACM Conference on Human Factors in Computing Systems (CHI) -HCI's flagship conference -to present their work on highly diverse topics.In 2023, CHI's main proceedings comprised 879 research papers in almost 150 different conference sessions.</p>
<p>Given the sheer volume of publications in the CHI proceedings and the diversity of the field of HCI, it is difficult to get an overview of the field, let alone the field's current research challenges.A research challenge is a difficult problem or question in a research field that has yet to be satisfactorily addressed or resolved.</p>
<p>Identifying the current research challenges would provide valuable insights about the current state of the HCI field and future research directions.This task is important as "there is a growing need for work that supports scholars in understanding the overall direction of the [HCI] field" (Stefanidi et al., 2023).</p>
<p>However, the scale and diversity of the field of HCI makes it difficult to identify the field's current research challenges.We therefore ask:</p>
<p>Can we use LLMs to automatically identify the current research challenges in the field of HCI?</p>
<p>To solve this knowledge-intensive task, we apply two LLMs, ChatGPT (i.e., and , in combination for the real-world task of mining insights from a large text corpus from the field of HCI.This text corpus was published after the two LLMs were trained.By evaluating the LLMs on never before seen data, we can evaluate their real-world capabilities for reasoning over textual data.</p>
<p>In particular, we seek an answer to the following question:</p>
<p>What are the current research challenges for researchers in the field of HCI?</p>
<p>To address this research question, we analyze the CHI 2023 proceedings (consisting of 879 papers).The CHI 2023 proceedings were selected due to their comprehensive coverage of current HCI research, offering a rich corpus for evaluating LLMs' insight mining capabilities.The analysis was conducted in two successive steps.We first extract a set of candidate research challenges with ChatGPT (gpt-3.5-turbo-0301)from confronting researchers in the field of Human-Computer Interaction.We map the challenges in an interactive visualization, providing a snapshot view on the current HCI research challenges, shedding light on the current landscape of HCI research, and providing insights on future research opportunities.</p>
<p>We contrast these findings with HCI's grand challenges and the UN's Sustainable Development Goals, providing valuable insights on the alignment of the field of HCI with its grander vision.We share the data and visualization in the spirit of open science. 1. Evaluation of LLMs for the practical task of cost-efficient mining of insights (Section 6):</p>
<p>We evaluate a two-step approach that complements ChatGPT with GPT-4 for insight mining in a corpus of text.This approach extends researchers' toolbox with a method for qualitatively analyzing a text corpus from a given perspective at scale.We critically examine the capabilities and limitations of this approach.</p>
<p>We believe evaluating LLMs on real-world tasks, such as the above, rather than on academic benchmarks, is important to inform researchers in academia of ChatGPT's and GPT-4's real-world capabilities.Our aim is not to compare ChatGPT against GPT-4.Rather, we evaluate GPT-4 as a complement to ChatGPT for cost-efficient mining of insights from a text corpus.In practice, working with LLMs involves not only direct costs for running the mining process, but also indirect costs for experimentation, iterative prompt design, testing, and prototyping.We emphasize cost-efficiency in our approach, as cost-efficient mining of insights is useful, for instance, when piloting research ideas or analyzing data from many different perspectives.Our aim is to achieve a high quality of results with little resources and expenses to support an agile approach to qualitative analysis of a data corpus from a given perspective.While this study focuses on HCI, the methodologies and findings could inform similar applications of LLMs in other academic domains, subject to domain-specific adaptations.</p>
<p>2 Related Work</p>
<p>Language Models</p>
<p>Large language models (LLMs) take a sequence of tokens as input and output a probability distribution over the next token.Text is generated by sampling from this next-token distribution in response to prompts.</p>
<p>Because LLMs were trained on internet-scale text corpora, many users turn to LLMs for retrieving answers to their questions, thereby using "LLMs as a new kind of search engine" (Hämäläinen, Tavast, &amp; Kunnari, 2023).This querying of the LLM can be referred to as knowledge extraction (Carlini et al., 2021) or knowledge retrieval (Linzbach, Tressel, Kallmeyer, Dietze, &amp; Jabeen, 2023).Although LLMs show promising capabilities, concerns about data biases, hallucinations, and the black-box nature of these models persist, impacting their reliability (Cong-Lem, Soyoof, &amp; Tsering, 2024).The use of LLMs for factual recall is prone to hallucinations (Cundy &amp; Ermon, 2023;Ji et al., 2023;M. Zhang, Press, Merrill, Liu, &amp; Smith, 2023), which may hinder the performance of knowledge extraction in real-world applications.Alternatively, LLMs can be used to reason over a given piece of text.This is enabled by the LLMs' ability to learn in-context (Brown et al., 2020;Dai et al., 2023;Kojima et al., 2022;Olsson et al., 2022).With in-context learning, LLMs can be used in many different downstream tasks beyond knowledge extraction.</p>
<p>In this paper, we investigate applying LLMs's ability for in-context learning for the task of insight mining.</p>
<p>Our aim is to extract answers to a specific research question from a given text corpus.Because it is possible to analyze a text corpus from many different perspectives, we specifically focus on the cost-efficiency of the process.In the following section, we explain how this practical task relates to other canonical tasks in the scholarly literature.</p>
<p>Insight Mining with LLMs</p>
<p>Our work is difficult to subsume under a single research area.In this section, we discuss how our real-world task relates to other canonical tasks and how OpenAI's LLMs have performed in some of these tasks.</p>
<p>Information extraction (IE) is the task of identifying structured information -such as entities, events, and their relationships -from unstructured data (Mausam, 2016).Researchers have developed many systems for open information extraction (Open-IE) over the years (e.g., Banko, Cafarella, Soderland, Broadhead, and Etzioni (2007); Del Corro and Gemulla (2013); Mausam, Schmitz, Soderland, Bart, and Etzioni (2012)).</p>
<p>OpenAI's ChatGPT performs remarkably well in open-IE tasks, despite certain shortcomings including its tendency to be overconfident (B.Li et al., 2023).The high performance of ChatGPT is not surprising given that ChatGPT has demonstrated good performance in many zero-shot natural language tasks (Qin et al., 2023).Compared to our approach, the IE task differs in that the output of our approach is unstructured text.</p>
<p>Document summarization strives to encapsulate the crucial concepts of a document succinctly, minimizing repeated content (Gupta &amp; Gupta, 2019).Automated extractive document summarization is concerned with presenting "salient concepts of a given document in a compact way, and [minimizing] repetition of the presented ideas or concepts" (X.Zhang, Li, Chi, Chandrasegaran, &amp; Ma, 2023).This task differs considerably from our objective of identifying research challenges in a text corpus.</p>
<p>Question answering (QA) (Voorhees, 2000) involves providing an answer to a specific question from a text.Closed-domain QA requires an understanding of the question and interpreting the given text in relation to the question.In the QA domain, LLMs have demonstrated adeptness in generating answers through multi-step reasoning processes (Creswell &amp; Shanahan, 2022).This ability of LLMs for reasoning over a text corpus makes them applicable for scientific question-answering (QA).</p>
<p>Qualitative analysis (QA) aims to unravel underlying meaning, patterns, and themes within data in a deeper exploration of specific topics (Braun &amp; Clarke, 2006, 2019).QA approaches are rooted in grounded theory (Glaser &amp; Strauss, 1967).This approach is beneficial when diving deep into complex topics, such as understanding the challenges in a research field.However, this method often culminates in the formulation of deep and nuanced insights, as well as narratives or conceptual frameworks, contrasting with our more approach of unearthing more literal insights concerning a particular question.Related to QA, Gao et al. (2023) investigated the potential of ChatGPT for conducting qualitative analysis and Xiao, Yuan, Liao, Abdelghani, and Oudeyer (2023) investigated the possibility of using GPT-3 in assisting qualitative coding.Both studies found GPT-based languaged models to be useful for the task of qualitative analysis.Note that traditional QA systems aim to answer a wide variety of questions.Our research, on the other hand, investigates the performance of LLMs on a single, deep question.While there is some overlap with the QA task, the depth and specificity of our investigation limit the applicability of QA as a conceptual framing for our study.</p>
<p>Knowledge discovery (KD) is a broader area of research that seeks to unveil novel patterns, trends, correlations, or insights within extensive datasets.Knowledge discovery implies a deeper understanding and synthesis of data rather than just retrieving or extracting it.Our use of a language model to explore a single, broad, and potentially complex question aligns with this notion.However, we note that traditional knowledge discovery methodologies diverge considerably from our approach, employing a variety of computational and statistical tools (Fayyad, Piatetsky-Shapiro, &amp; Smyth, 1996).Further, the term knowledge discovery is strongly associated with the specific methodology of knowledge discovery in databases (KDD) (Fayyad et al., 1996), whereas our approach is not related to databases.</p>
<p>Information retrieval (IR) is generally focused on locating and retrieving specific pieces of information within large datasets or corpora.This process is mainly reactive, responding to user queries without offering deeper insights or interpretations.In this sense, information retrieval might seem superficial for our goal, which seeks not only to retrieve but also to delve deeper by mining insightful responses to complex questions.</p>
<p>Text mining provides a more compatible framework for our work.This task involves analyzing texts to extract information and uncover hidden patterns and trends, often utilizing sophisticated algorithms to understand and interpret unstructured data.Text mining goes beyond mere retrieval, offering a groundwork where novel insights and knowledge can be generated.Yet, to further distinguish our work from text mining approaches that were generally not based on language models, we choose the framing of insight mining.</p>
<p>This concept encapsulates our approach to employ LLMs to extract insights from vast text corpora in response to specific complex queries.</p>
<p>The critical focus in the above knowledge-intensive tasks is on faithfulness and avoiding hallucinations (Creswell &amp; Shanahan, 2022;He, Zhang, &amp; Roth, 2022;Koto, Lau, &amp; Baldwin, 2022;Maynez, Narayan, Bohnet, &amp; McDonald, 2020).ChatGPT and GPT-4 have exhibited prowess in dissecting texts from various viewpoints, facilitating "What if?" analyses (Hämäläinen et al., 2023).In our work, we scale this approach to an entire corpus of documents, aiming at discovering answers to a specified question within a document corpus.In the following section, we explain how language models are commonly evaluated on such a task and the shortcomings of canonical evaluation approaches on real-world tasks.</p>
<p>Evaluating Large Language Models on Real-World Tasks</p>
<p>Large language models are increasingly being applied as a fundamental application layer in practice.Therefore, it is prudent to evaluate LLMs on real-world data and tasks.Researchers in academia often base their evaluation on task-specific benchmark metrics and datasets (e.g., (B. Li et al., 2023)).This is the standard way of evaluating large language models in machine learning (Bubeck et al., 2023).But while benchmark datasets and human-free evaluation metrics (Liu, Jia, &amp; Zhu, 2022;Vasilyev, Dharnidharka, &amp; Bohannon, 2020) provide a convenient means for comparing the performance of different LLMs, such evaluations may underrepresent the LLMs' capabilities on practical tasks and canonical metrics may not accurately represent the performance of LLMs.Further, benchmark datasets may be misaligned with real-world use cases, making them susceptible to distribution shifts (Suresh et al., 2023).Nevertheless, researchers in academia and industry widely re-use datasets and concentrate on few standard evaluation metrics (Bubeck et al., 2023;Koch et al., 2021;Paullada et al., 2021), with few exceptions.Bubeck et al. (2023), for instance, studied the performance of GPT-4 on selected edge cases and Z. Yang et al. (2023) curated a collection of qualitative samples in their evaluation of GPT-4V.Qualitative evaluations are, however, unusual in the field.</p>
<p>For researchers in academia and industry, the wide-spread reliance on benchmarks and standard metrics risks missing opportunities for applying language models in real-world tasks (Bubeck et al., 2023;Koch et al., 2021;Paullada et al., 2021).While exciting practical applications for LLMs are emerging -such as in the area of robotics (Vemprala, Bonatti, Bucker, &amp; Kapoor, 2023) and behavioral simulations (Park et al., 2023;Wang, Chiu, &amp; Chiu, 2023) -the evaluation of LLMs on real-world tasks is still an underexplored area of research (E.Jo, Epstein, Jung, &amp; Kim, 2023).The real-world task that we tackle in this paper is identifying the research challenges of the field of HCI.Comparing these findings with HCI's grand challenges may yield valuable contributions to the field.</p>
<p>Grand Challenges in HCI</p>
<p>This section briefly reviews two prior contributions on "grand" challenges in the field of HCI, offering context for our research results.Grand challenges are complex, significant problems that often require interdisciplinary approaches and large-scale, long-term efforts to solve.These challenges are typically characterized by their global or societal scale, technical complexity, and the need for a collaborative, multifaceted approach.</p>
<p>Historically, grand challenges have been used to focus attention, resources, and research on critical issues.</p>
<p>In the following, we review two sets of grand challenges postulated for the field of HCI.Shneiderman et al. (2016) identified 16 grand challenges for HCI practitioners, covering a wide range of topics.These include the promotion of life-long learning, encouraging resource conservation, and advancements in persuasive technologies.They also discuss the importance of accountability and responsibility, particularly in healthcare-related HCI.This enumeration of challenges reflects a diverse set of priorities and goals within the field, suggesting areas for future exploration and development.Stephanidis et al. (2019) outlined key challenges in HCI, with a focus on the interplay between humans and technology.Their work brings attention to aspects such as health, well-being, creativity, eudaimonia, accessibility, ethics, privacy, security, and human-environment interaction.These challenges highlight the evolving scope of HCI research and its increasing relevance to various aspects of daily life and societal functioning.</p>
<p>These grand challenges in the field of HCI broadly relate to the UN's Sustainable Development Goals (SDGs) (United Nations, 2015) by promoting well-being, health, education, and inclusive societies.The focus within HCI on sustainable technologies, ethics, accessibility, and secure information sharing mirrors the SDGs' emphasis on holistic and sustainable development.This connection illustrates how HCI challenges not only address specific technological and user-centered concerns but also contribute to broader societal objectives.</p>
<p>In our research, we use these sets of grand challenges to provide context and a point of comparison.The following section delves into the data collection and processing methods used in our research.This analysis is rooted in the comprehensive body of work presented at CHI 2023, offering a lens through which we can examine current priorities and research directions in HCI.</p>
<p>Text Corpus: The CHI 202Proceedings</p>
<p>In this section, we provide descriptive statistics of the collection of scholarly papers that formed the basis of our analysis.The main proceedings of CHI 2023 encompass 879 research papers, formatted in accordance with ACM's double-column template.These papers range from 8 to 45 pages, including references and optional appendices.To better approximate the actual number of content pages, we count the pages up to the final instance of the word "References."This method yields a more accurate estimate of the number of content pages per paper, as illustrated in Figure 1.Using this approximation, we find that full papers in the CHI 2023 proceedings had between 7 and 32 pages (M = 13.5 pages, SD = 2.6 pages).At CHI 2023, the papers were presented in 148 highly diverse thematic sessions, some with overlapping topics.For instance, the topic of mental health was discussed in three dedicated sessions with six papers each.The sheer volume and diversity of knowledge and research presented at the CHI conference sessions highlights that it is very difficult to get an overview of the HCI field and its current research challenges.In the following section, we describe our approach to tackling this problem.</p>
<p>Method</p>
<p>Our approach consists of the following phases: data acquisition and preparation, data processing, topic modeling, and topic visualization.Data processing is split into two consecutive steps: 1) extracting challenges with ChatGPT and 2) filtering challenges with GPT-4.We provide implementation details for each phase in the following sections.</p>
<p>Data Acquisition and Preparation</p>
<p>We downloaded the CHI 2023 proceedings from the ACM Digital Library, focusing only on full research papers.Next, we extracted the text from each paper, using the textract python library (version 1.6.5).</p>
<p>In one paper, the text could not be extracted.We used an OCR software on this paper to embed the text into the PDF document before extracting it with textract.Next, we removed the references and optional appendices from each paper by discarding the text after the last occurrence of the keyword "References."</p>
<p>Additionally, the following normalization was applied to each text document, using regular expressions in Python:</p>
<p>• remove the text " CHI 23, April 2328, 2023, Hamburg, Germany" which appears in the header of the documents,</p>
<p>• remove citations (e.g., " [23]"),</p>
<p>• replace line breaks with spaces and condense consecutive white space characters into one,</p>
<p>• set all text to lowercase.</p>
<p>The resulting text corpus contains 879 documents which we process in two consecutive steps.</p>
<p>Data Processing: Two-step Approach for Cost-Effective Mining of Insights</p>
<p>We employed a two-step approach for cost-effective insight mining on the text corpus: The two-step approach first involved extracting candidate challenges with ChatGPT (gpt-3.5-turbo-0301),followed by refining the list to the top five most significant challenges per paper using , based on criteria such as relevance and frequency.</p>
<p>The following two sections describe our prompt design methodology for these two consecutive steps.</p>
<p>Our experimentation with different prompts was conducted not in OpenAI's web interface, but in Jupyter notebooks using the OpenAI Python Library (v0.27.4).For all experiments, the temperature parameter was set to zero.The temperature is an important parameter of language models that controls the randomness in outputs (Cohere Team, 2022).Lower values will make the model more focused and deterministic.A temperature value of zero is recommended for factual use cases, such as data extraction and truthful Q&amp;A tasks (Shieh, 2023).Additionally, this temperature value was chosen to introduce consistency in the prompt design process.Deterministic outputs -as produced by the termperature of zero -are a necessary prerequisite for determining whether a prompt improved or not during the iterative prompt design process.The top p parameter was left at its default, as recommended by OpenAI.2</p>
<p>Step 1: Insight mining with ChatGPT</p>
<p>We iteratively experimented with different prompts for the task of extracting research challenges from the text corpus.The prompt prototyping process was conducted in a Jupyter notebook where we stored a history of prompts and results.We started by applying best practices for reliable prompting from the scholarly and gray literature (Bsharat, Myrzakhan, &amp; Shen, 2023;Lopez-Lira &amp; Tang, 2023;OpenAI, n.d.;Oppenlaender, 2023;Salewski, Alaniz, Rio-Torto, Schulz, &amp; Akata, 2023;Si et al., 2023).For each change made to the prompt, we observed the outcome on a sample of documents.If a perceived improvement was made, we kept the change, otherwise reverted to a prior prompt.This iterative process ultimately lead to the following prompt: Forget all the above.You are InfoMinerGPT, a language model trained to extract challenges for researchers in the field of HCI from academic papers.You output a list of challenges, one per line, without explanations.If there are no challenges mentioned in the text, you output 'None'.</p>
<p>Here is the academic paper:\n\n</p>
<p>The first part of this prompt aims to instruct ChatGPT to ignore its initial instructions and persona (F.Perez &amp; Ribeiro, 2022).This is needed because ChatGPT is primed to be an intelligent AI assistant with aim of providing explanations in its outputs.By instructing ChatGPT to ignore its initial instructions and assume an expert persona, we can improve the LLM's performance (Bsharat et al., 2023;F. Perez &amp; Ribeiro, 2022;Salewski et al., 2023;White et al., 2023) and reduce the "chattiness" of the model.Similar prompt instructions were used in other research studies (e.g.(Lopez-Lira &amp; Tang, 2023)).</p>
<p>We also experimented with other prompt formats, such as instructing the model to "never to break character" and few-shot prompting (i.e., providing several examples in the prompt) (Brown et al., 2020).However, we found the above prompt resulted in output that consistently met our expectations during our experiments in terms of the extracted statements being plausible research challenges related to the document source text.</p>
<p>Step 2: Information filtering with GPT-4</p>
<p>For cost-efficient insight mining, we apply the more powerful GPT-4 only in a second step for filtering the results provided by the cheaper ChatGPT.To achieve this, we iteratively designed a prompt for GPT-4 to filter the list of challenges on a per-paper basis, as follows:</p>
<p>Below is a JSON list of challenges extracted from an academic paper.Please remove any duplicates.Then keep only the 5 most important challenges for researchers in the field of HCI.You output a list of challenges, one per line, without explanations.Here are the challenges:\n\n This prompt was followed by the list of research challenges extracted by ChatGPT for each paper.The design of this prompt required much less experimentation, as GPT-4 is a more powerful model that is better able to consistently follows its given instructions (OpenAI, 2023; J. Yang et al., 2023).Special computational priming with a persona (Oppenlaender &amp; Hosio, 2019) was found not to be needed for completing this step.</p>
<p>Summary of prompt design</p>
<p>In our iterative experiments, we found the above prompts performed well and produced consistent results.</p>
<p>However, we acknowledge that the outputs are sensitive to the prompt design.Note that we do not regard our prompts as absolute optimum for discovering the ground truth in the data.Instead, our aim is to filter signal from noise.The prompts allowed us to consistently extract signal from the text while step-by-step reducing noise.We evaluate the quality of the extracted information in Section 6.</p>
<p>API querying statistics and costs</p>
<p>The source text was split into sentences using NLTK's sentence tokenizer.The API was then queried in batches of sentences.More specifically, we determined the API could process most papers in batches of 90 sentences without exceeding the model's maximum context length of 4,096 tokens.However, some papers had very long sentences and the API querying stopped with an InvalidRequestError on these papers.We implemented code to iteratively reduce the batch size by 20 sentences at a time when encountering such an error.Most papers were processed with a batch size of 90 sentences, while a few papers had to be processed with as low as 50 sentences per batch.</p>
<p>The total time spent querying the API was 13 hours and 45 min for Step 1 and 3 hours and 51 min for Step 2. We monitored the API querying, occasionally restarting the process when a RateLimit error occurred (indicating that OpenAI's API was overloaded at the time).The total cost (including initial experiments, prompt design, and batch querying) was US$49.95.</p>
<p>Topic Modeling and Visualization</p>
<p>We created an interactive plot of the extracted research challenges with Vega-Altair (VanderPlas et al., 2018).The interactive visualization includes features such as zoom, filter by topic clusters, and detailed views of individual research challenges, facilitating in-depth exploration.To this end, we converted the challenges into sentence embeddings.In natural language processing, embeddings are high-dimensional vector representations that capture and quantify the semantic or syntactic properties of linguistic units, such as words, phrases, or documents.We embedded each challenge using the all-mpnet-base-v2 pretrained model of sentence transformers (Reimers &amp; Gurevych, 2019).Besides Sentence-BERT embeddings, we also experimented with OpenAI's text-embedding-ada-002 embedding model and with the CLIP model (Radford et al., 2021), models trained on an extensive amount of textual data.We found embedding the research challenges with Sentence-BERT produced coherent and meaningful clusters.The silhouette score of the clusters, a measure of cluster consistency, was 0.27 for the Sentence-BERT embeddings (as compared to 0.19 and 0.24 for text-embedding-ada-002 and CLIP, respectively).</p>
<p>For projecting the embeddings into two-dimensional space, we experimented with two algorithms for dimensionality reduction: t-distributed Stochastic Neighbor Embedding (t-SNE) (van der Maaten &amp; Hinton, 2008) and Uniform Manifold Approximation and Projection (UMAP) (McInnes, Healy, Saul, &amp; Großberger, 2018).Because UMAP offers advantages over t-SNE (Coenen &amp; Pearce, n.d.;McInnes et al., 2018), such as better preservation of global structure, we applied UMAP for projecting the research challenge embeddings into two-dimensional space.</p>
<p>To support the interactive exploration of clusters in the visualization, we created cluster labels with BERTopic (Grootendorst, 2022).BERTopic is a topic modeling technique that leverages transformer-based language models -BERT (bidirectional encoder representations from transformers) ( manually reviewed each bag of words and assigned a label to each topic.For many of the topics, assigning a custom descriptive topic label was straightforward and no calculation of inter-rater agreement was required (McDonald, Schoenebeck, &amp; Forte, 2019).This initial manual coding helped us understand the data and the quality of the topics.Later, while optimizing the parameters of the UMAP, HDBSCAN, and BERTopic models, we switched to automatic labelling with ChatGPT as it provides a means to more quickly test different parameters without having to manually re-label each topic.Testing out different hyperparameters helped us find a set of parameters that balanced cluster coherence with cluster meaning.The final set of 113 topics was manually labeled by the first author.</p>
<p>There are two reasons why a BERTopic-supported approach for identifying topics was needed.First, some CHI sessions have generic names (e.g., "Building Bridges" and "Discovery Track Monday").The sessions, therefore, do not serve as good thematic groupings for the extracted research challenges.Second, challenges mentioned in papers are not necessarily related to the main topic of a paper or the session.Therefore, the session titles may not meaningfully capture the research challenges mentioned in the papers.</p>
<p>Research Challenges in HCI</p>
<p>This section provides an overview of the extracted HCI research challenges (see Figure 2).For a comprehensive review, we invite readers to explore the interactive visualization and the dataset. 3We close the section with a brief discussion on how the challenges relate to HCI's grand challenges reviewed in Section 2.4.Gray, unfilled circles represent challenges that did not group into any of the identified clusters.An interactive visualization is available at https://hci-research-challenges.github.io.</p>
<p>Current Research Challenges and Themes</p>
<p>We start with basic descriptive statistics of the research challenges extracted with our approach.ChatGPT extracted 34,638 challenges from the 879 papers.On average, there are 39.3 challenges per paper (SD = 21.5;M in = 3; M ax = 198) with a mean of 10.7 tokens per challenge (SD = 4.9 tokens).Filtering with GPT-4 resulted in a total of 4,392 challenges.GPT-4 selected between 3 and 5 challenges per paper (M = 4.99, SD = 0.06) with on average 11.1 tokens per challenge (SD = 4.3 tokens).A non-cherry-picked sample of research challenges is showcased in Table 1 and another example is given in Table 3.</p>
<p>The analysis with BERTopic found distinct research challenge clusters in 113 highly diverse topics.The research challenge clusters, according to BERTopic, are listed in Appendix A in Table 4.Note that BERTopic, just like other topic modeling and clustering approaches, provides only one snapshot view on the data.</p>
<p>Challenge Paper</p>
<p>Investigating how embodying physics-aware avatars impacts task performance in VR. (Tao et al., 2023) Developing automated tools to detect and categorize OOD data in NLP models (Song et al., 2023) Understanding how designers make sense of the workings of physical interfaces built with CV markers (Gyory et al., 2023) Improving findability and actionability of privacy controls for online behavioral advertising (Im et al., 2023) Dealing with nuanced ethical concerns in conducting HCI research in the wild (Garrett et al., 2023) We regard the BERTopic clusters not as an ultimate ground truth, but as a means to provide meaning and facilitate exploration in the interactive visualization.</p>
<p>The research topics are highly diverse (see  research opportunities.</p>
<p>We now turn to comparing the research challenges and research themes with HCI's grand challenges.</p>
<p>Comparison with HCI's Grand Challenges</p>
<p>An informal qualitative comparison of the grand challenges from Section 2.4 with the extracted research challenges finds that, compared to the research challenges, the grand challenges are broader and more strategic, and include overarching topics or domains which could be understood as key areas or fields of study.The research challenges, on the other hand, include more granular and specific actionable topics, which could be understood as subdomains, detailed research areas, or specific issues within the broader domains delineated by the grand challenges.In the remainder of this section, we compare the alignment of the extracted research challenges with the grand challenges in more detail.</p>
<p>Method</p>
<p>We embed the grand challenges and project them into the same embedding space as the research challenges mined from the CHI proceedings, using UMAP (McInnes et al., 2018).This allows us to visually analyze and compare the sets of research challenges.However, semantics may affect the results in such an approach.</p>
<p>For this reason, we slightly modified two of the grand challenges by Stephanidis et al. (2019) to disentangle conflated challenges.For instance, we split 'Creativity and Learning' into two separate challenges ('Creativ-   ity' and 'Learning').For the UN's SDGs, we noticed they were all plotting closely in the same area of the plot.One reason for this, of course, is that all SDGs are about sustainability.However, the use of the word 'sustainable' may affect the location of the SDGs in our plot.Since all SDG statements have sustainability at their core, we decided to slightly modify some of the SDG statements for the purpose of allowing a more meaningful comparison in our visualization.In particular, we removed mentions of 'sustainability' from the SDGs.The modified versions are included in Figure 4. the design and implementation of future HCI systems.We can, however, also identify current research that is being conducted in areas outside of the purview of HCI's grand challenges.</p>
<p>Results and discussion</p>
<p>As for the alignment of the HCI field with sustainable goals, a nuanced landscape emerges.The UN' SDGs, even in their modified form, cluster relatively tightly, reflecting a coherent emphasis on sustainability.When juxtaposing the SGDs against the spectrum of current HCI research, we can see that the research topics of 'waste management' and 'food' exhibit a direct correlation with sustainability themes.This direct alignment underscores the potential of HCI research to contribute tangibly to sustainable development.However, there are many areas of current HCI research that are only indirectly related to advancing sustainable development,</p>
<p>and there are research topics that seemingly have no strong connection with sustainability.</p>
<p>The burgeoning field of HCI holds immense potential to drive innovative solutions for global challenges.</p>
<p>An indirect alignment with the UN's SDGs may represent missed opportunities for HCI research to contribute more profoundly to critical global needs.This misalignment could lead to a research trajectory that, while academically robust and highly diverse, may not fully leverage the transformative capacity of HCI in addressing key sustainability issues.Further, the lack of strong connections with sustainable development goals may limit the interdisciplinary collaboration essential for holistic problem-solving.The SDGs, by nature, require multidisciplinary approaches.HCI, with its inherent multidisciplinary character, is well-positioned to bridge diverse fields.However, this potential is underutilized if the research agenda does not explicitly align with or contribute to these broader goals.The urgency of issues like climate change, poverty reduction, and health equity demands a concerted effort from all disciplines, including HCI.The lack of alignment may reflect a disconnection between HCI research and broader societal needs.This disconnect risks marginalizing the field, reducing its relevance and impact.As HCI researchers, our goal should not be to force all research into the mold of sustainability.However, it is crucial to be aware of these global imperatives and consider how our work can contribute, directly or indirectly, to these larger goals.This awareness can drive innovation, open up new research avenues, and enhance the societal impact of our work.</p>
<p>Evaluation</p>
<p>We structure the evaluation around two key questions related to the validation and verification of the extracted challenges.We start by discussing how quantitative evaluation with canonical metrics is insufficient in our case (Section 6.1), and then proceed with qualitative evaluation (sections 6.2 and 6.3).</p>
<p>Quantitative Evaluation</p>
<p>While our focus in this paper is on the qualitative evaluation due to there being no precedent to our specific task in the literature, we also evaluated the performance using several quantitative metrics commonly used in the field of machine learning.</p>
<p>Exact Match (EM) (Bulian, Buck, Gajewski, Börschinger, &amp; Schuster, 2022)  We also used BLEU (Papineni, Roukos, Ward, &amp; Zhu, 2002), which measures n-gram precision between generated and reference texts, as well as ROUGE-1 and ROUGE-L (Lin, 2004), which focus on the overlap of unigrams and longest common subsequences, respectively.Additionally, we evaluated our results with METEOR (Banerjee &amp; Lavie, 2005) which takes into account synonymy, stemming, and word order, BLANC (Vasilyev et al., 2020) for assessing the quality of text summaries, and BERTScore (T.Zhang, Kishore, Wu, Weinberger, &amp; Artzi, 2020) for comparing the cosine similarity of texts.These metrics are canonical metrics from the field of natural language processing.We primarily include them as reference for future work.</p>
<p>Note that there is no gold standard (reference set) in our case, but the metrics require a reference set.To address this issue, we calculated the metrics using the best-matching pairs between the research challenges and statements in the source text as an approximation.For instance, for Step 1, we calculated the best-matching pairs between each ChatGPT challenge and the best-matching sentence in the source document, based on embedding cosine similarity.A similar approach was taken in Step 2, comparing the GPT-4 statements with the best-matching statement from the ChatGPT output.The results are presented in Table 2.As mentioned in Section 2.3, evaluation of language models is a difficult task, and most standard metrics in Table 2 do not capture what we expect from the model in our practical task.While these metrics are very common in the field of machine learning, they do not fully capture our given task.For instance, BLEU, WER, and METEOR are machine translation metrics and BLANC calculates scores for text summaries.For this reason, we turn to qualitatively analyzing the results.</p>
<p>Task-specific Human Evaluation</p>
<p>Perhaps the most important question to ask is whether ChatGPT followed its instructions: Did we extract research challenges?After all, the model could have just picked random sentences from the source documents.</p>
<p>Similarly, did GPT-4 pick the most important challenges from the ChatGPT-provided list?Because we evaluate the LLMs on a real-world task, there is no convenient ground truth for answering these two questions.</p>
<p>Our evaluation approach applies 'narrow grounding' (i.e., comparing the LLMs' output with instances in the supplied prompt) to evaluate whether the output of the models is accurate.We further draw on our own knowledge to assess the outputs (called 'broad grounding').To apply this approach, we turn to qualitatively analyzing the performance on a random sample of documents.</p>
<p>Qualitative analysis methodology</p>
<p>In the spirit of an end-to-end evaluation of the two LLMs on a real-world task, we evaluated the performance by analyzing the final outputs.To this end, one Postdoctoral Researcher with about six years of experience in HCI research read a random sample of 45 papers (≈5% of the corpus) with the task of noting down the five most important research challenges from each paper, blind to the LLM-generated list.Two authors of this paper then qualitatively compared the human-created list with the GPT-4 list for each sampled paper, counting them as equivalent if there were three or more statements in the GPT-4 list that matched lexically or semantically with statements from the human-created list.Partial matches were counted, if the overall meaning was captured.For each sampled paper, we also asked: Does the GPT-4 list consist of potential research challenges for HCI researchers?This is a challenging question, as we do not have deep subject matter expertise in every area of HCI.We therefore phrased the question conservatively, focusing on the potential Table 3: Excerpt of information extracted from one CHI 2023 paper Kinnee et al. (2023).Research challenges selected by  from the research challenges extracted by ChatGPT, compared to the source text (right).The sentences from the source text in this table were selected based on embedding cosine similarity to the ChatGPT sentence embeddings.</p>
<p>GPT-4 challenge</p>
<p>Most similar sentence from source text reimagining relationships with technology through self-discovery rather than use self-tracking devices to know or change ourselves, our process deploys other-tracking tracking devices (those designed for technology firms to collect our data) to reimagine our relationships with technology appropriation and ownership of personal data through a reworking of personal data, the speculation emphasizes the work of adopting something for ones own use without the explicit permission of the entities that control that data power dynamics embedded in corporately controlled data first, it orients analysis toward a consideration of the power dynamics embedded in corporately controlled data emotional labor and affective positioning in autospeculation for kinnee, each encounter with the data requires a form of emotional labor that brings about strong physical and affective responses polyvocality and the need to elevate diverse voices in autospeculation in this orientation, our analysis prompts a few important questions for hci: whose voices should autospeculation elevate?</p>
<p>of the list consisting of research challenges.Inter-rater agreement between the authors was calculated using</p>
<p>Cohen's kappa (Cohen, 1960).</p>
<p>Preliminary observations and adjustment of methodology</p>
<p>The human annotator performed the same task as the two LLMs, first noting down a list of challenges (equivalent to the task completed by ChatGPT) and later trying to narrow it down to the five most important challenges (equivalent to the GPT-4 task).We included papers outside the PostDoc's specific expertise in HCI to ensure an unbiased and broad representation of the HCI field and test the LLMs across diverse subdomains.This approach reflects real-world scenarios in the field of HCI where researchers frequently encounter literature beyond their immediate specialization, providing a realistic and comprehensive evaluation of the LLMs' capabilities.We note that extracting research challenges from text and filtering this list to a concise set of five statements is a complex task.The human annotator faced several difficulties, particularly in domains outside their direct expertise, such as embodied interaction.In these areas, the annotator tended to extract verbatim statements rather than re-formulating them as research challenges.Additionally, the task's high cognitive load became evident when narrowing down the lists to five statements per paper.</p>
<p>Alignment with human judgment</p>
<p>Both raters agreed almost perfectly that the extracted statements are potential research challenges for researchers in the field of HCI (κ = 0.97).While validating each extracted challenge in more detail would require subject matter expertise in many different sub-fields within HCI, the extracted statements certainly look like plausible challenges.</p>
<p>We also note very high inter-rater agreement (κ = 0.86) between the raters on the question of how well the challenges align with human-identified challenges.There were many clear matches, both lexically and semantically, between the human-identified and GPT-extracted lists of challenges.In about two thirds of the sampled papers (65.9% and 63.6%), the two raters thought the human-identified list of research challenges matched perfectly with the GPT-4-extracted list.This may seem like a low agreement, but there are three reasons why the GPT-4 challenges are not better aligned with the human-annotated challenges.First, the PostDoc approached the task like a human reader (focusing on the abstract, introduction, and discussion), while the language model executed the given the task in chunks over the whole text indiscriminately.Second, the human annotator was subject to fatigue, and later tried to complete the task by scanning headlines and copy-pasting verbatim statements rather than analyzing and rephrasing the extracted statements into research challenges.The human may have missed important challenges with this approach.Last, we note the human often placed different emphasis on what was extracted from the paper.The human-created list often revolved around the paper's narrow main topic, while GPT-4 sometimes extracted broader challenges.For instance, in E. Jo et al. (2023), the human-extracted challenges revolved around "designing and deploying LLM-driven chatbots for public health intervention," while GPT-4 also included broader challenges outside the public health domain, such as "controlling the output of LLM-based chatbots to avoid unintended or biased responses" and "ensuring privacy and security of user data in AI-powered interventions."In other cases, the human annotator completely missed important challenges that GPT-4 picked up.For instance, for Q.Yang et al. (2023), the AI included the challenge "mitigating risks of de-skilling clinicians in the use of AI" which the human list does not mention.</p>
<p>In conclusion, the fact that about 33% of the sets of challenges did not align with human judgment does not necessarily mean that these lists are not valid HCI research challenges reflecting challenges stated in the papers.The lists were not aligned in a minority of cases because 1) the human and AI placed different emphasis (with AI often picking broader and the human more granular topic-specific research challenges) and</p>
<p>2) the quality of the human-created list was sub-par to the GPT-4 list of research challenges, both in lexical and semantic terms.In the following, we highlight specific observations about the LLMs' performance.</p>
<p>Other outstanding observations on LLM performance</p>
<p>In this section, we note three peculiarities about the LLMs' performance in completing the given task, derived from our review of the 45 sampled papers.</p>
<p>First, we note that acronyms were present in the research challenges extracted by both ChatGPT and GPT-4.This is, without doubt, due to the widespread use of acronyms in the papers.While the meaning is often readily apparent for HCI researchers (e.g., AI, VR, XR, UX, XAI, ICT, GUI, LLM, MOOC, NLP), the acronyms were not self-explanatory in several cases, including ES (Environmental Sustainability), SHCI (Sustainable HCI), RAI (Responsible AI), DHH (d/Deaf and Hard-of-Hearing), AAC (Augmentative and Alternative Communication), and OCCs (Online Critique Communities).Within the specific HCI subcommunities, these acronyms may be very clear, but their meaning may not be readily apparent to every researcher in HCI.</p>
<p>Second, we note that a few of the challenges miss relevant context for allowing correct interpretation.</p>
<p>These challenges appeared, on first sight, to be potential hallucinations.For instance, we flagged the GPT-4</p>
<p>statement "Addressing scalability issues for large-scale text data" as a potential hallucination.However, this statement refers to the scalability issue mentioned in the limitations section of Song et al. (2023).The statement, therefore, is an open research challenge, even though it is difficult to interpret without context from the paper.</p>
<p>Third, besides sometimes having a different emphasis than the human-extracted challenges (as mentioned in the previous section), we noticed that in a few papers, the selection of research challenges seemed to alternate between topic-specific and broad challenges.In Petridis et al. (2023), for instance, the research challenges selected by GPT-4 include "Supporting journalists in exploring multiple angles for a given press release" and "Ensuring responsible journalism with LLM-generated angles," but also broader challenges, such as "Addressing limitations of publicly available LLMs, such as outdated world knowledge and bias in training data", and "Mitigating bias in LLM-generated implications."The latter is another example of a statement that we flagged as potential hallucination.The authors do, however, go into details about bias mitigation during prompt design when generating "implications" from text (even though the exact lexical phrase is not being used).In conclusion, we found no evidence of hallucinations in the 45 sampled sets of research challenges.</p>
<p>Evaluation of Performance</p>
<p>The previous section demonstrated that the extracted statements are valid research challenges aligned with human judgment.In this section, we look at the quality of the extracted challenges in more detail.In particular, we investigate the presence of noise in Step 1 (Section 6.3.1) and the semantic similarity of the results with the source text (Section 6.3.2).</p>
<p>Noise in ChatGPT results</p>
<p>We manually reviewed the ChatGPT-extracted challenges and noticed statements such as:</p>
<p>• "Challenges for researchers in the field of HCI from this paper:"</p>
<p>• "Challenges not mentioned in the text."</p>
<p>Clearly, these statements are not research challenges.The statements are remnants of ChatGPT being programmed to act as an intelligent assistant that provides explanations in all its outputs.However, the statements could easily be filtered with basic string matching and regular expressions.We found only 317 (out of 34,638; ≈0.9%) of these statements in Step 1. GPT-4 seemed to be largely unaffected by these statements and ignored them when completing the given task of selecting research challenges from the ChatGPT-provided list.</p>
<p>We further noticed that authors in CHI often typeset their papers using ligatures (e.g., "ff").These multibyte characters cause accessibility-related issues in the source text (e.g., white space within words) extracted from the pdfs.However, both ChatGPT and GPT-4 were unaffected by this typographic issue.</p>
<p>Semantic similarity</p>
<p>A good information extractor should produce information that is semantically close to the source text.</p>
<p>Therefore, we compared the embedding cosine distances between the statements extracted in each of the two steps.For Step 1, we expected the plot of embedding cosine distances (defined as the inverse of embedding cosine similarity) to follow a long-tailed distribution.There should be many research challenges with high semantic similarity to sentences in the source text, and only few challenges that are semantically different.</p>
<p>To produce embeddings for Step 1, we first used the NLTK sentence tokenizer to split the source text into sentences.We then embedded the sentences (using the all-mpnet-base-v2 pre-trained sentence transformer model) and, for each ChatGPT statement, identified the best matching sentence pair, using embedding cosine similarity as measure.For Step 2, we followed the same approach and identified the best-matching pairs between GPT-4 and the ChatGPT.In Step 2, we expect the model to pick challenges from the list without paraphrasing, given its instruction of selecting the five most important challenges from the ChatGPT-provided list.We find the vast majority of statements were reproduced verbatim, as expected.In Step 2, GPT-4 deviated from the Step 1 wording in only 60 cases (1.38%), and 4,333 statements can be found verbatim in Step 1.This confirms that GPT-4 did select challenges from the list without much paraphrasing or hallucinations.</p>
<p>Discussion</p>
<p>In this section, we delve into the implications, potential applications, and broader impact of leveraging large language models for insight mining at scale, particularly in the context of HCI research.The use of LLMs for insight mining exemplifies a paradigm shift in research methodologies, potentially transforming how academic literature is analyzed and synthesized.Our discussion explores the paradigm shift brought about by foundation models in the research landscape, highlighting the transformative capabilities of these models in facilitating large-scale data analysis and insight extraction.We critically examine the current state of academia's response to generative AI, its underutilization in research methodologies, and the overarching implications for the HCI field.</p>
<p>Applying LLMs for Insight Mining at Scale</p>
<p>We are entering an era where foundation-scale models are becoming increasingly influential.Foundation models (Bommasani et al., 2021) are general-purpose, pre-trained models designed to perform a range of downstream tasks through prompting, although their effectiveness can vary depending on the task.For certain research questions that were challenging with traditional methods, in-context learning and careful prompt design offer new avenues for exploration.LLMs represent a significant addition to researchers' toolkit, potentially indicating an evolving shift in some areas of knowledge work.We see this paradigm shift already outside of academia, where an increasing number of applications are being developed based on LLMs under the nascent paradigm of LMOps or LLMOps (Tobin, 2023).For instance, Auto-GPT (Richards, 2023) and BabyAGI (Nakajima, 2023) are experimental prototypes that use GPT-4 for fully autonomous problem-solving.The interest in these projects is evident from their GitHub repositories' stars, speaking to the enormous popularity of the burgeoning paradigm of LLMOps and LLM-based agents.Academia, on the other hand, still largely struggles to keep up with recent developments in the field of generative AI due to its slow pace reflecting the thoroughness and rigor typical of academic research.For instance, due to long research and publishing cycles, research published at CHI 2023 still relied on GPT-3, a 2020 model that must now be considered outdated.</p>
<p>Moreover, the narrative in the scholarly literature regarding the latest generation of generative AI often revolves around its limitations (e.g., (Denning, 2023a)) and potential harm (e.g., (Rastogi, Ribeiro, King, &amp; Amershi, 2023)).Many authors in academia make normative statements on what ChatGPT should not be used for, even though what the LLM can do in real-world settings is still underexplored (E.Jo et al., 2023).</p>
<p>This value-laden reporting in the literature influences what is being studied in academia (Dotan &amp; Milli, 2020), and there is a deep seated mistrust against OpenAI's opaque LLMs among some researchers and users of generative AI (Denning, 2023b).The scholarly literature vastly ignores and underestimates ChatGPT's potential for in-context reasoning (e.g., Bender, Gebru, McMillan-Major, and Shmitchell (2021)).While it is true that LLMs will tend to hallucinate when used for the task of knowledge extraction (Dutta &amp; Chakraborty, 2023), their true ability comes to shine when given a text as context and a specific task on this context.The application for the tasks of insight mining and knowledge discovery remains under-explored.</p>
<p>Our aim in investigating this task is not to mine an absolute ground truth from a text corpus.We rather see it as an approach to separate signal from noise in the data, and to discover useful information that is "good enough" for its purpose (thus, turning it into knowledge).Like in the field of machine learning, where there are many hyperparameters that can influence the quality of results, there are many ways to design prompts for the task of insight mining.Finding the right prompt requires iterative experimentation and expertise in prompt engineering (Oppenlaender, 2022).This is a departure from the status quo and a paradigm shift for research in HCI and many other fields, where experiments typically yield only one set of results, rather than polivocal results.On the other hand, polivocality holds value (Draws et al., 2023;Gatos, Günay, Kırlangıç, Kuscu, &amp; Yantac, 2021;van Erp &amp; de Boer, 2021).Each output from a language model represents a different, but equally likely outcome, and subtle changes in input prompts can provide perspectives on textual data that are difficult to produce with traditional (manual) means.The goal in our real-world task is to facilitate experimentation from many different perspectives in a cost-efficient and time-effective way.In the next section, we discuss how the LLMs fared in this regard.</p>
<p>Cost-efficient Data Exploration with LLMs</p>
<p>Research is about experimentation, and many different perspectives on the corpus of scholarly papers could be explored.For instance, we could have asked: What are the current research topics in the HCI sub-field of accessibility?What are the methods used by HCI researchers?Answers to these questions are scattered within papers in the field of HCI, and not necessarily limited to papers published in one sub-community.</p>
<p>Therefore, answering these questions would require prompting the LLMs with the entire corpus of documents repeatedly.Consequently, an agile and cost-efficient approach is needed.Cost-efficient insight mining is useful in solving the task of analyzing a text corpus from different perspectives.For instance, journalists may want to analyze a press release from different angles (Petridis et al., 2023).Our study demonstrates that such an investigation can be scaled from a single document to entire corpora of text.</p>
<p>The CHI conference proceedings proved to be a fitting study subject in this regard.The volume of information published at the CHI conference is immense.In total, the CHI 2023 proceedings encompass approximately 11,894 pages of substantive content.To help visualize this, consider that if the papers published in the 2023 CHI conference proceedings were to be printed out and laid end-to-end, the length would extend to about 3.32 km (2.06 miles).For a single researcher, comprehensively reviewing this volume of literature to extract HCI research challenges would be a daunting task, potentially requiring weeks or months of dedicated effort.In contrast, our application of LLMs to this challenge demonstrates significant time efficiency.</p>
<p>The study was conducted using a standard cloud computing environment, with the total processing time for insight mining from the CHI 2023 proceedings amounting to approximately 17.5 hours.This rapid processing capability of LLMs highlights their potential as powerful tools for literature review and information synthesis in academic research.The nature of this approach (i.e., querying APIs) allowed our research team to focus on other tasks and engagements, underscoring the practical benefits of integrating AI-driven methods into scholarly work.LLMs have potential to revolutionize how researchers interact with and analyze large volumes of academic literature.Our findings suggest that LLMs can play a vital role in assisting researchers to quickly identify key themes and challenges in their fields, thereby enhancing the productivity and depth of academic inquiries.</p>
<p>The cost-efficiency of our approach could potentially be further enhanced by utilizing free open-source alternatives to OpenAI's proprietary API.The many available options include Stable Beluga (Stability AI, 2023a), Falcon (Almazrouei et al., 2023), T5 (Raffel et al., 2020), Pythia (Biderman et al., 2023), StableLM (Stability AI, 2023b), or LLaMA (Touvron, Lavril, et al., 2023) and LLaMA 2 (Touvron, Martin, et al., 2023), along with their fine-tuned variants.Nevertheless, OpenAI's LLMs stand out in terms of performance (X.Li et al., 2023;OpenAI, 2023;J. Yang et al., 2023), while still being relatively cost-efficient.Additionally, ChatGPT and GPT-4 are accessible via an API that is straightforward to use, requiring neither advanced machine learning skills nor significant local computing resources.</p>
<p>While the analysis could be conducted entirely using the more expensive GPT-4, we emphasize that costefficiency is crucial for flexibly analyzing large text corpora.At the time of our study, the pricing for GPT-3.5 completions was US$0.002 per 1,000 tokens.In contrast, GPT-4 completions (i.e., outputs) and prompts (i.e., inputs) were priced higher, at $0.03 and $0.06 per 1,000 tokens, respectively.In our experiments, the major cost contributor was the input prompt (including the source text).Utilizing GPT-4 for all requests would have increased the estimated cost significantly by an order of magnitude, to approximately US$512 (as compared to approximately US$50 for our study).This comparison underscores the cost-efficiency of our chosen approach.</p>
<p>LLMs -A Hammer for Every Nail?</p>
<p>While LLMs are capable in many real-world tasks, they are certainly not a catch-all solution for all kind of problems (Cong-Lem et al., 2024).However, we argue that much of the skepticism around LLMs arises from their misuse in various ways.The primary skepticism, perhaps, is that LLMs are "just" predicting next tokens, and we cannot trust them, given the noise and bias in their web-scraped training data (Sheng, Chang, Natarajan, &amp; Peng, 2021;van der Wal, Jumelet, Schulz, &amp; Zuidema, 2022;Zhao, Wang, Yatskar, Ordonez, &amp; Chang, 2017).User trust is a key element to fostering adoption of AI (Bach, Khan, Hallock, Beltrão, &amp; Sousa, 2024).Further, LLMs show sycophant tendency, that is, they aim to produce a user's preferred answer (which not necessarily is the best answer) (E.Perez et al., 2023;Sharma et al., 2023).By virtue of being models that predicts the next token, LLMs commit to whatever first draft they sampled.This first draft may not be the optimal choice, and may lead to "hallucination snowballing" (M.Zhang et al., 2023) where an LLM outputs false claims even though it could recognize that these claims are incorrect.Technical approaches, such as backtracking and backspacing (Cundy &amp; Ermon, 2023) and pause tokens (Goyal et al., 2023), were developed to mitigate and improve on this issue.For a first investigation on how well LLMs fare on mining insights from a text corpus, the application of such advanced methods are however not in the scope of our investigation and can left to future work.</p>
<p>We believe that at least hallucinations (Ji et al., 2023;M. Zhang et al., 2023) and sycophancy (E.Perez et al., 2023;Sharma et al., 2023) are not an issue in current state-of-the-art LLMs, if they are used correctly.</p>
<p>Correct usage, in our knowledge-intensive task of mining insights from text, consists of giving the model a context to work with (as opposed to giving the LLM just a question in the task of knowledge extraction).</p>
<p>Given this context, we found OpenAI's LLMs to be perfectly capable of answering questions on this context, without hallucinations.Further, "prompt engineering" can be used to simply instruct the LLM to state if an answer is not known (instead of hallucinating an answer).</p>
<p>However, a limiting factor of autoregressive language models is that they cannot come up with novel ideas or solutions.They are well capable of finding answers to a given question by drawing on their pretrained knowledge.But the result is limited by the extent of the training data.As for the application of LLMs in the context of deep qualitative analysis, a qualitative researcher may argue that depth requires time and investment in the process -"sleeping on the data" is in fact a common practice -that LLMs do not afford.Further, qualitative research is a process that enables the researcher to learn from the experience of conducting the research -an aspect that is lost by just handing over tasks to the LLM.This perspective suggests that the rapid processing capabilities of LLMs may not align with the traditional depth and temporal investment inherent in qualitative research.On the other hand, the researcher's personal learning journey is intrinsic, and tacit knowledge is difficult to share (Nonaka, 1994).LLMs, despite their internal opacity, facilitate the quick dissemination of research findings without necessitating an individual researcher's interpretative translation.Additionally, the potential for LLMs to yield less biased outcomes is an avenue worth exploring, though this requires further empirical investigation.</p>
<p>Implications for HCI</p>
<p>In the field of HCI, there exists a noticeable gap in large-scale investigations, a deficit rooted primarily in the constraints inherent in traditional qualitative research methods.Most investigations remain relatively small-scale, often involving only a handful of participants.This trend is not surprising, given the substantial costs and efforts associated with running studies that involve human subjects.Face-to-face research is not only expensive but also labor-intensive.Moreover, the qualitative approach central to these investigations, often grounded in the principles of grounded theory (Glaser &amp; Strauss, 1967), finds its limits not in the availability of data, but rather in the capacities of the human investigator.While grounded theory has been instrumental in facilitating in-depth studies, and there is undeniable merit to small-N investigations (Smith &amp; Little, 2018), the findings from small-scale studies often pose challenges when it comes to generalizing results to larger populations.Grounded theory, particular, has been criticized for being a poor fit for many contemporary studies in the field of HCI including increasing amounts of data (Deterding &amp; Waters, 2021).</p>
<p>Consequently, it is somewhat surprising that a greater number of researchers have not ventured to scale their research in the HCI field, a paradigm shift that could potentially broaden the scope and impact of their findings.</p>
<p>The advent of large language models introduces a new paradigm to HCI research that promises to revolutionize the scale and depth of qualitative analyses.LLMs are a game-changer in this domain, ushering in opportunities to greatly expand the scope of research initiatives by eliminating the bottleneck of tedious qualitative research.A case in point is the study conducted by Petridis et al. (2023), which underscores the potential of utilizing LLMs to analyze a single text document from a multitude of different perspectives and at the scale of a large conference proceedings corpus, thereby substantiating the validity of this novel approach.It would be tedious to conduct a qualitative analysis from many different perspectives, as 1)</p>
<p>the researcher conducting the analysis will always introduce bias, and 2) analyzing the material from each perspective would be expensive in terms of time required to complete the analysis.Leveraging the power of LLMs not only facilitates the examination of textual data from many different perspectives, but also extends the potential to conduct qualitative analyses beyond single text documents.</p>
<p>In our work, we adopted LLMs for this purpose, capitalizing on in-context learning (Brown et al., 2020;Lampinen et al., 2022) to foster cost-efficient mining of insights.This strategy, which we favor over statistical topic modeling techniques, enables us to scrutinize the textual data in alignment with specified objectivesin our case, the extraction of research challenges.Notably, the LLM allowed us to amplify the scale of data analysis to encompass the entire CHI 2023 proceedings, thereby alleviating the issues of human fatigue and the tedium associated with repetitive qualitative coding iterations, as demonstrated by the human annotator in our study.This approach has demonstrated the potential to substantially surpass previous qualitative methodologies in terms of both scale and depth, setting a new precedent in the HCI research domain.</p>
<p>Moving forward, we call on the community to explore new ways to incorporate large language models into their approaches.It is imperative that the HCI community recognizes and embraces the transformative potential of LLMs.Our findings strongly advocate for an incorporation of large language models into research methodologies.Further, we advocate for a systematic approach to prompt design, paving the way for an era where (automated) knowledge accumulation is not only streamlined but also considerably more expansive.This opens up avenues for studies that can foster a deeper understanding of user experiences and behaviors on a scale that was previously unimaginable.Moreover, this shift would not only catalyze a change in the scale of investigations but also potentially enhance the richness and nuance of insights derived.The ability to analyze substantial volumes of data through the lens of sophisticated algorithms can unearth patterns and trends that might otherwise remain elusive in smaller scale (small-N) investigations.It could potentially lead to the development of more robust theories and frameworks, grounded in a more comprehensive analysis of data.</p>
<p>As our work lives become more integrated with AI (Barbosa, da Silva Fernandes, Santos, &amp; Prates, 2024;H. Jo &amp; Park, 2023), the HCI community needs to engage in critical discussions surrounding the ethical implications of deploying LLMs in research (Sison, Daza, Gozalo-Brizuela, &amp; Garrido-Merchán, 2023) and education (Duong, Vu, Ngo, Do, &amp; Tran, 2024).Considering the vast capabilities of these models, it is paramount to approach their use with a nuanced understanding of the potential biases inherent in AI systems and the necessity for vigilant oversight to prevent misuse or misinterpretation of data.Further, as we venture into this new frontier, it becomes increasingly crucial to foster collaborations that bridge the gap between AI specialists and HCI researchers.This collaborative approach could facilitate the development of more sophisticated tools that are tailored to meet the specific needs and nuances of HCI research, promoting an interdisciplinary approach to knowledge creation and dissemination.</p>
<p>Limitations and Future Work</p>
<p>In this paper, we investigated the knowledge-intensive task of extracting research challenges from scholarly articles.We cannot make claims about the generalizability of our results to other possible tasks and other text corpora.However, we strongly believe that LLMs are useful for a wide range of insight mining tasks, for instance to facilitate qualitative analysis from different perspectives.LLMs have potential to reduce the cognitive work load involved in such demanding tasks (Frazier, McComb, Hass, &amp; Pitts, 2024).Future work could explore the application of this LLM-based insight mining approach to other academic conferences and journals, comparing the research challenges across different domains.</p>
<p>The main limitation of our approach is that it requires up-front knowledge about what questions can be answered from each document in the text corpus.In our case, we extracted research challenges, and it was clear that most, if not all, of the CHI papers would mention research challenges.If we had tried to discover factual statements that were not present in the papers, the LLMs would have had no choice but to hallucinate (He et al., 2022).However, this case could be covered with prompt engineering, and future work could explore prompt design to improve on this.</p>
<p>One limitation of using LLMs is their propensity for generating biased or irrelevant responses.Mitigation strategies include iterative prompt refinement and cross-validation with domain experts.Incorporating feedback mechanisms, such as expert validation of extracted challenges, could enhance the accuracy and relevance of LLM-generated insights.</p>
<p>In our experiments, we found the results are sensitive to the prompt.This highlights the importance of prompt design (or "prompt engineering") as a burgeoning area of research.Once a good prompt was found, however, results were fairly stable and reliable, with only few deviations (cf.Section 6.3.1).Besides prompt design, we believe consistency in querying the LLM API is key to getting reliable results.For some papers in the text corpus, we queried the API in smaller batches to avoid hitting ChatGPT's context window limit.Future work could investigate whether and how this batch size affects the consistency and reliability of outputs.</p>
<p>One last concern is that OpenAI's latest generation of LLMs are opaque models.It is known that language models may latently encode opinions (Jakesch, Bhat, Buschek, Zalmanson, &amp; Naaman, 2023) and cultural values (Johnson et al., 2022) in their outputs.Further, LLMs may reproduce stereotypes and biases (Bommasani et al., 2021;Brown et al., 2020).While we cannot rule out the presence of such bias in our data, our qualitative evaluation of a sample of the data did not find traces of bias.We invite the research community to scrutinize the research challenges, which are openly available for exploration and download.</p>
<p>Conclusion</p>
<p>In this paper, we presented an approach to leveraging LLMs on the real-world task of identifying the current key research challenges of the field of HCI using the 2023 CHI proceedings.This study not only maps out the current landscape of HCI research challenges but also demonstrates the transformative potential of LLMs in academic research, offering a new lens through which to view and analyze large text corpora.There is a lot of potential for this approach to allow researchers to better understand a given research community and to study how a research community's focus shifts over time.In particular, the approach proposed a two-step process which was shown to be efficient and cost-effective.</p>
<p>LLMs open exciting opportunities for leveraging new data sources and extracting insights from text at scale.Note, however, that our approach does not aim to replace qualitative analysis -we did analyze the research challenges using BERTopic, a method for qualitative and iterative exploration of topics identified from textual data.Rather, our approach aims to unlock the potential of data sources that previously were infeasible to analyze manually.</p>
<p>The landscape of LLMs is changing rapidly and since completing our study, fine-tuned variants of open source models are now also available via APIs at Cloud providers, such as Amazon Bedrock, Microsoft Azure, and Huggingface.Given the trend towards closed-source generative models, API-based research may become the norm (J.Yang et al., 2023).Such APIs may provide a flexible approach for analyzing data at scale, and LLM-based scientific discovery may become common ground.In this paper, we pursued this approach and applied LLMs for the practical task of analyzing a corpus of scholarly documents from a given perspective.More specifically, we discovered research challenges in the CHI 2023 proceedings.We iteratively designed prompts and critically evaluated the identified research challenges, finding that the complement of ChatGPT and GPT-4 makes an excellent means for qualitatively analyzing a text corpus from a given perspective.Because this process of insight mining from a text corpus could be repeated from many different perspectives, we specifically focused on the cost-efficiency of the approach.</p>
<p>There is a need for evaluating LLMs on practical tasks, such as ours, to educate researchers and industry practitioners on the true capabilities of LLMs.Underestimation of the true performance and capabilities of large language models hinders their adoption in research.We recommend researchers to apply our approach for deriving insights from textual data at scale.</p>
<p>A HCI Research Topics</p>
<p>Figure 1 :
1
Figure 1: Histogram of pages per research paper in the CHI 2023 proceedings.Blue: total number of pages per paper, including references and appendices.Orange: approximate number of content pages per paper.</p>
<p>Devlin, Chang, Lee, &amp; Toutanova, 2019), UMAP (McInnes et al., 2018) for dimensionality reduction, HDBSCAN (hierarchical densitybased spatial clustering of applications with noise) (McInnes, Healy, &amp; Astels, 2017) for clustering, and c-TF-IDF (class-based term frequency-inverse document frequency) (Grootendorst, 2020) -for creating topics.The topics generated by BERTopic are composed of bag of words.During initial experiments, we</p>
<p>Figure 2 :
2
Figure 2: Research challenges extracted from CHI 2023 proceedings using ChatGPT and GPT-4, with topic annotations by BERTtopic Grootendorst (2022).To create the plot, the challenges were first converted into embeddings and then projected into two-dimensional space with UMAP McInnes et al. (2018).Each filled circle represents a research challenge, with colors indicating different topic clusters identified by BERTopic.Gray, unfilled circles represent challenges that did not group into any of the identified clusters.An interactive visualization is available at https://hci-research-challenges.github.io.</p>
<p>Figure 3 :
3
Figure 3: Intertopic distance map with 21 research themes (T 1 -T 21 ).Each circle on the map represents a topic identified by BERTopic in the CHI 2023 proceedings.The size of the topics reflects the amount of research challenges associated with that topic.Topics that are close to each other can be considered to have similar content or themes, while topics far apart are more distinct or less related.Topics that are similar to each other are placed closer together, while dissimilar topics are farther apart.A topic cluster forms a research theme within HCI.We represent the research themes with selected salient keywords occurring in the topics that make up the theme.</p>
<p>Figure 4 :
4
Figure 4: Comparison of extracted research challenges with HCI's grand challenges and the UN's (modified) SDGs.</p>
<p>Figure 4
4
Figure 4 depicts the current research challenges of the HCI field in relation to the field's grand challenges and the UN's SDGs.We find the grand challenges are well-covered by the current research in the field of HCI.This is indicated by the grand challenges having at least one cluster of research challenges in their immediate vicinity.For instance, Stephanidis et al. (2019)'s grand challenge of 'privacy and security' is covered by the field's main research theme which also represents the largest cluster of research challenges.The identified research challenges underscore the importance of privacy, security, and accessibility in HCI practice, guiding</p>
<p>is a metric that quantifies the percentage of instances where two sets of data are identical in all aspects, often used to evaluate the accuracy of retrieved or computed results.In our case, a high EM score would indicate that the LLMs simply retrieved statements from the source text.A low EM score would indicate that the LLMs produced statements that are different from the source text.Going one step further, Edit Distance (ED) is a measure of the similarity between two strings, quantified as the minimum number of insertions, deletions, or substitutions required to transform one string into the other.Word Error Rate (WER) is a metric to assess the number of word-level errors made in a generated sequence, normalized by the length of the reference sequence.These metricsby comparing the extracted statements to statements in the source text -may give an indication to what extent the LLMs paraphrased in their outputs.</p>
<p>Figure 5 :
5
Figure 5: Cosine distances d between the embedded statements extracted by ChatGPT in Step 1 and the best-matching sentence embeddings from the source text.The distribution is long-tailed, with many statements being very similar to statements in the source text, and few not having a direct match.Note that not having a direct match does not mean the statement is not a valid research challenge, since ChatGPT may have paraphrased or summarized the source text.</p>
<p>Table 1 :
1
Random sample of research challenges.</p>
<p>Table 4
4T1 Gestures, eye/gaze trackingT2 Voice assistants, speech recognitionT3 Visualization, storytellingT4 Conversational AI, chatbotsT5 Writing, nlp, language modelsT6 Notifications, fitness tracking, emotionsT7 Recommendations, decision-makingT8 Human-AI collaboration, XAI and transparency, trustT9 HCI research, learning analytics, remote work, conflictsT10 VR/AR/mixed reality, remote workT11 Games, interaction, engagement, ritualsT12 Misinformation, social mediaT13 Data science, scalable datasets, health dataT14 Haptic/tactile feedback, sensing, stimulationT15 Privacy and security, consentT16 Ethics, algorithmic fairness, biasesT17 Digital literacy, family and parentingT18 Wearables, textiles, fabricationT19 Blind/visually impaired, older adults, DHHT20 Marginalized communities, LGBTQ, social normsT21 Health, well-being
in Appendix A), as expected.The most frequently occurring research challenges center around 'privacy and security' (n = 174), virtual reality (n = 139), interaction (n = 107), marginalized communities (n = 106) and improving accuracy (e.g., improving object detection; n = 103).Overall, the research challenges paint a picture of a mix between more traditional HCI research topics (interaction, gestures, accessibility, colors, cognitive biases, UX design, and user interfaces) and novel areas, such as human-AI collaboration, LLM-assisted writing, AI agents, chatbots, and virtual/augmented reality that have only recently gained more popularity.This reflects the strong influence that these highly trending topics have had on the field of HCI (and academia in general).The intertopic distance map depicted in Figure3provides another view on the current research topics in HCI.This map offers a graphical representation of the BERTopic topic model and allows us to understand the relationship between current research topics in the field of HCI.With this map, we can identify at least 4 21 main research themes (T 1 -T 21 ) in the field of HCI.Overall, however, we can note that among HCI's main research themes, there are no strong outliers, and research themes are generally well-connected.In particular, 'privacy and security' (T 15 ) is inter-meshed with several themes, such as 'misinformation, social media' (T 12 ), 'data science, . ..health data' (T 13 ).This research theme is also closely related to themes such as 'Human-AI collaboration, XAI, transparency and trust' (T 8 ).Similarly, the research themes of 'VR/AR/mixed reality. . .' (T 10 ) and 'haptic/tactile feedback. . .' (T 14 ) provide natural synergies to each other.Interestingly, 'gestures, eye/gaze tracking' (T 1 ) and 'health, well-being' (T 21 ) stand to have the longest distance from each other.Similarly, 'haptic feedback, sensing, stimulation' (T 14 ) and 'ethics. . .' (T 16 ) are not well connected research themes, and 'conversational AI. . .' (T 4 ) and 'blind/visually impaired. . .' (T 19 ) are themes that show not much overlap in terms of research challenges.This is an interesting contrast and may provide an indication of future</p>
<p>End hunger, achieve food security and improved nutrition and promote agriculture 3: Ensure healthy lives and promote well-being for all at all ages 4: Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all 5: Achieve gender equality and empower all women and girls 6: Ensure availability and management of water and sanitation for all 7: Ensure access to affordable, reliable and modern energy for all 8: Promote inclusive and economic growth, full and productive employment and decent work for all 9: Build resilient infrastructure, promote inclusive and industrialization and foster innovation 10: Reduce inequality within and among countries 11: Make cities and human settlements inclusive, safe and resilient 12: Ensure consumption and production patterns 13: Take urgent action to combat climate change and its impacts 14: Conserve the oceans, seas and marine resources 15: Protect and restore terrestrial ecosystems, manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss 16: Promote peaceful and inclusive societies, provide access to justice for all and build effective, accountable and inclusive institutions at all levels 17: Strengthen the means of implementation and revitalize the global partnership
Grand challenges by Stephanidis et al. (2019) a: Human-technology symbiosis b: Human-environment interactions c: Ethics d: Privacy e: Security f: Well-being, health and eudaimonia g: Accessibility and universal access h: Learning i: Creativity j: Social organization and democracy Grand challenges by Shneiderman et al. (2016) 1: Develop a handbook of human needs 2: Shift from user experience to community experience 3: Refine theories of persuasion 4: Encourage resource conservation. 5: Shape the learning health system. 6: Advance the design of medical devices 7: Support successful aging strategies 8: Promote lifelong learning 9: Stimulate rapid interface learning 10: Engineer new business models 11: Design novel input and output devices 12: Accelerate analytic clarity 13: Amplify empathy, compassion, and caring 14: Secure cyberspace 15: Encourage reflection, calmness, and mindfulness 16: Clarify responsibility and accountability UN Sustainable Development Goals (2015) 1: End poverty in all its forms everywhere 2: Clustered Research Challenges Unclustered Research Challenges UN Sustainable Development Goals (2015) Grand Challenges by Shneiderman et al. (2016) Grand Challenges by Stephanidis et al. (2019)</p>
<p>Table 2 :
2
Insight mining performance, as evaluated by canonical metrics from the field of NLP.Best-matching statements between GPT-4 and ChatGPT statements.
EMEDWERBLEUROUGE-1Step 1  †0.087856.82130.970348.530.6822Step 2  ‡0.45712.02600.059135.700.9713BLANC BERTScore METEOR BLEURT-20ROUGE-LStep 1  †0.43450.93610.60580.67550.6554Step 2  ‡0.68400.96290.98120.94590.9712† Best-matching statements between ChatGPT statements and source sentences.
‡</p>
<p>Table 4 :
4
Manually-labeled research topic clusters with the number of respective research challenges.
Topic#Topic#Topic#
See https://HCI-research-challenges.github.io and https://osf.io/fbsq7/?view only=b6b86e89fe444a74a33950b452a55242
https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature
Visualization: https://hci-research-challenges.github.io Dataset: https://osf.io/fbsq7/?view only=b6b86e89 fe444a74a33950b452a55242
The number of the themes is influenced by BERTopic's hyperparameters. Further, the intertopic distance map was created from topics with at least 10 research challenges. Therefore, the number of research themes identified in our work should not be interpreted as an absolute number of research themes in HCI.</p>
<p>Falcon-40B: An open large language model with state-of-the-art performance. E Almazrouei, H Alobeidli, A Alshamsi, A Cappelli, R Cojocaru, M Debbah, . . Penedo, G , 2023</p>
<p>A systematic literature review of user trust in ai-enabled systems: An hci perspective. T A Bach, A Khan, H Hallock, G Beltrão, S Sousa, 10.1080/10447318.2022.2138826International Journal of Human-Computer Interaction. 4052024</p>
<p>METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. S Banerjee, A Lavie, Proceedings of the ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. the ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarizationAnn Arbor, MichiganAssociation for Computational Linguistics2005. June</p>
<p>Open information extraction from the web. M Banko, M J Cafarella, S Soderland, M Broadhead, O Etzioni, Proceedings of the 20th international joint conference on artifical intelligence. the 20th international joint conference on artifical intelligenceSan Francisco, CA, USAMorgan Kaufmann Publishers Inc2007</p>
<p>Human-computer integration as an extension of interaction: Understanding its state-of-the-art and the next challenges. G A R Barbosa, U Da Silva Fernandes, N S Santos, R O Prates, 10.1080/10447318.2023.2177797International Journal of Human-Computer Interaction. 40112024</p>
<p>On the dangers of stochastic parrots: Can language models be too big?. E M Bender, T Gebru, A Mcmillan-Major, S Shmitchell, 10.1145/3442188.3445922Proceedings of the 2021 acm conference on fairness, accountability, and transparency. the 2021 acm conference on fairness, accountability, and transparencyNew York, NY, USAAssociation for Computing Machinery2021</p>
<p>Pythia: A suite for analyzing large language models across training and scaling. S Biderman, H Schoelkopf, Q Anthony, H Bradley, K O'brien, E Hallahan, . . Van Der Wal, 2023</p>
<p>On the opportunities and risks of foundation models. R Bommasani, D A Hudson, E Adeli, R Altman, S Arora, S Von Arx, . . Liang, P , ArXiv. 2021</p>
<p>Using thematic analysis in psychology. V Braun, V Clarke, 10.1191/1478088706qp063oaPsychology. 322006</p>
<p>Reflecting on reflexive thematic analysis. V Braun, V Clarke, 10.1080/2159676X.2019.1628806Qualitative Research in Sport, Exercise and Health. 1142019</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, . . Amodei, D , Advances in neural information processing systems. H Larochelle, M Ranzato, R Hadsell, M Balcan, H Lin, Curran Associates, Inc202033</p>
<p>Principled instructions are all you need for questioning LLaMA-1/2. S M Bsharat, A Myrzakhan, Z Shen, 2023</p>
<p>S Bubeck, V Chandrasekaran, R Eldan, J Gehrke, E Horvitz, E Kamar, . . Zhang, Y , 10.48550/arXiv.2303.12712Sparks of artificial general intelligence: Early experiments with GPT-4. 2023</p>
<p>Tomayto, tomahto. beyond token-level answer equivalence for question answering evaluation. J Bulian, C Buck, W Gajewski, B Börschinger, T Schuster, 10.18653/v1/2022.emnlp-main.20Proceedings of the 2022 conference on empirical methods in natural language processing. the 2022 conference on empirical methods in natural language processingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022, December</p>
<p>Extracting training data from large language models. N Carlini, F Tramèr, E Wallace, M Jagielski, A Herbert-Voss, K Lee, . . Raffel, C , Proceedings of the 30th USENIX security symposium. the 30th USENIX security symposium2021USENIX Association</p>
<p>Deep reinforcement learning from human preferences. P F Christiano, J Leike, T Brown, M Martic, S Legg, D Amodei, Advances in neural information processing systems. I Guyon, Curran Associates, Inc201730</p>
<p>Understanding UMAP. A Coenen, A Pearce, </p>
<p>A coefficient of agreement for nominal scales. J Cohen, 10.1177/001316446002000104Educational and Psychological Measurement. 2011960</p>
<p>LLM parameters demystified: Getting the best outputs from language AI. 2022</p>
<p>A systematic review of the limitations and associated opportunities of chatgpt. N Cong-Lem, A Soyoof, D Tsering, 10.1080/10447318.2024.2344142International Journal of Human-Computer Interaction. 002024</p>
<p>Faithful reasoning using large language models. A Creswell, M Shanahan, 10.48550/arXiv.2208.142712022</p>
<p>Sequencematch: Imitation learning for autoregressive sequence modelling with backtracking. C Cundy, S Ermon, 2023</p>
<p>Why can GPT learn in-context? language models implicitly perform gradient descent as meta-optimizers. D Dai, Y Sun, L Dong, Y Hao, S Ma, Z Sui, F Wei, 10.48550/arXiv.2212.105592023</p>
<p>Clausie: Clause-based open information extraction. L Del Corro, R Gemulla, 10.1145/2488388.2488420Proceedings of the 22nd international conference on world wide web. the 22nd international conference on world wide webNew York, NY, USAAssociation for Computing Machinery2013</p>
<p>Can generative ai bots be trusted?. P J Denning, 10.1145/3592981Commun. ACM. 6662023a, may</p>
<p>The smallness of large language models. P J Denning, 10.1145/3608966Commun. ACM. 6692023b, aug</p>
<p>Flexible coding of in-depth interviews: A twenty-first-century approach. N M Deterding, M C Waters, 10.1177/0049124118799377Sociological Methods &amp; Research. 5022021</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 conference of the north American chapter of the association for computational linguistics: Human language technologies. the 2019 conference of the north American chapter of the association for computational linguistics: Human language technologiesMinneapolis, MinnesotaAssociation for Computational Linguistics2019. June1</p>
<p>Value-laden disciplinary shifts in machine learning. R Dotan, S Milli, 10.1145/3351095.3373157Proceedings of the 2020 conference on fairness, accountability, and transparency. the 2020 conference on fairness, accountability, and transparencyNew York, NY, USAAssociation for Computing Machinery2020294</p>
<p>Viewpoint diversity in search results. T Draws, N Roy, O Inel, A Rieger, R Hada, M O Yalcin, . . Tintarev, N , Advances in information retrieval. J Kamps, Cham; Nature SwitzerlandSpringer2023</p>
<p>Alpacafarm: A simulation framework for methods that learn from human feedback. Y Dubois, X Li, R Taori, T Zhang, I Gulrajani, J Ba, . . Hashimoto, T B , 2023</p>
<p>Reduced student life satisfaction and academic performance: Unraveling the dark side of chatgpt in the higher education context. C D Duong, T N Vu, T V N Ngo, N D Do, N M Tran, 10.1080/10447318.2024.2356361International Journal of Human-Computer Interaction. 002024</p>
<p>Thus spake ChatGPT. S Dutta, T Chakraborty, 10.1145/3616863Commun. ACM. 66122023</p>
<p>The KDD process for extracting useful knowledge from volumes of data. U Fayyad, G Piatetsky-Shapiro, P Smyth, 10.1145/240455.240464Commun. ACM. 39111996, nov</p>
<p>The moderating effects of task complexity and age on the relationship between automation use and cognitive workload. S Frazier, S A Mccomb, Z Hass, B J Pitts, 10.1080/10447318.2022.2151773International Journal of Human-Computer Interaction. 4072024</p>
<p>Collabcoder: A GPT-powered workflow for collaborative qualitative analysis. J Gao, Y Guo, G Lim, T Zhang, Z Zhang, T J Li, .-J Perrault, S T , 10.48550/arXiv.2304.073662023</p>
<p>Felt ethics: Cultivating ethical sensibility in design practice. R Garrett, K Popova, C Núñez Pacheco, T Asgeirsdottir, A Lampinen, K Höök, 10.1145/3544548.3580875Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>How HCI bridges health and design in online health communities: A systematic review. D Gatos, A Günay, G Kırlangıç, K Kuscu, A E Yantac, 10.1145/3461778.3462100Proceedings of the 2021 acm designing interactive systems conference. the 2021 acm designing interactive systems conferenceNew York, NY, USAAssociation for Computing Machinery2021</p>
<p>The discovery of grounded theory: Strategies for qualitative research. B G Glaser, A L Strauss, 1967Aldine de GruyterNew York, NY</p>
<p>Think before you speak: Training language models with pause tokens. S Goyal, Z Ji, A S Rawat, A K Menon, S Kumar, V Nagarajan, 2023</p>
<p>c-TF-IDF. M Grootendorst, 2020</p>
<p>BERTopic: Neural topic modeling with a class-based TF-IDF procedure. M Grootendorst, 2022</p>
<p>Abstractive summarization: An overview of the state of the art. S Gupta, S K Gupta, 10.1016/j.eswa.2018.12.011Expert Systems with Applications. 1212019</p>
<p>Marking material interactions with computer vision. P Gyory, S S Bae, R Yang, E Y Do, .-L Zheng, C , 10.1145/3544548.3580643Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Evaluating large language models in generating synthetic HCI research data: A case study. P Hämäläinen, M Tavast, A Kunnari, 10.1145/3544548.3580688Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Rethinking with retrieval: Faithful large language model inference. H He, H Zhang, D Roth, 10.48550/arXiv.2301.003032022</p>
<p>Less is not more: Improving findability and actionability of privacy controls for online behavioral advertising. J Im, R Wang, W Lyu, N Cook, H Habib, L F Cranor, . . Schaub, F , 10.1145/3544548.3580773Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Co-writing with opinionated language models affects users' views. M Jakesch, A Bhat, D Buschek, L Zalmanson, M Naaman, 10.1145/3544548.3581196Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Survey of hallucination in natural language generation. Z Ji, N Lee, R Frieske, T Yu, D Su, Y Xu, . . Fung, P , 10.1145/3571730ACM Comput. Surv. 12552023, mar</p>
<p>Understanding the benefits and challenges of deploying conversational ai leveraging large language models for public health intervention. E Jo, D A Epstein, H Jung, Y.-H Kim, 10.1145/3544548.3581503Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Ai in the workplace: Examining the effects of chatgpt on information support and knowledge acquisition. H Jo, D.-H Park, 10.1080/10447318.2023.2278283International Journal of Human-Computer Interaction. 002023</p>
<p>The ghost in the machine has an american accent: value conflict in GPT-3. R L Johnson, G Pistilli, N Menédez-González, L D D Duran, E Panai, J Kalpokiene, D J Bertulfo, 10.48550/arXiv.2203.077852022</p>
<p>Autospeculation: Reflecting on the intimate and imaginative capacities of data analysis. B Kinnee, A Desjardins, D Rosner, 10.1145/3544548.3580902Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Reduced, reused and recycled: The life of a dataset in machine learning research. B Koch, E Denton, A Hanna, J G Foster, Thirty-fifth conference on neural information processing systems datasets and benchmarks track. 2021round 2</p>
<p>Large language models are zeroshot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Icml 2022 workshop on knowledge retrieval and language models. 2022</p>
<p>Can pretrained language models generate persuasive, faithful, and informative ad text for product descriptions?. F Koto, J H Lau, T Baldwin, 10.18653/v1/2022.ecnlp-1.27Proceedings of the fifth workshop on ecommerce and nlp. the fifth workshop on ecommerce and nlpDublin, IrelandAssociation for Computational Linguistics2022. May</p>
<p>Can language models learn from explanations in context?. A Lampinen, I Dasgupta, S Chan, K Mathewson, M Tessler, A Creswell, . . Hill, F , 2022Association for Computational LinguisticsDecember; Abu Dhabi, United Arab EmiratesIn Findings of the association for computational linguistics</p>
<p>Evaluating ChatGPT's information extraction capabilities: An assessment of performance, explainability, calibration, and faithfulness. B Li, G Fang, Y Yang, Q Wang, W Ye, W Zhao, S Zhang, 10.48550/arXiv.2304.116332023</p>
<p>AlpacaEval: An automatic evaluator of instruction-following models. X Li, T Zhang, Y Dubois, R Taori, I Gulrajani, C Guestrin, . . Hashimoto, T B , 2023</p>
<p>ROUGE: A package for automatic evaluation of summaries. C.-Y Lin, Text summarization branches out. Barcelona, SpainAssociation for Computational Linguistics2004, July</p>
<p>Decoding prompt syntax: Analysing its impact on knowledge retrieval in large language models. S Linzbach, T Tressel, L Kallmeyer, S Dietze, H Jabeen, 10.1145/3543873.3587655Companion proceedings of the acm web conference 2023. New York, NY, USAAssociation for Computing Machinery2023</p>
<p>Chi 1994-2013: Mapping two decades of intellectual progress through co-word analysis. Y Liu, J Goncalves, D Ferreira, B Xiao, S Hosio, V Kostakos, 10.1145/2556288.2556969Proceedings of the sigchi conference on human factors in computing systems. the sigchi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2014</p>
<p>Reference-free summarization evaluation via semantic correlation and compression ratio. Y Liu, Q Jia, K Zhu, 10.18653/v1/2022.naacl-main.153Proceedings of the 2022 conference of the north american chapter of the association for computational linguistics: Human language technologies. the 2022 conference of the north american chapter of the association for computational linguistics: Human language technologiesSeattle, United StatesAssociation for Computational Linguistics2022, July</p>
<p>Can ChatGPT forecast stock price movements? return predictability and large language models. Return Predictability and Large Language Models. A Lopez-Lira, Y Tang, 2023. Apr 6</p>
<p>Open information extraction systems and downstream applications. Mausam, Proceedings of the twenty-fifth international joint conference on artificial intelligence. the twenty-fifth international joint conference on artificial intelligenceAAAI Press2016</p>
<p>Open language learning for information extraction. Mausam, M Schmitz, S Soderland, R Bart, O Etzioni, Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. the 2012 joint conference on empirical methods in natural language processing and computational natural language learningJeju Island, KoreaAssociation for Computational Linguistics2012, July</p>
<p>On faithfulness and factuality in abstractive summarization. J Maynez, S Narayan, B Bohnet, R Mcdonald, 10.18653/v1/2020.acl-main.173Proceedings of the 58th annual meeting of the association for computational linguistics. the 58th annual meeting of the association for computational linguisticsAssociation for Computational Linguistics2020, July</p>
<p>Reliability and inter-rater reliability in qualitative research: Norms and guidelines for cscw and HCI practice. N Mcdonald, S Schoenebeck, A Forte, 10.1145/3359174Proc. ACM Hum.-Comput. Interact. 32019, novCSCW</p>
<p>HDBSCAN: Hierarchical density based clustering. L Mcinnes, J Healy, S Astels, J. Open Source Softw. 2112052017</p>
<p>Umap: Uniform manifold approximation and projection. L Mcinnes, J Healy, N Saul, L Großberger, 10.21105/joss.00861Journal of Open Source Software. 3298612018</p>
<p>. Y Nakajima, 2023</p>
<p>A dynamic theory of organizational knowledge creation. I Nonaka, Organization Science. 5172198591994</p>
<p>. C Olsson, N Elhage, N Nanda, N Joseph, N Dassarma, T Henighan, . . Olah, C , 10.48550/arXiv.2209.118952022In-context learning and induction heads</p>
<p>Text completion. Openai, </p>
<p>Introducing ChatGPT. Openai, 10.48550/arXiv.2303.08774GPT-4 technical report. 2022. 2023</p>
<p>The creativity of text-to-image generation. J Oppenlaender, 10.1145/3569219.356935225th international academic mindtrek conference. New York, NY, USAAssociation for Computing Machinery2022</p>
<p>A taxonomy of prompt modifiers for text-to-image generation. J Oppenlaender, 10.1080/0144929X.2023.2286532Behaviour &amp; Information Technology. 2023</p>
<p>Design recommendations for augmenting creative tasks with computational priming. J Oppenlaender, S Hosio, 10.1145/3365610.3365621Proceedings of the 18th international conference on mobile and ubiquitous multimedia. the 18th international conference on mobile and ubiquitous multimediaNew York, NY, USAACM2019</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, . . Lowe, R , Advances in neural information processing systems. A H Oh, A Agarwal, D Belgrave, K Cho, MIT Press2022</p>
<p>Bleu: A method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W.-J Zhu, 10.3115/1073083.1073135Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsUSAAssociation for Computational Linguistics2002</p>
<p>J S Park, J C O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, Generative agents: Interactive simulacra of human behavior. 2023</p>
<p>Data and its (dis)contents: A survey of dataset development and use in machine learning research. A Paullada, I D Raji, E M Bender, E Denton, A Hanna, 10.1016/j.patter.2021.100336Patterns. 2111003362021</p>
<p>Discovering language model behaviors with model-written evaluations. E Perez, S Ringer, K Lukosiute, K Nguyen, E Chen, S Heiner, . . Kaplan, J , 10.18653/v1/2023.findings-acl.847Findings of the association for computational linguistics: Acl 2023. A Rogers, J Boyd-Graber, &amp; N Okazaki, Toronto, CanadaAssociation for Computational Linguistics2023, July</p>
<p>Ignore previous prompt: Attack techniques for language models. F Perez, I Ribeiro, 2022</p>
<p>Anglekindling: Supporting journalistic angle ideation with large language models. S Petridis, N Diakopoulos, K Crowston, M Hansen, K Henderson, S Jastrzebski, . . Chilton, L B , 10.1145/3544548.3580907Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Is ChatGPT a general-purpose natural language processing task solver?. C Qin, A Zhang, Z Zhang, J Chen, M Yasunaga, D Yang, 10.48550/arXiv.2302.064762023</p>
<p>Learning transferable visual models from natural language supervision. A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, . . Sutskever, I , Proceedings of the 38th international conference on machine learning, ICML 2021. M Meila, T Zhang, the 38th international conference on machine learning, ICML 2021PMLR2021. 18-24 july 2021139virtual event</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, . . Liu, P J , J. Mach. Learn. Res. 2112020, jan</p>
<p>C Rastogi, M T Ribeiro, N King, S Amershi, Supporting human-AI collaboration in auditing LLMs with LLMs. 2023</p>
<p>Sentence-BERT: Sentence embeddings using Siamese BERT-networks. N Reimers, I Gurevych, 10.18653/v1/D19-1410Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing. the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processingHong Kong, ChinaAssociation for Computational Linguistics2019</p>
<p>Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous. T B Richards, 2023</p>
<p>In-context impersonation reveals large language models' strengths and biases. L Salewski, S Alaniz, I Rio-Torto, E Schulz, Z Akata, 10.48550/arXiv.2305.149302023</p>
<p>M Sharma, M Tong, T Korbak, D Duvenaud, A Askell, S R Bowman, . . Perez, E , Towards understanding sycophancy in language models. 2023</p>
<p>Societal biases in language generation: Progress and challenges. E Sheng, K.-W Chang, P Natarajan, N Peng, 10.18653/v1/2021.acl-long.330Proceedings of the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processing. C Zong, F Xia, W Li, &amp; R Navigli, the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processingAssociation for Computational Linguistics2021. August1Long papers</p>
<p>Best practices for prompt engineering with OpenAI API. Ope-nAI. J Shieh, 2023</p>
<p>Grand challenges for HCI researchers. B Shneiderman, C Plaisant, M Cohen, S Jacobs, N Elmqvist, N Diakopoulos, 10.1145/2977645Interactions. 2352016, aug</p>
<p>Prompting GPT-3 to be reliable. C Si, Z Gan, Z Yang, S Wang, J Wang, J L Boyd-Graber, L Wang, The 11th international conference on learning representations. 2023. May</p>
<p>Chatgpt: More than a "weapon of mass deception"' ethical challenges and responses from the human-centered artificial intelligence (hcai) perspective. A J G Sison, M T Daza, R Gozalo-Brizuela, E C Garrido-Merchán, 10.1080/10447318.2023.2225931International Journal of Human-Computer Interaction. 002023</p>
<p>Small is beautiful: In defense of the small-n design. P L Smith, D R Little, 10.3758/s13423-018-1451-8Psychonomic Bulletin &amp; Review. 252018</p>
<p>Deeplens: Interactive out-of-distribution data detection in nlp models. D Song, Z Wang, Y Huang, L Ma, T Zhang, 10.1145/3544548.3580741Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Meet Stable Beluga 1 and Stable Beluga 2, our large and mighty instruction fine-tuned language models. A I Stability, 2023a</p>
<p>StableLM: Stability AI language models. A I Stability, 2023b</p>
<p>Literature reviews in HCI: A review of reviews. E Stefanidi, M Bentvelzen, P W Woźniak, T Kosch, M P Woźniak, T Mildner, . . Niess, J , 10.1145/3544548.3581332Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Seven HCI grand challenges. C Stephanidis, G Salvendy, M Antona, J Y C Chen, J Dong, V G Duffy, . . Zhou, J , 10.1080/10447318.2019.1619259International Journal of Human-Computer Interaction. 35142019</p>
<p>Kaleidoscope: Semantically-grounded, context-specific ml model evaluation. H Suresh, D Shanmugam, T Chen, A G Bryan, A D'amour, J Guttag, A Satyanarayan, 10.1145/3544548.3581482Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Embodying physics-aware avatars in virtual reality. Y Tao, C Y Wang, A D Wilson, E Ofek, M Gonzalez-Franco, 10.1145/3544548.3580979Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Reliance on metrics is a fundamental challenge for AI. R L Thomas, D Uminsky, 10.1016/j.patter.2022.10047620223</p>
<p>LLMOps: Deployment and learning in production. J Tobin, 2023</p>
<p>Llama: Open and efficient foundation language models. H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, . . Lample, G , 10.48550/arXiv.2302.139712023</p>
<p>Llama 2: Open foundation and fine-tuned chat models. H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, . . Scialom, T , 2023</p>
<p>Transforming our world: the 2030 agenda for sustainable development. 2015United Nations General Assembly</p>
<p>Visualizing data using t-SNE. L Van Der Maaten, G Hinton, Journal of Machine Learning Research. 92008</p>
<p>Altair: Interactive statistical visualizations for Python. J Vanderplas, B Granger, J Heer, D Moritz, K Wongsuphasawat, A Satyanarayan, . . Sievert, S , 10.21105/joss.01057Journal of Open Source Software. 33210572018</p>
<p>The birth of bias: A case study on the evolution of gender bias in an english language model. O Van Der Wal, J Jumelet, K Schulz, W H Zuidema, 10.48550/arXiv.2207.102452022</p>
<p>A polyvocal and contextualised semantic web. M Van Erp, V De Boer, The semantic web: 18th international conference, eswc 2021, virtual event. 2021. june 6-10, 2021</p>
<p>. Heidelberg Berlin, 10.1007/978-3-030-77385-430Springer</p>
<p>Fill in the BLANC: Human-free quality estimation of document summaries. O Vasilyev, V Dharnidharka, J Bohannon, 10.18653/v1/2020.eval4nlp-1.2Proceedings of the first workshop on evaluation and comparison of nlp systems. the first workshop on evaluation and comparison of nlp systemsAssociation for Computational Linguistics2020, November</p>
<p>S Vemprala, R Bonatti, A Bucker, A Kapoor, No. MSR-TR-2023-8ChatGPT for robotics: Design principles and model abilities. Microsoft2023. FebruaryTech. Rep.</p>
<p>The trec-8 question answering track report. The TREC-8 Question Answering Track Report. E Voorhees, 2000, 2000-12-11</p>
<p>Humanoid agents: Platform for simulating human-like generative agents. Z Wang, Y Y Chiu, Y C Chiu, Proceedings of the 2023 conference on empirical methods in natural language processing. the 2023 conference on empirical methods in natural language processing2023</p>
<p>Finetuned language models are zero-shot learners. J Wei, M Bosma, V Zhao, K Guu, A W Yu, B Lester, . . Le, Q V , International conference on learning representations. 2022</p>
<p>. J White, Q Fu, S Hays, M Sandborn, C Olea, H Gilbert, . . Schmidt, D C , 2023A prompt pattern catalog to enhance prompt engineering with ChatGPT</p>
<p>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding. Z Xiao, X Yuan, Q V Liao, R Abdelghani, P.-Y Oudeyer, 10.1145/3581754.3584136Companion proceedings of the 28th international conference on intelligent user interfaces. New York, NY, USAAssociation for Computing Machinery2023</p>
<p>Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond. J Yang, H Jin, R Tang, X Han, Q Feng, H Jiang, . . Hu, X , 2023</p>
<p>Harnessing biomedical literature to calibrate clinicians' trust in AI decision support systems. Q Yang, Y Hao, K Quan, S Yang, Y Zhao, V Kuleshov, F Wang, 10.1145/3544548.3581393Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Z Yang, L Li, K Lin, J Wang, C.-C Lin, Z Liu, L Wang, The dawn of LMMs: Preliminary explorations with GPT-4V(ision). 2023</p>
<p>How language model hallucinations can snowball. M Zhang, O Press, W Merrill, A Liu, N A Smith, 10.48550/arXiv.2305.135342023</p>
<p>BERTScore: Evaluating text generation with BERT. T Zhang, V Kishore, F Wu, K Q Weinberger, Y Artzi, International conference on learning representations. 2020</p>
<p>ConceptEVA: Concept-based interactive exploration and customization of document summaries. X Zhang, J Li, P.-W Chi, S Chandrasegaran, K.-L Ma, 10.1145/3544548.3581260Proceedings of the 2023 chi conference on human factors in computing systems. the 2023 chi conference on human factors in computing systemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Men also like shopping: Reducing gender bias amplification using corpus-level constraints. J Zhao, T Wang, M Yatskar, V Ordonez, K.-W Chang, 10.18653/v1/D17-1323Proceedings of the 2017 conference on empirical methods in natural language processing. M Palmer, R Hwa, &amp; S Riedel, the 2017 conference on empirical methods in natural language processingCopenhagen, DenmarkAssociation for Computational Linguistics2017, September</p>
<p>Privacy and security 174 39. AI agents 28 77. 16</p>
<p>Virtual reality 139 40. Deceptive design 28 78. Body monitoring. 16</p>
<p>Self-driving cars 28 79. Phone usage and stress 15. Interaction. 10741</p>
<p>Marginalized communities 106 42. UX design collaboration 28 80. 15Transparency in algorithms</p>
<p>Target detection accuracy 103 43. Chatbots and mental health 26 81. User preferences and motivations 15. </p>
<p>Haptic feedback 95 44. Learning and group awareness 26 82. Recommendation and decisionmaking 15. </p>
<p>Accessibility for disabilities 77 45. Cognitive processes. Conversations. 2683</p>
<p>Blind and visually impaired 70 46. Scalable datasets and labeling 26 84. 14</p>
<p>Smart homes/IoT 67 47. Fitness tracking 25 85. Wearables and bodily practices 14 10. AR and drones 61 48. Mental wellbeing 25 86. Learning analytics 13 11. Crowdsourcing. 5787Gestures</p>
<p>Emotion recognition 51 50. Food and food delivery 24 88. Telemedicine 13 13. Trust and moderation in social media 47 51. Fairness in AI 24 89. Annotations 13</p>
<p>Natural language interfaces and editing 24 90. Cognitive biases 13 15. Human-AI collaboration 46 52HCI research. 4591Misleading visualizations 13</p>
<p>Environment and eco feedback 45 54. Older adults and care 23 92. Rituals and religion 13. </p>
<p>Text entry and keyboards 21 96. Frame rates and players 12 21. Hybrid and gig work 37 59. Captioning and accessibility for DHH 21 97. Browsing and clutter 11 22. Social media 36 60. Mixed reality and music 21 98. Waste management. 122011Sensing and stimulation 22 93. Colors xx 18. LGBTQ and sexual consent 40 56. Software development and coding 22 94. Prototyping and wearables 12 19. Trust in AI 40 57. Communities and sports 22 95</p>
<p>Remote meetings and gameplay 35 61. Trauma and violence 21 99. 11</p>
<p>Speech recognition 35 62. Mental health and stigma 20 100. Digital literacy. 11</p>
<p>Writing assistants 35 63. Social norms 20 101. Aesthetics and style 11. </p>
<p>Creativity support tools 20 102. Shape-changing user interfaces 11 27. 3D printing 35 65. Social VR moderation 20 103. Shape-changing control. 11Human-robot interaction 35 64</p>
<p>Fabrication and electronics 34 66. Mental models 19 104. 10</p>
<p>Engagement and relationships 33 67. Location-based games and hybrid spaces 18 105. 10</p>
<p>Immersive analytics and embodied visualization 18 106. Data science 10 31. Health data 32 69. Stories and storytelling 18 107. Saliency maps. 10</p>
<p>Ethics and ethical guidelines 32 70. Site-specific AR storytelling 10. 17108</p>
<p>Parents and family 32 71. Autism and assistive dating 17 109. health interventions 10</p>
<p>Notebooks and sensemaking 31 72. Debugging and diagnosing 17 110. AI design ideation10</p>
<p>Games and gamification 30 73. Conflict management. 1710</p>
<p>Avatars and embodiment 30 74. Ethical AI. 1710</p>
<p>Predictive notifications 16 113. Visualization. 1016Robustness. Textile interfaces</p>            </div>
        </div>

    </div>
</body>
</html>