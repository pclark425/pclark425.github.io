<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6400 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6400</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6400</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-126.html">extraction-schema-126</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <p><strong>Paper ID:</strong> paper-273507409</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.16930v3.pdf" target="_blank">Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes</a></p>
                <p><strong>Paper Abstract:</strong> Math reasoning is an active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence and has implications in several domains, including math education. However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill that can be isolated within models. Doing so could allow targeted intervention to improve math performance without altering non-math behavior and foster understanding of how models encode math reasoning. We introduce Math Neurosurgery ( MathNeuro ), a computationally efficient method we use to isolate math-specific parameters in LLMs us-ing only forward passes. MathNeuro builds on existing work by using weights and activations to calculate parameter importance, but isolates math-specific parameters by filtering out those important for general language tasks. Through pruning parameters MathNeuro identifies, we delete a LLM’s math reasoning ability without significantly impacting its general language ability. Scaling the identified parameters by a small constant improves a pretrained or instruction-tuned LLM’s performance by 4-17% on GSM8K and 5-35% on MATH while leaving non-math behavior unaltered. Math-Neuro is also data efficient: most of its effectiveness holds when identifying math-specific parameters using a single sample. MathNeuro highlights the potential for future work to inter-vene on math-specific parameters. 1</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6400.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6400.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MathNeuro</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Math Neurosurgery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A forward-pass, weight-and-activation based method that isolates math-specific parameters by computing parameter importance on math and non-math datasets (|W| * ||activations||) and taking TopK(math) \ TopK(non-math); interventions (prune or scale) on those parameters delete or boost math reasoning while leaving non-math behavior largely intact.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Phi 1.5; Llama 3.2 1B (instruction-tuned); Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT (all evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>decoder-only transformer (GPT-style)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>evaluated models in range 1B–8B parameters (Phi 1.5 1B; Llama 3.2 1B; Gemma 2 2B; Llama 3.2 3B; Llama 3.1 8B)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not exhaustively specified; evaluated models are pretrained on large web/text corpora and several are instruction-tuned (IT) on multi-task instruction data prior to experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K (primary), MATH (replication); also tested on EGSM, MATHQA for generalization</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step natural-language word-problem math reasoning (grade-school arithmetic/word problems for GSM8K; competition-level mathematics for MATH)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems solved with few-shot chain-of-thought (CoT) prompting (GSM8K: 8-shot CoT; MATH: 4-shot Minerva-style CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K: grade-school / multi-step arithmetic; MATH: harder, competition-style math</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting (8-shot CoT for GSM8K; 4-shot Minerva CoT for MATH). Evaluations run with Eleuther AI LM Eval Harness.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (GSM8K CoT accuracy; MATH accuracy); also measured non-math accuracies on RACE and MMLU</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Scaling the MathNeuro-identified parameters by a small universal factor improved GSM8K accuracy by 4–17% relative (roughly 3–6 percentage points absolute across smaller models; Llama 3.1 8B used a smaller factor and smaller absolute gain). On MATH, scaling improved accuracy by 5–35% (varying by model). Pruning MathNeuro-identified parameters effectively eliminated math performance (GSM8K/MATH) while causing only small non-math drops similar to random pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Parameter importance computed per parameter as S_ij = sum_k |W_ij| * ||X_{k,j}||_2 over N samples for a dataset; MathNeuro computes scores on math and non-math datasets separately and selects math-specific parameters as TopK(math) \ TopK(non-math). Math-specific parameters are distributed roughly evenly across decoder blocks (not concentrated), are a small fraction of total parameters (e.g., ~1.5%–1.8% of model parameters at TopK=15% for Llama 3.2 1B IT), and are highly consistent across random identification sets (≈95% overlap when using ≥100 samples). MathNeuro is data-efficient and often still effective when computed from a single sample (though precision degrades).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Single-sample identification is noisier: pruning based on one sample yields larger non-math accuracy drops than multi-sample identification. Pruning math-specific parameters causes incoherent or failed chain-of-thought outputs (repetition, hallucinated/repeated tokens) for math problems while leaving non-math outputs largely coherent. Scaling requires careful tuning: small models benefited from ~1.1, larger (8B) models from ~1.01; too-large scaling harms performance. Wanda baseline (no filtering) deletes non-math performance when pruning (shows that naive top-|W|*activations overlaps with general skills). LAPE baseline is unstable/variable across random samples and models.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Small multiplicative scaling of identified math-specific weights improves math accuracy up to a small threshold (grid-searches found ~1.075–1.1 useful for smaller models on GSM8K; ~1.01 for the 8B model). The identification consistency and effectiveness improve with more samples (≥100 gives stable parameter sets). Effects vary by model size; larger models required smaller scale factors for best results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6400.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6400.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Wanda</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Wanda (weight-activation pruning score)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A forward-only pruning/importance method that scores parameters by absolute weight times activation norm (|W| * ||activation||_2) to decide which parameters to prune; used here as a baseline for task-specific parameter identification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Phi 1.5; Llama 3.2 1B IT; Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT (evaluated as baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1B–8B (evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Method-agnostic; applied to pretrained and instruction-tuned transformer models in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, MATH (used to compute importance & as evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step word problems / math reasoning (same evaluation tasks as MathNeuro experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems with CoT prompting</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K and MATH difficulty levels</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot CoT for GSM8K/MATH during evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (GSM8K/MATH), non-math accuracy (RACE/MMLU)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Pruning parameters selected by Wanda destroys math performance but also produces larger non-math performance drops compared to MathNeuro (i.e., Wanda cannot isolate math-specific parameters). Scaling Wanda-identified parameters tended to either harm or produce inconsistent, small improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Computes per-parameter score S_ij = |W_ij| * ||X_j||_2 for the input/context and prunes parameters with smallest scores (or ranks by score). Does not filter out parameters important for non-math tasks, so its top parameters overlap with general language skills.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Because it does not perform task-specific filtering, pruning Wanda-selected parameters harms non-math tasks (catastrophic impact) and cannot isolate math-only subnetwork. Scaling is not reliably beneficial and can harm performance.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Not designed as a scaling-intervention method; in this work scaling Wanda-identified weights had inconsistent effects and often was not beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6400.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6400.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LAPE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language Activation Probability Entropy (LAPE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An activation-only method that identifies language- (or task-) specific neurons by thresholding activation probabilities across samples and measuring an entropy-like statistic; used here as a baseline for isolating math-specific neurons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Phi 1.5; Llama 3.2 1B IT; Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT (evaluated as baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1B–8B (evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Method-agnostic; applied to pretrained and instruction-tuned models.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, MATH (used for neuron identification and evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step word-problem math reasoning, general language tasks</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems with CoT prompting</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K and MATH</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot CoT prompting during evaluations</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy on GSM8K/MATH; non-math accuracies on RACE/MMLU</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>LAPE performed inconsistently across models and random data samples: pruning or scaling neurons identified by LAPE produced high variance in math and non-math impacts and was sensitive to the particular data used for identification (wide confidence intervals).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Relies solely on activation statistics (activation probabilities / entropy) rather than incorporating weight magnitudes; lacks the weight×activation context used by Wanda/MathNeuro.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>High sensitivity to sample choice; inconsistent identification of math-specific neurons; wide experimental variance and unstable pruning/scaling outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>No clear beneficial scaling trend observed; outcomes inconsistent across models and samples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6400.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6400.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Evaluated models (aggregate)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evaluated transformer LLMs (Phi 1.5, Llama 3.2 1B IT, Gemma 2 2B IT, Llama 3.2 3B IT, Llama 3.1 8B IT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Set of pretrained and instruction-tuned decoder-only transformer LLMs across 1B–8B parameter scales used to validate MathNeuro across model sizes; instruction-tuned variants were chosen to stress identification in multi-task models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Phi 1.5; Llama 3.2 1B IT; Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1B; 1B; 2B; 3B; 8B respectively</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained on large web/text corpora; several models are instruction-tuned on multi-task instruction datasets (models annotated as "IT"). Specific training corpora not enumerated in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K (primary) and MATH (replication), plus unseen tasks EGSM/MATHQA for generalization</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step word problems (GSM8K) and harder competition math (MATH); general-language tasks RACE, MMLU for non-math evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems; GSM8K solved with 8-shot CoT; MATH with Minerva 4-shot CoT</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K: grade-school multi-step; MATH: competition/harder problems</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought (CoT) prompting (8-shot GSM8K; 4-shot Minerva for MATH); Eleuther evaluation harness used</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (%) on GSM8K and MATH; non-math accuracy for RACE and MMLU</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Absolute baseline accuracies vary by model (figures show GSM8K CoT accuracy ranges roughly from ~0.27 to ~0.79 depending on model and setup in visualizations). Key experimental findings: MathNeuro scaling produced 3–6 percentage point absolute improvements on GSM8K across smaller models (4–17% relative improvement) and 5–35% relative improvements on MATH depending on model; pruning MathNeuro parameters eliminates math ability across models.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Models exhibit a small, consistent subnetwork of parameters important for math reasoning (identifiable with MathNeuro). Math-specific parameters occur across decoder blocks, not concentrated in one or two layers. Identification stability increases with sample count (≥100 samples yields ≈95% overlap).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Models fail on arithmetic when math-specific parameters are pruned (incoherent CoT, repeating or hallucinated tokens) and are sensitive to how many/top-K parameters are selected; non-math performance can be unintentionally harmed if identification does not filter non-math-important parameters (as Wanda demonstrates).</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Smaller models tolerate/benefit from larger scale factors (≈1.075–1.1); larger models require smaller scale factors (≈1.01); identification quality and improvements grow with more identification samples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics <em>(Rating: 2)</em></li>
                <li>How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model <em>(Rating: 2)</em></li>
                <li>An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs <em>(Rating: 2)</em></li>
                <li>Wanda <em>(Rating: 2)</em></li>
                <li>Language Activation Probability Entropy (LAPE) <em>(Rating: 2)</em></li>
                <li>Interpreting and Improving Large Language Models in Arithmetic Calculation <em>(Rating: 1)</em></li>
                <li>Language Models Encode the Value of Numbers Linearly <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6400",
    "paper_id": "paper-273507409",
    "extraction_schema_id": "extraction-schema-126",
    "extracted_data": [
        {
            "name_short": "MathNeuro",
            "name_full": "Math Neurosurgery",
            "brief_description": "A forward-pass, weight-and-activation based method that isolates math-specific parameters by computing parameter importance on math and non-math datasets (|W| * ||activations||) and taking TopK(math) \\ TopK(non-math); interventions (prune or scale) on those parameters delete or boost math reasoning while leaving non-math behavior largely intact.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Phi 1.5; Llama 3.2 1B (instruction-tuned); Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT (all evaluated)",
            "model_family": "decoder-only transformer (GPT-style)",
            "model_size": "evaluated models in range 1B–8B parameters (Phi 1.5 1B; Llama 3.2 1B; Gemma 2 2B; Llama 3.2 3B; Llama 3.1 8B)",
            "training_data_description": "Not exhaustively specified; evaluated models are pretrained on large web/text corpora and several are instruction-tuned (IT) on multi-task instruction data prior to experiments.",
            "benchmark_name": "GSM8K (primary), MATH (replication); also tested on EGSM, MATHQA for generalization",
            "task_type": "Multi-step natural-language word-problem math reasoning (grade-school arithmetic/word problems for GSM8K; competition-level mathematics for MATH)",
            "problem_format": "Natural-language word problems solved with few-shot chain-of-thought (CoT) prompting (GSM8K: 8-shot CoT; MATH: 4-shot Minerva-style CoT)",
            "difficulty_level": "GSM8K: grade-school / multi-step arithmetic; MATH: harder, competition-style math",
            "prompting_method": "Few-shot chain-of-thought prompting (8-shot CoT for GSM8K; 4-shot Minerva CoT for MATH). Evaluations run with Eleuther AI LM Eval Harness.",
            "performance_metric": "Accuracy (GSM8K CoT accuracy; MATH accuracy); also measured non-math accuracies on RACE and MMLU",
            "performance_value": "Scaling the MathNeuro-identified parameters by a small universal factor improved GSM8K accuracy by 4–17% relative (roughly 3–6 percentage points absolute across smaller models; Llama 3.1 8B used a smaller factor and smaller absolute gain). On MATH, scaling improved accuracy by 5–35% (varying by model). Pruning MathNeuro-identified parameters effectively eliminated math performance (GSM8K/MATH) while causing only small non-math drops similar to random pruning.",
            "internal_analysis": "Parameter importance computed per parameter as S_ij = sum_k |W_ij| * ||X_{k,j}||_2 over N samples for a dataset; MathNeuro computes scores on math and non-math datasets separately and selects math-specific parameters as TopK(math) \\ TopK(non-math). Math-specific parameters are distributed roughly evenly across decoder blocks (not concentrated), are a small fraction of total parameters (e.g., ~1.5%–1.8% of model parameters at TopK=15% for Llama 3.2 1B IT), and are highly consistent across random identification sets (≈95% overlap when using ≥100 samples). MathNeuro is data-efficient and often still effective when computed from a single sample (though precision degrades).",
            "failure_modes": "Single-sample identification is noisier: pruning based on one sample yields larger non-math accuracy drops than multi-sample identification. Pruning math-specific parameters causes incoherent or failed chain-of-thought outputs (repetition, hallucinated/repeated tokens) for math problems while leaving non-math outputs largely coherent. Scaling requires careful tuning: small models benefited from ~1.1, larger (8B) models from ~1.01; too-large scaling harms performance. Wanda baseline (no filtering) deletes non-math performance when pruning (shows that naive top-|W|*activations overlaps with general skills). LAPE baseline is unstable/variable across random samples and models.",
            "scaling_trend": "Small multiplicative scaling of identified math-specific weights improves math accuracy up to a small threshold (grid-searches found ~1.075–1.1 useful for smaller models on GSM8K; ~1.01 for the 8B model). The identification consistency and effectiveness improve with more samples (≥100 gives stable parameter sets). Effects vary by model size; larger models required smaller scale factors for best results.",
            "uuid": "e6400.0",
            "source_info": {
                "paper_title": "Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Wanda",
            "name_full": "Wanda (weight-activation pruning score)",
            "brief_description": "A forward-only pruning/importance method that scores parameters by absolute weight times activation norm (|W| * ||activation||_2) to decide which parameters to prune; used here as a baseline for task-specific parameter identification.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Phi 1.5; Llama 3.2 1B IT; Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT (evaluated as baseline)",
            "model_family": "decoder-only transformer",
            "model_size": "1B–8B (evaluated)",
            "training_data_description": "Method-agnostic; applied to pretrained and instruction-tuned transformer models in experiments.",
            "benchmark_name": "GSM8K, MATH (used to compute importance & as evaluation)",
            "task_type": "Multi-step word problems / math reasoning (same evaluation tasks as MathNeuro experiments)",
            "problem_format": "Natural-language word problems with CoT prompting",
            "difficulty_level": "GSM8K and MATH difficulty levels",
            "prompting_method": "Few-shot CoT for GSM8K/MATH during evaluation",
            "performance_metric": "Accuracy (GSM8K/MATH), non-math accuracy (RACE/MMLU)",
            "performance_value": "Pruning parameters selected by Wanda destroys math performance but also produces larger non-math performance drops compared to MathNeuro (i.e., Wanda cannot isolate math-specific parameters). Scaling Wanda-identified parameters tended to either harm or produce inconsistent, small improvements.",
            "internal_analysis": "Computes per-parameter score S_ij = |W_ij| * ||X_j||_2 for the input/context and prunes parameters with smallest scores (or ranks by score). Does not filter out parameters important for non-math tasks, so its top parameters overlap with general language skills.",
            "failure_modes": "Because it does not perform task-specific filtering, pruning Wanda-selected parameters harms non-math tasks (catastrophic impact) and cannot isolate math-only subnetwork. Scaling is not reliably beneficial and can harm performance.",
            "scaling_trend": "Not designed as a scaling-intervention method; in this work scaling Wanda-identified weights had inconsistent effects and often was not beneficial.",
            "uuid": "e6400.1",
            "source_info": {
                "paper_title": "Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "LAPE",
            "name_full": "Language Activation Probability Entropy (LAPE)",
            "brief_description": "An activation-only method that identifies language- (or task-) specific neurons by thresholding activation probabilities across samples and measuring an entropy-like statistic; used here as a baseline for isolating math-specific neurons.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Phi 1.5; Llama 3.2 1B IT; Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT (evaluated as baseline)",
            "model_family": "decoder-only transformer",
            "model_size": "1B–8B (evaluated)",
            "training_data_description": "Method-agnostic; applied to pretrained and instruction-tuned models.",
            "benchmark_name": "GSM8K, MATH (used for neuron identification and evaluation)",
            "task_type": "Multi-step word-problem math reasoning, general language tasks",
            "problem_format": "Natural-language word problems with CoT prompting",
            "difficulty_level": "GSM8K and MATH",
            "prompting_method": "Few-shot CoT prompting during evaluations",
            "performance_metric": "Accuracy on GSM8K/MATH; non-math accuracies on RACE/MMLU",
            "performance_value": "LAPE performed inconsistently across models and random data samples: pruning or scaling neurons identified by LAPE produced high variance in math and non-math impacts and was sensitive to the particular data used for identification (wide confidence intervals).",
            "internal_analysis": "Relies solely on activation statistics (activation probabilities / entropy) rather than incorporating weight magnitudes; lacks the weight×activation context used by Wanda/MathNeuro.",
            "failure_modes": "High sensitivity to sample choice; inconsistent identification of math-specific neurons; wide experimental variance and unstable pruning/scaling outcomes.",
            "scaling_trend": "No clear beneficial scaling trend observed; outcomes inconsistent across models and samples.",
            "uuid": "e6400.2",
            "source_info": {
                "paper_title": "Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Evaluated models (aggregate)",
            "name_full": "Evaluated transformer LLMs (Phi 1.5, Llama 3.2 1B IT, Gemma 2 2B IT, Llama 3.2 3B IT, Llama 3.1 8B IT)",
            "brief_description": "Set of pretrained and instruction-tuned decoder-only transformer LLMs across 1B–8B parameter scales used to validate MathNeuro across model sizes; instruction-tuned variants were chosen to stress identification in multi-task models.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Phi 1.5; Llama 3.2 1B IT; Gemma 2 2B IT; Llama 3.2 3B IT; Llama 3.1 8B IT",
            "model_family": "decoder-only transformer",
            "model_size": "1B; 1B; 2B; 3B; 8B respectively",
            "training_data_description": "Pretrained on large web/text corpora; several models are instruction-tuned on multi-task instruction datasets (models annotated as \"IT\"). Specific training corpora not enumerated in paper.",
            "benchmark_name": "GSM8K (primary) and MATH (replication), plus unseen tasks EGSM/MATHQA for generalization",
            "task_type": "Multi-step word problems (GSM8K) and harder competition math (MATH); general-language tasks RACE, MMLU for non-math evaluation",
            "problem_format": "Natural-language word problems; GSM8K solved with 8-shot CoT; MATH with Minerva 4-shot CoT",
            "difficulty_level": "GSM8K: grade-school multi-step; MATH: competition/harder problems",
            "prompting_method": "Few-shot chain-of-thought (CoT) prompting (8-shot GSM8K; 4-shot Minerva for MATH); Eleuther evaluation harness used",
            "performance_metric": "Accuracy (%) on GSM8K and MATH; non-math accuracy for RACE and MMLU",
            "performance_value": "Absolute baseline accuracies vary by model (figures show GSM8K CoT accuracy ranges roughly from ~0.27 to ~0.79 depending on model and setup in visualizations). Key experimental findings: MathNeuro scaling produced 3–6 percentage point absolute improvements on GSM8K across smaller models (4–17% relative improvement) and 5–35% relative improvements on MATH depending on model; pruning MathNeuro parameters eliminates math ability across models.",
            "internal_analysis": "Models exhibit a small, consistent subnetwork of parameters important for math reasoning (identifiable with MathNeuro). Math-specific parameters occur across decoder blocks, not concentrated in one or two layers. Identification stability increases with sample count (≥100 samples yields ≈95% overlap).",
            "failure_modes": "Models fail on arithmetic when math-specific parameters are pruned (incoherent CoT, repeating or hallucinated tokens) and are sensitive to how many/top-K parameters are selected; non-math performance can be unintentionally harmed if identification does not filter non-math-important parameters (as Wanda demonstrates).",
            "scaling_trend": "Smaller models tolerate/benefit from larger scale factors (≈1.075–1.1); larger models require smaller scale factors (≈1.01); identification quality and improvements grow with more identification samples.",
            "uuid": "e6400.3",
            "source_info": {
                "paper_title": "Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes",
                "publication_date_yy_mm": "2024-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics",
            "rating": 2,
            "sanitized_title": "arithmetic_without_algorithms_language_models_solve_math_with_a_bag_of_heuristics"
        },
        {
            "paper_title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model",
            "rating": 2,
            "sanitized_title": "how_does_gpt2_compute_greaterthan_interpreting_mathematical_abilities_in_a_pretrained_language_model"
        },
        {
            "paper_title": "An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs",
            "rating": 2,
            "sanitized_title": "an_investigation_of_neuron_activation_as_a_unified_lens_to_explain_chainofthought_eliciting_arithmetic_reasoning_of_llms"
        },
        {
            "paper_title": "Wanda",
            "rating": 2
        },
        {
            "paper_title": "Language Activation Probability Entropy (LAPE)",
            "rating": 2,
            "sanitized_title": "language_activation_probability_entropy_lape"
        },
        {
            "paper_title": "Interpreting and Improving Large Language Models in Arithmetic Calculation",
            "rating": 1,
            "sanitized_title": "interpreting_and_improving_large_language_models_in_arithmetic_calculation"
        },
        {
            "paper_title": "Language Models Encode the Value of Numbers Linearly",
            "rating": 1,
            "sanitized_title": "language_models_encode_the_value_of_numbers_linearly"
        }
    ],
    "cost": 0.0184475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes
18 Jun 2025</p>
<p>Bryan R Christ 
Zack Gottesman 
Jonathan Kropko 
Thomas Hartvigsen hartvigsen@virginia.edu 
Alessandro Stolfo 
Yonatan Belinkov 
Mrinmaya Sachan 
A Mechanistic 
Xavier Suau 
Pieter Delobelle 
Katherine Metcalf 
Ar- Mand Joulin 
Gemma Team 
Morgane Riviere 
PierShreya Pathak 
Giuseppe Sessa 
Cassidy Hardin 
Surya Bhupati- Raju 
Léonard Hussenot 
Thomas Mesnard 
Bobak Shahriari 
Alexandre Ramé 
Johan Ferret 
Peter Liu 
Pouya Tafti 
Abe Friesen 
Michelle Casbon 
Sabela Ramos 
Ravin Kumar 
Charline Le Lan 
Sammy Jerome 
Anton Tsitsulin 
Nino Vieillard 
Piotr Stanczyk 
Sertan Girgin 
Nikola Momchev 
Matt Hoffman 
Shantanu Thakoor 
Jean-Bastien Grill 
Behnam Neyshabur 
Olivier Bachem 
Alanna Wal- Ton 
Aliaksei Severyn 
Alicia Parrish 
Aliya Ah- Mad 
Allen Hutchison 
Alvin Abdagic 
Amanda Carl 
Amy Shen 
Andy Brock 
Andy Coenen 
An- Thony Laforge 
Antonia Paterson 
Ben Bastian 
Bilal Piot 
Bo Wu 
Brandon Royal 
Charlie Chen 
Chintu Kumar 
Chris Perry 
Chris Welty 
Christopher A Choquette-Choo 
Danila Sinopalnikov 
David Wein- Berger 
Dimple Vijaykumar 
Dominika Rogozińska 
Dustin Herbison 
Elisa Bandy 
Emma Wang 
Eric Noland 
Erica Moreira 
Evan Senter 
Evgenii Elty- Shev 
Francesco Visin 
Gabriel Rasskin 
Gary Wei 
Glenn Cameron 
Gus Martins 
Hadi Hashemi 
Hanna Klimczak-Plucińska 
Harleen Batra 
Harsh Dhand 
Ivan Nardini 
Jacinda Mein 
Jack Zhou 
James Svens- Son 
Jeff Stanway 
Jetha Chan 
Jin Peng Zhou 
Joana Carrasqueira 
Joana Iljazi 
Jocelyn Becker 
Joe Fer- Nandez 
Joost Van Amersfoort 
Josh Gordon 
Josh Lipschultz 
Josh Newlan 
Ju-Yeong Ji 
Kareem Mo- Hamed 
Kartikeya Badola 
Kat Black 
Katie Mil- Lican 
Keelin Mcdonell 
Kelvin Nguyen 
Kiranbir Sodhia 
Kish Greene 
Lars Lowe Sjoesund 
Lau- Ren Usui 
Laurent Sifre 
Lena Heuermann 
Leti- Cia Lago 
Lilly Mcnealus 
Baldini Livio 
Logan Soares 
Lucas Kilpatrick 
Luciano Dixon 
Machel Martins 
Manvinder Reid 
Mark Singh 
Mar- tin GörnerIverson 
Mat VellosoMateo Wirth 
Matt Davi- Dow 
Matt Miller 
Matthew Rahtz 
Wat- Son Matthew 
Meg Risdal 
Mehran Kazemi 
Michael Moyni- Han 
Ming Zhang 
Minsuk Kahng 
Minwoo Park 
Mofi Rahman 
Mohit Khatwani 
Natalie Dao 
Nen- Shad Bardoliwalla 
Nesh Devanathan 
Neta Dumai 
Nilay Chauhan 
Oscar Wahltinez 
Pankil Botarda 
Parker Barnes 
Paul Barham 
Paul Michel 
Peng- Chong Jin 
Petko Georgiev 
Phil Culliton 
Pradeep Kuppala 
Ramona Comanescu 
Ramona Merhej 
Reena Jana 
Reza Ardeshir Rokni 
Rishabh Agar- Wal 
Ryan Mullins 
Samaneh Saadat 
Sara Mc Carthy 
Sarah Perrin 
Sébastien M R Arnold 
Sebastian Krause 
Shengyang Dai 
Shruti Garg 
Shruti Sheth 
Sue Ronstrom 
Susan Chan 
Timothy Jordan 
Ting Yu 
Tom Eccles 
Tom Hennigan 
Tomas Kocisky 
Tulsee Doshi 
Vihan Jain 
Vikas Yadav 
Vilobh Meshram 
Vishal Dharmadhikari 
Warren Barkley 
Wei Wei 
Wenming Ye 
Woohyun Han 
Woosuk Kwon 
Xiang Xu 
Zhe Shen 
Zhitao Gong 
Zichuan Wei 
Victor Cotruta 
Phoebe Kirk 
Anand Rao 
Minh Giang 
Ludovic Peran 
Tris Warkentin 
Eli Collins </p>
<p>University of Virginia</p>
<p>Nicholas Apostoloff
Luca Zappella</p>
<p>Joelle Barral
Zoubin Ghahramani</p>
<p>Raia Hadsell, D. Sculley
Jeanine Banks, Anca Dragan</p>
<p>Slav Petrov</p>
<p>Demis Hassabis
Oriol Vinyals
Jeff Dean, Clement Farabet, Elena Buchatskaya, Sebastian BorgeaudKoray Kavukcuoglu</p>
<p>Noah Fiedel
Armand Joulin</p>
<p>Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes
18 Jun 20253688389FA6F0C172BD8D0ABE9C7953BFarXiv:2410.16930v4[cs.CL]
Math reasoning is an active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence and has implications in several domains, including math education.However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill that can be isolated within models.Doing so could allow targeted intervention to improve math performance without altering non-math behavior and foster understanding of how models encode math reasoning.We introduce Math Neurosurgery (MathNeuro), a computationally efficient method we use to isolate math-specific parameters in LLMs using only forward passes.MathNeuro builds on existing work by using weights and activations to calculate parameter importance, but isolates math-specific parameters by filtering out those important for general language tasks.Through pruning parameters MathNeuro identifies, we delete a LLM's math reasoning ability without significantly impacting its general language ability.Scaling the identified parameters by a small constant improves a pretrained or instruction-tuned LLM's performance by 4-17% on GSM8K and 5-35% on MATH while leaving non-math behavior unaltered.Math-Neuro is also data efficient: most of its effectiveness holds when identifying math-specific parameters using a single sample.MathNeuro highlights the potential for future work to intervene on math-specific parameters. 1</p>
<p>Introduction</p>
<p>Math reasoning, or solving math problems with logic, is an active area of LLM research because it represents artificial intelligence (e.g., Ahn et al. 2024;Li et al. 2024b) and has implications in many domains, including math education (e.g, Christ et al. 2024;Wang et al. 2024) and automated theorem proving (e.g., Song et al. 2024;Xin et al. 2024).Yet, few works have explored how LLMs encode math reasoning abilities in their parametric knowledge.Identifying math-specific parameters could be beneficial for many reasons, including a) targeting the right parameters to intervene on to improve a model's math reasoning ability as others have done in other domains (e.g., Tang et al. 2024;Suau et al. 2024), b) doing so without altering behavior on other tasks like these works have done in their domains, and c) fostering knowledge of how LLMs encode math reasoning.While some works explore how different math concepts or terms are stored or processed in model layers or neurons (e.g., Hanna et al. 2023;Rai and Yao 2024;Stolfo et al. 2023), none have developed a method for isolating parameters for math reasoning.</p>
<p>Outside of math reasoning, several works have explored how to identify neurons or parameters associated with particular knowledge or skills in LLMs (Chang et al., 2024;Dai et al., 2022;Panigrahi et al., 2023;Tang et al., 2024;Wang et al., 2022).While some methods are computationally expensive because they use gradient information, which may not be feasible for large models (e.g., Panigrahi et al. 2023), others are easier to compute because they rely on information obtained through forward passes, particularly as captured by activations (e.g., Tang et al. 2024).However, it is unknown if these domain-specific methods for single skill identification can effectively isolate a broad concept like math reasoning, which may be entangled with many other abilities within a LLM (e.g., reading comprehension, general knowledge).</p>
<p>We conduct the first study of parameter importance in LLMs for math reasoning.We apply two state-of-the-art (SOTA) gradient-free parameter importance methods to math reasoning.We find one of these methods, LAPE (Tang et al., 2024), performs inconsistently at identifying math-specific neurons across models, while the other, Wanda (Sun et al., 2023), identifies parameters important for math, but is unable to isolate math-specific parameters because the parameters it identifies overlap significantly with those important for other tasks.To address these limitations of existing methods, we develop a new method called Math Neurosurgery (MathNeuro) we use to isolate mathspecific parameters.Building on Wanda, Math-Neuro uses weights and activations to calculate parameter importance and achieve a context-aware representation of importance.MathNeuro extends beyond Wanda by adding task-specific parameter identification.Specifically, to isolate parameters important for math and not other abilities, MathNeuro filters out identified parameters that are found to be important for other general language understanding tasks.</p>
<p>We provide evidence that MathNeuro effectively isolates math-specific parameters by evaluating it with five LLMs from 1-8B parameters.Pruning parameters identified by MathNeuro effectively deletes a model's math reasoning ability.Despite destroying math reasoning, pruning these parameters results in a performance drop on other, nonmath tasks similar to the impact of random parameter pruning.We also find that scaling up MathNeuro-identified parameters by a small universal factor can boost both instruction-tuned and pre-trained LLMs' GSM8K (Cobbe et al., 2021) or MATH (Hendrycks et al., 2021b) performance by 4-17% or 5-35% across models, respectively.We further show that our method is data efficient: Math-Neuro is almost as effective using only a single sample to calculate parameter importance.In addition, we show MathNeuro consistently identifies a similar subset of parameters as math-specific across different sets of samples and that these parameters generalize across math reasoning tasks.We find math-specific parameters are located roughly evenly throughout a model's decoder blocks, suggesting math reasoning is likely encoded throughout a model's parameters rather than being concentrated in a specific layer or layers.</p>
<p>Our key contributions are as follows:</p>
<p>• We design MathNeuro, a simple yet effective way to isolate LLM math reasoning by filtering out parameters important for other tasks.• We demonstrate the effectiveness of this method by showing that deleting parameters identified by MathNeuro destroys a model's math performance and scaling them by a universal factor can increase it by 4-35%.</p>
<p>• We verify MathNeuro isolates math-specific parameters by showing pruning or scaling them does not significantly impact non-math performance more than random perturbation.</p>
<p>Related Work</p>
<p>Skill and Knowledge Localization in LLMs Several works have explored skill and knowledge localization in language models, although none focus on math specifically (Bau et al., 2018;Chang et al., 2024;Dalvi et al., 2018;Dai et al., 2022;Dalvi et al., 2020;Gurnee et al., 2023;Kojima et al., 2024;Leng and Xiong, 2024;Panigrahi et al., 2023;Radford et al., 2017;Suau et al., 2024;Sun et al., 2023;Tang et al., 2024;Wang et al., 2022;Xin et al., 2019;Zhao et al., 2024).Many methods use gradient information to calculate parameter importance, which is computationally infeasible for large models (Dai et al., 2022;Leng and Xiong, 2024;Panigrahi et al., 2023;Wang et al., 2022).However, others are more lightweight and calculate parameter importance using only forward passes, predominately through using information obtained through activation values (Kojima et al., 2024;Suau et al., 2024;Sun et al., 2023;Tang et al., 2024;Zhao et al., 2024).While these methods may find parameters important for the domains they study, it is unclear if they could identify parameters important for math reasoning, which could be distributed throughout a model or interwoven with other important natural language abilities given the task's complexity.To identify important parameters, MathNeuro builds upon Wanda (Sun et al., 2023), a SOTA LLM pruning method that prunes parameters unimportant for a model's output as measured by the smallest absolute value of weights times activations.MathNeuro inverts Wanda by identifying the most important parameters for a task and isolates math-specific parameters by filtering out parameters important for non-math, general language tasks through introducing task-specific data into the importance calculation.</p>
<p>Math Skill Localization in LLMs Some studies have explored how math knowledge is encoded within LLMs (Hanna et al., 2023;Nikankin et al., 2024;Rai and Yao, 2024;Stolfo et al., 2023;Zhang et al., 2024;Zhu et al., 2025).These works focus on how and where particular math concepts and key phrases such as addition and subtraction are processed by LLMs.While these findings are insightful, they do not identify parameters critical for a model's overall math performance but rather ones relating to processing different math concepts.</p>
<p>Methods</p>
<p>We propose MathNeuro, a parameter identification method that calculates importance using only forward passes.First, we separately identify LLM parameters important for a math task and a nonmath, general language task using samples for each task.Next, MathNeuro isolates math-specific parameters by taking the subset that are important for the math task but not for the non-math task.While MathNeuro may work for other, non-math tasks, we study math specifically.We describe the problem setup and our method in more detail below.</p>
<p>Preliminaries</p>
<p>Identifying parameters important for math reasoning in LLMs is beneficial because it is a critical AI capability, is understudied in interpretability work, has implications in several domains, and thus is an interesting test domain.However, this is nontrivial given that math reasoning not only involves direct computation, but also natural language reasoning.Thus, it may be difficult to distinguish parameters important only for math reasoning from those important for general language.Indeed, other work has found significant overlap between parameters important for different tasks (Tang et al., 2024).</p>
<p>Identifying Top Parameters</p>
<p>MathNeuro adapts Wanda (Sun et al., 2023), a SOTA LLM pruning method that prunes, or removes, parameters unimportant for a model's output.Wanda identifies parameters to prune using the absolute value of weights times activations for an input, providing a context-aware representation of parameter importance.Wanda produces a score    for weight  in neuron  within a weight matrix:
𝑆 𝑖 𝑗 = |𝑊 𝑖 𝑗 | • ∥ 𝑋 𝑗 ∥ 2
where    represents the weight, | • | is the absolute value operator, and ∥   ∥ 2 is the ℓ 2 norm of the -th feature aggregated across input tokens to normalize the input , or activation values.Wanda then prunes the parameters with the smallest scores.Wanda considers both weights and activations as elements of parameter importance because small but highly activated weights can be highly influential, while large but lightly activated weights may be less influential.MathNeuro inverts Wanda by identifying the parameters with the largest weights times activations as being most important to a given task.</p>
<p>Isolating Math-specific Parameters</p>
<p>While naively identifying the parameters with the highest absolute value of weights times activations may find parameters important for a given task, it may not isolate the parameters important for that task only, as discussed above.Thus, we calculate parameter importance for other unrelated tasks and use the disjoint set between these sets of parameters as the ones that are math-specific, which is the critical innovation of MathNeuro.To do this, we separately sum2 the absolute value of weights times activations for each parameter in attention and MLP layers for each data point  across  samples from a math dataset and an unrelated natural language task dataset.We focus on attention and MLP layers because recent work has found that knowledge and skills are often distributed in these two model components (Wei et al., 2024;Yin et al., 2024).Using this formulation, we compute scores for each parameter over math and non-math inputs:
𝑆 math 𝑖 𝑗 = 𝑁 ∑︁ 𝑘=1 |𝑊 𝑖 𝑗 | • ∥ 𝑋 𝑘 𝑗 ∥ 2 for 𝑋 ∈ D math 𝑆 non-math 𝑖 𝑗 = 𝑁 ∑︁ 𝑘=1 |𝑊 𝑖 𝑗 | • ∥ 𝑋 𝑘 𝑗 ∥ 2 for 𝑋 ∈ D non-math
Then, we separately identify the top K% of parameters with the highest score for each task in each layer.Lastly, we take the subset of parameters most important for the math task that are not in the set of parameters most important for the unrelated task, or   ℎ = TopK  ℎ \ TopK − ℎ .</p>
<p>Experiments</p>
<p>We next validate if MathNeuro successfully identifies math-specific parameters.We compare against SOTA alternatives and a simple baseline in two settings: 1) pruning parameters identified as important for math and 2) scaling these parameters.Pruning or scaling task-specific parameters is equivalent to the approach recent work has taken to deactivate or more highly activate neurons identified as language or knowledge specific (Kojima et al., 2024;Suau et al., 2024;Tang et al., 2024;Zhao et al., 2024), respectively, but intervenes on the weight rather than activation level.We show the impact of each intervention on both math and non-math performance across five LLMs ranging from 1-8B parameters.We perform parameter identification experiments using 500 samples and a single sample.</p>
<p>Experimental Setup</p>
<p>Models We evaluate five LLMs of varying sizes: Phi 1.5 (1B) (Li et al., 2023), Llama 3.2 1B Instruction Tuned (IT) (MetaAI, 2024b), Gemma 2 2B IT (Team et al., 2024), Llama 3.2 3B IT (MetaAI, 2024b), and Llama 3.1 8B IT (MetaAI, 2024a).We display results for Llama 3.2 1B IT below and report results for the other models in Appendices A, B, C, and D, which follow similar trends to those discussed below.We focus on instruction tuned models to evaluate if MathNeuro can successfully identify math-specific parameters in models that a) perform well at math given their size and b) are trained for a range of tasks, which means it may be more difficult to identify math-specific parameters.Phi 1.5 serves as a baseline for if MathNeuro works for a pretrained, non-IT model.</p>
<p>Datasets For identifying math-specific parameters, we use the popular and high-quality GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021b) datasets.We calculate parameter importance using the GSM8K or MATH training split and evaluate the impact of each method on the GSM8K or MATH test split.We report GSM8K results below and MATH results in Appendix F given the GSM8K results replicate for the MATH dataset.Following prior work (Agarwal et al., 2024;Brown et al., 2024;Lee et al., 2024;Li et al., 2024a), we subset the GSM8K test split to the same 200 random samples for every model for experimental efficiency.For identifying parameters important for non-math tasks and measuring performance drops after eliminating math-specific parameters, we follow recent work that assesses catastrophic forgetting in LLMs (Luo et al., 2024) by using RACE (Lai et al., 2017) for measuring reading comprehension and MMLU (Hendrycks et al., 2021a) for measuring general knowledge.These datasets are general language understanding tasks that are different from math reasoning.While MMLU contains some math-related questions, it assesses a variety of knowledge that, in aggregate, is mostly not math-specific.We conduct all evaluations using the Eleuther AI LM Evaluation Harness (Gao et al., 2024) and use an 8-shot chain-of-thought (CoT) prompting format for GSM8K, as is standard.</p>
<p>Baselines We compare MathNeuro to three identification methods computed using forward passes: (a) Wanda (Sun et al., 2023): We calculate parameter importance for math inputs and choose the top K% of parameters without filtering out those important for other unrelated tasks.</p>
<p>(b) Language Activation Probability Entropy (LAPE) (Tang et al., 2024): LAPE finds languagespecific neurons by thresholding activation probabilities as calculated by samples for each language under consideration.We use GSM8K, MMLU, and RACE for calculating task-specific neurons using this method.Using LAPE allows us to determine if existing activation-only parameter identification methods can isolate math-specific parameters.</p>
<p>(c) Random Parameter Identification: As a sanity check, we randomly select the same number of parameters as those identified by MathNeuro when using MMLU or RACE as D non-math .</p>
<p>Pruning Top Math Parameters</p>
<p>To test if the four parameter identification methods (MathNeuro and three baselines) identify parameters important for math reasoning, we iden-</p>
<p>Greater reduction in math accuracy</p>
<p>Greater reduction in math accuracy</p>
<p>Better preservation of non-math accuracy</p>
<p>Better preservation of non-math accuracy tify important parameters using each method for each model and prune them (set them to 0).We then compare each model's GSM8K, RACE, and MMLU accuracy to their own unedited performance.We do this five times for each model with different random subsets of 500 samples from each dataset to identify the average performance of each method.We identify the top .01,.1,.5, 1, 2.5, 5, 10 and 15% of parameters for each comparison and report the parameter proportion with the best performance.Appendix A explores how parameter proportion impacts GSM8K performance; notably, this hyperparameter does not impact performance for Wanda and LAPE exhibits a performance curve similar to MathNeuro.Figures 2, 9, 10, 11 and 12 show results from this experiment.An ideal method would fall in the top left of these plots, meaning math performance (GSM8K) is deleted while non-math performance (RACE and MMLU) is maintained.As seen in the figures, MathNeuro and Wanda eliminate math performance across models, while LAPE performs inconsistently across models, often displaying wide confidence intervals, suggesting its performance is sensitive to which data points are used.However, while Wanda also destroys each model's ability to perform non-math tasks, MathNeuro effectively isolates math-specific parameters across models, as shown in non-math performance decreases that are similar to the effect of random pruning.</p>
<p>Scaling Top Math Parameters</p>
<p>We next evaluate performance when more highly activating math-specific parameters by scaling the weights by a universal factor.For smaller models, we find the scalar 1.1 works best, while for larger models (Llama 3.1 8B IT), a smaller factor (1.01) works better.While we leave a rigorous study of this hyperparameter to future work due to its computational expense, see Appendix H for our experimentation with scale factors.As in Section 4.2, we scale the parameters each method identifies based on 500 random samples from each relevant dataset and repeat the process five times, reporting the parameter proportion that performs best.Figures 3,14,15,16,and 17 display results from this experiment.An ideal method would fall in the top right of these plots, meaning GSM8K accuracy increases while non-math performance is maintained.As shown in these figures, scaling parameters identified by MathNeuro results in a GSM8K performance increase of 4-17% across models, while scaling Wanda-identified parameters tends to either harm or slightly improve performance.As with pruning, LAPE performs inconsistently in the scaling setting across models.Scaling random parameters can help for some models, although the effect is not consistent across models.Each parameter identification method does not harm performance on RACE or MMLU, suggesting scaling's impact tends to be localized to math performance.</p>
<p>MathNeuro with a Single Sample</p>
<p>If a method can identify math-specific parameters using a single sample, then it could inform math interventions for settings where data are limited such as for assessing a specific math operation or topic.To test this with MathNeuro and the baselines, we conduct experiments to identify parameters based on a single math and non-math input.We then prune or scale parameters identified by each method and run each experiment five times using different random samples from each dataset.As shown in Figures 4,18,19,20 and  rameters when pruning using a single sample, as shown in lower drops in non-math performance relative to Wanda.However, these performance drops are larger than when using more samples, suggesting additional samples help MathNeuro more effectively isolate math-specific parameters.LAPE again performs inconsistently across models in the one sample pruning setting.As shown in Figures 5,22,23,24, and 25, we see similar or smaller, but still meaningful, boosts in GSM8K accuracy when scaling parameters Math-Neuro identifies using one math and non-math sample.While random scaling sometimes helps as observed in Section 4.3, the effect is again not consistent across models.In some cases, LAPE and Wanda increase GSM8K accuracy, though the effects are not consistent across models, and they also sometimes decrease performance.For all methods, there is no meaningful performance drop in MMLU or RACE accuracy, suggesting scaling's impact on non-math performance is still minor.</p>
<p>MathNeuro Parameter Consistency, Number, Location and Qualitative Impact</p>
<p>Next, we conduct experiments to explore if Math-Neuro identifies the same set of parameters as mathspecific across different random subsets of math and non-math data and the number and location of these parameters.We report results for these experiments in the sections below using RACE as the non-math dataset and equivalent results for using MMLU as the non-math dataset in Appendix I.</p>
<p>We also conduct a qualitative evaluation of model outputs after pruning or scaling parameters Math-Neuro identifies to explore how math and non-math outputs are affected by the method.All experiments are conducted using Llama 3.2 1B IT.</p>
<p>Consistency of Math-specific Parameters</p>
<p>We next explore if MathNeuro consistently identifies the same parameters as math-specific across different random subsets from a math and non-math dataset.This allows us to identify if math reasoning is in fact reliably concentrated in a subset of model parameters like the experiments above suggest.We first identify math-specific parameters using Math-Neuro on two different random subsets from a math and non-math dataset.Next, we calculate the percentage overlap between the parameters identified in both subsets.We do this five times for different sample sizes (1, 10, 100, 500, and 1,000) and for calculating different proportions of top parameters from each dataset.This allows us to construct confidence intervals and see how parameter identification consistency varies when calculating based on different sample sizes and top parameter proportions.As shown in Figure 6 and Appendix I, with 100 or more samples, roughly 95% or more of the parameters MathNeuro identifies overlap between two random subsets regardless of the proportion of top parameters calculated, which shows that the method is able to consistently identify the most important parameters for math performance and that these parameters are largely invariant with regard to the subset of data used to calculate them.</p>
<p>Number and Location of Math-specific Parameters</p>
<p>We next examine the proportion of parameters MathNeuro identifies as math-specific.We first identify math-specific parameters using random subsets from each dataset.Next, we calculate the percentage of the top K% of parameters that are identified as math-specific using those subsets.We repeat this five times for different sample sizes and top K%s to construct confidence intervals.</p>
<p>Greater reduction in math accuracy</p>
<p>Greater reduction in math accuracy</p>
<p>Better preservation of non-math accuracy</p>
<p>Better preservation of non-math accuracy As shown in Figure 7 and Appendix I, while the most parameters are identified as math-specific when calculating importance with one sample due to randomness, the amount of math-specific parameters identified by MathNeuro generally increases with the number of samples considered for all proportions of top parameters calculated.The relatively high amount of overlap in top parameters be-tween tasks displayed in these figures is likely why MathNeuro performs better than existing parameter identification methods that do not filter out parameters important for other tasks.The percentage of math-specific parameters in the top K% of parameters declines as the proportion of top parameters calculated increases because as this proportion increases, more of the model's top parameters are considered.These top parameters are likely more task-invariant than those found when considering a smaller percentage of the model's top parameters.</p>
<p>To explore where math-specific parameters are located within a model, we sum the number of parameters MathNeuro identifies in each decoder block for Llama 3.2 1B IT.To do this, we calculate the top 15% of parameters, which is the parameter proportion for which MathNeuro performs best for this model.As shown in Figure 8 and Appendix I, the number of math-specific parameters Math-Neuro identifies is relatively consistent across decoder blocks when using either RACE or MMLU for parameter identification.This suggests that  models encode math reasoning by distributing the capability throughout their parametric knowledge rather than concentrating it in a few layers.The parameters identified in these figures correspond to just 1.51% and 1.84% of the model's overall parameters when calculating parameter importance based on MMLU and RACE, respectively, despite being responsible for nearly all of its math performance.</p>
<p>Qualitative Analysis To verify model outputs are still coherent after pruning or scaling, we conduct a qualitative analysis of outputs before and after pruning or scaling parameters MathNeuro identifies.As shown in Tables 1, 3, and 4, only the output for answering a GSM8K question becomes incoherent after pruning math-specific parameters.</p>
<p>Before pruning, the model correctly solves the GSM8K problem; after pruning, it fails to generate an effective CoT.The pruned model effectively responds to RACE questions, although it gets the question wrong before and after pruning.The pruned model generates coherent output to MMLU questions, though it gets the answer right when using RACE as D non-math and wrong when using MMLU as D non-math .These findings confirm our quantitative findings showing the model can still perform non-math tasks after pruning math-specific parameters, although it experiences a performance drop similar to that obtained from random pruning.As shown in Tables 2, 3, and 5, the scaled model's outputs for RACE and MMLU questions remain mostly unmodified, while it correctly solves a GSM8K question after scaling based on MMLU as D non-math that it solved incorrectly before scaling.These findings parallel our quantitative findings that math reasoning increases post-scaling while non-math performance remains unchanged.</p>
<p>Impact of MathNeuro on Unseen Tasks</p>
<p>To explore if math-specific parameters MathNeuro identifies are consistently important across unseen math tasks and unimportant for unseen general language or non-math reasoning tasks, we repeat the pruning experiments reported in Section 4.2 using GSM8K as the math dataset and MMLU or RACE as the non-math dataset and evaluate the pruned model on 8 unseen tasks (see Appendix E for implementation details).Unseen tasks include 5 that are non-math reasoning or general language tasks (HellaSwag, MuTual, PIQA, Wiki-Text, and WinoGrande) (Zellers et al., 2019;Cui et al., 2020;Bisk et al., 2020;Merity et al., 2016;Sakaguchi et al., 2021) and 3 that are math tasks, both in domain (EGSM; Christ et al. 2024) and out of domain (MATH, MATHQA) (Hendrycks et al., 2021b;Amini et al., 2019).The figures in Appendix E display this experiment's results where the Wanda baseline represents the lowest possible bound on performance for a task given that it deletes all of a model's top parameters.Across models, pruning parameters identified by Math-Neuro effectively deletes math performance on both in domain and out of domain tasks while mostly maintaining performance on general language and non-math reasoning tasks.These findings expand those discussed in Section 4.2 by showing that math-specific parameters MathNeuro identifies are universally important across math reasoning tasks and unimportant across non-math tasks regardless of the math dataset used for identification.This generalizability across math tasks allays concerns that parameters identified in one dataset are really targeted towards characteristics of that dataset and, instead, shows MathNeuro isolates parameters important for math reasoning broadly.</p>
<p>Conclusion</p>
<p>Although math reasoning is an active area of LLM research, few works have explored how it is encoded within LLM parameters and if it is a skill that can be isolated within a model.We introduce MathNeuro, a forward-only identification method we use to isolate math-specific parameters in LLMs.</p>
<p>Through comprehensive experiments, we demonstrate MathNeuro's effectiveness by showing pruning or scaling the parameters it identifies can delete or reinforce a LLM's math reasoning ability, respectively, despite its simplicity and ease of calculation.Future work should build on this method by applying it to other domains and developing interventions for math-specific parameters that improve a model's performance on mathematical reasoning without catastrophic forgetting.</p>
<p>Limitations</p>
<p>While we comprehensively evaluate MathNeuro using several math and non-math datasets used in other works and focus our evaluations on math reasoning specifically, there are many other natural language and mathematical reasoning tasks models could be evaluated on.Future work should consider extending MathNeuro to these additional tasks and explore if MathNeuro can isolate parameters important for non-math tasks.While we used five recent models for our experiments, future work should also include additional models, especially those of larger sizes (&gt;8B).Additionally, due to computational expense, we were unable to conduct a full hyperparameter sweep for an optimal universal scaling factor for parameters identified by MathNeuro, though the rough grid search we report in Appendix H highlights that larger scale factors tend to work better for smaller models and smaller scale factors tend to work better for larger models.</p>
<p>Figures 9, 10, 11 and 12 show the results for pruning parameters identified by each method for Phi 1.5, Gemma 2 2B IT, Llama 3.2 3B IT, and Llama 3.1 8B IT, respectively.As shown in these figures, the results for each model closely mirror those discussed in Section 4.2, where MathNeuro performs the best at isolating math-specific parameters as shown by destroying GSM8K performance while having low drops in MMLU and RACE performance that are similar to the impact of pruning random model parameters.</p>
<p>Figure 13 shows the impact of parameter proportion on GSM8K performance when pruning parameters identified by each method for Llama 3.2 1B IT.As shown in the figure, GSM8K performance declines with increasing proportion of parameters considered when using MathNeuro until the parameter proportion reaches .05,at which point the effectiveness of the method levels off.GSM8K performance begins to increase after the top 10% of parameters are considered due to the top 15% of model parameters being more invariant across tasks, as shown in Section 4.5.For comparison methods, Wanda deletes math performance regardless of parameter proportion, LAPE exhbits a similar performance trend to MathNeuro, and pruning random parameters tends to hurt performance as the proportion of top parameters considered increases, which is expected.The other four models show similar trends when considering different proportions of top parameters.</p>
<p>B GSM8K Scaling Results</p>
<p>Figures 14, 15, 16 and 17 show the results for scaling parameters identified by each method for Phi 1.5, Gemma 2 2B IT, Llama 3.2 3B IT, and Llama 3.1 8B IT, respectively.As shown in these figures, the results for each model closely mirror those discussed in Section 4.3, where scaling parameters identified by MathNeuro consistently increases GSM8K performance by 3-6 percentage points across models, representing a 4-17% overall increase in math performance depending on the model.</p>
<p>C One Sample GSM8K Pruning Results</p>
<p>Figures 18, 19, 20 and 21 show the results for pruning parameters identified by each method for Phi 1.5, Gemma 2 2B IT, Llama 3.2 3B IT, and Llama 3.1 8B IT, respectively, when calculating parameter importance based on a single sample.As shown in these figures, the results for each model closely mirror those discussed in Section 4.4, where MathNeuro still performs the best at isolating math-specific parameters as shown by destroying GSM8K performance while having lower drops in MMLU and RACE performance than Wanda.However, as reported in Section 4.4, these results suggest additional samples help the method more effectively isolate math-specific parameters because the non-math drops in performance are larger than those shown in Appendix A, where we used 500 samples to calculate parameter importance.mirror those discussed in Section 4.4, where scaling parameters identified by MathNeuro using a single sample consistently increases GSM8K performance across models.These increases are either similar to those reported in Appendix B, or smaller but still meaningful.For some models, the comparison methods can increase GSM8K performance when calculating parameter importance based off a single sample, but MathNeuro is the only method for which a meaningful positive increase is consistent across models.</p>
<p>D One Sample GSM8K Scaling Results</p>
<p>E Impact of MathNeuro on Unseen Downstream Tasks</p>
<p>As discussed in Section 4.6, Figures 26, 27, 28, 29, and 30 display the results for evaluating unseen task performance after pruning parameters identified by MathNeuro using GSM8K as D math and MMLU or Race as D non-math .In these figures, Mu-Tual performance is unimpaired regardless of the parameter identification method used, suggesting that performance on this task is consistently equal to random guessing regardless of which parameters are pruned.All tasks are implemented using their default implementation in the Eleuther AI LM Evaluation Harness (Gao et al., 2024)</p>
<p>F.2 MATH Scaling Experiments</p>
<p>We also replicate our GSM8K scaling experiments using MATH as the math dataset and MMLU or RACE as the non-math dataset.Similar to our MATH pruning experiments, we subset the MATH testing split to the same random samples for each model and experimental run for experimental efficiency and implement the MATH task with the same prompting approach described above.We use a smaller sample of the MATH testing split (350 samples) for our scaling experiments given that we conduct the rough grid search for an optimal scaling factor and parameter proportion described in Appendix H and Section 4.3, respectively, and using a larger set of samples would be computationally prohibitive.As shown in Figures 41, 42, 43, 44, and 45, our GSM8K scaling results replicate when using MATH as the math dataset, as scaling math-specific parameters MathNeuro identifies boosts MATH performance by a small but meaningful amount while leaving MMLU and RACE performance unchanged.These increases in performance correspond to increasing baseline MATH performance by 5-35% depending on the model.These results show that scaling parameters identified using MathNeuro boosts math performance even when using different math datasets.</p>
<p>Using the same scaling factors and conducting a small grid search for the optimal parameter proportion like we did in Section 4.4, we also replicate our one sample scaling experiments using MATH as D math .Results are shown in Figures 46,47,48,49,and 50, where scaling MathNeuro-identified parameters using a single MATH sample for parameter identification still results in a small but meaningful boost in MATH performance while leaving nonmath performance unaltered.</p>
<p>G Sample Outputs</p>
<p>Tables 1, 2, 3, 4, and 5 display sample outputs from Llama 3.2 1B IT before and after pruning or scaling parameters identified by MathNeuro.The tables display outputs for a GSM8K, RACE, or MMLU question.</p>
<p>H Scaling Factor Grid Search</p>
<p>Because an exhaustive grid search for the optimal scaling factor for MathNeuro would be computationally prohibitive, we used a rough bisection grid search to find a factor that worked best for each model for the GSM8K and MATH scaling experiments.For each model, we tried three scaling factors based on initial experiments that showed scale factors above 1.1 were too large: 1.01, 1.05, and 1.075.For GSM8K, for smaller models (Phi 1.5, Gemma 2 2B IT, Llama 3.2 1B IT, and Llama  3.2 3B IT), 1.075 worked best or tied with 1.05, while for Llama 3.1 8B IT, a larger model, 1.01 worked best.For the smaller models, we next tried scale factors between 1.075 and 1.05 (1.0625) and between 1.075 and the maximum scale factor we saw improved results based on initial experiments (1.1), finding that 1.1 worked best for all models except for Llama 3.2 1B IT, where 1.1 tied with the results of 1.075.For GSM8K for Llama 3.1 8B IT, we next tried a scale factor between 1.05 and the minimum scale factor we used (1.025), finding that 1.01 still worked best.Each scale factor considered increased performance across models for GSM8K.</p>
<p>For MATH, for small models, 1.01 or 1.05 worked best, while for Llama 3.1 8B IT, 1.01 worked best.For the smaller models, we next tried a scale factor between 1.01 and 1.05 (1.025), finding that 1.025 worked best for Llama 3.2 1B IT, Phi 1.5, and Llama 3.2 3B IT, and that 1.05 worked best for Gemma 2 2B IT.For MATH, scale factors beyond 1.05 either did not improve performance or harmed performance, suggesting a smaller scale factor is more optimal for this task.However, scale factors between 1.01 and 1.05 improved MATH performance across models.The results of this grid search for Llama 3.2 1B for GSM8K are displayed in Figure 51.</p>
<p>I Number and Location of Math-specific</p>
<p>Parameters Using MMLU as D non-math</p>
<p>Figures 52, 53, and 54 show the consistency of math-specific parameters, percentage of top parameters that are math-specific, and distribution of math-specific parameters identified by MathNeuro using MMLU as the non-math dataset, respectively, based on the experiments described in Section 4.5.</p>
<p>Prompt</p>
<p>Read this passage and answer the multiple choice question below it.</p>
<p>A newspaper reporter's job can be very interesting.He meets all types of people and lives quite a busy life.He is for news all the time,then after several years he may get a desk job,and life becomes a bit more settled.Let's look at his work a little more closely.In a day he may have to interview the prime minister of a foreign country, and the next day he may be writing about a football match.Sometimes he may be so busy that he hardly has any time to sleep.And at other times he may go on for days looking out for news materials yet return empty-handed.</p>
<p>In the beginning, a reporter has to cover a very wide field.After the early years he becomes more specialized in his work.For example, he may finaliy be asked to write only on court cases or politics or sports.Some reporters may become so specialized that they are asked only to write on a special thing: horse racing, for example.In most newspaper houses there is at least one special racing correspondent.Some newspapers have book reviews.Their job is delightful.They read the latest book and then write reviews on the ones they like.Then there are those who write on fdms, so they get to see them even before they are shown in the cinema.How lucky, you would say!A reporter's job can also be very dangerous.If there is a flood or a riot they may get hurt or even be killed.Three years ago there was a reporter whose camera was destroyed by a group of men, because they were angry with him for taking their picture.</p>
<p>Prompt</p>
<p>Question: A 30-year-old nulliparous female presents to the office with the complaint of mood changes.She says that for the past several months she has been anxious, hyperactive, and unable to sleep 3 to 4 days prior to the onset of menses.She further reports that on the day her menses begins she becomes acutely depressed, anorectic, irritable, and lethargic.She has no psychiatric history.Physical examination findings are normal.She and her husband have been trying to conceive for over 2 years.History reveals a tuboplasty approximately 1 year ago to correct a closed fallopian tube.The most likely diagnosis is Answer choices: ['adjustment disorder with depressed mood', 'bipolar I disorder, mixed', 'cyclothymic personality', 'generalized anxiety disorder']</p>
<p>Response Before Pruning (correct; hit max number of output tokens) Answer: A Explanation: The patient's symptoms of mood changes, anxiety, hyperactivity, inability to sleep, acute depression, anorexia, irritability, and lethargy, particularly in the context of her history of tuboplasty, are characteristic of adjustment disorder with depressed mood.The patient's anxiety, hyperactivity, and acute depression in the premenstrual phase of her are also consistent with this diagnosis.The mixed presentation of mood changes is also consistent with this diagnosis, as bipolar I disorder, mixed type typically involves a combination of manic and depressive episodes.Cyclothymic personality disorder is characterized by periods of hypomania and depression that last for at least 2 years.Generalized anxiety disorder is characterized by excessive worry and</p>
<p>Response After Pruning Based on RACE as D non-math (correct) Answer: 'adjustment disorder with depressed mood' The most likely diagnosis is adjustment disorder with depressed mood.This is a condition where the person's symptoms of depression are triggered by a stressful event, but the symptoms are not severe enough to meet the criteria for a major depressive disorder.The symptoms of depression are typically present for at least two days, are persistent, and are severe enough to cause significant distress or impairment in social or work functioning.The diagnosis of adjustment disorder with depressed mood is typically made based on the criteria outlined in the DSM-IV.The symptoms of depression in adjustment disorder with depressed mood include: 1. Depressed mood 2. Loss of interest in activities 3. Insomnia or hypersomnia 4. Fatigue</p>
<p>Response After Pruning Based on MMLU as D non-math (incorrect; hit max number of output tokens) Answer: B Explanation: A 30-year-old nulliparous female presenting with mood changes is a classic presentation for bipolar disorder, particularly in the early stages.The patient's symptoms of irritability, lethargy, and an acute depression during menses are classic for a manic episode.The history of tuboplasty is a significant clue that points towards a bipolar disorder, especially given the rapid onset of symptoms and the pattern of episodes.The patient's past history of depression and the fact that she and her husband have been trying to conceive for over 2 years suggests a pattern of mood instability and possibly a depressive episode.The most likely diagnosis is bipolar I disorder, mixed.The symptoms of mood changes, irritability, lethargy, and</p>
<p>Prompt</p>
<p>Question: A 30-year-old nulliparous female presents to the office with the complaint of mood changes.She says that for the past several months she has been anxious, hyperactive, and unable to sleep 3 to 4 days prior to the onset of menses.She further reports that on the day her menses begins she becomes acutely depressed, anorectic, irritable, and lethargic.She has no psychiatric history.Physical examination findings are normal.She and her husband have been trying to conceive for over 2 years.History reveals a tuboplasty approximately 1 year ago to correct a closed fallopian tube.The most likely diagnosis is Answer choices: ['adjustment disorder with depressed mood', 'bipolar I disorder, mixed', 'cyclothymic personality', 'generalized anxiety disorder']</p>
<p>Response Before Scaling (correct; hit max number of output tokens) Answer: A Explanation: The patient's symptoms of mood changes, anxiety, hyperactivity, inability to sleep, acute depression, anorexia, irritability, and lethargy, particularly in the context of her history of tuboplasty, are characteristic of adjustment disorder with depressed mood.The patient's anxiety, hyperactivity, and acute depression in the premenstrual phase of her cycle are also consistent with this diagnosis.The mixed presentation of mood changes is also consistent with this diagnosis, as bipolar I disorder, mixed type typically involves a combination of manic and depressive episodes.Cyclothymic personality disorder is characterized by periods of hypomania and depression that last for at least 2 years.Generalized anxiety disorder is characterized by excessive worry and</p>
<p>Response After Scaling Based on RACE as D non-math (correct; hit max number of output tokens) Answer: A Explanation: The patient's symptoms of mood changes (anxiety, hyperactivity, irritability, lethargy) and the physical symptoms (anorexia) of anorexia nervosa, which are typically seen in the context of hormonal fluctuations, are consistent with this diagnosis.The physical symptoms of anorexia nervosa are also consistent with the tubal surgery.The patient's symptoms do not meet the criteria for a manic episode (i.e., she is not hyperactive or irritable for more than one week), and her symptoms do not meet the criteria for a depressive episode (i.e., she is not depressed for more than two weeks).The patient's age and the fact that she is trying to conceive do not support</p>
<p>Response After Scaling Based on MMLU as D non-math (correct; hit max number of output tokens) Answer: A Explanation: The patient's symptoms of mood changes, anxiety, hyperactivity, and sleep disturbances, particularly in the context of her menstrual cycle, are characteristic of premenstrual syndrome (PMS).The patient's history of tuboplasty and the timing of her symptoms suggest that she may be experiencing a cyclical pattern of mood changes, which is a hallmark of bipolar I disorder.The patient's symptoms are also consistent with a diagnosis of adjustment disorder with depressed mood, which is a type of mood disorder that occurs in response to a significant life stressor.The patient's symptoms are not consistent with cyclothymic personality or generalized anxiety disorder, which do not typically present with such a cyclical pattern of mood changes.The best answer</p>
<p>Figure 1 :
1
Figure 1: Overview of MathNeuro.First, we sum weights times activations over N samples for math and non-math inputs, finding the top-K parameters for each input type.Next, we find math-specific parameters by filtering out parameters important for non-math inputs.</p>
<p>Figure 2 :
2
Figure 2: Effect of pruning identified parameters on math and non-math performance for Llama 3.2 1B IT with TopK  ℎ = TopK − ℎ = 15%.Ideal methods fall in the top left of the plot.MMLU and RACE denote the dataset used as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point.</p>
<p>Figure 4 :Figure 5 :Figure 6 :
456
Figure 4: Effect of pruning identified parameters on math and non-math performance for Llama 3.2 1B IT with TopK  ℎ = TopK − ℎ = 10% based on one sample.Ideal methods fall in the top left of the plot.MMLU and RACE denote the dataset used as D non-math .Horizontal/vertical lines show each point's 95% confidence intervals.</p>
<p>Figure 7 :
7
Figure 7: Percentage of top parameters that are mathspecific as identified by MathNeuro for Llama 3.2 1B IT when identifying using GSM8K compared to RACE.</p>
<p>Figure 8 :
8
Figure 8: Distribution of math-specific parameters identified by MathNeuro for Llama 3.2 1B IT when identifying using GSM8K compared to RACE.</p>
<p>FiguresFigure 9 :Figure 10 :
910
Figures 22, 23, 24 and 25  show the results for scaling parameters identified by each method for Phi 1.5, Gemma 2 2B IT, Llama 3.2 3B IT, and Llama 3.1 8B IT, respectively, when calculating parameter importance based on one sample.As shown in these figures, the results for each model closely</p>
<p>Figure 15 :
15
Figure 15: Effect of scaling identified parameters by 1.1 on math and non-math performance for Gemma 2 2B IT based on calculating the top 5% of parameters.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.</p>
<p>Figure 26 :Figure 27 :Figure 28 :Figure 29 :Figure 30 :Figure 31 :Figure 32 :Figure 33 :Figure 34 :Figure 35 :
26272829303132333435
Figure26: Effect of pruning identified parameters on performance for unseen math and non-math tasks for Llama 3.2 1B IT when using GSM8K as D math and MMLU or Race as D non-math .Ideal methods for the first two rows of figures should fall in the top left of the plot, while ideal methods for the last two rows of figures should fall in the bottom left of the plot.Wanda results are not pictured in the Wikitext figures because PPL increased dramatically when using this method.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.</p>
<p>Figure 51 :
51
Figure 51: Impact of MathNeuro scale factor on GSM8K performance for Llama 3.2 1B IT.</p>
<p>Figure 52 :
52
Figure52: Consistency of math-specific parameters identified by MathNeuro for Llama 3.2 1B IT when identifying using GSM8K compared to MMLU.</p>
<p>Figure 53 :
53
Figure53: Percentage of top parameters that are mathspecific as identified by MathNeuro for Llama 3.2 1B IT when identifying using GSM8K compared to MMLU.</p>
<p>Math-specific Parameters Per Layer</p>
<p>Figure 54 :
54
Figure 54: Distribution of math-specific parameters identified by MathNeuro for Llama 3.2 1B IT when identifying using GSM8K compared to MMLU.</p>
<p>TopK − ℎ = 5%.Ideal methods fall in the top right of the plot.MMLU and RACE denote the dataset used as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point.
0.400.47MethodRACE Accuracy0.36 0.37 0.38 0.39MMLU Accuracy0.43 0.44 0.45 0.46Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE0.350.30 GSM8K CoT Accuracy 0.350.420.30 GSM8K CoT Accuracy 0.35Figure 3: Effect of scaling identified parameters by 1.1 on math and non-math performance for Llama 3.2 1B ITwith TopK 𝑚𝑎𝑡 ℎ =21, Math-Neuro performs best at isolating math-specific pa-</p>
<p>Effect of pruning identified parameters on math and non-math performance for Llama 3.2 3B IT based on calculating the top 2.5% (left) and 1% (right) of parameters.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of pruning identified parameters on math and non-math performance for Llama 3.1 8B IT based on calculating the top 1% of parameters.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.
0.0 GSM8K CoT Accuracy by Method and Parameter Proportion for Pruning Identified Parameters 0.2 0.4 0.6 GSM8K CoT Accuracy 0.0 0.2 0.4 0.6 GSM8K CoT Accuracy 0.3 0.4 0.5 0.6 MMLU Accuracy Method Base Model 0.5 0.25 0.30 0.35 0.40 Method LAPE Wanda LAPE Random-MMLU 0.4 Wanda Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.2 0.4 0.6 0.8 GSM8K CoT Accuracy 0.20 0.25 0.30 0.35 0.40 0.45 0.0 0.2 0.4 0.6 0.8 GSM8K CoT Accuracy 0.3 0.4 0.5 0.6 0.7 MMLU Accuracy Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 Proportion of Top Parameters Calculated 0.1 0.0 Figure 11: 0.0 RACE Accuracy RACE Accuracy 0.1 0.2 0.3 Random-MMLU Base GSM8K Accuracy Random-RACE MathNeuro (ours)-MMLU GSM8K CoT Accuracy MathNeuro (ours)-RACEFigure 12: 700 samples and for EGSM we use 100 due to itsures 31, 32, 33, 34, and 35, our GSM8K pruningsmaller size.results replicate when using MATH as the mathF MathNeuro Using the MATH Datasetdataset, as pruning math-specific parameters Math-Neuro identifies effectively deletes MATH perfor-F.1 MATH Pruning Experiments We replicate our GSM8K pruning experiments us-ing MATH as the math dataset and MMLU or RACE as the non-math dataset. Similar to our approach with GSM8K, we subset the MATH test-ing split to the same 700 random samples for each model and experimental run for experimental ef-ficiency. As with our other experiments, we use the Eleuther AI LM Evaluation Harness (Gao et al., 2024) for implementing the MATH evaluations, us-. For MATH, we use Eleuther's implementation of the 4-shot CoT Minerva prompt and for EGSM we use a fork mance while leaving MMLU and RACE perfor-mance largely unaltered. These results buttress those reported in Section 4.6 by showing that Math-Neuro's effectiveness in isolating math-specific pa-rameters holds when using a different math dataset. of the Eleuther AI LM Evaluation Harness where we implemented the task using GSM8K's 8-shot CoT prompt given they are both grade school math datasets. For all tasks except MATH and EGSM, Using the same hyperparameters, we also repli-we run evaluations using the full testing split for cate our one sample pruning experiments usinging their default implementation of the MinervaMATH as D math . Results are shown in FiguresMATH prompt with 4-shot CoT examples. For36, 37, 38, 39, and 40, where MathNeuro still per-each model, we use the exact same hyperparame-forms best at isolating math-specific parametersters as those reported for the pruning experimentswhen using a single MATH sample for parameterin Section 4.2 and Appendix A. As shown in Fig-identification.
each task given they are in multiple-choice format.For MATH and EGSM, which require long-form responses, we follow our other experiments by using the same set of random samples from each dataset for experimental efficiency.For MATH, we use Figure13: Impact of parameter proportion on GSM8K performance for pruning parameters identified by each method for Llama 3.2 1B IT when considering the top .01,.1,.5, 1, 2.5, 5, 10 and 15% of parameters.</p>
<p>Effect of scaling identified parameters by 1.1 on math and non-math performance for Phi 1.5 based on calculating the top .1% (left) and .01%(right) of parameters.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.
0.390.43MethodRACE Accuracy0.36 0.37 0.38MMLU Accuracy0.42 0.39 0.40 0.41Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE0.350.380.340.270.28 GSM8K CoT Accuracy 0.29 0.300.310.370.270.28 GSM8K CoT Accuracy 0.29 0.300.310.46 GSM8K CoT Accuracy 0.48 Figure 14: 0.44 0.48 0.40 0.42 0.44 0.46 RACE AccuracyMMLU Accuracy0.50 0.60 0.52 0.54 0.56 0.580.44 GSM8K CoT Accuracy 0.46 0.48Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE</p>
<p>Effect of scaling identified parameters by 1.1 on math and non-math performance for Llama 3.2 3B IT based on calculating the top 5% of parameters.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of pruning identified parameters on math and non-math performance for Gemma 2 2B IT for calculating the top 2.5% of parameters based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.1 on math and non-math performance for Phi 1.5 for calculating the top .1% of parameters based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.1 on math and non-math performance for Gemma 2 2B IT for calculating the top 2.5% of parameters based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.01 on math and non-math performance for Llama 3.1 8B IT for calculating the top 1% of parameters based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.
0.64 GSM8K CoT Accuracy 0.66 0.68 Figure 16: 0.77 0.39 0.40 0.41 0.42 0.43 0.44 0.45 RACE Accuracy 0.78 0.79 GSM8K CoT Accuracy 0.42 0.43 0.44 0.45 0.46 0.47 RACE Accuracy 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.70 0.80 GSM8K CoT Accuracy 0.225 0.250 0.275 0.300 0.325 0.350 0.375 RACE Accuracy 0.0 0.1 0.2 0.3 0.4 GSM8K CoT Accuracy 0.20 0.25 0.30 0.35 0.40 0.45 RACE Accuracy Figure 19: 0.0 0.2 0.4 0.6 GSM8K CoT Accuracy 0.25 0.30 0.35 0.40 RACE Accuracy 0.0 0.2 0.4 0.6 0.8 GSM8K CoT Accuracy 0.20 0.25 0.30 0.35 0.40 0.45 RACE Accuracy 0.27 0.28 0.29 0.30 0.31 0.32 GSM8K CoT Accuracy 0.34 0.35 0.36 0.37 0.38 0.39 RACE Accuracy 0.52 0.54 0.56 0.58 0.60 WinoGrande Accuracy 0.50 Figure 22: 0.375 0.400 0.425 0.450 GSM8K CoT Accuracy 0.40 0.42 0.44 0.46 0.48 RACE Accuracy 0.77 0.78 0.79 GSM8K CoT Accuracy 0.42 0.43 0.44 0.45 0.46 0.47 RACE Accuracy 0.1 0.2 0.3 GSM8K CoT Accuracy 0.0 0.1 0.2 0.3 GSM8K CoT Accuracy 0.50 0.55 0.60 0.65 0.70 0.75 PIQA Accuracy 50 Figure 25: 0.0 0.0 0.1 0.2 0.3 GSM8K CoT Accuracy 0 20 30 40 Wikitext PPL 10 0.15 Figure 23: 0.64 0.66 0.68 0.70 GSM8K CoT Accuracy 0.39 0.40 0.41 0.42 0.43 0.44 0.45 RACE Accuracy 0.0 0.1 0.2 0.3 GSM8K CoT Accuracy 0.00 0.05 0.10 MATH Accuracy0.64 GSM8K CoT Accuracy 0.66 0.68 0.77 0.78 0.79 GSM8K CoT Accuracy 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.70 0.80 GSM8K CoT Accuracy 0.0 0.225 0.58 0.59 0.60 0.61 0.62 0.64 0.65 0.66 0.67 0.68 0.69 MMLU Accuracy MMLU Accuracy 0.250 0.275 0.300 0.325 0.350 0.375 0.400 MMLU Accuracy 0.1 0.2 0.3 0.4 GSM8K CoT Accuracy 0.3 0.4 0.5 MMLU Accuracy 0.0 0.2 0.4 0.6 GSM8K CoT Accuracy 0.3 0.4 0.5 0.6 MMLU Accuracy 0.0 0.2 0.4 0.6 0.8 GSM8K CoT Accuracy 0.3 0.4 0.5 0.6 0.7 MMLU Accuracy 0.38 0.39 0.40 0.41 0.42 0.43 MMLU Accuracy 0.220 0.225 0.230 0.235 MuTual Accuracy 0.215 0.37 0.27 0.28 0.29 0.30 0.31 0.32 GSM8K CoT Accuracy 0.375 0.400 0.425 0.450 GSM8K CoT Accuracy 0.50 0.52 0.54 0.56 0.58 0.60 MMLU Accuracy 0.77 0.78 0.79 GSM8K CoT Accuracy 0.64 0.65 0.66 0.67 0.68 0.69 MMLU Accuracy 0.0 0.1 0.2 0.3 GSM8K CoT Accuracy 0.0 0.1 0.2 0.3 GSM8K CoT Accuracy 0.3 0.4 0.5 0.6 HellaSwag Accuracy 0.325 0.225 0.250 0.275 0.300 MathQA Accuracy 0.0 0.1 0.2 0.3 GSM8K CoT Accuracy 0.200 0.5 0.64 0.66 0.68 GSM8K CoT Accuracy 0.70 0.58 0.59 0.60 0.61 0.62 0.0 0.1 0.2 GSM8K CoT Accuracy 0.3 0.0 MMLU Accuracy 0.1 0.2 0.3 0.4 EGSM AccuracyMethod Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE
Figure 17: Effect of scaling identified parameters by 1.01 on math and non-math performance for Llama 3.1 8B IT based on calculating the top .5% of parameters.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Figure 18: Effect of pruning identified parameters on math and non-math performance for Phi 1.5 for calculating the top .5% of parameters based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Figure 20: Effect of pruning identified parameters on math and non-math performance for Llama 3.2 3B IT for calculating the top 10% of parameters based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Figure21: Effect of pruning identified parameters on math and non-math performance for Llama 3.1 8B IT for calculating the top 5% of parameters based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Figure24: Effect of scaling identified parameters by 1.1 on math and non-math performance for Llama 3.2 3B IT for calculating the top 5% of parameters based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.</p>
<p>Effect of pruning identified parameters on math and non-math performance for Llama 3.2 1B IT based on calculating the top 15% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of pruning identified parameters on math and non-math performance for Phi 1.5 based on calculating the top 5% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of pruning identified parameters on math and non-math performance for Gemma 2 2B IT based on calculating the top 5% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of pruning identified parameters on math and non-math performance for Llama 3.2 3B IT based on calculating the top 2.5% (left) and 1% (right) of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of pruning identified parameters on math and non-math performance for Llama 3.1 8B IT based on calculating the top 1% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top left of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.025 on math and non-math performance for Llama 3.2 1B IT based on calculating the top .5% of parameters using the MATH dataset as D math .Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.025 on math and non-math performance for Phi 1.5 based on calculating the top 15% of parameters using the MATH dataset as D math .Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.05 on math and non-math performance for Gemma 2 2B IT based on calculating the top .5% of parameters using the MATH dataset as D math .Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.025 on math and non-math performance for Llama 3.2 3B IT based on calculating the top 10% of parameters using the MATH dataset as D math .Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.01 on math and non-math performance for Llama 3.1 8B IT based on calculating the top 2.5% of parameters using the MATH dataset as D math .Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.025 on math and non-math performance for Llama 3.2 1B IT based on calculating the top .5% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.025 on math and non-math performance for Phi 1.5 based on calculating the top 10% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.025 on math and non-math performance for Llama 3.2 3B IT based on calculating the top .01% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.Effect of scaling identified parameters by 1.01 on math and non-math performance for Llama 3.1 8B IT based on calculating the top 10% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.
0.00 Figure 36: 0.00 0.25 0.30 0.35 RACE Accuracy 0.25 0.30 0.35 RACE Accuracy Figure 37: 0.00 0.25 0.30 0.35 0.40 0.45 RACE Accuracy Figure 38: 0.0 0.25 0.30 0.35 0.40 RACE Accuracy Figure 39: 0.0 0.20 0.25 0.30 0.35 0.40 0.45 RACE Accuracy Figure 40: 0.135 0.140 0.145 0.150 0.155 0.160 0.165 0.05 0.10 0.15 MATH Accuracy 0.01 0.02 0.03 MATH Accuracy 0.05 0.10 0.15 MATH Accuracy 0.1 0.2 0.3 MATH Accuracy 0.1 0.2 MATH Accuracy MATH Accuracy 0.32 0.34 0.36 0.38 0.40 0.42 RACE Accuracy Figure 41: 0.014 0.016 0.018 0.020 0.022 0.024 0.026 MATH Accuracy 0.34 0.35 0.36 0.37 0.38 0.39 RACE Accuracy Figure 42: 0.160 0.165 0.170 0.175 0.180 0.185 0.190 MATH Accuracy 0.38 0.40 0.42 0.44 0.46 RACE Accuracy 0.42 Figure 43: 0.26 0.27 0.28 0.29 MATH Accuracy 0.36 0.38 0.40 0.42 0.44 RACE Accuracy Figure 44: 0.26 0.27 0.28 MATH Accuracy 0.40 0.42 0.44 0.46 0.48 0.50 RACE Accuracy 0.15 0.16 0.17 MATH Accuracy 0.32 0.34 0.36 0.38 0.40 RACE Accuracy 0.38 0.40 0.42 0.44 RACE Accuracy Figure 45: 0.14 0.275 0.280 0.285 0.290 0.295 MATH Accuracy 0.36 Figure 46: 0.0125 0.0150 0.0175 0.0200 0.0225 0.0250 MATH Accuracy 0.34 0.35 0.36 0.37 0.38 0.39 RACE Accuracy Figure 47: 0.165 0.170 0.175 0.180 0.185 0.190 0.195 MATH Accuracy 0.38 0.40 0.42 0.44 0.46 RACE Accuracy 0.270 0.275 MATH Accuracy 0.40 0.42 0.44 0.46 0.48 0.50 RACE Accuracy Figure 50: 1.00 1.02 0.34 0.35 0.36 0.37 0.38 0.39 GSM8K CoT Accuracy Base GSM8K Accuracy MMLU Accuracy MMLU Accuracy 0.25 0.30 0.35 0.40 0.45 0.25 0.30 0.35 0.40 0.00 0.00 0.00 0.3 0.4 0.5 MMLU Accuracy 0.0 0.3 0.4 0.5 0.6 MMLU Accuracy 0.0 0.3 0.4 0.5 0.6 MMLU Accuracy 0.135 0.140 0.145 0.150 0.155 0.160 0.165 0.05 0.10 0.15 MATH Accuracy 0.01 0.02 0.03 MATH Accuracy 0.05 0.10 0.15 MATH Accuracy 0.1 0.2 0.3 MATH Accuracy 0.1 0.2 MATH Accuracy MATH Accuracy 0.40 0.42 0.44 0.46 0.48 0.50 MMLU Accuracy 0.014 0.016 0.018 0.020 0.022 0.024 0.026 MATH Accuracy 0.37 0.38 0.39 0.40 0.41 0.42 0.43 MMLU Accuracy 0.160 0.165 0.170 0.175 0.180 0.185 0.190 Base Model Method LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE MATH Accuracy 0.50 0.52 0.54 0.56 0.58 0.60 MMLU Accuracy 0.50 Method Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.26 0.27 0.28 0.29 MATH Accuracy 0.50 0.52 0.54 0.56 0.58 0.60 0.62 0.64 MMLU Accuracy Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.26 0.27 0.28 MATH Accuracy 0.62 0.64 0.66 0.68 0.70 0.72 MMLU Accuracy Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.14 0.15 0.16 0.17 MATH Accuracy 0.40 0.42 0.44 0.46 Base Model 0.48 LAPE Wanda Random-MMLU Random-RACE MMLU Accuracy MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.64 Method 0.54 0.56 0.58 0.60 Base Model 0.62 LAPE Wanda MMLU Accuracy Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.275 0.280 0.285 0.290 0.295 MATH Accuracy 0.50 0.52 0.0125 0.0150 0.0175 0.0200 0.0225 0.0250 MATH Accuracy 0.37 0.38 0.39 0.40 0.41 0.42 0.43 MMLU Accuracy Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE MATH Accuracy 0.165 0.170 0.175 0.180 0.185 0.190 0.195 0.50 0.52 0.54 0.56 0.58 0.60 MMLU Accuracy Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 0.265 0.270 0.275 MATH Accuracy 0.62 0.64 0.66 0.68 0.70 0.72 MMLU Accuracy Method Base Model LAPE Wanda Random-MMLU Random-RACE MathNeuro (ours)-MMLU MathNeuro (ours)-RACE 1.04 1.06 1.08 1.10 MathNeuro Scale Factor Figure 49: 0.265 GSM8K CoT Accuracy by MathNeuro Scale Factor
Figure48: Effect of scaling identified parameters by 1.05 on math and non-math performance for Gemma 2 2B IT based on calculating the top 1% of parameters using the MATH dataset as D math based on one sample.Ideal methods should fall in the top right of the plot.MMLU and RACE denote that a point was calculated using MMLU or RACE, respectively, as D non-math .Horizontal and vertical lines represent 95% confidence intervals for each point on the plot.</p>
<p>Dangerous or not, one thing is certain, and that is, their job is never dull!Question: Reporters who write on films are said to be lucky because they[blank].Answer choices: ['can write anything they like', 'can see more film stars', 'can pay less than other people', 'can see the fdms before most people see them in the cinema']
Response After Scaling Based on RACE as D non-math (incorrect)Answer: AResponse After Scaling Based on MMLU as D non-math (incorrect)Answer: A
Response Before Interventions (incorrect) Answer: 'can see more film stars' Response After Pruning Based on RACE as D non-math (incorrect) Answer: 'can see more film stars' Response After Pruning Based on MMLU as D non-math (incorrect) Answer: A. 'can write anything they like'</p>
<p>Table 3 :
3
Responses to a RACE question before and after pruning or scaling parameters identified by MathNeuro for Llama 3 1B IT.</p>
<p>Table 4 :
4
Responses to a MMLU question before and after pruning parameters identified by MathNeuro for Llama 3 1B IT.</p>
<p>Table 5 :
5
Responses to a MMLU question before and after scaling parameters identified by MathNeuro for Llama 3 1B IT.</p>
<p>Our experimental code can be found at https://github.com/bryanchrist/MathNeuro
This summation is akin to gradient-based identification methods summing gradients over inputs (e.g.,Das et al. 2023).
Ethics StatementAll data used in this paper come from open-access datasets and, therefore, should not contain any private sensitive information.QuestionBetty is saving money for a new wallet which costs $100.Betty has only half of the money she needs.Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents.How much more money does Betty need to buy the wallet?Response Before Pruning (correct) Let's think step by step.Betty has half of the money she needs, which is 100/2 =50.She received $15 from her parents, so now she has $50 + $15 = $65.Her grandparents gave her twice as much as her parents, which is 2 x $15 = $30.Now she has $65 + $30 = $95.The wallet costs $100, so Betty needs $100 -$95 = $5 more to buy the wallet.Response After Pruning Based on RACE as D non-math (incorrect) Let's think step by step.First, let's determine the total amount needed to buy the wallet.$100 is the total amount needed to buy the wallet.Betty's parents gave her $15.Her grandparents gave her $2 as a gift.Betty's grandparents gave her $15 as a gift.Betty's parents gave her $15 as a gift.Betty's grandparents gave her $15 as a gift.Betty's parents gave her $15 as a gift.Betty's grandparents gave her $15 as a gift.Betty's grandparents gave her $15 as a gift.Betty's grandparents gave her $15 as a gift.Betty's grandparents gave her $15 as a gift.Betty's grandparents gave her $15 as a gift.Betty's grandparents gave her $15Response After Pruning Based on MMLU as D non-math (incorrect) A: Let's think step by step.Betty needs $100 to buy the wallet.Her parents gave her $15 for that purpose, and her grandparents gave her $15 twice as much as her parents.This is a 50-50 split.Betty's grandparents gave her $15 twice as much as her parents, which is $15.Therefore, Betty's grandparents gave her $15 twice as much as her parents.B: Let's think step by step.Betty's grandparents gave her $15 twice as much as her parents.This is a 50-50 split.Betty's grandparents gave her $15 twice as much as her parents.Therefore, Betty's grandparents gave her $15 twice as much as her parents.C: Let's think step by step.Betty'sQuestionThe profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively.If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?Response Before Scaling (incorrect) Let's think step by step.Mike's share of the profit is 2 parts, and Johnson's share is 5 parts.The total number of parts is 2 + 5 = 7. Johnson's share of the profit is 5/7 of the total profit.If Johnson got $2500, then Mike's share of the profit is 2/7 of the total profit.If Mike spent $200 on a shirt, then he will have $200 + (2/7) of the profit.The profit is 7/7 of the total profit, so Mike's share of the profit is 2/7 of 7/7, which is 2/7.Mike's share of the profit is $200 + (2/7) of the profit, which is $200 + (2/7)(7/7) = $200 + 2 = $202.The answer is $202.Response After Scaling Based on RACE as D non-math (incorrect) Let's think step by step.Mike's share of the profit is 2 parts, and Johnson's share is 5 parts.The total number of parts is 2 + 5 = 7. Johnson's share is 5/7 of the total profit.Therefore, Mike's share is 2/7 of the total profit.Mike's share is 2/7 × $2500 = $142.86.Mike will have $142.86after spending $200 on a shirt.Response After Scaling Based on MMLU as D non-math (correct) Let's think step by step.Mike's share of the profit is 2 parts, and Johnson's share is 5 parts.The total number of parts is 2 + 5 = 7. Johnson's share is 5/7 of the total profit.If Johnson got $2500, then Mike's share is 2/7 of the total profit.If Mike spent $200 on a shirt, how much profit will he have left?To find Mike's profit, we need to find the total profit first.We can set up the following proportion: 2/7 = 2500/$x, where x is the total profit.Crossmultiplying, we get 2x = 2500(7).Dividing both sides by 2, we get x = 3500.Now that we know the total profit, we can find Mike's profit: Mike's share is 2/7 of the total profit, so Mike's profit is 2/7(3500) = 1000.Finally, we can find out how much profit Mike will have left after spending $200 on a shirt: Mike's profit -$200 = $800.The answer is $800.
Rishabh Agarwal, Avi Singh, Lei M Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang, Ankesh Anand, Zaheer Abbas, Azade Nova, John D Co-Reyes, Eric Chu, Feryal Behbahani, Aleksandra Faust, Hugo Larochelle, 10.48550/arXiv.2404.11018ArXiv:2404.11018Many-Shot In-Context Learning. 2024arXiv preprint</p>
<p>Large Language Models for Mathematical Reasoning: Progresses and Challenges. Janice Ahn, Rishu Verma, Renze Lou, Di Liu, Rui Zhang, Wenpeng Yin, ArXiv:2402.001572024arXiv preprint</p>
<p>Aida Amini, Saadia Gabriel, Peter Lin, Rik Koncel-Kedziorski, Yejin Choi, Hannaneh Hajishirzi, 10.48550/arXiv.1905.13319ArXiv:1905.13319MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms. 2019arXiv preprint</p>
<p>Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, James Glass, 10.48550/arXiv.1811.01157ArXiv:1811.01157Identifying and Controlling Important Neurons in Neural Machine Translation. 2018arXiv preprint</p>
<p>PIQA: Reasoning about Physical Commonsense in Natural Language. Yonatan Bisk, Rowan Zellers, Le Ronan, Jianfeng Bras, Yejin Gao, Choi, 10.1609/aaai.v34i05.6239Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2020345</p>
<p>Large Language Monkeys: Scaling Inference Compute with Repeated Sampling. Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V Le, Christopher Ré, Azalia Mirhoseini, 10.48550/arXiv.2407.21787ArXiv:2407.217872024arXiv preprint</p>
<p>Do Localization Methods Actually Localize Memorized Data in LLMs? A Tale of Two Benchmarks. Ting-Yun Chang, Jesse Thomason, Robin Jia, 10.18653/v1/2024.naacl-long.176Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMexico City, Mexico20241Association for Computational Linguistics</p>
<p>MATHWELL: Generating Educational Math Word Problems Using Teacher Annotations. Jonathan Bryan R Christ, Thomas Kropko, Hartvigsen, Findings of the Association for Computational Linguistics: EMNLP 2024. Miami, Florida, USAAssociation for Computational Linguistics2024</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, 10.48550/arXiv.2110.14168ArXiv:2110.14168Training Verifiers to Solve Math Word Problems. 2021arXiv preprint</p>
<p>MuTual: A Dataset for Multi-Turn Dialogue Reasoning. Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang, Ming Zhou, 10.48550/arXiv.2004.04494ArXiv:2004.044942020arXiv preprint</p>
<p>Knowledge Neurons in Pretrained Transformers. Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, Furu Wei, 10.18653/v1/2022.acl-long.581Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221</p>
<p>What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models. Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, Anthony Bau, James Glass, 2018</p>
<p>Fahim Dalvi, Hassan Sajjad, Nadir Durrani, Yonatan Belinkov, Pretrained Transformer Models. 2020</p>
<p>Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning. Sarkar Snigdha, Sarathi Das, Ranran Haoran Zhang, Peng Shi, Wenpeng Yin, Rui Zhang, 10.48550/arXiv.2311.03748ArXiv:2311.037482023arXiv preprint</p>
<p>A framework for few-shot language model evaluation. Leo Gao, Jonathan Tow, Stella Baber Abbasi, Sid Biderman, Anthony Black, Charles Dipofi, Laurence Foster, Jeffrey Golding, Alain Hsu, Haonan Le Noac'h, Kyle Li, Niklas Mcdonell, Chris Muennighoff, Jason Ociepa, Laria Phang, Hailey Reynolds, Aviya Schoelkopf, Lintang Skowron, Eric Sutawika, Anish Tang, Ben Thite, Kevin Wang, Andy Wang, Zou, 10.5281/zenodo.126086022024Version Number: v0.4.3</p>
<p>Finding Neurons in a Haystack: Case Studies with Sparse Probing. Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, Dimitris Bertsimas, 2023</p>
<p>How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. Michael Hanna, Ollie Liu, Alexandre Variengien, Advances in Neural Information Processing Systems. 202336</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, 10.48550/arXiv.2009.03300ArXiv:2009.03300Measuring Massive Multitask Language Understanding. 2021aarXiv preprint</p>
<p>Measuring Mathematical Problem Solving With the MATH Dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, 10.48550/arXiv.2103.03874ArXiv:2103.038742021barXiv preprint</p>
<p>Takeshi Kojima, Itsuki Okimura, Yusuke Iwasawa, Hitomi Yanaka, Yutaka Matsuo, 10.48550/arXiv.2404.02431ArXiv:2404.02431On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons. 2024arXiv preprint</p>
<p>RACE: Large-scale ReAding Comprehension Dataset From Examinations. Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, Eduard Hovy, 10.18653/v1/D17-1082Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational Linguistics2017</p>
<p>Nicholas Lee, Thanakul Wattanawong, Sehoon Kim, Karttikeya Mangalam, Sheng Shen, Gopala Anumanchipalli, Michael W Mahoney, Kurt Keutzer, Amir Gholami, LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement. 2024</p>
<p>Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons. Yongqi Leng, Deyi Xiong, 10.48550/arXiv.2407.06488ArXiv:2407.064882024arXiv preprint</p>
<p>Chen Li, Weiqi Wang, Jingcheng Hu, Yixuan Wei, Nanning Zheng, Han Hu, Zheng Zhang, Houwen Peng, ArXiv:2403.04706Common 7B Language Models Already Possess Strong Math Capabilities. 2024aarXiv preprint</p>
<p>Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, Wei Bi, 10.48550/arXiv.2402.19255ArXiv:2402.19255GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers. 2024barXiv preprint</p>
<p>Textbooks Are All You Need II: phi-1.5 technical report. Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, Yin Tat, Lee , 10.48550/arXiv.2309.05463ArXiv:2309.054632023arXiv preprint</p>
<p>An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning. Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, Yue Zhang, 10.48550/arXiv.2308.08747ArXiv:2308.087472024arXiv preprint</p>
<p>Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher, _eprint: 1609.07843Pointer Sentinel Mixture Models. 2016</p>
<p>Introducing Llama 3.1: Our most capable models to date. Metaai, 2024a</p>
<p>Llama 3.2: Revolutionizing edge AI and vision with open, customizable models. Metaai, 2024b</p>
<p>Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics. Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov, 10.48550/arXiv.2410.21272ArXiv:2410.212722024arXiv preprint</p>
<p>Task-Specific Skill Localization in Fine-tuned Language Models. Abhishek Panigrahi, Nikunj Saunshi, Haoyu Zhao, Sanjeev Arora, Proceedings of the 40th International Conference on Machine Learning. the 40th International Conference on Machine Learning2023</p>
<p>Learning to Generate Reviews and Discovering Sentiment. Alec Radford, Rafal Jozefowicz, Ilya Sutskever, 2017</p>
<p>An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs. Daking Rai, Ziyu Yao, 10.48550/arXiv.2406.12288ArXiv:2406.122882024arXiv preprint</p>
<p>Rose E Wang, Ana T Ribeiro, Carly D Robinson, Susanna Loeb, Dora Demszky, 10.48550/arXiv.2410.03017ArXiv:2410.03017Tutor CoPilot: A Human-AI Approach for Scaling Real-Time Expertise. 2024arXiv preprint</p>
<p>Finding Skill Neurons in Pre-trained Transformer-based Language Models. Xiaozhi Wang, Kaiyue Wen, Zhengyan Zhang, Lei Hou, Zhiyuan Liu, Juanzi Li, 10.18653/v1/2022.emnlp-main.765Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu DhabiAssociation for Computational Linguistics2022United Arab Emirates</p>
<p>Yifan Wei, Xiaoyan Yu, Yixuan Weng, Huanhuan Ma, Yuanzhe Zhang, Jun Zhao, Kang Liu, 10.48550/arXiv.2409.00617ArXiv:2409.00617Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models. 2024arXiv preprint</p>
<p>Huajian Xin, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu, Chong Ruan, Wenda Li, Xiaodan Liang, 10.48550/arXiv.2405.14333ArXiv:2405.14333DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data. 2024arXiv preprint</p>
<p>What Part of the Neural Network Does This? Understanding LSTMs by Measuring and Dissecting Neurons. Ji Xin, Jimmy Lin, Yaoliang Yu, 10.18653/v1/D19-1591Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational Linguistics2019</p>
<p>Fangcong Yin, Xi Ye, Greg Durrett, 10.48550/arXiv.2406.01563ArXiv:2406.01563LoFiT: Localized Fine-tuning on LLM Representations. 2024arXiv preprint</p>
<p>HellaSwag: Can a Machine Really Finish Your Sentence?. Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi, 10.48550/arXiv.1905.07830ArXiv:1905.078302019arXiv preprint</p>
<p>Interpreting and Improving Large Language Models in Arithmetic Calculation. Wei Zhang, Chaoqun Wan, Yonggang Zhang, Yiu-Ming Cheung, Xinmei Tian, Xu Shen, Jieping Ye, 10.48550/arXiv.2409.01659ArXiv:2409.016592024arXiv preprint</p>
<p>How do Large Language Models Handle Multilingualism?. Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, Lidong Bing, 10.48550/arXiv.2402.18815ArXiv:2402.188152024arXiv preprint</p>
<p>Language Models Encode the Value of Numbers Linearly. Fangwei Zhu, Damai Dai, Zhifang Sui, Proceedings of the 31st International Conference on Computational Linguistics. the 31st International Conference on Computational LinguisticsAbu Dhabi, UAE2025Association for Computational Linguistics</p>            </div>
        </div>

    </div>
</body>
</html>