<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9756 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9756</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9756</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-a2cae38a542a77c8fdb1d38350b58efd60cf12eb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a2cae38a542a77c8fdb1d38350b58efd60cf12eb" target="_blank">ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification</a></p>
                <p><strong>Paper Venue:</strong> Neurocomputing</p>
                <p><strong>Paper Abstract:</strong> In the era of sustainable smart agriculture, a massive amount of agricultural news text is being posted on the Internet, in which massive agricultural knowledge has been accumulated. In this context, it is urgent to explore effective text classification techniques for users to access the required agricultural knowledge with high efficiency. Mainstream deep learning approaches employing fine-tuning strategies on pre-trained language models (PLMs), have demonstrated remarkable performance gains over the past few years. Nonetheless, these methods still face many drawbacks that are complex to solve, including: 1. Limited agricultural training data due to the expensive-cost and labour-intensive annotation; 2. Poor domain transferability, especially of cross-linguistic ability; 3. Complex and expensive large models deployment.Inspired by the extraordinary success brought by the recent ChatGPT (e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore the capability and utilization of ChatGPT applying to the agricultural informatization field. ....(shown in article).... Code has been released on Github https://github.com/albert-jin/agricultural_textual_classification_ChatGPT.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9756",
    "paper_id": "paper-a2cae38a542a77c8fdb1d38350b58efd60cf12eb",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.005556,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Highlights</h1>
<h2>ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification</h2>
<p>Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang</p>
<ul>
<li>Inspired by the success of ChatGPT, we propose ChatAgri, a ChatGPT-based approach for agricultural text classification.</li>
<li>We have designed several appropriate task-specific prompt inquiries strategies to intuitively trigger the understanding capability of ChatGPT based on ChatGPT prompt templates.</li>
<li>ChatAgri achieves competitive performance compared to existing PLM-based fine-tuning approaches, showing superior semantic understanding.</li>
<li>Zero-shot learning experiments demonstrate ChatAgri's potential for agricultural text classification, compared to existing PLM-based fine-tuning approaches.</li>
<li>Multi-linguistic experiments discussed demonstrate ChatAgri's excellent cross-linguistic transferability, enabling the model to adapt to different agricultural applications quickly.</li>
</ul>
<h1>ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic Agricultural Text Classification</h1>
<p>Biao Zhao ${ }^{\mathrm{a}, <em>}$, Weiqiang Jin ${ }^{\mathrm{a}, </em>}$, Javier Del Ser ${ }^{\mathrm{b}}$, Guang Yang ${ }^{\mathrm{c}, \mathrm{d}, \mathrm{e}, * *}$<br>${ }^{a}$ School of Information and Communications Engineering, Xi'an Jiaotong University, Innovation Harbour, Xi'an, 710049, Shaanxi, China<br>${ }^{b}$ TECNALIA, Basque Research \&amp; Technology Alliance (BRTA), Derio, 48160, Spain<br>${ }^{c}$ Bioengineering, Imperial College London, London, SW7 2BX, UK<br>${ }^{d}$ Imperial-X, Imperial College London, London, W12 7SL, UK<br>${ }^{e}$ National Heart and Lung Institute, Imperial College London, London, SW3 6LY, UK</p>
<h4>Abstract</h4>
<p>In the era of sustainable smart agriculture, a massive amount of agricultural news text is being posted on the Internet, in which massive agricultural knowledge has been accumulated. In this context, it is urgent to explore effective text classification techniques for users to access the required agricultural knowledge with high efficiency. Mainstream deep learning approaches employing fine-tuning strategies on pre-trained language models (PLMs), have demonstrated remarkable performance gains over the past few years. Nonetheless, these methods still face many drawbacks that are complex to solve, including: 1. Limited agricultural training data due to the expensive-cost and labour-intensive annotation; 2. Poor domain transferability, especially of cross-linguistic ability; 3. Complex and expensive large models deployment. Inspired by the extraordinary success brought by the recent ChatGPT (e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore the capability and utilization of ChatGPT applying to the agricultural informatization field. Specifically, we have thoroughly explored various attempts to maximize the potentials of ChatGPT by considering various crucial factors, including prompt construction, answer parsing, and different ChatGPT variants. Furthermore, we conduct a preliminary comparative study on ChatGPT, PLMs-based fine-tuning methods, and PLMs-based prompt-tuning methods. A series of empirical results demonstrate that ChatGPT has effectively addressed the aforementioned research challenges and bottlenecks, which can be regarded as an ideal solution for agricultural text classification. Moreover, compared with existing PLM-based fine-tuning methods, ChatGPT achieves comparable performance even without fine-tuning on any agricultural data samples. We hope our preliminary study could prompt the emergence of a general-purposed AI paradigm for agricultural text processing.</p>
<p>Keywords:
Agricultural text classification, Very large pre-trained language model, Generative Pre-trained Transformer (GPT), ChatGPT and GPT-4</p>
<h2>1. Introduction</h2>
<p>With the rapid development of sustainable smart agriculture ecosystem, the quantity of various news contents related to agricultural themes on the Internet has undergone an explosive increase. Such a vast quality of unstructured data contains already latent histor-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>ical knowledge, helping us precisely study natural hazards and mitigate potential agricultural risks. Artificial intelligence-based agricultural text classification enables managing these massive Internet agricultural news automatically and makes these massive unstructured data easily indexable, which is a crucial step for agricultural digitization and agricultural Internet of Things.</p>
<p>In recent years, these mainstream agricultural document processing techniques including text classification generally rely on various deep representation learningbased methods, especially on approaches based on pre-trained language models (PLMs), including BERT,</p>
<p>BART, and T5 [1; 2; 3]. Xu et al. [4] proposed a novel model, namely time series-long short-term memory (AETS-LSTM), for predicting the rise and fall of agricultural exports. agricultural document processing. Cao et al. [5] utilized the BERT with symmetrical structure to analyze the sentiment tendency of the Internet consumers reviews towards the agricultural products. Leong et al. [6] employed a text-level character region awareness model (CRAFT) for recognizing and extracting the essential information from agricultural regulatory document and certificates. Jiang et al. [7] proposed a BERT-based text classification network for automatically classifying the French bulletin to make these data easily indexable. In additional to the aforementioned research efforts, these deep representation learning-based approaches have held great promise for almost all agricultural informatization applications.</p>
<p>Unfortunately, these PLMs-based fine-tuning solutions, inevitably encounter several challenging issues in the practical processes of model development, and application deployment. On the one hand, insufficient and poor quality supervised training data can greatly decrease the model performance whereas acquiring enough high-quality annotated data remains time-consuming and labour-intensive; on the other hand, even if trained properly on sufficient data, the inherent characteristics of supervised learning models limit their generalization capabilities to specific contexts related to the supervised corpus. In other words, when transplanted to new domains or new tasks, their limitations become evident, lacking a certain degree of scenario transferability, particularly of the crosslinguistic capacity. Moreover, due to the extremely large parameter volumes of PLMs, the corresponding deployment is complex and power-intensive, which requires high-performance equipments (such as massively parallel computing hardware, such as GPUs and TPUs). For example, the largest T5 model has over 11 billion parameters, which is 100 times the number of parameters of the BERT-base model. These prove that mainstream PLMs-based agricultural text classification methods fall far short of the standards for achieving General Purpose Artificial Intelligence (GPAI) in the future.</p>
<p>These introduced limitations and deficiencies have made existing agricultural document processing techniques can not handle well in almost application scenarios, especially for agricultural text classification. Recently, the artificial intelligence ChatGPT-family chatbots, proposed by the OpenAI foundation, has caused a groundbreaking revolution in the academic community, especially for natural language processing (NLP)</p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">Tell</span><span class="w"> </span><span class="nv">us</span><span class="w"> </span><span class="nv">what</span><span class="w"> </span><span class="nv">you</span><span class="w"> </span><span class="nv">can</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">agricultural</span><span class="w"> </span><span class="nv">application</span>.
</code></pre></div>

<p>As an AI language model, I can provide several ways to assist with agricultural applications. Here are some of the ways I can help:</p>
<ol>
<li>Crop Monitoring: I can analyze satellite and drone images to provide real-time data on crop health and yield predictions.</li>
<li>Soil Analysis: I can analyze soil data to provide recommendations on how to improve soil quality and optimize crop growth.</li>
<li>Weather Forecasting: I can provide real-time weather forecasting to help farmers make informed decisions about planting, harvesting, and protecting their crops.</li>
<li>Red and Disease Identification: I can analyze images of plants and soil to identify pests and diseases that may be affecting crop growth.</li>
<li>Market Analysis: I can analyze market data to provide insights into supply and demand trends for agricultural products.</li>
<li>Decision Support Systems: I can create personalized recommendations for farmers based on their specific needs and circumstances.</li>
</ol>
<p>Overall, as an AI language model, I can help farmers optimize their agricultural practices, improve their crop yield, and increase their profits.</p>
<p>Figure 1: Valuable suggestions advised by ChatGPT for assisting farmers and market regulator in better governing agricultural affairs (Query Date: 2023.3.16).
tasks. ChatGPT is essentially a powerful very large pretrained language model for dialogue based on the Transformer architecture [8], utilizing a larger corpus, higher computational power, and an unprecedented amount of network parameters ${ }^{1}$. What is inspiring is that unlike previous intelligent chat robots, ChatGPT can provides smooth and comprehensive responses to various complex and professional human questions. For instance, ChatGPT can perform tasks such as multilingual translation, poetry generation, and code generation based on specific requirements [9; 10]. Thus, ChatGPT have rapidly exhibited their remarkable language comprehension and generation abilities, which produces popularity and attracts ever-increasing attention in various cross-disciplinary researches that NLP community intersects with, such as radical radiology diagnosis [11] and sentiment analysis of surgery disease [12; 13].</p>
<p>After experiencing ChatGPT's universal and powerful capabilities, it is natural for us to wonder about how much potentials ChatGPT can bring to the agricultural products' production management process for optimizing sustainable agricultural applications. As shown in Fig. 1, when asked about the potential applications of GPT-3.5 (a standard model in ChatGPT-family) in agriculture, The model replied that it is capable of performing tasks such as weather forecasting, pest and disease identification, and market analysis (among others).</p>
<p>Inspired by the potential applications of ChatGPT in the field of smart agriculture, it is our belief that the</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 2: The paradigm comparison of the ChatGPT-based NLP solutions and existing prompt learning paradigm using an agricultural sentiment analysis example. Part. (a) denotes the task prototype of the agricultural sentiment analysis; Part. (b) denotes the standard workflow of ChatGPTbased approaches; and Part. (c) denotes the standard workflow of Masked LM prompt-tuning methods.
community is much in need for principled explorations to determine how much ChatGPT can contribute to the optimization of sustainable agricultural practices. With that concern in mind, we have decided to delve into the potentials of ChatGPT by focusing on the concise classification of agricultural text in this work.</p>
<p>By doing so, our experiments mainly investigate the potential power of ChatGPT (i.e. GPT-3.5 by default) [14] and its extension (i.e. GPT-4) [10] for classifying the agricultural-related documents. Notably, along with the proposed ChatAgri, this paper also provides a brand-new paradigm which is distinguished from existing methods. Through a series comparative experiments of ChatAgri with a range of mainstream text classification models, including classic fine-tuned PLMs [15; 16] and prompt-learning based on auto-regressive generative PLMs [17; 18; 19], we systematically evaluated and investigated the superiority of ChatGPT in agricultural text classification tasks, which distinguished it significantly from other methods.</p>
<p>Furthermore, we have investigated extensive literature related to ChatGPT-based question answering (QA) [20; 21; 22; 23] and the prompt learning scheme [17; 24; 25], and arrived at the following conclusions: Most language understanding tasks based on ChatGPT can be categorized as a new form of Prompt Learning based on PLMs. Specifically, regarding the adopted ChatGPT interface as a parameters-frozen large-scale PLM, the overall procedure are extremely similar to the prompttuning paradigm described in the survey of Liu et al. [17]. Fig. 2 gives a clear illustration of the major simi-
larities and distinguishes between ChatGPT-based NLP paradigm, (a) and MLM prompt-tuning paradigm, (b), through a typical example of the agricultural food comment sentiment analysis task. As depicted in part. (c) of Fig. 2, the MLM prompt-tuning paradigm can be divided into three primary procedures: template engineering, pre-trained language models reasoning, and answer mapping engineering [17]. As shown in part. (b) of Fig. 2, the general NLP research related to ChatGPT can be organized into the following several phases in our experiments [11; 26]: 1) prompting question construction engineering; 2) ChatGPT Q\&amp;A inference; 3) answer normalization engineering (alias. answer alignment). Thus, several core factors were considered to be optimized:</p>
<ul>
<li>1). Due to that interacting with ChatGPT involves providing instructions through human response, based on previous ChatGPT prompting works [27; 22; 21], we have designed several appropriate task-specific inquiries to intuitively trigger the understanding capability of ChatGPT;</li>
<li>2). As the textual generations of ChatGPT are essentially human-like natural language, they differ greatly when it comes to specific tasks. So, a accurate label mapping strategy from ChatGPT outputs to the final classified categories are needed to be developed. In our experiments, we devised two novel answer mapping strategies for this critical step for the answer alignment engineering.</li>
</ul>
<p>To evaluate extensive data in various agricultural subfields, sourced mainly comes from Internet news covering topics ranging from insect pests, and natural hazards to agricultural market comments. Further, even in cases multi-language corpora are tested, experiments validate that the proposed ChatAgri still features a significant transferring effectiveness in cross-linguistic scenarios.</p>
<p>In summary, our experiments provide a preliminary study of ChatGPT on agricultural text classification to gain a better understanding of it, and reported a systematic analysis according to the corresponding empirical results. We believe that by exploring how ChatGPT can contribute to agricultural production and management through text classification tasks such as pest and disease identification, agricultural news categorization, and market comment analysis, we can demonstrate the feasibility of ChatGPT in advancing agricultural practices, thereby paving the way for a more efficient and sustainable smart agriculture.</p>
<p>The novel ingredients of this work can be summarized as follows:</p>
<ul>
<li>Motivated by the various application progresses of very large pre-trained language models represented by ChatGPT, we conduct a preliminary study towards exploring the potentials of ChatGPT in agricultural text classification task and thus propose ChatGPT-based solution for agricultural text classification, namely ChatAgri;</li>
<li>Evaluated on several multi-linguistic datasets, ChatAgri achieves competitive performance compared to existing PLM-based fine-tuning approaches, showing a superior ability in terms of the impressive semantic understanding. Through several specific case analysis, it even surprisingly produces a intelligent reasoning chain;</li>
<li>The zero-shot learning experiments demonstrate the great potential of ChatAgri in agricultural text classification, compared to existing PLM-based fine-tuning approaches, which require high-quality supervised data, along with a time-consuming, labor-intensive annotations and expensive knowledge from agricultural domain experts;</li>
<li>Multi-linguistic experiments discussed in this work expose the excellent domain transferability of ChatAgri, by which the model can adapt to different agricultural applications quickly, and is a fundamental step accelerating the future General Purpose AI (GPAI);</li>
<li>ChatAgri, only relying on network interface and minimum hardware requirements, subverts the mainstream complex and power-intensive PLMbased methods, which holds great promise of the general and low-costing artificial intelligence techniques for the future smart agricultural applications;</li>
<li>To encourage further research of smart agricultural applications by leveraging ChatGPT, we released the codes of ChatAgri on Github ${ }^{2}$.</li>
</ul>
<p>The remainder of this paper is organized as follows: Section 2 provides an overview of the recent literature in related fields, with a focus on recent research for the agricultural text classification task, ChatGPT, and pre-trained language model-based NLP techniques. Section 3 presents a detailed description of the whole ChatAgri framework, including a detailed algorithmic description. In Section 4 and 5, we conduct a comprehensive analysis of the comparison experiments between ChatAgri and several mainstream PLM-based methods, along with various ablated studies. Finally, Section 6 offers a concise summary of the primary contributions of our research and outlines future prospects for further sustainable smart agriculture development based on our findings.</p>
<h2>2. Related Work</h2>
<p>In this section, we will review the related literature on accurately classifying cross-linguistic agricultural texts, recent advancements and applications in ChatGPT and its extensions, as well as PLM-based fine-tuning and prompt-tuning approaches in addressing the challenges of agricultural text classification.</p>
<h3>2.1. Agricultural Text Classification</h3>
<p>Over the past decade, the primary machine learning models (e.g. decision tree, CNN, LSTM, and GRU) [4] have been the dominant approaches in research on the agricultural document classification.</p>
<p>Azeez et al. [28] used the support vector machine (SVM) and decision tree induction classifiers to complete the regional agricultural land texture classification. Li et al. [29] simultaneously utilized the Bi-LSTM and the attention mechanism to further dynamically enrich</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the extracted multi-sources semantic features, which effectively improve the performance of agricultural text classification. Dunnmon et al. [30] leveraged CNN to predict agricultural Twitter feeds from farming communities to forecast food security indicators, and demonstrated that CNNs are widely superior to RNNs in agriculturally-relevant tweets sentiment classification.</p>
<p>Since the introduction of large models such as BERT [1] and GPT [31], many NLP tasks have achieved significant performance improvements and have gradually replaced traditional machine learning approaches [26]. Compared to traditional machine learning methods, large pre-trained language models are better equipped to handle the complexity scenarios, having received widespread attentions in both academic and industrial settings.</p>
<p>Shi et al. [32] employed BERT to identify the most representative information from unlabeled sources, which were manually labeled to construct the corpora of agricultural related news from diversified topics, enhancing the efficiency of labeling process and ultimately improving the corpora construction quality. Jiang et al. [7] automatically classify the French plants health bulletins to make these data easily searchable through fine-tuning BERT. Leong et al. [6] developed an automatic optical character recognition system for the categorization and classification of agricultural regulatory documents. To tackle the imbalance between the supply and demand of the agricultural market, Cao et al. [5] introduced a improved BERT-based sentiment analysis model for agricultural product evaluation through Internet reviews. The proposed BERT model with symmetrical structure accurately identifies the emotional tendencies of consumers, helping consumers evaluate the quality of agricultural products and helping agricultural enterprises optimize and upgrade their products.</p>
<h3>2.2. Traditional Machine Learning methods, and PLM-based Fine-tuning, and Prompt-tuning</h3>
<p>For a significant period of time in the past, the predominant approach for addressing the agricultural text processing problems was based on traditional machine learning methodologies. Xu et al. [33] proposed a novel method to predict the rise and fall of agricultural exports, called agricultural exports time series-long shortterm memory (AETS-LSTM). AETS-LSTM achieves improved prediction performance that predicts the tendencies of the agricultural exports, which is effective way to help agribusiness operators to make better evaluations and adjustment policies. To identify the pests and diseases symptoms of rice farming, Costa et al. [34]
build a knowledge-based system that used jaccard similarity coefficient (JSC), which performs tokenizing, filtering and porter stemming to extract critical information to deliver pests and disease problem.</p>
<p>Feature engineering-based methods were limited by their inability to capture the complexity and nuances of natural language, particularly when it comes to some semantic complex situations [26]. With the emergence of PLMs [31; 35; 1; 2], a powerful technique that revolutionized the field of NLP, many traditional methods $[7 ; 36 ; 30]$ has been substituted [8]. Since then, the PLM-based fine-tuning paradigm has been propelled to be the mainstream learning technique for various agricultural information processing [37]. PLM-based fine-tuning paradigm is designed by introducing additional network parameters and fine-tuning PLMs to downstream tasks using task-specific objective functions. Cao et al. [5] developed an improved BERTbased model to extract complete semantic information for the task of sentiment analysis in agricultural product reviews. The goal was to assist consumers in making informed purchasing decisions. They utilized TensorFlow to fine-tune the whole parameters of BERT and its downstream classifier to obtain a well-optimized model. Jin et al. [16] proposed a dictionary knowledge infused network, DictABSA, for sentiment analysis and agricultural text classification.</p>
<p>Nevertheless, these PLM-based fine-tuned models may not generalize well to new scenarios and required significant amount of annotated data, making it hard to be quickly developed and easily deployed. As a result, the role of traditional PLM-based fine-tuning has gradually diminished in NLP, being replaced by a more promising learning paradigm known as "prompt learning" or "prompt-tuning", according to a recent survey [17]. Different from the PLM-based fine-tune paradigm, prompt-tuning follows the original LM training which adapts the downstream task to the PLM itself with the help of constructed prompting templates, thus especially performing well in few-shot or even zero-shot scenarios. Lyu et al. [11] investigate the effect of different optimized prompts on the performance of the improved plain-language translations of the radiology report. Liu et al. [24] proposed $P$-Tuning, a novel method that automatically searches for prompts in the continuous space to improve the performance of PLMs. It uses a few continuous free parameters as prompts and optimizes them using gradient descent. Experiments proved that $P$-Tuning brings substantial improvements to GPTs, even outperforms BERT models to some extent. Liu et al. [25] also introduced $P$-Tuning $v 2$, a enhanced continuous prompt optimization method of $P$-Tuning [24].</p>
<p>P-Tuning v2 represents a significant improvement over $P$-Tuning by using continuous prompts for every layer of the PLM, rather than just the input layer, increasing the capacity of continuous prompts and helping to close the gap to fine-tuning across the small models and hard tasks. Hu et al. [38] devised a novel knowledge enhanced method for text classification, namely knowledgeable prompt-tuning (KPT). It incorporates rich external knowledge from knowledge bases (KBs) into the prompt verbalizer to better stimulate the internal knowledge in PLMs.</p>
<h3>2.3. ChatGPT</h3>
<p>ChatGPT is a leading conversational language model developed by OpenAI, which serves as an expert in all fields with omnipotent and omniscient knowledge. ChatGPT is a disruptive revolution across numerous research domains, extending beyond NLP, providing a user-friendly interface that grants the general public unprecedented access to the capabilities of large language models. ChatGPT, also known as GPT-3.5 that built upon GPT-3 [14], serves as a conversational robot capable of comprehending intricate instructions and producing high-quality replies across diverse scenarios. ChatGPT, acting as a valuable tool, has made a significant contribution to many application scenarios and has opened up new possibilities for virtual assistants. In terms of model structure, ChatGPT [10; 9] can be regarded as a quantum leap characterized by several distinctive characteristic features that stands out from previous NLP models such as BERT [1], BART [2], and T5 [3]. These can be summarized as: a very large language model using over billions of parameters, having the capability of a chain of thought prompting, and trained with reinforcement learning from human feedback (RLHF).</p>
<p>As millions of users continue to tap into these language models, countless new use cases emerge, opening the door to a flurry of ChatGPT potentials. Based on a recent empirical study [27; 26], ChatGPT has shown remarkable proficiency in multilingual translations, particularly in high-resource languages translator such as mutual translation between various European and American languages. Furthermore, this study found that ChatGPT performs similarly to other prominent translation services like Tencent TranSmart, DeepL Translate, and Google Translate. What's even more impressive is that ChatGPT can be used in code debugging and even code generation [10]. Based on Haque et al. [20], ChatGPT was evaluated on its capability to provide code snippets that adhered to the syntax and semantics of the programming language, such as</p>
<p>Python, Java, and JavaScript. Bang and colleagues [39] utilized several codes, including Python Turtle graphics and HTML Canvas, acted as tools for the multimodal task of generating images from text. These researchers demonstrate that ChatGPT was able to generate superior-quality codes based on brief business requirements expressed in natural language, overwhelmingly surpassing other code modification techniques.</p>
<p>The growing fascination with ChatGPT has spurred a wide range of investigations into the myriad of possibilities presented by this groundbreaking language model, particularly those in the agricultural field. Gao et al. [21] investigates the feasibility of using ChatGPT for event extraction, highlights the difficulties posed by event extraction due to its complexity and the need of a comprehensive set of instructions. Wei et al. [23] designed a universal zero-shot information extraction framework via chatting with ChatGPT, namely ChatIE, handling NLP tasks including named entity recognition, event extraction, and relation extraction. Specifically, ChatIE is devised as a decomposed multi-stages involving with several turns of QA: first stage to discover the element types presented in the sentence through one turn of QA, and second stage to find the elements to fill the corresponding element slots through multiple QA turns.</p>
<p>Furthermore, OpenAI [10] released GPT-4, an advanced, large-scale, multi-modal generative PLM, in early March of this year. It exhibits significant improvements over ChatGPT (GPT-3.5) in terms of multi-modal image and text interaction, broader digital character limitations and more accurate semantic understanding. GPT-4 holds immense promise for future diverse applications and is regarded as a significant stride toward achieving general-purpose technology.</p>
<p>Moreover, the official investigation of GPT-4 [9] confirms the hypothesis that these technologies can have a substantial effect on a wide swath of occupations, especially for higher-wage occupations that face greater exposure to PLMs. Recently, an open letter signed by numerous prominent researchers has called for a halt to "Pause Giant AI Experiments" towards the successive development of GPT-5 due to GPT-4's perceived terrifying power and its potential risks to society [10]. Even Sam Altman, the CEO of OpenAI, has also signed this open letter, demonstrating that the future impact of General Purpose AI, represented by ChatGPT, on various industries will be revolutionary and profoundly impressive.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: The framework of ChatAgri, which is illustrated by an typical example in the agricultural natural disaster dataset, French Plant Health Bulletin. First (left), several prompting construction strategies were applied to generate prompts, and the ChatGPT question is constituted by integrating these prompts with the original sentence; Second (center), ChatGPT provides response based on the inputs; Finally (right), the answer alignment strategies were devised to classify the intermediate answer to pre-defined categories.</p>
<h2>3. ChatAgri: ChatGPT-based Agricultural Text Classification</h2>
<h3>3.1. Methodology Overview</h3>
<p>Focusing on investigate the feasibility of applying ChatGPT to agricultural text classification, ChatAgri, one of the preliminary studies of ChatGPT-based agricultural applications is constructed in this paper, along with a series of systematically and exploratory experimental analysis discussed.</p>
<p>Through our investigations, there are no existing research works that systematically utilized ChatGPT to the text classification task until our ChatAgri proposed. To fill this gap, the question how to defined the corresponding general workflow for the ChatGPTbased agricultural text classification will be further discussed. Specifically, after referred to abundant latest literature, as shown in Fig. 3, we deem that almost all the ChatGPT-assisted applications can be divided into three phrases:</p>
<ul>
<li>Prompting Question Construction: The first stage which focuses on providing appropriate prompting strategies to be fed into ChatGPT;</li>
<li>ChatGPT Q\&amp;A Inference: The second stage about the reasoning procedure of ChatGPT Q\&amp;A, which
is transparent to us and can be regarded as a black box;</li>
<li>Answer Normalization or Alignment: The third stage transferring the natural language intermediate response to the target label in the pre-defined categories.</li>
</ul>
<p>Among these steps, in additional to the Q\&amp;A inference conducted by ChatGPT, a static reasoning procedure we can not participate in modification, the prompting construction engineering and answer alignment engineering can be further optimized during our experiments. From a macro perspective, ChatAgri is a pipeline structure in which each procedure influence the final prediction performance to a certain extent, including the quality of constructed prompts, the selected ChatGPT version, and the priority of adopted answer mapping strategies. Thus, the next subsections will introduce multiple novel solutions which are utilized in our experiments to fully exert the enormous potential and superiority of the ChatGPT in ChatAgri.</p>
<p>Furthermore, as opposed to the text classification in the universal domain, the agricultural text classification acted as a domain-specific research branch due to the additional requirements of domain expertise knowledge. Another crucial factor, domain-specificity, should</p>
<p>also taken into more considerations and corresponding customized strategies.</p>
<p>The following chapters would successively elaborate the specific solutions during the entire experiments of ChatAgri.</p>
<h3>3.2. Prompt Question Construction</h3>
<p>It is widely acknowledge to us that prompting engineering is a cumbersome art that requires extensive experience and manual trial-and-errors [17; 26]. To design the suitable prompts to trigger the sentence classification ability of ChatGPT, we investigate sufficient pioneering works that discuss about how to generate optimized ChatGPT prompting questions [40; 21; 22]. Specifically, as depicted in the left of Fig. 3, the adopted prompt generation strategies in this experiments includes: 1). manually defined prompts; 2). prompts triggered from ChatGPT; 3). prompts based on the zeroshot similarity comparisons; and 4). prompts based on Chain-of-Thought (CoT); These novel prompt generation strategies are discussed in the followings.</p>
<h3>3.2.1. Manually Defined Prompts</h3>
<p>Following the general communication habits, we manually elaborate several prompting templates, Table 1 displays the part of designed prompts. Note that it is necessary to provide ChatGPT with the two mentions: original textual context and pre-defined categories, through some appropriate ways. Furthermore, for simplicity, we insert two extra slots into the prompts to combine the corresponding mentions, which respectively are [SENT] (slot of sentence) and [CATE] (slot of categories).</p>
<p>Table 1: The partial manually devised prompts. [Res] denotes the response provided by ChatGPT.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">No.</th>
<th style="text-align: center;">prompting template</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">Classify the following sentence into one of the given categories: [CATE] \n Sentence: [SENT] \n Category: \t[Res]</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">Which categories do you think sentence: \n [SENT] \n belongs to, out of [CATE]? \n [Res]</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">.....</td>
</tr>
</tbody>
</table>
<p>To conduct the successive comparison experiments, we evaluate the specific effect of each candidate prompt to select the best candidate prompt. Formally, we employ a data sampling-based evaluation approach among these candidate prompts [39]. Concretely, we randomly selected a fixed number of samples (set as 100 during experiments by default) from the Twitter Natural Hazards dataset, then we further test the performance for
each prompts on this subset by accuracy. After overall comparisons, the prompt which is shown in Fig. 4 is selected as the most suitable manually defined prompt for subsequent experiments.</p>
<div class="codehilite"><pre><span></span><code>Your task is to categorize the given sentence into one of the
</code></pre></div>

<p>provided categories.</p>
<p>Please provide a clear and concise response that accurately identifies the category of the sentence to allow for categorizations.</p>
<p>The sentence is: [SENT].</p>
<p>The categories are specified in the [CATE].
The sentence to be classified is: [ChatGPT Response].</p>
<p>Figure 4: The adopted prompt which is selected through the subset evaluation.</p>
<p>Moreover, note that we add an extra command "Please only answer the category." into prompts to ask ChatGPT not to generate redundant explanation around the ChatGPT reply, which might be a disrupting factors for subsequent text label decisions. The factor has also been taken into consideration for the subsequent prompting methods.</p>
<h3>3.2.2. ChatGPT Triggered Prompts</h3>
<p>Drawing inspiration from the relevant literature [40; 22], we posit that inquiring about ChatGPT itself could potentially yield valuable insights into the generation of high-quality templates. Thus, we seek inspiration from ChatGPT by asking ChatGPT with the recommendations for templates generation. Note that a similar preliminary study of Zhong et al. [22] suggests that the task-specific prompts can be triggered by using the following human inquiries:</p>
<div class="codehilite"><pre><span></span><code><span class="o">&gt;</span><span class="w"> </span><span class="n">Provide</span><span class="w"> </span><span class="n">five</span><span class="w"> </span><span class="n">concise</span><span class="w"> </span><span class="n">prompts</span><span class="w"> </span><span class="ow">or</span>
<span class="n">templates</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">make</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">deal</span>
<span class="k">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">[</span><span class="n">x</span><span class="o">]</span><span class="w"> </span><span class="n">task</span><span class="p">.</span>
</code></pre></div>

<p>where the slot [x] means the specific task types. Experiments prove that this strategies performs well in most scenarios.</p>
<p>Correspondingly, as shown in Fig. 5, our request is intuitively constructed as follows:</p>
<div class="codehilite"><pre><span></span><code>&gt; Provide five concise prompts
or templates that can make you
deal with the agricultural text
classification task.
</code></pre></div>

<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 5: Candidate prompt templates triggered by requests to ChatGPT (Model: GPT-3.5, Query Date: 2023.4.02).</p>
<p>Afterwards, ChatGPT naturally answers us with several candidate responses, which is depicted in Fig. 5. The prompts that have been generated appear to be sensible and consistent in terms of their semantic content, while also exhibiting some noticeable distinctions in terms of their individual formats.</p>
<p>To this end, following the above described samplingbased evaluation method, we select the best-performed prompt to represent the ChatGPT triggered prompts for successive comparison experiments, which is shown as follows:</p>
<div class="codehilite"><pre><span></span><code><span class="ss">&quot;&gt; Classify the agricultural text:</span>
<span class="ss">[SENT] according to its main topic</span>
<span class="ss">[CATE].&quot;</span>
</code></pre></div>

<h3>3.2.3. Zero-Shot Similarity Prompts</h3>
<p>Motivated by previous few/zero-shot learning works that utilizes meta-learning paradigm [41; 23], we devised a novel prompting strategies upon it, called zeroshot similarity-based prompting.</p>
<p>Typically, few-shot object classification is performed by leveraging sample and classifiers from similar classes by some distance measure and similarity functions, such as cosine similarity and squared $\ell_{2}$ distance [41]. To give an example, let's consider the few-shot learning-based images classification task. Firstly, given an image to be classified, one extra representative image for each category was choosed. Then, they were embedded into the same low-dimensional space using an embedding network, such as siamese network, prototypical network, and matching network. Finally, the similarity threshold between the image to be classified and images from all-kind of categories is then used for label classification.</p>
<p>Back to agricultural text classification, the adopted ChatGPT interface can be regarded as a special distance similarity measurement for evaluating the inter-
relationship between two different sentences. All these procedures were conducted by performing one turn or multi turns QA. Specifically, we have designed two QA modes: end-to-end direct QA-based similarity evaluation and progressive comparison QAs-based similarity evaluation.</p>
<ul>
<li>End-to-end direct QA-based: Concretely, the most straightforward and simplest way is to directly ask ChatGPT that which sentence is most similar to the pre-classified sentence. Furthermore, we adopt the following prompt during experiments.</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="o">&gt;</span><span class="w"> </span><span class="n">Given</span><span class="w"> </span><span class="n">sentence</span><span class="w"> </span><span class="nl">S</span><span class="p">:</span><span class="o">[</span><span class="n">SENT1</span><span class="o">]</span><span class="p">,</span>
<span class="n">which</span><span class="w"> </span><span class="n">sentence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="nl">A</span><span class="p">:</span><span class="o">[</span><span class="n">SENT2</span><span class="o">]</span><span class="p">,</span>
<span class="nl">B</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">SENT3</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">do</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">think</span><span class="w"> </span><span class="k">is</span>
<span class="n">most</span><span class="w"> </span><span class="k">similar</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">sentence</span><span class="w"> </span><span class="n">S</span><span class="vm">?</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span>
<span class="p">...,</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">C</span><span class="vm">?</span>
</code></pre></div>

<p>In this manner, the text category can be finally determined. As see in Fig. 6, the target sentence can be classified to the category of sentence $\mathbf{C}$ based on only one-turn QA.</p>
<p>Given sentence
S: careless nfostlanter, aucune intervention ne se justifie actuellement
which sentence of
A: chouc le vol de pdride est important dans le boret, lindre et lone et la seine et manne.
B: le service régional de la protection des végétaux et la fredes participent à l'opposé
C: comtichon: des dégâts de grêle dans le bor et char favorisent l'installation du botrytis
do you think is most similar to sentence S? A,B, or C?</p>
<p>Based on the information provided, neither sentence A nor sentence B seem to be closely related to sentence $S$ in terms of topic and semantics. However, sentence $C$ seems to be somewhat related to sentence $S$, as they both deal with agricultural issues. Therefore, my answer 6.7.</p>
<p>Figure 6: The end-to-end direct similarity measurement QA-based prompting method for text classification.</p>
<ul>
<li>Progressive comparison QAs-based: Similar to bubble sorting algorithm that compares pairs of elements at a time and subsequently applying the comparison to successive elements. Encouraged by the sorting algorithm, we incorporate its use in determining text similarity. Intuitively, we use the QA prompt:</li>
</ul>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 7: The progressive similarity measurement QAs-based prompting method for text classification.</p>
<p>A typical example related to the threeclassification problem was given in Fig. 7. Based on two-turn QAs, the target sentence can be classified to the category of sentence $\mathbf{A}$ based on the topic similarity comparison in the second QA stage. To our knowledge, we are the first to utilize the multi-stage similarity comparison approach to conduct the text classification task.</p>
<h3>3.2.4. Chain-of-Thought Triggered Prompts</h3>
<p>In Jiao et al.s' [40] preliminary research of ChatGPT evaluation, they devised a Pivot Prompting translation strategy for ChatGPT-based multi-linguistic translator, which significantly improves the translation performance. Pivot Prompting translates source language to target language by using a high-resource pivot language (i.e. English by default) as a transition when two distant language is scarce. The above research reflected that this intermediate transitional strategy is particularly effective in some special application scenarios. Jin et
al.'s knowledge graph-based QA research [15] provides further evidence that these chains of reasoning are a critical factor that impacts the accuracy of the model.</p>
<p>Moreover, our inspection of ChatGPT's computational ability reveals that while ChatGPT tends to fall behind in its ability to reason and provide correct answers, it performs competitively when a step-by-step calculation process is used. Fig. 8 gives a typical example. To be more specific, while ChatGPT incorrectly provides the answer of 334 for the arithmetic problem $4+32 \cdot 5-2$, it is capable of correctly reasoning and arriving at the right answer for the same problem based on a step-by-step calculation process.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 8: The ChatGPT performance comparison between providing the answer directly and presenting a step-by-step calculation process in solving arithmetic problems. (Model: GPT-3.5, Query Date: 2023.3.15)</p>
<p>Building upon the experimental findings that support the effectiveness of step-by-step incremental reasoning, we explore the utility and viability of utilizing this technique for agricultural text classification. Concretely, we choose the manually defined prompts and ChatGPT triggered prompts as baselines. Also, drawing on these initial prompts, we require ChatGPT not only with delivering the final classification category but also with producing a corresponding comprehensive Chain-of-Thought reasoning analysis. For ease of illustration, as shown in Fig. 9, we further add the following expression based on the original QA prompt.
" $&gt;$ Please provide a step-by-step analysis towards the semantic and keywords, and present the corresponding classification reasoning process."</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 9: The Chain-of-Thought-based prompting strategy which is built upon a simple and direct QA prompt. (Model: GPT-3.5, Query Date: 2023.3.15)</p>
<p>This section presents several feasible strategies which shares a diverse range of distinctive features that set them apart from one another. But the prompting engineering is more complex and nuanced than what we can observe at a superficial level, as it is influenced by multiple factors, with dataset features playing a particularly significant role. For example, experimental results indicated that the Chain-of-Though triggered prompts performs particularly well on datasets with a high number of classification categories, but its effectiveness is not satisfactory when dealing with datasets with relatively simple classification (few categories), such as only two to three categories.</p>
<p>The upcoming experiments will systematically compare multiple prompting strategies proposed above to enable a comprehensive evaluation and research.</p>
<h3>3.3. ChatGPT Q\&amp;A Inference</h3>
<p>ChatGPT is a state-of-the-art conversation robot which are based on the generative language model, Generative Pre-trained Transformer (GPT). The ChatGPT model's conversational capability stems from its ability to generate coherent text using sequence-to-sequence learning and the transformer architecture, where it conditions on a given prompt and samples from a probability distribution of words. The prominent intelligent thinking of ChatGPT is derived from its training on extensive amounts of text data to acquire a statistical understanding of the patterns that exist in natural language.</p>
<p>The GPTs family uses the transformer architecture, which is a deep neural network that processes input data in parallel using multi-headed attention mechanisms. During the inference stage, the GPT model generates text by conditioning on a given prompt and sampling from a probability distribution of words that follow. The probability distribution is computed by applying the softmax function over the output of the model. The output of the model at each time step depends on the previous tokens generated, creating a generative process that allows the model to generate coherent text.</p>
<p>Mathematically, the token generative procedure of ChatGPT can be represented as:</p>
<p>$$
p(y \mid x)=\prod_{t=1}^{T} p\left(y_{t} \mid y_{1}, \ldots, y_{t-1}, x\right)
$$</p>
<p>where the $\prod$ means the probability multiplication operator. Given the previous tokens $y_{1}, \ldots, y_{t-1}$ and the input prompt $x, p\left(y_{t} \mid y_{1}, \ldots, y_{t-1}, x\right)$ is the probability distribution over the token $y_{t}$ in $t$-th time step and $T$ is the length of the generated sequence.</p>
<p>At this stage, we direct our focus towards ChatGPT and hypothesize that ChatGPT possesses inherent capabilities that enable it to act as an integrated zero-shot text classification interface through an interactive mode.</p>
<p>During the ChatGPT interaction process, we created a fresh conversation thread for each prompt to ensure that the previous conversation history would not impact ChatGPT's responses. By adopting this methodology, ChatGPT is able to consistently exercise independent thinking and deliver optimal responses by leveraging the information provided by the user.</p>
<p>Besides applying the vanilla ChatGPT (GPT-3.5), our experiments also evaluated the capabilities of GPT-4 [10]. GPT-4 represents a new breakthrough in OpenAI's ongoing efforts to advance the field of deep learning. The results showed that GPT-4 performed better than ChatGPT, even in some complex semantic text classification scenarios, as seen in the following section of related evaluations.</p>
<h3>3.4. Answer Alignment</h3>
<p>After the above steps, using an appropriate prompt and ChatGPT for question-answering, ChatGPT provided feedback on the classification results for the corresponding text. Nevertheless, its unique characteristic of generating responses in a conversational way presents challenges for the subsequent analysis and evaluation of its outputs. Unlike traditional PLM-based text classification models, ChatGPT's responses do not directly correspond to predefined labels, which means that an addi-</p>
<p>tional alignment strategy is required to convert these intermediate answers into the final labels that can be used to calculate various performance metrics (e.g. accuracy and F1-score). We refer to this additional mapping strategy as the "answer alignment engineering".</p>
<p>In our experiments, we investigated the impact of answer alignment engineering on the ChatGPT-based text classification's performance. Specifically, we designed and implemented two different alignment strategies: rule-based matching strategy and similarity-based matching strategy. Both approaches involve a mapping process that maps the intermediate responses to the corresponding labels. The rule-based matching approach uses predefined rules to match the responses to the labels, while the string matching approach computes the similarity between the response and each label and selects the label with the highest similarity score.</p>
<ul>
<li>Rule-based matching strategy: Essentially, the rule-based matching strategy is a text matching method that involves using patterns or rules based on token attributes, such as part-of-speech tags, to match sequences of tokens in unstructured text data. During our experiments, we use the Matcher ${ }^{3}$ object in spaCy v3 to find the matched tokens in context to classify the sentence returned by ChatGPT. spaCy v3 is a leading industrial-strength natural language processing and analysis tool ${ }^{4}$ using Python.
Specifically, we firstly analyze the text extraction patterns based on expert experience and ChatGPT's historical output habits, and design and define a set of rules. Then, the rules are applied to the text data and the extracted information is verified and validated. Finally, after adjustment and optimization, a comprehensive set of matching rules is summarized;</li>
<li>Similarity-based matching strategy: Although the former approach utilizes rigid matching with high accuracy, it is difficult to handle semantically ambiguous situations. To address this issue, we adopt the second strategy, which is the similaritybased matching strategy. Firstly, we aggregate and synthesize ChatGPT's commonly expressed utterances under each category to establish a repository of pivot answers for each category. Subse-</li>
</ul>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>quently, we apply the Levenshtein distance algorithm to compute the minimum edit distance between each pivot answer and the input answer being classified. The pivot answer with the smallest edit distance is regarded as the definitive category label. This approach offers comprehensive coverage and effectively mitigates the shortcomings of rule-based matching in accommodating ambiguous and nuanced language use.</p>
<p>The string similarity-based matching strategy is depicted in Fig. 10.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 10: The illustrating diagram of the similarity-based matching strategy.</p>
<p>In theory, neither of these two strategies can perfectly solve the problem of answer mapping. To overcome the challenge of answer mapping, we combined rule-based and similarity-based matching strategies in a pipeline approach. Specifically, we found that ChatGPT typically provides explicit category labels in natural language form. Therefore, in the first step, we tend to use the rule-based strategy to parse the intermediate answers. If the category is still uncertain, we then use the string similarity-based strategy to compute the similarity between the intermediate answer and each category's answer examples, selecting the category with the highest similarity as the final classification. In our experiments, this approach can simultaneously improve the accuracy and recall rate of the answer mapping process effectively.</p>
<p>Nevertheless, this work mainly explored a characterbased literal matching method that lacks semantic understanding. The method has certain limitations, whereas the deep neural network-based methods using PLMs are more adept at such scenarios. In our future work, we will attempt to use a PLMs-based semantic</p>
<p>understanding model for this step, which theoretically can bring about better performance.</p>
<h2>4. Experimental Setup</h2>
<p>We perform a series of experiments in order to figure out exactly what kinds of factors of these devised strategies that indeed influence the final agricultural text classification performance of the ChatAgri in Section 5. Correspondingly, acting as a preliminary, this section mainly introduces the details of the experimental setups, including the used multi-linguistic datasets, the employed text classification baselines for model comparisons, the adopted evaluation metrics, and the adopted hyperparameters of our ChatAgri.</p>
<h3>4.1. Datasets</h3>
<p>To demonstrate the actual potentials of ChatAgri for classifying agricultural text, we carefully collect several suitable datasets for evaluation and validation, ranging from different types of categories (e.g. plant diseases, insect pests, and twitter natural hazards) and numbers of categories to different languages, including French, English, and Chinese. These datasets are respectively called Amazon-Food-Comments, PestObserver-France, Natural-Hazards-Twitter, and Agri-News-Chinese in our experiments, whose details are illustrated as follows.</p>
<ul>
<li>Amazon-Food-Comments: An amazon food comment dataset that contains nearly 200,000 positive samples, neutral samples, and negative samples, which can be used to perform text classification tasks for both positive, neutral, and negative reviews ${ }^{5}$;</li>
<li>PestObserver-France: [7] A plant health bulletin classification dataset in French to estimate a agricultural prediction model that how well can it deal with heterogeneous documents and predict for natural hazards ${ }^{6}$;</li>
<li>Natural-Hazards-Twitter: [42] A natural disaster dataset with sentiment labels of United States</li>
</ul>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>which is proposed to identify attitudes towards disaster response. It contains different natural disaster types and nearly 5,000 Twitter sentences ${ }^{7}$;</p>
<ul>
<li>Natural-Hazards-Type: In addition to recognize the sentiment polarities of Natural-HazardsTwitter, we also re-organize it into a new disaster type classification dataset, denoted as Natural-Hazards-Type, to identify the natural disaster categories of text. Due to the large volume of the original Natural-Hazards-Twitter dataset, the new Natural-Hazards-Type dataset has taken a small subset of it, containing thousands of samples;</li>
<li>Agri-News-Chinese: Besides the above existing datasets, we proposed a Chinese Agricultural short text classification dataset, namely Agri-News-Chinese, containing seven categories, such as agricultural economy and aquatic fishery. Its data source was collected and cleaned from the agricultural technology expert online system (ATE expert online system) ${ }^{8}$, with a total volume of approximately 60000 pieces of data, divided into the train and test sets by 9:1.</li>
</ul>
<p>Table 2 gives a meta statistic for the five datasets, including the split distribution of train/test samples, the language scope, and the categories of textual topics.</p>
<h3>4.2. Baselines</h3>
<p>Existing extensive models for text classification can be divided into five major training paradigms: 1) traditional feature engineering-based machine learning (e.g. SVM, Decision Tree, and Random Forest) [28; 30; 29]; 2) word embedding-based deep learning (e.g. TextCNN, and TextRNN); 3) PLM-based finetuning, in which the PLMs include BERT [1], BART [2], T5 [3] and so on; 4) PLM-based prompt learning; and 5) the newest ChatGPT QA-based zero-shot learning paradigm that brought by ChatGPT recently (e.g. ChatIE [23], ChatEventExtract [21], and our ChatAgri).</p>
<p>To ensure the research comprehensiveness, the above introduced mainstream natural language understanding (NLU) paradigms were considered to be estimated and reported as the comparison baselines in our experiments. Specifically, besides the herein proposed ChatAgri, we adopted the following methods listed below for each mentioned learning paradigm.</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>Table 2: The statistical meta information of the adopted agricultural text classification datasets.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">train samples</th>
<th style="text-align: center;">test samples</th>
<th style="text-align: center;">language</th>
<th style="text-align: center;">categories</th>
<th style="text-align: center;">label count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Amazon-Food-Comments</td>
<td style="text-align: center;">165863</td>
<td style="text-align: center;">16175</td>
<td style="text-align: center;">English</td>
<td style="text-align: center;">'negative', 'positive', 'neutral'</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">PestObserver-France</td>
<td style="text-align: center;">322</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">French</td>
<td style="text-align: center;">'Bioagressor', 'Disease', 'Others'</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">Natural-Hazards-Twitter</td>
<td style="text-align: center;">45669</td>
<td style="text-align: center;">5074</td>
<td style="text-align: center;">English</td>
<td style="text-align: center;">'negative', 'positive'</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">Natural-Hazards-Type</td>
<td style="text-align: center;">5000</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">English</td>
<td style="text-align: center;">'Hurricane', 'Wildfires', 'Blizzard', 'Floods', 'Tornado'</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">Agri-News-Chinese</td>
<td style="text-align: center;">52000</td>
<td style="text-align: center;">6500</td>
<td style="text-align: center;">Chinese</td>
<td style="text-align: center;">'Agricultural economy', 'Horticulture', 'Agricultural engineering', Farming', 'Fisheries','Forestry','Crops'</td>
<td style="text-align: center;">7</td>
</tr>
</tbody>
</table>
<ul>
<li>SVM: [28] Support Vector Machine (SVM) is a classic classification method pursuing maximization of support vector distance between multiple class hyper-planes for classification, typically in the text category classification task. SVM mainly classifies the text by calculating the unstructured discrete textual features, optimizing them into high-dimensional spatialized vector representations;</li>
<li>Random Forest: [28] Random Forest (RF) is also a well-known classification algorithm, belonging to the ensemble methods family, combines multiple weaker classifier to create a stronger classifier for categorical data;</li>
<li>TextCNN: [43] Built on the top of pre-trained word vectors, TextCNN uses convolutional neural networks (CNN) as feature detector and utilizes kernels of different sizes to extract the valuable semantic feature for sentence classification. Lastly, the external softmax layer performs multiclassification on the convolutional logical values;</li>
<li>TextRNN: [44] Based on pre-trained word embeddings, TextRNN integrates recurrent neural network (RNN) into the multi-learning framework. Specifically, TextRNN utilizes long short-term memory (LSTM) to address the issues of gradient vanishing and exploding, thereby resolving the challenge of capturing long-range dependencies within sequences;</li>
<li>BERT-based fine-tuning: [1; 5; 26] Fine-tuning BERT has emerged as a widely employed methodology across diverse text processing tasks, including text classification. By generating contextualized word embeddings, BERT effectively captures both semantic and syntactic information associ-
ated with individual words. Leveraging its inherent strengths, BERT can be fine-tuned on specific tasks utilizing limited labeled datasets, rendering it a flexible and formidable solution for addressing an array of text processing objectives;</li>
<li>T5-based prompt-tuning: [17; 45; 3] Different from the "pre-train then fine-tune" procedure of fine-tuning methods, the prompt-tuning paradigm induces those PLM to generate suitable target responses with the help of additional triggered sentences, which are called "prompts". In prompttuning, the major research attention has been transferred on how to provide better prompts to activate the PLM's rich internal prior knowledge. We use the PLM, Transfer Text-to-Text Transforme (T5) to be the backbone. T5 is a unified very large PLM based on Transformer architecture, which converts all text processing tasks into Text-to-Text tasks;</li>
<li>BART-based prompt-tuning: [45; 2] We also investigate the usage of Bidirectional and AutoRegressive Transformers (BART), being acted as the backbone for prompt learning. BART simultaneously incorporates the advantages of BERT and GPT (i.e. the characteristics of the context bidirectional modelling and the sequence joint probability hypothesis);</li>
</ul>
<h3>4.3. Evaluation Metrics</h3>
<p>In such agricultural text classification task that involves multiple label classification, accuracy and F1score are two commonly used metrics.</p>
<p>Correspondingly, accuracy measures the proportion of correctly predicted samples among all predicted samples, is a simple and coarse-grained evaluation metric which only accumulates all the correct instances. And accuracy is calculated as follows:</p>
<p>$$
\text { Accuracy }=\text { Count }<em N="N">{T} / \text { Count }</em>
$$</p>
<p>where Count ${ }<em N="N">{T}$ represents the correctly predicted samples and Count ${ }</em>$ represents the total number of samples evaluated.</p>
<p>Comparatively, F1-score is considered to be a relatively fine-grained evaluation indicator than accuracy. In comparison to accuracy, F1-score is considered to be a higher confidence indicators which simultaneously considers the precision and recall. And F1-score is calculated as follows:</p>
<p>$$
\begin{aligned}
&amp; F 1=\frac{2 * \text { Precision } * \text { Recall }}{\text { Precision }+ \text { Recall }} \quad \text { where } \
&amp; \text { Precision }=\frac{T P}{T P+F P} \quad \&amp; \quad \text { Recall }=\frac{T P}{T P+F N}
\end{aligned}
$$</p>
<p>In the equation presented, Precision and Recall refer to the precision and recall rate of the classification results, respectively. $T P$ (true positives) represents the number of samples whose actual and predicted class are both positive; $F P$ (false positives) represents the number of samples whose actual class is negative but are predicted as positive; and $F N$ (false negatives) represents the number of samples whose actual class is positive but are predicted as negative.</p>
<p>Specifically, F1-score includes several calculating strategies: micro-F1, macro-F1, and weighted-F1. Without considering micro-F1 and macro-F1, we utilize the weighted-F1 as it accounts for the classification performance of categories under varying weights, thereby providing greater reference value.</p>
<h3>4.4. Hyperparameter Settings</h3>
<p>During our experimental procedure, there are various meta settings for all kinds of hyperparameters. The optimal hyperparameters, determined by their superior performance on the development set, will be selected for the final evaluation. The meta settings are summarized as follows.</p>
<p>We adopted the pretrained word vectors, GloVe [46], as the embeddings of the baselines of TextCNN and TextRNN. GloVe leverages the word co-occurrence statistics that can capture both syntactic and semantic relationships between words ${ }^{9}$. Considering the trade-offs between computational limitations and performances and to ensure experimental competitiveness and stability, we adopted the version "bert-base-</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup>uncased" ${ }^{10}$ for the PLM BERT, the version "t5-base"11 for the PLM T5, and the version "facebook/bart-base"12 for the PLM BART respectively. The code implementation is developed using Python $3.7^{13}$ and PyTorch $1.9 .0^{14}$ frameworks. For experimental simplicity, the prompts of the prompt-tuning baselines are pre-defined as "Given a sentence of [SENT], it is more like to be a topic of [SLOT] from [CATE]", and the probability scores of the estimated words in the position of {SLOT} are then regarded as the intermediate answers for the final classification. Furthermore, the experimental hardware environment comprises a CPU Intel Core i9-9900k, and a single Nvidia GPU of GTX 1080Ti.</p>
<h2>5. Experimental Results and Analyses</h2>
<p>Next, we conducted a series of baseline comparison experiments and ablation experiments to analyze and explore the specific connections between various key factors that affect the performance of ChatAgri on agricultural text classification tasks. We first verified the competitiveness and superiority of ChatAgri relative to known state-of-the-art (SOTA) models. Then, we systematically investigated the impact of different prompting strategies on the classification accuracy for text classification. Moreover, we also attempted to apply GPT-4 and investigated the superiority of GPT-4 compared to the basic version of ChatGPT, GPT3.5. The systematic analysis toward extensive empirical results firmly demonstrate the enormous potentials, feasibility, and broad application prospects of ChatGPT in agricultural text classification tasks.</p>
<h3>5.1. Methods Comparison</h3>
<p>Table 3 details comprehensive experimental results on the agricultural text classification task for our model ChatAgri and existing state-of-the-art approaches. In this table, as shown by multiple rows before the row data of ChatGPT-based Prompt QA, we conducted a systematic evaluation of the classification performance</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>Table 3: Performance Statistics of all baselines and ChatAgri on all adopted datasets. We respectively boldface and underline the score with the best performance and the second-best performance across all models (Query Date: 2023.3.16).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Learning <br> Paradigms</th>
<th style="text-align: center;">Baseline <br> Methods</th>
<th style="text-align: center;">Amazon-Food <br> -Comments</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">PestObserver <br> -France</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Natural-Hazards <br> -Twitter</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Natural-Hazards <br> -Type</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Agri-News <br> -Chinese</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">weighted <br> -F1</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">weighted <br> -F1</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">weighted <br> -F1</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">weighted <br> -F1</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">weighted <br> -F1</td>
</tr>
<tr>
<td style="text-align: center;">Traditional</td>
<td style="text-align: center;">SVM</td>
<td style="text-align: center;">0.627</td>
<td style="text-align: center;">0.624</td>
<td style="text-align: center;">0.672</td>
<td style="text-align: center;">0.655</td>
<td style="text-align: center;">0.763</td>
<td style="text-align: center;">0.742</td>
<td style="text-align: center;">0.811</td>
<td style="text-align: center;">0.811</td>
<td style="text-align: center;">0.523</td>
<td style="text-align: center;">0.522</td>
</tr>
<tr>
<td style="text-align: center;">Machine Learning</td>
<td style="text-align: center;">Random Forest</td>
<td style="text-align: center;">0.647</td>
<td style="text-align: center;">0.643</td>
<td style="text-align: center;">0.664</td>
<td style="text-align: center;">0.652</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;">0.755</td>
<td style="text-align: center;">0.863</td>
<td style="text-align: center;">0.863</td>
<td style="text-align: center;">0.553</td>
<td style="text-align: center;">0.534</td>
</tr>
<tr>
<td style="text-align: center;">Word Embedding</td>
<td style="text-align: center;">TextCNN</td>
<td style="text-align: center;">0.748</td>
<td style="text-align: center;">0.742</td>
<td style="text-align: center;">0.715</td>
<td style="text-align: center;">0.704</td>
<td style="text-align: center;">0.834</td>
<td style="text-align: center;">0.816</td>
<td style="text-align: center;">0.914</td>
<td style="text-align: center;">0.914</td>
<td style="text-align: center;">0.792</td>
<td style="text-align: center;">0.785</td>
</tr>
<tr>
<td style="text-align: center;">-based learning</td>
<td style="text-align: center;">TextRNN</td>
<td style="text-align: center;">0.727</td>
<td style="text-align: center;">0.725</td>
<td style="text-align: center;">0.707</td>
<td style="text-align: center;">0.697</td>
<td style="text-align: center;">0.845</td>
<td style="text-align: center;">0.827</td>
<td style="text-align: center;">0.931</td>
<td style="text-align: center;">0.931</td>
<td style="text-align: center;">0.812</td>
<td style="text-align: center;">0.801</td>
</tr>
<tr>
<td style="text-align: center;">PLM-based <br> fine-tuning</td>
<td style="text-align: center;">BERT-based <br> fine-tuning</td>
<td style="text-align: center;">0.767</td>
<td style="text-align: center;">0.764</td>
<td style="text-align: center;">0.736</td>
<td style="text-align: center;">0.714</td>
<td style="text-align: center;">0.869</td>
<td style="text-align: center;">0.839</td>
<td style="text-align: center;">0.945</td>
<td style="text-align: center;">0.945</td>
<td style="text-align: center;">0.826</td>
<td style="text-align: center;">0.819</td>
</tr>
<tr>
<td style="text-align: center;">PLM-base <br> prompt-tuning</td>
<td style="text-align: center;">T5-based <br> prompt-tuning</td>
<td style="text-align: center;">0.805</td>
<td style="text-align: center;">0.798</td>
<td style="text-align: center;">0.764</td>
<td style="text-align: center;">0.753</td>
<td style="text-align: center;">0.874</td>
<td style="text-align: center;">0.857</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">0.859</td>
<td style="text-align: center;">0.854</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BART-based <br> prompt-tuning</td>
<td style="text-align: center;">0.800</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">0.757</td>
<td style="text-align: center;">0.767</td>
<td style="text-align: center;">0.875</td>
<td style="text-align: center;">0.865</td>
<td style="text-align: center;">0.971</td>
<td style="text-align: center;">0.971</td>
<td style="text-align: center;">0.867</td>
<td style="text-align: center;">0.862</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT-based <br> Prompt QA</td>
<td style="text-align: center;">ChatAgri-base <br> (Ours)</td>
<td style="text-align: center;">0.798</td>
<td style="text-align: center;">0.793</td>
<td style="text-align: center;">0.794</td>
<td style="text-align: center;">0.789</td>
<td style="text-align: center;">0.866</td>
<td style="text-align: center;">0.853</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.863</td>
<td style="text-align: center;">0.856</td>
</tr>
</tbody>
</table>
<p>of these baseline models on these five datasets based on the above described hyperparameter settings. The time node of ChatGPT interface calls is March 16, 2023. Subsequent OpenAI official updates may lead to certain performance fluctuations towards the ChatGPT interface. The last row shows the evaluation results of our ChatAgri. For simplicity and clarity, we took the primary designed solution of ChatAgri as the basic model of ChatAgri for comparison. Specifically, we used the manually defined prompts, which is illustrated in Section 3.2.1, as the prompting template for ChatAgri. And we simultaneously adopted the rule-based and similarity-based text pattern matching strategy for the answer alignment engineering. Correspondingly, we labeled this basic model of ChatAgri as ChatAgri-base.</p>
<p>In Table 3, we classified all the existing agricultural text classification methods explored in this experiment according to their belonged learning paradigms. Among them, these methods based on fine-tuning PLM and PLM prompt engineering can be seen as the latest optimal benchmark approaches, and are respectively recorded in the last few rows of the table. From the table, it can be clearly observed that our ChatAgri has achieved exciting and competitive performance on some specific datasets, such as PestObserver-France and Natural-Hazards-Type. Not to mention surpassing traditional machine learning methods or word vectorbased representation learning methods by an absolute gap of over $10 \%$ to $20 \%$, which is a noticeable performance margin. Compared with the latest Transformer PLM-based deep learning methods,</p>
<p>ChatAgri is also a particularly strong presence, with no loss in accuracy or weighted-f1 compared to these SOTA methods. Specifically, ChatAgri significantly outperformed the PLM-based fine-tuning method represented by fine-tuned BERT by about $3.0 \%$ accuracy on the PestObserver-France dataset, and outperformed the PLM-based prompt-tuning method represented by prompt-tuned BART by approximately $2.2 \%$ weighted-f1 indicator. Similarly, ChatAgri also surpassed the above two state-of-the-art models by $0.6 \%$ accuracy and weighted-f1 indicators on the Natural-Hazards-Type dataset. In addition, the performance of ChatAgri on other datasets is also impressive. For example, it can be seen from the table that the performance of ChatAgri on the Agri-News-Chinese Chinese dataset have significantly surpassed the PLM-based fine-tuning method represented by fine-tuned BERT by about $3.7 \%$ accuracy and $4.7 \%$ weighted-f1 indicator. In addition, ChatAgri's performance is also slightly higher than the PLM-based fine-tuning method represented by prompttuned T5 by approximately $0.4 \%$ accuracy and $0.2 \%$ weighted-f1.</p>
<p>In addition, we further explored the reasons why ChatAgri performed more strongly on some datasets but slightly worse than previous SOTA methods on others. By observations from Table 3, we found that ChatAgri had obvious advantages on two minority language datasets, PestObserver-France and Agri-NewsChinese, but performed poorly on the widely-used English datasets, Amazon-Food-Comment and Natural-Hazards-Twitter. We speculate that this is mainly due</p>
<p>to the difference in the scale of large-scale language corpus training for different languages. After comprehensive investigations on latest literature [39; 10; 9], we can conclude that ChatGPT excels at handling various cross-linguistic tasks. Unlike previous methods based on traditional PLMs, ChatGPT's learning corpus is totally comprehensive and of high quality, covering the majority of languages spoken in most countries. Moreover, ChatGPT's ultra-large parameter size allows it to memorize and master more linguistic knowledge, not just limited to English. Therefore, in terms of cross-lingual understanding capability, ChatGPT is significantly superior to traditional PLM models (e.g. BERT, RoBERTa, and BART). Correspondingly, traditional PLM models perform poorly on less commonly spoken language datasets, as their learning corpus is far less comprehensive and of lower quality than that of ChatGPT. This probably is the primary factor that allows ChatAgri to perform well on various minority language datasets regardless of these datasets' linguistic characteristics.</p>
<p>On the Natural-Hazards-Type disaster category classification dataset based on the transformation of Natural-Hazards-Twitter, we found that both the PLMbased method and ChatAgri performed very well, fluctuating around $94 \%$ to $97 \%$ of accuracy and weightedf1, which meets almost all the users' needs. By observing this dataset itself, we observe that most of the text in the dataset can be classified by using some fixed phrases as trigger words. For example, there is a sentence in the dataset: "Florida governor declares state of emergency ahead of Dorian and warns Floridians on the East Coast", where the word "Dorian" essentially belongs to the topic of a happened American hurricane disaster. As we know, a simple semantic context always can make the training and prediction of NLU tasks much simpler, so these existing SOTA models have achieved satisfactory performances. It is worth mentioning that during the process of reorganizing the Natural-HazardsTwitter dataset into the Natural-Hazards-Type dataset, we intuitively maintained the same quantity of test samples for each category. Therefore, the calculation results of the accuracy indicator on the Natural-Hazards-Type dataset are the same with the weighted-F1 indicator.</p>
<p>The above discussion fully demonstrate the superiority of ChatGPT in agricultural text classification: even though ChatGPT has not been trained on any training set, it can still outperform all kinds of SOTA methods that trained on large-scale training sets. Note that ChatAgri-base used as a comparison baseline here solely employs the manually defined prompting strategy, which is a basic and simple one. Even the simple</p>
<p>ChatAgri can achieve impressive results, which makes us more convinced that the ChatGPT-based solution will be the future direction for the continuous research development of agricultural text classification.</p>
<h3>5.2. Improving ChatGPT with Advanced Prompting Strategies</h3>
<p>In order to explore the influence of different prompt generation strategies to the final classification performance, we conducted systematic evaluations and indepth explorations of various prompt generation strategies introduced in Section 3.2 to clarify the advantages and significance of different prompt generation strategies in this section. The current date for ChatGPT interface calls is March 24, 2023. Subsequent OpenAI updates to the ChatGPT official API may influence the future function calls, leading to certain performance discrepancies.</p>
<p>From the first two rows of Table 4, it can be discovered that the ChatAgri which adopts ChatGPT Triggered-Prompts outperforms the Manually Defined Prompts strategy counterpart in most cases, indicating that ChatGPT can generate better prompts to trigger its more comprehensive knowledge for more accurate prediction. For instance, ChagAgri based on ChatGPT Triggered-Prompts improved the accuracy by average $2.1 \%$ and $1.1 \%$ on the PestObserver-France and Agri-News-Chinese datasets, respectively, compared to ChagAgri based on Manually Defined Prompts. This empirically demonstrates that prompt engineering for ChatGPT should be combined with ChatGPT's own understanding and feedback to achieve better classification performance.</p>
<p>From the third and fourth rows of Table 4, it can be observed that the Zero-Shot Similarity-Prompts strategy performs significantly better than the baseline prompts on the first three datasets, but its performance on the Natural-Hazards-Type and Agri-News-Chinese datasets is relatively unsatisfactory, even falling behind the basic prompts, namely Manually Defined Prompts and ChatGPT Triggered-Prompts. For example, ChatAgri based on Zero-Shot Similarity-Prompts reduced the accuracy and weighted-f1 by $0.3 \%$ compared to ChatAgri-base based on Manually Defined Prompts on the Natural-Hazards-Type dataset.</p>
<p>We can also easily observe from Table 4 that the Chain-of-Thought Prompts strategy significantly improves the overall task performance on all datasets, and its effect is better than that of ChatAgri based on ZeroShot Similarity-Prompts. Especially on the Natural-Hazards-Type and Agri-News-Chinese datasets, Chain-of-Thought Triggered-Prompts has further improved,</p>
<p>Table 4: Comparative experimental results of ChatAgri-base and various model variants of ChatAgri that utilized various advanced prompts, where the ChatAgri-base can be regarded as a basic ChatAgri implementation (Query Date: 2023.3.24).</p>
<p>| Prompting Strategies | Amazon-Food <br> -Comments | | PestObserver <br> -France | | Natural-Hazards <br> -Twitter | | Natural-Hazards <br> -Type | | Agri-News <br> -Chinese | |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| | acc | weighted <br> -F1 | acc | weighted <br> -F1 | acc | weighted <br> -F1 | acc | weighted <br> -F1 | acc | weighted <br> -F1 |
| Manually Defined Prompts (ChatAgri-base) | 0.798 | 0.793 | 0.794 | 0.789 | 0.866 | 0.853 | 0.978 | 0.978 | 0.863 | 0.856 |
| ChatGPT Triggered | 0.806 | 0.803 | 0.815 | 0.812 | 0.871 | 0.862 | 0.978 | 0.978 | 0.874 | 0.867 |
| - Prompts | $\uparrow 0.8 \%$ | $\uparrow 1.0 \%$ | $\uparrow 2.1 \%$ | $\uparrow 1.4 \%$ | $\uparrow 0.5 \%$ | $\uparrow 0.9 \%$ | $=0.0 \%$ | $=0.0 \%$ | $\uparrow 1.1 \%$ | $\uparrow 1.1 \%$ |
| Zero-Shot Similarity | 0.810 | 0.807 | 0.824 | 0.821 | 0.874 | 0.866 | 0.975 | 0.975 | 0.863 | 0.856 |
| - Prompts | $\uparrow 1.2 \%$ | $\uparrow 1.4 \%$ | $\uparrow 3.0 \%$ | $\uparrow 2.2 \%$ | $\uparrow 0.8 \%$ | $\uparrow 1.3 \%$ | $\downarrow 0.3 \%$ | $\downarrow 0.3 \%$ | $=0.0 \%$ | $=0.0 \%$ |
| Chain-of-Thought Triggered | 0.816 | 0.814 | 0.832 | 0.829 | 0.874 | 0.866 | 0.981 | 0.981 | 0.889 | 0.883 |
| - Prompts | $\uparrow 1.8 \%$ | $\uparrow 2.1 \%$ | $\uparrow 3.8 \%$ | $\uparrow 3.0 \%$ | $\uparrow 0.8 \%$ | $\uparrow 1.3 \%$ | $\uparrow 0.3 \%$ | $\uparrow 0.3 \%$ | $\uparrow 2.7 \%$ | $\uparrow 2.7 \%$ |</p>
<p>which is an excellent effect that Zero-Shot SimilarityPrompts cannot achieve. For example, on the Agri-News-Chinese dataset, Chain-of-Thought TriggeredPrompts simultaneously improved the accuracy and weighted-f1 by average $2.7 \%$ compared to ChagAgribase.</p>
<p>It is worth mentioning that for the binary classification dataset Natural-Hazards-Twitter, the classification process based on the Chain-of-Thought rules only requires one comparison step, and the pivot sentence selected by this strategy is exactly the same as that used by Zero-Shot Similarity-Prompts. Therefore, the performance of the Chain-of-Thought Prompts and ZeroShot Similarity-Prompts strategies is the same here. Moreover, due to the simple semantics of the Natural-Hazards-Type constructed by us, the prediction effect of various ChatAgri model variants is close to saturation. Therefore, the Natural-Hazards-Type dataset is not more persuasive than other datasets in terms of reference value.</p>
<p>In summary, Chain-of-Thought Triggered-Prompts is particularly good at handling texts with many classification categories in multi-classification tasks, which also confirms the effectiveness of the divide-and-conquer idea of splitting complex multiple classification tasks into multiple simple binary classifications for handling slightly complex classification tasks. In contrast, Zero-Shot Similarity-Prompts performs relatively poorly when there are many classification categories, and even worse than the effects of Manually Defined Prompts and ChatGPT Triggered-Prompts. We speculate that the main reason is that the selection of pivot sentences is not perfect on the one hand, and on the other hand, when ChatGPT judges the specific similarity of multiple semantically similar pivot sentences,
multiple semantically similar pivot sentences can easily confuse ChatGPT, leading to its easy misjudgment of the final classification result.</p>
<h3>5.3. Few-shot prompt-tuning and zero-shot ChatAgri</h3>
<p>Although most representative text classification methods are based on supervised learning with a large volume of high-quality annotated samples. The fact is, the annotation procedure of supervised corpora demands the expertise of domain specialists and is expensive and time-consuming, as well as a significant amount of manual efforts. Thus, in specific practical application scenarios, it is often more widespread and ubiquitous to apply data-scarce learning due to insufficient resource and scarce data.</p>
<p>As numerous literature have suggested [17; 24; 25], prompt-learning is particularly useful in data insufficient scenarios. It is a powerful and promising NLP technique which fully leverages the prior knowledge learned from the PLM's pre-trained stage. By using the prompting tricks, prompt-learning allows PLMs quickly adapt to various new tasks while learning on a small amount of data. Here, we delved in-depth into the characteristics, differences, and interactions between ChatGPT and prompt-learning paradigms. The evaluation statistic of these prompt learning methods was simulated based on the open-source framework OpenPrompt. OpenPrompt [45] is an advanced research toolkit developed by Tsinghua University ${ }^{15}$. OpenPrompt integrates various prompt-based learning methods, making it easy and feasible for researchers to quickly develop and deploy their prompt-tuning solutions.</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 5: Performance statistics of ChatAgri and prompt learning baselines in the zero/few-shot supervised learning. Values (\%) in green represent the increased performances of ChatAgri (zero-shot) compared to the second-best results (50-shot).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Few-Shot Learning</th>
<th style="text-align: center;">Methods</th>
<th style="text-align: center;">Amazon-Food <br> -Comments</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">PestObserver <br> -France</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Natural-Hazards <br> -Twitter</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Natural-Hazards <br> -Type</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Agri-News <br> -Chinese</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { weighted } \ &amp; -\mathrm{F} 1 \end{aligned}$</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { weighted } \ &amp; -\mathrm{F} 1 \end{aligned}$</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { weighted } \ &amp; -\mathrm{F} 1 \end{aligned}$</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { weighted } \ &amp; -\mathrm{F} 1 \end{aligned}$</td>
<td style="text-align: center;">acc</td>
<td style="text-align: center;">$\begin{aligned} &amp; \text { weighted } \ &amp; -\mathrm{F} 1 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Zero - <br> Shot</td>
<td style="text-align: center;">T5-based prompt-tuning</td>
<td style="text-align: center;">0.521</td>
<td style="text-align: center;">0.523</td>
<td style="text-align: center;">0.474</td>
<td style="text-align: center;">0.466</td>
<td style="text-align: center;">0.562</td>
<td style="text-align: center;">0.545</td>
<td style="text-align: center;">0.597</td>
<td style="text-align: center;">0.597</td>
<td style="text-align: center;">0.425</td>
<td style="text-align: center;">0.419</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BART-based prompt-tuning</td>
<td style="text-align: center;">0.545</td>
<td style="text-align: center;">0.539</td>
<td style="text-align: center;">0.439</td>
<td style="text-align: center;">0.431</td>
<td style="text-align: center;">0.573</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.452</td>
<td style="text-align: center;">0.447</td>
</tr>
<tr>
<td style="text-align: center;">20 - <br> Shot</td>
<td style="text-align: center;">T5-based prompt-tuning</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">0.595</td>
<td style="text-align: center;">0.585</td>
<td style="text-align: center;">0.578</td>
<td style="text-align: center;">0.674</td>
<td style="text-align: center;">0.651</td>
<td style="text-align: center;">0.757</td>
<td style="text-align: center;">0.757</td>
<td style="text-align: center;">0.563</td>
<td style="text-align: center;">0.559</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BART-based prompt-tuning</td>
<td style="text-align: center;">0.627</td>
<td style="text-align: center;">0.609</td>
<td style="text-align: center;">0.563</td>
<td style="text-align: center;">0.554</td>
<td style="text-align: center;">0.643</td>
<td style="text-align: center;">0.626</td>
<td style="text-align: center;">0.761</td>
<td style="text-align: center;">0.761</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">0.592</td>
</tr>
<tr>
<td style="text-align: center;">50 - <br> Shot</td>
<td style="text-align: center;">T5-based prompt-tuning</td>
<td style="text-align: center;">0.679</td>
<td style="text-align: center;">0.674</td>
<td style="text-align: center;">0.656</td>
<td style="text-align: center;">0.647</td>
<td style="text-align: center;">0.732</td>
<td style="text-align: center;">0.719</td>
<td style="text-align: center;">0.831</td>
<td style="text-align: center;">0.831</td>
<td style="text-align: center;">0.766</td>
<td style="text-align: center;">0.760</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BART-based prompt-tuning</td>
<td style="text-align: center;">0.694</td>
<td style="text-align: center;">0.688</td>
<td style="text-align: center;">0.643</td>
<td style="text-align: center;">0.629</td>
<td style="text-align: center;">0.758</td>
<td style="text-align: center;">0.746</td>
<td style="text-align: center;">0.854</td>
<td style="text-align: center;">0.854</td>
<td style="text-align: center;">0.742</td>
<td style="text-align: center;">0.738</td>
</tr>
<tr>
<td style="text-align: center;">Zero-Shot <br> (Default)</td>
<td style="text-align: center;">ChatAgri-base <br> (Ours)</td>
<td style="text-align: center;">0.798 <br> $\uparrow 10.5 \%$</td>
<td style="text-align: center;">0.793 <br> $\uparrow 10.5 \%$</td>
<td style="text-align: center;">0.794 <br> $\uparrow 15.1 \%$</td>
<td style="text-align: center;">0.789 <br> $\uparrow 16.0 \%$</td>
<td style="text-align: center;">0.866 <br> $\uparrow 10.8 \%$</td>
<td style="text-align: center;">0.853 <br> $\uparrow 10.7 \%$</td>
<td style="text-align: center;">0.978 <br> $\uparrow 12.4 \%$</td>
<td style="text-align: center;">0.978 <br> $\uparrow 12.4 \%$</td>
<td style="text-align: center;">0.863 <br> $\uparrow 12.1 \%$</td>
<td style="text-align: center;">0.856 <br> $\uparrow 11.8 \%$</td>
</tr>
</tbody>
</table>
<p>Correspondingly, we provided a detailed comparison to explore the relationships between ChatAgri and PLM-based prompt-tuning methods under few-shot and zero-shot learning settings. As shown in Table 5, we report the experimental results of these SOTA methods (i.e. T5-based prompt-tuning, BART-based prompttuning and ChatAgri) under the few-shot learning and zero-shot settings.</p>
<p>Specifically, from the first row of Table 5, it can be seen that prompt learning methods are extremely effective in zero-shot learning (i.e., without any training on any samples), far surpassing the performance of models that guess based on average probability. For instance, on the Natural-Hazards-Twitter dataset, the BART-based prompt-tuning method achieved an accuracy of $57.3 \%$ in zero-shot learning, compared to a performance of $33.3 \%$ based on average probability, an improvement of about 24 percentage points. Especially on the fiveclassification dataset, Natural-Hazards-Type, the evaluated accuracy was $63.9 \%$, which is much higher than the baseline accuracy of $20 \%$ for random prediction. In addition, under the 20 -shot and 50 -shot few-shot settings, the improvement of these prompt learning methods is even more significant, and the specific experimental results can be found in the third and fourth rows. The above statistical results indicate that prompt learning methods are very effective in training with small amounts of data.</p>
<p>Most impressively, it can be obviously observed from
the table that ChatAgri performs significantly better than these prompt learning methods and achieves state-of-the-art performances in most aspects, regardless of different classification category topics and counts. The text classification performance of ChatAgri-base has surpassed these SOTA models in all test datasets with a significant improvement, demonstrating its superiority in all aspects. For example, compared with the baseline BART-based prompt-tuning that trained on 50-shot setting, ChatAgri-base yielded approximately absolute $10.5 \%, 15.1 \%$, and $10.8 \%$ improvements in accuracy on datasets Amazon-Food-Comment, PestObserver-France, and Natural-Hazards-Twitter, respectively. It goes without saying that even compared to prompt learning models under zero-shot learning, those better performed, which is trained on a small amount of data, are significantly inferior to the ChatGPT-based classification framework ChatAgri without any finetuning. In addition, better prompt engineering, ChatGPT models, and answer alignment engineering could further bring better results to the ChatAgri technology. Overall, ChatAgri has essentially surpassed the existing state-of-the-art prompt learning paradigm in all aspects, which is also the enormous potentials brought by the ultra-large-scale models.</p>
<p>In conclusion, ChatAgri shows its effectiveness and superiority in data-insufficient learning scenarios, indicating that ChatGPT has strong cross-domain and generalization capabilities. This kind of generalization is</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 11: The values shows the absolute metrics of accuracy and wighted-F1, which are reported using (\%). The first group of a.(1), a.(2) and a.(3) denotes the ChatAgri ${ }<em _beta="\beta">{\text {ar }}$, and the second group of b.(1), b.(2) and b.(3) denotes the ChatAgri ${ }</em>$ counterpart. Reported results were averaged over 5 runs to ensure experimental reliability and robustness.
one of the directions for the development of future General Purpose AI, as it can help us build more flexible and adaptable intelligent systems that can handle various tasks and scenarios.</p>
<p>As we know, better performance would like to be obtained once using smoother prompts or update ChatGPT itself. As the impact of advanced prompting strategies has been investigated in Section 5.2, we then explore the potentials of upgrading the ChatAgri framework with more advanced ChatGPT, GPT-4.</p>
<h3>5.4. Potentials between ChatGPT and GPT-4</h3>
<p>Just as we were conducting research on vanilla ChatGPT (GPT-3.5) in March to April, 2023, OpenAI coincidentally released their latest powerful conversational system, GPT-4 [10], which serves as an improved version of ChatGPT. Thus, it is necessary to conduct additional exploration experiments to evaluate the overall performance of GPT-4, the upgraded ChatGPT, in the agriculture field text classification task.</p>
<p>Building on the advanced technologies learned from ChatGPT, GPT-4 has been iteratively refined to achieve unprecedented levels of authenticity, controllability, and rejection of undesirable outputs. In terms of model parameter scale, GPT-4 is expected to have over 1 trillion
parameters, a significant increase from the GPT-3.5's 175 billion parameters. This means that GPT-4 will be able to handle larger amounts of data and generate longer, more complex, coherent, accurate, diverse, and creative text. In terms of overall capability, compared to the previous version of ChatGPT, GPT-4 boasts improved performances in advanced reasoning, handling complex instructions, and demonstrating more creativity.</p>
<p>But GPT-4 currently has a cap of 25 messages every three hours by the latest released policy of OpenAI. It is the computation resource scarcity that caused the limited API capacity, which is far way from reaching the demand of the comprehensive experiments towards GPT-4 based ChatAgri. To overcome those pitfalls, we have taken a relatively balanced approach based on the trade-offs between experimental effectiveness and resource consumption (running time and empirical cost) in our experiments. Specifically, we made several reasonable reductions to the experiment from three perspectives: the linguistic categories, scales and their contributions of the datasets. The specific adjustments and arrangements for this experiment are as follows:</p>
<ul>
<li>For dataset selection, in order to comprehensively</li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{15}$ OpenPrompt can be accessed at https://github.com/ thun1p/OpenPrompt/ [Accessed on 2023.03].&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{10}$ BERT can be obtained from: https://huggingface.co/ docs/transformers/model_doc/bert [Accessed on 2023.03].
${ }^{11}$ T5-base can be obtained from: https://huggingface.co/ t5-base [Accessed on 2023.03].
${ }^{12}$ BART can be obtained from: https://huggingface.co/ docs/transformers/model_doc/bart [Accessed on 2023.03].
${ }^{13}$ Python can be downloaded from: https://www.python.org/ downloads/release/python-370 [Accessed on 2023.03].
${ }^{14}$ Pytorch can be downloaded from: https://pytorch.org/ blog/pytorch-1.9-released [Accessed on 2023.03].&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>