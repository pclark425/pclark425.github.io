<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5312 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5312</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5312</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-108.html">extraction-schema-108</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-ddc1899e59a8e4fda60f5a175fef710a63abcef9</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ddc1899e59a8e4fda60f5a175fef710a63abcef9" target="_blank">DrugAssist: a large language model for molecule optimization</a></p>
                <p><strong>Paper Venue:</strong> Briefings Bioinform.</p>
                <p><strong>Paper TL;DR:</strong> The proposed DrugAssist is an interactive molecule optimization model which performs optimization through human–machine dialogue by leveraging LLM’s strong interactivity and generalizability, simultaneously showcasing immense potential in transferability and iterative optimization.</p>
                <p><strong>Paper Abstract:</strong> Abstract Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human–machine dialogue by leveraging LLM’s strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called ‘MolOpt-Instructions’ for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs’ application for drug discovery.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5312.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5312.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DrugAssist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DrugAssist (fine-tuned Llama2-7B-Chat for molecule optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interactive, instruction-tuned large language model for molecule optimization that generates optimized SMILES via multi-turn human-machine dialogue and iterative refinement; fine-tuned on a large instruction dataset (MolOpt-Instructions) to optimize single and multiple molecular properties under similarity constraints and range/threshold objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DrugAssist (fine-tuned Llama2-7B-Chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based conversational LLM (instruction-tuned/chat model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine-tuned on MolOpt-Instructions (~1M instruction-response molecule pairs derived from 1M ZINC molecules via mmpdb and annotated with properties from iDrug) mixed with Stanford Alpaca instruction-following data (Alpaca replicated 5x) using multi-task learning to preserve dialogue capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Drug discovery — molecule optimization (single- and multi-property optimization including Solubility, BBBP, hERG, QED, hydrogen bond donors/acceptors; supports increase/decrease, thresholded, and target-range objectives).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Supervised instruction tuning / fine-tuning of Llama2-7B-Chat on the MolOpt-Instructions dataset, used at inference via natural-language prompts and multi-turn human-in-the-loop iterative refinement; retrieval-assisted iterative optimization (providing example molecules from a database as hints) is supported.</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>SMILES strings (generated SMILES as optimized molecules).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Success rate (task-specific: e.g., property in required range or exceeding threshold), valid SMILES rate (validity), similarity to source molecule, 'valid ratio' and 'correct ratio' under 'loose' and 'strict' criteria, per-property thresholds (e.g., QED Δ≥0.1, BBBP Δ≥0.1, Solubility range requirements), and multi-property simultaneous success.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>MolOpt-Instructions (released by authors), ZINC (source of molecules), iDrug (property prediction engine used for labels), Stanford Alpaca (mixed instruction data); evaluation testset: 500 randomly selected ZINC molecules and the standard molecule optimization benchmarks used by prior works for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>DrugAssist achieves leading performance among compared methods: Table 4 reports Solubility success 0.74, BBBP success 0.80, multi-property ('All') success 0.62, valid rate 0.98 and average similarity 0.69. In Table 5 across 16 tasks DrugAssist shows very high valid ratios (~0.95-0.99) and high correct ratios (examples: QED+ correct 0.76/0.63 loose/strict; solubility+ correct 0.80/0.41 loose/strict; bbbp+ correct 0.82/0.61), substantially outperforming baseline LLMs and traditional sequence models on both single- and multi-property optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared against sequence-based baselines (Mol-Seq2Seq, Mol-Transformer) and other LLMs (Llama2-7B-Chat baseline, GPT-3.5-turbo via ChatDrug prompts, BioMedGPT-LM-7B), DrugAssist outperformed them in success rate and validity; Mol-Transformer had high validity and similarity but lower success; GPT-3.5 often produced valid SMILES but frequently returned identical molecules (low optimization success); BioMedGPT-LM-7B often produced non-molecular or irrelevant outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Lower success on more stringent 'range' specification tasks (notably esol+ strict) compared to other tasks; reliance on in-silico property predictors (iDrug) for training/evaluation (no experimental wet-lab validation reported); potential for hallucination and need to reduce it (noted as future work); model may fail initially and require iterative human-provided example retrieval to succeed; catastrophic forgetting addressed via multi-task mixing but remains a broader concern.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5312.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5312.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-7B-Chat (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 2 7B Chat (Meta's fine-tuned conversational Llama2-7B model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open foundation conversational transformer model by Meta used here both as the pre-trained base for DrugAssist and as a baseline LLM for molecule optimization via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llama 2: Open foundation and fine-tuned chat models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2-7B-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based conversational LLM (chat model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Pretrained/fine-tuned by Meta on mixed corpora (precise pretraining corpora not specified in this paper); used unmodified as a baseline and as the base model for DrugAssist fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used as a general-purpose conversational model applied (via prompting) to molecule optimization tasks in the study.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompting (single- and multi-turn natural language prompts) without domain-specific fine-tuning for molecule optimization in baseline comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>SMILES (when prompted to output optimized molecules).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Same metrics as DrugAssist in comparisons: valid ratio, correct ratio under loose/strict criteria, success rates for property objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>Evaluated on the authors' 16 optimization tasks and 500-molecule ZINC testset used in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Baseline Llama2-7B-Chat produced moderate valid ratios but low correct ratios on optimization tasks (examples from Table 5: QED+ valid ratio 0.69/0.55 and correct ratio 0.17/0.16), performing substantially worse than DrugAssist after fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Underperforms compared to DrugAssist (fine-tuned version) and often produces fewer successful optimizations than GPT-3.5-turbo in validity, though GPT-3.5 often fails to modify molecules meaningfully; Mol-Transformer (task-specific transformer) shows stronger performance than Llama2 baseline on some metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Without domain-specific instruction fine-tuning, its ability to follow molecule-optimization instructions and produce valid, property-optimized SMILES is limited (low success/correct ratios reported).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5312.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5312.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-turbo (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-turbo (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used closed-source chat-oriented LLM (referred to as ChatGPT/GPT-3.5-turbo) used via prompt engineering / ChatDrug workflow to attempt molecule editing/optimization; produces many valid SMILES but often outputs identical molecules or fails to complete optimization objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based chat/auto-regressive LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified in this paper (general ChatGPT pretraining not detailed here).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Applied to molecule optimization tasks via prompting (through ChatDrug-style prompts) in comparative experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt engineering / multi-turn prompting (ChatDrug workflow) with carefully crafted prompts to request optimized SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>SMILES strings (model outputs when successful), but often returns unchanged input molecule.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Valid ratio and correct ratio under loose/strict criteria across 16 optimization tasks (same evaluation framework as for DrugAssist).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>Evaluated on the same 16 tasks and 500-molecule ZINC testset used by the authors.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GPT-3.5-turbo produced very high valid ratios on many tasks (e.g., QED+ valid 0.97/0.96) but low correct/optimization success (e.g., QED+ correct 0.15/0.15), often outputting the same molecule unchanged, resulting in poor optimization effectiveness compared to DrugAssist.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Higher validity than some baselines but lower optimization success than DrugAssist; GPT-3.5 often fails to propose modifications that change target properties meaningfully.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Tendency to return identical molecules (no meaningful optimization) despite valid SMILES output; lower success rates on property-targeted optimization tasks even when multi-turn prompting is used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5312.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5312.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioMedGPT-LM-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioMedGPT-LM-7B (BiomedGPT large generative model, 7B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Llama2-based biomedical generative language model used as a baseline; in this study it struggled to understand molecule optimization instructions and frequently produced invalid or non-molecular outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BioMedGPT-LM-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Llama2-based transformer generative model for biomedical domain</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Described as biomedical-domain pretraining/fine-tuning in its original work; specific training corpus not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Applied as an LLM baseline for molecule optimization via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompting (single/multi-turn) to request optimized SMILES; no domain-specific instruction fine-tuning on MolOpt-Instructions in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>Intended SMILES; however, often produced non-molecular or irrelevant textual guidance instead of SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Valid ratio and correct ratio under loose/strict criteria across the same set of tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>Evaluated on the authors' 16 tasks and 500-molecule ZINC testset.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>BioMedGPT-LM-7B showed poor valid ratios and low success rates (example QED+ valid ratio 0.34/0.32 and correct ratio 0.15/0.09), frequently failing to output optimized SMILES and instead returning guidance or non-molecule content.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Performs worse than DrugAssist and GPT-3.5 in this molecule-optimization benchmark; its domain specialization did not translate to successful molecule generation under the prompting regimes used here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Difficulty understanding optimization instructions in this setup; often generated non-molecule outputs (e.g., telling users to visit websites) instead of SMILES, leading to low validity and poor utility for molecule generation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5312.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5312.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatMol</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatMol (Interactive molecular discovery with natural language)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conversational system for molecular design mentioned in related work that supports molecule understanding and molecule generation (bi-directional conversion between textual descriptions and SMILES); cited as prior work enabling conversational molecular design.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Interactive molecular discovery with natural language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatMol (system/framework)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Conversational LLM-based molecular design framework (details in original paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not detailed in this paper (see cited ChatMol reference for specifics).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Conversational molecular design (molecule understanding and generation).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Conversational prompting / bidirectional conversion between descriptions and SMILES (as described in related work section).</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>SMILES and textual molecular descriptions (bidirectional conversion).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified in this paper (only cited; evaluation details reside in the original ChatMol publication).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Mentioned as existing work enabling conversational molecular design and generation; not evaluated or used experimentally in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Cited as part of the landscape of conversational LLM applications to molecules; DrugAssist differs by being instruction-tuned specifically on an extensive MolOpt-Instructions dataset for iterative optimization with human dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not discussed in this paper; refer to the original ChatMol publication for limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5312.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5312.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDrug</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDrug (ChatGPT-powered conversational drug editing using retrieval and domain feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A workflow/framework to facilitate drug editing using LLMs (ChatGPT); cited here as a prior approach for obtaining molecule-editing suggestions via carefully crafted prompts and retrieval/domain-feedback workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chatgpt-powered conversational drug editing using retrieval and domain feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatDrug (framework using general LLMs, e.g., ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Prompting/retrieval-augmented conversational workflow integrating LLM outputs and retrieval/domain feedback</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>dependent on the underlying LLM (e.g., GPT-3.5) — not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Framework uses prompts and retrieval from molecular databases; no fixed training data described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Conversational drug editing and molecule optimization via LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt engineering combined with retrieval and domain feedback to produce molecule edit suggestions (used as reference workflow in related work and comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>SMILES and textual editing suggestions (as described in the cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not detailed here; in this paper GPT-3.5 via similar prompting showed high validity but low optimization success.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>Not specified in this paper; see ChatDrug publication for details.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited as an LLM-based molecule editing workflow; the present paper used a ChatDrug-like prompting approach to obtain GPT-3.5 outputs for baseline comparison (those GPT-3.5 outputs often had high validity but low optimization success).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Serves as an example of prior LLM-based editing workflows; DrugAssist differs by being instruction-tuned on a dedicated molecule-optimization instruction dataset enabling better optimization success and iterative refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not discussed in depth here; authors note general LLM prompting methods (as in ChatDrug) can yield valid SMILES but often fail to change molecule properties meaningfully without task-specific fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chatgpt-powered conversational drug editing using retrieval and domain feedback <em>(Rating: 2)</em></li>
                <li>Interactive molecular discovery with natural language <em>(Rating: 2)</em></li>
                <li>Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine <em>(Rating: 2)</em></li>
                <li>Comprehensive evaluation of molecule property prediction with chatgpt <em>(Rating: 2)</em></li>
                <li>Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5312",
    "paper_id": "paper-ddc1899e59a8e4fda60f5a175fef710a63abcef9",
    "extraction_schema_id": "extraction-schema-108",
    "extracted_data": [
        {
            "name_short": "DrugAssist",
            "name_full": "DrugAssist (fine-tuned Llama2-7B-Chat for molecule optimization)",
            "brief_description": "An interactive, instruction-tuned large language model for molecule optimization that generates optimized SMILES via multi-turn human-machine dialogue and iterative refinement; fine-tuned on a large instruction dataset (MolOpt-Instructions) to optimize single and multiple molecular properties under similarity constraints and range/threshold objectives.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "DrugAssist (fine-tuned Llama2-7B-Chat)",
            "model_type": "Transformer-based conversational LLM (instruction-tuned/chat model)",
            "model_size": "7B parameters",
            "training_data": "Fine-tuned on MolOpt-Instructions (~1M instruction-response molecule pairs derived from 1M ZINC molecules via mmpdb and annotated with properties from iDrug) mixed with Stanford Alpaca instruction-following data (Alpaca replicated 5x) using multi-task learning to preserve dialogue capabilities.",
            "application_domain": "Drug discovery — molecule optimization (single- and multi-property optimization including Solubility, BBBP, hERG, QED, hydrogen bond donors/acceptors; supports increase/decrease, thresholded, and target-range objectives).",
            "generation_method": "Supervised instruction tuning / fine-tuning of Llama2-7B-Chat on the MolOpt-Instructions dataset, used at inference via natural-language prompts and multi-turn human-in-the-loop iterative refinement; retrieval-assisted iterative optimization (providing example molecules from a database as hints) is supported.",
            "output_representation": "SMILES strings (generated SMILES as optimized molecules).",
            "evaluation_metrics": "Success rate (task-specific: e.g., property in required range or exceeding threshold), valid SMILES rate (validity), similarity to source molecule, 'valid ratio' and 'correct ratio' under 'loose' and 'strict' criteria, per-property thresholds (e.g., QED Δ≥0.1, BBBP Δ≥0.1, Solubility range requirements), and multi-property simultaneous success.",
            "benchmarks_or_datasets": "MolOpt-Instructions (released by authors), ZINC (source of molecules), iDrug (property prediction engine used for labels), Stanford Alpaca (mixed instruction data); evaluation testset: 500 randomly selected ZINC molecules and the standard molecule optimization benchmarks used by prior works for comparison.",
            "results_summary": "DrugAssist achieves leading performance among compared methods: Table 4 reports Solubility success 0.74, BBBP success 0.80, multi-property ('All') success 0.62, valid rate 0.98 and average similarity 0.69. In Table 5 across 16 tasks DrugAssist shows very high valid ratios (~0.95-0.99) and high correct ratios (examples: QED+ correct 0.76/0.63 loose/strict; solubility+ correct 0.80/0.41 loose/strict; bbbp+ correct 0.82/0.61), substantially outperforming baseline LLMs and traditional sequence models on both single- and multi-property optimization.",
            "comparison_to_other_methods": "Compared against sequence-based baselines (Mol-Seq2Seq, Mol-Transformer) and other LLMs (Llama2-7B-Chat baseline, GPT-3.5-turbo via ChatDrug prompts, BioMedGPT-LM-7B), DrugAssist outperformed them in success rate and validity; Mol-Transformer had high validity and similarity but lower success; GPT-3.5 often produced valid SMILES but frequently returned identical molecules (low optimization success); BioMedGPT-LM-7B often produced non-molecular or irrelevant outputs.",
            "limitations_or_challenges": "Lower success on more stringent 'range' specification tasks (notably esol+ strict) compared to other tasks; reliance on in-silico property predictors (iDrug) for training/evaluation (no experimental wet-lab validation reported); potential for hallucination and need to reduce it (noted as future work); model may fail initially and require iterative human-provided example retrieval to succeed; catastrophic forgetting addressed via multi-task mixing but remains a broader concern.",
            "uuid": "e5312.0",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Llama2-7B-Chat (baseline)",
            "name_full": "Llama 2 7B Chat (Meta's fine-tuned conversational Llama2-7B model)",
            "brief_description": "An open foundation conversational transformer model by Meta used here both as the pre-trained base for DrugAssist and as a baseline LLM for molecule optimization via prompting.",
            "citation_title": "Llama 2: Open foundation and fine-tuned chat models",
            "mention_or_use": "use",
            "model_name": "Llama2-7B-Chat",
            "model_type": "Transformer-based conversational LLM (chat model)",
            "model_size": "7B parameters",
            "training_data": "Pretrained/fine-tuned by Meta on mixed corpora (precise pretraining corpora not specified in this paper); used unmodified as a baseline and as the base model for DrugAssist fine-tuning.",
            "application_domain": "Used as a general-purpose conversational model applied (via prompting) to molecule optimization tasks in the study.",
            "generation_method": "Prompting (single- and multi-turn natural language prompts) without domain-specific fine-tuning for molecule optimization in baseline comparisons.",
            "output_representation": "SMILES (when prompted to output optimized molecules).",
            "evaluation_metrics": "Same metrics as DrugAssist in comparisons: valid ratio, correct ratio under loose/strict criteria, success rates for property objectives.",
            "benchmarks_or_datasets": "Evaluated on the authors' 16 optimization tasks and 500-molecule ZINC testset used in comparisons.",
            "results_summary": "Baseline Llama2-7B-Chat produced moderate valid ratios but low correct ratios on optimization tasks (examples from Table 5: QED+ valid ratio 0.69/0.55 and correct ratio 0.17/0.16), performing substantially worse than DrugAssist after fine-tuning.",
            "comparison_to_other_methods": "Underperforms compared to DrugAssist (fine-tuned version) and often produces fewer successful optimizations than GPT-3.5-turbo in validity, though GPT-3.5 often fails to modify molecules meaningfully; Mol-Transformer (task-specific transformer) shows stronger performance than Llama2 baseline on some metrics.",
            "limitations_or_challenges": "Without domain-specific instruction fine-tuning, its ability to follow molecule-optimization instructions and produce valid, property-optimized SMILES is limited (low success/correct ratios reported).",
            "uuid": "e5312.1",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "GPT-3.5-turbo (ChatGPT)",
            "name_full": "GPT-3.5-turbo (ChatGPT)",
            "brief_description": "A widely-used closed-source chat-oriented LLM (referred to as ChatGPT/GPT-3.5-turbo) used via prompt engineering / ChatDrug workflow to attempt molecule editing/optimization; produces many valid SMILES but often outputs identical molecules or fails to complete optimization objectives.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo (ChatGPT)",
            "model_type": "Transformer-based chat/auto-regressive LLM",
            "model_size": "not specified in this paper",
            "training_data": "Not specified in this paper (general ChatGPT pretraining not detailed here).",
            "application_domain": "Applied to molecule optimization tasks via prompting (through ChatDrug-style prompts) in comparative experiments.",
            "generation_method": "Prompt engineering / multi-turn prompting (ChatDrug workflow) with carefully crafted prompts to request optimized SMILES.",
            "output_representation": "SMILES strings (model outputs when successful), but often returns unchanged input molecule.",
            "evaluation_metrics": "Valid ratio and correct ratio under loose/strict criteria across 16 optimization tasks (same evaluation framework as for DrugAssist).",
            "benchmarks_or_datasets": "Evaluated on the same 16 tasks and 500-molecule ZINC testset used by the authors.",
            "results_summary": "GPT-3.5-turbo produced very high valid ratios on many tasks (e.g., QED+ valid 0.97/0.96) but low correct/optimization success (e.g., QED+ correct 0.15/0.15), often outputting the same molecule unchanged, resulting in poor optimization effectiveness compared to DrugAssist.",
            "comparison_to_other_methods": "Higher validity than some baselines but lower optimization success than DrugAssist; GPT-3.5 often fails to propose modifications that change target properties meaningfully.",
            "limitations_or_challenges": "Tendency to return identical molecules (no meaningful optimization) despite valid SMILES output; lower success rates on property-targeted optimization tasks even when multi-turn prompting is used.",
            "uuid": "e5312.2",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "BioMedGPT-LM-7B",
            "name_full": "BioMedGPT-LM-7B (BiomedGPT large generative model, 7B)",
            "brief_description": "A Llama2-based biomedical generative language model used as a baseline; in this study it struggled to understand molecule optimization instructions and frequently produced invalid or non-molecular outputs.",
            "citation_title": "Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine",
            "mention_or_use": "use",
            "model_name": "BioMedGPT-LM-7B",
            "model_type": "Llama2-based transformer generative model for biomedical domain",
            "model_size": "7B parameters",
            "training_data": "Described as biomedical-domain pretraining/fine-tuning in its original work; specific training corpus not detailed in this paper.",
            "application_domain": "Applied as an LLM baseline for molecule optimization via prompting.",
            "generation_method": "Prompting (single/multi-turn) to request optimized SMILES; no domain-specific instruction fine-tuning on MolOpt-Instructions in this study.",
            "output_representation": "Intended SMILES; however, often produced non-molecular or irrelevant textual guidance instead of SMILES.",
            "evaluation_metrics": "Valid ratio and correct ratio under loose/strict criteria across the same set of tasks.",
            "benchmarks_or_datasets": "Evaluated on the authors' 16 tasks and 500-molecule ZINC testset.",
            "results_summary": "BioMedGPT-LM-7B showed poor valid ratios and low success rates (example QED+ valid ratio 0.34/0.32 and correct ratio 0.15/0.09), frequently failing to output optimized SMILES and instead returning guidance or non-molecule content.",
            "comparison_to_other_methods": "Performs worse than DrugAssist and GPT-3.5 in this molecule-optimization benchmark; its domain specialization did not translate to successful molecule generation under the prompting regimes used here.",
            "limitations_or_challenges": "Difficulty understanding optimization instructions in this setup; often generated non-molecule outputs (e.g., telling users to visit websites) instead of SMILES, leading to low validity and poor utility for molecule generation tasks.",
            "uuid": "e5312.3",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "ChatMol",
            "name_full": "ChatMol (Interactive molecular discovery with natural language)",
            "brief_description": "A conversational system for molecular design mentioned in related work that supports molecule understanding and molecule generation (bi-directional conversion between textual descriptions and SMILES); cited as prior work enabling conversational molecular design.",
            "citation_title": "Interactive molecular discovery with natural language",
            "mention_or_use": "mention",
            "model_name": "ChatMol (system/framework)",
            "model_type": "Conversational LLM-based molecular design framework (details in original paper)",
            "model_size": "not specified in this paper",
            "training_data": "Not detailed in this paper (see cited ChatMol reference for specifics).",
            "application_domain": "Conversational molecular design (molecule understanding and generation).",
            "generation_method": "Conversational prompting / bidirectional conversion between descriptions and SMILES (as described in related work section).",
            "output_representation": "SMILES and textual molecular descriptions (bidirectional conversion).",
            "evaluation_metrics": "Not specified in this paper (only cited; evaluation details reside in the original ChatMol publication).",
            "benchmarks_or_datasets": "Not specified in this paper.",
            "results_summary": "Mentioned as existing work enabling conversational molecular design and generation; not evaluated or used experimentally in this paper.",
            "comparison_to_other_methods": "Cited as part of the landscape of conversational LLM applications to molecules; DrugAssist differs by being instruction-tuned specifically on an extensive MolOpt-Instructions dataset for iterative optimization with human dialogue.",
            "limitations_or_challenges": "Not discussed in this paper; refer to the original ChatMol publication for limitations.",
            "uuid": "e5312.4",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "ChatDrug",
            "name_full": "ChatDrug (ChatGPT-powered conversational drug editing using retrieval and domain feedback)",
            "brief_description": "A workflow/framework to facilitate drug editing using LLMs (ChatGPT); cited here as a prior approach for obtaining molecule-editing suggestions via carefully crafted prompts and retrieval/domain-feedback workflows.",
            "citation_title": "Chatgpt-powered conversational drug editing using retrieval and domain feedback",
            "mention_or_use": "mention",
            "model_name": "ChatDrug (framework using general LLMs, e.g., ChatGPT)",
            "model_type": "Prompting/retrieval-augmented conversational workflow integrating LLM outputs and retrieval/domain feedback",
            "model_size": "dependent on the underlying LLM (e.g., GPT-3.5) — not specified here",
            "training_data": "Framework uses prompts and retrieval from molecular databases; no fixed training data described in this paper.",
            "application_domain": "Conversational drug editing and molecule optimization via LLMs.",
            "generation_method": "Prompt engineering combined with retrieval and domain feedback to produce molecule edit suggestions (used as reference workflow in related work and comparisons).",
            "output_representation": "SMILES and textual editing suggestions (as described in the cited work).",
            "evaluation_metrics": "Not detailed here; in this paper GPT-3.5 via similar prompting showed high validity but low optimization success.",
            "benchmarks_or_datasets": "Not specified in this paper; see ChatDrug publication for details.",
            "results_summary": "Cited as an LLM-based molecule editing workflow; the present paper used a ChatDrug-like prompting approach to obtain GPT-3.5 outputs for baseline comparison (those GPT-3.5 outputs often had high validity but low optimization success).",
            "comparison_to_other_methods": "Serves as an example of prior LLM-based editing workflows; DrugAssist differs by being instruction-tuned on a dedicated molecule-optimization instruction dataset enabling better optimization success and iterative refinement.",
            "limitations_or_challenges": "Not discussed in depth here; authors note general LLM prompting methods (as in ChatDrug) can yield valid SMILES but often fail to change molecule properties meaningfully without task-specific fine-tuning.",
            "uuid": "e5312.5",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chatgpt-powered conversational drug editing using retrieval and domain feedback",
            "rating": 2
        },
        {
            "paper_title": "Interactive molecular discovery with natural language",
            "rating": 2
        },
        {
            "paper_title": "Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine",
            "rating": 2
        },
        {
            "paper_title": "Comprehensive evaluation of molecule property prediction with chatgpt",
            "rating": 2
        },
        {
            "paper_title": "Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge",
            "rating": 1
        }
    ],
    "cost": 0.01747975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>DrugAssist: A Large Language Model for MOLECULE OPTIMIZATION</h1>
<p>Geyan Ye, ${ }^{1 \dagger}$ Xibao Cai, ${ }^{2 \dagger}$ Houtim Lai, ${ }^{1}$ Xing Wang, ${ }^{1}$ Junhong Huang, ${ }^{1}$<br>Longyue Wang, ${ }^{1 *}$ Wei Liu ${ }^{1}$ \&amp; Xiangxiang Zeng ${ }^{2}$<br>${ }^{1}$ Tencent AI Lab ${ }^{2}$ Department of Computer Science, Hunan University<br>{blazerye, vinnylywang, topliu}@tencent.com<br>{dalecai, xzeng}@hnu.edu.cn</p>
<h4>Abstract</h4>
<p>Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through humanmachine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instructionbased dataset called "MolOpt-Instructions" for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The illustration of our proposed DrugAssist model framework, which focus on optimizing molecules through human-machine dialogue.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>1 INTRODUCTION</h1>
<p>Recently, generative artificial intelligence has made remarkable strides in the field of natural language processing (NLP), particularly with the advent of Large Language Models (LLMs) such as GPT (Generative Pre-trained Transformer) (Radford et al., 2019). These models have demonstrated impressive capabilities in a wide range of tasks, extending far beyond everyday communication and question-answering scenarios. Researchers have increasingly recognized the potential of these models in addressing complex and diverse problems across various domains, prompting interests in their applications within professional fields.</p>
<p>In recent years, there has been an increasing number of attempts to apply conversational LLMs in the field of drug discovery (Yunxiang et al., 2023; Han et al., 2023; Wu et al., 2023; Luo et al., 2023; Zeng et al., 2023; Liu et al., 2023b). However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Existing approaches can be broadly categorized into two main types. The first type represents molecules as sequences (commonly SMILES strings) and generates an optimized molecular sequence by learning from the input data. The second type of approach represents molecules as graphs and formulates molecule optimization as a graph-to-graph translation problem (He et al., 2022). One of the major issues with these approaches is the lack of interactivity. They focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of the invaluable expert experience and feedback. In contrast, the drug discovery pipeline involves iterative refining processes that entail conversations with domain experts to incorporate their feedback, ultimately achieving the desired outcome (Liu et al., 2023b).</p>
<p>In light of the advancements in powerful LLMs, our work aims to leverage their strong interactivity and generalizability for molecule optimization. To the best of our knowledge, there are currently no molecule optimization models that focus on human-machine interaction. We summarize main contributions of this work as follows:</p>
<ul>
<li>To facilitate future research, we publicly release a large instruction-based dataset called "MolOptInstructions" for fine-tuning language models on molecule optimization tasks. The dataset contains an adequate amount of data, ensuring both similarity constraints and a substantial difference in properties between molecules.</li>
<li>We propose DrugAssist, an interactive molecule optimization model fine-tuned on Llama2-7BChat, which performs optimization through human-machine dialogue. By enabling multi-turn conversations, domain experts can guide the model in further optimizing initially generated molecules with imperfections.</li>
<li>Compared to traditional molecular optimization approaches (He et al., 2021; Jin et al., 2020) and LLM-based implementations (Liu et al., 2023b; Luo et al., 2023), DrugAssist has consistently achieved leading results in multi-property optimization, which is a less frequently addressed and more challenging task in molecule optimization. Moreover, our optimization objectives include maintaining optimized molecular property values within a given range. DrugAssist continues to demonstrate impressive performance in this category of tasks, which are more aligned with real-world requirements compared to most studies that solely focus on increasing or decreasing property values.</li>
</ul>
<h2>2 Related Work</h2>
<h3>2.1 TRADITIONAL APPROACHES IN MOLECULE OPTIMIZATION</h3>
<p>Based on the different representations of molecules, we can divide these models into two categories: sequence-based and graph-based.</p>
<p>Sequence-based Most of these methods utilize SMILES (Simplified Molecular-Input Line-Entry System) string as the molecular representation. They view molecule optimization as machine translation problem in natural language processing (NLP), where a text is translated from one language to another (He et al., 2021). Similar to translation tasks in NLP, the conversion between molecules encoded in SMILES in molecular optimization tasks can also be seen as a transformation between "languages". The main architectures for this category of models include recurrent neural networks</p>
<p>(RNNs) (Gupta et al., 2018; Bjerrum \&amp; Threlfall, 2017; Segler et al., 2018), variational autoencoders (VAEs) (Jin et al., 2018a;b; Dai et al., 2018; Liu et al., 2018; Simonovsky \&amp; Komodakis, 2018), and Transformer (He et al., 2021; 2022). Meanwhile, reinforcement learning (Olivecrona et al., 2017; Putin et al., 2018), adversarial training (Kadurin et al., 2017), and transfer learning (Segler et al., 2018) serve as typical optimization techniques. Considering the significant progress has made in the field of LLMs in recent years, we believe that these sequence-based molecule optimization methods have great potential for further exploration.</p>
<p>Graph-based These methods typically use graph to represent molecules and directly generate molecule graphs. VAEs are also very popular in molecular graph generation. Jin et al. (2018a) decomposed a molecular graph into a junction tree of chemical substructures. Then, they employed a junction tree VAE (JT-VAE) to generate molecules with improved properties by applying gradient ascent over the learned latent space. Subsequent works have derived many variants based on JTVAE, such as VJTNN (Jin et al., 2018b), HierG2G (Jin et al., 2020), etc. In comparison to sequencebased methods, a notable distinction is that most graph-based approaches, such as JT-VAE, can consistently generate valid molecules due to the validation checks performed at each step of the generation process.</p>
<p>Despite the achievements of the aforementioned methods in the field of molecule optimization, we believe that they still have some shortcomings that need to be addressed:</p>
<ul>
<li>Most of the existing works focus on optimizing a single property of molecules, while there are few that simultaneously optimize multiple properties, which is a more common requirement in real life. Moreover, in most works, the optimization goal is to maximize the difference in properties between the optimized and original molecules while satisfying a certain similarity constraint. Alongside this, it's worth noting that in real-life situations, there is often a need for the property value of the optimized molecule to fall within a specific range, an aspect that has received little attention in existing research.</li>
<li>Most methods suffer from catastrophic forgetting when the optimization task is changed. For example, a model that performs well in optimizing QED values of molecules needs to be retrained on a dataset containing $\log \mathrm{P}$ property before being used to optimize $\log \mathrm{P}$ values. This approach not only incurs additional costs but also suffers from a lack of sufficient experimental data to facilitate training for some molecular properties, such as ADMET.</li>
<li>To the best of our knowledge, no existing studies have focused on the interactivity of these molecular optimization models. Interactive models facilitate effective communication between domain experts and artificial intelligence models. Experts can conveniently provide feedback and suggestions to the model in the form of natural language, and the model can also obtain real-time access to expert experience related to specific problems. However, existing approaches struggle to efficiently utilize these valuable expert experiences and feedback.</li>
</ul>
<h1>2.2 LLMS IN BIOMEDICAL DOMAIN</h1>
<p>In recent years, there has been an increasing number of attempts to apply LLMs in the field of biomedicine. The majority of research efforts are centered around QA (question-answering) tasks, such as Chatdoctor (Yunxiang et al., 2023), Med-Alpaca (Han et al., 2023), PMC-LLaMA (Wu et al., 2023) that focus on medical QA, and BioMedGPT (Luo et al., 2023) on molecule/protein QA. There is relatively much less work focused on addressing practical tasks within the drug discovery domain. ChatMol (Zeng et al., 2023) is employed for conversational molecular design, specifically, it can accomplish two tasks: molecule understanding and molecule generation, which involve bidirectional conversion between molecular descriptions and SMILES strings of molecules. ChatDrug (Liu et al., 2023b) is a framework to facilitate drug editing using LLMs. Specifically, following the ChatDrug workflow, users can obtain carefully crafted prompts that assist in obtaining suggestions on drug editing tasks from general LLMs, such as ChatGPT.</p>
<h2>3 MEthods</h2>
<p>Our methodology incorporates two primary components: the construction of our MolOptInstructions dataset and the subsequent instruction tuning of Llama2-7B-chat model.</p>
<h1>3.1 Construction of MolOpt-Instructions Dataset</h1>
<p>Most of datasets currently used for molecule optimization are in the form of "molecule-molecule pairs", which cannot be directly used to train language models like Llama. Although Fang et al. (2023) introduce a comprehensive instruction dataset specifically designed for training Large Language Models in the biomedical domain, it does not cover tasks associated with molecule optimization. Additionally, in some popular benchmark dataset (Jin et al., 2018b), the molecule pairs which are relatively few in number, only satisfy similarity constraints, and the difference in properties between the molecules within the same pair is not sufficiently significant. To tackle these issues, we construct instruction-based datasets called "MolOpt-Instructions" for fine-tuning language models on molecule optimization tasks. It contains an adequate amount of data, ensuring both similarity constraints and a substantial difference in properties between molecules.</p>
<p>Overview and Statistics MolOpt-Instructions consists over one million molecule pairs. Currently, it includes six types of molecular properties, namely Solubility, BBBP (Blood-Brain Barrier Penetration), hERG (Human Ether-a-go-go-Related Gene) inhibition, QED (Quantitative Estimate of Drug-likeness) and the number of hydrogen bond donor and acceptor, with detailed information provided in Table 1.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Unique pairs</th>
<th style="text-align: center;">Unique molecules</th>
<th style="text-align: center;">Similarity</th>
<th style="text-align: center;">LogP difference</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1,029,949$</td>
<td style="text-align: center;">$1,595,839$</td>
<td style="text-align: center;">$0.69 \pm 0.06$</td>
<td style="text-align: center;">$2.82 \pm 0.31$</td>
</tr>
</tbody>
</table>
<p>Table 1: Statistics of our proposed MolOpt-Instructions dataset. It contains an adequate amount of data, ensuring both similarity constraints and a substantial difference in properties between molecules.</p>
<p>Data Construction The workflow of the data construction is shown in Figure 2. To begin with, we randomly selected one million molecules from ZINC database (Irwin \&amp; Shoichet, 2005). Then, we used mmpdb (Dalke et al., 2018) to construct a database from these molecules and generate similar pairs. Mmpdb, an open-source Matched Molecular Pair (MMP) platform, generates MMPs through Matched Molecular Pair Analysis (MMPA). In essence, a MMP consists of two molecules that differ by a defined structural transformation, resulting in highly similar molecular structures within the pairs generated by mmpdb. Following this, we selected the molecular pairs that met our requirements from these candidates. Our selection criteria are as follows: the similarity between each pair of molecules should be greater than 0.65 , and the difference in $\log P$ should be greater than 2.5. Once we identified the suitable molecular pairs, we proceeded to calculate their property values using iDrug, an AI-driven drug discovery platform developed by Tencent (iDrug, 2020). To make the data more balanced, we maintain a roughly 1:1 ratio of increased to decreased property values for target molecules relative to source molecules by swapping the source and target molecules of some pairs. The rationale behind choosing the difference in $\log \mathrm{P}$ as a screening criterion lies in its close relation to various aspects of a molecule's biological activity and pharmacokinetics. After obtaining these pairs and their corresponding property values, we asked ChatGPT to suggest a variety of instructions and manually refine them for the molecule optimization tasks.</p>
<p>We designed three types of optimization tasks: the first category requires only an increase or decrease in the given property value; the second category adds a threshold requirement for the increase or decrease; and the third category requires the optimized property value to be within a given range. In Table 2, we show an example of an instruction for each of these three categories. All instructions in the dataset can be found in https://github.com/blazerye/DrugAssist.</p>
<p>Different from several widely used molecule optimization datasets, our optimization tasks are not just vaguely asking to "optimize the given molecule", but also have range requirements, making them more closely aligned with real-world scenarios.</p>
<p>Analysis and Discussion To ensure the diversity of molecules in our dataset, we employ Murcko scaffold analysis to evaluate the chemical diversity of the source molecules randomly selected from ZINC database. The average molecules per scaffold is 2.95 , and more than $93.7 \%$ of the scaffolds contained no more than five molecules. The scaffold analysis indicates a high degree of structural</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The workflow of data construction of MolOpt-Instructions. First, we randomly picked one million molecules from the ZINC dataset. Then, we used mmpb (Dalke et al., 2018) to generate similar pairs based on these molecules and selected the molecular pairs that met our requirements from these candidates. Once we identified the suitable molecular pairs, we proceeded to calculate their property values using iDrug (iDrug, 2020). After obtaining these pairs and their corresponding property values, we asked ChatGPT to suggest a variety of instructions and manually refine them for the molecule optimization tasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task category</th>
<th style="text-align: left;">Example prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">loose</td>
<td style="text-align: left;">I have a molecule with the SMILES string [SMILES]. Suggest modifications <br> to increase its [property] value while maintaining its core structure.</td>
</tr>
<tr>
<td style="text-align: center;">strict</td>
<td style="text-align: left;">I have a molecule with the SMILES string [SMILES]. Suggest modifications <br> to increase its [property] value by at least [threshold] compared to the pre- <br> optimized value while maintaining its core structure.</td>
</tr>
<tr>
<td style="text-align: center;">range</td>
<td style="text-align: left;">Here is a molecule represented by the SMILES string [SMILES]. Provide <br> me with an optimized version that has a [property] value between [lower <br> bound] and [upper bound]. The output molecule should be similar to the input <br> molecule.</td>
</tr>
</tbody>
</table>
<p>Table 2: Examples of prompts for optimization tasks with three different goals - loose, strict and range. "[SMILES]" represents the SMILES string for the molecule.
diversity among the source molecules. Therefore, models developed using this dataset are expected to demonstrate robust prediction coverage for a broad spectrum of structurally diverse compounds.</p>
<p>Furthermore, we also plot distribution graphs for molecular structural and ADMET-related properties, as shown in Figure 3 and Figure 4, respectively. For molecular structural properties, we focus on Bertz complexity, molecular weight, atom count and ring count. Bertz Complexity is a key parameter for assessing the structural complexity of a molecule, providing insights into its potential reactivity and stability. Molecular weight, a measure of a molecule's size, influences various physical and chemical properties, including solubility, volatility, and reaction kinetics. Atom count, indicative of the molecule's size and complexity, impacts its stability and potential intermolecular interactions. Ring count, a measure of cyclic structures within a molecule, informs about its structural rigidity, conformational flexibility, and possible biological activity. These graphs provide a more intuitive visualization of the diversity in the physical structure and biochemical properties of molecules in MolOpt-Instructions.</p>
<h1>3.2 InStruction Tuning</h1>
<p>For LLMs to follow natural language instructions and complete real-world tasks, instruction tuning has been widely used for alignment (Ouyang et al., 2022). In this process, the LLM is fine-tuned on a collection of tasks, which are defined through a set of instructions.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Distribution of structural properties of molecules within MolOpt-Instructions, illustrating the structural diversity of the molecules.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Distribution of ADMET-related properties of molecules within MolOpt-Instructions. Currently, MolOpt-Instructions covers six properties, namely Solubility, BBBP (Blood-Brain Barrier Penetration), hERG (Human Ether-a-go-go-Related Gene) inhibition, QED (Quantitative Estimate of Drug-likeness) and the number of hydrogen bond donor and acceptor. The distribution graph demonstrates the diversity of biochemical properties of molecules in our dataset.</p>
<p>Our work follow the similar approach performing instruction tuning on Llama2-7B-Chat using our MolOpt-Instructions dataset. Formally, we define the text input as a sequence of tokens, $U=$ $\left{u_{1}, u_{2}, \ldots, u_{N}\right}$, where each $u_{i}$ is a text token and $N$ is the total sequence length. At the stage of instruction fine-tuning, the sequence $U$ is further split into two parts, instruction $I$ and response $R$. The training objective is to minimize the negative log-likelihood over the response $R$ with respect to trainable parameters $\theta$ as follows: $L(R ; \theta)=-\sum_{u_{i} \in R} \log \Phi\left(u_{i} \mid u_{&lt;i}, I\right)$.
Multi-task learning In instruction tuning, the occurrence of catastrophic forgetting is a common phenomenon in pre-trained language models (De Lange et al., 2021; Dong et al., 2023). Ensuring that the model maintains high interactivity while optimizing molecules is one of our important objectives. To achieve this, we employ multi-task learning as our instruction tuning strategy. Specifically, the composition of our text input consists of two parts: (1) General knowledge: such as everyday conversational question-answering data; (2) Domain-specific knowledge: for our model, it pertains to molecule optimization. We mix these two types of data at a certain ratio. To achieve this ratio, we replicate the data from the less abundant category. Figure 5 illustrates our instruction tuning strategy.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The illustration of multi-task learning strategy. We apply instruction tuning by directly combining different data sources (general knowledge and molecule optimization), effectively mitigating catastrophic forgetting during the fine-tuning stage.</p>
<h1>4 EXPERIMENTS</h1>
<p>We provide a comprehensive view of DrugAssist's performance on traditional molecule optimization tasks, as well as its capabilities in dialogue and interaction.</p>
<h3>4.1 EXPERIMENTAL SETUP</h3>
<p>Models DrugAssist is a model fine-tuned from the Meta's Llama-2-7B-Chat model on over one million instruction-response demonstrations. We conduct a systematic comparison with the following sequence-based models:</p>
<ul>
<li>He et al. (2021) utilized the SOTA machine translation models, the Seq2Seq with attention and the Transformer for molecule optimization tasks.</li>
<li>ChatDrug (Liu et al., 2018) is a framework to facilitate the systematic investigation of drug editing using LLMs. For the molecule optimization tasks, they obtained results from ChatGPT (GPT-3.5turbo) using carefully crafted prompts.</li>
<li>Llama2-7B-Chat (Touvron et al., 2023) is a fine-tuned generative text model with 7 billion parameters, developed and publicly released by Meta. It outperforms open-source chat models on most benchmarks, and is on par with some popular closed-source models like ChatGPT and PaLM (Narang \&amp; Chowdhery, 2022).</li>
<li>BioMedGPT-LM-7B (Luo et al., 2023) is the first large generative language model based on Llama2 in the biomedical domain.</li>
</ul>
<p>Training Details At instruction tuning stage, we train the model for 10 epochs with a batch size of 512. We use the AdamW optimizer, with $\beta=(0.9,0.999)$ and a learning rate of $1 \mathrm{e}-4$, without weight decay. Warm-up is executed over $3 \%$ of the total training steps, followed by a cosine schedule for learning rate decay. Linear layers within the LLM utilize a LoRA rank of 64 and a LoRA alpha of 128. The model is trained on 8 NVIDIA Tesla A100-SXM4-40GB GPUs.</p>
<p>Dataset for Instruction Tuning To ensure our model maintains high interactivity while optimizing moluecules, we employ multi-task learning strategy introduced in Section 3.2 to construct training data. We utilize instruction data from two sources:</p>
<ul>
<li>MolOpt-Instructions We have provided a detailed introduction to this dataset in Section 3.</li>
<li>Stanford Alpaca In order to preserve the model's natural language dialogue capabilities and counteract the forgetting effect during the supervised fine-tuning phase, we utilized the dataset employed for fine-tuning a 7B Llama model, which comprises 52 k instruction-following data provided by Stanford.</li>
</ul>
<p>Considering that the MolOpt-Instructions dataset contains significantly more data than the Stanford Alpaca dataset, we created the final dataset by replicating the Stanford Alpaca dataset five times and then mixing it with the Molopt-Instructions dataset. We divide the mixed data into training, validation, and test sets at a ratio of $0.9: 0.05: 0.05$, respectively.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Multi-round optimization process proposed by Liu et al. (2023b). The model is initially provided with a source molecule and specific optimization criteria. Upon generating the optimized molecule, its property values are assessed. If it meets the requirements, the process terminates. If not, a molecule most similar to the source molecule and fulfilling the criteria is retrieved from the database to guide further optimization. The process continues until the requirements is met or the predefined maximum number of iterations is reached.</p>
<h1>4.2 Evaluation Methods</h1>
<p>Comparisons with Traditional Approaches We compared DrugAssist with two molecule optimization models proposed by He et al. (2021). One of them employs a Seq2Seq with attention architecture (which we refer to as Mol-Seq2Seq), and the other uses a Transformer architecture (which we refer to as Mol-Transformer). Specifically, we compared the performance of these models in optimizing two properties: BBBP and Solubility. We calculated the success rates, validity, and average similarity between molecules before and after optimization, with the detailed definition of "success" summarized as follows:</p>
<ul>
<li>Solubility: We consider the optimization to be successful if the Solubility of the generated molecule falls within the given range. Specifically, we have divided the Solubility values into 10 intervals, each with a size of 1 .</li>
<li>BBBP: We consider the optimization to be successful if the generated molecule's BBBP property type is correct. Specifically, we have categorized BBBP values into three groups: low, medium, and high, corresponding to the value ranges of $0-0.3,0.3-0.7$, and $0.7-1$, respectively.</li>
</ul>
<p>The prompt we used is "Here is a molecule represented by the SMILES string [SMILES]. Provide me with an optimized version that has a molecular solubility value between [lower bound] and [upper bound] (unit: logarithm of mol/L), and change the blood-brain barrier penetration (BBBP) from [source category] to [target category]". We use this prompt to obtain results from DrugAssist in a single-turn dialogue manner.</p>
<p>Comparisons with LLMs We compared DrugAssist with ChatDrug, Llama2-7B-Chat, and BioMedGPT-LM-7B. We randomly selected an additional 500 molecules from the ZINC dataset to serve as the testset for this experiment. Specifically, we compared the performance of these models on 16 tasks. Following the approach of Liu et al. (2023b), we employ multi-turn dialogues to enable LLMs to optimize molecules. We first propose optimization requirements, and if the model's output does not meet our requirements, we search the database for a molecule that meets the requirements and is most similar to the model's output, using it as a hint for the model to make modifications, until the requirements are met or the pre-set number of iterations is reached. Figure 6 illustrates the optimization process.</p>
<p>We computed the success rate and validity for each task. We have adopted two sets of criteria for defining "successful optimization" - loose and strict. For the loose criteria, if the optimized molecular property is higher or lower than the pre-optimization property as required, we consider the optimization to be successful. For the strict criteria, except for the "Solubility", if the optimized molecular property is higher or lower than the pre-optimization property by a specified threshold, we consider the optimization to be successful. For the "Solubility", if the optimized molecular property value falls within the required range, we consider the optimization to be successful. Our range requirements are set as follows: Given a test molecule with Solubility value x , in the task of increasing the Solubility value, the optimized range requirement is $[\mathrm{x}+0.5, \mathrm{x}+1.5]$; in the task of</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Property</th>
<th style="text-align: center;">Threshold</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">QED</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: left;">hydrogen bond acceptor</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">hydrogen bond donor</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">BBBP</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: left;">hERG inhibition</td>
<td style="text-align: center;">0.1</td>
</tr>
</tbody>
</table>
<p>Table 3: The threshold settings for different properties. For the strict criteria, except for the "Solubility", we consider the optimization to be successful only if the optimized molecular property is higher or lower than the pre-optimization property by the threshold shown in table.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Solubility</th>
<th style="text-align: center;">BBBP</th>
<th style="text-align: center;">All</th>
<th style="text-align: center;">Valid rate</th>
<th style="text-align: center;">Similarity</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Mol-Seq2Seq</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: left;">Mol-Transformer</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">$\mathbf{0 . 7 0}$</td>
</tr>
<tr>
<td style="text-align: left;">Ours</td>
<td style="text-align: center;">$\mathbf{0 . 7 4}$</td>
<td style="text-align: center;">$\mathbf{0 . 8 0}$</td>
<td style="text-align: center;">$\mathbf{0 . 6 2}$</td>
<td style="text-align: center;">$\mathbf{0 . 9 8}$</td>
<td style="text-align: center;">0.69</td>
</tr>
</tbody>
</table>
<p>Table 4: Comparisons with traditional approaches on optimizing molecules' Solubility and BBBP value. We choose success rate, valid rate and similarity as evaluation metrics. The Solubility and BBBP columns display the success rates of the model optimizing these two individual properties respectively, while the "All" column shows the success rate of the model simultaneously optimizing both properties. Our model has achieved the highest success rates in both single-property and multiproperty optimization while maintaining high validity and high similarity to the molecules to be optimized. Furthermore, we can also observe that the Transformer architecture performs much better than the Seq2Seq with attention architecture on this task.
decreasing the Solubility value, the optimized range requirement is [x-1.5, x-0.5]. The threshold settings for different properties in our experiments are shown in Table 3. Detailed prompt settings for each task can be found in Table 6 in Appendix. BBBP, Solubility, and hERG inhibition are predicted from iDrug, while the rest can be calculated deterministically using RDKit.</p>
<h1>4.3 MAIN RESULTS</h1>
<p>In this section, we conduct a comprehensive and systematic comparison with aforementioned models.</p>
<p>Comparisons with traditional approaches Here we compared our model with He et al. (2021). The results are shown in Table 4. Our model has achieved the highest success rates in both singleproperty and multi-property optimization while maintaining high validity and high similarity to the molecules to be optimized.</p>
<p>Comparisons with LLMs The results are shown in Table 5. Our model significantly outperforms other LLMs in terms of both success rate and valid rate across all tasks.</p>
<p>From the perspective of the valid ratio of generating valid molecules, BioMedGPT-LM performs poorly. The main reason is that it has difficulty understanding the optimization requirements, often generating content such as guiding users to websites for molecule optimization, rather than outputting the optimized molecule. Although GPT-3.5-turbo appears to have high valid ratio, it often generates molecules that are identical to the given molecule to be optimized, thus failing to serve the purpose of molecule optimization. Our model, on the other hand, demonstrates a significant advantage in generating valid molecules, with virtually no instances of misunderstanding requirements or generating identical molecules to the ones to be optimized.</p>
<p>From the perspective of accuracy, even when we use multi-turn dialogues to prompt the baseline LLMs for comparison, they still struggle to complete the optimization tasks, with low success rates even on relatively simple tasks that only require increasing a single property value.</p>
<p>Our model exhibits good molecule optimization capabilities and strong adaptability to different properties and optimization objectives. Even though our model has only been exposed to data with</p>
<p>individual properties during training, it achieves competitive results in multi-property optimization tasks. However, we also note that our model has a relatively lower success rate in tasks specifying the range of post-optimization property values ("esol+ strict" task). How to better achieve these more challenging optimization objectives is worth further exploration in the future.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Valid ratio (loose/strict)</th>
<th style="text-align: center;">Correct ratio (loose/strict)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$q e d+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.69 / 0.55$</td>
<td style="text-align: center;">$0.17 / 0.16$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.97 / 0.96$</td>
<td style="text-align: center;">$0.15 / 0.15$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.34 / 0.32$</td>
<td style="text-align: center;">$0.15 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.97$</td>
<td style="text-align: center;">$0.76 / 0.63$</td>
</tr>
<tr>
<td style="text-align: center;">acceptor+</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.45 / 0.43$</td>
<td style="text-align: center;">$0.08 / 0.08$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.98 / 0.96$</td>
<td style="text-align: center;">$0.04 / 0.06$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.45 / 0.39$</td>
<td style="text-align: center;">$0.18 / 0.13$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.97 / 0.96$</td>
<td style="text-align: center;">$0.71 / 0.67$</td>
</tr>
<tr>
<td style="text-align: center;">donor+</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.45 / 0.48$</td>
<td style="text-align: center;">$0.15 / 0.08$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.98 / 0.95$</td>
<td style="text-align: center;">$0.10 / 0.04$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.46 / 0.46$</td>
<td style="text-align: center;">$0.17 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.98 / 0.95$</td>
<td style="text-align: center;">$0.72 / 0.76$</td>
</tr>
<tr>
<td style="text-align: center;">solubility+</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.56 / 0.56$</td>
<td style="text-align: center;">$0.36 / 0.20$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.94 / 0.95$</td>
<td style="text-align: center;">$0.16 / 0.05$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.27 / 0.35$</td>
<td style="text-align: center;">$0.18 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.98 / 0.98$</td>
<td style="text-align: center;">$0.80 / 0.41$</td>
</tr>
<tr>
<td style="text-align: center;">$b b b p+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.56 / 0.57$</td>
<td style="text-align: center;">$0.19 / 0.14$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.97 / 0.95$</td>
<td style="text-align: center;">$0.10 / 0.10$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.26 / 0.22$</td>
<td style="text-align: center;">$0.16 / 0.07$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.98$</td>
<td style="text-align: center;">$0.82 / 0.61$</td>
</tr>
<tr>
<td style="text-align: center;">herg-</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.59 / 0.55$</td>
<td style="text-align: center;">$0.39 / 0.31$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.98 / 0.97$</td>
<td style="text-align: center;">$0.13 / 0.15$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.20 / 0.18$</td>
<td style="text-align: center;">$0.13 / 0.12$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.98$</td>
<td style="text-align: center;">$0.71 / 0.67$</td>
</tr>
<tr>
<td style="text-align: center;">sol $+\&amp; a c c+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.55 / 0.52$</td>
<td style="text-align: center;">$0.15 / 0.04$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.92 / 0.91$</td>
<td style="text-align: center;">$0.09 / 0.02$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.29 / 0.32$</td>
<td style="text-align: center;">$0.10 / 0.07$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.95 / 0.95$</td>
<td style="text-align: center;">$0.50 / 0.27$</td>
</tr>
<tr>
<td style="text-align: center;">qed $+\&amp; b b b p+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.52 / 0.56$</td>
<td style="text-align: center;">$0.14 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.96 / 0.95$</td>
<td style="text-align: center;">$0.09 / 0.06$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.35 / 0.36$</td>
<td style="text-align: center;">$0.16 / 0.11$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.98$</td>
<td style="text-align: center;">$0.65 / 0.41$</td>
</tr>
</tbody>
</table>
<p>Table 5: Comparisons with LLMs. We evaluated the performance of LLMs on 16 tasks, covering all three optimization objectives introduced in Section 3.1 - loose, strict, and range. We calculated the valid ratio (number of valid SMILES generated/total number in the test set) and success rate (number of molecules meeting optimization objectives/total number in the test set) of the generated molecules. In the task naming, " + " represents the goal of increasing the property value, while "-" represents property the attribute value. The " $\&amp;$ " symbol represents the simultaneous optimization of two given properties. "sol" stands for "Solubility", and "acc" stands for "the number of hydrogen bond acceptor". "loose" and "strict" are the two criteria for defining successful optimization, as detailed in Section 4.1.</p>
<h1>4.4 CASE Study</h1>
<p>In this section, we showcase the exceptional capabilities of our model in molecule optimization tasks through several specific examples, beyond its high success rate.</p>
<p>Transferability Figure 7 demonstrates the good transferability of our model under the zero-shot setting. We randomly selected two properties, BBBP and QED, and asked DrugAssist to increase their values by at least 0.1 simultaneously. Our model achieved this and the resulting molecule is structurally similar to the original one. Although the model has only been exposed to data with individual properties during training, users can still freely combine these properties when using the model to optimize them simultaneously. Traditional models, however, often require retraining on new datasets with multiple properties in order to achieve this.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Good transferability of DrugAssist under the zero-shot setting. Users can freely combine individual properties in training data to request DrugAssist to optimize them simultaneously.</p>
<p>Figure 8 demonstrates the good transferability of DrugAssist under the few-shot setting. We asked DrugAssist to increase the logP value of a given molecule by at least 0.1 , even though this property is not included in the training data. By providing a few examples of similar molecules with successfully increased $\log \mathrm{P}$ values by at least 0.1 in the prompt, our model was able to achieve this. Our model can optimize properties not encountered during training through few-shot, which is difficult to achieve for traditional models (e.g., JT-VAE).
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Good transferability of DrugAssist under the few-shot setting. By providing examples of successful optimizations for molecules similar to the one to be optimized, DrugAssist can optimize properties not encountered during training.</p>
<p>Iterative optimization Figure 9 illustrates the iterative optimization capability of our model. We asked DrugAssist to increase the QED value of a given molecule by at least 0.1 , but it failed. Then, we found a molecule from the database that was similar to the failed molecule it provided and met the optimization requirements as a hint for it to generate a new one. This time, it chose to optimize different functional groups than the first time and succeeded, and the final molecule generated is structurally similar to the original given molecule. We can conclude that when the model provides a molecule that does not fully meet the requirements, it can correct the error and generate a new, compliant molecule based on a human-provided example that meets the criteria. This ability highlights</p>
<p>the potential for DrugAssist to assist researchers in continually adjusting and optimizing molecules in real-world scenarios.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Iterative optimization capability of DrugAssist. when the model provides a molecule that does not fully meet the requirements, it can correct the error and generate a new, compliant molecule based on a human-provided example.</p>
<h1>5 CONCLUSION AND Future WORK</h1>
<p>In this paper, we present DrugAssist, an interactive molecule optimization model. Unlike previous methods, DrugAssist can interact with humans in real-time using natural language. It can provide optimized results based on the instructions given by users and continue to adjust according to their feedback. It demonstrates excellent performance in both single-property and multi-property optimization, including more challenging tasks, such as optimizing within specified property value ranges. Additionally, it shows great potential in transferability and iterative optimization capabilities during the interaction process. Furthermore, we publicly release MolOpt-Instructions, an instruction-based dataset to facilitate future work on fine-tuning LLMs in the molecule optimization domain.</p>
<p>In the future, we aim to improve the model's ability to handle multimodal data and tasks (Lyu et al., 2023; Li et al., 2023a) to reduce hallucination problems (Zhang et al., 2023; Liu et al., 2023a; Li et al., 2023b; Cai et al., 2023). Additionally, we are endeavoring to further enhance DrugAssist's interactive capabilities to better understand users' needs and feedback.</p>
<h2>REFERENCES</h2>
<p>Esben Jannik Bjerrum and Richard Threlfall. Molecular generation with recurrent neural networks (rnns). arXiv preprint arXiv:1705.04612, 2017.</p>
<p>Xibao Cai, Houtim Lai, Xing Wang, Longyue Wang, Wei Liu, Yijun Wang, Zixu Wang, Dongsheng Cao, and Xiangxiang Zeng. Comprehensive evaluation of molecule property prediction with chatgpt. Methods, 2023.</p>
<p>Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, and Le Song. Syntax-directed variational autoencoder for molecule generation. In Proceedings of the international conference on learning representations, 2018.</p>
<p>Andrew Dalke, Jerome Hert, and Christian Kramer. mmpdb: An open-source matched molecular pair platform for large multiproperty data sets. Journal of chemical information and modeling, 58 (5):902-910, 2018.</p>
<p>Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366-3385, 2021.</p>
<p>Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, and Jingren Zhou. How abilities in large language models are affected by supervised fine-tuning data composition. arXiv preprint arXiv:2310.05492, 2023.</p>
<p>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, and Huajun Chen. Mol-instructions: A large-scale biomolecular instruction dataset for large language models. arXiv preprint arXiv:2306.08018, 2023.</p>
<p>Anvita Gupta, Alex T Müller, Berend JH Huisman, Jens A Fuchs, Petra Schneider, and Gisbert Schneider. Generative recurrent networks for de novo drug design. Molecular informatics, 37 (1-2):1700111, 2018.</p>
<p>Tianyu Han, Lisa C Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser, Alexander Löser, Daniel Truhn, and Keno K Bressem. Medalpaca-an open-source collection of medical conversational ai models and training data. arXiv preprint arXiv:2304.08247, 2023.</p>
<p>Jiazhen He, Huifang You, Emil Sandström, Eva Nittinger, Esben Jannik Bjerrum, Christian Tyrchan, Werngard Czechtizky, and Ola Engkvist. Molecular optimization by capturing chemist's intuition using deep neural networks. Journal of cheminformatics, 13(1):1-17, 2021.</p>
<p>Jiazhen He, Eva Nittinger, Christian Tyrchan, Werngard Czechtizky, Atanas Patronov, Esben Jannik Bjerrum, and Ola Engkvist. Transformer-based molecular optimization beyond matched molecular pairs. Journal of cheminformatics, 14(1):18, 2022.
iDrug, 2020. URL https://drug.ai.tencent.com.
John J Irwin and Brian K Shoichet. Zinc- a free database of commercially available compounds for virtual screening. Journal of chemical information and modeling, 45(1):177-182, 2005.</p>
<p>Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Junction tree variational autoencoder for molecular graph generation. In International conference on machine learning, pp. 2323-2332. PMLR, 2018a.</p>
<p>Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi Jaakkola. Learning multimodal graph-tograph translation for molecular optimization. arXiv preprint arXiv:1812.01070, 2018b.</p>
<p>Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Hierarchical generation of molecular graphs using structural motifs. In International conference on machine learning, pp. 4839-4848. PMLR, 2020 .</p>
<p>Artur Kadurin, Sergey Nikolenko, Kuzma Khrabrov, Alex Aliper, and Alex Zhavoronkov. drugan: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico. Molecular pharmaceutics, 14(9):3098-3104, 2017.</p>
<p>Yingshu Li, Yunyi Liu, Zhanyu Wang, Xinyu Liang, Lingqiao Liu, Lei Wang, Leyang Cui, Zhaopeng Tu, Longyue Wang, and Luping Zhou. A comprehensive study of gpt-4v's multimodal capabilities in medical imaging. medRxiv, pp. 2023-11, 2023a.</p>
<p>Yunxin Li, Longyue Wang, Baotian Hu, Xinyu Chen, Wanqi Zhong, Chenyang Lyu, and Min Zhang. A comprehensive evaluation of gpt-4v on knowledge-intensive visual question answering. arXiv preprint arXiv:2311.07536, 2023b.</p>
<p>Bingshuai Liu, Chenyang Lyu, Zijun Min, Zhanyu Wang, Jinsong Su, and Longyue Wang. Retrievalaugmented multi-modal chain-of-thoughts reasoning for large language models. arXiv preprint arXiv:2312.01714, 2023a.</p>
<p>Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander Gaunt. Constrained graph variational autoencoders for molecule design. Advances in neural information processing systems, 31, 2018.</p>
<p>Shengchao Liu, Jiongxiao Wang, Yijin Yang, Chengpeng Wang, Ling Liu, Hongyu Guo, and Chaowei Xiao. Chatgpt-powered conversational drug editing using retrieval and domain feedback. arXiv preprint arXiv:2305.18090, 2023b.</p>
<p>Yizhen Luo, Jiahuan Zhang, Siqi Fan, Kai Yang, Yushuai Wu, Mu Qiao, and Zaiqing Nie. Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine. arXiv preprint arXiv:2308.09442, 2023.</p>
<p>Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming Shi, and Zhaopeng Tu. Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration. arXiv preprint arXiv:2306.09093, 2023.</p>
<p>Sharan Narang and Aakanksha Chowdhery. Pathways language model (palm): Scaling to 540 billion parameters for breakthrough performance. Google AI Blog, 2022.</p>
<p>Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen. Molecular de-novo design through deep reinforcement learning. Journal of cheminformatics, 9(1):1-14, 2017.</p>
<p>Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35: $27730-27744,2022$.</p>
<p>Evgeny Putin, Arip Asadulaev, Yan Ivanenkov, Vladimir Aladinskiy, Benjamin Sanchez-Lengeling, Alán Aspuru-Guzik, and Alex Zhavoronkov. Reinforced adversarial neural computer for de novo molecular design. Journal of chemical information and modeling, 58(6):1194-1204, 2018.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.</p>
<p>Marwin HS Segler, Thierry Kogej, Christian Tyrchan, and Mark P Waller. Generating focused molecule libraries for drug discovery with recurrent neural networks. ACS central science, 4(1): $120-131,2018$.</p>
<p>Martin Simonovsky and Nikos Komodakis. Graphvae: Towards generation of small graphs using variational autoencoders. In Artificial Neural Networks and Machine Learning-ICANN 2018: 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27, pp. 412-422. Springer, 2018.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.</p>
<p>Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie. Pmc-llama: Towards building open-source language models for medicine. arXiv preprint arXiv:2305.10415, 2023.</p>
<p>Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge. arXiv preprint arXiv:2303.14070, 2023.</p>
<p>Zheni Zeng, Bangchen Yin, Shipeng Wang, Jiarui Liu, Cheng Yang, Haishen Yao, Xingzhi Sun, Maosong Sun, Guotong Xie, and Zhiyuan Liu. Interactive molecular discovery with natural language. arXiv preprint arXiv:2306.11976, 2023.</p>
<p>Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. Siren's song in the ai ocean: A survey on hallucination in large language models. arXiv preprint arXiv:2309.01219, 2023.</p>
<h1>A Prompt Settings for the comparisons with LLMs</h1>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">qed+ loose</td>
<td style="text-align: center;">Help me make molecule [SMILES] more like a drug. The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">qed+ strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">acceptor+ loose</td>
<td style="text-align: center;">Can you make molecule [SMILES] with more hydrogen bond acceptors? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">acceptor+ strict</td>
<td style="text-align: center;">Help me increase the number of hydrogen bond acceptors in the molecule [SMILES] by at least 2 compared to the pre-optimized value. The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">donor+ loose</td>
<td style="text-align: center;">Can you make molecule [SMILES] with more hydrogen bond donors? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">donor+ strict</td>
<td style="text-align: center;">Help me increase the number of hydrogen bond donors in the molecule [SMILES] by at least 2 compared to the pre-optimized value. The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">solubility+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its water solubility value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">solubility+ strict</td>
<td style="text-align: center;">Can you give me an optimized version of the molecule [SMILES] with a water solubility value ranging from lower bound to higher bound (logarithm of $\mathrm{mol} / \mathrm{L}$ ) while maintaining similarity to the original molecule?</td>
</tr>
<tr>
<td style="text-align: center;">bbbp+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">bbbp+ strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value by at least 0.1 compared to the pre-optimized value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">herg- loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to decrease its hERG inhibition value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">herg- strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to decrease its hERG inhibition value by at least 0.1 compared to the pre-optimized value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">sol $+\&amp;$ acc+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its water solubility value and to have more hydrogen bond acceptors? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">sol $+\&amp;$ acc+ strict</td>
<td style="text-align: center;">Can you give me an optimized version of the molecule [SMILES] with a water solubility value ranging from lower bound to higher bound (logarithm of $\mathrm{mol} / \mathrm{L}$ ), and with at least 2 more hydrogen bond acceptors while maintaining similarity to the original molecule?</td>
</tr>
<tr>
<td style="text-align: center;">qed $+\&amp;$ bbbp+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value and make it more like a drug? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">qed $+\&amp;$ bbbp+ strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value by at least 0.1 and increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like? The output molecule should be similar to the input molecule.</td>
</tr>
</tbody>
</table>
<p>Table 6: Prompts for different tasks. "[SMILES]" represents the SMILES string for the molecule.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ul>
<li>Corresponding Author, ${ }^{\dagger}$ Equal Contribution.</li>
</ul>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>