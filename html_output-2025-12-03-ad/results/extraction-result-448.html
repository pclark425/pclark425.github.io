<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-448 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-448</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-448</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-244709368</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2111.12990v2.pdf" target="_blank">Learning Algebraic Representation for Systematic Generalization in Abstract Reasoning</a></p>
                <p><strong>Paper Abstract:</strong> Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representation for the abstract spatial-temporal reasoning task of Raven's Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner. The ALANS learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representation, while the backend transforms it into an algebraic structure and induces the hidden operator on the fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show the generative nature of the learned algebraic representation; it can be decoded by isomorphism to generate an answer.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e448.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e448.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALANS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ALgebra-Aware Neuro-Semi-Symbolic learner</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-semi-symbolic hybrid that combines a neural visual perception frontend with an algebraic (matrix-based) symbolic reasoning backend that induces operators on the fly via inner optimization, designed to improve systematic generalization on Raven-style abstract reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ALANS (ALgebra-Aware Neuro-Semi-Symbolic learner)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Modular hybrid: a neural visual perception frontend (sliding-window object CNN that outputs object-attribute distributions and a belief-inference engine that marginalizes to panel-level belief states) feeds probabilistic belief states into an algebraic abstract reasoning backend that lifts belief states to a learnable matrix representation (via Peano-axiom inspired encodings and representation theory), induces the hidden operator by solving a regularized linear-regression inner optimization, executes the induced matrix operator to predict the answer representation, decodes by isomorphism to produce a probabilistic answer belief state, and selects the choice with minimum divergence.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Algebraic symbolic component: attribute-specific discrete algebraic structures (integer-indexed sets / groups) represented via a learnable matrix space (zero element as M0 and successor as a matrix M_a); symbolic 'operators' are elements of a learnable matrix group and are induced (not hand-defined) from context panels. Representation-theoretic isomorphism between abstract algebra and matrix representation establishes the symbolic layer.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural perception and optimization: object CNN (four-branch, sliding-window) producing objectness, type, size, color distributions; a belief-inference engine computing panel-level attribute distributions; gradient-based end-to-end training (ADAM); inner optimization problems solved in closed form (regularized linear regression) as differentiable subroutines embedded in the forward pass.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular neuro-semi-symbolic integration: perception produces probabilistic belief states passed to the algebraic backend; the backend lifts beliefs to matrices and performs inner-level closed-form optimization (operator induction and execution) within the forward pass; the whole system is end-to-end trainable (soft expectations over beliefs permit gradients to flow) and uses a hybrid loss that includes cross-entropy on answer selection plus auxiliary loss shaping operator distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Improved systematic generalization (ability to extrapolate to out-of-distribution relation instances), interpretability (explicit belief states, induced operators, and executable algebraic representations that mirror human-like induce-execute-compare reasoning), on-the-fly induction of symbolic operators (semi-symbolic — operators are not predefined), and generative capability (decoded predicted representation can be rendered to synthesize a solution panel).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Abstract visual reasoning — Raven's Progressive Matrices (RPM)-style problems (RAVEN / I-RAVEN datasets and systematic generalization splits: systematicity, productivity, localism).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Systematic-generalization (Zhang et al. generator): average accuracy ≈ 79.63% (Systematicity: 78.45%, Productivity: 79.95%, Localism: 80.50%). Systematic-generalization (Hu et al. generator / I-RAVEN splits): average accuracy ≈ 65.42% (Systematicity: 64.80%, Productivity: 65.55%, Localism: 65.90%). I.I.D. RAVEN benchmark: overall accuracy ≈ 74.4% (per Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Various pure connectionist baselines reported lower systematic-generalization performance (examples in paper: ResNet, WReN, CoPINet, MXGNet, SCL, etc.; see paper Tables for numbers); direct single-number baseline is not a single declarative-free baseline but multiple models are compared (typical systematic-generalization averages for pure connectionist methods are ≈ 25–60% depending on method and split).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Substantially better out-of-distribution systematic generalization than multiple pure connectionist baselines on the three constructed OOD splits (systematicity, productivity, localism); algebraic representation + semi-symbolic operator induction supports productivity and localism (constituent-to-recursive composition) and operator induction improves systematicity; still sensitive to perception uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High: explicit panel belief states, explicit learned algebraic encodings (zero and successor matrices), induced operator matrices, and a clear induce->execute->compare pipeline permit inspection and decoding (isomorphism allows decoding predicted algebraic representations back to attribute probabilities and rendering).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Assumes independence across attributes (factorization), fixed and known attribute value spaces; sensitivity to perception uncertainty as expectations over belief distributions introduce noise into operator induction; reasoning module still imperfect (gap between ALANS and ALANS-V shows remaining inductive limitations); color attribute reasoning and perception were weaker; curriculum and staged training needed for stability.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Motivated by abstract algebra and representation theory with Peano-axiom grounding: lift discrete algebraic elements and operators into a learnable matrix representation establishing an isomorphism that reduces symbolic algebra induction to solving linear-algebraic (regularized least-squares) inner optimizations; principle that algebraic treatment provides structural inductive bias for systematic generalization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e448.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deepproblog: Neural probabilistic logic programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid system that integrates neural predicates with probabilistic logic programming (ProbLog) to combine perception (neural networks) with symbolic logical reasoning in a unified probabilistic framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deepproblog: Neural probabilistic logic programming</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Neural-probabilistic logic programming framework that connects learned neural components (e.g., perceptual classifiers) to a ProbLog program that performs probabilistic logic inference, allowing learning and reasoning to be combined.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Probabilistic logic programming (ProbLog) — symbolic/probabilistic logical rules and queries.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks providing learned predicates (perception/classification components).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Neural predicates are embedded into a ProbLog program; probabilistic logic inference and learning are combined to allow end-to-end training across neural and symbolic parts (neural outputs feed into logical inference).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Brings together perceptual learning and symbolic probabilistic reasoning enabling explanations grounded in logic, and end-to-end learning of perceptual-to-symbolic pipelines; supports reasoning with uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>General neural-symbolic tasks connecting perception and logic (paper does not give RPM experiments in this text).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Paper mentions it as a hybrid that connects learning and reasoning; no detailed generalization metrics given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Improved interpretability due to explicit logical programs and probabilistic predicates; symbolic rules provide explanations for inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed in detail in this paper's text.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Combines probabilistic logic programming foundations (ProbLog) with neural predicate learning to create a differentiable pipeline for symbolic probabilistic reasoning with learned perception.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e448.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NSM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural State Machine (NSM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic approach for visual question answering that uses a probabilistic graph for reasoning over neural perceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning by abstraction: The neural state machine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural State Machine (NSM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Architecture that separates perception from reasoning by building a probabilistic graph / state machine over visual entities detected by neural perceptual modules, then performing higher-level reasoning over that graph.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Probabilistic graph structure used for reasoning (explicit graph-based symbolic representation of entities/relations).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural perception modules that detect entities and produce features; learned modules to propagate and aggregate information on the graph.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Perception yields nodes/features for a symbolic/probabilistic graph, then neural message-passing / graph inference performs reasoning on that graph; neuro-symbolic pipeline with explicit graph abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Disentangles vision and reasoning, enabling more structured reasoning over detected entities and edges and potential gains in interpretability and compositionality for VQA tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Visual question answering (VQA) (as described in the paper's related work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Mentioned as an example of neuro-symbolic architecture that can help reasoning; no quantitative generalization claims provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Probabilistic graph representation affords inspection of relational structure used during reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not detailed in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Constructs an explicit graph abstraction (state machine) over perceptual outputs to separate and combine symbolic reasoning and neural perception.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e448.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Logic Machines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable neural architecture that implements inductive logic-like reasoning end-to-end to learn rules and perform relational induction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural logic machines</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Logic Machines (NLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A neural architecture designed to emulate logical/relational operators in a differentiable manner, enabling end-to-end inductive learning of rule-like behaviors over relations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Logic-like relational operators and rule induction as an intended symbolic component (implemented via structured layers that mimic logical computation).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Differentiable neural layers (designed to represent logical/relational operations) trained end-to-end.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>End-to-end differentiable network architecture that encodes relational reasoning primitives enabling neural induction of logical rules.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Ability to learn relational rules and perform inductive generalization with neural parameterization of logical computations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Relational reasoning and inductive rule learning tasks (not RPM in this paper's experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Designed to improve compositional/relational generalization through structured neural approximations to logic; this paper only cites it as prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Architectural resemblance to logical computation may aid interpretability of learned relational operations, but specifics not given here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not specified in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Implements a neural approximation of logical relational computation to support end-to-end induction of rules.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e448.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neuro-Symbolic Concept Learner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The neuro-symbolic concept learner</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic system that separates perception and symbolic parsing, mapping visual scenes to symbols and chaining predefined logical operators associated with language tokens to perform reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neuro-Symbolic Concept Learner (NS-CL)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system where a neural perception module extracts symbolic scene representations and a symbolic program executor composes predefined logic operators (from parsed language) to answer questions; perception and symbolic modules can be trained to align under supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Predefined logic operators and symbolic program execution acting on extracted symbols (structured symbolic programs derived from language).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural perception modules mapping pixels to objects and attributes; learned modules that produce symbols for the symbolic executor.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Perception and symbolic executor are separate modules: the neural perception module produces symbols that the symbolic executor (with predefined operators) executes; semi-modular pipeline with supervision to align components.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Disentangling of vision and symbolic reasoning, interpretability via symbolic programs and operators, and improved compositional generalization for grounded language tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Visual question answering and grounded language tasks (cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Demonstrated compositional generalization in its original work; here cited as an example of neuro-symbolic separation of perception and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability since reasoning is performed by explicit symbolic programs and operators.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>In other work requires predefined operators and program templates; not discussed in detail here.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Separation of perception (neural) and symbolic program execution (symbolic) to leverage strengths of both for grounded reasoning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e448.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Yi et al. NS-VQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-symbolic VQA: Disentangling reasoning from vision and language understanding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic VQA approach that disentangles visual perception and symbolic reasoning by parsing language to symbolic programs and executing them over neural scene representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural-symbolic vqa: Disentangling reasoning from vision and language understanding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural-Symbolic VQA (Yi et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Pipeline where a neural perception module produces scene representations and a symbolic program derived from language is executed (via predefined logic operators) to answer visual questions, separating vision and reasoning components.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic programs / logic operators derived from language parsing used for reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural perception modules that produce scene representations (and neural modules that map language to symbolic programs).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular: parsed symbolic programs drive execution over neural scene representations; separation allows interpretability and modular training.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Improved disentanglement of vision and reasoning, interpretability via explicit program execution, and better handling of compositional language queries.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Visual question answering (VQA).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Cited as an example of modular neuro-symbolic design enabling better generalization on compositional language-vision tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic programs and operators provide transparent reasoning traces.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Original designs often require predefined operators and separate training; specifics not elaborated here.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Divide-and-conquer: disentangle perception and symbolic reasoning to combine interpretability and learnability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e448.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeSS / Stack Machines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Compositional generalization via neural-symbolic stack machines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural-symbolic stack-machine-style architectures that implement algorithmic stacks and operators to improve compositional generalization by combining neural control with symbolic-style stack operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Compositional generalization via neural-symbolic stack machines</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural-Symbolic Stack Machines (NeSS / stack-machine approaches)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Architectures that simulate an algorithmic stack (symbolic data structure and operators) controlled by neural components; intended to combine algorithmic symbolic operations with neural parameterization to enable compositional behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Stack-based symbolic data structures and algorithmic operators (symbolic control flow / stack operations).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural controllers that decide stack operations and manipulate representations, trained to implement algorithmic/compositional behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybrid stack machine where symbolic stack semantics are simulated/used and neural networks learn to drive operations; neuro-symbolic coupling aimed at procedural algorithmic generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Improved compositional generalization and algorithmic-style manipulation of structured data, bridging procedural symbolic algorithms and neural controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Compositional generalization tasks and algorithmic generalization benchmarks (cited as relevant prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Designed to target compositional generalization; cited as relevant to neuro-symbolic approaches that aim to generalize beyond raw perceptual correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Stack semantics provide an interpretable procedural substrate; details not given here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed in detail in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Algorithmic / procedural substrate (stack machines) augmented with neural learnable controllers to recover symbolic algorithmic behavior in a differentiable setting.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e448.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e448.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Interpreter (NI)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dynamic inference with neural interpreters</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural approach that decomposes computation into learned modules and dynamically routes inputs through learned interpreter-like modules to support compositionality and generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dynamic inference with neural interpreters</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Interpreter (NI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A modular neural architecture that learns set of modules (interpreters) and routes inputs through different module compositions dynamically to perform reasoning-like computations and generalize compositionally.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Not strictly declarative symbolic code; more of a neural modular interpreter abstraction (module composition plays role similar to symbolic subroutines but implemented neurally).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural modules and learned routing mechanisms that implement procedural composition at runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Purely neural modular interpreter: dynamic routing/composition of learned modules for input-specific computation paths (cited as complementary to ALANS).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Routing-based compositionality and dynamic reuse of learned modules to generalize to new inputs; improved modularization of computation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Generalization and compositional tasks (cited as complementary work).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Aimed at compositional generalization via dynamic module routing; cited as complementary to ALANS's focus on operator induction.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Modular structure can be inspected, but reasoning is still neural rather than explicit symbolic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Described as complementary and more focused on compositional routing rather than explicit induction/execution of symbolic operators.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Modularity and dynamic routing as a way to achieve compositional generalization within a neural paradigm.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deepproblog: Neural probabilistic logic programming <em>(Rating: 2)</em></li>
                <li>Neural logic machines <em>(Rating: 2)</em></li>
                <li>Learning by abstraction: The neural state machine <em>(Rating: 2)</em></li>
                <li>The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision <em>(Rating: 2)</em></li>
                <li>Neural-symbolic vqa: Disentangling reasoning from vision and language understanding <em>(Rating: 2)</em></li>
                <li>Compositional generalization via neural-symbolic stack machines <em>(Rating: 2)</em></li>
                <li>Dynamic inference with neural interpreters <em>(Rating: 2)</em></li>
                <li>Learning explanatory rules from noisy data <em>(Rating: 1)</em></li>
                <li>Logic tensor networks: Deep learning and logical reasoning from data and knowledge <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-448",
    "paper_id": "paper-244709368",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "ALANS",
            "name_full": "ALgebra-Aware Neuro-Semi-Symbolic learner",
            "brief_description": "A neuro-semi-symbolic hybrid that combines a neural visual perception frontend with an algebraic (matrix-based) symbolic reasoning backend that induces operators on the fly via inner optimization, designed to improve systematic generalization on Raven-style abstract reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ALANS (ALgebra-Aware Neuro-Semi-Symbolic learner)",
            "system_description": "Modular hybrid: a neural visual perception frontend (sliding-window object CNN that outputs object-attribute distributions and a belief-inference engine that marginalizes to panel-level belief states) feeds probabilistic belief states into an algebraic abstract reasoning backend that lifts belief states to a learnable matrix representation (via Peano-axiom inspired encodings and representation theory), induces the hidden operator by solving a regularized linear-regression inner optimization, executes the induced matrix operator to predict the answer representation, decodes by isomorphism to produce a probabilistic answer belief state, and selects the choice with minimum divergence.",
            "declarative_component": "Algebraic symbolic component: attribute-specific discrete algebraic structures (integer-indexed sets / groups) represented via a learnable matrix space (zero element as M0 and successor as a matrix M_a); symbolic 'operators' are elements of a learnable matrix group and are induced (not hand-defined) from context panels. Representation-theoretic isomorphism between abstract algebra and matrix representation establishes the symbolic layer.",
            "imperative_component": "Neural perception and optimization: object CNN (four-branch, sliding-window) producing objectness, type, size, color distributions; a belief-inference engine computing panel-level attribute distributions; gradient-based end-to-end training (ADAM); inner optimization problems solved in closed form (regularized linear regression) as differentiable subroutines embedded in the forward pass.",
            "integration_method": "Modular neuro-semi-symbolic integration: perception produces probabilistic belief states passed to the algebraic backend; the backend lifts beliefs to matrices and performs inner-level closed-form optimization (operator induction and execution) within the forward pass; the whole system is end-to-end trainable (soft expectations over beliefs permit gradients to flow) and uses a hybrid loss that includes cross-entropy on answer selection plus auxiliary loss shaping operator distributions.",
            "emergent_properties": "Improved systematic generalization (ability to extrapolate to out-of-distribution relation instances), interpretability (explicit belief states, induced operators, and executable algebraic representations that mirror human-like induce-execute-compare reasoning), on-the-fly induction of symbolic operators (semi-symbolic — operators are not predefined), and generative capability (decoded predicted representation can be rendered to synthesize a solution panel).",
            "task_or_benchmark": "Abstract visual reasoning — Raven's Progressive Matrices (RPM)-style problems (RAVEN / I-RAVEN datasets and systematic generalization splits: systematicity, productivity, localism).",
            "hybrid_performance": "Systematic-generalization (Zhang et al. generator): average accuracy ≈ 79.63% (Systematicity: 78.45%, Productivity: 79.95%, Localism: 80.50%). Systematic-generalization (Hu et al. generator / I-RAVEN splits): average accuracy ≈ 65.42% (Systematicity: 64.80%, Productivity: 65.55%, Localism: 65.90%). I.I.D. RAVEN benchmark: overall accuracy ≈ 74.4% (per Table 4).",
            "declarative_only_performance": null,
            "imperative_only_performance": "Various pure connectionist baselines reported lower systematic-generalization performance (examples in paper: ResNet, WReN, CoPINet, MXGNet, SCL, etc.; see paper Tables for numbers); direct single-number baseline is not a single declarative-free baseline but multiple models are compared (typical systematic-generalization averages for pure connectionist methods are ≈ 25–60% depending on method and split).",
            "has_comparative_results": true,
            "generalization_properties": "Substantially better out-of-distribution systematic generalization than multiple pure connectionist baselines on the three constructed OOD splits (systematicity, productivity, localism); algebraic representation + semi-symbolic operator induction supports productivity and localism (constituent-to-recursive composition) and operator induction improves systematicity; still sensitive to perception uncertainty.",
            "interpretability_properties": "High: explicit panel belief states, explicit learned algebraic encodings (zero and successor matrices), induced operator matrices, and a clear induce-&gt;execute-&gt;compare pipeline permit inspection and decoding (isomorphism allows decoding predicted algebraic representations back to attribute probabilities and rendering).",
            "limitations_or_failures": "Assumes independence across attributes (factorization), fixed and known attribute value spaces; sensitivity to perception uncertainty as expectations over belief distributions introduce noise into operator induction; reasoning module still imperfect (gap between ALANS and ALANS-V shows remaining inductive limitations); color attribute reasoning and perception were weaker; curriculum and staged training needed for stability.",
            "theoretical_framework": "Motivated by abstract algebra and representation theory with Peano-axiom grounding: lift discrete algebraic elements and operators into a learnable matrix representation establishing an isomorphism that reduces symbolic algebra induction to solving linear-algebraic (regularized least-squares) inner optimizations; principle that algebraic treatment provides structural inductive bias for systematic generalization.",
            "uuid": "e448.0"
        },
        {
            "name_short": "DeepProbLog",
            "name_full": "Deepproblog: Neural probabilistic logic programming",
            "brief_description": "A hybrid system that integrates neural predicates with probabilistic logic programming (ProbLog) to combine perception (neural networks) with symbolic logical reasoning in a unified probabilistic framework.",
            "citation_title": "Deepproblog: Neural probabilistic logic programming",
            "mention_or_use": "mention",
            "system_name": "DeepProbLog",
            "system_description": "Neural-probabilistic logic programming framework that connects learned neural components (e.g., perceptual classifiers) to a ProbLog program that performs probabilistic logic inference, allowing learning and reasoning to be combined.",
            "declarative_component": "Probabilistic logic programming (ProbLog) — symbolic/probabilistic logical rules and queries.",
            "imperative_component": "Neural networks providing learned predicates (perception/classification components).",
            "integration_method": "Neural predicates are embedded into a ProbLog program; probabilistic logic inference and learning are combined to allow end-to-end training across neural and symbolic parts (neural outputs feed into logical inference).",
            "emergent_properties": "Brings together perceptual learning and symbolic probabilistic reasoning enabling explanations grounded in logic, and end-to-end learning of perceptual-to-symbolic pipelines; supports reasoning with uncertainty.",
            "task_or_benchmark": "General neural-symbolic tasks connecting perception and logic (paper does not give RPM experiments in this text).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Paper mentions it as a hybrid that connects learning and reasoning; no detailed generalization metrics given in this paper.",
            "interpretability_properties": "Improved interpretability due to explicit logical programs and probabilistic predicates; symbolic rules provide explanations for inferences.",
            "limitations_or_failures": "Not discussed in detail in this paper's text.",
            "theoretical_framework": "Combines probabilistic logic programming foundations (ProbLog) with neural predicate learning to create a differentiable pipeline for symbolic probabilistic reasoning with learned perception.",
            "uuid": "e448.1"
        },
        {
            "name_short": "NSM",
            "name_full": "Neural State Machine (NSM)",
            "brief_description": "A neuro-symbolic approach for visual question answering that uses a probabilistic graph for reasoning over neural perceptual representations.",
            "citation_title": "Learning by abstraction: The neural state machine",
            "mention_or_use": "mention",
            "system_name": "Neural State Machine (NSM)",
            "system_description": "Architecture that separates perception from reasoning by building a probabilistic graph / state machine over visual entities detected by neural perceptual modules, then performing higher-level reasoning over that graph.",
            "declarative_component": "Probabilistic graph structure used for reasoning (explicit graph-based symbolic representation of entities/relations).",
            "imperative_component": "Neural perception modules that detect entities and produce features; learned modules to propagate and aggregate information on the graph.",
            "integration_method": "Perception yields nodes/features for a symbolic/probabilistic graph, then neural message-passing / graph inference performs reasoning on that graph; neuro-symbolic pipeline with explicit graph abstraction.",
            "emergent_properties": "Disentangles vision and reasoning, enabling more structured reasoning over detected entities and edges and potential gains in interpretability and compositionality for VQA tasks.",
            "task_or_benchmark": "Visual question answering (VQA) (as described in the paper's related work).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Mentioned as an example of neuro-symbolic architecture that can help reasoning; no quantitative generalization claims provided here.",
            "interpretability_properties": "Probabilistic graph representation affords inspection of relational structure used during reasoning.",
            "limitations_or_failures": "Not detailed in this text.",
            "theoretical_framework": "Constructs an explicit graph abstraction (state machine) over perceptual outputs to separate and combine symbolic reasoning and neural perception.",
            "uuid": "e448.2"
        },
        {
            "name_short": "NLM",
            "name_full": "Neural Logic Machines",
            "brief_description": "A differentiable neural architecture that implements inductive logic-like reasoning end-to-end to learn rules and perform relational induction.",
            "citation_title": "Neural logic machines",
            "mention_or_use": "mention",
            "system_name": "Neural Logic Machines (NLM)",
            "system_description": "A neural architecture designed to emulate logical/relational operators in a differentiable manner, enabling end-to-end inductive learning of rule-like behaviors over relations.",
            "declarative_component": "Logic-like relational operators and rule induction as an intended symbolic component (implemented via structured layers that mimic logical computation).",
            "imperative_component": "Differentiable neural layers (designed to represent logical/relational operations) trained end-to-end.",
            "integration_method": "End-to-end differentiable network architecture that encodes relational reasoning primitives enabling neural induction of logical rules.",
            "emergent_properties": "Ability to learn relational rules and perform inductive generalization with neural parameterization of logical computations.",
            "task_or_benchmark": "Relational reasoning and inductive rule learning tasks (not RPM in this paper's experiments).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Designed to improve compositional/relational generalization through structured neural approximations to logic; this paper only cites it as prior work.",
            "interpretability_properties": "Architectural resemblance to logical computation may aid interpretability of learned relational operations, but specifics not given here.",
            "limitations_or_failures": "Not specified in this text.",
            "theoretical_framework": "Implements a neural approximation of logical relational computation to support end-to-end induction of rules.",
            "uuid": "e448.3"
        },
        {
            "name_short": "Neuro-Symbolic Concept Learner",
            "name_full": "The neuro-symbolic concept learner",
            "brief_description": "A neuro-symbolic system that separates perception and symbolic parsing, mapping visual scenes to symbols and chaining predefined logical operators associated with language tokens to perform reasoning.",
            "citation_title": "The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision",
            "mention_or_use": "mention",
            "system_name": "Neuro-Symbolic Concept Learner (NS-CL)",
            "system_description": "A system where a neural perception module extracts symbolic scene representations and a symbolic program executor composes predefined logic operators (from parsed language) to answer questions; perception and symbolic modules can be trained to align under supervision.",
            "declarative_component": "Predefined logic operators and symbolic program execution acting on extracted symbols (structured symbolic programs derived from language).",
            "imperative_component": "Neural perception modules mapping pixels to objects and attributes; learned modules that produce symbols for the symbolic executor.",
            "integration_method": "Perception and symbolic executor are separate modules: the neural perception module produces symbols that the symbolic executor (with predefined operators) executes; semi-modular pipeline with supervision to align components.",
            "emergent_properties": "Disentangling of vision and symbolic reasoning, interpretability via symbolic programs and operators, and improved compositional generalization for grounded language tasks.",
            "task_or_benchmark": "Visual question answering and grounded language tasks (cited in related work).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Demonstrated compositional generalization in its original work; here cited as an example of neuro-symbolic separation of perception and reasoning.",
            "interpretability_properties": "High interpretability since reasoning is performed by explicit symbolic programs and operators.",
            "limitations_or_failures": "In other work requires predefined operators and program templates; not discussed in detail here.",
            "theoretical_framework": "Separation of perception (neural) and symbolic program execution (symbolic) to leverage strengths of both for grounded reasoning.",
            "uuid": "e448.4"
        },
        {
            "name_short": "Yi et al. NS-VQA",
            "name_full": "Neural-symbolic VQA: Disentangling reasoning from vision and language understanding",
            "brief_description": "A neuro-symbolic VQA approach that disentangles visual perception and symbolic reasoning by parsing language to symbolic programs and executing them over neural scene representations.",
            "citation_title": "Neural-symbolic vqa: Disentangling reasoning from vision and language understanding",
            "mention_or_use": "mention",
            "system_name": "Neural-Symbolic VQA (Yi et al.)",
            "system_description": "Pipeline where a neural perception module produces scene representations and a symbolic program derived from language is executed (via predefined logic operators) to answer visual questions, separating vision and reasoning components.",
            "declarative_component": "Symbolic programs / logic operators derived from language parsing used for reasoning.",
            "imperative_component": "Neural perception modules that produce scene representations (and neural modules that map language to symbolic programs).",
            "integration_method": "Modular: parsed symbolic programs drive execution over neural scene representations; separation allows interpretability and modular training.",
            "emergent_properties": "Improved disentanglement of vision and reasoning, interpretability via explicit program execution, and better handling of compositional language queries.",
            "task_or_benchmark": "Visual question answering (VQA).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Cited as an example of modular neuro-symbolic design enabling better generalization on compositional language-vision tasks.",
            "interpretability_properties": "Symbolic programs and operators provide transparent reasoning traces.",
            "limitations_or_failures": "Original designs often require predefined operators and separate training; specifics not elaborated here.",
            "theoretical_framework": "Divide-and-conquer: disentangle perception and symbolic reasoning to combine interpretability and learnability.",
            "uuid": "e448.5"
        },
        {
            "name_short": "NeSS / Stack Machines",
            "name_full": "Compositional generalization via neural-symbolic stack machines",
            "brief_description": "Neural-symbolic stack-machine-style architectures that implement algorithmic stacks and operators to improve compositional generalization by combining neural control with symbolic-style stack operations.",
            "citation_title": "Compositional generalization via neural-symbolic stack machines",
            "mention_or_use": "mention",
            "system_name": "Neural-Symbolic Stack Machines (NeSS / stack-machine approaches)",
            "system_description": "Architectures that simulate an algorithmic stack (symbolic data structure and operators) controlled by neural components; intended to combine algorithmic symbolic operations with neural parameterization to enable compositional behavior.",
            "declarative_component": "Stack-based symbolic data structures and algorithmic operators (symbolic control flow / stack operations).",
            "imperative_component": "Neural controllers that decide stack operations and manipulate representations, trained to implement algorithmic/compositional behaviors.",
            "integration_method": "Hybrid stack machine where symbolic stack semantics are simulated/used and neural networks learn to drive operations; neuro-symbolic coupling aimed at procedural algorithmic generalization.",
            "emergent_properties": "Improved compositional generalization and algorithmic-style manipulation of structured data, bridging procedural symbolic algorithms and neural controllers.",
            "task_or_benchmark": "Compositional generalization tasks and algorithmic generalization benchmarks (cited as relevant prior work).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Designed to target compositional generalization; cited as relevant to neuro-symbolic approaches that aim to generalize beyond raw perceptual correlations.",
            "interpretability_properties": "Stack semantics provide an interpretable procedural substrate; details not given here.",
            "limitations_or_failures": "Not discussed in detail in this paper.",
            "theoretical_framework": "Algorithmic / procedural substrate (stack machines) augmented with neural learnable controllers to recover symbolic algorithmic behavior in a differentiable setting.",
            "uuid": "e448.6"
        },
        {
            "name_short": "Neural Interpreter (NI)",
            "name_full": "Dynamic inference with neural interpreters",
            "brief_description": "A neural approach that decomposes computation into learned modules and dynamically routes inputs through learned interpreter-like modules to support compositionality and generalization.",
            "citation_title": "Dynamic inference with neural interpreters",
            "mention_or_use": "mention",
            "system_name": "Neural Interpreter (NI)",
            "system_description": "A modular neural architecture that learns set of modules (interpreters) and routes inputs through different module compositions dynamically to perform reasoning-like computations and generalize compositionally.",
            "declarative_component": "Not strictly declarative symbolic code; more of a neural modular interpreter abstraction (module composition plays role similar to symbolic subroutines but implemented neurally).",
            "imperative_component": "Neural modules and learned routing mechanisms that implement procedural composition at runtime.",
            "integration_method": "Purely neural modular interpreter: dynamic routing/composition of learned modules for input-specific computation paths (cited as complementary to ALANS).",
            "emergent_properties": "Routing-based compositionality and dynamic reuse of learned modules to generalize to new inputs; improved modularization of computation.",
            "task_or_benchmark": "Generalization and compositional tasks (cited as complementary work).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Aimed at compositional generalization via dynamic module routing; cited as complementary to ALANS's focus on operator induction.",
            "interpretability_properties": "Modular structure can be inspected, but reasoning is still neural rather than explicit symbolic execution.",
            "limitations_or_failures": "Described as complementary and more focused on compositional routing rather than explicit induction/execution of symbolic operators.",
            "theoretical_framework": "Modularity and dynamic routing as a way to achieve compositional generalization within a neural paradigm.",
            "uuid": "e448.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deepproblog: Neural probabilistic logic programming",
            "rating": 2,
            "sanitized_title": "deepproblog_neural_probabilistic_logic_programming"
        },
        {
            "paper_title": "Neural logic machines",
            "rating": 2,
            "sanitized_title": "neural_logic_machines"
        },
        {
            "paper_title": "Learning by abstraction: The neural state machine",
            "rating": 2,
            "sanitized_title": "learning_by_abstraction_the_neural_state_machine"
        },
        {
            "paper_title": "The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision",
            "rating": 2,
            "sanitized_title": "the_neurosymbolic_concept_learner_interpreting_scenes_words_and_sentences_from_natural_supervision"
        },
        {
            "paper_title": "Neural-symbolic vqa: Disentangling reasoning from vision and language understanding",
            "rating": 2,
            "sanitized_title": "neuralsymbolic_vqa_disentangling_reasoning_from_vision_and_language_understanding"
        },
        {
            "paper_title": "Compositional generalization via neural-symbolic stack machines",
            "rating": 2,
            "sanitized_title": "compositional_generalization_via_neuralsymbolic_stack_machines"
        },
        {
            "paper_title": "Dynamic inference with neural interpreters",
            "rating": 2,
            "sanitized_title": "dynamic_inference_with_neural_interpreters"
        },
        {
            "paper_title": "Learning explanatory rules from noisy data",
            "rating": 1,
            "sanitized_title": "learning_explanatory_rules_from_noisy_data"
        },
        {
            "paper_title": "Logic tensor networks: Deep learning and logical reasoning from data and knowledge",
            "rating": 1,
            "sanitized_title": "logic_tensor_networks_deep_learning_and_logical_reasoning_from_data_and_knowledge"
        }
    ],
    "cost": 0.02129,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Learning Algebraic Representation for Systematic Generalization in Abstract Reasoning</p>
<p>Chi Zhang 
University of California
90095Los AngelesCAUSA</p>
<p>Sirui Xie srxie@ucla.edu 
BaoxiongJia ‹1 
University of California
90095Los AngelesCAUSA</p>
<p>Ying Nian Wu 
University of California
90095Los AngelesCAUSA</p>
<p>Song-Chun Zhu sczhu@stat.ucla.edu 
University of California
90095Los AngelesCAUSA</p>
<p>Institute for Artificial Intelligence
Peking University
10080BeijingChina</p>
<p>Tsinghua University
10080BeijingChina</p>
<p>Beijing Institute for General Artificial Intelligence
10080BeijingChina</p>
<p>Yixin Zhu yixin.zhu@pku.edu.cn 
University of California
90095Los AngelesCAUSA</p>
<p>Institute for Artificial Intelligence
Peking University
10080BeijingChina</p>
<p>Learning Algebraic Representation for Systematic Generalization in Abstract Reasoning</p>
<p>Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representation for the abstract spatial-temporal reasoning task of Raven's Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner. The ALANS learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representation, while the backend transforms it into an algebraic structure and induces the hidden operator on the fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show the generative nature of the learned algebraic representation; it can be decoded by isomorphism to generate an answer.</p>
<p>Abstract. Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representation for the abstract spatial-temporal reasoning task of Raven's Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner. The ALANS learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representation, while the backend transforms it into an algebraic structure and induces the hidden operator on the fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show the generative nature of the learned algebraic representation; it can be decoded by isomorphism to generate an answer.</p>
<p>Introduction</p>
<p>"Thought is in fact a kind of Algebra." -William James [25] Imagine you are given two alphabetical sequences of "c, b, a" and "d, c, b", and asked to fill in the missing element in "e, d, ?". In nearly no time will one realize the answer to be c. However, more surprising for human learning is that, effortlessly and instantaneously, we can "freely generalize" [37] the solution to any partial consecutive ordered sequences. While believed to be innate in early development for human infants [39], such systematic generalizability has constantly been missing and proven to be particularly challenging in existing connectionist models [2,29]. In fact, such an ability to entertain a given thought and semantically related contents strongly implies an abstract algebra-like treatment [12]; in literature, it is referred to as the "language of thought" [11], "physical symbol system" [44], and "algebraic mind" [37]. However, in stark contrast, existing connectionist models tend only to capture statistical correlation [7,26,29], rather than providing any account for a structural inductive bias where systematic algebra can be carried out to facilitate generalization.</p>
<p>This contrast instinctively raises a question-what constitutes such an algebraic inductive bias? We argue that the foundation of modeling counterpart to the algebraic treatment in early human development [37,39] lies in algebraic computations set up on mathematical axioms, a form of formalized human intuition and the beginning of modern mathematical reasoning [17,34]. Of particular importance to the algebra's basic building blocks is the Peano Axiom [46]. In the Peano Axiom, the essential components of algebra, the algebraic set, and corresponding operators over it, are governed by three statements: (1) the existence of at least one element in the field to study ("zero" element), (2) a successor function that is recursively applied to all elements and can, therefore, span the entire field, and (3) the principle of mathematical induction. Building on such a fundamental axiom, we begin to form the notion of an algebraic set and induce the operator to construct an algebraic structure. We hypothesize that such an algebraic treatment set up on fundamental axioms is essential for a model's systematic generalizability, the lack of which will only make it sub-optimal.</p>
<p>To demonstrate the benefits of adopting such an algebraic treatment in systematic generalization, we showcase a prototype for Raven's Progressive Matrices (RPM) [48,49], an exemplar task for abstract spatial-temporal reasoning [51,68]. In this task, an agent is given an incomplete 3ˆ3 matrix consisting of eight context panels with the last one missing, and asked to pick one answer from a set of eight choices that best completes the matrix. Human's reasoning capability of solving this abstract reasoning task has been commonly regarded as an indicator of "general intelligence" [4] and "fluid intelligence" [19,24,55,56]. In spite of the task being one that ideally requires abstraction, algebraization, induction, and generalization [4,48,49], recent endeavors unanimously propose pure connectionist models that attempt to circumvent such intrinsic cognitive requirements [21,51,58,64,68,70,74]. However, these methods' inefficiency is also evident in systematic generalization; they struggle to extrapolate to domains beyond training [51,70], shown also in this paper.</p>
<p>To address the issue, we introduce an ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner. At a high-level, the ALANS learner is embedded in a general neuro-symbolic architecture [14,36,66,67] but has the on-the-fly operator learnability, hence semi-symbolic. Specifically, it consists of a neural visual per-ception frontend and an algebraic abstract reasoning backend. For each RPM instance, the neural visual perception frontend first slides a window over each panel to obtain the object-based representation [26,63] for every object. A belief inference engine latter aggregates all object-based representation in each panel to produce the probabilistic belief state. The algebraic abstract reasoning backend then takes the belief states of the eight context panels, treats them as snapshots on an algebraic structure, lifts them into a matrix-based algebraic representation built on the Peano Axiom and the representation theory [23], and induces the hidden operator in the algebraic structure by solving an inner optimization problem [3,8,72]. The answer's algebraic representation is predicted by executing the induced operator: its corresponding set element is decoded by isomorphism, and the final answer is selected as the one most similar to the prediction.</p>
<p>The ALANS learner enjoys several benefits in abstract reasoning with an algebraic treatment:</p>
<ol>
<li>Unlike previous monolithic models, the ALANS learner offers a more interpretable account of the entire abstract reasoning process: the neural visual perception frontend extracts object-based representation and produces belief states of panels by explicit probability inference, whereas the algebraic abstract reasoning backend induces the hidden operator in the algebraic structure. The final answer's representation is obtained by executing the induced operator, and the choice panel with minimum distance is selected. This process much resembles the top-down bottom-up strategy in human reasoning missed in recent literature [21,51,58,64,68,70,74]: humans reason by inducing the hidden relation, executing it to generate a feasible solution in mind, and choosing the most similar answer available [4]. 2. While keeping the semantic interpretability and end-to-end trainability in existing neuro-symbolic frameworks [14,36,66,67], ALANS is semi-symbolic in the sense that the symbolic operator can be learned and concluded on the fly without manual definition for every one of them. Such an inductive ability also enables a greater extent of the desired generalizability. 3. By decoding the predicted representation in the algebraic structure, we can also generate an answer that satisfies the hidden relation in the context. This work makes three major contributions. (1) We propose the ALANS learner, a neuro-semi-symbolic design, in contrast to existing monolithic models.</li>
</ol>
<p>(2) To demonstrate the efficacy of incorporating an algebraic treatment in reasoning, we show the superior systematic generalization ability of the proposed ALANS learner in various extrapolatory RPM domains. (3) We present analyses into both neural visual perception and algebraic abstract reasoning.</p>
<p>Related Work</p>
<p>Quest for Symbolized Manipulation</p>
<p>The idea to treat thinking as a mental language can be dated back to Augustine [1,62]. Since the 1970s, this school of thought has undergone a dramatic revival as the quest for symbolized manipulation in cognitive modeling, such as "language of thought" [11], "physical symbol system" [44], and "algebraic mind" [37]. In their study, connectionist's task-specific superiority and inability to generalize beyond training [7,26,51,68] have been hypothetically linked to a lack of such symbolized algebraic manipulation [7,29,38]. With evidence that an algebraic treatment adopted in early human development [39] can potentially address the issue [2,36,38], classicist [12] approaches for generalizable reasoning used in programs [40] and blocks world [61] have resurrected. As a hybrid approach to bridge connectionist and classicist, recent developments lead to neuro-symbolic architectures. In particular, the community of theorem proving has been one of the earliest to endorse the technique [13,50,53]: BILP [10] and NLM [9] make inductive programming end-to-end, and DeepProbLog [35] connects learning and reasoning. Recently, Hudson and Manning [22] propose NSM for visual question answering where a probabilistic graph is used for reasoning. Yi et al . [67] demonstrate a neuro-symbolic prototype for the same task where a perception module and a language parsing module are separately trained, with the predefined logic operators associated with language tokens chained to process the visual information. Mao et al . [36] soften the predefined operators to afford end-to-end training with only question answers. Han et al . [14] use the hybrid architecture for metaconcept learning. Yi et al . [66] and Chen et al . [6] show how neuro-symbolic models can handle explanatory, predictive, and counterfactual questions in temporal and causal reasoning. Lately, NeSS [5] exemplifies an algorithmic stack machine that can be used to improve generalization in language learning. ALANS follows the classicist's call but adopts a neuro-semi -symbolic architecture: it is end-to-end trainable as opposed to Yi et al . [66,67] and the operator can be learned and concluded on the fly without manual specification.</p>
<p>Abstract Visual Reasoning</p>
<p>Recent works by Santoro et al . [51] and Zhang et al . [68] arouse the community's interest in abstract visual reasoning; the task of Raven's Progressive Matrices (RPM) is introduced as such a measure for intelligent agents. As an intelligence quotient test for humans [48,49], RPM is believed to be strongly correlated with human's general intelligence [4] and fluid intelligence [19,24,55,56]. Early RPM-solving systems employ symbolic representation based on hand-designed features and assume access to the underlying logics [4,31,32,33]. Another stream of research on RPM recruits similarity-based metrics to select the most similar answer from the choices [20,30,41,42,43,54]. However, these visual or semantic features are unable to handle uncertainty from imperfect perception, and directly assuming access to the logic operations simplifies the problem. Recently proposed data-driven approaches arise from the availability of large datasets: Santoro et al . [51] extend a pedagogical RPM generation method [59], whereas Zhang et al . [68] use a stochastic image grammar [75] and introduce structural annotations in it, which Hu et al . [21] further refine to avoid shortcut solutions by statistics in candidate panels. Despite the fact that RPM intrinsically requires one to perform abstraction, algebraization, induction, and generalization, Belief Inference Fig. 1. An overview of the ALANS learner. For an RPM instance, the neural visual perception module produces the belief states for all panels: an object CNN extracts object attribute distributions for each image region, and a belief inference engine marginalizes them out to obtain panel attribute distributions. For each panel attribute, the algebraic abstract reasoning module transforms the belief states into matrix-based algebraic representation and induces hidden operators by solving inner optimizations. The answer representation is obtained by executing the induced operators, and the choice most similar to the prediction is selected as the solution. An example of the underlying discrete algebra and its correspondence is also shown on the right.</p>
<p>existing methods bypass such cognitive requirements using a single feedforward pass in connectionist models: Santoro et al . [51] use a relational module [52], Steenbrugge et al . [57] augment it with a VAE [28], Zhang et al . [68] assemble a dynamic tree, Hill et al . [18] arrange the data in a contrastive manner, Zhang et al . [70] propose a contrast module, Zhang et al . [74] formulate it in a studentteacher setting, Wang et al . [58] build a multiplex graph network, Hu et al . [21] aggregate features from a hierarchical decomposition, and Wu et al . [64] apply a scattering transformation to learn objects, attributes, and relations. Recently, Zhang et al . [71] employ a neuro-symbolic design but requires full knowledge over the hidden relations to perform abduction. While our work adopts the visual perception module and employs a similar training strategy from Zhang et al . [71], the ALANS learner manages to induce the hidden relations, enabling on-the-fly relation induction and systematic generalization on relational learning. The recent work of Neural Interpreter (NI) [47] is a complementary neural approach to our method: Although both NI and ALANS decompose the reasoning process into sub-components and aggregate them, NI focuses more on compositionality, routing new input via different paths of learned modules to generalize, whereas ALANS more on induction, enabling a learned module to adapt on the fly.</p>
<p>The ALANS Learner</p>
<p>In this section, we introduce the ALANS learner for the RPM problem. In each RPM instance, an agent is given an incomplete 3ˆ3 panel matrix with the last entry missing and asked to induce the operator hidden in the matrix and choose from eight choice panels one that follows it. Formally, let the answer variable be denoted as y, the context panels as tI o,i u 8 i"1 , and choice panels as tI c,i u 8 i"1 . Then the problem can be formulated as estimating P py | tI o,i u 8</p>
<p>i"1 , tI c,i u 8 i"1 q. According to the common design [4,51,68], there is one operator that governs each panel attribute. Hence, by assuming independence among attributes, we propose to factorize the probability of P py " n | tI o,i u 8</p>
<p>i"1 , tI c,i u 8 i"1 q as
ź a ÿ T a P py a " n | T a , tI o,i u 8 i"1 , tI c,i u 8 i"1 qˆP pT a | tI o,i u 8 i"1 q,(1)
where y a denotes the answer selection based only on attribute a and T a the operator on a.</p>
<p>Overview As shown in Fig. 1, the ALANS learner decomposes the process into perception and reasoning: the neural visual perception frontend is adopted from Zhang et al . [71] and extracts the belief states from each of the sixteen panels, whereas the algebraic abstract reasoning backend views an instance as an example in an abstract algebra structure, transforms belief states into algebraic representation by the representation theory, induces the hidden operators, and executes the operators to predict the representation of the answer. Therefore, in Eq. (1), the operator distribution is modeled by the fitness of an operator and the answer distribution by the distance between the predicted representation and that of a candidate.</p>
<p>Neural Visual Perception</p>
<p>We follow the design in Zhang et al . [71] and decompose visual perception into an object CNN and a belief state inference engine. Specifically, for each panel, we use a sliding window to traverse the spatial domain of the image and feed each image region into an object CNN. The CNN has four branches, producing for each region its object attribute distributions, including objectiveness (if the region contains an object), type, size, and color. The belief inference engine summarizes the panel attribute distributions (over position, number, type, size, and color) by marginalizing out all object attribute distributions (over objectiveness, type, size, and color). As an example, the distribution of the panel attribute of Number can be computed as such: for N image regions and their predicted objectiveness
P pNumber " kq " ÿ R o Pt0,1u N ř j R o j "k N ź j"1 P pr o j " R o j q,(2)
where P pr o j q denotes the jth region's estimated objectiveness distribution, and R o is a binary sequence of length N that sums to k. All panel attribute distributions compose the belief state of a panel. In the following, we denote the belief state as b and the distribution of an attribute a as P pb a q. For more details, please refer to Zhang et al . [71] and the Appendix.</p>
<p>Algebraic Abstract Reasoning</p>
<p>Given the belief states of both context and choice panels, the algebraic abstract reasoning backend concerns the induction of hidden operators and the prediction of answer representation for each attribute. The fitness of induced operators is used for estimating the operator distribution and the difference between the prediction and the choice panel for estimating the answer distribution.</p>
<p>Algebraic Underpinning Without loss of generality, here we assume row-wise operators. For each attribute, under perfect perception, the first two rows in an RPM instance provide snapshots into an example of group [15] constrained to an integer-indexed set, a simple algebra structure that is closed under a binary operator. To see this, note that an accurate perception module would see each panel attribute as a deterministic set element. Therefore, RPM instances with unary operators, such as progression, are group examples with special binary operators where one operand is constant. Instances with binary operators, such as arithmetics, directly follow the group properties. Those with ternary operators are ones defined on a three-tuple set from rows. <br />
" &gt; A A A B 8 n i c b V D L S s N A F J 3 U V 4 2 v q k s 3 g 0 V w V R I L P h Z i 0 Y 3 L C n 1 B G s p k O m m H T m b C z E Q o o Z / h x o U i 3 f o f 7 t 2 I f + M k L a L W A x c O 5 9 z L P f c G M a N K O 8 6 n V V h a X l l d K 6 7 b G 5 t b 2 z u l 3 b 2 W E o n E p I k F E 7 I T I E U Y 5 a S p q W a k E 0 u C o o C R d j C 6 y f z 2 P Z G K C t 7 Q 4 5 j 4 E R p w G l K M t J G 8 b o T 0 E C O W N i a 9 U t m p O D n g I n H n p H z 1 Z l / G 0 w + 7 3 i u 9 d / s C J x H h G j O k l O c 6 s f Z T J D X F j E z s b q J I j P A I D Y h n K E c R U X 6 a R 5 7 A I 6 P 0 Y S i k K a 5 h r v 6 c S F G k 1 D g K T G c W U f 3 1 M v E / z 0 t 0 e O 6 n l M e J J h z P F o U J g 1 r A 7 H 7 Y p 5 J g z c a G I C y p y Q r x E E m E t f m S n T / h I s P p 9 8 m L p H V S c a u V 6 p 1 b r l 2 D G Y r g A B y C Y + C C M 1 A D t 6 A O m g A D A R 7 A E 3 i 2 t P V o v V j T W W v B m s / s g 1 + w X r 8 A B d u U 3 w = = &lt; / l a t e x i t &gt; b a o,iN w 6 B O u M U N K N R w 7 0 G 6 E p K a Y k V G m G S o S I D x A P d I w l C O f K D d K r h 7 B P a N 0 Y F d I U 1 z D R P 0 5 E S F f q a H v m U 4 f 6 b 7 6 6 8 X i f 1 4 j 1 N 1 T N 6 I 8 C D X h e L K o G z K o B Y w j g B 0 q C d Z s a A j C k p p b I e 4 j i b A 2 Q W W S E M 5 i H H + / P E u q R w W n W C h e O b n S O Z g g D X b A L t g H D j g B J X A J y q A C M J D g D t y D B + v W G l u P 1 t O k N W V N Z 7 b B L 1 g v X 5 R j l d Y = &lt; / l a t e x i t &gt; b a o,i+2Y X F p O r a R X 1 9 Y 3 N j N b 2 1 U l Q o l J B Q s m Z N 1 D i j D K S U V T z U g 9 k A T 5 H i M 1 b 3 A R + 7 U b I h U V / F o P A + L 6 q M d p l 2 K k j d T y W q g d i R y k 8 B A W R u 1 M 1 s 7 b C e A s c a Y k W 8 p 9 P H + O X 4 / K 7 c x b s y N w 6 B O u M U N K N R w 7 0 G 6 E p K a Y k V G 6 G S o S I D x A P d I w l C O f K D d K r h 7 B f a N 0 Y F d I U 1 z D R P 0 5 E S F f q a H v m U 4 f 6 b 7 6 6 8 X i f 1 4 j 1 N 1 T N 6 I 8 C D X h e L K o G z K o B Y w j g B 0 q C d Z s a A j C k p p b I e 4 j i b A 2 Q a W T E M 5 i H H + / P E u q h b x T z B e v n G z p H E y Q A r t g D x w A B 5 y A E r g E Z V A B G E h w B + 7 B g 3 V r j a 1 H 6 2 n S O m d N Z 3 b A L 1 g v X 5 X o l d c = &lt; / l a t e x i t &gt; M (b a o,i+2 ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K I P G K i z Q 9 G Q r x J C Y W r X 6 j A 4 6 b D I = " &gt; A A A B + n i c b V D J S g N B E O 2 J W 4 z b R I 9 e G o M Q M Y a Z B F x u Q S 9 e h A h m g W Q c e j q d p E n P Q n e P E s Z 8 S i 4 e D O J N / B J v / o B X f 8 G e S R C 3 B w W P 9 6 q o q u c E j A p p G G 9 a a m 5 + Y X E p v Z x Z W V 1 b 3 9 C z m 3 X h h x y T G v a Z z 5 s O E o R R j 9 Q k l Y w 0 A 0 6 Q 6 z D S c A Z n s d + 4 I V x Q 3 7 u S w 4 B Y L u p 5 t E s x k k q y 9 e x F 3 r l G d u Q X I I X 7 s D T a s / W c U T Q S w L / E n J F c p f A + + R g / H 1 R t / b X d 8 X H o E k 9 i h o R o m U Y g r Q h x S T E j o 0 w 7 F C R A e I B 6 p K W o h 1 w i r C g 5 f Q R 3 l d K B X Z + r 8 i R M 1 O 8 T E X K F G L q O 6 n S R 7 I v f X i z + 5 7 V C 2 T 2 2 I u o F o S Q e n i 7 q h g x K H 8 Y 5 w A 7 l B E s 2 V A R h T t W t E P c R R 1 i q t D J J C C c x D r 9 e / k v q p a J Z L p Y v z V z l F E y R B t t g B + S B C Y 5 A B Z y D K q g B D G 7 B G D y A i X a n 3 W u P 2 t O 0 N a X N Z r b A D 2 g v n 3 f S l s Q = &lt; / l a t e x i t &gt; M (b a o,i+1 ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 7 b 3 K w W n u 1 J Q k 3 P 7 p q i N y i A F L g Q = " &gt; A A A B + n i c b V D L S s N A F J 3 U V 6 2 v V J d u B o t Q s Z b E g o 9 d 0 Y 0 b o Y J 9 Q B v D Z D p t h 0 4 y Y W a i l N h P 6 c a F R d y J X + L O H 3 D r L 5 i k R d R 6 4 M L h n H u 5 9 x 7 H Z 1 Q q w 3 j X U n P z C 4 t L 6 e X M y u r a + o a e 3 a x J H g h M q p g z L h o O k o R R j 1 Q V V Y w 0 f E G Q 6 z B S d / r n s V + / J U J S 7 l 2 r g U 8 s F 3 U 9 2 q E Y q U i y 9 e x l 3 r l B d s g L k M J 9 a A 7 3 b D 1 n F I 0 E c J a Y U 5 I r F z 7 G n 6 O X g 4 q t v 7 X a H A c u 8 R R m S M q m a f j K C p F Q F D M y z L Q C S X y E + 6 h L m h H 1 k E u k F S a n D + F u p L R h h 4 u o P A U T 9 e d E i F w p B 6 4 T d b p I 9 e R f L x b / 8 5 q B 6 p x Y I f X 8 Q B E P T x Z 1 A g Y V h 3 E O s E 0 F w Y o N I o K w o N G t E P e Q Q F h F a W W S E E 5 j H H 2 / P E t q h 0 W z V C x d m b n y G Z g g D b b B D s g D E x y D M r g A F V A F G N y B E X g E Y + 1 e e 9 C e t O d J a 0 q b z m y B X 9 B e v w B 2 T J b D &lt; / l a t e x i t &gt; M (b a o,i ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o i N W 9 + u 1 3 H 6 F P 8 i + / F k B P n H p s / I = " &gt; A A A B 9 H i c b V D L S s N A F J 3 U V 6 2 v q k s 3 g 0 W o U E t i w c e u 6 M a N U M E + o I 1 l M p 2 0 Q y e Z O D M p l N D v c K O g i L h z 4 a e 4 8 w f c + g t O 0 i J q P X D h c M 6 9 3 H u P E z A q l W m + G 6 m Z 2 b n 5 h f R i Z m l 5 Z X U t u 7 5 R k z w U m F Q x Z 1 w 0 H C Q J o z 6 p K q o Y a Q S C I M 9 h p O 7 0 T 2 O / P i B C U u 5 f q m F A b A 9 1 f e p S j J S W 7 P O 8 c 4 X a E S 9 A O t p t Z 3 N m 0 U w A p 4 k 1 I b l y 4 e P 5 8 + 5 1 r 9 L O v r U 6 H I c e 8 R V m S M q m Z Q b K j p B Q F D M y y r R C S Q K E + 6 h L m p r 6 y C P S j p K j R 3 B H K x 3 o c q H L V z B R f 0 5 E y J N y 6 D m 6 0 0 O q J / 9 6 s f i f 1 w y V e 2 R H 1 A 9 C R X w 8 X u S G D C o O 4 w R g h w q C F R t q g r C g + l a I e 0 g g r H R O m S S E 4 x g H 3 y 9 P k 9 p + 0 S o V S x d W r n w C x k i D L b A N 8 s A C h 6 A M z k A F V A E G 1 + A G 3 I M H Y 2 D c G o / G 0 7 g 1 Z U x m N s E v G C 9 f b X G V z g = = &lt; / l a t e x i t &gt; M (·)
&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g y R l S F L N g D X F R B Y x f 4 F K P v 6 j g a w = " &gt; A A A B 7 3 i c b Z D L S s N A F I Y n 9 V b r r e r S z d A i V I S S W P C y C 7 p  Algebraic Representation A systematic algebraic view allows us to felicitously recruit ideas in the representation theory [23] to glean the hidden properties in the abstract structures: it makes abstract algebra amenable by reducing it onto linear algebra. Following the same spirit, we propose to lift both the set elements and the hidden operators to a learnable matrix space. To encode the set element, we employ the Peano Axiom [46]. According to the Peano Axiom, an integer-indexed set can be constructed by (1) a zero element (0), (2) a successor function (Sp¨q), and (3) the principle of mathematical induction, such that the kth element is encoded as S k p0q. Specifically, we instantiate the zero element as a learnable matrix M 0 and the successor function as the matrix-matrix product parameterized by M .
x I 1 S w F 2 h C m U w m 7 d D J J M 5 M h F D 6 E i K 4 U M S t r + O u b + M k L a L W H w Y + / v 8 c 5 p z j x Y x K Z Z p T o 7 C 0 v L K 6 V l w v b W x u b e + U d / f a M k o E J i 0 c s U h 0 P S Q J o 5 y 0 F F W M d G N B U O g x 0 v F G V 1 n e e S B C 0 o j f q T Q m b o g G n A Y U I 6 W t 7 k 3 N w X 6 k j v r l q l k 3 c 8 F F s O Z Q t S v O 8 d P U T p v 9 8 q f j R z g J C V e Y I S l 7 l h k r d 4 y E o p i R S c l J J I k R H q E B 6 W n k K C T S H e f z T u C h d n w Y R E I / r m D u / u w Y o 1 D K N P R 0 Z Y j U U P 7 N M v O / r J e o 4 N w d U x 4 n i n A 8 + y h I G F Q R z J a H P h U E K 5 Z q Q F h Q P S v E Q y Q Q V v p E p f w I F 5 l O v 1 d e h P Z J 3 W r U G 7 d W 1 b 4 E M x X B A a i A G r D A G b D B N W i C F s C A g U f wh I G F Q R z J a H P h U E K 5 Z q Q F h Q P S v E Q y Q Q V v p E p f w I F 5 l O v 1 d e h P Z J 3 W r U G 7 d W 1 b 4 E M x X B A a i A G r D A G b D B N W i C F s C A g U f w
In an attribute-specific manner, the representation of an attribute taking the kth value is pM a q k M a 0 . For operators, we consider them to live in a learnable matrix group of a corresponding dimension, such that the action of an operator on a set can be represented as matrix multiplication. Such algebraic representation establishes an isomorphism between the matrix space and the abstract algebraic structure: abstract elements on the algebraic structure have a bijective mapping to/from the matrix space, and inducing the abstract relation can be reduced to solving for a matrix operator. See Fig. 2 for a graphical illustration of the isomorphism.</p>
<p>Operator Induction Operator induction concerns about finding a concrete operator in the abstract algebraic structure. By the property of closure, we formulate it as an inner-level regularized linear regression problem: a binary operator T a b for attribute a in a group minimizes ℓ a b pT q defined as
ℓ a b pT q " ÿ i E " }M pb a o,i qT M pb a o,i<code>1 q´M pb a o,i</code>2 q} 2 F ‰`λ a b }T } 2 F ,(3)
where under visual uncertainty, we take the expectation w.r.t. the distributions in the belief states of context panels P pb a o,i q in the first two rows, and denote its algebraic representation as M pb a o,i q. For unary operators, one operand can be treated as constant and absorbed into T . Note that Eq. (3) admits a closed-form solution (please refer to the Appendix for details). Therefore, the operator can be learned and adapted for different instances of binary relations and concluded on the fly. Such a design also simplifies the recent neuro-symbolic approaches, where every single symbol operator needs to be hand-defined [14,36,66,67]. Instead, we only specify an inner-level optimization framework and allow symbolic operators to be quickly induced based on the neural observations, while keeping the semantic interpretability in the neuro-symbolic methods. Therefore, we term such a design semi-symbolic.</p>
<p>The operator probability in Eq. (1) is then modeled by each operator type's fitness, e.g., for binary,
P pT a " T a b | tI o,i u 8 i"1 q 9 expp´ℓ a b pT a b qq.(4)
Operator Execution To predict the algebraic representation of the answer, we solve another inner-level optimization similar to Eq. (3), but now treating the representation of the answer as a variable:
y M a b " arg min M ℓ a b pM q " Er}M pb a o,7 qT a b M pb a o,8 q´M } 2 F s,(5)
where the expectation is taken w.r.t. context panels in the last row. The optimization also admits a closed-form solution (please refer to the Appendix for details), which corresponds to the execution of the induced operator in Eq. (3). The predicted representation is decoded probabilistically as the predicted belief state of the solution,
P p p b a " k | T a q 9 expp´} y M a´p M a q k M a 0 } 2 F q.(6)
Answer Selection Based on Eqs. (1) and (4), estimating the answer distribution is now boiled down to estimating the conditional answer distributions for each attribute. Here, we propose to model it based on the Jensen-Shannon Divergence (JSD) of the predicted belief state and that of a choice, P py a " n | T a , tI o,i u 8 i"1 , tI c,i u 8 i"1 q 9 expp´d a n q,</p>
<p>where we define d a n as d a n " D JSD pP p p b a | T a q}P pb a c,n qqq.</p>
<p>Discussion Comparing with the possible problem-solving process by humans [4], we argue that the proposed algebraic abstract reasoning module offers a computational and interpretable counterpart to human-like reasoning in RPM. Specifically, the induction component resembles fluid intelligence, where one quickly induces the hidden operator by observing the context panels. The execution component synthesizes an image by executing the induced operator, and the choice most similar to the image is selected as the answer. We also note that by decoding the predicted representation in Eq. (6), a solution can be generated : by sequentially selecting the most probable operator and the most probable attribute value, a rendering engine can directly render the solution. The reasoning backend also enables end-to-end training: by integrating the belief states from neural perception, the module conducts both induction and execution in a soft manner, such that the gradients can be back-propagated and both the visual frontend and the reasoning backend jointly trained.</p>
<p>Training Strategy</p>
<p>We train the entire ALANS learner by minimizing the cross-entropy loss between the estimated answer distribution and the ground-truth selection and an auxiliary loss [51,58,68,71] that shapes the operator distribution from the reasoning engine, i.e.,
min θ,tM a 0 u,tM a u ℓpP py | tI o,i u 8 i"1 , tI c,i u 8 i"1 q, y ‹ q`ÿ a λ a ℓpP pT a | tI o,i u 8 i"1 q, y a ‹ q,(9)
where ℓp¨q denotes the cross-entropy loss, y ‹ the correct choice in candidates, and y a ‹ the ground-truth operator selection for attribute a. The first part of the loss encourages the model to select the right choice for evaluation, while the second part motivates meaningful internal representation to emerge. Compared to Zhang et al . [71], the system requires joint operation from not only a trained perception module θ, but also the algebraic encodings from the zero elements tM a 0 u and the successor functions tM a u, and correspondingly, induced operators T . We notice the three-stage curriculum in Zhang et al . [71] is crucial for such a neuro-semi-symbolic system. In particular, we use λ a to balance the trade-off in the curriculum: in the first stage, we only train parameters regarding objectiveness; in the second stage, we freeze objectiveness parameters and cyclically train parameters involving type, size, and color; in the last stage, we fine-tune all parameters.</p>
<p>Experiments</p>
<p>A cognitive architecture with systematic generalization is believed to demonstrate the following three principles [12,37,38]: (1) systematicity, (2) productivity, and (3) localism. Systematicity requires an architecture to be able to entertain "semantically related" contents after understanding a given thought. Productivity states the awareness of a constituent implies that of a recursive application of the constituent; vice versa for localism.</p>
<p>To verify the effectiveness of an algebraic treatment in systematic generalization, we showcase the superiority of the proposed ALANS learner on the three principles in the abstract spatial-temporal reasoning task of RPM. Specifically, we use the generation methods proposed in Zhang et al . [68] and Hu et al . [21] to generate RPM problems and carefully split training and testing to construct the three regimes. The former generates candidates by perturbing only one attribute of the correct answer while the later modifies attribute values in a hierarchical manner to avoid shortcut solutions by pure statistics. Both methods categorize relations in RPM into three types, according to Carpenter et al . [4]: unary (Constant and Progression), binary (Arithmetic), and ternary (Distribution of Three), each of which comes with several instances. Grounding the principles into learning abstract relations in RPM, we fix the configuration to be 3ˆ3Grid and generate the following data splits for evaluation (please refer to the Appendix for details):</p>
<p>-Systematicity: the training set contains only a subset of instances for each type of relation, while the test set all other relation instances. -Productivity: as the binary relation results from a recursive application of the unary relation, the training set contains only unary relations, whereas the test set only binary relations. -Localism: the training and testing sets in the productivity split are swapped to study localism.</p>
<p>We follow Zhang et al . [68] to generate 10, 000 instances for each split and assign 6 folds for training, 2 folds for validation, and 2 folds for testing.</p>
<p>Experimental Setup</p>
<p>We evaluate the systematic generalizability of the proposed ALANS learner on the above three splits, and compare the ALANS learner with other baselines, including ResNet [16], ResNet+DRT [68], WReN [51], CoPINet [70], MXGNet [58], LEN [74], HriNet [21], and SCL [64]. We use either official or public implementations that reproduce the original results. All models are implemented in Py-Torch [45] and optimized using ADAM [27] on an Nvidia Titan Xp GPU. We validate trained models on validation sets and report performance on test sets.</p>
<p>Systematic Generalization</p>
<p>Tab. 1 shows the performance of various models on systematic generalization, i.e., systematicity, productivity, and localism. Compared to results reported in existing works mentioned above, all pure connectionist models experience a devastating performance drop when it comes to the critical cognitive requirements on systematic generalization, indicating that pure connectionist models fail to perform abstraction, algebraization, induction, or generalization needed in solving the abstract reasoning task; instead, they seem to only take a shortcut to bypass them. In particular, MXGNet's [58] superiority is diminishing in systematic generalization. In spite of learning with structural annotations, ResNet+DRT [68] does not fare better than its base model. The recently proposed HriNet [21] slightly improves on ResNet [16] in this aspect, with LEN [74] being only marginally better. WReN [51], on the other hand, shows oscillating performance across three regimes. Evaluated under systematic generation, SCL [64] and CoPINet [70] also far deviate from "superior performance." These observations suggest that pure connectionist models highly likely learn from variation in visual appearance rather than the algebra underlying the problem. Embedded in a neural-semi-symbolic framework, the proposed ALANS learner improves on systematic generalization by a large margin. With an algebra-aware design, the model is considerably stable across different principles of systematic generalization. The algebraic representation learned in relations of either a constituent or a recursive composition naturally supports productivity and localism, while semi-symbolic inner optimization further allows various instances of an operator type to be induced from the algebraic representation and boosts systematicity. The importance of the algebraic representation is made more significant in the ablation study: ALANS-Ind, with algebraic representation replaced by independent encodings and the algebraic isomorphism broken, shows inferior performance. We also examine the performance of the learner with perfect visual annotations (denoted as ALANS-V) to see how the proposed algebraic reasoning module works: the gap despite of accurate perception indicates space for improvement for the inductive reasoning part of the model. In the next section, we further show that the neuro-semi-symbolic decomposition in ALANS's design enables diagnostic tests into its jointly learned perception module and reasoning module. This design is in stark contrast to black-box models.</p>
<p>Analysis into Perception and Reasoning</p>
<p>The neural-semi-symbolic design affords analyses into both perception and reasoning. To evaluate the neural perception and the algebraic reasoning modules, we extract region-based object attribute annotations from the datasets [21,68] and categorize all relations into three types, i.e., unary, binary, and ternary.</p>
<p>Tab. 2 shows the perception module's performance on the test sets in the three regimes of systematic generalization. We note that in order for the ALANS learner to achieve the desired results shown in Tab. 1, ALANS learns to construct the concept of objectiveness perfectly. The model also shows fairly accurate prediction on the attributes of type and size. However, on the texture-related concept of color, ALANS fails to develop a reliable notion on it. Despite that, the general prediction accuracy of the perception module is still surprising, considering that the perception module is jointly learned with ground-truth annotations on answer selections. The relatively lower accuracy on color could be attributed to its larger space compared to other attributes. Tab. 3 lists the reasoning module's performance during testing for the three aspects. Note that on position, the unary operator (shifting) and binary operator (set arithmetics) do not systematically imply each other. Hence, we do not count them as probes into productivity and localism. In general, we notice that the better the perception accuracy on one attribute, the better the performance on reasoning. However, we also note that despite the relatively accurate perception of objectiveness, type, and size, near perfect reasoning is never guaranteed. This deficiency is due to the perception uncertainty handled by expectation in Eq. (3): in spite of correctness when we take arg max, marginalizing by expectation will unavoidably introduce noise into the reasoning process. Therefore, an ideal reasoning module requires the perception frontend to be not only correct but also certain. Computationally, one can sample from the perception module and optimize Eq. (9) using REINFORCE [60]. However, the credit assignment problem and variance in gradient estimation will further complicate training.</p>
<p>In-Distribution Performance</p>
<p>To further evaluate how models perform under the regular Independent and Identically Distributed (I.I.D.) setup, we train the models on the original datasets generated by Zhang et al . [68] and Hu et al . [21] and measure the model accuracy in the test splits. We compare ALANS with published baselines in Tab. 1.</p>
<p>Tab. 4 (left) shows the results on the RAVEN dataset [68]. With the jointly trained vision component, the ALANS learner does not fare better than the best connectionist approaches, making it on par with SCL only. As the dataset is  known to have shortcut solutions, neural approaches like MXGNet and CoPINet could potentially find it easier to solve and hence achieve much superior results in this setup. However, ALANS-V, the variant with a perfect perception component reaches a level of much robustness and accuracy, attaining the best results in grid-like layouts, empirically believed to be the hardest in human evaluation [68]. Tab. 4 (right) shows the results on the I-RAVEN dataset [21]. Apart from ALANS-V's realizing the best performance across all models, we also notice the consistency of performance of the proposed method across datasets, with or without the shortcut issues. All other methods show drastically varying performance, particularly for CoPINet and MXGNet, arguably because of the choice generation strategy that effectively prunes easy solution paths via statistics.</p>
<p>In summary, by analyzing the results from Tabs. 1 and 4 together, we notice that ALANS not only attains reasonable performance on the I.I.D. setup but also generalizes systematically.</p>
<p>Generative Potential</p>
<p>Compared to existing discriminative-only RPM-solving methods, the proposed ALANS learner is unique in its generative potential. As mentioned above, the final panel attribute can be decoded by sequentially selecting the most probable hidden operator and the attribute value. A solution can be generated when equipped with a rendering engine. In Fig. 3, we use the rendering program from Zhang et al . [68] to showcase the generative potential in the ALANS learner. 7 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h P e q u C A H 3 r I R w 8 J g W V F U m 0 6 h J a w = " &gt; A A A C Z H i c b V B b S 8 M w G M 3 q b c 7 b d P g k S H E I P o 1 2 4 u 1 t 6 I u P C k 6 F d Y w 0 / T b D k r Q k q W 6 E / h Z f 9 S f 5 B / w d p t 0 Q q x 4 I H M 7 5 b j l h w q j S n v d R c R Y W l 5 Z X q q u 1 t f W N z a 3 6 9 s 6 9 i l N J o E t i F s v H E C t g V E B X U 8 3 g M Z G A e c j g I R x f 5 f 7 D M 0 h F Y 3 G n p w n 0 O R 4 J O q Q E a y s N 6 o 2 g m G E k R J k J J h z L c T a o N 7 2 W V 8 D 9 S / w 5 a a I 5 b g b b l Y s g i k n K Q W j C s F I 9 3 0 t 0 3 2 C p K W G Q 1 Y J U Q Y L J G I + g Z 6 n A H F T f F J s z 9 9 A q k T u M p X 1 C u 4 X 6 s 8 N g r t S U h 7 a S Y / 2 k f n u 5 + J / X S / X w v G + o S F I N g s w W D V P m 6 t j N o 3 A j K o F o N r U E E 0 n t r S 5 5 w h I T b Q M r b U l o f l r p H 2 Y y O 7 8 W C H g h M e d Y R C Y g R Y A m i K g Y m R M / y w 7 L / q T k n 1 i / C P s i x + l 3 t H / J f b v l H 7 e O b 9 v N z u U 8 9 i r a Q w f o C P n o D H X Q N b p B X U T Q F L 2 i N / R e + X T W n Y a z O y t 1 K v O e B i r B 2 f 8 C p U a 8 M A = = &lt; / l a t e x i t &gt; 7 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h P e q u C A H 3 r I R w 8 J g W V F U m 0 6 h J a w = " &gt; A A A C Z H i c b V B b S 8 M w G M 3 q b c 7 b d P g k S H E I P o 1 2 4 u 1 t 6 I u P C k 6 F d Y w 0 / T b D k r Q k q W 6 E / h Z f 9 S f 5 B / w d p t 0 Q q x 4 I H M 7 5 b j l h w q j S n v d R c R Y W l 5 Z X q q u 1 t f W N z a 3 6 9 s 6 9 i l N J o E t i F s v H E C t g V E B X U 8 3 g M Z G A e c j g I R x f 5 f 7 D M 0 h F Y 3 G n p w n 0 O R 4 J O q Q E a y s N 6 o 2 g m G E k R J k J J h z L c T a o N 7 2 W V 8 D 9 S / w 5 a a I 5 b g b b l Y s g i k n K Q W j C s F I 9 3 0 t 0 3 2 C p K W G Q 1 Y J U Q Y L J G I + g Z 6 n A H F T f F J s z 9 9 A q k T u M p X 1 C u 4 X 6 s 8 N g r t S U h 7 a S Y / 2 k f n u 5 + J / X S / X w v G + o S F I N g s w W D V P m 6 t j N o 3 A j K o F o N r U E E 0 n t r S 5 5 w h I T b Q M r b U l o f l r p H 2 Y y O 7 8 W C H g h M e d Y R C Y g R Y A m i K g Y m R M / y w 7 L / q T k n 1 i / C P s i x + l 3 t H / J f b v l H 7 e O b 9 v N z u U 8 9 i r a Q w f o C P n o D H X Q N b p B X U T Q F L 2 i N / R e + X T W n Y a z O y t 1 K v O e B i r B 2 f 8 C p U a 8 M A = = &lt; / l a t e x i t &gt; 7 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h P e q u C A H 3 r I R w 8 J g W V F U m 0 6 h J a w = " &gt; A A A C Z H i c b V B b S 8 M w G M 3 q b c 7 b d P g k S H E I P o 1 2 4 u 1 t 6 I u P C k 6 F d Y w 0 / T b D k r Q k q W 6 E / h Z f 9 S f 5 B / w d p t 0 Q q x 4 I H M 7 5 b j l h w q j S n v d R c R Y W l 5 Z X q q u 1 t f W N z a 3 6 9 s 6 9 i l N J o E t i F s v H E C t g V E B X U 8 3 g M Z G A e c j g I R x f 5 f 7 D M 0 h F Y 3 G n p w n 0 O R 4 J O q Q E a y s N 6 o 2 g m G E k R J k J J h z L c T a o N 7 2 W V 8 D 9 S / w 5 a a I 5 b g b b l Y s g i k n K Q W j C s F I 9 3 0 t 0 3 2 C p K W G Q 1 Y J U Q Y L J G I + g Z 6 n A H F T f F J s z 9 9 A q k T u M p X 1 C u 4 X 6 s 8 N g r t S U h 7 a S Y / 2 k f n u 5 + J / X S / X w v G + o S F I N g s w W D V P m 6 t j N o 3 A j K o F o N r U E E 0 n t r S 5 5 w h I T b Q M r b U l o f l r p H 2 Y y O 7 8 W C H g h M e d Y R C Y g R Y A m i K g Y m R M / y w 7 L / q T k n 1 i / C P s i x + l 3 t H / J f b v l H 7 e O b 9 v N z u U 8 9 i r a Q w f o C P n o D H X Q N b p B X U T Q F L 2 i N / R e + X T W n Y a z O y t 1 K v O e B i r B 2 f 8 C p U a 8 M A = = &lt; / l a t e x i t &gt; 7 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h P e q u C A H 3 r I R w 8 J g W V F U m 0 6 h J a w = " &gt; A A A C Z H i c b V B b S 8 M w G M 3 q b c 7 b d P g k S H E I P o 1 2 4 u 1 t 6 I u P C k 6 F d Y w 0 / T b D k r Q k q W 6 E / h Z f 9 S f 5 B / w d p t 0 Q q x 4 I H M 7 5 b j l h w q j S n v d R c R Y W l 5 Z X q q u 1 t f W N z a 3 6 9 s 6 9 i l N J o E t i F s v H E C t g V E B X U 8 3 g M Z G A e c j g I R x f 5 f 7 D M 0 h F Y 3 G n p w n 0 O R 4 J O q Q E a y s N 6 o 2 g m G E k R J k J J h z L c T a o N 7 2 W V 8 D 9 S / w 5 a a I 5 b g b b l Y s g i k n K Q W j C s F I 9 3 0 t 0 3 2 C p K W G Q 1 Y J U Q Y L J G I + g Z 6 n A H F T f F J s z 9 9 A q k T u M p X 1 C u 4 X 6 s 8 N g r t S U h 7 a S Y / 2 k f n u 5 + J / X S / X w v G + o S F I N g s w W D V P m 6 t j N o Ground-truth relations are also listed. Note the generated results do not look exactly the same as the correct candidate choices due to random rotations during rendering, but they are semantically correct.</p>
<p>Conclusion and Limitation</p>
<p>In this work, we propose the ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner, echoing a normative theory in the connectionist-classicist debate that an algebraic treatment in a cognitive architecture should improve a model's systematic generalization ability. In particular, the ALANS learner employs a neural-semi-symbolic architecture, where the neural visual perception module is responsible for summarizing visual information and the algebraic abstract reasoning module transforms it into algebraic representation with isomorphism established by the Peano Axiom and the representation theory, conducts operator induction, and executes it to arrive at an answer. In three RPM domains reflective of systematic generalization, the proposed ALANS learner shows superior performance compared to other pure connectionist baselines. The proposed ALANS learner also bears some limitations. For one thing, we make the assumption in our formulation that relations on different attributes are independent and can be factorized. This assumption is not universally correct and could potentially lead to failure in more complex reasoning scenarios when attributes are correlated. For another, we assume a fixed and known space for each attribute in the perception module, while in the real world the space for one attribute could be dynamically changing. In addition, the reasoning module is sensitive to perception uncertainty as has already been discussed in the experimental results. Besides, the gap between perfection and the status quo in reasoning remains to be filled. In this work, we only show how the hidden operator can be induced with regularized linear regression via the representation theory. However, more elaborate differentiable optimization problems can certainly be incorporated for other problems.</p>
<p>With the limitation in mind, we hope that this preliminary study could inspire more research on incorporating algebraic structures into current connectionist models and help address challenging modeling problems [65,69,73,76].</p>
<p>Fig. 2 .
2Isomorphism between the abstract algebra and the matrixbased representation. In this view, operator induction is now reduced to solving for a matrix.</p>
<p>Fig. 3 .
3Examples of RPM instances with the missing entries filled by solutions directly generated by the ALANS learner.</p>
<p>Table 1 .
1Model performance on different aspects of systematic generalization. The performance is measured by accuracy on the test sets. Results on datasets generated by Zhang et al .[68] (upper) and by Hu et al .[21] (lower).Method 
MXGNet ResNet+DRT ResNet HriNet LEN WReN SCL CoPINet ALANS ALANS-Ind ALANS-V </p>
<p>Systematicity 20.95% 
33.00% 
27.35% 28.05% 40.15% 35.20% 37.35% 59.30% 78.45% 52.70% 
93.85% 
Productivity 30.40% 
27.95% 
27.05% 31.45% 42.30% 56.95% 51.10% 60.00% 79.95% 36.45% 
90.20% 
Localism 
28.80% 
24.90% 
23.05% 29.70% 39.65% 38.70% 47.75% 60.10% 80.50% 59.80% 
95.30% </p>
<p>Average 
26.72% 
28.62% 
25.82% 29.73% 40.70% 43.62% 45.40% 59.80% 79.63% 48.65% 
93.12% </p>
<p>Systematicity 13.35% 
13.50% 
14.20% 21.00% 17.40% 15.00% 24.90% 18.35% 64.80% 52.80% 
84.85% 
Productivity 14.10% 
16.10% 
20.70% 20.35% 19.70% 17.95% 22.20% 29.10% 65.55% 32.10% 
86.55% 
Localism 
15.80% 
13.85% 
17.45% 24.60% 20.15% 19.70% 29.95% 31.85% 65.90% 50.70% 
90.95% </p>
<p>Average 
14.42% 
14.48% 
17.45% 21.98% 19.08% 17.55% 25.68% 26.43% 65.42% 45.20% 
87.45% </p>
<p>Table 2 .
2Perception accuracy of the proposed ALANS learner, measured by whether the module can correctly predict an attribute's value. Results on datasets generated by Zhang et al .[68] (left) and by Hu et al .[21] (right).Object Attribute Objectiveness Type Size Color </p>
<p>Systematicity 
100.00% 
99.95% 94.65% 71.35% 
Productivity 
100.00% 
99.97% 98.04% 77.61% 
Localism 
100.00% 
95.65% 98.56% 80.05% </p>
<p>Average 
100.00% 
98.52% 97.08% 76.34% </p>
<p>Object Attribute Objectiveness Type Size Color </p>
<p>Systematicity 
100.00% 
96.34% 92.36% 63.98% 
Productivity 
100.00% 
94.28% 97.00% 69.89% 
Localism 
100.00% 
95.80% 98.36% 60.35% </p>
<p>Average 
100.00% 
95.47% 95.91% 64.74% </p>
<p>Table 3 .
3Reasoning accuracy of the proposed ALANS learner, measured by whether the module can correctly predict the type of a relation on an attribute. Results on datasets generated by Zhang et al .[68] (left) and by Hu et al .[21] (right).Relation on Position Number Type Size Color </p>
<p>Systematicity 72.04% 82.14% 81.50% 80.80% 40.40% 
Productivity 
-
98.75% 89.50% 72.10% 33.95% 
Localism 
-
74.70% 44.25% 56.40% 54.20% </p>
<p>Average 
72.04% 85.20% 71.75% 69.77% 42.85% </p>
<p>Relation on Position Number Type Size Color </p>
<p>Systematicity 69.96% 80.34% 83.50% 80.85% 28.85% 
Productivity 
-
99.10% 87.95% 68.50% 23.10% 
Localism 
-
70.55% 36.65% 42.30% 33.20% </p>
<p>Average 
69.96% 83.33% 69.37% 63.88% 28.38% </p>
<p>Table 4 .
46%{20.7% 58.1%{24.2% 46.5%{18.2% 50.4%{19.8% 65.8%{22.0% 67.1%{22.1% 69.1%{21.0% 60.1%{18.Model performance on RAVEN [68] (left) and I-RAVEN [21] (right) 
under the regular I.I.D. evaluation, measured by accuracy on the test sets. </p>
<p>Method 
Acc 
Center 
2x2Grid 
3x3Grid 
L-R 
U-D 
O-IC 
O-IG </p>
<p>WReN 
34.0%{21.5% 58.4%{24.0% 38.9%{25.0% 37.7%{20.1% 21.6%{19.7% 19.8%{19.9% 38.9%{21.3% 22.6%{20.6% 
ResNet 
53.4%{18.4% 52.8%{22.6% 41.9%{15.5% 44.3%{18.1% 58.8%{19.0% 60.2%{19.6% 63.2%{17.5% 53.1%{16.6% 
ResNet+DRT 59.1% 
LEN 
71.6%{32.8% 79.1%{44.8% 56.1%{27.9% 60.3%{23.9% 80.5%{34.1% 76.4%{34.4% 79.3%{35.8% 69.9%{28.5% 
HriNet 
45.1%{60.8% 66.1%{78.2% 40.7%{50.1% 38.0%{42.4% 44.9%{70.1% 43.2%{70.3% 47.2%{68.2% 35.8%{46.3% 
MXGNet 
84.0%{33.1% 94.3%{40.7% 60.5%{27.9% 64.9%{24.7% 96.6%{35.8% 96.4%{34.5% 94.1%{36.4% 81.3%{31.6% 
CoPINet 
91.4%{46.1% 95.1%{54.4% 77.5%{36.8% 78.9%{31.9% 99.1%{51.9% 99.7%{52.5% 98.5%{52.2% 91.4%{42.8% 
ALANS 
74.4%{78.5% 69.1%{72.3% 80.2%{79.5% 75.0%{72.9% 72.2%{79.2% 73.3%{79.6% 76.3%{85.9% 74.9%{79.9% 
SCL 
74.2%{80.5% 82.8%{84.6% 70.4%{79.4% 64.1%{69.9% 77.6%{82.7% 78.4%{82.6% 84.2%{87.3% 62.2%{77.2% 
ALANS-V 
94.4%{93.5% 98.4%{98.9% 91.5%{85.0% 87.0%{83.2% 97.3%{90.9% 96.4%{98.1% 97.3%{99.1% 93.2%{89.5% </p>
<p>Acknowledgement We thank Prof. Hongjing Lu and colleagues from UCLA for fruitful discussions. We would also like to thank anonymous reviewers for constructive feedback.
The confessions. Clark (1876). S Augustine, Augustine, S.: The confessions. Clark (1876)</p>
<p>Systematic generalization: What is required and can it be learned?. D Bahdanau, S Murty, M Noukhovitch, T H Nguyen, H D Vries, A Courville, International Conference on Learning Representations (ICLR. Bahdanau, D., Murty, S., Noukhovitch, M., Nguyen, T.H., Vries, H.d., Courville, A.: Systematic generalization: What is required and can it be learned? In: Inter- national Conference on Learning Representations (ICLR) (2019)</p>
<p>J F Bard, Practical bilevel optimization: algorithms and applications. Springer Science &amp; Business Media30Bard, J.F.: Practical bilevel optimization: algorithms and applications, vol. 30. Springer Science &amp; Business Media (2013)</p>
<p>What one intelligence test measures: a theoretical account of the processing in the raven progressive matrices test. P A Carpenter, M A Just, P Shell, Psychological Review. 973404Carpenter, P.A., Just, M.A., Shell, P.: What one intelligence test measures: a theoretical account of the processing in the raven progressive matrices test. Psy- chological Review 97(3), 404 (1990)</p>
<p>Compositional generalization via neural-symbolic stack machines. X Chen, C Liang, A W Yu, D Song, D Zhou, Advances in Neural Information Processing Systems. Chen, X., Liang, C., Yu, A.W., Song, D., Zhou, D.: Compositional generalization via neural-symbolic stack machines. In: Advances in Neural Information Processing Systems (2020)</p>
<p>Grounding physical concepts of objects and events through dynamic visual reasoning. Z Chen, J Mao, J Wu, K Y K Wong, J B Tenenbaum, C Gan, International Conference on Learning Representations (ICLR. Chen, Z., Mao, J., Wu, J., Wong, K.Y.K., Tenenbaum, J.B., Gan, C.: Grounding physical concepts of objects and events through dynamic visual reasoning. In: International Conference on Learning Representations (ICLR) (2020)</p>
<p>The measure of intelligence. F Chollet, arXiv:1911.01547arXiv preprintChollet, F.: The measure of intelligence. arXiv preprint arXiv:1911.01547 (2019)</p>
<p>An overview of bilevel optimization. B Colson, P Marcotte, G Savard, Annals of Operations Research. 1531Colson, B., Marcotte, P., Savard, G.: An overview of bilevel optimization. Annals of Operations Research 153(1), 235-256 (2007)</p>
<p>Neural logic machines. H Dong, J Mao, T Lin, C Wang, L Li, D Zhou, International Conference on Learning Representations (ICLR). Dong, H., Mao, J., Lin, T., Wang, C., Li, L., Zhou, D.: Neural logic machines. In: International Conference on Learning Representations (ICLR) (2018)</p>
<p>Learning explanatory rules from noisy data. R Evans, E Grefenstette, Journal of Artificial Intelligence Research (JAIR). 61Evans, R., Grefenstette, E.: Learning explanatory rules from noisy data. Journal of Artificial Intelligence Research (JAIR) 61, 1-64 (2018)</p>
<p>J A Fodor, The language of thought. Harvard university press5Fodor, J.A.: The language of thought, vol. 5. Harvard university press (1975)</p>
<p>Connectionism and cognitive architecture: A critical analysis. J A Fodor, Z W Pylyshyn, Cognition. 281-2Fodor, J.A., Pylyshyn, Z.W., et al.: Connectionism and cognitive architecture: A critical analysis. Cognition 28(1-2), 3-71 (1988)</p>
<p>Neural-symbolic learning systems: foundations and applications. A S D Garcez, K B Broda, D M Gabbay, Springer Science &amp; Business MediaGarcez, A.S.d., Broda, K.B., Gabbay, D.M.: Neural-symbolic learning systems: foundations and applications. Springer Science &amp; Business Media (2012)</p>
<p>Visual concept-metaconcept learning. C Han, J Mao, C Gan, J Tenenbaum, J Wu, Advances in Neural Information Processing Systems (NeurIPS). Han, C., Mao, J., Gan, C., Tenenbaum, J., Wu, J.: Visual concept-metaconcept learning. In: Advances in Neural Information Processing Systems (NeurIPS) (2019)</p>
<p>Theory of quasi-groups. B A Hausmann, O Ore, American Journal of Mathematics. 594Hausmann, B.A., Ore, O.: Theory of quasi-groups. American Journal of Mathe- matics 59(4), 983-1004 (1937)</p>
<p>Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Conference on Computer Vision and Pattern Recognition (CVPR). He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2016)</p>
<p>The thirteen books of Euclid's Elements. T L Heath, Courier Corporation. Heath, T.L., et al.: The thirteen books of Euclid's Elements. Courier Corporation (1956)</p>
<p>Learning to make analogies by contrasting abstract relational structure. F Hill, A Santoro, D G Barrett, A S Morcos, T Lillicrap, International Conference on Learning Representations (ICLR. Hill, F., Santoro, A., Barrett, D.G., Morcos, A.S., Lillicrap, T.: Learning to make analogies by contrasting abstract relational structure. In: International Conference on Learning Representations (ICLR) (2019)</p>
<p>Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought. D R Hofstadter, Basic books. Hofstadter, D.R.: Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought. Basic books (1995)</p>
<p>From semantic vectors to analogical mapping. K J Holyoak, N Ichien, H Lu, Current Directions in Psychological Science p. 09637214221098054Holyoak, K.J., Ichien, N., Lu, H.: From semantic vectors to analogical mapping. Current Directions in Psychological Science p. 09637214221098054 (2022)</p>
<p>S Hu, Y Ma, X Liu, Y Wei, S Bai, arXiv:2002.06838Hierarchical rule induction network for abstract visual reasoning. arXiv preprintHu, S., Ma, Y., Liu, X., Wei, Y., Bai, S.: Hierarchical rule induction network for abstract visual reasoning. arXiv preprint arXiv:2002.06838 (2020)</p>
<p>Learning by abstraction: The neural state machine. D Hudson, C D Manning, Advances in Neural Information Processing Systems. Hudson, D., Manning, C.D.: Learning by abstraction: The neural state machine. In: Advances in Neural Information Processing Systems (2019)</p>
<p>J E Humphreys, Introduction to Lie algebras and representation theory. Springer Science &amp; Business Media9Humphreys, J.E.: Introduction to Lie algebras and representation theory, vol. 9. Springer Science &amp; Business Media (2012)</p>
<p>Improving fluid intelligence with training on working memory. S M Jaeggi, M Buschkuehl, J Jonides, W J Perrig, Proceedings of the National Academy of Sciences. 19PNASJaeggi, S.M., Buschkuehl, M., Jonides, J., Perrig, W.J.: Improving fluid intelligence with training on working memory. Proceedings of the National Academy of Sciences (PNAS) 105(19), 6829-6833 (2008)</p>
<p>The Principles of Psychology. W James, Henry Holt and CompanyJames, W.: The Principles of Psychology. Henry Holt and Company (1891)</p>
<p>Schema networks: Zero-shot transfer with a generative causal model of intuitive physics. K Kansky, T Silver, D A Mély, M Eldawy, M Lázaro-Gredilla, X Lou, N Dorfman, S Sidor, S Phoenix, D George, International Conference on Machine Learning (ICML. Kansky, K., Silver, T., Mély, D.A., Eldawy, M., Lázaro-Gredilla, M., Lou, X., Dorf- man, N., Sidor, S., Phoenix, S., George, D.: Schema networks: Zero-shot transfer with a generative causal model of intuitive physics. In: International Conference on Machine Learning (ICML) (2017)</p>
<p>Adam: A method for stochastic optimization. D P Kingma, J Ba, International Conference on Learning Representations (ICLR. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: Interna- tional Conference on Learning Representations (ICLR) (2014)</p>
<p>D P Kingma, M Welling, arXiv:1312.6114Auto-encoding variational bayes. arXiv preprintKingma, D.P., Welling, M.: Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013)</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. B Lake, M Baroni, International Conference on Machine Learning (ICML). Lake, B., Baroni, M.: Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In: International Conference on Machine Learning (ICML) (2018)</p>
<p>A bayesian model of rule induction in raven's progressive matrices. D R Little, S Lewandowsky, T L Griffiths, Annual Meeting of the Cognitive Science Society (CogSci). Little, D.R., Lewandowsky, S., Griffiths, T.L.: A bayesian model of rule induction in raven's progressive matrices. In: Annual Meeting of the Cognitive Science Society (CogSci) (2012)</p>
<p>Modeling visual problem solving as analogical reasoning. A Lovett, K Forbus, Psychological Review. 124160Lovett, A., Forbus, K.: Modeling visual problem solving as analogical reasoning. Psychological Review 124(1), 60 (2017)</p>
<p>A structure-mapping model of raven's progressive matrices. A Lovett, K Forbus, J Usher, Annual Meeting of the Cognitive Science Society (CogSci). Lovett, A., Forbus, K., Usher, J.: A structure-mapping model of raven's progressive matrices. In: Annual Meeting of the Cognitive Science Society (CogSci) (2010)</p>
<p>Solving geometric analogy problems through two-stage analogical mapping. A Lovett, E Tomai, K Forbus, J Usher, Cognitive Science. 337Lovett, A., Tomai, E., Forbus, K., Usher, J.: Solving geometric analogy problems through two-stage analogical mapping. Cognitive Science 33(7), 1192-1231 (2009)</p>
<p>Believing the axioms. i. P Maddy, The Journal of Symbolic Logic. 532Maddy, P.: Believing the axioms. i. The Journal of Symbolic Logic 53(2), 481-511 (1988)</p>
<p>Deepproblog: Neural probabilistic logic programming. R Manhaeve, S Dumancic, A Kimmig, T Demeester, L De Raedt, Advances in Neural Information Processing Systems (NeurIPS). Manhaeve, R., Dumancic, S., Kimmig, A., Demeester, T., De Raedt, L.: Deep- problog: Neural probabilistic logic programming. In: Advances in Neural Informa- tion Processing Systems (NeurIPS) (2018)</p>
<p>The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. J Mao, C Gan, P Kohli, J B Tenenbaum, J Wu, International Conference on Learning Representations (ICLR. Mao, J., Gan, C., Kohli, P., Tenenbaum, J.B., Wu, J.: The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. In: International Conference on Learning Representations (ICLR) (2019)</p>
<p>The algebraic mind. G Marcus, MIT PressCambridge, MAMarcus, G.: The algebraic mind. Cambridge, MA: MIT Press (2001)</p>
<p>G Marcus, arXiv:2002.06177The next decade in ai: four steps towards robust artificial intelligence. arXiv preprintMarcus, G.: The next decade in ai: four steps towards robust artificial intelligence. arXiv preprint arXiv:2002.06177 (2020)</p>
<p>Rule learning by seven-monthold infants. G F Marcus, S Vijayan, S B Rao, P M Vishton, Science. 2835398Marcus, G.F., Vijayan, S., Rao, S.B., Vishton, P.M.: Rule learning by seven-month- old infants. Science 283(5398), 77-80 (1999)</p>
<p>Programs with common sense. RLE and MIT computation center. J Mccarthy, McCarthy, J.: Programs with common sense. RLE and MIT computation center (1960)</p>
<p>Confident reasoning on raven's progressive matrices tests. K Mcgreggor, A Goel, AAAI Conference on Artificial Intelligence (AAAI). McGreggor, K., Goel, A.: Confident reasoning on raven's progressive matrices tests. In: AAAI Conference on Artificial Intelligence (AAAI) (2014)</p>
<p>K Mcgreggor, M Kunda, A Goel, Fractals and ravens. 215McGreggor, K., Kunda, M., Goel, A.: Fractals and ravens. Artificial Intelligence 215, 1-23 (2014)</p>
<p>Similarity-based reasoning, raven's matrices, and general intelligence. C S Mekik, R Sun, D Y Dai, International Joint Conference on Artificial Intelligence (IJCAI). Mekik, C.S., Sun, R., Dai, D.Y.: Similarity-based reasoning, raven's matrices, and general intelligence. In: International Joint Conference on Artificial Intelligence (IJCAI) (2018)</p>
<p>Physical symbol systems. A Newell, Cognitive Science. 42Newell, A.: Physical symbol systems. Cognitive Science 4(2), 135-183 (1980)</p>
<p>Automatic differentiation in PyTorch. A Paszke, S Gross, S Chintala, G Chanan, E Yang, Z Devito, Z Lin, A Desmaison, L Antiga, A Lerer, NIPS Autodiff Workshop. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in PyTorch. In: NIPS Autodiff Workshop (2017)</p>
<p>Arithmetices principia: Nova methodo exposita. G Peano, Fratres BoccaPeano, G.: Arithmetices principia: Nova methodo exposita. Fratres Bocca (1889)</p>
<p>Dynamic inference with neural interpreters. N Rahaman, M W Gondal, S Joshi, P Gehler, Y Bengio, F Locatello, B Schölkopf, Advances in Neural Information Processing Systems (NeurIPS). Rahaman, N., Gondal, M.W., Joshi, S., Gehler, P., Bengio, Y., Locatello, F., Schölkopf, B.: Dynamic inference with neural interpreters. Advances in Neural Information Processing Systems (NeurIPS) (2021)</p>
<p>Mental tests used in genetic studies: The performance of related individuals on tests mainly educative and mainly reproductive. J C Raven, University of LondonMaster's thesisRaven, J.C.: Mental tests used in genetic studies: The performance of related in- dividuals on tests mainly educative and mainly reproductive. Master's thesis, Uni- versity of London (1936)</p>
<p>Raven's progressive matrices and vocabulary scales. J C Raven, J H Court, Oxford pyschologists PressRaven, J.C., Court, J.H.: Raven's progressive matrices and vocabulary scales. Ox- ford pyschologists Press (1998)</p>
<p>End-to-end differentiable proving. T Rocktäschel, S Riedel, Advances in Neural Information Processing Systems (NeurIPS. Rocktäschel, T., Riedel, S.: End-to-end differentiable proving. In: Advances in Neu- ral Information Processing Systems (NeurIPS) (2017)</p>
<p>Measuring abstract reasoning in neural networks. A Santoro, F Hill, D Barrett, A Morcos, T Lillicrap, International Conference on Machine Learning (ICML). Santoro, A., Hill, F., Barrett, D., Morcos, A., Lillicrap, T.: Measuring abstract reasoning in neural networks. In: International Conference on Machine Learning (ICML) (2018)</p>
<p>A simple neural network module for relational reasoning. A Santoro, D Raposo, D G Barrett, M Malinowski, R Pascanu, P Battaglia, T Lillicrap, Advances in Neural Information Processing Systems (NeurIPS. Santoro, A., Raposo, D., Barrett, D.G., Malinowski, M., Pascanu, R., Battaglia, P., Lillicrap, T.: A simple neural network module for relational reasoning. In: Advances in Neural Information Processing Systems (NeurIPS) (2017)</p>
<p>L Serafini, A D Garcez, arXiv:1606.04422Logic tensor networks: Deep learning and logical reasoning from data and knowledge. arXiv preprintSerafini, L., Garcez, A.d.: Logic tensor networks: Deep learning and logical reason- ing from data and knowledge. arXiv preprint arXiv:1606.04422 (2016)</p>
<p>The structural affinity method for solving the raven's progressive matrices test for intelligence. S Shegheva, A Goel, AAAI Conference on Artificial Intelligence (AAAI). Shegheva, S., Goel, A.: The structural affinity method for solving the raven's pro- gressive matrices test for intelligence. In: AAAI Conference on Artificial Intelligence (AAAI) (2018)</p>
<p>The nature of "intelligence" and the principles of cognition. C Spearman, MacmillanSpearman, C.: The nature of "intelligence" and the principles of cognition. Macmil- lan (1923)</p>
<p>The abilities of man. C Spearman, Macmillan6New YorkSpearman, C.: The abilities of man, vol. 6. Macmillan New York (1927)</p>
<p>Improving generalization for abstract reasoning tasks using disentangled feature representations. X Steenbrugge, S Leroux, T Verbelen, B Dhoedt, arXiv:1811.04784arXiv preprintSteenbrugge, X., Leroux, S., Verbelen, T., Dhoedt, B.: Improving generalization for abstract reasoning tasks using disentangled feature representations. arXiv preprint arXiv:1811.04784 (2018)</p>
<p>Abstract diagrammatic reasoning with multiplex graph networks. D Wang, M Jamnik, P Lio, International Conference on Learning Representations (ICLR. Wang, D., Jamnik, M., Lio, P.: Abstract diagrammatic reasoning with multiplex graph networks. In: International Conference on Learning Representations (ICLR) (2020)</p>
<p>Automatic generation of raven's progressive matrices. K Wang, Z Su, International Joint Conference on Artificial Intelligence (IJCAI. Wang, K., Su, Z.: Automatic generation of raven's progressive matrices. In: Inter- national Joint Conference on Artificial Intelligence (IJCAI) (2015)</p>
<p>Simple statistical gradient-following algorithms for connectionist reinforcement learning. R J Williams, Machine Learning. 83-4Williams, R.J.: Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning 8(3-4), 229-256 (1992)</p>
<p>Procedures as a representation for data in a computer program for understanding natural language. T Winograd, Tech. rep., MIT. Cent. Space Res. Winograd, T.: Procedures as a representation for data in a computer program for understanding natural language. Tech. rep., MIT. Cent. Space Res. (1971)</p>
<p>Philosophical investigations. Philosophische Untersuchungen. L Wittgenstein, MacmillanWittgenstein, L.: Philosophical investigations. Philosophische Untersuchungen. Macmillan (1953)</p>
<p>Neural scene de-rendering. J Wu, J B Tenenbaum, P Kohli, Conference on Computer Vision and Pattern Recognition (CVPR. Wu, J., Tenenbaum, J.B., Kohli, P.: Neural scene de-rendering. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2017)</p>
<p>Y Wu, H Dong, R Grosse, J Ba, arXiv:2007.04212The scattering compositional learner: Discovering objects, attributes, relationships in analogical reasoning. arXiv preprintWu, Y., Dong, H., Grosse, R., Ba, J.: The scattering compositional learner: Dis- covering objects, attributes, relationships in analogical reasoning. arXiv preprint arXiv:2007.04212 (2020)</p>
<p>M Xu, G Jiang, C Zhang, S C Zhu, Y Zhu, arXiv:2206.09203Est: Evaluating scientific thinking in artificial agents. arXiv preprintXu, M., Jiang, G., Zhang, C., Zhu, S.C., Zhu, Y.: Est: Evaluating scientific thinking in artificial agents. arXiv preprint arXiv:2206.09203 (2022)</p>
<p>Clevrer: Collision events for video representation and reasoning. K Yi, C Gan, Y Li, P Kohli, J Wu, A Torralba, J Tenenbaum, International Conference on Learning Representations (ICLR. Yi, K., Gan, C., Li, Y., Kohli, P., Wu, J., Torralba, A., Tenenbaum, J.: Clevrer: Collision events for video representation and reasoning. In: International Confer- ence on Learning Representations (ICLR) (2020)</p>
<p>Neural-symbolic vqa: Disentangling reasoning from vision and language understanding. K Yi, J Wu, C Gan, A Torralba, P Kohli, J Tenenbaum, Advances in Neural Information Processing Systems (NeurIPS). Yi, K., Wu, J., Gan, C., Torralba, A., Kohli, P., Tenenbaum, J.: Neural-symbolic vqa: Disentangling reasoning from vision and language understanding. In: Ad- vances in Neural Information Processing Systems (NeurIPS) (2018)</p>
<p>Raven: A dataset for relational and analogical visual reasoning. C Zhang, F Gao, B Jia, Y Zhu, S C Zhu, Conference on Computer Vision and Pattern Recognition (CVPR). Zhang, C., Gao, F., Jia, B., Zhu, Y., Zhu, S.C.: Raven: A dataset for relational and analogical visual reasoning. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2019)</p>
<p>Acre: Abstract causal reasoning beyond covariation. C Zhang, B Jia, M Edmonds, S C Zhu, Y Zhu, Conference on Computer Vision and Pattern Recognition (CVPR). Zhang, C., Jia, B., Edmonds, M., Zhu, S.C., Zhu, Y.: Acre: Abstract causal reason- ing beyond covariation. In: Conference on Computer Vision and Pattern Recogni- tion (CVPR) (2021)</p>
<p>Learning perceptual inference by contrasting. C Zhang, B Jia, F Gao, Y Zhu, H Lu, S C Zhu, Advances in Neural Information Processing Systems (NeurIPS). Zhang, C., Jia, B., Gao, F., Zhu, Y., Lu, H., Zhu, S.C.: Learning perceptual in- ference by contrasting. In: Advances in Neural Information Processing Systems (NeurIPS) (2019)</p>
<p>Abstract spatial-temporal reasoning via probabilistic abduction and execution. C Zhang, B Jia, S C Zhu, Y Zhu, Conference on Computer Vision and Pattern Recognition (CVPR). Zhang, C., Jia, B., Zhu, S.C., Zhu, Y.: Abstract spatial-temporal reasoning via probabilistic abduction and execution. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2021)</p>
<p>Metastyle: Three-way trade-off among speed, flexibility, and quality in neural style transfer. C Zhang, Y Zhu, S C Zhu, AAAI Conference on Artificial Intelligence (AAAI). Zhang, C., Zhu, Y., Zhu, S.C.: Metastyle: Three-way trade-off among speed, flex- ibility, and quality in neural style transfer. In: AAAI Conference on Artificial In- telligence (AAAI) (2019)</p>
<p>Machine number sense: A dataset of visual arithmetic problems for abstract and relational reasoning. W Zhang, C Zhang, Y Zhu, S C Zhu, AAAI Conference on Artificial Intelligence (AAAI). Zhang, W., Zhang, C., Zhu, Y., Zhu, S.C.: Machine number sense: A dataset of visual arithmetic problems for abstract and relational reasoning. In: AAAI Con- ference on Artificial Intelligence (AAAI) (2020)</p>
<p>Abstract reasoning with distracting features. K Zheng, Z J Zha, W Wei, Advances in Neural Information Processing Systems (NeurIPS). Zheng, K., Zha, Z.J., Wei, W.: Abstract reasoning with distracting features. In: Advances in Neural Information Processing Systems (NeurIPS) (2019)</p>
<p>A stochastic grammar of images. S C Zhu, D Mumford, Foundations and Trends® in Computer Graphics and Vision. 24Zhu, S.C., Mumford, D., et al.: A stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision 2(4), 259-362 (2007)</p>
<p>Dark, beyond deep: A paradigm shift to cognitive ai with humanlike common sense. Y Zhu, T Gao, L Fan, S Huang, M Edmonds, H Liu, F Gao, C Zhang, S Qi, Y N Wu, Engineering. 63Zhu, Y., Gao, T., Fan, L., Huang, S., Edmonds, M., Liu, H., Gao, F., Zhang, C., Qi, S., Wu, Y.N., et al.: Dark, beyond deep: A paradigm shift to cognitive ai with humanlike common sense. Engineering 6(3), 310-345 (2020)</p>            </div>
        </div>

    </div>
</body>
</html>