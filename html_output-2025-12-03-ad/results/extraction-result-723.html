<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-723 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-723</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-723</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-249210097</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2205.15638v4.pdf" target="_blank">Differentiable Invariant Causal Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Learning causal structure from observational data is a fundamental challenge in machine learning. However, the majority of commonly used differentiable causal discovery methods are non-identifiable, turning this problem into a continuous optimization task prone to data biases. In many real-life situations, data is collected from different environments, in which the functional relations remain consistent across environments, while the distribution of additive noises may vary. This paper proposes Differentiable Invariant Causal Discovery (DICD), utilizing the multi-environment information based on a differentiable framework to avoid learning spurious edges and wrong causal directions. Specifically, DICD aims to discover the environment-invariant causation while removing the environment-dependent correlation. We further formulate the constraint that enforces the target structure equation model to maintain optimal across the environments. Theoretical guarantees for the identifiability of proposed DICD are provided under mild conditions with enough environments. Extensive experiments on synthetic and real-world datasets verify that DICD outperforms state-of-the-art causal discovery methods up to 36% in SHD. Our code will be open-sourced.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e723.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e723.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DICD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable Invariant Causal Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable causal discovery algorithm that uses multi-environment data and an invariant-learning-inspired penalty to prefer DAG structures whose structural equation models (SEM) are optimal and stable across environments, thereby rejecting spurious edges that vary with environment noise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DICD</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>DICD learns a DAG by combining the continuous-score/DAG-constraint framework (NOTEARS style) with an invariant-optimality penalty across environments. It represents structure via a structure matrix S (or directly via AS = S • A / f_S for nonlinear) and fits SEM parameters per the DAG. To enforce environment-invariance it adds a differentiable penalty derived from the first-order optimality condition: the squared norm of the gradient of the per-environment loss w.r.t. an inserted scaling matrix B evaluated at B=1 (linear: ||∂L_e(A_S • B)/∂B|_{B=1}||_2^2; nonlinear: analogous term on the MLP first-layer parameters). This penalizes edges whose optimal coefficients vary across environments, encouraging selection of edges with invariant coefficients. Training also enforces acyclicity via standard continuous constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic multi-environment datasets and ColoredMNIST (multi-environment partitioning)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interactive, simulated multi-environment datasets: linear and nonlinear SEMs where environments differ by additive-noise variances (simulated 'environment variables' connected to selected nodes and later removed to create hidden distractors). Also a ColoredMNIST dataset partitioned into color/noise environments; environments are pre-specified (not actively chosen).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects and removes spurious/ distractor-induced edges by testing parameter stability across environments and penalizing instability via a differentiable first-order optimality penalty; effectively performs variable/edge selection by downweighting edges with environment-dependent coefficients.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious correlations induced by environment-dependent additive noise, hidden environment (distractor) variables connected to observed nodes (selection/annotation biases), over-reconstruction shortcuts (incorrect edge directions that exploit correlation).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Identifies spurious edges by instability of estimated SEM coefficients across environments: if coefficient estimates change between environments, the edge is penalized; operationalized by the gradient-of-loss w.r.t. an inserted scaling matrix B evaluated at B=1 (the necessary optimality condition).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Adds a penalty term (lambda * sum_e ||∂L_e(...)/∂B|_{B=1}||_2^2) to the training objective so that edges whose inclusion causes environment-dependent optimal coefficients are discouraged; structure is recovered from the learned AS or f_S.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Refutes spurious edges by showing they lead to inconsistent optimal SEM parameters across environments and therefore higher penalized objective; theoretical identifiability results show the ground-truth graph minimizes total (penalized) reconstruction loss across sufficiently diverse environments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Substantially improved: e.g., linear ER graph with 10 nodes: SHD 4.9 (DICD) vs 10.1 (NOTEARS); overall reported up to 36% relative improvement in SHD (10-node ER case). Nonlinear ER 10-node: SHD 19.2 (DICD) vs 23.8 (NOTEARS-MLP); up to 29% improvement reported in some nonlinear settings.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines operating under ERM (no invariant penalty) such as NOTEARS / NOTEARS-MLP show higher SHD, higher FDR or lower TPR in many settings (e.g., NOTEARS SHD 10.1 vs DICD 4.9 on ER 10-node linear). Exact table entries reported across settings in paper (see Tables 2,4,6,7).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td>Simulated by 0.3*d environment variables in linear experiments and 0.5*d in nonlinear experiments (these environment nodes are removed from observed data to create hidden distractors).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using multi-environment information and enforcing parameter optimality/invariance across environments successfully mitigates over-reconstruction and spurious edges: DICD lowers FDR, raises TPR, and reduces SHD versus popular differentiable baselines. The method is computationally efficient versus some constraint-based multi-environment methods (e.g., CD-NOD) and has theoretical identifiability guarantees in linear Gaussian SEMs when environments are sufficiently diverse.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e723.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e723.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NOTEARS (Continuous optimization for DAG learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable score-based causal discovery method that formulates DAG learning as continuous optimization with a smooth acyclicity constraint, typically minimizing reconstruction loss under the DAG constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Forms SEM as linear (X A) and uses a continuous acyclicity constraint (trace(exp(W ∘ W)) - d = 0) on the weighted adjacency matrix; optimizes reconstruction loss (ERM) plus sparsity regularization via gradient-based solvers to obtain a DAG. In nonlinear cases, NOTEARS-MLP extends this idea to neural nets by constraining the first layer.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Concatenated datasets from all environments (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>ERM-trained on pooled observations without explicit multi-environment invariant penalty; environments can be concatenated but not used to enforce invariance.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Prone to capturing spurious correlations induced by hidden distractors, selection/annotation biases and noise heterogeneity because it optimizes pooled reconstruction loss (ERM).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline ERM performance reported in paper (example: linear ER 10-node: SHD 10.1, FDR 0.07, TPR 0.78; NOTEARS often shows higher SHD or FDR than DICD).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ERM-based differentiable methods like NOTEARS can overfit spurious correlations and produce incorrect edge directions (over-reconstruction); pooling environments without invariance constraints can therefore produce sub-optimal DAGs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e723.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e723.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NOTEARS-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NOTEARS-MLP (nonlinear extension of NOTEARS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Nonlinear differentiable causal discovery method using MLPs to model structural functions and a continuous acyclicity constraint applied to the first MLP layer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>NOTEARS-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Approximates SEM functions with multilayer perceptrons for nonlinear causal relations and enforces DAG constraint by constraining the first-layer weights (columns) to reflect adjacency; optimizes ERM reconstruction loss plus regularizers under continuous DAG constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Concatenated datasets from all environments (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same pooled/non-interventional setting as NOTEARS but modeling nonlinear SEMs; environments are concatenated for baseline training.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Prone to spurious correlations in nonlinear regimes; can miss true causal correlations or produce over-reconstruction.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Reported in nonlinear experiments (e.g., ER 10-node nonlinear: SHD 23.8 vs DICD 19.2; NOTEARS-MLP often worse than DICD in SHD and TPR).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>As a nonlinear ERM baseline, NOTEARS-MLP can be outperformed by invariant approaches (DICD) that use multi-environment constraints to reject spurious edges.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e723.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e723.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CD-NOD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CD-NOD (Causal Discovery from heterogeneous/nonstationary data)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A constraint-based causal discovery approach that leverages independent changes across environments to orient edges and exploit heterogeneity to detect causal directions and reject spurious relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal discovery from heterogeneous/nonstationary data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CD-NOD</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A constraint-based method tailored for heterogeneous datasets: detects independence/changes in distributions across environments and uses constrained tests and kernel methods to orient edges and identify causal structures by leveraging environment-induced distribution shifts; designed to exploit independent changes for orientation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Heterogeneous/multi-environment datasets (requires environment labels)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Designed specifically to operate when environment partitions are known and the distributional changes across them can be used to identify causal directions; not interactive/active experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Uses tests for independent changes across environments (distributional shifts) and constraint-based orientation rules; kernel-based tests to detect nonstationarity tied to specific variables (effectively identifies variables affected by environment/distractors).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Heterogeneous additive noise, nonstationarity, environment-specific distribution shifts that induce spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Statistical independence/change detection across environments (including kernel-based tests) to find which conditional distributions change and thus orient edges and flag spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit via constraint-based elimination (edges inconsistent with change patterns are not accepted) rather than explicit downweighting; no differentiable penalty term.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Uses constraints derived from observed heterogeneity to rule out candidate directions that contradict the pattern of changes across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Reported as a baseline: performs well in some nonlinear cases but is computationally expensive (reported running times >9h for 10 nodes, >300h for 50 nodes), and in experiments CD-NOD sometimes competitive but slower.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Leveraging heterogeneity can help orient causal directions and reduce spurious edges, but constraint-based multi-environment methods like CD-NOD may be computationally costly and scale poorly to larger nonlinear problems; DICD offers a differentiable and more scalable alternative.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e723.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e723.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DARING</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DARING (Differentiable causal discovery with residual independence)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable causal discovery method that enforces independence between residuals and predictors using an adversarial training approach to eliminate spurious dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DARING: differentiable causal discovery with residual independence</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DARING</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Constrains independence between residuals and candidate parents via an adversarial objective: a discriminator tries to detect dependence between residuals and predictors, while the causal model minimizes this dependence together with reconstruction loss and a DAG constraint; aims to reduce spurious edges by enforcing residual independence.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Pooled datasets (baseline), typically the authors apply it on concatenated data; in this paper DARING is used with NOTEARS-MLP backbone</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interactive; applied to the same synthetic/real datasets as other baselines without explicit multi-environment invariance penalty in the baseline configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects spurious links by testing independence between residuals and predictors; uses adversarial training to enforce residual independence and thus downweight edges that produce dependent residuals indicative of misspecification or confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Residual dependence due to omitted variables, misspecified parents, or spurious correlations; aims to detect edges that leave dependent residuals.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Adversarial critic learns to detect dependence between residuals and inputs; strong dependence signals discourage the corresponding edge configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Adversarial training penalizes models that yield dependent residuals; this indirectly downweights edges that produce such dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Edges that consistently produce residual dependence across training are discouraged/removed by the adversarial penalty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported as a baseline: competitive in some settings but generally DICD outperforms DARING on SHD and TPR in experiments reported (DARING often has higher SHD than DICD across many settings).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Residual-independence constraints enforced adversarially can help remove spurious edges, but DICD's environment-invariance approach yields stronger reductions in spurious edges and SHD in the presented multi-environment benchmarks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e723.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e723.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An algorithmic principle that seeks predictors whose optimality (risk minimizer) is invariant across training environments, used to avoid learning spurious correlations tied to specific environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Invariant risk minimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Risk Minimization (IRM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Optimization objective that encourages learning of predictors (or representation + classifier) whose risk minimizer is the same across environments; in practice implemented via penalties that encourage gradient of per-environment loss w.r.t. classifier parameters to be zero, promoting invariance and robustness to environment-specific spuriously predictive features.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Conceptual / multi-environment learning framework</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Assumes pre-partitioned environments (non-interactive); environments are used to identify invariant predictors rather than pooled training.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Promotes invariance across environments so features predictive only due to environment-specific correlations (distractors) are not selected; implemented via gradient-based penalties (first-order optimality constraints) or constrained optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific shortcuts, spurious correlations, distributional shift tied to environment/idiosyncratic features.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detects spurious features/edges by observing that predictors relying on them will have different optimal parameters across environments (non-invariance).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Penalty terms that enforce per-environment optimality conditions (e.g., gradient-of-risk terms) reduce importance of environment-specific signals.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Candidate predictors that fail the invariance optimality across environments are rejected; theoretical arguments show invariance implies causality under assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>IRM is the conceptual basis for DICD's penalty: the paper adapts IRM-style first-order optimality penalties to differentiable DAG learning to detect and exclude spurious edges whose estimated coefficients vary across environments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Invariant risk minimization <em>(Rating: 2)</em></li>
                <li>Causal inference by using invariant prediction: identification and confidence intervals <em>(Rating: 2)</em></li>
                <li>Causal discovery from heterogeneous/nonstationary data <em>(Rating: 2)</em></li>
                <li>Multi-domain causal structure learning in linear systems <em>(Rating: 2)</em></li>
                <li>DARING: differentiable causal discovery with residual independence <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-723",
    "paper_id": "paper-249210097",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "DICD",
            "name_full": "Differentiable Invariant Causal Discovery",
            "brief_description": "A differentiable causal discovery algorithm that uses multi-environment data and an invariant-learning-inspired penalty to prefer DAG structures whose structural equation models (SEM) are optimal and stable across environments, thereby rejecting spurious edges that vary with environment noise.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "DICD",
            "method_description": "DICD learns a DAG by combining the continuous-score/DAG-constraint framework (NOTEARS style) with an invariant-optimality penalty across environments. It represents structure via a structure matrix S (or directly via AS = S • A / f_S for nonlinear) and fits SEM parameters per the DAG. To enforce environment-invariance it adds a differentiable penalty derived from the first-order optimality condition: the squared norm of the gradient of the per-environment loss w.r.t. an inserted scaling matrix B evaluated at B=1 (linear: ||∂L_e(A_S • B)/∂B|_{B=1}||_2^2; nonlinear: analogous term on the MLP first-layer parameters). This penalizes edges whose optimal coefficients vary across environments, encouraging selection of edges with invariant coefficients. Training also enforces acyclicity via standard continuous constraints.",
            "environment_name": "Synthetic multi-environment datasets and ColoredMNIST (multi-environment partitioning)",
            "environment_description": "Non-interactive, simulated multi-environment datasets: linear and nonlinear SEMs where environments differ by additive-noise variances (simulated 'environment variables' connected to selected nodes and later removed to create hidden distractors). Also a ColoredMNIST dataset partitioned into color/noise environments; environments are pre-specified (not actively chosen).",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects and removes spurious/ distractor-induced edges by testing parameter stability across environments and penalizing instability via a differentiable first-order optimality penalty; effectively performs variable/edge selection by downweighting edges with environment-dependent coefficients.",
            "spurious_signal_types": "Spurious correlations induced by environment-dependent additive noise, hidden environment (distractor) variables connected to observed nodes (selection/annotation biases), over-reconstruction shortcuts (incorrect edge directions that exploit correlation).",
            "detection_method": "Identifies spurious edges by instability of estimated SEM coefficients across environments: if coefficient estimates change between environments, the edge is penalized; operationalized by the gradient-of-loss w.r.t. an inserted scaling matrix B evaluated at B=1 (the necessary optimality condition).",
            "downweighting_method": "Adds a penalty term (lambda * sum_e ||∂L_e(...)/∂B|_{B=1}||_2^2) to the training objective so that edges whose inclusion causes environment-dependent optimal coefficients are discouraged; structure is recovered from the learned AS or f_S.",
            "refutation_method": "Refutes spurious edges by showing they lead to inconsistent optimal SEM parameters across environments and therefore higher penalized objective; theoretical identifiability results show the ground-truth graph minimizes total (penalized) reconstruction loss across sufficiently diverse environments.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Substantially improved: e.g., linear ER graph with 10 nodes: SHD 4.9 (DICD) vs 10.1 (NOTEARS); overall reported up to 36% relative improvement in SHD (10-node ER case). Nonlinear ER 10-node: SHD 19.2 (DICD) vs 23.8 (NOTEARS-MLP); up to 29% improvement reported in some nonlinear settings.",
            "performance_without_robustness": "Baselines operating under ERM (no invariant penalty) such as NOTEARS / NOTEARS-MLP show higher SHD, higher FDR or lower TPR in many settings (e.g., NOTEARS SHD 10.1 vs DICD 4.9 on ER 10-node linear). Exact table entries reported across settings in paper (see Tables 2,4,6,7).",
            "has_ablation_study": false,
            "number_of_distractors": "Simulated by 0.3*d environment variables in linear experiments and 0.5*d in nonlinear experiments (these environment nodes are removed from observed data to create hidden distractors).",
            "key_findings": "Using multi-environment information and enforcing parameter optimality/invariance across environments successfully mitigates over-reconstruction and spurious edges: DICD lowers FDR, raises TPR, and reduces SHD versus popular differentiable baselines. The method is computationally efficient versus some constraint-based multi-environment methods (e.g., CD-NOD) and has theoretical identifiability guarantees in linear Gaussian SEMs when environments are sufficiently diverse.",
            "uuid": "e723.0"
        },
        {
            "name_short": "NOTEARS",
            "name_full": "NOTEARS (Continuous optimization for DAG learning)",
            "brief_description": "A differentiable score-based causal discovery method that formulates DAG learning as continuous optimization with a smooth acyclicity constraint, typically minimizing reconstruction loss under the DAG constraint.",
            "citation_title": "NOTEARS",
            "mention_or_use": "use",
            "method_name": "NOTEARS",
            "method_description": "Forms SEM as linear (X A) and uses a continuous acyclicity constraint (trace(exp(W ∘ W)) - d = 0) on the weighted adjacency matrix; optimizes reconstruction loss (ERM) plus sparsity regularization via gradient-based solvers to obtain a DAG. In nonlinear cases, NOTEARS-MLP extends this idea to neural nets by constraining the first layer.",
            "environment_name": "Concatenated datasets from all environments (baseline)",
            "environment_description": "ERM-trained on pooled observations without explicit multi-environment invariant penalty; environments can be concatenated but not used to enforce invariance.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Prone to capturing spurious correlations induced by hidden distractors, selection/annotation biases and noise heterogeneity because it optimizes pooled reconstruction loss (ERM).",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": "Baseline ERM performance reported in paper (example: linear ER 10-node: SHD 10.1, FDR 0.07, TPR 0.78; NOTEARS often shows higher SHD or FDR than DICD).",
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "ERM-based differentiable methods like NOTEARS can overfit spurious correlations and produce incorrect edge directions (over-reconstruction); pooling environments without invariance constraints can therefore produce sub-optimal DAGs.",
            "uuid": "e723.1"
        },
        {
            "name_short": "NOTEARS-MLP",
            "name_full": "NOTEARS-MLP (nonlinear extension of NOTEARS)",
            "brief_description": "Nonlinear differentiable causal discovery method using MLPs to model structural functions and a continuous acyclicity constraint applied to the first MLP layer.",
            "citation_title": "NOTEARS-MLP",
            "mention_or_use": "use",
            "method_name": "NOTEARS-MLP",
            "method_description": "Approximates SEM functions with multilayer perceptrons for nonlinear causal relations and enforces DAG constraint by constraining the first-layer weights (columns) to reflect adjacency; optimizes ERM reconstruction loss plus regularizers under continuous DAG constraint.",
            "environment_name": "Concatenated datasets from all environments (baseline)",
            "environment_description": "Same pooled/non-interventional setting as NOTEARS but modeling nonlinear SEMs; environments are concatenated for baseline training.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Prone to spurious correlations in nonlinear regimes; can miss true causal correlations or produce over-reconstruction.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": "Reported in nonlinear experiments (e.g., ER 10-node nonlinear: SHD 23.8 vs DICD 19.2; NOTEARS-MLP often worse than DICD in SHD and TPR).",
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "As a nonlinear ERM baseline, NOTEARS-MLP can be outperformed by invariant approaches (DICD) that use multi-environment constraints to reject spurious edges.",
            "uuid": "e723.2"
        },
        {
            "name_short": "CD-NOD",
            "name_full": "CD-NOD (Causal Discovery from heterogeneous/nonstationary data)",
            "brief_description": "A constraint-based causal discovery approach that leverages independent changes across environments to orient edges and exploit heterogeneity to detect causal directions and reject spurious relations.",
            "citation_title": "Causal discovery from heterogeneous/nonstationary data",
            "mention_or_use": "use",
            "method_name": "CD-NOD",
            "method_description": "A constraint-based method tailored for heterogeneous datasets: detects independence/changes in distributions across environments and uses constrained tests and kernel methods to orient edges and identify causal structures by leveraging environment-induced distribution shifts; designed to exploit independent changes for orientation.",
            "environment_name": "Heterogeneous/multi-environment datasets (requires environment labels)",
            "environment_description": "Designed specifically to operate when environment partitions are known and the distributional changes across them can be used to identify causal directions; not interactive/active experimentation.",
            "handles_distractors": true,
            "distractor_handling_technique": "Uses tests for independent changes across environments (distributional shifts) and constraint-based orientation rules; kernel-based tests to detect nonstationarity tied to specific variables (effectively identifies variables affected by environment/distractors).",
            "spurious_signal_types": "Heterogeneous additive noise, nonstationarity, environment-specific distribution shifts that induce spurious correlations.",
            "detection_method": "Statistical independence/change detection across environments (including kernel-based tests) to find which conditional distributions change and thus orient edges and flag spurious edges.",
            "downweighting_method": "Implicit via constraint-based elimination (edges inconsistent with change patterns are not accepted) rather than explicit downweighting; no differentiable penalty term.",
            "refutation_method": "Uses constraints derived from observed heterogeneity to rule out candidate directions that contradict the pattern of changes across environments.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": "Reported as a baseline: performs well in some nonlinear cases but is computationally expensive (reported running times &gt;9h for 10 nodes, &gt;300h for 50 nodes), and in experiments CD-NOD sometimes competitive but slower.",
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Leveraging heterogeneity can help orient causal directions and reduce spurious edges, but constraint-based multi-environment methods like CD-NOD may be computationally costly and scale poorly to larger nonlinear problems; DICD offers a differentiable and more scalable alternative.",
            "uuid": "e723.3"
        },
        {
            "name_short": "DARING",
            "name_full": "DARING (Differentiable causal discovery with residual independence)",
            "brief_description": "A differentiable causal discovery method that enforces independence between residuals and predictors using an adversarial training approach to eliminate spurious dependencies.",
            "citation_title": "DARING: differentiable causal discovery with residual independence",
            "mention_or_use": "use",
            "method_name": "DARING",
            "method_description": "Constrains independence between residuals and candidate parents via an adversarial objective: a discriminator tries to detect dependence between residuals and predictors, while the causal model minimizes this dependence together with reconstruction loss and a DAG constraint; aims to reduce spurious edges by enforcing residual independence.",
            "environment_name": "Pooled datasets (baseline), typically the authors apply it on concatenated data; in this paper DARING is used with NOTEARS-MLP backbone",
            "environment_description": "Non-interactive; applied to the same synthetic/real datasets as other baselines without explicit multi-environment invariance penalty in the baseline configuration.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects spurious links by testing independence between residuals and predictors; uses adversarial training to enforce residual independence and thus downweight edges that produce dependent residuals indicative of misspecification or confounding.",
            "spurious_signal_types": "Residual dependence due to omitted variables, misspecified parents, or spurious correlations; aims to detect edges that leave dependent residuals.",
            "detection_method": "Adversarial critic learns to detect dependence between residuals and inputs; strong dependence signals discourage the corresponding edge configuration.",
            "downweighting_method": "Adversarial training penalizes models that yield dependent residuals; this indirectly downweights edges that produce such dependence.",
            "refutation_method": "Edges that consistently produce residual dependence across training are discouraged/removed by the adversarial penalty.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported as a baseline: competitive in some settings but generally DICD outperforms DARING on SHD and TPR in experiments reported (DARING often has higher SHD than DICD across many settings).",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Residual-independence constraints enforced adversarially can help remove spurious edges, but DICD's environment-invariance approach yields stronger reductions in spurious edges and SHD in the presented multi-environment benchmarks.",
            "uuid": "e723.4"
        },
        {
            "name_short": "IRM",
            "name_full": "Invariant Risk Minimization",
            "brief_description": "An algorithmic principle that seeks predictors whose optimality (risk minimizer) is invariant across training environments, used to avoid learning spurious correlations tied to specific environments.",
            "citation_title": "Invariant risk minimization",
            "mention_or_use": "mention",
            "method_name": "Invariant Risk Minimization (IRM)",
            "method_description": "Optimization objective that encourages learning of predictors (or representation + classifier) whose risk minimizer is the same across environments; in practice implemented via penalties that encourage gradient of per-environment loss w.r.t. classifier parameters to be zero, promoting invariance and robustness to environment-specific spuriously predictive features.",
            "environment_name": "Conceptual / multi-environment learning framework",
            "environment_description": "Assumes pre-partitioned environments (non-interactive); environments are used to identify invariant predictors rather than pooled training.",
            "handles_distractors": true,
            "distractor_handling_technique": "Promotes invariance across environments so features predictive only due to environment-specific correlations (distractors) are not selected; implemented via gradient-based penalties (first-order optimality constraints) or constrained optimization.",
            "spurious_signal_types": "Environment-specific shortcuts, spurious correlations, distributional shift tied to environment/idiosyncratic features.",
            "detection_method": "Detects spurious features/edges by observing that predictors relying on them will have different optimal parameters across environments (non-invariance).",
            "downweighting_method": "Penalty terms that enforce per-environment optimality conditions (e.g., gradient-of-risk terms) reduce importance of environment-specific signals.",
            "refutation_method": "Candidate predictors that fail the invariance optimality across environments are rejected; theoretical arguments show invariance implies causality under assumptions.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "IRM is the conceptual basis for DICD's penalty: the paper adapts IRM-style first-order optimality penalties to differentiable DAG learning to detect and exclude spurious edges whose estimated coefficients vary across environments.",
            "uuid": "e723.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Invariant risk minimization",
            "rating": 2,
            "sanitized_title": "invariant_risk_minimization"
        },
        {
            "paper_title": "Causal inference by using invariant prediction: identification and confidence intervals",
            "rating": 2,
            "sanitized_title": "causal_inference_by_using_invariant_prediction_identification_and_confidence_intervals"
        },
        {
            "paper_title": "Causal discovery from heterogeneous/nonstationary data",
            "rating": 2,
            "sanitized_title": "causal_discovery_from_heterogeneousnonstationary_data"
        },
        {
            "paper_title": "Multi-domain causal structure learning in linear systems",
            "rating": 2,
            "sanitized_title": "multidomain_causal_structure_learning_in_linear_systems"
        },
        {
            "paper_title": "DARING: differentiable causal discovery with residual independence",
            "rating": 2,
            "sanitized_title": "daring_differentiable_causal_discovery_with_residual_independence"
        }
    ],
    "cost": 0.0185515,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Differentiable Invariant Causal Discovery</p>
<p>Yu Wang 
An Zhang 
Xiang Wang 
Yancheng Yuan 
Xiangnan He 
Tat-Seng Chua 
Differentiable Invariant Causal Discovery
1Index Terms-Causal DiscoveryInvariant LearningCausal Structure LearningCausal Graph Learning !
Learning causal structure from observational data is a fundamental challenge in machine learning. However, the majority of commonly used differentiable causal discovery methods are non-identifiable, turning this problem into a continuous optimization task prone to data biases. In many real-life situations, data is collected from different environments, in which the functional relations remain consistent across environments, while the distribution of additive noises may vary. This paper proposes Differentiable Invariant Causal Discovery (DICD), utilizing the multi-environment information based on a differentiable framework to avoid learning spurious edges and wrong causal directions. Specifically, DICD aims to discover the environment-invariant causation while removing the environment-dependent correlation. We further formulate the constraint that enforces the target structure equation model to maintain optimal across the environments. Theoretical guarantees for the identifiability of proposed DICD are provided under mild conditions with enough environments. Extensive experiments on synthetic and real-world datasets verify that DICD outperforms state-of-the-art causal discovery methods up to 36% in SHD. Our code will be open-sourced.</p>
<p>INTRODUCTION</p>
<p>Causal discovery (CD) is a fundamental problem in a variety of tasks, such as understanding the generation process of data [1], and probing explainability of models [2], [3]. It has tremendous impacts on various domains, like biology [4], [5], and finance [6]. CD aims to learn the causal structure among a set of variables from the observational data and represent the structure as a directed acyclic graph (DAG). The acyclicity constraint frames CD as the combinatorial optimization of discrete edges, which however, is NP-hard. Recently, leading CD solutions [1], [7], [8], [9] gracefully convert the DAG learning into the continuous optimization task. Specifically, the idea stemming from NOTEARS [1] is to build a scoring function upon the adjacency matrix over the variables and find an equivalent continuous constraint on acyclicity.</p>
<p>NOTEARS [1] inspired the development of numerous differentiable causal discovery algorithms that use gradient descent to find the optimal causal graph [10], [11], [12]. When compared to traditional constraint-based causal discovery, these methods have demonstrated superior performance and efficiency in uncovering the true graph with a large amount of data. However, most of them follow the paradigm of empirical risk minimization (ERM) [13] -first imposing the scored DAG on the observations to reconstruct, and then minimizing the empirical risks between the observational and reconstructed data, so as to optimize the DAG. Despite the promising performance, we argue that ERM is prone to capture data biases or shortcut [14], [15], [16], thus derailing the structure learning of DAG. Specifically, the observations of variables are often marred • Y. Wang, X. Wang and X. He  by some spurious correlations, such as the annotator or selection biases in the data acquisition pipeline [14], thus posing undesired entanglements of variables. ERM easily latches on these correlations [14], [15], [17] to refine the DAG structure, as the following example illustrates.</p>
<p>Consider the ground-truth DAG in Table 1 as the target being reconstructed by the CD solutions, where each edge denotes a causal relationship between two variable nodes. X consists of three variables, which have different relationships with Y : A determines Y , B is influenced by Y , and C is irrelevant to Y . While the CD solutions are designed to identify the causation edges, ERM does not need to learn the correct DAG to reach a low reconstruct loss for fitting the observations. For example, instead of looking at the true causation B ← Y , it is easy to capture the statistical shortcut edge B → Y , since B is strongly correlated with Y and the reconstructed DAGs achieve even lower losses as compared to the ground-truth DAG. This common problem is consistent with over-reconstruction [18] but remains largely unexplored.</p>
<p>In this study, we aim to design a paradigm that distinguishes the causation edges from spuriously-correlated edges and obtains the faithful DAG. Although learning causal structure from observational data is challenging, we draw inspiration from invariant learning [14], [15], [17] and approximate the task by searching the edges with invariant structural equations in multi-environment settings. Across different environments, only factual causation edges remain invariant, while edges with wrong causal directions hardly remain stable, according to the assumptions in invariant learning [14]. Though reminiscent of past ideas -e.g., causal structure learning in multi-domain, from heterogeneous/nonstationary data [19], [20], [21], [22], [23], [24], [25] -these methods are only applicable in a linear system or restricted to conditional independence tests, which suffer from high computation complexity as the number of variables increases. To achieve effective differentiable causal discovery in both linear and nonlinear scenarios, we reconsider Table 1 and additionally exhibit the multi- TABLE 1 Examples that NOTEARS would find the wrong causal graph while multi-environment settings can help identify the true graph. We present the DAGs derived from minimal reconstruction loss in different environments. The graph on the left denotes the ground truth. The edges in red are wrong or spurious, while the dash one represents the corresponding coefficient is zero. We list the reconstruction loss value following with the triplets in brackets representing coefficients of Y with A, B and C. The loss values and parameters of the potential sub-optimal causal structures learned by NOTEARS in a single environment are highlighted in red. Detailed data generating processes are as follows. X ∼ N (0, 1), A = X + z A (∼ N (0, 1)), B = X + Y /2 + z e B (∼ N (0, (σ e B ) 2 )), C = X/2 + z e C (∼ N (0, (σ e C ) 2 )), Y = A/4 + Y (∼ N (0, 1)). σ e B and σ e C varies across three environments, e 1 , e 2 and e 3 , with (σ e B ) 2 = (σ e C ) 2 = 1, 2, 4, respectively. 1 4.57 (0.24, 1.14, -1.32) 5.07 (0.24, 0.32, 0.00) 5.07 (0.24, 0.50, 0.00) e 2 6.59 (0.24, 1.09, -1.19) 7.14 (0.24, 0.23, 0.00) 7.07 (0.24, 0.50, 0.00) e 3 10.60 (0.24, 1.07, -1.12) 11.21 (0.24, 0.15, 0.00) 11.07 (0.24, 0.50, 0.00) Towards this end, we propose differentiable invariant causal discovery (DICD), a novel scheme of DAG structure learning that incorporates the idea of invariant learningthat is, learning an invariant DAG with the piece of environment information. Specifically, a DAG generator module learns to generate the environment-aware DAGs from individual environments. For each DAG, the structure equation model (SEM) [26] describes the functions of learned causation edges. We then exploit invariant risk minimization (IRM) [14] to encourage the SEMs to be optimal across all environments, obtaining DAGs regardless of environment changes. On synthetic and real-world datasets, extensive experiments demonstrate the effectiveness of DICD to surpass current state-of-the-art CD solutions.
B C A X Y B C A X Y B C A X Y B C A X Y eB C A X Y B C A X Y B C A X Y 5.
Our main contributions are:</p>
<p>• To the best of our knowledge, we are among the first class to adopt the environment information into the differentiable causal discovery framework. • We propose a novel causal discovery solution, DICD, to incorporate invariant learning in both linear and nonlinear settings. Experimental results on synthetic and realworld datasets demonstrate that DICD could significantly better reveal true correlations and eliminate the spurious ones compared to prevalent methods. • We provide theoretical guarantees for the identifiability of proposed DICD in linear systems under mild conditions, given certain assumptions about the environments.</p>
<p>PRELIMINARY</p>
<p>We first make some necessary and reasonable assumptions. Then, we give the task formulation of causal discovery (CD). After that, we introduce the continuous optimization paradigm via empirical risk minimization (ERM), as well as the linear and nonlinear solutions. We list the notations mentioned in our paper in Appendix A</p>
<p>Assumptions. (i) The structural equations are invariant across different environments; (ii) The system is causally sufficient; (iii) Observational data is generated from a structural equation model with independent additive noise; (iv) The distribution shift of additive noise appears in different environments.</p>
<p>The assumptions (i) -(iii) are crucial to our method and provide key insights on how causal structure can be identified from observational data. Assumption (i) states that the invariance principle is held across environments. Assumption (ii) ensures that no hidden confounders exist in the system. In other words, there is no systematic bias induced by hidden confounders. Assumption (iii) implies that only independent additive noise is considered in our paper, which is commonly used in causal discovery. Assumption (iv) defines the multiple environments, which is consistent with the definition of environment assumed in [20], [22] with heterogeneous data [21] or interventional data [19]. A formal definition of different environments is given in Definition 3.1. Technically speaking, assumption (iv) presents both challenges and opportunities for causal discovery and provides a sufficient condition that the causal structure becomes identifiable. A more formal Theorem 4.1 on this argument will be presented later in Section 4.</p>
<p>Task Formulation of CD. Let X = [x 1 |· · · |x n ] ∈ R n×d denote the n observational data of d variables, which are generated from a target directed acyclic graph (DAG). The target DAG is (V, D), where V represents the set of node variables, denoted as {X 1 , · · · , X d }. And D is the set of cause-effect edges between variables. The observational data is assumed to be generated from the following SEM:
X j = F j (P a(X j )) + z j , j ∈ {1, · · · , d},(1)
where X j is the j-th node variable, F j is the causal structure function, P a(X j ) is the set of the parents of X j , and z j refers to the additive noise with variance σ 2 j . Without loss of generality, we assume that the noises are zero-mean. In real-life settings, since the dataset may be obtained from various environments, the distribution of additive noises z j may differ across different environments. The causal structure functions F j , on the other hand, are generally invariant. The goal of CD is to learn a DAG to reconstruct the observations X. The acyclicity restriction of DAG is the fundamental obstacle, because it frames DAG learning as a NP-hard combinatorial optimization task.</p>
<p>Common Paradigm of ERM. Popular differentiable CD solutions, e.g., NOTEARS [1] and its follow-up studies [10], [12], convert DAG learning into a continuous optimization process to overcome the obstacle of the combinatorial optimization problem. The primary idea is to build a scoring function upon the adjacency matrix of variables and discover an equivalent continuous constraint on acyclicity. To optimize the scoring function, they mostly adopt the paradigm of ERM to minimize the empirical risks between the observational and reconstructed data as:
min f L(f ) = 1 n n i=1 l(x i , f (x i )) s.t. G(f ) ∈ DAG,
where x i is the i-th sample in the dataset. l(·, ·) is the reconstruction loss function, i.e., squared loss or negative log-likelihood. f = (f 1 , · · · , f d ) formulates the estimated structure function [26] of variables, where f i : R d → R is the estimated structure function of node variable X i , and thus f : R d → R d is the structure function for all nodes.
f i (X 1 , · · · , X d ) is dependent on X j , if X j ∈ Pa(X i ).
The score-based solutions seek to learn f conditioning on the DAG constraint: G(f ) ∈ DAG, where G(f ) refers to the graph corresponding to f . Following prior studies [1], [10], we use the matrix W ∈ R d×d to encode the graph G(f ), where each element [W] ij = 0 indicates the existence of edge X i → X j . Then we define the matrix W as:
[W(f )] ij := |∂ i f j |,(2)
where
∂ i f j = ∂fj (X1,···,X d ) ∂Xi
is f j 's partial derivative w.r.t. X i . Thus, f j does not depend on X i if and only if |∂ i f j |= 0. With Equation (2), we can exploit linear and nonlinear functions f to characterize acyclicity in linear and nonlinear SEMs, respectively.</p>
<p>Linear SEM. In the case of linear SEM [1], we formulate f (X) as a linear matrix multiplication: f (X) = XA (with each instance f (x i ) = A x i , i ∈ {1, · · · .n}), where A ∈ R d×d denotes the coefficient matrix. This formulation frames the acyclicity in Equation (2) as:
[W(f )] ij = |A ij |.(3)
Nonlinear SEM. In the case of nonlinear SEM [10], we define f i (X) as a multilayer perceptron (MLP) with h hidden layers and an activation function σ as:
f i (X) = MLP(X; A (1) i , · · · , A (h) i ) = σ(· · · σ(XA (1) i ) · · ·)A (h) i ,(4)
where A (l) i ∈ R m l−1 ×m l is the learnable weight matrix of the l-th hidden layer for the i-th node, m l is the number of hidden units in the l-th layer, and m 0 = d. According to [10], we could define W θ (f ) as
[W θ (f )] ij = i-th column(A (1) j ) 2 .(5)
Then the acyclicity constraint could be latched on W θ (f ), which serves as the replacement of the intractable W(f ) for nonlinear setting.</p>
<p>METHODOLOGY</p>
<p>In this section, we first present differentiable invariant causal discovery (DICD) to conduct causal structural learning over multiple environments. Then, we give detailed formulations in both linear and nonlinear settings.</p>
<p>Differentiable Invariant Causal Discovery (DICD)</p>
<p>Despite the great success, the ERM paradigm easily captures spurious correlations between variables by overreconstructing the observations [18] (See the toy example in Table 1). It is essential to distinguish the causation edges from the spuriously-correlated edges. Towards this end, we get access to the multi-environment information and incorporate the idea of invariant learning, so as to frame the causal discovery task as identifying environment-invariant causation edges and discarding environment-dependent correlations.</p>
<p>First, we argue that the multi-environment, in various forms like explicit or implicit metadata, is common in many real-world datasets and can partition the data into different groups or domains. The environments in LFW dataset [27], for instance, can divide the data into blackand-white and colorful photographs. In ImageNet dataset [28], the data can be grouped by different sources and years of images. Moreover, several benchmarks for the domainshifts problems have been provided by WILDS [29]. Among them, Camelyon17 [30] includes the images collected from five hospitals that serve as different environments, while Amazon [31] provides review texts from different reviewers that can work as environments. Towards the end, the formal definition of the different environments in our paper is given as follow:</p>
<p>Definition 3.1. For two datasets generated from the same structure equation model as shown in Equation (1). if there exists i ∈ {1, · · · , d} such that the distribution of z i is different across these datasets and X i is not the source node (see Definition 3.2) in the corresponding graph. Then we say these two datasets are drawn from different environments.</p>
<p>Definition 3.2.</p>
<p>We define the node in the graph with no parents as the Source Node.</p>
<p>With the environment information, we utilize the invariant learning to conduct multi-environment causal discovery -the function parameters of SEM from the target DAG should remain optimal across all the environments. Guided by this idea, our DICD consists of two modules: (1) Invariant structural model S, which presents the structure of DAG, i.e., a binary adjacency matrix. By "invariant", we mean that S should be consistent across environments; and (2) Optimal causal function f , which depicts the causal relation of variables. By "optimal", we mean that f should be optimal over all the environments once the structural model S is given. Considering the example in Table 1 again, S is the DAG structure, while f refers to the coefficients of edges. For an invariant DAG structure, completely various optimal coefficients will be learned in different environments. As a result, by utilizing the environment information, incorrect DAGs with smaller reconstruction losses can be excluded based on S and f .</p>
<p>Having environment-aware groups of observations, we define the empirical risk within the environment e ∈ E as:
L e (S • f ) = 1 n e ne i=1 l(X e i , (S • f )(X e i )),
where • refers to the composition of the two functions, and n e is the number of samples in environment e. We then build two constraints on S and f across all environments, and establish the model of DICD:
min S•f e∈E L e (S • f ),(6)s.t. G(S) = G(f ) ∈ DAG,(7)f = arg min f L e (S •f ), ∀e ∈ E.(8)
Equation (7) states the DAG constraint, where the DAGs represented by S and f are equivalent. In other words, f latches on S's DAG structure. Equation (8) claims that f refers to the optimal causal model fitting Equation (6) across all environments. Following NOTEARS [10], the DAG constraints can rewrite as hard DAG equation constraints:
G(S) = G(f ), h(W(f )) = 0,(9)
where W(f ) is defined as Equation (2) in the linear setting and should be replaced with W θ (f ) in Equation (5) </p>
<p>Linear SEM</p>
<p>When f characterizes acyclicity in the linear SEM, we have f (X) = XA and ∂ i f j (X) = A ij (cf. Equation (3)). With the invariant structure model S as the binary matrix, we can convert S • f as S • A, which is the Hadamard product of S and A. However, the bilevel optimization formulation of the DICD model is difficult to solve and is susceptible to failure due to over-parametrization in our setting. We further simplify the learning of these two matrices as the optimization of a new matrix A S = S • A ∈ R d×d . As such, we restrict the loss function in Equation (6) with the DAG constraint in Equation (7) as:
min AS e∈E L e (A S ), s.t. h(A S ) = 0.
This relaxed version only focuses on optimizing over A S during training. After learning A S , we can simply reset coefficient matrix A = A S and let S be the binary indicator on A S 's elements. We then explore the tractable formulation for the optimality constraint across environments in Equation (8) with the following theorem: Theorem 3.1. In the linear setting, we define a matrix variable as B ∈ R d×d . After replacing S•A with A S , the constraint Equation (7-8) satisfy the following necessary condition:
∂L e (A S • B) ∂B | B=1 2 2 = 0, ∀e ∈ E,(10)
where 1 is the all-one matrix.</p>
<p>Proof. The basic optimality constraint across environments for Equation (7)(8) can be described as:
A * = arg min A L e (S • A), ∀e ∈ E, s.t. G(S) = G(A) ∈ DAG.(11)
Then we introduce a new matrix variable B and insert it into Equation (11). The optimal of B can be defined as:
B * = arg min B L e (S • A * • B), ∀e ∈ E.(12)
We assert B * could be the all-one matrix 1, which indicates:
L e (S • A * • 1) ≤ L e (S • A * • B), ∀B ∈ R D×D , ∀e ∈ E.(13)
Assuming there exists B that satisfies
L e (S • A * • B ) &lt; L e (S • A * • 1), then replacing A * • B with A , we could have L e (S • A ) &lt; L e (S • A * )
. This result obviously contradicts with Equation (11). As such, Equation (13) holds.</p>
<p>We replace S • A with A S . Now if A is the optimal parameter of Equation (11) (i.e., A * ), then A S becomes A * S , which yield the following equation:
1 = arg min B L e (A * S • B), ∀e ∈ E.
According to the first-order optimality condition, we have:
∂L e (A * S • A) ∂B | B=1 = 0.
This concludes the proof.</p>
<p>Based on Theorem 3.1, we could find that the intractable optimality constraint across environments is now differentiable with the objective Equation (10).</p>
<p>We establish the DICD model in linear cases as follows:
min AS e∈E L e (A S ) + λ e∈E ∂L e (A S • B) ∂B | B=1 2 2 , s.t. h(A S ) = 0.(14)
This objective function potentially incorporates the invariant structure and the optimal coefficients into the single variable A S , thus only adds one more penalty for training compared with NOTEARS.</p>
<p>Nonlinear SEM</p>
<p>In nonlinear settings, We shall continue to concentrate on the scenario with scalar-valued variables (i.e., X ∈ R n×d ) for simplicity. However, the vector-valued variables (i.e., X ∈ R n×d×dx ) could be simply incorporated into DICD.</p>
<p>NOTEARS-MLP [10] deploys the continuous DAG constraint for nonlinear SEM to the first layer of all the MLPs, as shown in Equation (5). Inspired by this, we establish the relationship between the structure matrix S and the first layer of the MLPs. In other words, ensuring the parameters of MLP latch on the structure S in order to satisfy G(S) = G(f ) constraint. The precise solution to the equation G(S) = G(f ) is to maintain the following restriction throughout the optimization process:
∀i, j, S ji = 0 =⇒ ||j-th column(A (1) i )|| 2 = 0,(15)
where A</p>
<p>(1) i is the matrix parameter of the first layer in the i-th MLP. The intuition behind the above equation is that setting j-th column(A (1) i ) to zero would block the correlation from j to i, corresponding to S ji = 0.</p>
<p>Though the first term in constraint Equation (9) could be formulated in Equation (15). The optimization of Equation (6-8) is still intractable. We need to construct an differentiable term to replace the constraint Equation (15). To address this problem, we propose to simplify the optimization of S and f to optimizing a new function f S = (f S1 , · · · , f Sd ), where f Si = S • f i . The exact correlation is described in the following equation:
f Si = S • f i = MLP(Re([S] i , m 1 ) • A (1) i , A (2) i , · · · , A (h) i ) = MLP(A (1) Si , A (2) i , · · · , A (h) i ), where m 1 comes from A (1) i ∈ R m0×m1 , and Re([S] i , m 1 ) refers to [[S] i , · · · , [S] i m1 times ] , with [S] i being the i-th column of S. We denote Re([S] i , m 1 )•A (1) i as A (1)
Si . Similar to the linear setting, once f S is learned, we can simply set f = f S and S as the adjacency matrix of G(f ). Then f and S will share the same graph structure. Now we propose the following theorem for nonlinear setting:
Theorem 3.2. In nonlinear system, we denote A (l) i , l ∈ {1, · · · ,
d} as the parameter of the l-th layer of MLP f i , and A Si is the parameter of the 1st layer of MLP f Si , i ∈ {1, · · · , d}. Then
after replacing Re([S] i , m 1 ) • A (1) i with A (1)
Si , we define a matrix variable as B ∈ R m1×d , the optimal condition Equations (7-8) except for the DAG part satisfy the following necessary condition:
d i=1 ∂L e (MLP(A (1) Si • B, A (2) i , · · · , A (n) i )) ∂B B=1 2 2 = 0, ∀e ∈ E.(16)
Proof. The basic optimal condition described in Equation (7)(8) without the DAG constraint could be written as:
A (1) * i = arg min A (1) i L e (MLP(Re([S] i , m 1 ) • A (1) i , · · · , A (n) i )), ∀e ∈ E, s.t. G(S) = G(f ),(17)
where
Re([S i ], m 1 ) means [[S] i , · · · , [S] i m1 times ] , with [S] i being
the i-th column of S. Note that the following equations with e in this proof indicate all the environments, we omit the condition ∀e ∈ E in the following to simplify the proof. Similar to the proof of Proposition 3.1, we define a new matrix B ∈ R m1×d , and insert this term into the above equation, then we can have:
B * = arg min B L e (MLP(Re([S] i , m 1 ) • A (1) * i • B, · · · , A (n) i )).(18)
We argue that B * could be 1, a matrix of dimensions m 1 × d filled with ones. This is expressed as:
1 = arg min B L e (MLP(Re([S] i , m 1 ) • A (1) * i • B, · · · , A (n) i ))
.
Then replacing Re([S] i , m 1 ) • A (1) * i with A *
Si would yield:
1 = arg min B L e (MLP(A * Si • B, A (2) i , · · · , A (n) i )).
Again, by the first-order optimality condition, we have Equation (16).</p>
<p>With Theorem 3.2, we could transform the intractable constraint in Equation (8) into the differentiable term subject to the first layer of MLP. The detailed formulation in the nonlinear setting can be expressed as:
min fS e∈E L e (f S ) + λ e∈E d i=1 ∂L e (MLP(A Si • B, A (2) i , · · · , A (n) i )) ∂B B=1 2 2 , s.t. h(W θ (f S )) = 0.(19)
This objective function also potentially uses f S to both incorporate f and the invariant structure matrix S.</p>
<p>THEORETICAL ANALYSIS</p>
<p>In this section, we aim to provide the sufficient conditions for identifiability of DICD in the linear SEM systems. We will leave the discussion about which assumptions can or cannot be further relaxed in future work. (1), if for any X i ∈ V that is not the source node, there exist two environments e 1 , e 2 ∈ E, such that:</p>
<p>Theorem 4.1. For linear SEMs systems with Gaussian additive noises as in Equation
V ar(z e1 i ) = V ar(z e2 i ),(20)∀X j ∈ V{X i }, V ar(z e1 j ) = V ar(z e2 j ),(21)
where V ar(·) represents the variance, z e1 j and z e2 j are the additive noise from P a(X j ) to X j in e 1 and e 2 , respectively. Then the causal structure is identifiable.</p>
<p>Here we emphasize that the graph and the coefficients that satisfy the following sufficient conditions and Equation (6)(7)(8) will be exactly the true causal graph and the true coefficients, corresponding to the identifiable graph.</p>
<p>Theorem 4.1 indicates that our DICD is guaranteed to retrieve the true causal graph in linear systems, when the diversity of environments is adequate.</p>
<p>The assumptions in Theorem 4.1 are restrictive mainly because Equation (21)) requires that the variances of the nodes other than X i to be the same across environments e 1 and e 2 . In our proof, Equation (21) is only used for proving Lemma 4.2. However, we will show that, even if we don't assume Equation (21), we may still obtain Equation 32 in the proof of Lemma 4.2 below, which leads to the proof of Lemma 4.2.</p>
<p>With Equation (31), we know the sufficient and necessary condition ofŵ e1 j0 =ŵ e2 j0 is:
E e1 [X i X j0 ] − k∈P as(i){j0}ŵ e k E e1 [X k X j0 ] E e1 [X 2 j0 ] = E e2 [X i X j0 ] − k∈P as(i){j0}ŵ e k E e2 [X k X j0 ] E e2 [X 2 j0 ]
.</p>
<p>Since we do not have Equation (21)), every single term in the above equation is not necessarily equivalent. The probability of the combinations of all these non-equivalent terms being equivalent is very small. Thus during the implementation, Lemma 4.2 is easy to be true. Then the other parts of the proof of Theorem 4.1 will remain the same. Next, we provide the proof skeleton of Theorem 4.1 and leave the full proof in Appendix A.</p>
<p>There are three main steps in our proof. First, we prove that if the causal structure is correct, then the optimal coefficients are the ground truth coefficients (Lemma 4.1). Second, we show that the stable graph (see definition 4.1) with the minimal sum of reconstruction loss from all environments is exactly the true graph (Theorem 4.2). In the end, we can prove that our algorithm could yield the ground truth graph and coefficients with adequate environments.</p>
<p>To begin with, we give the following lemma to show that our DICD could yield the true coefficient in the linear SEM under the true causal structure. Lemma 4.1. Given the true graph G 0 , the corresponding structure S 0 is the adjacency matrix of G 0 . ∀e ∈ E, we denote the optimal parameters for the coefficients in environment e as:
W e = arg min W L e (S 0 • W), s.t. G(S 0 ) = G(W).(22)
Then we haveŴ e = W 0 , ∀e ∈ E, where W 0 is the ground truth coefficients.</p>
<p>The following definitions are necessary for the rest of this section. 
G(S) = G(W) = G, W = arg min W L e (S • W), ∀e ∈ E,(23)
then we call G a stable graph.</p>
<p>Definition 4.2.</p>
<p>For two nodes X 1 and X 2 in a DAG, if X 2 is reachable from X 1 , then X 1 is a predecessor of X 2 . We denote all the predecessors of X 2 in graph G 0 as P re 0 (X 2 ).</p>
<p>With Definition 4.1, we further denote the parents of the variable X i in G 0 as P a 0 (X i ) and the corresponding indexes as P a 0 (i). We propose the following Lemma 4.2 to demonstrate that the causal directions between any two variables cannot violate each other in any stable graph and the true causal graph, which could serve as the preconditions in Theorem 4.2 to prove it.</p>
<p>Lemma 4.2.</p>
<p>For any given stable graph G s , if we assume the conditions in Theorem 4.1 hold, then ∀X i ∈ V which is not a source node, we have X i / ∈ P re 0 (X j ) for any X j ∈ P a s (X i ).</p>
<p>Finally, Theorem 4.1 can be implied by the following theorem:</p>
<p>Theorem 4.2. For any given stable graph G s and the ground truth graph G 0 , we denote their corresponding structures as S 0 and S s , respectively. We further denote their corresponding consistent optimal parameters as W s and W 0 , respectively. Then we have:
e∈E L e (S 0 • W 0 ) ≤ e∈E L e (S s • W s ),(24)
and the equation holds only for W 0 = W s .</p>
<p>The proof of Theorem 4.2 is given in Appendix A. Theorem 4.2 imples that, with the conditions in Equation (7) and Equation (8), The ground truth graph will be yielded by Equation (6).</p>
<p>EXPERIMENTS</p>
<p>In this section, we study the empirical performance of our proposed method. We aim to answer the following research questions:</p>
<p>• RQ1: How does DICD perform compared to the previous methods in both linear and nonlinear settings? • RQ2: How do DICD and other baselines perform with various factors (i.e., the number of environments, density of graph). • RQ3: How does DICD perform on real-world datasets compared with other applicable baselines?</p>
<p>Experimental Settings</p>
<p>We now provide the detailed settings for our experiments. The descriptions for the synthetic datasets and the realworld dataset are in Section 5.1.4 and Section 5.1.5, respectively. For all the experiments in this paper, we all generate 10 datasets for each graph setting and report the mean and standard deviation.</p>
<p>Baselines</p>
<p>We select four state-of-the-art causal discovery methods for comparison:</p>
<p>• CD-NOD [21] is a constrained-based causal discovery method designed for heterogeneous datasets, i.e., datasets from different environments. CD-NOD utilizes the independent changes across environments to determine the causal orientations, and proposes constrained-based and kernel-based methods to find the causal structure.</p>
<p>• NOTEARS [1] is specifically designed for linear setting, and is also the backbone of DICD in linear cases. NOTEARS estimates the true causal graph by minimizing the reconstruction loss with the continuous acyclicity constraint. We re-implement NOTEARS with replacing the L-BFGS-B iteration with Adam gradient descent, which could yield compatible performance and more importantly, could be deployed on GPU.</p>
<p>• NOTEARS-MLP [10] is specifically designed for nonlinear setting, which also serves as the foundation of DICD in nonlinear situations. NOTEARS-MLP approximates the generative SEM model by MLP while only constraining the first layer of the MLP with the continuous acyclicity constraint.</p>
<p>• DAGGNN [7] formulates causal discovery with variational autoencoder, where the encoder and decoder are all graph neural networks. Choosing the evidence lower bound as the loss function and slightly modifying the acyclicity constraint, DAGGNN could manage to recover the weighted adjacency matrix.</p>
<p>• NOCURL [12] utilizes a two-step procedure: first find an initial cyclic solution, then employ Hodge decomposition of graphs and learn an acyclic graph by projecting the cyclic graph to the gradient of a potential function.</p>
<p>• DARING [18] imposes explicit residual independence constraint with an adversarial strategy. We choose the backbone as NOTEARS-MLP to conform with the settings above.</p>
<p>Hyperparameter Settings</p>
<p>For linear settings, there are two hyper-parameters in total: λ 1 for the l 1 -norm regularization term; λ D for the DICD penalty term. We tune λ 1 in {0.01, 0.1} for NOTEARS and DICD. Besides, we tune λ D in {0.1, 1} for DICD. Then for nonlinear settings, there are three hyper-parameters in total: λ 1 , λ 2 , λ D , among which λ 1 and λ 2 are for the l 1 -norm and l 2 -norm regularization terms, respectively. We tune λ 1 , λ 2 both in {0.01, 0.1} and λ D in {0.1, 1}. The scheduler for λ in Equation (14) and Equation (19) is shown as follows:
λ =            k K/3 • λ D k ≤ K/3 λ D K/3 ≤ k ≤ 2K/3 K − k K/3 • λ D k ≥ 2K/3 ,
where K is the estimated total step, and k is the current iteration. The intuition behind this scheduler is that we need to let the model fit the data at the beginning, then as the training process goes, we need to enforce our penalty to help find the true causal graph. Then for the last stage, the graph structure has almost been inferred. We need to gradually remove our penalty to let the structural causal function with the given structure fit the data.</p>
<p>Evaluation Protocols</p>
<p>We use the three most popular metrics in causal discover: false discovery rate (FDR), true positive rate (TPR) and structural Hamming distance (SHD). Higher TPR stand for better performances, while FDR and SHD should be lower to represent the better strategies.</p>
<p>Synthetic Datasets</p>
<p>We conduct experiments on two synthetic datasets for linear and nonlinear settings. Besides, we apply our method DICD on Colored MNIST [32] dataset to explore its effectiveness on real-world datasets. As for the synthetic data, the ground truth DAG is generated from two random graph models: Erdos-Renyi (ER) and scale-free (SF), following [10]. For the overall experimental comparison, we set the node degree as four. For the linear and nonlinear setting, we construct the environment variable E to simulate the effects of the environments on the additive noises. For the linear setting, after generating the graph, we randomly select 0.3 * d nodes in this graph, and then build 0.3 * d new nodes. We call these new variables as the environment variables and denote them as E, and they satisfy the same distributions and are all independent from each other. Then we create 0.3 * d edges from each environment node to the each selected node. In this way, we could simulate different environments with varying the distribution of the environment variables E.</p>
<p>Then given this new graph with d + 0.3 * d nodes, we simulate random edge weights to obtain a new matrix W ∈ R (d+ 0.3 * d )×(d+ 0.3 * d ) . With W, we sample X = W T X + z ∈ R d+ 0.3 * d with z from Gaussian noise model to generate 10 random datasets X e ∈ R n×(d+ 0.3 * d ) . Then we remove the column corresponding to the additional 0.3 * d environment variables E to generate the final datasets X ∈ R n×d . We change the variances of the noises of the environment variables E to simulate different environments. In the nonlinear setting, after generating the graph, we randomly select 0.5 * d nodes in the graph, and then create 0.5 * d environment nodes and also 0.5 * d edges from each environment node to the selected node. Then given this new graph, we simulate the SEM X j = F j (X pa(j) ) + z j for all j ∈ {1 · · · , d + 0.5 * d } in topological order. For the environment variables, we vary the distributions of the noises in different environments. Then for the other nodes, we set the distribution of the noises as N (0, 1). We choose f j to be Additive Noise Models with two-layer MLPs. We will also remove the column corresponding to the variable E to generate the datasets X ∈ R n×d .</p>
<p>Real-world Dataset</p>
<p>For the real-world dataset, We sample 10000 images in total, and 2000 images for each environment. We classify MNIST digits from 2 classes, where classes 0 and 1 indicate original digits (0,1,2,3,4) and (5,6,7,8,9). Then for each environment, we select the ratio of class 0 being green, which is shown in the "Ratio" column in Table 3. Then the noise variances(i.e. noise scale) for each environment are provided in the "Noise Scale" column in Table 3.</p>
<p>Overall Performances (RQ1)</p>
<p>We present the overall performances of DICD and the baselines for fair comparison. In the baselines, NOTEARS, DAGGNN, NoCurl, DARING are run on the concatenated datasets from all the environments. CD-NOD is run with the environment-id corresponding to each sample.</p>
<p>Linear Synthetic Data</p>
<p>In this experiment, we explore the improvements when introducing different groups by comparing the DAG estimations against the ground truth structure. We simulate {ER4, SF4} graphs with d = {10, 20, 50, 100} nodes. For   Table 2 and Table 6 summarizes the results when the number of nodes equals to {10, 20, 50, 100}. From these tables, we could have the following key observations: (1) DICD has outperformed all other baselines across various settings. More precisely, DICD achieves significant improvements over the strongest baselines by up to 36% in SHD (10 nodes, ER graph). (2) Generally, DICD has the lower FDR and higher TPR, which also coincides with the intuition that DICD could eliminate spurious correlations and reveal the true ones.</p>
<p>Nonlinear Synthetic Data</p>
<p>We  Table 4 and results with d = 100 are shown in Table 7. From these tables, we could find: (1) DICD consistently outperforms other baselines in all eight settings upon the most crucial metric SHD. The improvements on SHD over the best baseline are up to 29% (50 nodes, ER graph). (2) DICD achieves compatible FDR with NOTEARS but far higher TPR. This shows that in the nonlinear setting, DICD is better at revealing the true causal correlations that might have been missed by NOTEARS. (3) The over-reconstruction problem still exists in other methods, while DICD has the potential to mitigate it, which could be the reason for the performance improvements. (4) CD-NOD performs fairly well in nonlinear cases, which means the multi-environment setting might be more helpful when the correlations between variables are more complicated. However, CD-NOD consumes in average more than 9 hours in the simplest setting (10 nodes), and more than 300 hours in the case of 50 nodes, which is far more expensive than our algorithm. As shown in Table 5, we only record the running time of CD-NOD in nonlinear settings, since its running time is almost unacceptable in these cases. Then we report the averaged running time for different seeds and different graph types (ER or SF). From the table, we can observe that CD-NOD is very expensive for nonlinear cases, while the running time of DICD almost remain constant when the number of nodes get larger.</p>
<p>Study of Various Factors (RQ2)</p>
<p>In this section, we discuss various factors that may affect the performances of DICD and other methods. Due to limit of space, we discuss the effect of environmental imbalance in Appendix 5.3.2.  Figure 1, we can observe: (1) When the number of environments is greater than 4 in the linear setup, more environments will not yield to better results, which means for simple structure equation models, four environments may have already ruled out the possibility of incorrect graphs. (2) In the nonlinear setting, it is amazing to   find that DICD could achieve better performance even there is only one environment. The reason could be that when there are more parameters in the function, the explicit constraint on the optimality of the parameters could contribute much to learning the best graph, which is more likely to be the ground truth graph. (3) More environments in nonlinear settings could degrade the performance of all approaches; the reason for this could be that heterogeneous noises can be particularly unfriendly when the relationships between variables become quite intricate.</p>
<p>The Effect of Environment Number</p>
<p>The Effect of the Imbalance between Different Environments</p>
<p>Since the imbalance of data is the major problem in machine learning, we aim to explore how the imbalance of data size between different environments would affect the  (2) In both linear and nonlinear settings, the balanced situation is the best for DICD, which means we have enough information from every environment. (3) Even there is only one group, DICD could make significant improvements against NOTEARS, which coincides with the discovery in Section 5.3.1.</p>
<p>The Effect of Density of Graph</p>
<p>We aim to discover how much the node degree (i.e., density) will affect our algorithm compared to the other baselines. We choose SF graph with d = 20 for this case study. In the linear setting, we generate samples from five environments, 200 samples for each. And for nonlinear settings, we draw samples from two environments, 1000 samples for each. The x-axis represents the mean degree of the nodes in the generated graph. For instance, Node degree = 10 means there are 200 edges in total when generating the SF graph. from Figure 4, we could observe: (1) DICD almost  consistently outperforms the other methods, except for few cases.</p>
<p>(2) As the node degree (i.e., the density) increases, especially in nonlinear settings, the improvements of DICD over baselines get larger, which means DICD could better adapt to the denser settings.</p>
<p>Real Data (RQ3)</p>
<p>Finally, we evaluate our method on the real-world data:</p>
<p>ColoredMNIST. Our method, as well as NOTEARS-MLP, could be simply extended to the setting of vector-valued variable. DAG-GNN is already designed to work in this situation. However, DARING do not discuss this situation in the paper. Though it seems that DARING could also be generalized to vector-valued, efforts need to be taken. Thus we omit it as comparison in this section. As stated earlier in Section 5.1.5, we sample 10000 images from the MNIST dataset and generate the colored version of MNIST.</p>
<p>In the pictures, we have kept the digits to be black, while the background has the color red or green. The images are resized to 8*8, and then flattened to yield a 64-dim vector. The label vector and color vector are set to be all zeros or all ones (according to the original label) with dimension as 64. Then during searching (or training) we only consider the possible correlations among the white backgrounds, colors, noises, and digits. Thus we have four variables in the designed task. As shown in Figure 3. We could find NOTEARS, DAGGNN and NoCurl all make mistakes, while DICD gives reasonable predictions.</p>
<p>RELATED WORK</p>
<p>Causal Discovery has caught enormous attention recently. We will mainly discuss the differentiable score-based algorithms and the works considering multi-environments.</p>
<p>Differentiable Score-based algorithms. Score-based causal discovery methods aim to find the causal structure by optimizing a carefully defined score function via various modelling methods. Though there are conventional methods [33], [34], [35], [36], [37] applying various techniques such as hill-climbing [38] and integer programming [39], the differentiable methods using gradient descent show stronger power. NOTEARS [1] reformulate the causal discovery problem with acyclicity constraint as a continuous program. DAG-GNN [7] proposes a variant of the acyclicity constraint and solves the generalized linear SEM in a graph autoencoder structure. NOTEARS-MLP [10] and GRAN-DAG [9] extend the continuous acyclicity regularization into a neural network and achieve better results in the nonlinear settings. RL-BIC [8] introduces RL to find the DAG with the best BIC score. DARING [18] proposes to constrain the independence between the residuals and adopts an adversarial training strategy. DAG-GAN [40] formulates the problem of DAG structure learning from the perspective of distributional optimization. [41] shows that applying soft sparsity and DAG constraints would be enough. There are also other works that apply some alternatives of the continuous acyclicity regularization. DAG-NOFEAR [42] propose the constraint term that only depends on the absolute value of the adjacency matrix W, instead of W W in h(W) in Equation (9), which is correlated to l1 penalty and sparsity. NOCURL [12] aims at eliminating the DAG constraint entirely, by showing that the set of weighted adjacency matrices of DAGs are equivalent to the set of weighted gradients of graph potential functions. NODAG [43] proposes to solve an l 1 -penalized optimization, while ENCO [44] provides convergence guarantees without constraining the score function with respect to acyclicity. These methods all have their own strategies to control the acyclicity.</p>
<p>Previous work considering multi-environments.</p>
<p>Most work with multi-environment settings are built on constraint-based methods [21], [45], [46], [47], [48]. Although they achieved lots of improvements, there are some major limitations: 1) may have overly strict domain definition [19]; 2) limited to linear cases only [20], [22], [23]; 3) designed to solve much simpler problems than CD such as causal direction identification [23], [24]; 4) may involve a large number of independence tests and be very time-consuming [20], [21], which is also the general problem of constrain-based methods. However, We define the environments following [14], [20], [22], and our method is capable of solving the general causal discovery problems in both linear and nonlinear cases. There is another interesting and more general task called Federated Causal Discovery [49], [50], [51], [52], [53], which aims to solve the problem about decentralized datasets. Though our targets are different, the algorithms are somewhat similar.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>Despite the great success in causal structure learning, today's differentiable causal discovery methods are still suffering from non-identifiability issue and over-reconstruction problem from observation data. Utilizing the inherent heterogeneity when environment partition is provided in advanced is not yet discussed in the differentiable causal discovery task. In this paper, we proposed a simple yet effective Differentiable Invariant Causal Discovery (DICD) method to tackle the challenge by incorporating the multi-environment information. Our main idea is that, given the true causal graph, the parameters of SEM learned from different environments should remain consistent. Theoretical guarantees for the identifiability of proposed DICD are provided under certain assumptions about the environments. The extensive experimental results demonstrate the effectiveness of DICD. One limitation of DICD is the requirement of prior knowledge of the environment. In the future study, we will  explore the end-to-end causal discovery technique with environment inference, i.e., directly infer partitions of training data without access to environment label. We believe that the idea of this work, i.e., invariant learning inspired causal discovery, provides a potential research direction and will inspire more valuable works for learning identifiable DAG from observation data. </p>
<p>APPENDIX</p>
<p>BASIC STRUCTURE EXAMPLE</p>
<p>In this section, we provide another example shown in Table  8 to demonstrate our motivation introduced in Section 1. In this table, the blue graphs denote the ground truth, while graphs with red edges are the wrong edges in the wrong structures. Below the structures, the first number in front of the parenthesis refers to the least reconstruction loss(||XW − X|| 2 ) given the structure in the same column of Table 8. Given the structure, we can use the structure to constrain which of the elements in W should be nonzero elements and others are not. Then we can learn the optimal parameters for these non-zero elements. As shown in the Table, the numbers in the parenthesis refer to the optimal parameters for the edges between A-B, B-C, A-C, respectively. From this table, we can find that with wrong causal structures which have the potential to obtain lower reconstruction loss (i.e., over-reconstruction), the parameters learned given these structures are not consistent across different environments. Thus with the condition given by DICD, we can rule out wrong graphs.</p>
<p>NOTATIONS</p>
<p>We provide the meanings of all the notations used in this paper in Table 9.</p>
<p>PROOF OF THEOREM 4.1</p>
<p>To begin with, we provide the notations used in this proof. We denote the set of all variables as {X 1 , · · · , X d }, and the vector variable [X 1 , · · · , X d ] is denoted as X in this section. The set of parent nodes of X i is denoted as P a(X i ), while the index set of P a(X i ) is denoted as P a(i).</p>
<p>First of all, we prove Lemma 4.1 to show that our DICD could yield the true coefficient in linear systems under the true causal structure.</p>
<p>Proof. We consider the linear regression coefficientŴ e for every environment e. The regression process in Equation (22) is equivalent to performing the regression for every node X m , m ∈ {1, · · · , d} from its parents P a(X m ).</p>
<p>We incorporate the environment information into the expectation operator E e . The coefficients of the node X m is denoted as: 
[Ŵ e ] m = arg min w E e ||X m − (w • [S 0 ] m ) X||,(25)[Ŵ e ] m = E e [X m ([S 0 ] m • X)[(S 0 ] m • X) −1 [S 0 ] m • X].
For simplicity, we denote [S 0 ] m • X as X S0m . We extract the m-th column of W 0 as [W 0 ] m , and the true generation process for X m could be expressed as:
X m = [W 0 ] m X + z m ,(26)
where z m ∼ N (0, (σ e m ) 2 ). Then as [W 0 ] is the ground truth coefficients, [W 0 ] should be consistent with the graph G 0 , as well as the structure S 0 . Thus we have: S0m . Thus the generation process in Equation (26) could be rewritten as:
W 0 = S 0 •W 0 , which indicates [W 0 ] m X = [S 0 ] m • [W 0 ] m X = [W 0 ] m XX m = [W 0 ] m X S0m + z m .(27)
Then we can substitute Equation (27) into Equation (25) to obtain:
[Ŵ e ] m = E e [([W 0 ] m X S0m + z m )(X S0m (X S0m ) ) −1 X S0m ].
Since z m is an independent additive noise, we can remove z m in the above equation and yield:</p>
<p>[
Ŵ e ] m = E e [([w 0 ] m X S0m )(X S0m (X S0m ) ) −1 X S0m ] = E e [(X S0m (X S0m ) ) −1 X S0m X S0m ][W 0 ] m = [W 0 ] m .(28)
Note that [W 0 ] m X S0m is a scalar. We adopt the rule , where a, 
(a · b)c = (c · b T ) · a[W 0 ] m .
Since m is any number in {1, · · · , d}, we havê W e = W 0 . The lemma is proved.</p>
<p>With Definition 4.1, we further denote the parents of the variable X i in G 0 as P a 0 (X i ) and the corresponding indexes as P a 0 (i).</p>
<p>Lemma 4.2 demonstrates that the causal directions between any two variables cannot violate each other in any stable graph and the true causal graph. And we give the proof as following:</p>
<p>Proof. To prove the lemma, we only need to show that given any X i ∈ {X 1 , · · · , X d } without being the source node, if ∃ X j such that:</p>
<p>X j ∈ P a s (X i ), X i ∈ P re 0 (X j ).</p>
<p>Then G s cannot be a stable graph. To achieve this, we need to incorporate the information of the environment e. Given j satisfying Equation (29), we aim to find j 0 such that: X j0 ∈ P a s (X i ), z j0 ⊥ P a s (X i )\X j0 .</p>
<p>Suppose there exists j satisfying Equation (29), we will find j 0 with the following process: (1) Set j 0 to be j;</p>
<p>(2) If ∃ X k ∈ P a s (X i ) such that there exists the path from X j0 to X k , then we set j 0 to be k. In this step, the condition X i ∈ P re 0 (X j0 ) still holds. If there is no such X k ∈ P a s (X i ) satisfying the above condition, we will exit the iteration.</p>
<p>In this iteration, we always have X i ∈ P re 0 (X j0 ). Also, with the above process, we know that ∀ X k ∈ P a s (X i ){X j0 }, X j0 / ∈ P re 0 (X k ), which means: z e j0 ⊥ X k |∀k ∈ P a s (i){j 0 }.  (∼ N (0, 4)), B = A/2 + z B (∼ N (0, 1)), C = A + B/2 + z C (∼ N (0, 4)). Environment 2: A = z A (∼ N (0, 4)), B = A/2 + z B (∼ N (0, 4)), C = A + B/2 + z C (∼ N (0, 1)). Note that only the variance of z B is different in two environments.  R n×d , observational data x j R n , observational data corresponding to the j-th variable X j j-th node variable F ground truth structure function F j ground truth structure function corresponding to X j f estimated structure function f j estimated structure function corresponding to X j Pa(X j ) parent set of X j Pa(j) the index set of the parents of X j z j additive noise of X j σ 2 j variance of z j G(·) corresponding graph of · W R d×d , the coefficients for all edges of G(f ) in linear situations m l the number of hidden units in the l-th layer in MLP S {0, 1} d×d invariant structure model Now since the result of the regression from P a s (X i ) to X i is exactly the m-th column ofŴ e , we denote the result of the regression based on Equation (23) 
w k X k − X i 2 2 ,
s.t. w j = 0, j ∈ {1, · · · , d}\P a s (m).</p>
<p>Then the optimal value for w j0 is:
w e j0 = E e [X i X j0 ] − k∈P as(i){j0}ŵ e k E e [X k X j0 ] E e [X 2 j0 ] .(31)
According to the conditions of theorem 4.1, there exist two distinct environments e 1 , e 2 ∈ E such that V ar(z e1 j0 ) = V ar(z e2 j0 ) and for any other node X i , i.e., i = j 0 , we have V ar(z e1 i ) = V ar(z e2 i ). Hence in the right term in Equation (31), with X i ⊥ z j0 (according to the condition X i ∈ P re 0 (X j0 )), and ∀k ∈ P a s (i){j 0 }, z e j0 ⊥ X k in Equation (30), we could have:
E e1 [X i X j0 ] = E e2 [X i X j0 ], ∀k ∈ P a s (X i ){j 0 }, E e1 [X k X j0 ] = E e1 [X k X j0 ].
If there exists k ∈ P a s (i){j 0 } such thatŵ e k is different across e 1 and e 2 , then G s is already not stable, which raises the contradiction. Otherwise, ifŵ e1 k =ŵ e2 k , ∀k ∈ P a s (i){j 0 }, then since E e1 [X 2 j0 ] = E e2 [X 2 j0 ], we will havê w e1 j0 =ŵ e2 j0 ,</p>
<p>indicating G s is not a stable graph. The contradiction still exists. Thus we can have the conclusion: If G s is a stable graph, then ∀X j ∈ P a s (X i ), we have X i / ∈ P re 0 (X j ). The lemma is proved. Now we give the proof of Theorem 4.2. Since it's written from Theorem 4.1 with Definition 4.1, then Theorem 4.1 will also be proved.</p>
<p>Proof. Note that in this case W 0 is the optimal parameters for G 0 , and thus it is also the true coefficients for data generation. (as shown in Lemma 4.1.)</p>
<p>To prove Theorem 4.1, we will split the regression loss in Equation (22) to the specific loss value in every environment and every node except source nodes. In other words, we illustrate that for any environment e ∈ E, L e (S 0 • W 0 ) ≤ L e (S s • W s ), which could directly lead to Equation (24). Hence, in the following part, with a slight abuse of notation, we will omit the subscript e. We will show that ∀ X i ∈ V, where V is the node set, the regression loss from P a(X i ) to X i in G s is larger or equal than in G 0 , with the equaling condition holds when:</p>
<p>i-th column(W 0 ) = i-th column(W s ).</p>
<p>Given any X i ∈ V, i ∈ {1, · · · , d}, we denote all the parents of X i in G s , G 0 as P a s (X i ), P a 0 (X i ) and the corresponding indexes of its parents as P a s (i), P a 0 (i), respectively. Then the true generation process for the variable X i could be denoted as:
X i = k∈P a0(i) [W 0 ] ki X k + z i ; z i ∼ N (0, σ 2 i ).(34)
When performing regression from P a s (X i ) to X i , we need to constrain G(W s ) = G s , which means [W s ] ki = 0|∀k ∈ {1, · · · , d}\P a s (i).</p>
<p>We denote the minimal loss and the optimal elements as L s i = min
{w k |k∈P as(i)} E X i − k∈P as(i) w k X k 2 2 ,(35)
{w * k |k ∈ P a s (i)} = arg min where {w * k |k ∈ P a s (i)} is a set and its elements are exactly the corresponding elements of [W s ] i , i.e., the non-zero elements of i-th column of W s .</p>
<p>for the nonlinear setting. Besides h(W) = tr(e W•W ) − d. Here, • refers to the Hadamard product (aka. the element-wise product), and tr(e W•W ) is the trace of e W•W .</p>
<p>Definition 4. 1 .
1For a given graph G, if there exist S, W such that:</p>
<p>Fig. 1 .
1SHD w.r.t. the number of environments.performances of our method and other baselines. The total number of samples in this dataset is 1000 for linear settings and 2000 for nonlinear settings. We choose ER graphs with d = 20 and s 0 = 4d = 80 for this case study. The noises for the variable E in two environments are set to be {0.2, 0.4}. Then the ratio inFigure 2means the percentage of the samples from the first environment. From this figure, we could have the following observations: (1) In most of the settings, DICD outperforms other methods consistently, except when the data is higher imbalanced in linear setting, where there is almost only one environment.</p>
<p>Fig. 2 .
2SHD for different percentage of imbalance between two environments in linear and nonlinear settings.</p>
<p>Fig. 3. Revealed graph by different methods on Real World Data</p>
<p>Fig. 4 .
4SHD for different density conditions.</p>
<p>are with University of Science and Technology of China. Email: yuw164@ucsd.edu, xiangwang1223@gmail.com, xiangnanhe@gmail.com. • A. Zhang, T. Chua are with Sea-NExt Joint Lab from National University of Singapore. Email: an zhang@nus.edu.sg, dcscts@nus.edu.sg. • Y. Yuan is with The Hong Kong Polytechnic University. Email: yancheng.yuan@polyu.edu.hk. • Correspondonce to A. Zhang.</p>
<p>environment information, which impacts the distributions of additive noises. Applying ERM on these environments separately results in different functions when there exist spurious correlations in the causal graph. This inspires us to exclude such unstable edges towards a robust DAG across environments.00 (0.25, 0.50, 0.00) 
e 1 
5.05 (0.24, 0.50, 0.10) 
4.57 (-0.23, 1.38, -1.54) 
5.12 (0.07, 0.29, 0.00) 
7.00 (0.25, 0.50, 0.00) 
e 2 
7.06 (0.24, 0.50, 0.06) 
6.59 (-0.24, 1.36, -1.44) 
7.17 (0.14, 0.18, 0.00) 
11.00 (0.25, 0.50, 0.00) 
e 3 
11.06 (0.24, 0.50, 0.03) 
10.59 (-0.24, 1.35, -1.39) 11.21 (0.18, 0.11, 0.00) </p>
<p>TABLE 2 Linear
2Setting, for ER and SF graphs of 10, 20, 50 nodes10 nodes 
20 nodes 
50 nodes 
ER4 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD </p>
<p>CD-NOD 
0.48±0.06 0.17±0.02 33.5±0.9 
0.48±0.19 0.11±0.02 75.7±5.0 
0.56±0.08 0.15±0.06 
195.0±8.0 
NOTEARS 
0.07±0.01 0.78±0.02 10.1±0.8 
0.20±0.03 0.71±0.08 35.9±7.4 
0.27±0.04 0.78±0.03 
96.7±13.7 
DAGGNN 
0.08±0.01 0.86±0.02 
7.6±0.9 
0.34±0.04 0.79±0.05 48.3±7.1 
0.36±0.03 0.86±0.03 122.3±14.6 
NOCURL 
0.14±0.01 0.81±0.01 
9.8±0.4 
0.19±0.02 0.92±0.01 22.3±2.4 
0.31±0.02 0.94±0.01 
89.5±9.5 
DARING 
0.08±0.01 0.81±0.03 
9.3±1.3 
0.38±0.07 0.58±0.07 60.9±9.9 
0.48±0.01 0.60±0.06 
187.6±4.9 
DICD 
0.03±0.01 0.88±0.02 
4.9±1.0 
0.16±0.03 0.89±0.04 19.7±5.8 
0.26±0.02 0.89±0.06 
82.0±5.3 </p>
<p>SF4 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD </p>
<p>CD-NOD 
0.36±0.10 0.19±0.02 25.0±1.4 
0.34±0.05 0.18±0.01 59.3±0.9 
0.38±0.04 0.15±0.01 
168.3±1.7 
NOTEARS 
0.04±0.04 0.81±0.02 
6.1±1.1 
0.19±0.01 0.77±0.02 27.1±1.5 
0.17±0.01 0.83±0.01 
60.7±2.5 
DAGGNN 
0.07±0.03 0.98±0.02 
2.9±1.5 
0.27±0.03 0.84±0.02 31.6±2.6 
0.26±0.02 0.88±0.01 
80.6±8.3 
NOCURL 
0.06±0.02 0.86±0.02 
4.8±1.1 
0.25±0.01 0.86±0.01 28.2±1.3 
0.26±0.08 0.93±0.05 
71.8±10.6 
DARING 
0.17±0.04 0.86±0.07 
9.0±2.7 
0.26±0.02 0.80±0.01 32.6±1.8 
0.28±0.02 0.87±0.01 
87.3±5.9 
DICD 
0.05±0.04 0.98±0.02 
2.3±1.7 
0.16±0.05 0.81±0.09 22.1±8.4 
0.18±0.03 0.91±0.01 
53.7±8.7 </p>
<p>TABLE 3 Experimental
3Settings for Colored MNIST.Environment Ratio Noise Scale </p>
<p>e 1 
0.16 
10/255 
e 2 
0.32 
20/255 
e 3 
0.48 
30/255 
e 4 
0.64 
40/255 
e 5 
0.80 
50/255 </p>
<p>each environment, we generate 200 samples. We evaluate 
our methods with datasets from 5 environments, and the 
variances of Gaussian noise for the environment variable E 
in each environment are {0.2, 0.4, 0.6, 0.8, 1.0}. </p>
<p>TABLE 4
4Nonlinear Setting, for ER and SF graphs of 10, 20, 50 nodes </p>
<p>10 nodes 
20 nodes 
50 nodes 
ER4 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD </p>
<p>CD-NOD 
0.39±0.06 0.50±0.07 20.0±3.1 
0.31±0.04 0.56±0.06 56.8±4.2 
0.35±0.07 0.82±0.05 115.7±18.3 
NOTEARS-MLP 
0.24±0.10 0.44±0.12 23.8±3.5 
0.25±0.05 0.35±0.09 59.0±5.0 
0.30±0.08 0.86±0.06 102.9±25.4 
DAGGNN 
0.50±0.06 0.21±0.04 32.2±1.5 
0.61±0.07 0.24±0.05 82.9±4.5 
0.62±0.06 0.15±0.03 217.0±16.0 
NOCURL 
0.38±0.02 0.38±0.05 27.4±1.5 
0.56±0.07 0.34±0.07 80.2±7.6 
0.69±0.07 0.28±0.07 258.2±25.2 
DARING 
0.44±0.04 0.28±0.04 29.8±2.7 
0.55±0.09 0.23±0.07 77.6±5.7 
0.58±0.09 0.23±0.05 209.4±20.0 
DICD 
0.20±0.08 0.57±0.10 19.2±4.3 
0.26±0.06 0.69±0.07 40.3±6.1 
0.26±0.04 0.88±0.03 
84.4±11.7 </p>
<p>SF4 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD </p>
<p>CD-NOD 
0.42±0.03 0.68±0.04 19.5±2.5 
0.31±0.09 0.64±0.07 46.3±6.8 
0.32±0.05 0.75±0.09 104.3±12.1 
NOTEARS-MLP 
0.41±0.10 0.31±0.16 25.2±4.6 
0.29±0.10 0.56±0.10 51.0±7.4 
0.29±0.08 0.72±0.13 113.7±17.3 
DAGGNN 
0.62±0.09 0.26±0.07 31.2±3.4 
0.69±0.07 0.16±0.03 80.1±7.4 
0.64±0.03 0.15±0.05 
210.3±8.2 
NOCURL 
0.54±0.06 0.40±0.10 26.2±2.0 
0.70±0.04 0.27±0.05 87.2±3.0 
0.70±0.02 0.22±0.01 
240.8±9.3 
DARING 
0.54±0.10 0.27±0.05 29.0±2.7 
0.58±0.06 0.21±0.03 73.1±4.5 
0.53±0.03 0.19±0.02 
193.0±5.0 
DICD 
0.34±0.06 0.71±0.15 16.2±4.3 
0.27±0.06 0.68±0.15 37.9±7.1 
0.29±0.04 0.80±0.03 
99.3±9.0 </p>
<p>TABLE 5 
Running time comparison </p>
<p>10 nodes 20 nodes 50 nodes </p>
<p>CD-NOD </p>
<blockquote>
<p>9h 
64h 
300h 
DICD 
15min 
15min 
15min </p>
</blockquote>
<p>TABLE 6 Linear
6Setting, for ER and SF graphs of 100 nodesER4 
SF4 
Method 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD </p>
<p>NOTEARS 
0.17±0.03 
0.78±0.03 147.9±15.7 
0.12±0.04 0.91±0.02 
81.4±23.0 
DAGGNN 
0.23±0.03 0.79±0.04 
178.3±9.6 
0.31±0.02 0.92±0.01 195.3±20.4 
NOCURL 
0.25±0.01 0.94±0.00 
136.0±5.3 
0.14±0.04 0.98±0.01 
69.8±23.2 
DARING 
0.29±0.02 0.69±0.04 234.0±14.3 
0.29±0.01 0.90±0.01 
180.9±5.4 
DICD 
0.20±0.03 0.87±0.01 133.9±16.2 
0.12±0.03 0.97±0.01 
61.9±15.6 </p>
<p>TABLE 7 Nonlinear
7Setting, for ER and SF graphs of 100 nodesER4 
SF4 
Method 
FDR 
TPR 
SHD 
FDR 
TPR 
SHD </p>
<p>NOTEARS 
0.20±0.04 0.40±0.07 270.0±24.1 
0.17±0.06 0.42±0.10 260.1±27.3 
DAGGNN 
0.52±0.05 0.09±0.01 
390.6±7.7 
0.50±0.08 0.09±0.02 390.3±13.4 
DARING 
0.41±0.05 0.15±0.02 
367.0±8.8 
0.42±0.04 0.15±0.02 
367.3±6.9 
NOCURL 
0.62±0.06 0.23±0.02 447.2±33.0 
0.60±0.03 0.18±0.02 418.6±10.7 
DICD 
0.18±0.05 0.54±0.10 226.6±23.1 
0.18±0.03 0.53±0.06 228.0±16.3 </p>
<p>Yancheng Yuan is a research assistant Professor of Department of Applied Mathematics, The Hong Kong Polytechnic University. His research focuses on the optimization theory, algorithm design and software development, mathematical foundation of data science, and datadriven applications. He has published papers in prestigious journals and conferences, including SIOPT, JMLR, IJAA, OMS, ICML, WWW. Xiangnan He is a professor at the University of Science and Technology of China (USTC). His research interests span information retrieval, data mining, and multi-media analytics. He has over 90 publications in top conferences such as SIGIR, WWW, and MM, KDD, and journals including TKDE, TOIS, and TMM. His work has received the Best Paper Award Honorable Mention in WWW 2018 and SIGIR 2016. He is in the Editorial Board of the AI Open journal, served as the PC chair of CCIS 2019, the area chair of MM 2019, ECML-PKDD 2020, and the (senior) PC member for top conferences including SIGIR, WWW, KDD, WSDM etc. Tat-Seng Chua is the KITHCT Chair Professor at the School of Computing, National University of Singapore. He was the Acting and Founding Dean of the School during 1998-2000. Dr Chuas main research interest is in multimedia information retrieval and social media analytics. In particular, his research focuses on the extraction, retrieval and question-answering (QA) of text and rich media arising from the Web and multiple social networks. He is the co-Director of NExT, a joint Center between NUS and Tsinghua University to develop technologies for live social media search. Dr Chua is the 2015 winner of the prestigious ACM SIGMM award for Outstanding Technical Contributions to Multimedia Computing, Communications and Applications. He is the Chair of steering committee of ACM International Conference on Multimedia Retrieval (ICMR) and Multimedia Modeling (MMM) conference series. Dr Chua is also the General Co-Chair of ACM Multimedia 2005, ACM ICMR 2005, ACM SIGIR 2008, and ACM Web Science 2015. He serves in the editorial boards of four international journals. Dr. Chua is the co-Founder of two technology startup companies in Singapore. He holds a PhD from the University of Leeds, UK.Yu Wang Yu Wang is currently a first-year PhD 
student at University of California, San Diego. 
His research interests lie in Machine Learning 
and Natural Language Process. During his un-
dergraduate stage in University of Science and 
Technology of Chinan (USTC), he was awarded 
Baosteel Scholarship, Huawei Scholarship, Ex-
cellent Student Scholarship -Gold, etc. </p>
<p>An Zhang is now a research fellow at Na-
tional University of Singapore. She received her 
Ph.D. degree from the Department of Statis-
tics and Applied Probability, National University 
of Singapore, in 2021. Her areas of interest 
in research include explainable artificial intelli-
gence, causal representation learning, differen-
tiable causal discovery, and graph neural net-
works. She has publications appeared in several 
top conferences such as NeurIPS, ICLR, SIGIR. </p>
<p>Xiang Wang is now a professor at the University 
of Science and Technology of China (USTC). He 
received his Ph.D. degree from National Univer-
sity of Singapore in 2019. His research interests 
include recommender systems, graph learning, 
and explainable deep learning techniques. He 
has published some academic papers on inter-
national conferences such as NeurIPS, ICLR, 
KDD, WWW, SIGIR. He serves as a program 
committee member for several top conferences 
such as KDD, SIGIR, WWW, and IJCAI, and 
invited reviewer for prestigious journals such as TKDE, TOIS, TNNLS. </p>
<p>where [Ŵ e ] m represents the m-th column of [Ŵ e ] and [S 0 ] m is the m-th column of [S 0 ]. Then we can further express [Ŵ e ] m in Equation (25) as:</p>
<p>b, c are vectors of the same dimension in the second line. Moreover, since [W 0 ] m is independent of the environment e and the variable vector X, it can be moved out of the expectation operation. Based on Equation (28), the obtained coefficients in environment e, [Ŵ e ] m , is exactly the true causal coefficients</p>
<p>TABLE 8
8The specific confounder case in which NOTEARS[1] might make mistakes. Detailed data generation processes are as follows. Environment 1:A = z A</p>
<p>TABLE 9
9Notations and the corresponding MeaningsNotations 
Meanings </p>
<p>n 
number of the data samples 
d 
number of the variables (or nodes) 
X </p>
<p>as :
as[Ŵ e ] m = arg min [w1,···,w d ] E e w j0 X j0+ </p>
<p>k∈P as(m){j} </p>
<p>Then we define three sets of indexes as follows:I u = P a 0 (i) ∩ P a s (i),I v = P a 0 (i)\P a s (i), I k = P a s (i)\P a 0 (i).Then after substituting Equation(34)into Equation(35), we have:According to Lemma 4.1, ∀ X j ∈ P a s (X i ), we have X i / ∈ P re 0 (X j ), which means X j ⊥ z i . Thus we have z i ⊥ P a s (X i ). By definition, we have z i ⊥ P a 0 (X i ), which yield z i ⊥ {P a s (X i ) ∪ P a 0 (X i )}. Then we can rewrite the above equation as:Since the reconstruction loss for X i in the true graph G 0 , denoted as L 0 i is exactly the variance of the additive noise added on X i , i.e., σ 2 i . Thus here we already have L s i ≥ L 0 i = σ 2 i . In the following part, We will explore the conditions that make the equation hold exactly. Note that ∀j ∈ P a 0 (i), we have [W 0 ] ji = 0. Then for all the nodes in I u ∪ I v ∪ I k , there must exists a node denoted as X end ∈ I u ∪ I v ∪ I k that has no successors in I u ∪ I v ∪ I k according to G 0 . This means the noises corresponding to X end will be independent from all the other nodes in I u ∪ I v ∪ I k . Then we discuss three situations for X end to be in I u , I v , and I k , respectively:• If X end ∈ I u , we denote the index for X end as u 1 . Then we have:Then the minimum operation minin Equation(35)will directly set the optimal value of w u1 , i.e., w * u1 to be [W 0 ] u1i . • If X end ∈ I v , we denote the index for X end as v 1 . Then we have:In this case, we will have the strict inequality L s i &gt; L 0 i , which means the reconstruction loss for G s will be strictly larger than G 0 .• If X end ∈ I k , we denote the index for X end as k 1 . Then we have:Then the minimum operation min {w k |k∈P as(i)} in Equation(35)will directly set the optimal value of w k1 , i.e., w * k1 to be 0.If X end ∈ I v , then we can already have L s i &gt; L 0 i . For the other two situations, we will remove X end ∈ I u or I k to form the new set I u and I k , then find the new X end in I u ∪ I v ∪ I k to perform the above process again. According to this discussion, we could easily give the necessary and sufficient conditions for L s i to be equal to L 0 i :If not, then there must be one step of removing the current X end such that X end ∈ I v , which will directly lead to L s i &gt; L 0 i . • ∀u ∈ I u , w * u = [W 0 ] ui . • ∀k ∈ I k , w * k = 0. Now we have the optimal values: {w u |u ∈ I u } and {w k |k ∈ I k }. Besides, according to the definition of I u and I k , and I v = ∅, we have: I u ∪ I k = P a s (j) and I u = P a 0 (i). Since I k ∩ P a 0 (i) = ∅, we have: ∀k ∈ I k , [W 0 ] ki = 0.Since the structure of W s and W 0 need to be constrained to be the same as G s and G 0 , respectively, we must have:Then according to the above conditions, we have:i-th column(W 0 ) = i-th column(W s ).which is Equation(33). Since X i is any variable except source node in V, we could have W 0 = W s . (Note that for the columns corresponding to the source node, all the elements in these columns should be zero such that G(W s ) = G s and G(W 0 ) = G 0 ).We conclude the proof of Theorem 4.2.
Dags with NO TEARS: continuous optimization for structure learning. X Zheng, B Aragam, P Ravikumar, E P Xing, in NeurIPS. X. Zheng, B. Aragam, P. Ravikumar, and E. P. Xing, "Dags with NO TEARS: continuous optimization for structure learning," in NeurIPS, 2018, pp. 9492-9503.</p>
<p>Cxplain: Causal explanations for model interpretation under uncertainty. P Schwab, W Karlen, NeurIPS. 10230P. Schwab and W. Karlen, "Cxplain: Causal explanations for model interpretation under uncertainty," in NeurIPS, 2019, pp. 10 220- 10 230.</p>
<p>Pgm-explainer: Probabilistic graphical model explanations for graph neural networks. M N Vu, M T Thai, NeurIPSM. N. Vu and M. T. Thai, "Pgm-explainer: Probabilistic graphical model explanations for graph neural networks," in NeurIPS, 2020.</p>
<p>Causal protein-signaling networks derived from multiparameter single-cell data. K Sachs, O Perez, D Pe&apos;er, D A Lauffenburger, G P Nolan, Science. 3085721K. Sachs, O. Perez, D. Pe'er, D. A. Lauffenburger, and G. P. Nolan, "Causal protein-signaling networks derived from multiparameter single-cell data," Science, vol. 308, no. 5721, pp. 523-529, 2005.</p>
<p>From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data. R Opgen-Rhein, K Strimmer, BMC systems biology. 11R. Opgen-Rhein and K. Strimmer, "From correlation to causation networks: a simple approximate learning algorithm and its ap- plication to high-dimensional plant gene expression data," BMC systems biology, vol. 1, no. 1, pp. 1-10, 2007.</p>
<p>A bayesian network structure for operational risk modelling in structured finance operations. A D Sanford, I A Moosa, JORS. 634A. D. Sanford and I. A. Moosa, "A bayesian network structure for operational risk modelling in structured finance operations," JORS, vol. 63, no. 4, pp. 431-444, 2012.</p>
<p>Y Yu, J Chen, T Gao, M Yu, DAG-GNN: DAG structure learning with graph neural networks," in ICML. 97Y. Yu, J. Chen, T. Gao, and M. Yu, "DAG-GNN: DAG structure learning with graph neural networks," in ICML, vol. 97, 2019, pp. 7154-7163.</p>
<p>Causal discovery with reinforcement learning. S Zhu, I Ng, Z Chen, ICLR. S. Zhu, I. Ng, and Z. Chen, "Causal discovery with reinforcement learning," in ICLR, 2020.</p>
<p>Gradient-based neural DAG learning. S Lachapelle, P Brouillard, T Deleu, S Lacoste-Julien, ICLR. OpenReview.net. S. Lachapelle, P. Brouillard, T. Deleu, and S. Lacoste-Julien, "Gradient-based neural DAG learning," in ICLR. OpenRe- view.net, 2020.</p>
<p>Learning sparse nonparametric dags. X Zheng, C Dan, B Aragam, P Ravikumar, E P Xing, AISTATS. 108X. Zheng, C. Dan, B. Aragam, P. Ravikumar, and E. P. Xing, "Learning sparse nonparametric dags," in AISTATS, vol. 108, 2020, pp. 3414-3425.</p>
<p>Differentiable causal discovery under unmeasured confounding. R Bhattacharya, T Nagarajan, D Malinsky, I Shpitser, AISTATS. PMLR, 2021. R. Bhattacharya, T. Nagarajan, D. Malinsky, and I. Shpitser, "Dif- ferentiable causal discovery under unmeasured confounding," in AISTATS. PMLR, 2021, pp. 2314-2322.</p>
<p>Dags with no curl: Efficient dag structure learning. Y Yu, T Gao, NeurIPS 2020. Y. Yu and T. Gao, "Dags with no curl: Efficient dag structure learning," in NeurIPS 2020, 2020.</p>
<p>Principles of risk minimization for learning theory. V Vapnik, NeurIPS. V. Vapnik, "Principles of risk minimization for learning theory," in NeurIPS, 1991, pp. 831-838.</p>
<p>Invariant risk minimization. M Arjovsky, L Bottou, I Gulrajani, D Lopez-Paz, CoRRM. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz, "Invariant risk minimization," CoRR, 2019.</p>
<p>Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. S Sagawa, P W Koh, T B Hashimoto, P Liang, S. Sagawa, P. W. Koh, T. B. Hashimoto, and P. Liang, "Distribution- ally robust neural networks for group shifts: On the importance of regularization for worst-case generalization," 2019.</p>
<p>Rubi: Reducing unimodal biases in visual question answering. R Cadène, C Dancette, H Ben-Younes, M Cord, D Parikh, CoRR. R. Cadène, C. Dancette, H. Ben-younes, M. Cord, and D. Parikh, "Rubi: Reducing unimodal biases in visual question answering," CoRR, vol. abs/1906.10169, 2019.</p>
<p>Out-of-distribution generalization via risk extrapolation (rex). D Krueger, E Caballero, J Jacobsen, A Zhang, J Binas, D Zhang, R L Priol, A C Courville, in ICML, 2021D. Krueger, E. Caballero, J. Jacobsen, A. Zhang, J. Binas, D. Zhang, R. L. Priol, and A. C. Courville, "Out-of-distribution generaliza- tion via risk extrapolation (rex)," in ICML, 2021, pp. 5815-5826.</p>
<p>DARING: differentiable causal discovery with residual independence. Y He, P Cui, Z Shen, R Xu, F Liu, Y Jiang, KDD. Y. He, P. Cui, Z. Shen, R. Xu, F. Liu, and Y. Jiang, "DARING: differentiable causal discovery with residual independence," in KDD, 2021, pp. 596-605.</p>
<p>Causal inference by using invariant prediction: identification and confidence intervals. J Peters, P Bühlmann, N Meinshausen, Journal of the Royal Statistical Society: Series B (Statistical Methodology). 785J. Peters, P. Bühlmann, and N. Meinshausen, "Causal inference by using invariant prediction: identification and confidence in- tervals," Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 78, no. 5, pp. 947-1012, 2016.</p>
<p>Multidomain causal structure learning in linear systems. A Ghassami, N Kiyavash, B Huang, K Zhang, " in NeurIPS. A. Ghassami, N. Kiyavash, B. Huang, and K. Zhang, "Multi- domain causal structure learning in linear systems," in NeurIPS, 2018, pp. 6269-6279.</p>
<p>Causal discovery from heterogeneous/nonstationary data. B Huang, K Zhang, J Zhang, J D Ramsey, R Sanchez-Romero, C Glymour, B Schölkopf, JMLR. 21B. Huang, K. Zhang, J. Zhang, J. D. Ramsey, R. Sanchez-Romero, C. Glymour, and B. Schölkopf, "Causal discovery from heteroge- neous/nonstationary data," JMLR, vol. 21, pp. 89:1-89:53, 2020.</p>
<p>Learning causal structures using regression invariance. A Ghassami, S Salehkaleybar, N Kiyavash, K Zhang, A. Ghassami, S. Salehkaleybar, N. Kiyavash, and K. Zhang, "Learning causal structures using regression invariance," in NIPS, 2017, pp. 3011-3021.</p>
<p>Causal discovery and forecasting in nonstationary environments with state-space models. B Huang, K Zhang, M Gong, C Glymour, ICML. B. Huang, K. Zhang, M. Gong, and C. Glymour, "Causal discovery and forecasting in nonstationary environments with state-space models," in ICML, 2019, pp. 2901-2910.</p>
<p>FOM: fourth-order moment based causal direction identification on the heteroscedastic data. R Cai, J Ye, J Qiao, H Fu, Z Hao, Neural Networks. 124R. Cai, J. Ye, J. Qiao, H. Fu, and Z. Hao, "FOM: fourth-order mo- ment based causal direction identification on the heteroscedastic data," Neural Networks, vol. 124, pp. 193-201, 2020.</p>
<p>Causal discovery from multidomain data using the independence of modularities. J Qiao, Y Bai, R Cai, Z Hao, Neural Computing and Applicationis. 343J. Qiao, Y. Bai, R. Cai, and Z. Hao, "Causal discovery from multi- domain data using the independence of modularities," Neural Computing and Applicationis, vol. 34, no. 3, pp. 1939-1949, 2022.</p>
<p>Causal inference in statistics: A primer. J Pearl, M Glymour, N P Jewell, John Wiley &amp; SonsJ. Pearl, M. Glymour, and N. P. Jewell, Causal inference in statistics: A primer. John Wiley &amp; Sons, 2016.</p>
<p>Labeled faces in the wild: A database forstudying face recognition in unconstrained environments. G B Huang, M Mattar, T Berg, E Learned-Miller, Workshop on faces in'Real-Life'Images: detection, alignment, and recognition. G. B. Huang, M. Mattar, T. Berg, and E. Learned-Miller, "Labeled faces in the wild: A database forstudying face recognition in un- constrained environments," in Workshop on faces in'Real-Life'Images: detection, alignment, and recognition, 2008.</p>
<p>Imagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L Li, K Li, L Fei-Fei, CVPR. J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei, "Imagenet: A large-scale hierarchical image database," in CVPR, 2009, pp. 248-255.</p>
<p>Wilds: A benchmark of in-the-wild distribution shifts. P W Koh, S Sagawa, S M Xie, M Zhang, A Balsubramani, W Hu, M Yasunaga, R L Phillips, I Gao, T Lee, ICML. P. W. Koh, S. Sagawa, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Yasunaga, R. L. Phillips, I. Gao, T. Lee et al., "Wilds: A benchmark of in-the-wild distribution shifts," in ICML, 2021, pp. 5637-5664.</p>
<p>From detection of individual metastases to classification of lymph node status at the patient level: the camelyon17 challenge. P Bandi, O Geessink, Q Manson, M Van Dijk, M Balkenhol, M Hermsen, B E Bejnordi, B Lee, K Paeng, A Zhong, TMIP. Bandi, O. Geessink, Q. Manson, M. Van Dijk, M. Balkenhol, M. Hermsen, B. E. Bejnordi, B. Lee, K. Paeng, A. Zhong et al., "From detection of individual metastases to classification of lymph node status at the patient level: the camelyon17 challenge," TMI, 2018.</p>
<p>Justifying recommendations using distantly-labeled reviews and fine-grained aspects. J Ni, J Li, J Mcauley, EMNLP-IJCNLP. J. Ni, J. Li, and J. McAuley, "Justifying recommendations using distantly-labeled reviews and fine-grained aspects," in EMNLP- IJCNLP, 2019.</p>
<p>The mnist database of handwritten digit images for machine learning research. L Deng, SPM. 296L. Deng, "The mnist database of handwritten digit images for machine learning research," SPM, vol. 29, no. 6, pp. 141-142, 2012.</p>
<p>Learning bayesian networks: The combination of knowledge and statistical data. D Heckerman, D Geiger, D M Chickering, Maching Learning. 20D. Heckerman, D. Geiger, and D. M. Chickering, "Learning bayesian networks: The combination of knowledge and statistical data," Maching Learning, vol. 20, no. 3, pp. 197-243, 1995.</p>
<p>The max-min hillclimbing bayesian network structure learning algorithm. I Tsamardinos, L E Brown, C F Aliferis, Machine learning. 651I. Tsamardinos, L. E. Brown, and C. F. Aliferis, "The max-min hill- climbing bayesian network structure learning algorithm," Machine learning, vol. 65, no. 1, pp. 31-78, 2006.</p>
<p>Learning bayesian networks by hill climbing: efficient methods based on progressive restriction of the neighborhood. J A Gámez, J L Mateo, J M Puerta, Data Mining and Knowledge Discovery. 221-2J. A. Gámez, J. L. Mateo, and J. M. Puerta, "Learning bayesian networks by hill climbing: efficient methods based on progressive restriction of the neighborhood," Data Mining and Knowledge Dis- covery, vol. 22, no. 1-2, pp. 106-148, 2011.</p>
<p>Advances in learning bayesian networks of bounded treewidth. S Nie, D D Mauá, C P De Campos, Q Ji, NeurIPS. S. Nie, D. D. Mauá, C. P. de Campos, and Q. Ji, "Advances in learning bayesian networks of bounded treewidth," in NeurIPS, 2014, pp. 2285-2293.</p>
<p>Learning bayesian networks with thousands of variables. M Scanagatta, C P De Campos, G Corani, M Zaffalon, NeurIPS. M. Scanagatta, C. P. de Campos, G. Corani, and M. Zaffalon, "Learning bayesian networks with thousands of variables," in NeurIPS, 2015, pp. 1864-1872.</p>
<p>Learning optimal bayesian networks: A shortest path perspective. C Yuan, B M Malone, JAIR. 48C. Yuan and B. M. Malone, "Learning optimal bayesian networks: A shortest path perspective," JAIR, vol. 48, pp. 23-65, 2013.</p>
<p>Integer programming for learning directed acyclic graphs from continuous data. H Manzour, S Küçükyavuz, A Shojaie, abs/1904.10574CoRR. H. Manzour, S. Küçükyavuz, and A. Shojaie, "Integer program- ming for learning directed acyclic graphs from continuous data," CoRR, vol. abs/1904.10574, 2019.</p>
<p>Dag-gan: Causal structure learning with generative adversarial nets. Y Gao, L Shen, S.-T Xia, ICASSP. IEEEY. Gao, L. Shen, and S.-T. Xia, "Dag-gan: Causal structure learning with generative adversarial nets," in ICASSP. IEEE, 2021, pp. 3320-3324.</p>
<p>On the role of sparsity and DAG constraints for learning linear dags. I Ng, A Ghassami, K Zhang, NeurIPSI. Ng, A. Ghassami, and K. Zhang, "On the role of sparsity and DAG constraints for learning linear dags," in NeurIPS, 2020.</p>
<p>Dags with no fears: A closer look at continuous optimization for learning bayesian networks. D Wei, T Gao, Y Yu, NeurIPSD. Wei, T. Gao, and Y. Yu, "Dags with no fears: A closer look at continuous optimization for learning bayesian networks," in NeurIPS, 2020.</p>
<p>Learning dags without imposing acyclicity. G Varando, CoRR. G. Varando, "Learning dags without imposing acyclicity," CoRR, vol. abs/2006.03005, 2020.</p>
<p>Efficient neural causal discovery without acyclicity constraints. P Lippe, T Cohen, E Gavves, abs/2107.10483CoRR. P. Lippe, T. Cohen, and E. Gavves, "Efficient neural causal dis- covery without acyclicity constraints," CoRR, vol. abs/2107.10483, 2021.</p>
<p>Causation, prediction, and search. P Spirtes, C N Glymour, R Scheines, D Heckerman, MIT pressP. Spirtes, C. N. Glymour, R. Scheines, and D. Heckerman, Causa- tion, prediction, and search. MIT press, 2000.</p>
<p>Causal inference in the presence of latent variables and selection bias. P Spirtes, C Meek, T S Richardson, UAI. P. Spirtes, C. Meek, and T. S. Richardson, "Causal inference in the presence of latent variables and selection bias," in UAI, 1995, pp. 499-506.</p>
<p>Testing independence between linear combinations for causal discovery. H Zhang, K Zhang, S Zhou, J Guan, J Zhang, AAAI. 35H. Zhang, K. Zhang, S. Zhou, J. Guan, and J. Zhang, "Testing independence between linear combinations for causal discovery," in AAAI, vol. 35, no. 7, 2021, pp. 6538-6546.</p>
<p>Causality: Models, reasoning, and inference : Judea pearl. R Shanmugam, ISBN 0-521-77362-8Neurocomputing. 3841-4cambridge university pressR. Shanmugam, "Causality: Models, reasoning, and inference : Judea pearl; cambridge university press, cambridge, uk, 2000, pp 384, ISBN 0-521-77362-8," Neurocomputing, vol. 41, no. 1-4, pp. 189- 190, 2001.</p>
<p>Federated causal discovery. E Gao, J Chen, L Shen, T Liu, M Gong, H Bondell, abs/2112.03555CoRR. E. Gao, J. Chen, L. Shen, T. Liu, M. Gong, and H. Bondell, "Federated causal discovery," CoRR, vol. abs/2112.03555, 2021.</p>
<p>Towards federated bayesian network structure learning with continuous optimization. I Ng, K Zhang, abs/2110.09356CoRR. I. Ng and K. Zhang, "Towards federated bayesian network structure learning with continuous optimization," CoRR, vol. abs/2110.09356, 2021.</p>
<p>Integrating locally learned causal structures with overlapping variables. R E Tillman, D Danks, C Glymour, NIPS. Curran Associates, IncR. E. Tillman, D. Danks, and C. Glymour, "Integrating locally learned causal structures with overlapping variables," in NIPS. Curran Associates, Inc., 2008, pp. 1665-1672.</p>
<p>Learning causal structure from overlapping variable sets. S Triantafilou, I Tsamardinos, I G Tollis, AISTATS, ser. JMLR Proceedings. 9S. Triantafilou, I. Tsamardinos, and I. G. Tollis, "Learning causal structure from overlapping variable sets," in AISTATS, ser. JMLR Proceedings, vol. 9. JMLR.org, 2010, pp. 860-867.</p>
<p>Constraint-based causal discovery from multiple interventions over overlapping variable sets. S Triantafillou, I Tsamardinos, J. Mach. Learn. Res. 16S. Triantafillou and I. Tsamardinos, "Constraint-based causal dis- covery from multiple interventions over overlapping variable sets," J. Mach. Learn. Res., vol. 16, pp. 2147-2205, 2015.</p>            </div>
        </div>

    </div>
</body>
</html>