<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6571 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6571</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6571</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-129.html">extraction-schema-129</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-266150003</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.05180v2.pdf" target="_blank">PathFinder: Guided Search over Multi-Step Reasoning Paths</a></p>
                <p><strong>Paper Abstract:</strong> With recent advancements in large language models, methods like chain-of-thought prompting to elicit reasoning chains have been shown to improve results on reasoning tasks. However, tasks that require multiple steps of reasoning still pose significant challenges to state-of-the-art models. Drawing inspiration from the beam search algorithm, we propose PathFinder, a tree-search-based reasoning path generation approach. It enhances diverse branching and multi-hop reasoning through the integration of dynamic decoding, enabled by varying sampling methods and parameters. Using constrained reasoning, PathFinder integrates novel quality constraints, pruning, and exploration methods to enhance the efficiency and the quality of generation. Moreover, it includes scoring and ranking features to improve candidate selection. Our approach outperforms competitive baselines on three complex arithmetic and commonsense reasoning tasks by 6% on average. Our model generalizes well to longer, unseen reasoning chains, reflecting similar complexities to beam search with large branching factors.</p>
                <p><strong>Cost:</strong> 0.028</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6571.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6571.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (N-gram)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with n-gram similarity candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tree-search-based step-level decoding method that generates diverse multi-step reasoning paths via varying sampling parameters, constrained pruning, and selects final chains using an n-gram similarity scorer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search step-level decoding + N-gram scorer)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic word problems requiring multi-step arithmetic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>11.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Generates step-level branches with varied sampling (top-k, top-p, temperature) and prunes using step scores; n-gram scorer selects paths that are more similar across candidates. Diversity helps find correct chains but overall gains are modest on GSM8K versus the greedy baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6571.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (N-gram)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with n-gram similarity candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tree-search-based step-level decoding method that generates diverse multi-step reasoning paths via varying sampling parameters, constrained pruning, and selects final chains using an n-gram similarity scorer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search step-level decoding + N-gram scorer)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense questions requiring multi-step decomposition and per-step evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>59.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-2.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>PATHFINDER's N-gram scorer selects more informative branches but does not beat the LLAMA-7B self-consistency performance on StrategyQA; diversity alone isn't sufficient â€” scorer quality matters.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6571.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (N-gram)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with n-gram similarity candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tree-search-based step-level decoding method that generates diverse multi-step reasoning paths via varying sampling parameters, constrained pruning, and selects final chains using an n-gram similarity scorer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search step-level decoding + N-gram scorer)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning (CommonsenseQA)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>50.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>6.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>N-gram scorer substantially improves selection on CSQA compared to the greedy CoT baseline; authors note FLAN-T5 verifier further improves CSQA (likely due to finetuning on that data).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6571.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (FLAN-T5-XL verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with FLAN-T5-XL verifier for candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PATHFINDER generates step-level candidate reasoning chains with LLAMA-7B and uses a FLAN-T5-XL verifier model to score and rank candidates for final selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + FLAN-T5-XL (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + 3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search) + verifier-based ranking</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search + verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>11.7</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Using a stronger verifier yields small improvements on GSM8K; authors caution FLAN-T5-XL was finetuned on CSQA and GSM8K so results can be inflated on those tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6571.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (FLAN-T5-XL verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with FLAN-T5-XL verifier for candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PATHFINDER generates step-level candidate reasoning chains with LLAMA-7B and uses a FLAN-T5-XL verifier model to score and rank candidates for final selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + FLAN-T5-XL (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + 3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search) + verifier-based ranking</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search + verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>60.8</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-0.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Verifier-based ranking yields similar performance to n-gram selection on StrategyQA; PATHFINDER still does not surpass LLAMA-7B self-consistency on StrategyQA in the reported runs.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6571.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (FLAN-T5-XL verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with FLAN-T5-XL verifier for candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PATHFINDER generates step-level candidate reasoning chains with LLAMA-7B and uses a FLAN-T5-XL verifier model to score and rank candidates for final selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + FLAN-T5-XL (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + 3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search) + verifier-based ranking</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search + verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>55.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>11.8</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>FLAN-T5-XL verifier substantially boosts CSQA accuracy compared to the greedy baseline; authors attribute part of this to FLAN-T5 having been finetuned on CSQA.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6571.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (TEXT-DAVINCI-003 verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with TEXT-DAVINCI-003 (GPT-3.5 family) verifier</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PATHFINDER uses LLAMA-7B to generate step-level candidates and uses TEXT-DAVINCI-003 to evaluate faithfulness and rank candidate reasoning chains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + TEXT-DAVINCI-003 (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + ~6.7B (verifier family)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search) + external LLM verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search + verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>15.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>4.4</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Using a high-quality external verifier (TEXT-DAVINCI-003) gives the largest gains on GSM8K among tested verifiers, but authors note a runtime/resource tradeoff with GPT-3.5-based evaluators.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6571.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (TEXT-DAVINCI-003 verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with TEXT-DAVINCI-003 (GPT-3.5 family) verifier</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PATHFINDER uses LLAMA-7B to generate step-level candidates and uses TEXT-DAVINCI-003 to evaluate faithfulness and rank candidate reasoning chains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + TEXT-DAVINCI-003 (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + ~6.7B (verifier family)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search) + external LLM verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search + verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>61.7</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>TEXT-DAVINCI-003 verifier leads to small gains on StrategyQA over the greedy CoT baseline; authors highlight diminishing returns versus verifier cost.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6571.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PATHFINDER (TEXT-DAVINCI-003 verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PATHFINDER: tree-search decoding with TEXT-DAVINCI-003 (GPT-3.5 family) verifier</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PATHFINDER uses LLAMA-7B to generate step-level candidates and uses TEXT-DAVINCI-003 to evaluate faithfulness and rank candidate reasoning chains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + TEXT-DAVINCI-003 (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + ~6.7B (verifier family)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>PATHFINDER (tree-search) + external LLM verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search + verifier</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>56.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>13.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>TEXT-DAVINCI-003 verifier gives the largest reported CSQA accuracy in the paper for PATHFINDER variants, but at substantially higher computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6571.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLAMA-7B with chain-of-thought prompting, greedy token-level decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LLAMA-7B prompted with few-shot chain-of-thought examples and decoded greedily to produce reasoning traces and answers; used as the primary model baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting + greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>11.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>none (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Reported as baseline performance using greedy decoding with CoT prompts; used to compute PATHFINDER improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6571.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLAMA-7B with chain-of-thought prompting, greedy token-level decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LLAMA-7B prompted with few-shot chain-of-thought examples and decoded greedily to produce reasoning traces and answers; used as the primary model baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting + greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>61.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>none (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Baseline CoT greedy decoding result; PATHFINDER variants are compared against this baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6571.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLAMA-7B with chain-of-thought prompting, greedy token-level decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LLAMA-7B prompted with few-shot chain-of-thought examples and decoded greedily to produce reasoning traces and answers; used as the primary model baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting + greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>43.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>none (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Baseline on CSQA using CoT and greedy decoding; PATHFINDER (N-gram) improved notably over this baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e6571.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLAMA-7B (self-consistency)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLAMA-7B with chain-of-thought prompting and self-consistency majority voting over multiple CoTs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Self-consistency aggregates answers across multiple sampled reasoning chains (marginalizing answers) to pick the most consistent final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (aggregate multiple CoTs)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>15.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>4.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency substantially improves over single greedy CoT by aggregating diverse reasoning chains; paper notes PATHFINDER still lags behind self-consistency on StrategyQA in some runs.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e6571.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLAMA-7B (self-consistency)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLAMA-7B with chain-of-thought prompting and self-consistency majority voting over multiple CoTs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Self-consistency aggregates answers across multiple sampled reasoning chains (marginalizing answers) to pick the most consistent final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (aggregate multiple CoTs)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>64.8</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>3.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency improves StrategyQA accuracy over greedy CoT; PATHFINDER variants with some scorers do not surpass this in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e6571.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLAMA-7B (self-consistency)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLAMA-7B with chain-of-thought prompting and self-consistency majority voting over multiple CoTs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Self-consistency aggregates answers across multiple sampled reasoning chains (marginalizing answers) to pick the most consistent final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (aggregate multiple CoTs)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>46.9</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>3.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency yields consistent improvements; compared against PATHFINDER variants to show tradeoffs between search strategy and simple aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e6571.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FLAN-T5-XL (3B) baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-XL (3B) with chain-of-thought prompting and greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-finetuned encoder-decoder T5 variant evaluated with CoT prompts and greedy decoding; used as a baseline and as a verifier model in PATHFINDER.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FLAN-T5-XL</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting + greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>13.5</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>2.5</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>FLAN-T5-XL baseline outperforms the LLAMA-7B greedy baseline on GSM8K; also used as a verifier inside PATHFINDER.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.16">
                <h3 class="extraction-instance">Extracted Data Instance 16 (e6571.16)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FLAN-T5-XL (3B) baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-XL (3B) with chain-of-thought prompting and greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-finetuned encoder-decoder T5 variant evaluated with CoT prompts and greedy decoding; used as a baseline and as a verifier model in PATHFINDER.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FLAN-T5-XL</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting + greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>73.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>12.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>FLAN-T5-XL shows much higher performance on StrategyQA relative to LLAMA-7B baseline, likely due to finetuning on related tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.17">
                <h3 class="extraction-instance">Extracted Data Instance 17 (e6571.17)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FLAN-T5-XL (3B) baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-XL (3B) with chain-of-thought prompting and greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-finetuned encoder-decoder T5 variant evaluated with CoT prompts and greedy decoding; used as a baseline and as a verifier model in PATHFINDER.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FLAN-T5-XL</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting + greedy decoding</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>85.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>42.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Very strong CSQA performance, likely influenced by training/finetuning overlap; authors caution comparisons due to this finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.18">
                <h3 class="extraction-instance">Extracted Data Instance 18 (e6571.18)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MINERVA-8B (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Minerva-8B (math-specialized LLM) - reported baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An 8B parameter model specialized for quantitative reasoning; reported as a literature baseline on GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva-8B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>reported baseline (Minerva pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / program-aided</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>16.2</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>5.2</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Reported literature baseline showing stronger GSM8K performance than LLAMA-7B baselines; included for comparison rather than internal experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.19">
                <h3 class="extraction-instance">Extracted Data Instance 19 (e6571.19)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-6.7B (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT (reported ~6.7B family) with CoT prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-style model reported in literature with CoT prompting and greedy decoding; included in paper as a comparative baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT (~6.7B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6.7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought prompting + greedy decoding (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>2.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-8.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Reported low GSM8K performance in table; included as a literature comparison. The paper uses these literature numbers to contextualize PATHFINDER.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.20">
                <h3 class="extraction-instance">Extracted Data Instance 20 (e6571.20)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-6.7B (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT (reported ~6.7B family) with CoT prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-style model reported in literature with CoT prompting and greedy decoding; included in paper as a comparative baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT (~6.7B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6.7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought prompting + greedy decoding (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>50.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-11.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Reported StrategyQA performance for GPT family model used as contextual baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.21">
                <h3 class="extraction-instance">Extracted Data Instance 21 (e6571.21)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-6.7B (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT (reported ~6.7B family) with CoT prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-style model reported in literature with CoT prompting and greedy decoding; included in paper as a comparative baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT (~6.7B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6.7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought prompting + greedy decoding (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>24.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-19.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Reported CSQA performance for GPT-style baseline; used mainly for literature-level comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.22">
                <h3 class="extraction-instance">Extracted Data Instance 22 (e6571.22)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>N-gram scorer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>N-gram similarity scorer (trigram in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A candidate selection function that ranks candidate reasoning chains by the number of shared n-grams among hypotheses, used to select the final reasoning path.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + N-gram scorer</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>N-gram similarity scoring for candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble / similarity-based selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>50.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>random candidate selection / greedy CoT baseline</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>6.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Surprisingly effective and computationally cheap; authors observe that n-gram similarity can reliably pick correct branches and that scorer sensitivity to noise implies an optimal branching factor exists.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.23">
                <h3 class="extraction-instance">Extracted Data Instance 23 (e6571.23)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Consistency scorer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency (majority vote over answers from multiple CoTs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble selection method that marginalizes answers across multiple sampled reasoning chains and picks the most frequent final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (ensemble answer marginalization)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>15.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>LLAMA-7B (greedy CoT baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>4.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Authors used self-consistency as both a baseline and a scorer; noted self-consistency does not utilize entire reasoning chains but marginalizes final answers, and provides strong gains in several tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.24">
                <h3 class="extraction-instance">Extracted Data Instance 24 (e6571.24)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cosine similarity scorer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cosine similarity over sentence embeddings (all-mpnet-base-v2) as candidate scorer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Selects final answer by summing pairwise cosine similarities between embeddings of candidate reasoning chains, using sentence-transformer embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + all-mpnet-base-v2 embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + embedding model</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>cosine-similarity-based selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similarity-based selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>N-gram scorer</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Included as an alternative scorer in ablations; the paper reports that different scorers outperform random selection and that TEXT-DAVINCI-003 achieves highest scorer accuracy, but exact per-benchmark numbers for each scorer are shown in a figure rather than tabulated.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.25">
                <h3 class="extraction-instance">Extracted Data Instance 25 (e6571.25)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT/BLEURT scorers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERTScore / BLEURT similarity scorers for ranking reasoning chains</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use BERTScore and BLEURT metrics as similarity functions to rank candidate reasoning chains, following wisdom-of-crowd style selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + BERT/BLEURT scorers</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B + scorer models</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>BERTScore / BLEURT-based selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similarity-based selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>N-gram scorer</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Tried as scorers in ablation; all scorers beat random selection but there is a gap between 'upper bound' and scorer-selected performance, indicating room for better scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.26">
                <h3 class="extraction-instance">Extracted Data Instance 26 (e6571.26)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Informativeness (Info-chain) scorer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Info-chain informativeness scorer (mutual alignment with context)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Ranks reasoning chains by informativeness measured as alignment between source context and chains (Info-chain score).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B (generator) + Info-chain scorer</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Informativeness-based selection (Info-chain)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>information-theoretic selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>STRATEGYQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>yes/no commonsense with evidence</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>N-gram scorer</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Used in ablations as an alternative selection function; authors describe it conceptually but do not highlight it as the top performer.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6571.27">
                <h3 class="extraction-instance">Extracted Data Instance 27 (e6571.27)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>End-to-end generation (greedy)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>End-to-end generation: prompt the model to produce multiple full reasoning chains and then score them</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An alternative to tree-search where the model is prompted to produce a set of whole reasoning chains (no step-level tree), followed by candidate selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PATHFINDER: Guided Search over Multi-Step Reasoning Paths</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLAMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>End-to-end generation + candidate selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential + ensemble selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>CSQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multiple-choice commonsense reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>PATHFINDER (tree-search)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Authors report tree-search outperforms end-to-end generation only when tree-search achieves sufficient diversity (branching factor >= 8 for LLAMA-7B); end-to-end lacks the same controlled per-step diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PathFinder: Guided Search over Multi-Step Reasoning Paths', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Decomposition enhances reasoning via self-evaluation guided decoding <em>(Rating: 2)</em></li>
                <li>PAL: Program-aided language models <em>(Rating: 1)</em></li>
                <li>Solving quantitative reasoning problems with language models <em>(Rating: 2)</em></li>
                <li>Making large language models better reasoners with step-aware verifier <em>(Rating: 1)</em></li>
                <li>Follow the wisdom of the crowd: Effective text generation via minimum bayes risk decoding <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6571",
    "paper_id": "paper-266150003",
    "extraction_schema_id": "extraction-schema-129",
    "extracted_data": [
        {
            "name_short": "PATHFINDER (N-gram)",
            "name_full": "PATHFINDER: tree-search decoding with n-gram similarity candidate selection",
            "brief_description": "A tree-search-based step-level decoding method that generates diverse multi-step reasoning paths via varying sampling parameters, constrained pruning, and selects final chains using an n-gram similarity scorer.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "PATHFINDER (tree-search step-level decoding + N-gram scorer)",
            "reasoning_method_type": "tree-search",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic word problems requiring multi-step arithmetic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 11.3,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 0.3,
            "statistical_significance": false,
            "analysis_notes": "Generates step-level branches with varied sampling (top-k, top-p, temperature) and prunes using step scores; n-gram scorer selects paths that are more similar across candidates. Diversity helps find correct chains but overall gains are modest on GSM8K versus the greedy baseline.",
            "ablation_study_present": true,
            "uuid": "e6571.0",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (N-gram)",
            "name_full": "PATHFINDER: tree-search decoding with n-gram similarity candidate selection",
            "brief_description": "A tree-search-based step-level decoding method that generates diverse multi-step reasoning paths via varying sampling parameters, constrained pruning, and selects final chains using an n-gram similarity scorer.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "PATHFINDER (tree-search step-level decoding + N-gram scorer)",
            "reasoning_method_type": "tree-search",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense questions requiring multi-step decomposition and per-step evidence",
            "performance_metric": "accuracy",
            "performance_value": 59.0,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": -2.1,
            "statistical_significance": false,
            "analysis_notes": "PATHFINDER's N-gram scorer selects more informative branches but does not beat the LLAMA-7B self-consistency performance on StrategyQA; diversity alone isn't sufficient â€” scorer quality matters.",
            "ablation_study_present": true,
            "uuid": "e6571.1",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (N-gram)",
            "name_full": "PATHFINDER: tree-search decoding with n-gram similarity candidate selection",
            "brief_description": "A tree-search-based step-level decoding method that generates diverse multi-step reasoning paths via varying sampling parameters, constrained pruning, and selects final chains using an n-gram similarity scorer.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "PATHFINDER (tree-search step-level decoding + N-gram scorer)",
            "reasoning_method_type": "tree-search",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning (CommonsenseQA)",
            "performance_metric": "accuracy",
            "performance_value": 50.0,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 6.7,
            "statistical_significance": false,
            "analysis_notes": "N-gram scorer substantially improves selection on CSQA compared to the greedy CoT baseline; authors note FLAN-T5 verifier further improves CSQA (likely due to finetuning on that data).",
            "ablation_study_present": true,
            "uuid": "e6571.2",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (FLAN-T5-XL verifier)",
            "name_full": "PATHFINDER: tree-search decoding with FLAN-T5-XL verifier for candidate selection",
            "brief_description": "PATHFINDER generates step-level candidate reasoning chains with LLAMA-7B and uses a FLAN-T5-XL verifier model to score and rank candidates for final selection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + FLAN-T5-XL (verifier)",
            "model_size": "7B + 3B",
            "reasoning_method_name": "PATHFINDER (tree-search) + verifier-based ranking",
            "reasoning_method_type": "tree-search + verifier",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 11.7,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 0.7,
            "statistical_significance": false,
            "analysis_notes": "Using a stronger verifier yields small improvements on GSM8K; authors caution FLAN-T5-XL was finetuned on CSQA and GSM8K so results can be inflated on those tasks.",
            "ablation_study_present": true,
            "uuid": "e6571.3",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (FLAN-T5-XL verifier)",
            "name_full": "PATHFINDER: tree-search decoding with FLAN-T5-XL verifier for candidate selection",
            "brief_description": "PATHFINDER generates step-level candidate reasoning chains with LLAMA-7B and uses a FLAN-T5-XL verifier model to score and rank candidates for final selection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + FLAN-T5-XL (verifier)",
            "model_size": "7B + 3B",
            "reasoning_method_name": "PATHFINDER (tree-search) + verifier-based ranking",
            "reasoning_method_type": "tree-search + verifier",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": 60.8,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": -0.3,
            "statistical_significance": false,
            "analysis_notes": "Verifier-based ranking yields similar performance to n-gram selection on StrategyQA; PATHFINDER still does not surpass LLAMA-7B self-consistency on StrategyQA in the reported runs.",
            "ablation_study_present": true,
            "uuid": "e6571.4",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (FLAN-T5-XL verifier)",
            "name_full": "PATHFINDER: tree-search decoding with FLAN-T5-XL verifier for candidate selection",
            "brief_description": "PATHFINDER generates step-level candidate reasoning chains with LLAMA-7B and uses a FLAN-T5-XL verifier model to score and rank candidates for final selection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + FLAN-T5-XL (verifier)",
            "model_size": "7B + 3B",
            "reasoning_method_name": "PATHFINDER (tree-search) + verifier-based ranking",
            "reasoning_method_type": "tree-search + verifier",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 55.1,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 11.8,
            "statistical_significance": false,
            "analysis_notes": "FLAN-T5-XL verifier substantially boosts CSQA accuracy compared to the greedy baseline; authors attribute part of this to FLAN-T5 having been finetuned on CSQA.",
            "ablation_study_present": true,
            "uuid": "e6571.5",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (TEXT-DAVINCI-003 verifier)",
            "name_full": "PATHFINDER: tree-search decoding with TEXT-DAVINCI-003 (GPT-3.5 family) verifier",
            "brief_description": "PATHFINDER uses LLAMA-7B to generate step-level candidates and uses TEXT-DAVINCI-003 to evaluate faithfulness and rank candidate reasoning chains.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + TEXT-DAVINCI-003 (verifier)",
            "model_size": "7B + ~6.7B (verifier family)",
            "reasoning_method_name": "PATHFINDER (tree-search) + external LLM verifier",
            "reasoning_method_type": "tree-search + verifier",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 15.4,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 4.4,
            "statistical_significance": false,
            "analysis_notes": "Using a high-quality external verifier (TEXT-DAVINCI-003) gives the largest gains on GSM8K among tested verifiers, but authors note a runtime/resource tradeoff with GPT-3.5-based evaluators.",
            "ablation_study_present": true,
            "uuid": "e6571.6",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (TEXT-DAVINCI-003 verifier)",
            "name_full": "PATHFINDER: tree-search decoding with TEXT-DAVINCI-003 (GPT-3.5 family) verifier",
            "brief_description": "PATHFINDER uses LLAMA-7B to generate step-level candidates and uses TEXT-DAVINCI-003 to evaluate faithfulness and rank candidate reasoning chains.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + TEXT-DAVINCI-003 (verifier)",
            "model_size": "7B + ~6.7B (verifier family)",
            "reasoning_method_name": "PATHFINDER (tree-search) + external LLM verifier",
            "reasoning_method_type": "tree-search + verifier",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": 61.7,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 0.6,
            "statistical_significance": false,
            "analysis_notes": "TEXT-DAVINCI-003 verifier leads to small gains on StrategyQA over the greedy CoT baseline; authors highlight diminishing returns versus verifier cost.",
            "ablation_study_present": true,
            "uuid": "e6571.7",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PATHFINDER (TEXT-DAVINCI-003 verifier)",
            "name_full": "PATHFINDER: tree-search decoding with TEXT-DAVINCI-003 (GPT-3.5 family) verifier",
            "brief_description": "PATHFINDER uses LLAMA-7B to generate step-level candidates and uses TEXT-DAVINCI-003 to evaluate faithfulness and rank candidate reasoning chains.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + TEXT-DAVINCI-003 (verifier)",
            "model_size": "7B + ~6.7B (verifier family)",
            "reasoning_method_name": "PATHFINDER (tree-search) + external LLM verifier",
            "reasoning_method_type": "tree-search + verifier",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 56.3,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 13.0,
            "statistical_significance": false,
            "analysis_notes": "TEXT-DAVINCI-003 verifier gives the largest reported CSQA accuracy in the paper for PATHFINDER variants, but at substantially higher computational cost.",
            "ablation_study_present": true,
            "uuid": "e6571.8",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "LLAMA-7B (greedy CoT baseline)",
            "name_full": "LLAMA-7B with chain-of-thought prompting, greedy token-level decoding",
            "brief_description": "LLAMA-7B prompted with few-shot chain-of-thought examples and decoded greedily to produce reasoning traces and answers; used as the primary model baseline.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting + greedy decoding",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 11.0,
            "comparison_target_method": "none (baseline)",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Reported as baseline performance using greedy decoding with CoT prompts; used to compute PATHFINDER improvements.",
            "ablation_study_present": false,
            "uuid": "e6571.9",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "LLAMA-7B (greedy CoT baseline)",
            "name_full": "LLAMA-7B with chain-of-thought prompting, greedy token-level decoding",
            "brief_description": "LLAMA-7B prompted with few-shot chain-of-thought examples and decoded greedily to produce reasoning traces and answers; used as the primary model baseline.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting + greedy decoding",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": 61.1,
            "comparison_target_method": "none (baseline)",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Baseline CoT greedy decoding result; PATHFINDER variants are compared against this baseline.",
            "ablation_study_present": false,
            "uuid": "e6571.10",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "LLAMA-7B (greedy CoT baseline)",
            "name_full": "LLAMA-7B with chain-of-thought prompting, greedy token-level decoding",
            "brief_description": "LLAMA-7B prompted with few-shot chain-of-thought examples and decoded greedily to produce reasoning traces and answers; used as the primary model baseline.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting + greedy decoding",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 43.3,
            "comparison_target_method": "none (baseline)",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Baseline on CSQA using CoT and greedy decoding; PATHFINDER (N-gram) improved notably over this baseline.",
            "ablation_study_present": false,
            "uuid": "e6571.11",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "LLAMA-7B (self-consistency)",
            "name_full": "LLAMA-7B with chain-of-thought prompting and self-consistency majority voting over multiple CoTs",
            "brief_description": "Self-consistency aggregates answers across multiple sampled reasoning chains (marginalizing answers) to pick the most consistent final answer.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Self-Consistency (aggregate multiple CoTs)",
            "reasoning_method_type": "ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 15.3,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 4.3,
            "statistical_significance": false,
            "analysis_notes": "Self-consistency substantially improves over single greedy CoT by aggregating diverse reasoning chains; paper notes PATHFINDER still lags behind self-consistency on StrategyQA in some runs.",
            "ablation_study_present": false,
            "uuid": "e6571.12",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "LLAMA-7B (self-consistency)",
            "name_full": "LLAMA-7B with chain-of-thought prompting and self-consistency majority voting over multiple CoTs",
            "brief_description": "Self-consistency aggregates answers across multiple sampled reasoning chains (marginalizing answers) to pick the most consistent final answer.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Self-Consistency (aggregate multiple CoTs)",
            "reasoning_method_type": "ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": 64.8,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 3.7,
            "statistical_significance": false,
            "analysis_notes": "Self-consistency improves StrategyQA accuracy over greedy CoT; PATHFINDER variants with some scorers do not surpass this in reported experiments.",
            "ablation_study_present": false,
            "uuid": "e6571.13",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "LLAMA-7B (self-consistency)",
            "name_full": "LLAMA-7B with chain-of-thought prompting and self-consistency majority voting over multiple CoTs",
            "brief_description": "Self-consistency aggregates answers across multiple sampled reasoning chains (marginalizing answers) to pick the most consistent final answer.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Self-Consistency (aggregate multiple CoTs)",
            "reasoning_method_type": "ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 46.9,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 3.6,
            "statistical_significance": false,
            "analysis_notes": "Self-consistency yields consistent improvements; compared against PATHFINDER variants to show tradeoffs between search strategy and simple aggregation.",
            "ablation_study_present": false,
            "uuid": "e6571.14",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "FLAN-T5-XL (3B) baseline",
            "name_full": "FLAN-T5-XL (3B) with chain-of-thought prompting and greedy decoding",
            "brief_description": "An instruction-finetuned encoder-decoder T5 variant evaluated with CoT prompts and greedy decoding; used as a baseline and as a verifier model in PATHFINDER.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "FLAN-T5-XL",
            "model_size": "3B",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting + greedy decoding",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 13.5,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 2.5,
            "statistical_significance": false,
            "analysis_notes": "FLAN-T5-XL baseline outperforms the LLAMA-7B greedy baseline on GSM8K; also used as a verifier inside PATHFINDER.",
            "ablation_study_present": false,
            "uuid": "e6571.15",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "FLAN-T5-XL (3B) baseline",
            "name_full": "FLAN-T5-XL (3B) with chain-of-thought prompting and greedy decoding",
            "brief_description": "An instruction-finetuned encoder-decoder T5 variant evaluated with CoT prompts and greedy decoding; used as a baseline and as a verifier model in PATHFINDER.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "FLAN-T5-XL",
            "model_size": "3B",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting + greedy decoding",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": 73.4,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 12.3,
            "statistical_significance": false,
            "analysis_notes": "FLAN-T5-XL shows much higher performance on StrategyQA relative to LLAMA-7B baseline, likely due to finetuning on related tasks.",
            "ablation_study_present": false,
            "uuid": "e6571.16",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "FLAN-T5-XL (3B) baseline",
            "name_full": "FLAN-T5-XL (3B) with chain-of-thought prompting and greedy decoding",
            "brief_description": "An instruction-finetuned encoder-decoder T5 variant evaluated with CoT prompts and greedy decoding; used as a baseline and as a verifier model in PATHFINDER.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "FLAN-T5-XL",
            "model_size": "3B",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting + greedy decoding",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 85.4,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 42.1,
            "statistical_significance": false,
            "analysis_notes": "Very strong CSQA performance, likely influenced by training/finetuning overlap; authors caution comparisons due to this finetuning.",
            "ablation_study_present": false,
            "uuid": "e6571.17",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "MINERVA-8B (reported)",
            "name_full": "Minerva-8B (math-specialized LLM) - reported baseline",
            "brief_description": "An 8B parameter model specialized for quantitative reasoning; reported as a literature baseline on GSM8K.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "mention",
            "model_name": "Minerva-8B",
            "model_size": "8B",
            "reasoning_method_name": "reported baseline (Minerva pipeline)",
            "reasoning_method_type": "sequential / program-aided",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 16.2,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 5.2,
            "statistical_significance": false,
            "analysis_notes": "Reported literature baseline showing stronger GSM8K performance than LLAMA-7B baselines; included for comparison rather than internal experiments.",
            "ablation_study_present": false,
            "uuid": "e6571.18",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "GPT-6.7B (reported)",
            "name_full": "GPT (reported ~6.7B family) with CoT prompting",
            "brief_description": "A GPT-style model reported in literature with CoT prompting and greedy decoding; included in paper as a comparative baseline.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "mention",
            "model_name": "GPT (~6.7B)",
            "model_size": "6.7B",
            "reasoning_method_name": "Chain-of-Thought prompting + greedy decoding (reported)",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 2.4,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": -8.6,
            "statistical_significance": false,
            "analysis_notes": "Reported low GSM8K performance in table; included as a literature comparison. The paper uses these literature numbers to contextualize PATHFINDER.",
            "ablation_study_present": false,
            "uuid": "e6571.19",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "GPT-6.7B (reported)",
            "name_full": "GPT (reported ~6.7B family) with CoT prompting",
            "brief_description": "A GPT-style model reported in literature with CoT prompting and greedy decoding; included in paper as a comparative baseline.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "mention",
            "model_name": "GPT (~6.7B)",
            "model_size": "6.7B",
            "reasoning_method_name": "Chain-of-Thought prompting + greedy decoding (reported)",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": 50.0,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": -11.1,
            "statistical_significance": false,
            "analysis_notes": "Reported StrategyQA performance for GPT family model used as contextual baseline.",
            "ablation_study_present": false,
            "uuid": "e6571.20",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "GPT-6.7B (reported)",
            "name_full": "GPT (reported ~6.7B family) with CoT prompting",
            "brief_description": "A GPT-style model reported in literature with CoT prompting and greedy decoding; included in paper as a comparative baseline.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "mention",
            "model_name": "GPT (~6.7B)",
            "model_size": "6.7B",
            "reasoning_method_name": "Chain-of-Thought prompting + greedy decoding (reported)",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 24.0,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": -19.3,
            "statistical_significance": false,
            "analysis_notes": "Reported CSQA performance for GPT-style baseline; used mainly for literature-level comparison.",
            "ablation_study_present": false,
            "uuid": "e6571.21",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "N-gram scorer",
            "name_full": "N-gram similarity scorer (trigram in experiments)",
            "brief_description": "A candidate selection function that ranks candidate reasoning chains by the number of shared n-grams among hypotheses, used to select the final reasoning path.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + N-gram scorer",
            "model_size": "7B",
            "reasoning_method_name": "N-gram similarity scoring for candidate selection",
            "reasoning_method_type": "ensemble / similarity-based selection",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": 50.0,
            "comparison_target_method": "random candidate selection / greedy CoT baseline",
            "performance_difference": 6.7,
            "statistical_significance": false,
            "analysis_notes": "Surprisingly effective and computationally cheap; authors observe that n-gram similarity can reliably pick correct branches and that scorer sensitivity to noise implies an optimal branching factor exists.",
            "ablation_study_present": true,
            "uuid": "e6571.22",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Self-Consistency scorer",
            "name_full": "Self-Consistency (majority vote over answers from multiple CoTs)",
            "brief_description": "An ensemble selection method that marginalizes answers across multiple sampled reasoning chains and picks the most frequent final answer.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "Self-Consistency (ensemble answer marginalization)",
            "reasoning_method_type": "ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": 15.3,
            "comparison_target_method": "LLAMA-7B (greedy CoT baseline)",
            "performance_difference": 4.3,
            "statistical_significance": false,
            "analysis_notes": "Authors used self-consistency as both a baseline and a scorer; noted self-consistency does not utilize entire reasoning chains but marginalizes final answers, and provides strong gains in several tasks.",
            "ablation_study_present": false,
            "uuid": "e6571.23",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Cosine similarity scorer",
            "name_full": "Cosine similarity over sentence embeddings (all-mpnet-base-v2) as candidate scorer",
            "brief_description": "Selects final answer by summing pairwise cosine similarities between embeddings of candidate reasoning chains, using sentence-transformer embeddings.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + all-mpnet-base-v2 embeddings",
            "model_size": "7B + embedding model",
            "reasoning_method_name": "cosine-similarity-based selection",
            "reasoning_method_type": "similarity-based selection",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": null,
            "comparison_target_method": "N-gram scorer",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Included as an alternative scorer in ablations; the paper reports that different scorers outperform random selection and that TEXT-DAVINCI-003 achieves highest scorer accuracy, but exact per-benchmark numbers for each scorer are shown in a figure rather than tabulated.",
            "ablation_study_present": true,
            "uuid": "e6571.24",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "BERT/BLEURT scorers",
            "name_full": "BERTScore / BLEURT similarity scorers for ranking reasoning chains",
            "brief_description": "Use BERTScore and BLEURT metrics as similarity functions to rank candidate reasoning chains, following wisdom-of-crowd style selection.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + BERT/BLEURT scorers",
            "model_size": "7B + scorer models",
            "reasoning_method_name": "BERTScore / BLEURT-based selection",
            "reasoning_method_type": "similarity-based selection",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "GSM8K",
            "task_description": "grade-school arithmetic",
            "performance_metric": "accuracy",
            "performance_value": null,
            "comparison_target_method": "N-gram scorer",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Tried as scorers in ablation; all scorers beat random selection but there is a gap between 'upper bound' and scorer-selected performance, indicating room for better scoring.",
            "ablation_study_present": true,
            "uuid": "e6571.25",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Informativeness (Info-chain) scorer",
            "name_full": "Info-chain informativeness scorer (mutual alignment with context)",
            "brief_description": "Ranks reasoning chains by informativeness measured as alignment between source context and chains (Info-chain score).",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B (generator) + Info-chain scorer",
            "model_size": "7B",
            "reasoning_method_name": "Informativeness-based selection (Info-chain)",
            "reasoning_method_type": "information-theoretic selection",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "STRATEGYQA",
            "task_description": "yes/no commonsense with evidence",
            "performance_metric": "accuracy",
            "performance_value": null,
            "comparison_target_method": "N-gram scorer",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Used in ablations as an alternative selection function; authors describe it conceptually but do not highlight it as the top performer.",
            "ablation_study_present": true,
            "uuid": "e6571.26",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "End-to-end generation (greedy)",
            "name_full": "End-to-end generation: prompt the model to produce multiple full reasoning chains and then score them",
            "brief_description": "An alternative to tree-search where the model is prompted to produce a set of whole reasoning chains (no step-level tree), followed by candidate selection.",
            "citation_title": "PATHFINDER: Guided Search over Multi-Step Reasoning Paths",
            "mention_or_use": "use",
            "model_name": "LLAMA-7B",
            "model_size": "7B",
            "reasoning_method_name": "End-to-end generation + candidate selection",
            "reasoning_method_type": "sequential + ensemble selection",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "CSQA",
            "task_description": "multiple-choice commonsense reasoning",
            "performance_metric": "accuracy",
            "performance_value": null,
            "comparison_target_method": "PATHFINDER (tree-search)",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Authors report tree-search outperforms end-to-end generation only when tree-search achieves sufficient diversity (branching factor &gt;= 8 for LLAMA-7B); end-to-end lacks the same controlled per-step diversity.",
            "ablation_study_present": true,
            "uuid": "e6571.27",
            "source_info": {
                "paper_title": "PathFinder: Guided Search over Multi-Step Reasoning Paths",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Decomposition enhances reasoning via self-evaluation guided decoding",
            "rating": 2,
            "sanitized_title": "decomposition_enhances_reasoning_via_selfevaluation_guided_decoding"
        },
        {
            "paper_title": "PAL: Program-aided language models",
            "rating": 1,
            "sanitized_title": "pal_programaided_language_models"
        },
        {
            "paper_title": "Solving quantitative reasoning problems with language models",
            "rating": 2,
            "sanitized_title": "solving_quantitative_reasoning_problems_with_language_models"
        },
        {
            "paper_title": "Making large language models better reasoners with step-aware verifier",
            "rating": 1,
            "sanitized_title": "making_large_language_models_better_reasoners_with_stepaware_verifier"
        },
        {
            "paper_title": "Follow the wisdom of the crowd: Effective text generation via minimum bayes risk decoding",
            "rating": 1,
            "sanitized_title": "follow_the_wisdom_of_the_crowd_effective_text_generation_via_minimum_bayes_risk_decoding"
        }
    ],
    "cost": 0.02782775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PATHFINDER: Guided Search over Multi-Step Reasoning Paths
12 Dec 2023</p>
<p>Olga Golovneva 
Sean O'brien 
Ramakanth Pasunuru 
Tianlu Wang 
Luke Zettlemoyer 
Maryam Fazel-Zarandi 
Asli Celikyilmaz 
PATHFINDER: Guided Search over Multi-Step Reasoning Paths
12 Dec 202389B64D191D84CE6B597AFAA00BED2FF0arXiv:2312.05180v2[cs.CL]2 N-gram score: 28 Cosine Similarity score: 144 BERT score: 193 BLEURT score: -003 Informativeness score: 060 Flan-T5-XL verifier: 095 Flan-T5-XXL verifier: 099 Self-consistency: 1 N-gram score: 22 Cosine Similarity score: 149 BERT score: 191 BLEURT score: -054 Informativeness score: 048 Flan-T5-XL verifier: 061 Flan-T5-XXL verifier: 042 Self-consistency score: 2 N-gram score: 20 Cosine Similarity score: 152 BERT score: 191 BLEURT score: -076 Informativeness score: 039 Flan-T5-XL verifier: 069 Flan-T5-XXL verifier: 098
With recent advancements in large language models, methods like chain-of-thought prompting to elicit reasoning chains have been shown to improve results on reasoning tasks.However, tasks that require multiple steps of reasoning still pose significant challenges to state-of-the-art models.Drawing inspiration from the beam search algorithm, we propose PATHFINDER, a tree-search-based reasoning path generation approach.It enhances diverse branching and multi-hop reasoning through the integration of dynamic decoding, enabled by varying sampling methods and parameters.Using constrained reasoning, PATHFINDER integrates novel quality constraints, pruning, and exploration methods to enhance the efficiency and the quality of generation.Moreover, it includes scoring and ranking features to improve candidate selection.Our approach outperforms competitive baselines on three complex arithmetic and commonsense reasoning tasks by 6% on average.Our model generalizes well to longer, unseen reasoning chains, reflecting similar complexities to beam search with large branching factors.</p>
<p>Introduction</p>
<p>Recent progress in large language models (LLMs) has led to a new era in machine reasoning, particularly through the use of prompting methods.These methods, such as chain-of-thought (CoT) Wei et al. (2022), scratchpads Nye et al. (2021), least-to-most Zhou et al. (2023), and program-aided language models (PAL) Gao et al. (2023), typically break down complex tasks into reasoning chains and have shown to improve model performance on tasks such as logical Clark et al. (2020), arithmetic Cobbe et al. (2021) and commonsense Talmor et al. (2021) reasoning.</p>
<p>As tasks that require multiple steps of reasoning become more complex, LLMs begin to struggle with accumulating errors across multiple reasoning steps.Even more challenging is ensuring that each step in a chain is correctly evaluated and contributes positively to the overall reasoning chain and accuracy of the solution.To address these issues, recent work has implemented methods like self-consistency for majority voting Wang et al. (2023), diversifying prompts Li et al. (2023) and Python programs for more accurate reasoning generations Gao et al. (2023).Despite these improvements, the process of creating reasoning chains as a standard autoregressive process still faces challenges due to large search space, sub-optimal assessment and guidance of the reasoning process, especially in complex, multi-step tasks.</p>
<p>In this work, we introduce PATHFINDER, a decoding method designed for the generation and refinement of reasoning chains generated by LLMs.PATHFINDER embodies our approach of dividing the reasoning decoding into two distinct tasks: candidate generation and candidate selection.For the candidate generation process, PATHFINDER employs a tree-search-based method.It integrates a set of constraints to improve the quality of generated reasoning candidates, along with a pruning</p>
<p>The Japanese have a long history of using jars to store things.</p>
<p>-0.0186 -0.0180 -0.0099 -0.0022</p>
<p>Energy can be stored in a battery.</p>
<p>-0.0028 -0.0048 -0.0044</p>
<p>Energy cannot be stored.</p>
<p>-0.0147</p>
<p>Thus, Reiki cannot be stored in a bottle.</p>
<p>-0.0016 -0.0 -0.0</p>
<p>The answer is no Thus, Reiki can be stored in a battery.</p>
<p>-0.0 -0.0051 -0.0014</p>
<p>Figure 1: PATHFINDER leverages step-level generic constrained decoding to guide step-by-step reasoning generations.In this example from the StrategyQA dataset, although the reasoning steps are close in n-grams, PATHFINDER prunes less likely branches and chooses more informative ones that explain the question.Branching factor=3, buffer size=3.Numbers in purple rectangles are scores produced by the pruning function governed by Equation 2 using greedy step decoding (Ï„ âˆ’ â†’ 0).Highest scores produced for each non-pruned branch are underlined.Details on different candidate selection scores at the leaf of each reasoning path are provided in Section 4.</p>
<p>function for efficient computation and removes subpar candidates as shown in Figure 1.Our model also incorporates an exploration factor to ensure the diversity of reasoning generations.For the candidate selection process, PATHFINDER utilizes a set of novel similarity-based functions that we benchmark against existing LLM-based verifiers.This selection process allows for the selection of more accurate reasoning chains from the candidate pool, thereby refining the quality of the overall reasoning.We conduct extensive experiments across four generation tasks that necessitate multi-step reasoning.Using the small-size LLAMA-7B (Touvron et al., 2023) as a backbone language model, PATHFINDER demonstrates substantial performance improvements across all tasks, highlighting its effectiveness in improving reasoning capabilities of language models.We discuss related research in more detail in the Appendix C.</p>
<p>In summary, we develop PATHFINDER, a new decoding method for effective generation of reasoning traces.Our algorithm is versatile, as it can be applied to a variety of multi-step reasoning generation tasks via decoding time constraints, reducing the need for tuning on costly labeled data.Our extensive experiments demonstrate its effectiveness on several complex tasks.</p>
<p>PATHFINDER: Reasoning Decoder</p>
<p>We describe PATHFINDER, a tree-search-based reasoning path generation approach.We first introduce the decoding problem and then describe our approach which incorporates a two step decoding process: candidate generation and selection.</p>
<p>Decoding.Sequence generation is a task of generating output sequence y (e.g., reasoning path) given input sequence x (e.g., question, prompt, etc.).In multi-step reasoning from LLMs, a sequential reasoning chain composed of T steps is generated across multiple timesteps.We denote a reasoning chain as y = y
1:T =[y 1 , y 2 , â€¢ â€¢ â€¢ , y T ],
where each y t denotes a reasoning step of sequence of distinct tokens.A reasoning chain is autoregressively generated and the decoding consists of solving:
y * = arg max yâˆˆY log P (y|x)(1)
where Y = {y 1 , ..., y K } is the set of all generated reasoning paths in response to the input x using generation model P (y|x).</p>
<p>Candidate Generation.At the core of PATHFINDER is a tree-search algorithm for long form reasoning generation, which generates multiple plausible generation paths.Unlike token-based beam search methods Holtzman et al. (2020), the branching in our approach occurs at the level of reasoning steps instead of individual tokens.This means that each reasoning step is regarded as a discrete node (see Figure 1).The branching is influenced by varying among a fixed number of sampling parameters (e.g., top-k, top-p, temperature), allowing PATHFINDER to explore various decoding methods and enabling search over different decoding strategies at each time step.This dynamic decoding property facilitates multi-hop reasoning, resulting in diverse branches.</p>
<p>To trade off quality against compute, we draw a number of candidates from each non-pruned leaf within the reasoning tree as our branching factor at every stage of the process.We continue to sample until all leaves have either reached termination points or have achieved a predefined maximum depth.</p>
<p>To avoid over-generation of reasoning step branches, we also introduce a buffer size b, limiting the number of hypothesises stored for each context, and implement pruning methods.In particular, for each hypothesis reasoning step
y t = [y 1 t , â€¢ â€¢ â€¢ , y N t ],
where y i t is the i th token in the sequence on length N , generated in response to the prompt x, we prune branches based on the sequence scores , normalized by the number of tokens:
Ï€(y t ) = i log p Î¸ (y i t |x, y i&lt; t )/N Î» (2)
where Î» âˆˆ R is a model-specific length penalty parameter , and p Î¸ is a token generation model.Additionally, similar to Xie et al. (2023), we introduce step sampling temperature Ï„ with annealing factor Î± used to decay temperature step-by-step as Ï„ âˆ’ â†’ Î±Ï„ to add controlled variation in the branches, and sample according to the distribution: Candidate Selection.To select a final hypothesis out of a pool of candidates, we experiment with a number of scoring functions of the form:
p(y t ) âˆ exp(Ï€(y t )/Ï„ )(y * = arg max yj âˆˆY y k âˆˆY,y k Ì¸ =yj S(y j , y k ) (4)
where the number of candidate reasoning chains in the pool Y is limited by the buffer size (K â‰¤ b), and S is a similarity function.The intuition is similar to self-consistency (Wang et al., 2022) or wisdom of the crowd (Suzgun et al., 2022), in the assumption that a solution following from more diverse, generated reasoning chains majority is more likely to be the correct one.In fact, our results support the use of an N-gram-based similarity metric .Specifically, if g j is a set of n-grams for the hypothesis y j , the N-gram similarity function is defined as the number of common n-grams as follows:
S(y j , y k ) = |g j âˆ© g k | (5)
Candidate selection is a critical component of PATHFINDER.Numbers with an asterisk* are from our evaluations using greedy decoding and CoT prompts provided in Appendix D. For self-consistency scores, we marginalize answer across 16 reasoning chains sampled with temperature T = 1.0, top-k (k = 40) and top-p (p = 0.5).We note that FLAN-T5 is finetuned on data from both the CSQA and GSM8K datasets and thus will have somewhat inflated performance in comparison to comparably-sized models not trained on these tasks.</p>
<p>3 Experiments: Reasoning Generation Datasets.We conduct experiments on various benchmark datasets that require complex reasoning skills to reach the final answer: (1) GSM8K (Cobbe et al., 2021), an arithmetic reasoning dataset of 8.5K linguistically diverse grade school math word problems;</p>
<p>(2) STRATEGYQA (Geva et al., 2021), a commonsense reasoning dataset of 2,780 questions, annotated with their decomposition and per-step evidence;</p>
<p>(3) CSQA (Talmor et al., 2018), a multiple-choice commonsense reasoning dataset of 12,102 questions with one correct answer and four distractor answers.</p>
<p>Backbone LLMs for PATHFINDER.We select two widely-used open-sourced models to generate and evaluate chains of reasoning: LLAMA-7B (Touvron et al., 2023) and FLAN-T5-XL (3B) (Chung et al., 2022).We prompt LLAMA-7B model with chain-of-thought examples (Wei et al., 2022) to generate reasoning steps along with the final answers.We provide specific parameter values and prompt sequences in Appendix D. We also experiment with different methods for candidate selection.In particular, we report results using the following setups: Baselines.We benchmark our approach against leading best models with reported results in the literature, ensuring the model sizes are comparable for fair evaluation2 .Specifically we compare against GPT-6.7BWei et al. (2022), LLAMA-7B (Touvron et al., 2023), FLAN-T5-XL (3B) (Fu et al., 2023), and Minerva-8B Lewkowycz et al. (2022).Reported results represent evaluation results on generations produced with CoT prompting and greedy token-level decoding.We also include our own evaluations on a few tasks that to the best of our knowledge are missing in the literature using greedy decoding and prompts provided in Appendix D.</p>
<p>Results.Table 1 compares different LLMs with different decoding methods showing answer accuracy as the evaluation metric.PATHFINDER improves baseline performance on all selected reasoning tasks by 6% on average, but lacks behind the base model with self-consistency applied on STRATEGYQA dataset by 3%.Even simple N-gram-based similarity metric allows to select better paths leading to model improvements with respect to baseline on GSM8K and CSQA datasets.We note that FLAN-T5-XL verifier significantly improves performance on CSQA task, but not that much on the others.This is likely due to the fact that is was trained on this task, while other tasks are significantly harder to evaluate (GSM8K), or not familiar to the model (STRATEGYQA).While overall TEXT- DAVINCI-003 verifier shows better performance, there is a trade-off between the amount of resources needed to run GPT3.5-basedevaluations and improvements in performance it could give; Figure 1 shows an example of the generated tree for one of the STRATEGYQA questions.It showcases how PATHFINDER that although the reasoning steps are close in N-grams, PATHFINDER prunes less likely branches and chooses more informative ones that explain the question.Finally, the N-gram scorer selects the correct answer by selecting the branch with higher n-gram similarity to other branches.</p>
<p>Ablation Study</p>
<p>How do various candidate selection strategies impact the overall performance?In this section, we evaluate our model using various scorer functions and verifier models, which rank a fixed set of candidates and select the highest-scoring one as the final prediction.We present an upper bound accuracy, which is an accuracy of the "perfect" scorer that would select the correct final answer if present in candidate pool, and contrast the N-gram-based scorer with several alternative approaches: Self-Consistency scorer, Cosine Similarity scorer, BERT and BLEURT scorers, Informativeness scorer, and Verifier models.We provide more details on scorer functions construction and ranking methods in Appendix D and Appendix E. We summarize the results in Figure 2. All scorers outperform random selection, with TEXT-DAVINCI-003 results in highest accuracy score of 58.1.At the same time we want to emphasize the gap between the upper bound accuracy and the final accuracy when a scorer function or verifier model is used to rank and select best hypothesis, which clearly shows that the right choice of the candidate selection strategy can significantly boost performance further.</p>
<p>How does the branching factor affect performance?The tree branching factor together with the pruning function significantly influences the diversity of candidates.Intuitively, generating more candidates increases the likelihood of producing at least one correct generation.However, as our scoring models are not perfect, a high volume of noisy candidates could confuse them and escalate the rate of false positives.We asses the N-gram scorer performance to comprehend the scorer sensitivity to noise.Figure 3 indicates an optimal branching factor for each buffer size, which supports our hypothesis regarding the scorer function's sensitivity to noise levels.Thus, for tree-search-based step-level decoding it is important to find an optimal value of the branching factor to balance between the diversity of the candidates and the amount of noise.Similar phenomenon was previously observed for beam search token-level decoding, where increasing the number of decoding candidates past a certain point leads to the worse generation quality (Yang et al., 2018;Koehn and Knowles, 2017).</p>
<p>Does an increased buffer size consistently improve performance?</p>
<p>To answer this question we empirically investigate the N-gram scorer performance.The results summarized in Figure 3 reveal that for small branching factors considered in this study, the accuracy score platoes.Beyond a certain point, increasing the buffer size does not yield more generations because they are limited by the branching factor and generation constrains.In fact, for CSQA experiments shown in Figure 3, at branching factor 8 the average number of hypothesis candidates almost does not change after buffer size 32, and is around 22. The platoe point shifts higher with the increase in the number of generations per node.Throughout our experiments, we observed a consistent improvement in optimal to generate the whole reasoning path for each candidate, and then apply tri-gram scorer model on the number of generated candidates corresponding to the buffer size value (denoted as end-to-end generation).Decoding process is sensitive to the amount of noise, which results in the existence of an optimal branching factor that maximizes the final accuracy.For each branching factor there is a limit on the maximal number of diverse branches the model can generate, and increasing buffer size after this point does not result in bigger trees, and we observe a platoe in terms of accuracy scores.performance with the an increased buffer size.However, our observations are limited by available computational resources, suggesting that behavior might vary for extreme branching factors.</p>
<p>Branching Factor</p>
<p>Do we actually need trees?In Figure 3, along with the tree-search-based results, we also report end-to-end generation performance, i.e., at candidate generation stage, instead of creating a tree we prompt the model to generate a set of reasoning chains, and then apply our candidate selection process.We observe that a sufficient diversity in reasoning steps is necessary for the tree-search-based approach to outperform the end-to-end generation method.Specifically, for the LLAMA-7B model, the tree-search generation approach only outperforms end-to-end generation at a branching factor of 8 or above.Therefore, while tree-search generation has its advantages, it's effectiveness in comparison to end-to-end generation is largely dependent on sufficient diversity in reasoning steps and a relatively high branching factor.</p>
<p>Computational complexity</p>
<p>The benefits gained from this approach come at a high computational cost.Assuming a full buffer of c candidates after a few reasoning steps, we generate cb candidate new steps before selection and pruning at each step.If the original reasoning chain required T tokens to generate, PATHFINDER requires O(bcT ) tokens.This can be compared against self-consistency with k paths, which requires O(kT ) tokens, but can be more easily parallelized with memory split across devices.In practice, we see that, while a simple reasoning path takes under 1 GPU-hour to generate (Table 2), it takes several GPU-hours to generate reasoning tree that would outperform end-to-end generation for complex reasoning tasks.With more effective pruning functions and scorers, we should be able to realize gains with fewer sampled paths.Because our framework is agnostic to the choice of either, we anticipate that better models will allow for a lower branching factor and buffer size, making the method more computationally feasible.</p>
<p>Conclusion</p>
<p>We proposed PATHFINDER, a novel decoding method that optimizes reasoning chain generation in large langauge models.We demonstrate notable performance improvements on four multi-step reasoning tasks, emphasizing its versatility and effectiveness.Our approach overcomes traditional limitations, enhancing reasoning capabilities and opening doors for future research.</p>
<p>C Related work</p>
<p>Decoding strategies for text generation.These methods present a continual trade-off between quality and diversity.Traditional deterministic methods such as greedy decoding and beam search Jurafsky and Martin (2009); Graves (2012) 2019) seek to address the mismatch between monotonic decoding and satisfying constraints.Contrary to these strategies which often struggle with the balance between quality and diversity, PATHFINDER focuses primarily on reasoning tasks and not open-ended text generation, operating on reasoning steps rather than on individual tokens.By separating out the steps of tree-search-based generation and similarity-based selection, our approach generates diverse reasoning chains and refines them for optimal quality.</p>
<p>Advanced CoT Strategies and Self Consistency.It has been shown that aggregating from diverse CoTs (i.e., multiple reasoning paths for each problem) can effectively enhance end-task performance Wei et al. (2022).Recent works such as self-consistency Wang et al. (2023) and crowd sampling Suzgun et al. ( 2022) generate multiple reasoning paths and try to find a consensus among the derived answers.Self-consistency has significantly boosted performance in CoT reasoning, even in tasks where CoT prompting traditionally harms performance; crowd sampling has shown gains in non-reasoning tasks like summarization.Our approach bears resemblance to these, but differs in its use of a tree search for candidate generation, its operation on the step level rather than on the full generations, and its use of a novel similarity function.</p>
<p>Other approaches offload some portion of problem-solving to external tools, like training a model to use tools as in Toolformer Schick et al. (2023) or prompting a model to solve a problem with a code interpreter as in PAL Gao et al. (2023).Our approach does not require access to external tools, although it does not prohibit their use.Further, unlike Toolformer our method is training-free.</p>
<p>Our work parallels the study of by Xie et al., which presents a self-evaluation guided stochastic beam search for multi-step reasoning.Their method employs beam search decoding tailored to intermediate steps and guides the searching process by controlling the error of each reasoning step to prevent potential error accumulation.Another approach for step selection and evaluation was recently developed by Hao et al. (2023) and Shridhar et al. (2023), that relies on the world model to ask, refine, and evaluate generated steps.</p>
<p>D Experimental setup</p>
<p>Inference parameters.To run experiments with PATHFINDER we used LLAMA-7B.For stepby-step generations, we applied temperature token sampling with T = 1.0, with additional top-k (k = 40) and top-p (p = 0.5) truncation to increase the diversity of the samples during tree generation.</p>
<p>For end-to-end generation we applied greedy decoding.We fixed the maximum generation length at 128 tokens per step for tree generation, and 512 for the full reasoning generation.We run experiments on 8 GPUs with batch size 16.</p>
<p>Prompt construction.All prompts used for hypothesis generations are listed in Table 3.In particular, for GSM8K dataset we follow prompts from Touvron et al. ( 2023), for STRATEGYQA and CSQA datasets we follow Wei et al. (2022).</p>
<p>Pruning.In main experiments we applied annealing factor Î± = 0.5, and used step sampling temperature Ï„ = 1.0.Ï„ = 0 corresponds to the maximum likelihood sampling, while Ï„ âˆ’ â†’ inf corresponds to the uniform sampling.This setup allows for higher variation of steps in the beginning of generation, and becomes more strict with depth.We have experimented removing annealing factor and varying Ï„ = {0, 0.5, 1.0, 16} on the train partition of GSM8K dataset, and found the optimal performance at Ï„ = 1 with annealing.</p>
<p>Scoring functions.We contrast the N-gram-based scorer with several alternative approaches:</p>
<p>â€¢ Self-Consistency scorer: The final answer is determined by marginalizing out the sampled reasoning paths to find the most consistent answer in the final answer set (Wang et al., 2022).This method does not take into account reasoning chains, so we modify Equation 4 as y * = arg max yj âˆˆY n aj , where A = {a 1 , ..., a b } are all generated answers extracted from corresponding hypothesises Y, and each answer a j appears n aj times in A.</p>
<p>â€¢ Cosine Similarity scorer: The final answer is selected by marginalizing out the total cosine similarity of the reasoning chains, so we modify the Equation 5as S(y j , y k ) = cos(e j , e k ), where e j is the embedding of the hypothesis reasoning path y j as determined by the all-mpnet-base-v2 HuggingFace sentence embedding model.</p>
<p>â€¢ BERT and BLEURT scorers: Following wisdom of the crowd work Suzgun et al. ( 2022), we try BLEURT (Sellam et al., 2020) and BERTSCORE (Zhang et al., 2019) metrics as similarity function S in Equation 4. â€¢ Informativeness scorer: We select the final hypothesis based on the amount of information shared between the source context c and the reasoning paths, measured through mutual alignment.Specifically, we use the Info-chain score defined as I(y j , c) in (Golovneva et al., 2022), and revise Equation 4for this scorer function as y * = arg max yj âˆˆY I(y j , c).</p>
<p>â€¢ Verifier models: We select the final hypothesis reasoning path and the answer based on the score provided by a pre-trained verifier model.We use FLAN-T5-XL and TEXT-DAVINCI-003 models to rank the hypothesises and select the one ranked at the top.To score the hypothesises, models are prompted to evaluate the correctness of the reasoning path, then hypothesises are ranked based on returned faithfulness score.We provide more details of the ranking method in Appendix E.</p>
<p>Few-shot prompts used for GSM8K dataset Answer these questions:</p>
<p>Q: There are 15 trees in the grove.Grove workers will plant trees in the grove today.After they are done, there will be 21 trees.How many trees did the grove workers plant today?A: There are 15 trees originally.Then there were 21 trees after some more were planted.So there must have been 21 -15 = 6.The answer is 6.</p>
<p>Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?A: There are originally 3 cars.2 more cars arrive.3 + 2 = 5.The answer is 5.The answer is 9.</p>
<p>Q: There were nine computers in the server room.Five more computers were installed each day, from monday to thursday.How many computers are now in the server room?A: There were originally 9 computers.For each of 4 days, 5 more computers were added.So 5 * 4 = 20 computers were added.9 + 20 is 29.The answer is 29.</p>
<p>Q: Michael had 58 golf balls.On tuesday, he lost 23 golf balls.On wednesday, he lost 2 more.How many golf balls did he have at the end of wednesday?A: Michael started with 58 golf balls.After losing 23 on tuesday, he had 58 -23 = 35.After losing 2 more, he had 35 -2 = 33 golf balls.The answer is 33.</p>
<p>Q: Olivia has $23.She bought five bagels for $3 each.How much money does she have left?A: Olivia had 23 dollars.5 bagels for 3 dollars each will be 5 x 3 = 15 dollars.So she has 23 -15 dollars left. 23 -15 is 8.The answer is 8.</p>
<p>Few-shot prompts used for StrategyQA dataset</p>
<p>Answer these questions:</p>
<p>Q: Do hamsters provide food for any animals?A: Hamsters are prey animals.Prey are food for predators.Thus, hamsters provide food for some animals.The answer is yes.</p>
<p>Q: Could Brooke Shields succeed at University of Pennsylvania?A: Brooke Shields went to Princeton University.Princeton University is about as academically rigorous as the University of Pennsylvania.Thus, Brooke Shields could also succeed at the University of Pennsylvania.The answer is yes.</p>
<p>Q: Yes or no: Hydrogen's atomic number squared exceeds number of Spice Girls?</p>
<p>A: Hydrogen has an atomic number of 1. 1 squared is 1.There are 5 Spice Girls.Thus, Hydrogen's atomic number squared is less than 5.The answer is no.</p>
<p>Q: Yes or no: Is it common to see frost during some college commencements?A: College commencement ceremonies can happen in December, May, and June.December is in the winter, so there can be frost.Thus, there could be frost at some commencements.The answer is yes.</p>
<p>Q: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?A: The War in Vietnam was 6 months.The gestation period for a llama is 11 months, which is more than 6 months.Thus, a llama could not give birth twice during the War in Vietnam.The answer is no.</p>
<p>Q: Before getting a divorce, what did the wife feel who was doing all the work?Answer Choices:: (A) harder (B) anguish (C) bitterness (D) tears (E) sadness</p>
<p>A: The answer should be the feeling of someone getting divorced who was doing all the work.Of the above choices, the closest feeling is bitterness.The answer is C. Table 3: Prompts used for hypothesis generation per dataset.</p>
<p>E Verifier model</p>
<p>To rank the generated hypothesises we can use pre-trained LLMs to that known to be well calibrated with respect to the True/False questions, and thus were used for self-evaluation (Kadavath et al., 2022).We adopt this approach and extend it to using any external LLM model by prompting it with 5 shots of multiple-choice questions to identify if the generated reasoning is (A) correct or (B) incorrect.We use FLAN-T5 and TEXT-DAVINCI-003 models for evaluation, and extract the probability of the reasoning being correct as a faithfulness score.We note that FLAN-T5 is finetuned on the training partitions of CSQA and GSM8K, and thus will have somewhat inflated performance in comparison to comparably sized models not trained on these tasks.We follow Xie et al. (2023) and use the probability of the option A as a score to rank and select generations.</p>
<p>(1) PATHFINDER (LLAMA-7B, N-gram): uses LLAMA-7B model for text generation, and tri-gram similarity for candidate selection; (2) PATHFINDER (LLAMA-7B, FLAN-T5-XL): uses LLAMA-7B model for text generation, and FLAN-T5-XL verifier model for candidate selection; (3) PATHFINDER (LLAMA-7B, TEXT-DAVINCI-003) uses LLaMa-7B model for text generation, and TEXT-DAVINCI-003 verifier model from the family of GPT-3.5 models for candidate selection.</p>
<p>Figure 2 :
2
Figure 2: The impact of different similarity-based scoring functions and verifier models (vertical axis) on the accuracy score (horizontal axis) of PATHFINDER, utilizing LLAMA-7B as backbone LLMs, on the CSQA and GSM8K datasets.We use buffer size 128 with branching factor of 8 for CSQA, and buffer size 16 with branching factor of 4 for GSM8K dataset.Scoring functions score and rank hypothesises based on similarity metrics, while verifier model ranks hypothesises based on the generated faithfulness score.</p>
<p>Figure 3 :
3
Figure 3: PATHFINDER (LLAMA-7B, N-gram) accuracy scores on CSQA dataset as a function of barnching factor (left) and buffer size (right).On the right figure we also include the results where we use LLAMA-7Bto generate the whole reasoning path for each candidate, and then apply tri-gram scorer model on the number of generated candidates corresponding to the buffer size value (denoted as end-to-end generation).Decoding process is sensitive to the amount of noise, which results in the existence of an optimal branching factor that maximizes the final accuracy.For each branching factor there is a limit on the maximal number of diverse branches the model can generate, and increasing buffer size after this point does not result in bigger trees, and we observe a platoe in terms of accuracy scores.</p>
<p>offer high-quality results but can lack diversity and are prone to degeneration.Truncation-based sampling methods such as temperature sampling, top-k sampling, top-p sampling and locally typical sampling have been used to balance this trade-off Holtzman et al. (2020); Meister et al. (2023).The advent of autoregressive LLMs like GPT has spurred numerous works focusing on various factors such as diversity Ippolito et al. (2019), fluency Holtzman et al. (2020), and constraint satisfaction Anderson et al. (2017); Miao et al. (2019); Welleck et al. (2019); Lu et al. (2021) in decoding strategies.Constrained decoding methods have seen enhancements like grid beam search Anderson et al. (2017) and constrained beam search Hokamp and Liu (2017) that aim at satisfying lexical constraints during generation.Other works such as Metropolis-Hastings samplingbased conditional generation Miao et al. (2019) and tree-based constrained text generation Welleck et al. (</p>
<p>Table 1 :
1
Common techniques are using scorer functions and verifier models.Scorer functions Suzgun et al. (2022); Prasad et al. (2023) help rank fixed set of candidate generations and guide the selection of the final prediction based on some property of the generated text, such as similarity.On the other hand verifier models Li et al. (2023) Performance of different models on four reasoning benchmark datasets measured with accuracy.Best numbers are bolded among models and the second best numbers are underlined.
ModelGSM8K StrategyQA CSQAGPT-6.7B2.450.024.0MINERVA-8B16.2--LLAMA-7B11.061.1<em>43.3</em>LLAMA-7B (self consistency)15.3<em>64.8</em>46.9<em>FLAN-T5-XL (3B)13.573.4</em>85.4*PATHFINDER (LLAMA-7B, N-gram)11.359.050.0PATHFINDER (LLAMA-7B, FLAN-T5-XL)11.760.855.1PATHFINDER (LLAMA-7B, TEXT-DAVINCI-003)15.461.756.3
use external models to explicitly evaluate the correctness of the produced hypothesis, and rank generations based on the faithfulness score.We validate PATHFINDER against verifier models and different similarity-based scorers in our ablation studies in Section 4. We note that the usage of a suitable scoring function is preferred over a verifier model as it would improve runtime and reduce memory load.</p>
<p>Table 2 :
2
Average
DatasetEnd-to-end24816GSM8K0.80.51.6 5.3-StrategyQA0.20.20.8 1.6 3.3CSQA0.070.06 0.2 0.6 1.4
GPU-hours required LLAMA-7B model to generate a reasoning tree for different branching factors br.Batch of 16 samples was used in all datasets.All numbers are calculated for buffer size 8, we also report average GPU-hours for end-to-end generation and sampling size 8.</p>
<p>Leah had 32 chocolates and her sister had 42.If they ate 35, how many pieces do they have left in total?A: Originally, Leah had 32 chocolates.Her sister had 42.So in total they had 32 + 42 = 74.After eating 35, they had 74 -35 = 39.The answer is 39.Jason had 20 lollipops.He gave Denny some lollipops.Now Jason has 12 lollipops.How many lollipops did Jason give to Denny?A: Jason started with 20 lollipops.Then he had 12 after giving some to Denny.So he gave Denny 20 -12 = 8.The answer is 8. Shawn has five toys.For Christmas, he got two toys each from his mom and dad.How many toys does he have now?A: Shawn started with 5 toys.If he got 2 toys each from his mom and dad, then that is 4 more toys.5 + 4 = 9.</p>
<p>Q:Q: Q:</p>
<p>We also attempted to generate results using the self-evaluation guided decoding method described inXie et al. (2023) for the LLaMa-7B model. However, the process was slow and computationally expensive: Reducing the beam size to 2 and number of samples at each step to 4, this method took over 4 days to run and achieved an accuracy of 9.5 on GSM8K and 58.3 on StrategyQA.
A LimitationsOur study is limited by the number of models and tasks we used to empirically support the proposed approach.Although PATHFINDER outperforms other baselines on selected tasks, it comes with significant increase in computational complexity.To be able to efficiently use tree-search-based step-level decoding, we would need to develop more effective sampling and scoring techniques that will allow us to achieve high-quality results faster and at lower computational costs.B Ethics StatementOur method, PATHFINDER, improves text generation, specifically focused on step-by-step rationale generation from large language models.Thus, it inherits the potential benefits and risks associated with text generation applicationsBrown et al. (2020).By imposing logical constraints on text generation, we aim to enhance control, consistency, and accuracy, specifically in tasks that require step-by-step reasoning, such as arithmetic reasoning.We would like to note that any language model, even under constraints could potentially be exploited to produce biased, or offensive narrativesMcGuffie and Newhouse (2020).For in-depth exploration of these risks, we direct the reader to the analysis presented in(Bender et al., 2021).Q: Yes or no: Would a pear sink in water?A: The density of a pear is about 0.6g/cm3, which is less than water.Objects less dense than water float.Thus, a pear would float.The answer is no.
Guided open vocabulary image captioning with constrained beam search. Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould, 10.18653/v1/D17-1098Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational Linguistics2017</p>
<p>On the dangers of stochastic parrots: Can language models be too big? FAccT '21, page 610-623. Emily M Bender, Timnit Gebru, Angelina Mcmillan-Major, Shmargaret Shmitchell, 10.1145/3442188.34459222021Association for Computing MachineryNew York, NY, USA</p>
<p>Alec Radford, Ilya Sutskever, and Dario Amodei. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlishCurran Associates, Inc202033Language models are few-shot learners</p>
<p>Chung Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, arXiv:2210.11416Scaling instruction-finetuned language models. 2022arXiv preprint</p>
<p>Peter Clark, Oyvind Tafjord, Kyle Richardson, Transformers as soft reasoners over language. IJCAI. 2020</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance. Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, Tushar Khot, arXiv:2305.173062023arXiv preprint</p>
<p>Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, Pal: Program-aided language models. 2023</p>
<p>Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, Transactions of the Association for Computational Linguistics. 92021</p>
<p>Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz, arXiv:2212.07919Roscoe: A suite of metrics for scoring step-by-step reasoning. 2022arXiv preprint</p>
<p>Sequence transduction with recurrent neural networks. Alex Graves, 2012</p>
<p>Reasoning with language model is planning with world model. Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, 2023</p>
<p>Lexically constrained decoding for sequence generation using grid beam search. Chris Hokamp, Qun Liu, 10.18653/v1/P17-1141Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20171</p>
<p>The curious case of neural text degeneration. Ari Holtzman, Jan Buys, Maxwell Forbes, Yejin Choi, 2020ICLR</p>
<p>HuggingFace. sentence-transformers/all-mpnet-base-v2. </p>
<p>Comparison of diverse decoding methods from conditional language models. Daphne Ippolito, Reno Kriz, JoÃ£o Sedoc, Maria Kustikova, Chris Callison-Burch, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics2019</p>
<p>Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition. Dan Jurafsky, James H Martin, 2009Pearson Prentice HallUpper Saddle River, N.J.</p>
<p>Language models (mostly) know what they know. Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield Dodds, Nova Dassarma, Eli Tran-Johnson, arXiv:2207.052212022arXiv preprint</p>
<p>Six challenges for neural machine translation. Philipp Koehn, Rebecca Knowles, 10.18653/v1/W17-3204Proceedings of the First Workshop on Neural Machine Translation. the First Workshop on Neural Machine TranslationVancouver. Association for Computational Linguistics2017</p>
<p>Less annotating, more classifying-addressing the data scarcity issue of supervised machine learning with deep transfer learning and bert-nli. , Moritz Laurer, Andreu W V Atteveldt, Kasper Casas, Welbers, 2022</p>
<p>Solving quantitative reasoning problems with language models. Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, Vedant Misra, Advances in Neural Information Processing Systems. 2022</p>
<p>Making large language models better reasoners with step-aware verifier. Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, Weizhu Chen, 2023</p>
<p>NeuroLogic decoding: (un)supervised neural text generation with predicate logic constraints. Ximing Lu, Peter West, Rowan Zellers, Le Ronan, Chandra Bras, Yejin Bhagavatula, Choi, 10.18653/v1/2021.naacl-main.339Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterOnline. Association for Computational Linguistics2021</p>
<p>The radicalization risks of GPT-3 and advanced neural language models. Kris Mcguffie, Alex Newhouse, 2020CoRR</p>
<p>Clara Meister, Tiago Pimentel, Gian Wiher, Ryan Cotterell, Locally typical sampling. ACL. 2023</p>
<p>Cgmh: Constrained sentence generation by metropolis-hastings sampling. Ning Miao, Hao Zhou, Lili Mou, Rui Yan, Lei Li, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201933</p>
<p>Show your work: Scratchpads for intermediate computation with language models. I Maxwell, Anders Nye, Guy Johan Andreassen, Henryk Gur-Ari, Jacob Michalewski, David Austin, David Bieber, Aitor Dohan, Maarten Lewkowycz, David Bosma, Charles Luan, Augustus Sutton, Odena, CoRR, abs/2112.001142021</p>
<p>Archiki Prasad, Swarnadeep Saha, Xiang Zhou, Mohit Bansal, arXiv:2304.10703Receval: Evaluating reasoning chains via correctness and informativeness. 2023arXiv preprint</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto DessÃ¬, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, 2023</p>
<p>BLEURT: Learning robust metrics for text generation. Thibault Sellam, Dipanjan Das, Ankur Parikh, 10.18653/v1/2020.acl-main.704Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020</p>
<p>The art of llm refinement: Ask, refine, and. Kumar Shridhar, Koustuv Sinha, Andrew Cohen, Tianlu Wang, Ping Yu, Ram Pasunuru, Mrinmaya Sachan, Jason Weston, Asli Celikyilmaz, ; Trust, Luke Mirac Suzgun, Dan Melas-Kyriazi, Jurafsky, arXiv:2211.07634Follow the wisdom of the crowd: Effective text generation via minimum bayes risk decoding. 2023. 2022arXiv preprint</p>
<p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, arXiv:1811.00937Commonsenseqa: A question answering challenge targeting commonsense knowledge. 2018arXiv preprint</p>
<p>Commonsenseqa 2.0: Exposing the limits of AI through gamification. Alon Talmor, Ori Yoran, Le Ronan, Chandra Bras, Yoav Bhagavatula, Yejin Goldberg, Jonathan Choi, Berant, 2021NeurIPS</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, TimothÃ©e Lachaux, Baptiste Lacroix, Naman RoziÃ¨re, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, 2023</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou, arXiv:2203.111712022arXiv preprint</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H Chi, Quoc Le, Denny Zhou, CoRR, abs/2201.119032022</p>
<p>Non-monotonic sequential text generation. Sean Welleck, KiantÃ© Brantley, Hal DaumÃ© Iii, Kyunghyun Cho, International Conference on Machine Learning. PMLR2019</p>
<p>Decomposition enhances reasoning via self-evaluation guided decoding. Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, Qizhe Xie, 2023</p>
<p>Breaking the beam search curse: A study of (re-)scoring methods and stopping criteria for neural machine translation. Yilin Yang, Liang Huang, Mingbo Ma, 10.18653/v1/D18-1342Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational Linguistics2018</p>
<p>Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, arXiv:1904.09675Bertscore: Evaluating text generation with bert. 2019arXiv preprint</p>
<p>Denny Zhou, Nathanael SchÃ¤rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, and Ed Chi. 2023. Least-to-most prompting enables complex reasoning in large language models. </p>            </div>
        </div>

    </div>
</body>
</html>