<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4814 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4814</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4814</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-104.html">extraction-schema-104</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games, with a focus on how memory is used, the type of memory mechanisms, comparative performance with and without memory, and any recommendations or challenges regarding memory usage.</div>
                <p><strong>Paper ID:</strong> paper-d56c1e49fcc6a8effe90786af5c7d1f0a295a7a6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d56c1e49fcc6a8effe90786af5c7d1f0a295a7a6" target="_blank">Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> Neurocomputing</p>
                <p><strong>Paper TL;DR:</strong> This work proposes to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability and is a potential solution to enable the LLM to model the extremely long context.</p>
                <p><strong>Paper Abstract:</strong> Recently, large language models (LLMs), such as GPT-4, stand out remarkable conversational abilities, enabling them to engage in dynamic and contextually relevant dialogues across a wide range of topics. However, given a long conversation, these chatbots fail to recall past information and tend to generate inconsistent responses. To address this, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the chatbot can easily generate a highly consistent response with the help of the latest memory. We evaluate our method on both open and closed LLMs, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-context conversation. Also, we show that our strategy could nicely complement both long-context (e.g., 8K and 16K) and retrieval-enhanced LLMs, bringing further long-term dialogue performance. Notably, our method is a potential solution to enable the LLM to model the extremely long context. The code and scripts are released.</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4814",
    "paper_id": "paper-d56c1e49fcc6a8effe90786af5c7d1f0a295a7a6",
    "extraction_schema_id": "extraction-schema-104",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00316375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models</h1>
<p>Qingyue Wang ${ }^{\mathrm{a}}$, Yanhe $\mathrm{Fu}^{\mathrm{b}}$, Yanan Cao ${ }^{\mathrm{b}, *}$, Shuai Wang ${ }^{\mathrm{a}}$, Zhiliang Tian ${ }^{\mathrm{c}}$, Liang Ding $^{\mathrm{d}}$<br>${ }^{a}$ the Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China<br>${ }^{b}$ the institute of information engineering, Chinese Academy of Sciences, Beijing, China<br>${ }^{c}$ the College of Computer, National University of Defense Technology, Changsha, China<br>${ }^{d}$ the University of Sydney, Sydney, Australia</p>
<h4>Abstract</h4>
<p>Recently, large language models (LLMs), such as GPT-4, stand out remarkable conversational abilities, enabling them to engage in dynamic and contextually relevant dialogues across a wide range of topics. However, in a long-term conversation, these chatbots fail to recall appropriate information from the past, resulting in inconsistent responses. To address this, we propose to recursively generate summaries/ memory using large language models to enhance their long-term dialog ability. Specifically, our method first stimulates the LLM to memorize small dialogue contexts. After that, the LLM recursively produces new memory using previous old memory and subsequent contexts. Finally, the chatbot is prompted to generate a response based on the latest memory. The experiments on widely used LLMs show that our method generates more consistent responses in long-term</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>conversations, and it can be significantly enhanced with just two/ three dialog illustrations. Also, we find that our strategy could nicely complement both large context windows (e.g., 8 K and 16 K ) and retrieval-enhanced LLMs, bringing further long-term dialogue performance. Notably, our method is a potential solution to enable the LLM to model the extremely long dialog context. The code and scripts will be released later.</p>
<p>Keywords: recursive summary, long-term memory, large language models, dialog generation.</p>
<h1>1. Introduction</h1>
<p>Recently, large language models (LLMs), such as ChatGPT ${ }^{1}$ and GPT-4 (Achiam et al., 2023), demonstrate promising performances in various natural language applications (Brown et al., 2020; Zeng et al., 2022; Zhong et al., 2023; Lu et al., 2023b; Peng et al., 2023; Wu et al., 2023). One notable capability lies in their remarkable conversational prowess, comprehending input, and generating humanlike responses.</p>
<p>Large context windows allow many LLMs ${ }^{2}$ to process entire dialog histories, yet they often struggle to effectively comprehend past interactions and integrate key information into responses (Zhou et al., 2023). Applications such as personal AI companions, which need to recall past conversations for rapport building, and health assistants, which must consider a complete record of patient inquiries to provide diagnostic results, demonstrate the importance of maintaining consistency</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A long-term conversation example from the Multi-Session Chat Dataset (Xu et al., 2022a). When the user refers back to previous subjects (i.e., composing music), even the ChatGPT (gpt-turbo-3.5-0301 version) generates an inconsistent response.
and coherence in long-term dialogues. Figure 1 illustrates a dialog spanning over 20 turns, centered around a discussion of the speakers' personas (e.g., the bot composes music, and the user enjoys country music). However, even the powerful ChatGPT forgets past information and produces a poor response, showing the necessity to explicitly model long-term memory during conversations.</p>
<p>To address this, there are two mainstream methods to enhance the long-term dialog ability of LLMs. The first one is the retrieval-based method, which directly stores past conversational utterances in the storage and adapts an advanced retriever to identify the most relevant history (Guu et al., 2020; Lewis et al., 2020). However, it is difficult to obtain a well-performing (ideal) retriever, ensuring that the retrieved utterances capture the complete semantics about current conversations. The second way is to employ a memory module to summarize important conversation information to assist the LLM, which is also called memory-based</p>
<p>approaches (Mazar√© et al., 2018; Xu et al., 2022b; Chen et al., 2024a). They usually apply a separately trained model or a powerful large language model to generate memory for past dialogues. Nevertheless, these methods lack the necessary iteration mechanism on generated memory, resulting in the reserved outdated information directly hurting the quality of responses.</p>
<p>In this paper, we propose a simple and effective plug-in method that enables LLM itself to generate summaries, which store the real-time information of speakers through continuous updating and reviewing past context to aid long-term interactions. In practice, a generative LLM is first prompted to produce a summary given a short dialog context. After that, we ask the LLM to continue updating and generate a new summary/ memory by combining the previous memory and subsequent dialogues. Finally, we encourage the LLM to respond using the latest memory as the primary reference to engage the ongoing dialogue. Given that the generated summaries are much shorter than the full dialogues, our proposed schema not only models long-term conversation memory but also serves as a potential solution to enable current LLMs to handle extremely long contexts (across multiple dialogue sessions) without expensively expanding the maximum length setting.</p>
<p>Experimentally, we implement our method using a variety of state-of-theart open (Llama (Touvron et al., 2023) and ChatGLM (GLM et al., 2024)) and closed (OpenAI's GPT-3.5-Turbo) LLMs, and the performance on long-term dialog surpasses that of popular approaches both in automatic and human evaluations. Moreover, we verify the effectiveness of using explicit memory for longterm dialogs and using our generated memory is easier for LLMs to digest. These findings underscore the importance of developing advanced memory generation</p>
<p>strategies. Our method can further enhance response quality by incorporating the in-context learning (ICL) technique, where multiple samples in the format of (dialogue, memory, and golden response) are presented to LLMs. This allows them to utilize the generated memory more flexibly. Additionally, we demonstrate the generalizability of our approach across different LLMs, with our method achieving approximately a $+3 \%$ improvement in BLEU score on text-davinci-003. Finally, we observe that our schema complements existing window-extended LLMs (e.g., GPT-3.5-Turbo-16k and LongLoRA-8k) and retrieval-enhanced LLMs (e.g., LLM-BM25 and LLM-DPR), producing more coherent and consistent responses in long-term conversations.</p>
<p>In summary, our contributions are as follows:</p>
<ul>
<li>We propose a novel method by recursively summarizing past dialogues to enhance the LLM's memory, enabling the generation of highly consistent responses in long-term conversations.</li>
<li>The solid experiments on the public datasets show the superiority of the proposed method, with multiple open-source and closed-source LLMs verifying its universality and robustness.</li>
<li>The simplicity of our method makes it nicely complements existing works, including retrieval-based and long-context techniques, having the great potential to be an orthogonal plug-in for the LLM community.</li>
</ul>
<h1>2. Related Work</h1>
<h3>2.1. Large Language Models</h3>
<p>Language language models (LLMs) have shown outstanding performance in a variety of user-facing language technologies, including conversation, summarization, and creative writing (Achiam et al., 2023; Shuster et al., 2022; Rubin and Berant, 2024). While these LLMs achieve notable success in many popular tasks, their ability to model long text remains a challenge (An et al., 2023). To address the problem, some works are to adapt transformers to accommodate longer inputs, such as position interpolation (Chen et al., 2023) and efficient self-attention (Beltagy et al., 2020; Chen et al., 2024b). However, these context window-extended LLMs not only require continual training on high-quality long texts but still struggle to use and retrieve the core information from the entire input (Liu et al., 2023). Recently, in question-answer task, some researchers found that the performances of LLMs degrade significantly when people change the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts (Liu et al., 2023; Li et al., 2023). Many works suggest that the lack of explicit memory mechanisms in current LLMs hinders their performance on tasks requiring sustained context awareness and understanding (Chen et al., 2024a). Nowadays, the performance of LLMs has not yet been explored deeply in long-range dialogue scenarios. This work focuses on developing the long-term modeling ability of the LLM, where we prompt it to self-memory, self-update, and self-use in conversations, aiding consistent response generation.</p>
<h1>2.2. Long-term Open-Domain Dialogue</h1>
<p>Open-domain dialogue systems (Liu et al., 2016; Zhang et al., 2018; Kann et al., 2022), also known as chatbots or conversational agents, have gained immense popularity and a lot of studies in recent years. Among them, the long-term conversation setting is pretty a hard problem, because it needs the capability of understanding and memorizing key dialogue history information (Wu et al., 2022; Zhang et al., 2022) about current query. The most popular and potential solution is to directly store the partial information for tracking the history of conversation (Lee et al., 2023), usually in the form of dialogue utterances or summaries. The current conversation and relevant information are then inputted into the response generator. One intuitive idea is to apply a retriever to find the most relevant utterances according to the current dialog, which is called as the retrievalbased method. Another popular method is a memory-based method, which tries to generate and manage the summary to obtain key information from history. For example, MemoChat (Lu et al., 2023a) allows chatbots to reorganize the past dialogue histories according to different topics of speakers and prompt the LLM to retrieve from the structured memory during generation. Going further, MemoryBank (Zhong et al., 2024) proposes a new memory mechanism by generating summaries for each dialog session first and then compressing them into a global one. However, their memory is completely fixed once stored, failing to guarantee its consistency with ongoing dialog. The important comparison between these existing methods and ours is shown in Figure 2. As seen, our approach and these methods mainly diverge in the way of memory generation, where we continuously integrate historical information and old memory to obtain real-time memory, enabling the gain of accurate memory and modeling of long-distance dependencies.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Comparison among baselines and ours. The "U", "S", "T", and "M" are abbreviations for the Utterance, Session, dialog Topic, and Memory. The red dashed box refers to the memory used to generate the response.</p>
<h1>3. Approach Overview</h1>
<p>Following previous works (Xu et al., 2022a; Bae et al., 2022), we denote that a long-context dialogue consists of multiple sessions with a specific user, which is also called Multi-Session Dialogue. The goal of the task is to generate contextrelevant and highly consistent responses to the user based on past sessions and current context. Formally, each dialogue can be written as $D=\left{S, C_{t}, r_{t}\right}$. Here, $S=\left{S_{1}, S_{2}, \ldots, S_{N}\right}$ represents $N$ past sessions and each of the sessions consists of multiple utterances between two speakers. $r_{t}$ is the ground truth response to $C_{t}$ with background sessions $S . C_{t}=\left{u_{1}, r_{1}, \ldots, u_{t}\right}$ denotes the dialogue context of the current session at $t$ step, where $u$ and $r$ represent the utterances from the user and the chatbot, respectively.</p>
<p>In this paper, we propose a new memory mechanism to aid a large language model for multi-session dialog tasks. The memory contains multiple natural language sentences, storing the key information of speakers extracted from previous sessions. Our goal is to obtain a reliable memory given past sessions and predict a consistent and meaningful response using the current dialogue context and the</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The schematic overview of our method. The model uses the first session to generate initial memory (green arrows), then updates the memory when the second session ends (yellow arrows), and generates a response using the latest memory at the third session (blue arrows).
memory. Specifically, we decompose the goal into two stages with the following probability distribution:</p>
<p>$$
P\left(r_{t} \mid C_{t}, S\right)=P\left(r_{t} \mid C_{t}, M_{N}\right) P\left(M_{N} \mid S\right)
$$</p>
<p>where $M_{i}$ represents the available memory when the $i$-th session is finished. And $P\left(M_{N} \mid S\right)=\prod_{i=1}^{N} P\left(M_{i} \mid S_{i}, M_{i-1}\right)$ is a sequential or Markov process where each memory $M_{i}$ of session $i$ depends only on the current session and the previous memory $M_{i-1}$.</p>
<h1>4. Approach</h1>
<p>To achieve long-term dialog, we prompt an arbitrary large language model to finish two tasks, i.e., memory iteration and memory-based response generation. The former is responsible for recursively summarizing the key information along with long-term dialogue, and the latter is to incorporate the latest mem-</p>
<p>ory and current dialog to generate an appropriate and consistent response. The workflow of our proposed method is shown in Figure 3.</p>
<h1>4.1. Memory Iteration</h1>
<p>The goal of memory iteration is to obtain a coherent and up-to-date summary for the chatbot. Early works (Bae et al., 2022; Choi et al., 2023) update memory by carrying multiple "hard operations" on summaries, such as replace, append, and delete, which rely on high-quality dialogue with operation labels. However, this laborious design disrupts the semantic coherence of the summary and is not suitable for management over a long period. Differently, we guide the LLMs to recursively self-generate memory (summaries) using dialogue context and previous memory. By utilizing old summaries, the model can fully digest the current dialog context and thus gain a high-quality memory. Formally, the updated memory is computed by:</p>
<p>$$
M_{i}=\boldsymbol{L} \boldsymbol{L} \boldsymbol{M}\left(S_{i}, M_{i-1}, \mathrm{P}_{m}\right)
$$</p>
<p>where $M_{i}=\left{m_{1}, m_{2}, \ldots, m_{J}\right}$ denotes multiple sentences, containing summarized key information from the session $S_{i}$, and $\mathrm{P}<em N="N">{\mathrm{m}}$ is the prompt of LLM for generating new memory. The memory iteration will be repeated $N$ times until all previous sessions end, where we can obtain the latest memory $M</em>$. Take the dialog in Figure 3 as an example, two memory iterations happen at the end of the first and second sessions. In the second iteration, the LLM incorporates the new personality (i.e., the bot recently joined a new gym) from Session 2 into the old memory (i.e., the bot enjoys walking and running).</p>
<p>Prompt Construction. To enable LLM to efficiently carry the memory iteration task, we design a specific prompt for it, which is shown in Table 1. It mainly</p>
<p>Table 1: The prompt design of memory iteration, including task definition, task description and task inputs</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">You are an advanced AI language model with the ability to store and update a memory to keep track of</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">key personality information for both the user and the bot. You will receive a previous memory and</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">dialogue context. Your goal is to update the memory by incorporating the new personality information.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">To successfully update the memory, follow these steps:</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">1.Carefully analyze the existing memory and extract the key personality of the user and bot from it.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">2. Consider the dialogue context provided to identify any new or changed personality that needs to</td>
</tr>
<tr>
<td style="text-align: left;">Prompt</td>
<td style="text-align: left;">be incorporated into the memory.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">3. Combine the old and new personality information to create an updated representation of the user and</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">bot's traits.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">4. Structure the updated memory in a clear and concise manner, ensuring it does not exceed 20 sentences.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Remember, the memory should serve as a reference point to</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">maintain continuity in the dialogue and help you respond accurately to the user based on their personality.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">[Previous Memory] [Session Context]</td>
</tr>
<tr>
<td style="text-align: left;">Output</td>
<td style="text-align: left;">[Updated Memory]</td>
</tr>
</tbody>
</table>
<p>consists of three parts: (1) Task definition is responsible for defining the role of the current LLM, as well as the memory iterator's (LLM) input and output. (2) Task description gives detailed steps to finish the above task. To make sure the memory update is timely, we remind the LLM to create a new representation of speakers by considering old summaries and current sessions.(3) Task input contains two placeholders, where we take previous memory and a whole session as the inputs. Through experimental verification, we found that using step-by-step instructions helps the LLM better understand and execute the memory iteration ${ }^{3}$.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 2: The prompt of memory-based response generation, including task definition, task description and task inputs</p>
<table>
<thead>
<tr>
<th>Prompt</th>
<th>You will be provided with a memory containing personality information for both yourself and the user.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Your goal is to respond accurately to the user based on the personality traits and dialogue context.</td>
</tr>
<tr>
<td></td>
<td>Follow these steps to successfully complete the task:</td>
</tr>
<tr>
<td></td>
<td>1. Analyze the provided memory to extract the key personality traits for both yourself and the user.</td>
</tr>
<tr>
<td></td>
<td>2. Review the dialogue history to understand the context and flow of the conversation.</td>
</tr>
<tr>
<td></td>
<td>3. Utilize the extracted personality traits and dialogue context to formulate an appropriate response.</td>
</tr>
<tr>
<td></td>
<td>4. If no specific personality trait is applicable, respond naturally as a human would.</td>
</tr>
<tr>
<td></td>
<td>5. Pay attention to the relevance and importance of the personality information, focusing on capturing</td>
</tr>
<tr>
<td></td>
<td>the most significant aspects while maintaining the overall coherence of the memory.</td>
</tr>
<tr>
<td></td>
<td>[Previous Memory] [Current Context]</td>
</tr>
<tr>
<td>Output</td>
<td>[Response]</td>
</tr>
</tbody>
</table>
<h1>4.2. Memory-based Response Generation</h1>
<p>The final goal is to produce consistent and natural responses given dialogue memory and the context of the current session. Formally, the response of the current session can be obtained by stimulating the LLM as a response generator:</p>
<p>$$
r_{t}=\boldsymbol{L} \boldsymbol{L} \boldsymbol{M}\left(C_{t}, M_{N}, \mathrm{P}_{\mathrm{r}}\right)
$$</p>
<p>where $P_{r}$ is a prompt of the generator. Especially, taking the generated memory $M_{N}$ and current session $C_{t}$, we ask the LLM again to generate a response. In Figure 3, the LLM considers the newest memory from Session 2 and provides a high consistent response to the user, i.e., " more flexibility with a 24 -hour gym membership".</p>
<p>Prompt Construction. The the prompt for memory-based response generation is shown in Table 2. The prompt is similar to that of memory iteration, including task definition, description, and inputs, where we remind the LLM to utilize the</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="o">:</span><span class="w"> </span><span class="nt">Response</span><span class="w"> </span><span class="nt">generation</span><span class="w"> </span><span class="nt">using</span><span class="w"> </span><span class="nt">recursive</span><span class="w"> </span><span class="nt">memory</span><span class="o">.</span>
<span class="w">    </span><span class="nt">Input</span><span class="o">:</span><span class="w"> </span><span class="nt">A</span><span class="w"> </span><span class="nt">long-term</span><span class="w"> </span><span class="nt">dialog</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">D</span><span class="o">=</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="p">{</span><span class="err">S,</span><span class="w"> </span><span class="err">C_{t</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="err">\}\</span><span class="o">)</span><span class="w"> </span><span class="nt">consisting</span><span class="w"> </span><span class="nt">multiple</span><span class="w"> </span><span class="nt">sessions</span><span class="w"> </span><span class="nt">with</span>
<span class="w">        </span><span class="nt">a</span><span class="w"> </span><span class="nt">user</span><span class="o">;</span><span class="w"> </span><span class="nt">A</span><span class="w"> </span><span class="nt">generative</span><span class="w"> </span><span class="nt">pre-trained</span><span class="w"> </span><span class="nt">model</span><span class="w"> </span><span class="nt">LLM</span><span class="o">;</span><span class="w"> </span><span class="nt">Pre-defined</span><span class="w"> </span><span class="nt">prompt</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">P_</span><span class="p">{</span><span class="err">m</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">P_</span><span class="p">{</span><span class="err">r</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="nt">Output</span><span class="o">:</span><span class="w"> </span><span class="nt">A</span><span class="w"> </span><span class="nt">response</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="nt">user</span><span class="o">.</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">1</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">0</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">none</span><span class="o">;</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="nt">Set</span><span class="w"> </span><span class="nt">initial</span><span class="w"> </span><span class="nt">memory</span><span class="w"> </span><span class="nt">as</span><span class="w"> </span><span class="nt">empty</span>
<span class="w">    </span><span class="nt">2</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">i</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">1</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">N</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">    </span><span class="nt">3</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">quad</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">=</span><span class="nt">L</span><span class="w"> </span><span class="nt">L</span><span class="w"> </span><span class="nt">M</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">S_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">i-1</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">P_</span><span class="p">{</span><span class="err">m</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="o">;</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="nt">Update</span><span class="w"> </span><span class="nt">memory</span><span class="w"> </span><span class="nt">when</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">session</span><span class="w"> </span><span class="nt">ends</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">4</span><span class="w"> </span><span class="nt">r_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="o">=</span><span class="nt">L</span><span class="w"> </span><span class="nt">L</span><span class="w"> </span><span class="nt">M</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">C_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">P_</span><span class="p">{</span><span class="err">r</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="o">;</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="nt">Response</span><span class="w"> </span><span class="nt">using</span><span class="w"> </span><span class="nt">latest</span><span class="w"> </span><span class="nt">memory</span>
<span class="w">    </span><span class="nt">5</span><span class="w"> </span><span class="nt">return</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">r_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
</code></pre></div>

<p>extracted information and maintain the consistency of memory when responding. Also, the step-by-step instructions method is also effective for memory-based response generation.</p>
<h1>4.3. Algorithm</h1>
<p>The process of response generation using recursive memory is illustrated in Algorithm 1. In the beginning, the initial memory is set as an empty, i.e., "none" string. After that, we recursively update the memory using each session context (line 3). Finally, the LLM generates a response with the help of the latest memory (line 5). The generative pre-trained models used for memory iteration and response generation can be different. For instance, the developers can train a private memory iterator through customized models or data, to enhance the target open/</p>
<p>closed LLMs for long-term or long-context tasks.</p>
<h1>5. Experimental Settings</h1>
<h3>5.1. Datasets</h3>
<p>We validate the effectiveness of the proposed method on two widely-used long-term dialogue datasets: Multi-Session Chat (MSC) dataset (Xu et al., 2022a) and Carecall dataset (Bae et al., 2022).</p>
<p>MSC dataset. is the largest human-human long conversations dataset so far. The early sessions are a short conversation where two speakers get to know each other for the first time and then they either continue to talk about the previous subject or spark up conversation on a new topic.</p>
<p>Carecall. is a Korean open-domain multi-session dataset, which is used for monitoring patient health. For a fair comparison, we use the public machine-translated English version ${ }^{4}$ in the experiments.</p>
<p>The CareCall's setting is similar procedure presented in the MSC dataset. The main difference is that the Carecall additionally contains more persona updates that are likely to change in a short period, such as the user's health and diet, while the persona information in the MSC dataset remains fixed once it is stored. Both of the two datasets have five sessions and each one consists of multiple utterances between two speakers (the user and chatbot), where the conversationalists reengage after several hours or days and continue chatting. As early sessions only have a very short history of conversations, we mainly evaluate the proposed method in</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>session 4 and 5 for the ability of long-term modeling. The statistics of two datasets are given in Appendix A.</p>
<h1>5.2. Evaluation Metrics</h1>
<p>we conduct diverse evaluations during experiments, including automatic metrics, human evaluation, and LLM judgments, focusing on the quality of generated memory and response.</p>
<p>Automatic Metrics. We employ BLEU-1/2 (Papineni et al., 2002), F1 with reference to the human annotations. Besides, we compute BertScore (Li et al., 2016) to measure the semantics similarity between the references and the generated responses.</p>
<p>Human Evaluation. Many works point out that automatic evaluation metrics are insufficient for capturing the nuances of conversations (Deriu et al., 2019). Following the previous works (Bae et al., 2022), we ask three crowd-sourcing workers to assign a score from 0 to 2 (0:bad, 1:OK, 2:good) to the generated responses based on the aspects of engagingness, coherence, and consistency. These criteria are discussed as follows: (1) Engagingness: It evaluates whether the chatbot captures the user's interest and makes them want to continue the conversation. A high score on engagingness means the responses are interesting and contextually appropriate, encouraging users to keep chatting. (2) Coherence: It measures whether the response maintains a logical and clear flow based on the conversation's context. A coherent response ensures the conversation makes sense and stays relevant, enhancing user engagement. (3) Consistency: It assesses whether the response aligns with the information provided in previous interactions. Con-</p>
<p>sistent responses build trust and reliability by demonstrating that the chatbot remembers and integrates past exchanges accurately.</p>
<p>LLM Evaluation. Recently, LLM-as-a-Judge strategy (Pan et al., 2023) has been widely used in evaluating generation tasks. Some works reveal minimal deviation of GPT-4's evaluation from humans ( $&gt;0.85$ agreements) in dialog quality (Zhang et al., 2023a). Inspired by this, we employ the GPT-4 as an advanced evaluator, using two common methods to assess the quality of generated responses. (1) Single model evaluation (Lu et al., 2023a): we prompt GPT-4 to rate the responses individually from the three aspects, i.e., engagingness, coherence and consistency with an integer scale from 1 (very bad) to 100 (very good). (2) Pairwise model evaluation (Dubois et al., 2024): we ask the GPT-4 to directly compare two anonymous generations and determine which response is better. While single model evaluation provides detailed insights into specific aspects of each response, pairwise comparison is essential for understanding relative performance, particularly when distinguishing subtle differences between outputs.</p>
<h1>5.3. Baselines</h1>
<p>We mainly employ the following methods for long-text dialogues in LLMs: context-only approaches (without using any memory), retrieval-based approaches (with different retrievers), and memory-based approaches (with different memory mechanisms)</p>
<p>Context-only Approach. It is the most naive approach to directly employ the LLM as a chatbot, where it concatenates past sessions and current dialogue context as</p>
<p>the input. We use "Llama2-7B" (Touvron et al., 2023), "ChatGLM2-6B"5, and OpenAI ChatGPT "gpt-3.5-turbo-0301" as the backbone LLMs for the contextonly approach ${ }^{6}$.</p>
<p>Retrieval-based Approach. Many previous works (Xu et al., 2022a) employ retrievers to filter key information and then include top- $k$ documents into inputs to assist long-context dialogs. For the long-term dialog, the top- $k$ documents refer to the relevant utterances from history. Here, we choose two widely used retrieval algorithms, i.e., BM25 (Robertson et al., 2009) and pre-trained dense passage retrieval (DPR) (Karpukhin et al., 2020), to look up the relevant utterances from past sessions. For convenience, we name the above retrieval-based baselines as ChatGPT-BM25 and ChatGPT-DPR, respectively.</p>
<p>Memory-based Approach. Recent works employ a summarizer to abstract important information from the past to aid long-term conversation. Simply, we just choose two representative methods from various memory-based techniques, MemoryBank (Zhong et al., 2024) and MemoChat (Lu et al., 2023a). MemoryBank proposes a human-like long-term memory mechanism, which creates ordered summaries of past dialogs with timestamps, and then reorganizes them to obtain the global memory. The memory will be forgotten and updated by Ebbinghaus's forgetting curve. Here, we plug MemoryBank with ChatGPT as a strong baseline, named ChatGPT-MemoryBank. Differently, MemoChat maintains the structured conversational memory to aid long-term dialogue, i.e., generating the summaries for each dialogue topic. We plug the MemoChat into ChatGPT, named</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>ChatGPT-MemoChat, for a fair comparison with others.
Note that our approach focuses on the zero-shot setting for LLMs to engage in a long-term dialog, making the comparisons with other fine-tuned models unfair.</p>
<h1>5.4. Implementation</h1>
<p>We implement our method by letting the LLM response using recursively generated memory in a long-term dialogue, thus it is called as "LLM-Rsum".</p>
<p>Backbone LLMs. We employ OpenAI ChatGPT "gpt-3.5-turbo-0301", "Llama2$7 B$ " and "ChatGLM2-6B" in the main experiments, "text-davinci-003" and "Llama2$7 B$ " (Touvron et al., 2023) in the analysis to show the universality, "longlora$8 k$ " (Chen et al., 2024b) and ChatGPT-16k "gpt-3.5-turbo-16k" as the backbones of complementary discussion. Unless otherwise specified, we employ the same LLM to finish the memory iteration and memory-based response generation. During generation, we set the temperatures of all LLMs as 0 for fair comparisons. The max length of input tokens for Carecall and MSC datasets is no more than 4 k , thus all backbone LLMs in experiments can process the entire dialog context.</p>
<p>Retrievers. Considering the scale of past utterances is not large enough to use the FAISS (Research, 2019), we choose the top-k most relevant utterances that will be combined with ongoing dialogues, prompting the LLM to respond. Following previous works (Xu et al., 2022a) for long-term dialogs, the k is set into 3 and 5.</p>
<p>Memory-based Approaches. The implementation and prompt design of the MemoryBank and Memochat methods are based on the code publicly released in their original papers. For details, please refer to the original papers.</p>
<p>Table 3: Comparison of automatic and human evaluations among different methods on MSC and Carecall datasets, reporting the quality of generated response. The "BScore", "Enga.", "Cohe" and "Cons" are the abbreviations of BertScore, Engagingness, Coherence, and Consistency. The best value is bolded.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>MSC Dataset</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th>Carecall Datset</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>F1</td>
<td>BLEU-1/2</td>
<td>BScore</td>
<td>Enga.</td>
<td>Cohe.</td>
<td>Cons.</td>
<td>F1</td>
<td>BLEU-1/2</td>
<td>BScore</td>
<td>Enga.</td>
<td>Cohe.</td>
<td>Cons.</td>
</tr>
<tr>
<td>Context-only LLM</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Llama2-7B</td>
<td>16.43</td>
<td>20.96/12.09</td>
<td>84.04</td>
<td>1.32</td>
<td>1.20</td>
<td>1.13</td>
<td>13.71</td>
<td>20.89/12.28</td>
<td>84.49</td>
<td>0.75</td>
<td>0.75</td>
<td>1.00</td>
</tr>
<tr>
<td>ChatGLM2-6B</td>
<td>15.38</td>
<td>21.69/12.51</td>
<td>84.48</td>
<td>1.10</td>
<td>1.15</td>
<td>1.07</td>
<td>13.09</td>
<td>20.59/12.03</td>
<td>84.91</td>
<td>0.66</td>
<td>0.63</td>
<td>0.86</td>
</tr>
<tr>
<td>ChatGPT</td>
<td>19.41</td>
<td>21.23/12.24</td>
<td>86.13</td>
<td>1.83</td>
<td>1.37</td>
<td>1.32</td>
<td>13.69</td>
<td>21.15/12.20</td>
<td>85.53</td>
<td>1.50</td>
<td>1.52</td>
<td>1.43</td>
</tr>
<tr>
<td>Retrieval-based Approach</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ChatGPT-BM25 (k=3)</td>
<td>19.56</td>
<td>21.60/12.46</td>
<td>85.82</td>
<td>1.72</td>
<td>1.48</td>
<td>1.32</td>
<td>12.64</td>
<td>21.57/12.44</td>
<td>85.24</td>
<td>1.40</td>
<td>1.31</td>
<td>1.31</td>
</tr>
<tr>
<td>ChatGPT-DPR (k=3)</td>
<td>20.23</td>
<td>21.75/12.55</td>
<td>86.04</td>
<td>1.76</td>
<td>1.51</td>
<td>1.34</td>
<td>12.21</td>
<td>21.39/12.35</td>
<td>85.25</td>
<td>1.55</td>
<td>1.35</td>
<td>1.45</td>
</tr>
<tr>
<td>Memory-based Approach</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ChatGPT-MemoChat</td>
<td>18.93</td>
<td>21.82/12.59</td>
<td>85.99</td>
<td>1.70</td>
<td>1.55</td>
<td>1.35</td>
<td>11.19</td>
<td>21.07/12.18</td>
<td>85.22</td>
<td>1.45</td>
<td>1.20</td>
<td>1.30</td>
</tr>
<tr>
<td>ChatGPT-MemoryBank</td>
<td>20.28</td>
<td>21.82/12.58</td>
<td>86.12</td>
<td>1.78</td>
<td>1.57</td>
<td>1.40</td>
<td>13.15</td>
<td>21.29/12.39</td>
<td>85.34</td>
<td>1.57</td>
<td>1.52</td>
<td>1.68</td>
</tr>
<tr>
<td>ChatGPT-Rsum (Ours)</td>
<td>20.48</td>
<td>21.83/12.59</td>
<td>86.89</td>
<td>1.85</td>
<td>1.60</td>
<td>1.45</td>
<td>14.02</td>
<td>21.64/12.48</td>
<td>86.05</td>
<td>1.62</td>
<td>1.60</td>
<td>1.70</td>
</tr>
</tbody>
</table>
<p>LLM evaluations. We use the GPT-4 model (version "gpt-4-0314") as the evaluator, setting the temperature to 0 when making judgments. The prompts for evaluating the single model and pairwise models are referred to (Lu et al., 2023a) and (Dubois et al., 2024), respectively. All prompts used in the experiments can be seen in Appendix B.</p>
<h1>6. Experimental Results</h1>
<h3>6.1. Main Results</h3>
<p>Automatic Metrics Results. In Table 3, we compare different methods over session 5 in the MSC and Carecall datasets using popular LLMs. Firstly, among the vanilla models ("Llama2-7B", "ChatGLM2-6B", and "ChatGPT"), ChatGPT consistently performs well across two datasets, with competitive scores in BScore, F1 and BLEU-1/2. These results illustrate that ChatGPT is robust enough to handle a</p>
<p>long-term dialog, thus, we leave ChatGPT as the backbone model for our method. Secondly, as expected, the proposed method ("ChatGPT-Rsum") achieves the best performance on both datasets, showing the benefits of using automatically recursive memory. Specifically, our method achieves about $+0.2 \%$ on the F1 score, which is acceptable compared to that in previous works (Xu et al., 2022a). The MSC datasets are harder than other open-domain datasets due to the 3x context, so the slight improvements are normal. Thirdly, retrieval-based methods may not be always helpful in enhancing the quality of generation. From the results, the performances of ChatGPT-BM25 and ChatGPT-DPR are much worse than vanilla ChatGPT in the Carecall dataset, which is completely contrary to that in MSC. The reason is that the chatbot needs to actively guide the dialog topics in the Carecall, thus it is hard to retrieve appropriate and relevant context from the user's query. Therefore, the performance of generated responses will be damaged due to unrelated information.</p>
<p>Human Evaluation Results. We also present the results of human evaluations on different methods in Table 3. From the results, we find that: 1) Most memoryaugmented methods gain higher scores on consistency and coherence than vanilla ChatGPT, proving that maintaining a memory is more effective than using the whole history directly when engaging in a long-term conversation for LLMs; 2) Our method can generate more engaging response than other memory-based baselines (ChatGPT-MemoryBank and ChatGPT-MemoChat). The reason is that continually updating memory actively establishes global dependencies inside past histories, which helps LLMs to better understand the dialog and generate highquality responses.</p>
<p>Table 4: Comparison of evaluation metrics results by GPT-4 across different methods on session 5 in MSC dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Engagingness</th>
<th style="text-align: left;">Coherence</th>
<th style="text-align: left;">Consistency</th>
<th style="text-align: left;">Average</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ChatGPT</td>
<td style="text-align: left;">75.48</td>
<td style="text-align: left;">75.00</td>
<td style="text-align: left;">75.48</td>
<td style="text-align: left;">$\underline{75.32}$</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT-MemoryBank</td>
<td style="text-align: left;">74.68</td>
<td style="text-align: left;">80.92</td>
<td style="text-align: left;">84.56</td>
<td style="text-align: left;">$\underline{80.05}$</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT-MemoChat</td>
<td style="text-align: left;">72.32</td>
<td style="text-align: left;">77.36</td>
<td style="text-align: left;">78.96</td>
<td style="text-align: left;">$\underline{76.21}$</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT-Rsum (Ours)</td>
<td style="text-align: left;">$\mathbf{7 8 . 9 2}$</td>
<td style="text-align: left;">$\mathbf{8 3 . 5 6}$</td>
<td style="text-align: left;">$\mathbf{8 4 . 7 6}$</td>
<td style="text-align: left;">$\underline{\mathbf{8 2 . 4 1}}$</td>
</tr>
</tbody>
</table>
<h1>6.2. LLM Evaluation</h1>
<p>Single Model Evaluation. Table 4 reports the GPT-4's evaluation metrics results on session 5 among various methods in the MSC dataset. Also, the results prove the high agreements between humans (in Table 3) and GPT-4 judgment on the overall quality of generated responses, i.e., ChatGPT-Rsum $&gt;$ ChatGPT-MemoryBank $&gt;$ ChatGPT-MemoChat $&gt;$ ChatGPT. Given this, we mainly present the LLM evaluations in the following experiments to reduce labor costs. Lastly, it is worth noting that compared to human evaluation results, the GPT-4 tends to give higher scores on both sentence coherence and consistency. We suppose that the values of humans and LLMs might not be fully aligned at a fine-grained level, which could be a new direction for developing LLM evaluation.</p>
<p>Pairwise Models Evaluation. Furthermore, we randomly sample 1000 generated responses from pairwise models, i.e., ours vs. baselines, and then ask the GPT-4 to decide which response is better based on engagingness, consistency, and coherency. The results are shown in Figure 4. Compared to the most competitive baseline (MemoryBank), our proposed method obtains a $36.3 \%$ improvement (winning $48.2 \%$ and only losing $11.9 \%$ ), which illustrates the advancement of the proposed iteration mechanism.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ https://github.com/THUDM/ChatGLM2-6B
${ }^{6}$ For convenience's sake, the following "ChatGPT" refer to the gpt-3.5-turbo-0301 version.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>