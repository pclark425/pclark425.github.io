<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-920 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-920</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-920</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-22.html">extraction-schema-22</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <p><strong>Paper ID:</strong> paper-ed9943d73eb42116fe33564b5065c78b5ca0b16e</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ed9943d73eb42116fe33564b5065c78b5ca0b16e" target="_blank">RestGPT: Connecting Large Language Models with Real-World Applications via RESTful APIs</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper introduces RestGPT, which leverages LLMs to solve user requests by connecting with RESTful APIs and proposes a coarse-to-fine online planning mechanism to enhance the ability of planning and API selection.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e920.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e920.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RestGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RestGPT: Connecting Large Language Models with Real-World RESTful APIs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based framework that connects large language models to real-world RESTful APIs using a modular, coarse-to-fine online planning loop (Planner, API Selector, Executor) and a schema-driven response parser to robustly decompose tasks and call many APIs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>RestGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Modular agent built around an LLM: (1) Planner that emits high-level natural-language subtasks; (2) API Selector that maps subtasks to concrete API calls using OAS endpoint descriptions; (3) Executor containing a Caller and a schema-based Response Parser that generates Python parsing code from OAS schemas. Iterative online 'plan-and-execute' loop with special continue/end states.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB movie DB, Spotify music player)</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>tool use / planning / multi-step reasoning / sequential decision-making (RESTful API control)</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>text-davinci-003: Success 75.0% (TMDB), 72.7% (Spotify); Correct Path 79.0% (TMDB), 74.5% (Spotify); Delta Solution Len. +0.55 (TMDB), +0.25 (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Coarse-to-fine online planning (separate Planner + API Selector), Executor with Caller + schema-based Response Parser, use of OpenAPI Specification (OAS), modular prompts and in-context examples.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompting / in-context examples (no additional fine-tuning reported for main experiments); uses off-the-shelf LLMs (text-davinci-003 primarily).</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>architectural change and prompting strategy</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Introduces a coarse-to-fine online planning architecture: separate Planner producing NL subtasks and API Selector producing concrete API plans, iterative plan-execute loop with feedback (continue/end states). Executor uses OAS response schemas to generate Python parsing code rather than direct JSON prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Substantial improvement on interactive/API tasks versus baselines: RestGPT (text-davinci-003) success 75% (TMDB) vs ReAct 44% and Offline 29%; ablation w/o Planner falls to 44% (TMDB), showing Planner yields +31 percentage points over w/o-planner; w/o Parser also degrades (46% TMDB).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Authors argue current LLMs, despite strong QA/reasoning abilities, lack the ability to simultaneously plan, understand API documentation, and select APIs within limited context windows; offline/static planning cannot adapt to API feedback, and conversational fine-tuning (e.g. ChatGPT) can cause verbosity that harms planning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e920.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RestGPT (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RestGPT implemented with ChatGPT (gpt-3.5-turbo-0301)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The RestGPT architecture executed using OpenAI's ChatGPT variant as the underlying LLM to measure sensitivity to base model choice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>RestGPT (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same RestGPT architecture (Planner, API Selector, Executor) but uses gpt-3.5-turbo-0301 as the LLM backbone.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify)</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>tool use / planning / multi-step reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Success 68.0% (TMDB), 69.1% (Spotify); Correct Path 65.0% (TMDB), 72.3% (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Same modular RestGPT architecture; observed differences attributed to ChatGPT's conversational fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompting / in-context examples (no further fine-tuning in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>ablation / base-model substitution</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Swap the underlying LLM to ChatGPT to test sensitivity; observed more planning-stage errors and verbosity relative to text-davinci-003.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Performance slightly worse than text-davinci-003 (e.g., TMDB success 68% vs 75%).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>ChatGPT's conversational training causes longer, more verbose outputs and a tendency to continue planning after task completion, hurting interactive planning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e920.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RestGPT (Llama2-13B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RestGPT implemented with Llama2-13B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RestGPT architecture tested with Llama2-13B chat models, which failed to generate valid plans in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>RestGPT (Llama2-13B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RestGPT pipeline using the official Llama-2-13b-chat-hf checkpoints as LLM; authors attempted multiple official checkpoints.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify)</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>tool use / planning</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>0.0% Success and CP on both TMDB and Spotify in reported experiments (could not comprehend prompts/generate valid plans).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Same RestGPT architecture; observed model failure to follow complex planning prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>off-the-shelf checkpoint (no fine-tuning reported)</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>base-model substitution</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Using un-fine-tuned Llama2-13B checkpoints within RestGPT; authors also tried all official checkpoints but they failed to comprehend the prompts sufficiently to produce valid API plans.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Severe drop to 0% success, highlighting sensitivity of interactive pipelines to LLM prompt-following ability and pretraining/fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Lack of supervised instruction/fine-tuning on complex multi-step planning prompts prevents Llama2-13B from performing interactive API planning despite general language modeling capability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e920.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RestGPT (Vicuna-13B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RestGPT implemented with Vicuna-13B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RestGPT tested with Vicuna-13B (fine-tuned from Llama2 on ChatGPT-like conversations), showing partial capability on simple instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>RestGPT (Vicuna-13B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RestGPT pipeline using vicuna-13b-v1.5 (LLaMA2 fine-tuned on user-shared ChatGPT conversations).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify)</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>tool use / planning</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Success 9.0% (TMDB), 12.7% (Spotify); Correct Path 15.0% (TMDB), 20.6% (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Same RestGPT architecture; Vicuna demonstrates some prompt-following improvement over raw Llama2.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>pre-fine-tuned on ChatGPT-like data (outside this paper); used as off-the-shelf model in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>base-model substitution / indirect training effect</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Vicuna is Llama2 fine-tuned on ChatGPT-generated conversational data, which helps but is insufficient to match stronger commercial LLMs on complex API planning.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Partial success on simple tasks but far below text-davinci-003 and ChatGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Fine-tuning on conversational data improves prompt following but not necessarily the complex planning/document-understanding required for multi-step API tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e920.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReAct: Synergizing reasoning and acting in language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that interleaves chain-of-thought style reasoning with discrete actions (tool calls) to allow LLMs to plan and act iteratively.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>React: Synergizing reasoning and acting in language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>ReAct (framework)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Interleaved generation of natural-language reasoning traces (chain-of-thought) and actions; actions can be tool/API calls expressed in natural language and executed by an external handler.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify) as reproduced baseline</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>tool use / planning / multi-step reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Reproduced baseline: Success 44.0% (TMDB), 54.5% (Spotify); Correct Path 57.0% (TMDB), 49.1% (Spotify); Delta Solution Len. +0.76 (TMDB), +0.31 (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Interleaved chain-of-thought + actions (single LLM handles reasoning and API selection in one stream).</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompting / in-context learning (as a prompting framework rather than a trained model)</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>prompting strategy / single-stream reasoning+acting</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>ReAct relies on a single LLM to both reason (chain-of-thought) and produce actions; in this paper it was used with the provided Executor module to call RESTful APIs.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Underperformed compared to RestGPT's modular coarse-to-fine approach (44% vs 75% success on TMDB), indicating single-stream ReAct struggles to simultaneously handle planning, API understanding and selection in complex multi-step API tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Authors suggest current LLMs find it difficult to simultaneously manage planning and the detailed API-document understanding required for multi-step API execution within the same generation stream.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e920.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Offline introspective method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Offline introspective plan-then-execute method (used in HuggingGPT/Chameleon)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Generate a complete multi-step plan ahead of execution, then sequentially execute API calls without using intermediate API feedback to update the plan.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tool learning with foundation models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Offline introspective planning (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generates a static multi-step plan before execution and then executes it step-by-step; lacks online adaptation to API feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify) as reproduced baseline</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>planning / multi-step tool use</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Offline baseline: Success 29.0% (TMDB), 14.5% (Spotify); Correct Path 33.0% (TMDB), 36.4% (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Offline plan-then-execute (no online feedback loop).</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompting / planning with no online feedback</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>baseline (no intervention)</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Static multi-step planning without adapting to execution feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Poor interactive performance especially on complex/time-dependent tasks compared to RestGPT's online planning (29% vs 75% success on TMDB).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Lack of API feedback and inability to adapt plans during execution makes offline planning brittle in real-world API environments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e920.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DEPS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DEPS: Describe, Explain, Plan and Select</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interactive planning approach that iteratively updates plans based on environment feedback to improve long-term planning in open-world tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>DEPS</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Iterative planning framework where LLMs Describe and Explain to refine Plans and Select actions, designed for interactive planning with feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify) as reproduced baseline</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>interactive planning / multi-step reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>DEPS baseline: Success 38.0% (TMDB), 19.3% (Spotify); Correct Path 43.0% (TMDB), 43.8% (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Iterative plan refinement with environment feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompting / in-context iterative procedure</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>interactive planning strategy</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>DEPS iteratively updates plans using LLM-produced descriptions/explanations and selects next actions based on feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Better than strict offline but still significantly below RestGPT; authors attribute the gap to inferior planning/document-understanding compared to their coarse-to-fine approach.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Insufficient handling of API documentation complexity and limited ability to generate concrete API plans from high-level intents.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e920.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent framework that reflects on trial-and-error feedback by writing reflective text into episodic memory to improve subsequent planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Agent that uses reflective textual feedback stored in memory after failed trials to influence subsequent planning; limited trials allowed.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify) as reproduced baseline</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>trial-and-error planning / multi-step reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Reflexion baseline: Success 52.0% (TMDB), 59.6% (Spotify); Correct Path 59.0% (TMDB), 61.4% (Spotify).</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Verbal reflection and episodic memory for learning from failed trials.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>trial-and-error with LLM prompts and memory (verbal reinforcement-style), no explicit RLHF reported.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>architectural / memory-based intervention</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Use of reflected text in memory to guide future planning; limited number of trials.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Improved over some baselines (e.g., offline) but still below RestGPT on TMDB and Spotify in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Reflection helps but does not fully address the need for modular planning and explicit API-document comprehension.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e920.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Schema-based Response Parser</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Schema-based Response Parser (Executor component in RestGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Executor sub-module that uses OpenAPI response schemas to generate Python parsing code to extract required information from complex/large JSON API responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Schema-based Response Parser</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generates Python parsing code conditioned on OAS response schema and output instructions, executes the code to extract structured outputs; falls back to direct LLM parsing on execution errors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (used within RestGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>response parsing / tool-use support</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Ablation: removing parser drops RestGPT success from 75.0% to 46.0% (TMDB) and from 72.7% to 47.3% (Spotify) in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Uses OAS response schemas, code-generation + execution pipeline for robust JSON extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>not a training method  architectural/engineering intervention (prompt-based code generation).</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>architectural change (executor design)</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Replace direct LLM JSON parsing with schema-aware code generation to exploit structured response descriptions in OAS for robust extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Large positive effect: with parser success 75% (TMDB) vs 46% without; shows schema-based parsing substantially improves interactive API task success and robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Direct LLM parsing struggles with long/complex JSON and loses required fields; schema-guided code generation reduces errors by constraining extraction to documented schema.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e920.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e920.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM or agent performance on question-answering tasks versus interactive/procedural tasks (such as tool use, planning, multi-step reasoning, sequential decision-making), including any architectural or training interventions that affect this performance gap.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Coarse-to-Fine Planner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Coarse-to-Fine Online Planner (RestGPT Planner + API Selector)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-layer planning strategy splitting high-level NL subtask planning (Planner) and fine-grained API selection (API Selector) in an iterative online loop with execution feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Coarse-to-Fine Online Planner</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Planner produces NL sub-tasks using commonsense and previous results; API Selector reads OAS endpoint descriptions and maps subtasks into concrete API call sequences; iterative online loop allows 'continue' or 'end' signals based on execution results.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qa_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_name</strong></td>
                            <td>RestBench (TMDB, Spotify) within RestGPT</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_task_type</strong></td>
                            <td>planning / multi-step reasoning / sequential decision-making</td>
                        </tr>
                        <tr>
                            <td><strong>interactive_performance</strong></td>
                            <td>Ablation: removing Planner reduces success to 44.0% (TMDB) and 54.5% (Spotify)  roughly the level of ReAct; with Planner RestGPT reaches 75.0% and 72.7%.</td>
                        </tr>
                        <tr>
                            <td><strong>reports_both_qa_and_interactive</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_gap_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>Modular separation of high-level NL planning from API-level selection; online feedback loop with continue/end states.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompting / modular in-context examples (no extra training)</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>architectural change</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_description</strong></td>
                            <td>Explicit separation of planning and API selection reduces cognitive load on a single LLM generation stream and enables online adaptation to API feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_effect</strong></td>
                            <td>Large positive effect: yields +31 percentage points (TMDB) over w/o-planner baseline. Improves planning efficiency (smaller Delta Solution Len.).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesized_cause_of_gap</strong></td>
                            <td>Single-stream LLM approaches (e.g., ReAct) must multitask (plan + API-doc comprehension + selection) and thus fail on complex multi-step API tasks; splitting roles reduces this burden and leverages LLM strengths for different subproblems.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>React: Synergizing reasoning and acting in language models. <em>(Rating: 2)</em></li>
                <li>Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. <em>(Rating: 2)</em></li>
                <li>Reflexion: Language agents with verbal reinforcement learning. <em>(Rating: 2)</em></li>
                <li>Toolformer: Language models can teach themselves to use tools. <em>(Rating: 1)</em></li>
                <li>HuggingGPT: Solving AI tasks with ChatGPT and its friends in HuggingFace. <em>(Rating: 2)</em></li>
                <li>Gorilla: Large language model connected with massive APIs. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-920",
    "paper_id": "paper-ed9943d73eb42116fe33564b5065c78b5ca0b16e",
    "extraction_schema_id": "extraction-schema-22",
    "extracted_data": [
        {
            "name_short": "RestGPT",
            "name_full": "RestGPT: Connecting Large Language Models with Real-World RESTful APIs",
            "brief_description": "An LLM-based framework that connects large language models to real-world RESTful APIs using a modular, coarse-to-fine online planning loop (Planner, API Selector, Executor) and a schema-driven response parser to robustly decompose tasks and call many APIs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_or_agent_name": "RestGPT",
            "model_description": "Modular agent built around an LLM: (1) Planner that emits high-level natural-language subtasks; (2) API Selector that maps subtasks to concrete API calls using OAS endpoint descriptions; (3) Executor containing a Caller and a schema-based Response Parser that generates Python parsing code from OAS schemas. Iterative online 'plan-and-execute' loop with special continue/end states.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB movie DB, Spotify music player)",
            "interactive_task_type": "tool use / planning / multi-step reasoning / sequential decision-making (RESTful API control)",
            "interactive_performance": "text-davinci-003: Success 75.0% (TMDB), 72.7% (Spotify); Correct Path 79.0% (TMDB), 74.5% (Spotify); Delta Solution Len. +0.55 (TMDB), +0.25 (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Coarse-to-fine online planning (separate Planner + API Selector), Executor with Caller + schema-based Response Parser, use of OpenAPI Specification (OAS), modular prompts and in-context examples.",
            "training_method": "prompting / in-context examples (no additional fine-tuning reported for main experiments); uses off-the-shelf LLMs (text-davinci-003 primarily).",
            "intervention_type": "architectural change and prompting strategy",
            "intervention_description": "Introduces a coarse-to-fine online planning architecture: separate Planner producing NL subtasks and API Selector producing concrete API plans, iterative plan-execute loop with feedback (continue/end states). Executor uses OAS response schemas to generate Python parsing code rather than direct JSON prompting.",
            "intervention_effect": "Substantial improvement on interactive/API tasks versus baselines: RestGPT (text-davinci-003) success 75% (TMDB) vs ReAct 44% and Offline 29%; ablation w/o Planner falls to 44% (TMDB), showing Planner yields +31 percentage points over w/o-planner; w/o Parser also degrades (46% TMDB).",
            "hypothesized_cause_of_gap": "Authors argue current LLMs, despite strong QA/reasoning abilities, lack the ability to simultaneously plan, understand API documentation, and select APIs within limited context windows; offline/static planning cannot adapt to API feedback, and conversational fine-tuning (e.g. ChatGPT) can cause verbosity that harms planning.",
            "uuid": "e920.0"
        },
        {
            "name_short": "RestGPT (ChatGPT)",
            "name_full": "RestGPT implemented with ChatGPT (gpt-3.5-turbo-0301)",
            "brief_description": "The RestGPT architecture executed using OpenAI's ChatGPT variant as the underlying LLM to measure sensitivity to base model choice.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_or_agent_name": "RestGPT (ChatGPT)",
            "model_description": "Same RestGPT architecture (Planner, API Selector, Executor) but uses gpt-3.5-turbo-0301 as the LLM backbone.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify)",
            "interactive_task_type": "tool use / planning / multi-step reasoning",
            "interactive_performance": "Success 68.0% (TMDB), 69.1% (Spotify); Correct Path 65.0% (TMDB), 72.3% (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Same modular RestGPT architecture; observed differences attributed to ChatGPT's conversational fine-tuning.",
            "training_method": "prompting / in-context examples (no further fine-tuning in this paper).",
            "intervention_type": "ablation / base-model substitution",
            "intervention_description": "Swap the underlying LLM to ChatGPT to test sensitivity; observed more planning-stage errors and verbosity relative to text-davinci-003.",
            "intervention_effect": "Performance slightly worse than text-davinci-003 (e.g., TMDB success 68% vs 75%).",
            "hypothesized_cause_of_gap": "ChatGPT's conversational training causes longer, more verbose outputs and a tendency to continue planning after task completion, hurting interactive planning.",
            "uuid": "e920.1"
        },
        {
            "name_short": "RestGPT (Llama2-13B)",
            "name_full": "RestGPT implemented with Llama2-13B",
            "brief_description": "RestGPT architecture tested with Llama2-13B chat models, which failed to generate valid plans in these experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_or_agent_name": "RestGPT (Llama2-13B)",
            "model_description": "RestGPT pipeline using the official Llama-2-13b-chat-hf checkpoints as LLM; authors attempted multiple official checkpoints.",
            "model_size": "13B",
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify)",
            "interactive_task_type": "tool use / planning",
            "interactive_performance": "0.0% Success and CP on both TMDB and Spotify in reported experiments (could not comprehend prompts/generate valid plans).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Same RestGPT architecture; observed model failure to follow complex planning prompts.",
            "training_method": "off-the-shelf checkpoint (no fine-tuning reported)",
            "intervention_type": "base-model substitution",
            "intervention_description": "Using un-fine-tuned Llama2-13B checkpoints within RestGPT; authors also tried all official checkpoints but they failed to comprehend the prompts sufficiently to produce valid API plans.",
            "intervention_effect": "Severe drop to 0% success, highlighting sensitivity of interactive pipelines to LLM prompt-following ability and pretraining/fine-tuning.",
            "hypothesized_cause_of_gap": "Lack of supervised instruction/fine-tuning on complex multi-step planning prompts prevents Llama2-13B from performing interactive API planning despite general language modeling capability.",
            "uuid": "e920.2"
        },
        {
            "name_short": "RestGPT (Vicuna-13B)",
            "name_full": "RestGPT implemented with Vicuna-13B",
            "brief_description": "RestGPT tested with Vicuna-13B (fine-tuned from Llama2 on ChatGPT-like conversations), showing partial capability on simple instructions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_or_agent_name": "RestGPT (Vicuna-13B)",
            "model_description": "RestGPT pipeline using vicuna-13b-v1.5 (LLaMA2 fine-tuned on user-shared ChatGPT conversations).",
            "model_size": "13B",
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify)",
            "interactive_task_type": "tool use / planning",
            "interactive_performance": "Success 9.0% (TMDB), 12.7% (Spotify); Correct Path 15.0% (TMDB), 20.6% (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Same RestGPT architecture; Vicuna demonstrates some prompt-following improvement over raw Llama2.",
            "training_method": "pre-fine-tuned on ChatGPT-like data (outside this paper); used as off-the-shelf model in experiments.",
            "intervention_type": "base-model substitution / indirect training effect",
            "intervention_description": "Vicuna is Llama2 fine-tuned on ChatGPT-generated conversational data, which helps but is insufficient to match stronger commercial LLMs on complex API planning.",
            "intervention_effect": "Partial success on simple tasks but far below text-davinci-003 and ChatGPT.",
            "hypothesized_cause_of_gap": "Fine-tuning on conversational data improves prompt following but not necessarily the complex planning/document-understanding required for multi-step API tasks.",
            "uuid": "e920.3"
        },
        {
            "name_short": "ReAct",
            "name_full": "ReAct: Synergizing reasoning and acting in language models",
            "brief_description": "A framework that interleaves chain-of-thought style reasoning with discrete actions (tool calls) to allow LLMs to plan and act iteratively.",
            "citation_title": "React: Synergizing reasoning and acting in language models.",
            "mention_or_use": "mention",
            "model_or_agent_name": "ReAct (framework)",
            "model_description": "Interleaved generation of natural-language reasoning traces (chain-of-thought) and actions; actions can be tool/API calls expressed in natural language and executed by an external handler.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify) as reproduced baseline",
            "interactive_task_type": "tool use / planning / multi-step reasoning",
            "interactive_performance": "Reproduced baseline: Success 44.0% (TMDB), 54.5% (Spotify); Correct Path 57.0% (TMDB), 49.1% (Spotify); Delta Solution Len. +0.76 (TMDB), +0.31 (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Interleaved chain-of-thought + actions (single LLM handles reasoning and API selection in one stream).",
            "training_method": "prompting / in-context learning (as a prompting framework rather than a trained model)",
            "intervention_type": "prompting strategy / single-stream reasoning+acting",
            "intervention_description": "ReAct relies on a single LLM to both reason (chain-of-thought) and produce actions; in this paper it was used with the provided Executor module to call RESTful APIs.",
            "intervention_effect": "Underperformed compared to RestGPT's modular coarse-to-fine approach (44% vs 75% success on TMDB), indicating single-stream ReAct struggles to simultaneously handle planning, API understanding and selection in complex multi-step API tasks.",
            "hypothesized_cause_of_gap": "Authors suggest current LLMs find it difficult to simultaneously manage planning and the detailed API-document understanding required for multi-step API execution within the same generation stream.",
            "uuid": "e920.4"
        },
        {
            "name_short": "Offline introspective method",
            "name_full": "Offline introspective plan-then-execute method (used in HuggingGPT/Chameleon)",
            "brief_description": "Generate a complete multi-step plan ahead of execution, then sequentially execute API calls without using intermediate API feedback to update the plan.",
            "citation_title": "Tool learning with foundation models",
            "mention_or_use": "mention",
            "model_or_agent_name": "Offline introspective planning (baseline)",
            "model_description": "Generates a static multi-step plan before execution and then executes it step-by-step; lacks online adaptation to API feedback.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify) as reproduced baseline",
            "interactive_task_type": "planning / multi-step tool use",
            "interactive_performance": "Offline baseline: Success 29.0% (TMDB), 14.5% (Spotify); Correct Path 33.0% (TMDB), 36.4% (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Offline plan-then-execute (no online feedback loop).",
            "training_method": "prompting / planning with no online feedback",
            "intervention_type": "baseline (no intervention)",
            "intervention_description": "Static multi-step planning without adapting to execution feedback.",
            "intervention_effect": "Poor interactive performance especially on complex/time-dependent tasks compared to RestGPT's online planning (29% vs 75% success on TMDB).",
            "hypothesized_cause_of_gap": "Lack of API feedback and inability to adapt plans during execution makes offline planning brittle in real-world API environments.",
            "uuid": "e920.5"
        },
        {
            "name_short": "DEPS",
            "name_full": "DEPS: Describe, Explain, Plan and Select",
            "brief_description": "An interactive planning approach that iteratively updates plans based on environment feedback to improve long-term planning in open-world tasks.",
            "citation_title": "Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.",
            "mention_or_use": "mention",
            "model_or_agent_name": "DEPS",
            "model_description": "Iterative planning framework where LLMs Describe and Explain to refine Plans and Select actions, designed for interactive planning with feedback.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify) as reproduced baseline",
            "interactive_task_type": "interactive planning / multi-step reasoning",
            "interactive_performance": "DEPS baseline: Success 38.0% (TMDB), 19.3% (Spotify); Correct Path 43.0% (TMDB), 43.8% (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Iterative plan refinement with environment feedback.",
            "training_method": "prompting / in-context iterative procedure",
            "intervention_type": "interactive planning strategy",
            "intervention_description": "DEPS iteratively updates plans using LLM-produced descriptions/explanations and selects next actions based on feedback.",
            "intervention_effect": "Better than strict offline but still significantly below RestGPT; authors attribute the gap to inferior planning/document-understanding compared to their coarse-to-fine approach.",
            "hypothesized_cause_of_gap": "Insufficient handling of API documentation complexity and limited ability to generate concrete API plans from high-level intents.",
            "uuid": "e920.6"
        },
        {
            "name_short": "Reflexion",
            "name_full": "Reflexion: Language agents with verbal reinforcement learning",
            "brief_description": "An agent framework that reflects on trial-and-error feedback by writing reflective text into episodic memory to improve subsequent planning.",
            "citation_title": "Reflexion: Language agents with verbal reinforcement learning.",
            "mention_or_use": "mention",
            "model_or_agent_name": "Reflexion",
            "model_description": "Agent that uses reflective textual feedback stored in memory after failed trials to influence subsequent planning; limited trials allowed.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify) as reproduced baseline",
            "interactive_task_type": "trial-and-error planning / multi-step reasoning",
            "interactive_performance": "Reflexion baseline: Success 52.0% (TMDB), 59.6% (Spotify); Correct Path 59.0% (TMDB), 61.4% (Spotify).",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Verbal reflection and episodic memory for learning from failed trials.",
            "training_method": "trial-and-error with LLM prompts and memory (verbal reinforcement-style), no explicit RLHF reported.",
            "intervention_type": "architectural / memory-based intervention",
            "intervention_description": "Use of reflected text in memory to guide future planning; limited number of trials.",
            "intervention_effect": "Improved over some baselines (e.g., offline) but still below RestGPT on TMDB and Spotify in these experiments.",
            "hypothesized_cause_of_gap": "Reflection helps but does not fully address the need for modular planning and explicit API-document comprehension.",
            "uuid": "e920.7"
        },
        {
            "name_short": "Schema-based Response Parser",
            "name_full": "Schema-based Response Parser (Executor component in RestGPT)",
            "brief_description": "Executor sub-module that uses OpenAPI response schemas to generate Python parsing code to extract required information from complex/large JSON API responses.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_or_agent_name": "Schema-based Response Parser",
            "model_description": "Generates Python parsing code conditioned on OAS response schema and output instructions, executes the code to extract structured outputs; falls back to direct LLM parsing on execution errors.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (used within RestGPT)",
            "interactive_task_type": "response parsing / tool-use support",
            "interactive_performance": "Ablation: removing parser drops RestGPT success from 75.0% to 46.0% (TMDB) and from 72.7% to 47.3% (Spotify) in reported experiments.",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Uses OAS response schemas, code-generation + execution pipeline for robust JSON extraction.",
            "training_method": "not a training method  architectural/engineering intervention (prompt-based code generation).",
            "intervention_type": "architectural change (executor design)",
            "intervention_description": "Replace direct LLM JSON parsing with schema-aware code generation to exploit structured response descriptions in OAS for robust extraction.",
            "intervention_effect": "Large positive effect: with parser success 75% (TMDB) vs 46% without; shows schema-based parsing substantially improves interactive API task success and robustness.",
            "hypothesized_cause_of_gap": "Direct LLM parsing struggles with long/complex JSON and loses required fields; schema-guided code generation reduces errors by constraining extraction to documented schema.",
            "uuid": "e920.8"
        },
        {
            "name_short": "Coarse-to-Fine Planner",
            "name_full": "Coarse-to-Fine Online Planner (RestGPT Planner + API Selector)",
            "brief_description": "A two-layer planning strategy splitting high-level NL subtask planning (Planner) and fine-grained API selection (API Selector) in an iterative online loop with execution feedback.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_or_agent_name": "Coarse-to-Fine Online Planner",
            "model_description": "Planner produces NL sub-tasks using commonsense and previous results; API Selector reads OAS endpoint descriptions and maps subtasks into concrete API call sequences; iterative online loop allows 'continue' or 'end' signals based on execution results.",
            "model_size": null,
            "qa_task_name": null,
            "qa_performance": null,
            "interactive_task_name": "RestBench (TMDB, Spotify) within RestGPT",
            "interactive_task_type": "planning / multi-step reasoning / sequential decision-making",
            "interactive_performance": "Ablation: removing Planner reduces success to 44.0% (TMDB) and 54.5% (Spotify)  roughly the level of ReAct; with Planner RestGPT reaches 75.0% and 72.7%.",
            "reports_both_qa_and_interactive": false,
            "performance_gap_observed": true,
            "architectural_features": "Modular separation of high-level NL planning from API-level selection; online feedback loop with continue/end states.",
            "training_method": "prompting / modular in-context examples (no extra training)",
            "intervention_type": "architectural change",
            "intervention_description": "Explicit separation of planning and API selection reduces cognitive load on a single LLM generation stream and enables online adaptation to API feedback.",
            "intervention_effect": "Large positive effect: yields +31 percentage points (TMDB) over w/o-planner baseline. Improves planning efficiency (smaller Delta Solution Len.).",
            "hypothesized_cause_of_gap": "Single-stream LLM approaches (e.g., ReAct) must multitask (plan + API-doc comprehension + selection) and thus fail on complex multi-step API tasks; splitting roles reduces this burden and leverages LLM strengths for different subproblems.",
            "uuid": "e920.9"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "React: Synergizing reasoning and acting in language models.",
            "rating": 2
        },
        {
            "paper_title": "Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.",
            "rating": 2
        },
        {
            "paper_title": "Reflexion: Language agents with verbal reinforcement learning.",
            "rating": 2
        },
        {
            "paper_title": "Toolformer: Language models can teach themselves to use tools.",
            "rating": 1
        },
        {
            "paper_title": "HuggingGPT: Solving AI tasks with ChatGPT and its friends in HuggingFace.",
            "rating": 2
        },
        {
            "paper_title": "Gorilla: Large language model connected with massive APIs.",
            "rating": 1
        }
    ],
    "cost": 0.0180885,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>RestGPT: Connecting Large Language Models with Real-World RESTful APIs</h1>
<p>Yifan Song ${ }^{1}$, Weimin Xiong ${ }^{1}$, Dawei Zhu ${ }^{1}$, Wenhao Wu ${ }^{1}$, Han Qian ${ }^{2}$, Mingbo Song ${ }^{2}$ Hailiang Huang ${ }^{2}$, Cheng $\mathbf{L i}^{3}$, Ke Wang ${ }^{3}$, Rong Yao ${ }^{3}$, Ye Tian ${ }^{3}$, Sujian Li ${ }^{1 *}$<br>${ }^{1}$ School of Computer Science, Peking University<br>${ }^{2}$ School of Electronics Engineering and Computer Science, Peking University<br>${ }^{3}$ Huawei Technologies<br>{yfsong, lisujian}@pku.edu.cn<br>https://restgpt.github.io</p>
<h4>Abstract</h4>
<p>Tool-augmented large language models (LLMs) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting LLMs with RESTful APIs, which adhere to the widely adopted REST software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose RestGPT, which exploits the power of LLMs and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and API selection. RestGPT also contains an API executor tailored for calling RESTful APIs, which can meticulously formulate parameters and parse API responses. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality benchmark which consists of two real-world scenarios and human-annotated instructions with gold solution paths. Experiments show that RestGPT is able to achieve impressive results in complex tasks and has strong robustness, which paves a new way towards AGI.</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs), such as GPT-3 [1] and ChatGPT [2], have shown various emergent abilities, including in-context learning [1, 3], reasoning [4, 5], and step-by-step planning [6, 7]. In pursuit of advancing the capabilities of LLMs for practical applications, an ongoing research direction is investigating the incorporation of external tools/APIs to enhance the functionality of LLMs[8, 9, 10, 11]. This endeavor has yielded successful integration of diverse tools, including search engines and other foundational models, with LLMs[12, 13, 14].</p>
<p>Despite significant progresses, we find that existing API-augmented LLMs are still in the experimental stage and have yet to fully meet the demands of real-world user instructions. As shown in Table 1, current methods are limited to connect with a small number of specially designed tools/APIs [11, 12, 15]. For example, Chameleon [12] designs a set of 15 tools, such as table verbalizer and image captioner. Additionally, the absence of a standardized API design specification obstructs the scalability of previous endeavors. Thus, the potential for connecting LLMs with a diverse range of real-world APIs, like RESTful APIs, remains under-explored and challenging. Furthermore, when dealing with a complex instruction in real scenario, it is necessary to decompose it into smaller subtasks and accomplish them by employing a mix of various APIs. As a result, it becomes essential for</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th>Model</th>
<th>API/Tool Use</th>
<th></th>
<th></th>
<th>Framework</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Num.</td>
<td>Extensibility</td>
<td>Schema</td>
<td>Planning</td>
<td>Planning Form</td>
<td>Feedback</td>
<td>Plug-n-Play</td>
</tr>
<tr>
<td>ReAct</td>
<td>3</td>
<td>-</td>
<td>Specialized</td>
<td>Online</td>
<td>Natural Lang.</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Toolformer</td>
<td>5</td>
<td>-</td>
<td>Specialized</td>
<td>$\square$</td>
<td>-</td>
<td>$\square$</td>
<td>$\square$</td>
</tr>
<tr>
<td>Visual ChatGPT</td>
<td>22</td>
<td>-</td>
<td>Specialized</td>
<td>$\square$</td>
<td>-</td>
<td>Human</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>ViperGPT</td>
<td>11</td>
<td>-</td>
<td>Python func.</td>
<td>Offline</td>
<td>Program</td>
<td>$\square$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>HuggingGPT</td>
<td>$24^{\dagger}$</td>
<td>$+$</td>
<td>HuggingFace</td>
<td>Offline</td>
<td>Natural Lang.</td>
<td>$\square$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>API-Bank</td>
<td>53</td>
<td>-</td>
<td>Specialized</td>
<td>$\square$</td>
<td>-</td>
<td>Human</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Chameleon</td>
<td>15</td>
<td>-</td>
<td>Specialized</td>
<td>Offline</td>
<td>Natural Lang.</td>
<td>$\square$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Gorilla</td>
<td>$1645^{\dagger}$</td>
<td>$+$</td>
<td>JSON</td>
<td>$\square$</td>
<td>-</td>
<td>$\square$</td>
<td>$\square$</td>
</tr>
<tr>
<td>GPT4Tools</td>
<td>31</td>
<td>-</td>
<td>Specialized</td>
<td>$\square$</td>
<td>-</td>
<td>Human</td>
<td>$\square$</td>
</tr>
<tr>
<td>RestGPT (ours)</td>
<td>100+</td>
<td>$++$</td>
<td>RESTful</td>
<td>Online</td>
<td>Coarse-to-Fine</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
</tbody>
</table>
<p>Table 1: A comparison of work that augments LLMs with API/tool usage. ${ }^{\dagger}$ denotes API selection with retrieval.</p>
<p>API-augmented LLMs to have robust planning and decision-making capabilities to effectively tackle real-world tasks [9]. Nonetheless, existing techniques, either offline introspective plan-then-execute methods [9, 13, 12] or the ReAct framework [16], encounter challenges in effectively adapting API feedback and generating viable plans.</p>
<p>In this work, we delve into a more realistic scenario by connecting LLMs with real-world RESTful APIs, aiming at fulfilling practical user instructions. RESTful is the de facto standard for web service development [17], which utilizes HTTP methods (e.g., GET, POST) and URIs to manipulate resources. RESTful API development typically adheres to the OpenAPI Specification (OAS) [18], which describes the operations, parameters, and response schemas of each API endpoint. Therefore, our resulting framework can connect with any RESTful application and offer standardized API development processes, thereby enabling enhanced extensibility compared to previous approaches. However, connecting LLMs with RESTful APIs also brings practical challenges. First, calling real-world APIs may give rise to a multitude of unforeseen situations, necessitating the framework to exhibit strong robustness and conduct reasonable planning. Second, the parameters and responses of RESTful APIs often follow specific formats, leading to difficulty in API invoking and response parsing.</p>
<p>To tackle the limitations of previous methods and the practical challenges associated with RESTful APIs, we propose RestGPT, a LLM-based framework connecting with RESTful APIs to handle complex instructions. RestGPT comprises three main modules: a Planner, an API Selector, and an Executor. The core of each module is prompting an LLM. Unlike prior work that uses static or ReAct style planning which lacks flexibility in realistic scenarios, RestGPT adopts an iterative coarse-to-fine online planning mechanism. Given a complicated instruction, the planner generates a sub-task for current task in the format of natural language. Subsequently, the API selector maps the coarse high-level sub-task to finer API calling plan, forming a coarse-to-fine task planning. The executor, responsible for invoking RESTful APIs and get execution results, is further divided it into two sub-modules: a Caller and a response Parser. The caller organizes API call parameters based on the API plan and API documentation, while the parser utilizes the response schema defined in OAS to generate Python code to parse responses. Once receiving the execution results of the API plan, the planner performs online planning for the subsequent sub-task in the next step. Through the integration of the three modules, our method RestGPT shows superior extensibility and flexibility in mastering RESTful APIs.</p>
<p>To evaluate the performance of RestGPT in utilizing RESTful APIs, we introduce RestBench, a human-annotated benchmark consisting of two realistic scenarios, TMDB movie database and Spotify music player. For each scenario, we collect diverse real-world user instructions that require the utilization of multiple APIs to complete. Based on the RestBench, we conduct comprehensive experiments to investigate the performance of RestGPT across different dimensions. The experimental results demonstrate that RestGPT exhibits robust capabilities in handling complex user instructions and has significant advantages in task planning, API understanding, and response parsing.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Our contributions can be summarized as follows:</p>
<ol>
<li>For the first time, we attempt to connect large language models with RESTful APIs, enabling the resulting framework to be compatible with existing real-world applications while also providing powerful extensibility.</li>
<li>We propose RestGPT, a coarse-to-fine online planning framework that effectively handles the practical challenges associated with connecting LLMs with RESTful APIs, including API understanding, planning, and API response parsing.</li>
<li>To evaluate the performance of RestGPT, we build a human-annotated benchmark, RestBench, which comprises two practical scenarios. Experimental results show the capability of RestGPT to effectively utilize a number of RESTful APIs to accomplish complex instructions.</li>
</ol>
<h1>2 Background</h1>
<h3>2.1 Tool-Augmented Language Models</h3>
<p>The emergence of recent powerful LLMs has enabled artificial intelligence systems to match human skills in utilizing tools [8, 9]. To enhance the performance of LLMs in accessing up-to-date information and carrying out precise mathematical reasoning, early work leverages simple tools like web search engines and calculators, such as ReAct [16], Toolformer [11], and ART [19]. Another line of research has focused on equipping LLMs to coordinate with external models for complex AI tasks, exemplified by HuggingGPT [13], ViperGPT [20], Visual ChatGPT [14] and Chameleon [12]. Recently, some work study how to enable open-sourced LLMs, such as LLaMa, to perform API usage [21, 15, 22]. Additionally, API-Bank [23] provides a systematic benchmark to showcase the efficacy of LLMs using tools to respond to human instructions.</p>
<p>Despite the notable advancements in incorporating tools for large language models, previous methods have exhibited certain limitations, most notably their restricted support for a limited number of specially designed APIs [12] and their inferior planning methods [9, 24, 12]. We compare RestGPT with other tool-augmented language models in Table 1. As shown, our work stands out by supporting for over 100 RESTful APIs. Furthermore, compared with most previous approaches adopt static offline planning which cannot interact with APIs and utilize feedback to adjust the plan, we employ a coarse-to-fine online planning framework with feedback, facilitating more flexible planning for complex instructions. Our work shares the similar spirit of AutoGPT, an autonomous agent capable of accomplishing complex tasks with numerous tools. While AutoGPT relies on developers to ensure compatibility with various applications, RestGPT can be integrated with any RESTful API-based applications in a plug-and-play fashion.</p>
<h3>2.2 RESTful APIs</h3>
<p>RESTful APIs have become a popular way to expose functionalities and data of web services to client applications [25, 17]. RESTful APIs also provide a standard for integrating external systems together with using a simple yet powerful interface. There are millions of RESTful APIs available on Internet, such as Spotify, Twitter, Gmail, etc. RESTful APIs are based on the REST architectural style, which emphasizes a client-server communication via stateless HTTP requests, including GET, POST, etc, where resources are identified by self-descriptive URIs [25]. The response of RESTful APIs are always structured in JSON format and contain various information. Thus, LLMs connected with RESTful APIs must possess a strong ability to extract the required information from the response.</p>
<p>OpenAPI Specification (OAS, or Swagger) [18], has been widely adopted as a standard for defining RESTful APIs. OAS is a structured documentation file which describes the endpoints, operations, parameters, response schemas, and other details of an API endpoint, providing a clear interface for our method to use the APIs.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overview of RestGPT. The planner, API selector, executor collaborate to form the coarse-to-fine online planning framework. The caller and response parser in the executor provides robust execution of the RESTful API calling plan.</p>
<h1>3 RestGPT</h1>
<h3>3.1 RestGPT Architecture</h3>
<p>As demonstrated in Figure 1, RestGPT is composed of three main modules: a Planner $\mathcal{P}$, an API Selector $\mathcal{S}$ and an Executor $\mathcal{E}$. The planner decomposes each user instruction into several sub-tasks, while the API selector selects APIs to address each sub-task. The executor, consisting of a Caller and a response Parser, performs RESTful API calls and extracts useful information from the JSON response to form the execution result. The core of each component is an LLM with the corresponding prompt and in-context examples describing the function of the component.</p>
<p>One of the challenges in connecting LLMs with a vast number of APIs is to ensure that the framework is able to fully understand the API documents with a limited context window size of LLMs. As depicted in Figure 1, we designate different modules to read distinct parts of the OpenAPI Specification (OAS). This strategy allows us to leverage OAS information to its fullest potentials when working with RESTful APIs. Specifically, the API selector reads the endpoint descriptions of all APIs to select a proper API for solving the current sub-task. Then, the caller uses the detailed documents of the API within the API plan to generate the correct API calling parameters and request body. Lastly, the parser is developed to make use of the response schema within OAS to generate the parsing code for information extraction.</p>
<h3>3.2 Coarse-to-fine Online Planning</h3>
<p>To fully exploit the planning and decision making capabilities of LLMs and enable our method to dynamically adjust the plan to changing circumstances when accomplishing real-world user instructions, we propose a coarse-to-fine online planning mechanism in RestGPT.</p>
<p>The workflow of RestGPT can be characterized as an iterative "plan and execution" loop. During the planning stage, the planner and API selector collaborate to accomplish an instruction through iteratively decomposing it into suitable natural language sub-tasks and corresponding APIs. In each step $t$, the planner $\mathcal{P}$ leverages commonsense knowledge to generate a natural language (NL) sub-task $p_{t}$ based on the user instruction $q$, previous NL plans $\left(p_{1}, \ldots, p_{t-1}\right)$, and execution results $\left(r_{1}, \ldots, r_{t-1}\right)$, thereby constructing a high-level NL plan. Then, the API selector $\mathcal{S}$ reads the descriptions of available API endpoints to select appropriate APIs and construct the finer API plan $a_{t}$, which may contain a single or multiple API calls to solve the current NL plan $p_{t}$. Then the executor $\mathcal{E}$ executes the API plan $a_{t}$ and gets the execution result $r_{t}$ for current step. This process can be formulated as:</p>
<p>$$
\begin{aligned}
\text { NL Plan: } p_{t} &amp; \leftarrow \mathcal{P}\left(q ; p_{1}, r_{1} \ldots, p_{t-1}, r_{t-1}\right) \
\text { API Plan: } a_{t} &amp; \leftarrow \mathcal{S}\left(p_{t} ; r_{1}, \ldots, r_{t-1}\right) \
\text { Exec. Res.: } r_{t} &amp; \leftarrow \mathcal{E}\left(a_{t} ; r_{1}, \ldots, r_{t-1}\right)
\end{aligned}
$$</p>
<p>In this way, the planner and API selector are dedicated to NL sub-task planning and API selection, respectively, effectively utilizing the large language models abilities of planning and text comprehension.</p>
<p>Alongside the "plan and execution" loop, we design two special states, "continual" and "end", for the planner to monitor the execution result from the executor. Specifically, if the planner finds that the current executor's output $r_{t}$ has not completed the present NL sub-task $p_{t}$, it will output a "continue" signal and provide a special NL plan $p_{t+1}$ to the API selector, instructing it to continue fulfilling the plan $p_{t}$. In such cases, the API selector will re-generate a new API plan based on the original NL plan $p_{t}$, new NL plan $p_{t+1}$, previous API plan $a_{t}$ and execution result $r_{t}$. This process is described as:</p>
<p>$$
\begin{aligned}
\text { API Plan: } a_{t+1} &amp; \leftarrow \mathcal{S}\left(p_{t}, p_{t+1} ; r_{1}, \ldots, r_{t-1} ; a_{t}, r_{t}\right) \
\text { Exec. Res.: } r_{t+1} &amp; \leftarrow \mathcal{E}\left(a_{t+1} ; r_{1}, \ldots, r_{t-1}, r_{t}\right)
\end{aligned}
$$</p>
<p>If the planner assesses that the user's request has been completed, it will give the termination signal "end" and output the final result. With such a design, our method achieves a more flexible online planning which is capable of handling various situations encountered in real-world scenarios.</p>
<p>The planner, API selector, and executor collaborate to form RestGPT's coarse-to-fine online planning framework. This framework significantly enhances the ability to decompose tasks and select appropriate APIs, providing the model with the flexibility to effectively tackle user instructions.</p>
<h1>3.3 API Plan Execution</h1>
<p>Once an API calling plan is generated, the next step is to execute it. The executor $\mathcal{E}$ consists of a caller and a response parser. The caller should read the API documents carefully and generate correct parameters or request body for the API call. Due to the constraints of maximum context length, we filter API documents and only preserve APIs appearing in current API plan $a_{t}$. Given the generated parameters and request body, we use Requests Python library to call the RESTful API. Besides, to guide the response parser to extract information from the API response, the caller also generates a response description and output instruction for the response parser. Figure 2 presents an example output of the caller.
RESTful APIs typically return a JSON formatted response with much redundant information. The executor needs to extract the required information from the response and return it to the planner. However, the response may sometimes have a complex structure or be lengthy, making it difficult to extract important information via directly prompting the LLMs. To address this problem, we make use of the response schema defined in the OAS. Specifically, we utilize the coding capability of LLM to generate Python parsing code based on the provided schema and output instructions generated by the caller. Next, the Python code is executed to get the final result. If there are no execution exceptions or errors, the output is returned. Otherwise, the LLM is prompted to parse the response directly as a backup.</p>
<h2>4 RestBench</h2>
<p>To assess the effectiveness of RestGPT in processing complex user instructions through RESTful APIs, we introduce RestBench, a high-quality human annotated dataset comprising of two real-world scenarios. Existing researches have proposed several benchmarks for the evaluation of tool/API augmented LLMs [23, 21, 9]. However, these benchmarks primarily focus on simple tasks that can be accomplished using a single API. We hope RestBench can facilitate the exploration on utilizing multiple APIs to address real-world user instructions.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Scenario</th>
<th style="text-align: center;">Num. <br> APIs</th>
<th style="text-align: center;">Len. of Solution Path</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Avg. <br> Len.</th>
<th style="text-align: center;">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">TMDB</td>
<td style="text-align: center;">54</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">66</td>
<td style="text-align: center;">27</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: left;">Spotify</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">57</td>
</tr>
</tbody>
</table>
<p>Table 2: Statistics of RestBench test set. We report the number of instructions with different lengths of solution path.</p>
<h1>4.1 Scenarios and APIs</h1>
<p>We select two common real-world scenarios: TMDB movie database and Spotify music player. The main consideration is to evaluate the capabilities of RestGPT: (1) augmenting LLMs with external specialized domain database via RESTful APIs; (2) connecting LLMs with RESTful APIs to autonomously control real-world applications. TMDB offers official RESTful APIs encompassing the information of movies, TVs, actors, and images. Spotify music player provides API endpoints to retrieve content metadata, receive recommendations, create and manage playlists, and control playback. For these two scenarios, we filter out 54 and 40 commonly used APIs respectively and obtain the corresponding OpenAPI Specifications to build RestBench.</p>
<h3>4.2 Dataset Collection</h3>
<p>High-quality instructions generally satisfy two crucial aspects: (1) to reflect a wide range of real user needs; (2) to cover different levels of complexity to fully study the reasoning and planning ability of our method. To achieve these goals, we adopt a bottom-up instruction collection approach. We employ 6 experts that work on NLP research to brainstorm instructions for different combinations of APIs. Along with the instructions, the experts need to annotate the gold API solution path for each instruction. To guarantee the quality of the instructions, we employ two additional experts to thoroughly verify the solvability of each instruction and correctness of the corresponding solution path. Ultimately, we annotate 10 instruction-solution pairs for each scenario as the development set, and 100 pairs for TMDB and 57 pairs for Spotify as the test set. Though the data scale is not large, these instructions are typical of the frequently raised user requests. Moreover, different from prior work which uses LLMs to get API calling procedure, we utilize human labeled API solution paths for evaluation. Table 3 presents example instructions of the two scenarios. The statistics of RestBench are shown in Table 2.</p>
<h3>4.3 Evaluation Metrics</h3>
<p>Since some user requests are time-dependent (see the TMDB example in Table 3), it is impractical to annotate a fixed ground-truth answer for each instruction, whereas, the API solution paths for most instructions remain consistent. If the model-generated API call path contains the gold API call path as a subsequence (with the elements not necessarily being contiguous), we think that the model has generated a correct path. To further evaluate the model's performance, we rely on human evaluation to determine if the model result successfully fulfills the user query. We calculate the proportion of correct paths and successful query completions as metrics, i.e., Correct Path Rate and Success Rate. Moreover, the number of actual API calls can be utilized to measure the planning efficiency of different methods. Given the length of gold solutions, we further define $\Delta$ Solution Len. as the</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>TMDB</th>
<th></th>
<th></th>
<th>Spotify</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Success%</td>
<td>CP%</td>
<td>$\Delta$ Solution Len.</td>
<td>Success%</td>
<td>CP%</td>
<td>$\Delta$ Solution Len.</td>
</tr>
<tr>
<td>Offline [9]</td>
<td>29.0</td>
<td>33.0</td>
<td>+1.52</td>
<td>14.5</td>
<td>36.4</td>
<td>+1.10</td>
</tr>
<tr>
<td>DEPS [7]</td>
<td>38.0</td>
<td>43.0</td>
<td>+1.20</td>
<td>19.3</td>
<td>43.8</td>
<td>+1.74</td>
</tr>
<tr>
<td>ReAct [16]</td>
<td>44.0</td>
<td>57.0</td>
<td>+0.76</td>
<td>54.5</td>
<td>49.1</td>
<td>+0.31</td>
</tr>
<tr>
<td>Reflexion [26]</td>
<td>52.0</td>
<td>59.0</td>
<td>+1.37</td>
<td>59.6</td>
<td>61.4</td>
<td>+1.68</td>
</tr>
<tr>
<td>RestGPT</td>
<td>75.0</td>
<td>79.0</td>
<td>+0.55</td>
<td>72.7</td>
<td>74.5</td>
<td>+0.25</td>
</tr>
<tr>
<td>w/o Planner ${ }^{\dagger}$</td>
<td>44.0</td>
<td>57.0</td>
<td>+0.76</td>
<td>54.5</td>
<td>49.1</td>
<td>+0.31</td>
</tr>
<tr>
<td>w/o Parser</td>
<td>46.0</td>
<td>53.0</td>
<td>+0.60</td>
<td>47.3</td>
<td>52.7</td>
<td>+0.24</td>
</tr>
<tr>
<td>RestGPT (ChatGPT)</td>
<td>68.0</td>
<td>65.0</td>
<td>+0.72</td>
<td>69.1</td>
<td>72.3</td>
<td>+0.28</td>
</tr>
<tr>
<td>RestGPT (Llama2-13B)</td>
<td>0.0</td>
<td>0.0</td>
<td>-</td>
<td>0.0</td>
<td>0.0</td>
<td>-</td>
</tr>
<tr>
<td>RestGPT (Vicuna-13B)</td>
<td>9.0</td>
<td>15.0</td>
<td>+1.21</td>
<td>12.7</td>
<td>20.6</td>
<td>+1.52</td>
</tr>
</tbody>
</table>
<p>Table 4: Success rate ( $\%$ ), Correct Path rate (CP, \%), and $\Delta$ Solution Length on two scenarios of RestBench. The best results are in boldface. $\dagger$ RestGPT w/o planner is equivalent with ReAct equipped with our proposed executor.
mean number of additional API calls required to successfully execute an instruction:</p>
<p>$$
\Delta \text { Solution Len. }=\frac{1}{N_{s}} \sum_{i=0}^{N}\left(L_{\text {real }}^{i}-L_{\text {gold }}^{i}\right) \cdot \mathbb{I}(i, \text { success })
$$</p>
<p>where $N_{s}$ is the number of successfully accomplished instructions, $L_{\text {real }}^{i}$ and $L_{\text {gold }}^{i}$ are the actually and gold number of API calls for the $i$-th instruction respectively, $\mathbb{I}(i$, success $)$ denotes whether the $i$-th instruction is successfully completed.</p>
<h1>5 Experiments</h1>
<h3>5.1 Experimental Setup</h3>
<p>We compare RestGPT with four recent baselines, including offline introspective method [9] used in HuggingGPT [13] and Chameleon [12], DEPS [7], ReAct [16] and Reflexion [26]. Since some methods are not originally designed for tool/API usage, we reproduce them and add the API executor proposed in Section 3.3 to make them able to call RESTful APIs. The maximum steps for DEPS is set to 10 and the maximum trials for Reflexion is set to 2.
To showcase the planning and API calling capabilities of our method, we implement two ablation variants of RestGPT. The first variant involves removing the planner and allowing the API selector to directly choose APIs in a ReAct style. This approach can be seen as ReAct equipped with our proposed executor. The second one is to replace the schema-based response parser with an LLM that directly reads and extracts the required information from the JSON response.
In our experiments, we employ text-davinci-003 from OpenAI as the LLM for RestGPT and all baselines. The decoding temperature is set to 0 for the most deterministic generation.</p>
<h3>5.2 Main Results</h3>
<p>Table 4 shows the performance of RestGPT and baselines on two scenarios. Our approach outperforms all other methods in both scenarios, achieving a success rate of $75 \%$ on the movie database and over $70 \%$ on the music player. Note that in most cases, the correct path rate is slightly higher than success rate, indicating that the method may generate correct API calling plan but fail to execute it. RestGPT also stands out with its minimal solution length, showcasing the superior planning ability of the coarse-to-fine online planning mechanism.
Ablation experiments on coarse-to-fine planning and schema-based parser show both mechanisms are conductive to the model performance. Particularly, when removing the planner, the performance degrades significantly, indicating that current LLMs are unable to simultaneously conduct planning, API understanding and selection. Thus, the coarse-to-fine planning mechanism plays a crucial role in</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Error breakdown of RestGPT on RestBench. Error types are categorized by the module where the error occurred.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Scaling ability of RestGPT. (a) (b) Scaling curves of the gold solution path on TMDB and Spotify. The length of gold API solution path indicates the complexity of the instruction. (c) Scaling curves of the number of APIs on TMDB scenario.</p>
<p>Our framework. The ablation results without parser demonstrates that the schema-based parser enables LLMs to better comprehend and parse the real-world API responses with complicated structure.</p>
<p>To investigate the performance of our method with different base LLMs, we implement RestGPT with ChatGPT (gpt-3.5-turbo-0301), Llama2-13B (Llama-2-13b-chat-hf), and Vicuna-13B (vicuna-13b-v1.5). As shown in Table 4, the performance of ChatGPT is slightly worse than text-davinci-003. Interestingly, we have tried all official checkpoints of Llama2-13B, but none of them were able to comprehend the prompt and generate valid plans. In contrast, Vicuna-13B, which is fine-tuned from Llama2 on user-shared conversations, can accomplish some simple instructions. This result indicates that by fine-tuning LLMs on ChatGPT-generated data, the model can acquire the ability to understand and follow complicate prompts.</p>
<h3>5.3 Error Analysis</h3>
<p>To further investigate the effectiveness of different modules in RestGPT, we conduct error analysis. In Figure 3, we classify errors based on the module in which they occur. We discover that the majority of errors occur during the planning stage, i.e., within the planner (purple) and API selector (blue). The planner sometimes loses track of its intended objective after multiple rounds of execution, resulting in early exit before completing the instruction. For the API selector, it may either select incorrect APIs or hallucinate to make up in-path parameters. This error analysis highlights the insufficient planning and decision-making capabilities of LLMs.</p>
<p>Compared with text-davinci-003, ChatGPT tends to make more errors in the planning stage, leading to slightly worse performance on both scenarios. More specifically, we find that ChatGPT is often too verbose and tend to continue planning even after the user instruction has been fulfilled. This behavior can be attributed to the fact that ChatGPT is trained specifically for conversational interactions, which encourages it to generate more lengthy responses.</p>
<h3>5.4 Scaling Curves</h3>
<p>In this section, we aim to demonstrate the scaling ability of RestGPT on two dimensions: scaling the difficulty of the tasks and scaling the number of APIs.</p>
<p>For each instruction in RestBench, the length of gold solution path indicates the complexity of the instruction. We calculate the success rate of models on instructions with varying complexities.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Case study of three methods, (a) Offline [9, 13, 12], (b) ReAct [16], and (c) RestGPT. For offline method, we only show the generated plan. For ReAct and RestGPT, we omit the detailed execution process of the executor.</p>
<p>As depicted in Figure 4 (a) (b), the success rate of all methods decreases as the complexity of the instruction increases. Notably, when the gold path length is 4, all baselines struggle to complete the task in both scenarios. In contrast, our proposed RestGPT can still achieve a success rate of over 40%, showing its superior performance in planning and API calling.</p>
<p>Before conducting experiments on scaling the number of APIs, we handpicked 10 APIs from TMDB and created a small test set comprising 15 instructions. All 15 instructions can be resolved using the selected 10 APIs. Then, we increasingly expanded the number of APIs and introduced additional noise APIs sourced from the official TMDB APIs. The results are shown in Figure 4 (c). As the number of noise APIs increases, the performance of all baseline methods deteriorates due to their inferior planning and reasoning. However, our method almost remains unaffected. These results effectively demonstrate the strong extensibility of our proposed RestGPT.</p>
<h3>5.5 Case Study</h3>
<p>In Figure 5, we conduct a case study to compare the planning ability of RestGPT with the offline planning [9, 12] and ReAct [16] framework. Firstly, we observe the offline method is unable to solve most user instructions. As depicted in Figure 5 (a), the planner not only selects the wrong API (step 2), but also ignores the dependencies between APIs and used the parameter "user_id" before obtaining it (step 4). Regarding ReAct which generates chain-of-thought and actions in an interleaved manner, we find that current LLMs have a limited ability to simultaneously conduct planning, API understanding and selection. As shown in Figure 5 (b), the planner of ReAct generates a sub-task that is difficult to solve (step 2) and also ignores the dependencies between different APIs (step 3). Due to the inferior planning, it consumes 6 API calls to complete the task. In contrast, RestGPT employs a planner to generate high-level NL sub-tasks and an API selector to choose appropriate APIs to solve the sub-task. Notably, in step 3, the planner assesses the playlist that has not been successfully created and generate "continue" signal with further instructions for the API selector. Our method accomplishes the instruction with only 4 API calls. The coarse-to-fine online planning framework of RestGPT fully exploits the LLMs' planning and document understanding capabilities, providing the model with the flexibility to tackle complex user requests.</p>
<h2>6 Conclusion</h2>
<p>In this paper, we explore the scenarios of connecting current large language models (LLMs) with real-world applications via RESTful APIs. To overcome the limitations of existing approaches and tackle the challenges in integrating LLMs with RESTful APIs, we propose RestGPT, an approach that leverages LLMs to complete complex user instructions. Our method features a coarse-to-fine online planning mechanism to enable more flexible planning and API selection. Furthermore, to handle the complex scenario of calling RESTful APIs, we designed a specialized API executor to</p>
<p>formulate parameters and parse API responses. To assess the performance of our method, we build a high-quality dataset, RestBench, which consists of human-annotated instructions from two realistic scenarios. Extensive experiments demonstrate that RestGPT achieves impressive results in complex tasks and exhibits strong robustness, which paves a new way towards AGI. In the future, we aim to delve into a broader range of intricate tasks, thoroughly examining the immense potential of RestGPT across both academic and industrial domains.</p>
<h1>References</h1>
<p>[1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.
[2] OpenAI. Chatgpt, 2022. URL https://openai.com/blog/chatgpt.
[3] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. A survey for in-context learning. arXiv preprint arXiv:2301.00234, 2022.
[4] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.
[5] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022.
[6] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International Conference on Machine Learning, pages 9118-9147. PMLR, 2022.
[7] Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang. Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. arXiv preprint arXiv:2302.01560, 2023.
[8] Grgoire Mialon, Roberto Dess, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozire, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. arXiv preprint arXiv:2302.07842, 2023.
[9] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al. Tool learning with foundation models. arXiv preprint arXiv:2304.08354, 2023.
[10] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language models. arXiv preprint arXiv:2205.12255, 2022.
[11] Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.
[12] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large language models. arXiv preprint arXiv:2304.09842, 2023.
[13] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580, 2023.
[14] Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671, 2023.
[15] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, and Ying Shan. Gpt4tools: Teaching large language model to use tools via self-instruction. arXiv preprint arXiv:2305.18752, 2023.
[16] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.
[17] Li Li, Wu Chou, Wei Zhou, and Min Luo. Design patterns and extensibility of rest api for networking applications. IEEE Transactions on Network and Service Management, 13(1):154-167, 2016.
[18] SmartBear. Swagger, 2023. URL https://swagger.io/.</p>
<p>[19] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.
[20] Ddac Surs, Sachit Menon, and Carl Vondrick. Vipergpt: Visual inference via python execution for reasoning. arXiv preprint arXiv:2303.08128, 2023.
[21] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model connected with massive apis. arXiv preprint arXiv:2305.15334, 2023.
[22] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le Sun. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases. arXiv preprint arXiv:2306.05301, 2023.
[23] Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Api-bank: A benchmark for tool-augmented llms. arXiv preprint arXiv:2304.08244, 2023.
[24] Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui. Large language models are not fair evaluators. arXiv preprint arXiv:2305.17926, 2023.
[25] Mark Masse. REST API design rulebook: designing consistent RESTful web service interfaces. " OReilly Media, Inc.", 2011.
[26] Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. arXiv preprint arXiv:2303.11366, 2023.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: A RESTful API from TMDB.</p>
<h1>A RESTful APIs and OAS</h1>
<p>RESTful API (Representational State Transfer API) is an architectural style used for designing networked applications. It is based on the principles of Representational State Transfer (REST) and is widely used for building web services.[25, 17]. In a RESTful API, resources (such as data objects or services) are represented as URLs (Uniform Resource Locators), known as endpoints. These endpoints are accessed over the HTTP protocol, and different HTTP methods (GET, POST, etc.) are used to perform operations on the resources. There are millions of RESTful APIs available on Internet, such as Spotify, Twitter, Gmail, etc.</p>
<p>The OpenAPI Specification (OAS), formerly known as Swagger, is a specification for defining and documenting RESTful APIs [18]. It provides a standardized way to describe the structure, functionality, and behavior of an API, making it easier for developers to understand and interact with the API. The OpenAPI Specification is written in JSON or YAML format and consists of a set of rules and conventions that define the endpoints, request/response formats, parameters, authentication methods, and other details of the API. More specifically, an OAS consists of the following aspects for each API endpoint:</p>
<ul>
<li>API Path: a relative path to an individual API endpoint, e.g., /{person_id}/details.</li>
<li>API Description: what the API does, how it works, and any potential errors or exceptions that may be raised.</li>
<li>Request Method: the desired action to be performed for the API, e.g., GET, POST, DELETE.</li>
<li>Parameter List: parameter name, parameter description, data type, default value, optional values of each parameter for the API.</li>
<li>Response Schema: the schema of the response of the API. This information can assist the response parser to extract useful information from the JSON response.</li>
<li>Response Example (Optional): an example of a API call which can help demonstrate what the API will response.</li>
<li>Error and Exception: potential error codes and their corresponding descriptions.</li>
</ul>
<p>We provide an example of an OAS description of an API endpoint in Figure 6 and Figure 7.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">OpenAPI Specification</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">description: Search for movies <br> operationId: GET_search-movie <br> parameters: <br> - description: Pass a ISO 639-1 value to display translated data for <br> the fields that support it. <br> in: query <br> name: language <br> schema: <br> default: ex-US <br> type: string <br> - description: Pass a text query to search. This value should be UNI encoded. <br> in: query <br> name: query <br> required: true <br> schema: <br> type: string <br> - description: Specify which page to query. <br> in: query <br> name: page <br> schema: <br> default: 1 <br> type: integer <br> - description: Choose whether to inlcude adult (pornography) content. <br> in the results. <br> in: query <br> name: include_adult <br> schema: <br> default: false <br> type: boolean <br> - description: Specify a ISO 5166-1 code to filter release dates. <br> Must be uppercase. <br> in: query <br> name: region <br> schema: <br> type: string <br> - in: query <br> name: year <br> schema: <br> type: integer <br> - in: query <br> name: primary_release_year <br> schema: <br> type: integer</td>
<td style="text-align: center;">responses: <br> "200": <br> context: <br> application/json: <br> schema: <br> properties: <br> page: <br> type: integer <br> results: <br> items: <br> properties: <br> adult: <br> type: boolean <br> backdrop_path: <br> type: string <br> genre_ids: <br> items: <br> type: integer <br> type: array <br> id: <br> type: integer <br> original_language: <br> type: string <br> original_title: <br> type: string <br> overview: <br> type: string <br> popularity: <br> type: number <br> poster_path: <br> type: string <br> release_date: <br> type: string <br> title: <br> type: string <br> video: <br> type: boolean <br> vote_average: <br> type: number <br> vote_count: <br> type: integer <br> title: Movie list Result Object <br> type: object <br> type: array <br> total_pages: <br> type: integer <br> total_results: <br> type: integer <br> type: object</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Figure 7: The OpenAPI Specification (OAS) of the API endpoint in Figure 6.</p>
<h1>B Baselines</h1>
<p>To demonstrate the effectiveness of RestGPT, we compare it with four recent baselines:
Offline introspective method [9] is widely used in work on tool-augmented LLMs, such as HuggingGPT [13] and Chameleon [12]. This method directly generates multi-step plans for tool use and then sequentially executes the API plan. Due to the absence of API feedback, offline method cannot adjust the plan to adapt the unforeseen situations and errors in complex scenarios.
DEPS [7], or "Describe, Explain, Plan and Select", is an interactive planning approach based on LLMs to improve the long-term planning ability on open-world problems. DEPS will iteratively update the plan based on the environment feedback until the task is finished.
ReAct [16] generates the chain-of-thought and actions in an interleaved manner. The LLMs will reason about the current situation to make a better subsequent plan.
Reflexion [26] is inspired from the "trial and error" of human learning process. It verbally reflect on task feedback signals, then maintain the reflective text in an episodic memory to induce better planning in subsequent trials.
Since some methods are not originally designed for tool/API usage, we reproduce them and add the API executor we proposed to make them able to call RESTful APIs.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 8: Case study on the response parser. The purpose of response parsing is to extract required information from the API response (b) according to the plan (a). We compare our proposed parser (d) with directly prompting an LLM as a parser (c).</p>
<h1>C Case Study on the Executor</h1>
<p>Figure 8 illustrates how RestGPT parses JSON responses of RESTful APIs. We compare RestGPT parser with directly prompting an LLM as a parser. As shown, responses from RESTful APIs are usually in lengthy and complex JSON format ( 694 lines in Figure 8 (b)) The RestGPT parser generates information extraction code based on the response schema in the OAS to avoid parsing lengthy JSON files directly, significantly improving the efficiency and accuracy of response parsing.</p>
<h2>D More Cases on RestBench</h2>
<p>In this section, we show more cases of RestGPT accomplishing complex instructions in two scenarios of RestBench. Table 5 and 6 show two cases of the TMDB scenario. Table 7 and 8 show two cases of the Spotify scenario.</p>
<h2>E Failure Cases</h2>
<p>We also present two failure cases of RestGPT. In the first case (Table 9), the API selector hallucinate to make up the in-path parameter tv_id for the API. The second failure case (Table 10) involved multiple issues. Firstly, the executor correctly provided the desired query result, while the planner</p>
<p>continued to generate a redundant plan. Additionally, the response parser generated incorrect parsing code and got the name of the album instead of the track. As a result, RestGPT returned an incorrect answer. These failure cases highlight the limitations of RestGPT and the need for further improvement.</p>
<h1>F Implementation Details</h1>
<p>In this section, we show the details of the prompt design in RestGPT. Some prompts are inspired by the OpenAPI agent implemented by LangChain ${ }^{2}$. The prompts of the planner, API selector, caller, response parser are shown in Table 11, 12, 13, 14, respectively.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>$\triangleright$ Instruction of TMDB</h1>
<p>Give me the number of movies directed by Sofia Coppola.
$\triangleright$ RestGPT
Planner: search for the director "Sofia Coppola"
API Selector: GET /search/person to search for the director "Sofia Coppola"</p>
<h2>Caller:</h2>
<p>I need to make a GET request to the /search/person endpoint with the query parameter set to "Sofia Coppola".
Operation: GET
Input: ${$
"url": "https://api.themoviedb.org/3/search/person",
"params": ${$
"query": "Sofia Coppola"
},
"description": "The API response is a list of people matching the query.",
"output_instructions": "What is the id of Sofia Coppola?"
}
Parser: The id of the person is 1769
Caller: Successfully call GET /search/person to search for the director "Sofia Coppola". The id of Sofia Coppola is 1769 .</p>
<p>Planner: Get the number of movies directed by Sofia Coppola (1769)
API Selector: GET /person/1769/movie_credits to get the number of movies directed by Sofia Coppola (id 1769)</p>
<h2>Caller:</h2>
<p>I need to call GET /person/1769/movie_credits to get the number of movies directed by Sofia Coppola (id 1769).
Operation: GET
Input: ${$
"url": "https://api.themoviedb.org/3/person/1769/movie_credits",
"description": "The API response is the movie credit list of Sofia Coppola (id 1769)",
"output_instructions": "What are the names and ids of the movies directed by this person?"
}
Parser: The movies directed by Sofia Coppola are Lost in Translation (153), The Virgin Suicides (1443), Marie Antoinette (1887), Somewhere (39210), Lick the Star (92657), The Bling Ring (96936), A Very Murray Christmas (364067), Bed, Bath and Beyond (384947), The Beguiled (399019), On the Rocks (575417), The Custom of the Country (758422), New York City Ballet (826970), Priscilla (1020006), Un matin partout dans le monde (835318)</p>
<p>Caller: Successfully call GET /person/1769/movie_credits to get the movie credit list of Sofia Coppola (id 1769). The movies directed by Sofia Coppola are Lost in Translation (153), The Virgin Suicides (1443), Marie Antoinette (1887), Somewhere (39210), Lick the Star (92657), The Bling Ring (96936), A Very Murray Christmas (364067), Bed, Bath and Beyond (384947), The Beguiled (399019), On the Rocks (575417), The Custom of the Country (758422), New York City Ballet (826970), Priscilla (1020006), Un matin partout dans le monde (835318).</p>
<p>Planner: I am finished executing a plan and have the information the user asked for or the data the used asked to create. Final Answer: Sofia Coppola has directed 14 movies.</p>
<p>Table 5: Case 1 for TMDB.</p>
<h1>$\triangleright$ Instruction of TMDB</h1>
<p>Who is the director of Leonardo DiCaprio's latest movie?</p>
<h2>$\triangleright$ RestGPT</h2>
<p>Planner: search for the latest movie of Leonardo DiCaprio
API Selector: GET /search/person to get the id of Leonardo DiCaprio</p>
<h2>Caller:</h2>
<p>I need to make a GET request to the /search/person endpoint with the query parameter set to "Leonardo DiCaprio"
Operation: GET
Input: ${$
"url": "https://api.themoviedb.org/3/search/person",
"params": {"query": "Leonardo DiCaprio"},
"description": "The API response is a list of people.",
"output_instructions": "What is the id of Leonardo DiCaprio?"
}
Parser: The id of the person is 6193
Caller: Successfully call GET /search/person to search for the person "Leonardo DiCaprio". The id of Leonardo DiCaprio is 6193.</p>
<p>Planner: Continue. search for the latest movie of Leonardo DiCaprio (6193)
API Selector: GET /person/6193/movie_credits to get the latest movie of Leonardo DiCaprio (6193) Caller:
I need to call GET /person/6193/movie_credits to get the latest movie of Leonardo DiCaprio (6193). Operation: GET
Input: ${$
"url": "https://api.themoviedb.org/3/person/6193/movie_credits",
"description": "The API response is the movie credit list of Leonardo DiCaprio (id 6193)",
"output_instructions": "What is the name and id of the latest movie of Leonardo DiCaprio (6193)?" }
Parser: The name of the latest movie of Leonardo DiCaprio is Killers of the Flower Moon and the id is 466420
Caller: Successfully call GET /person/6193/movie_credits to get the movie credit list of Leonardo DiCaprio (id 6193). The name of the latest movie of Leonardo DiCaprio is Killers of the Flower Moon and the id is 466420 .</p>
<p>Planner: search for the director of Killers of the Flower Moon (466420)
Caller:
I need to call GET /movie/{movie_id}/credits to get the director of the movie Killers of the Flower Moon (id 466420).
Operation: GET
Input: ${$
"url": "https://api.themoviedb.org/3/movie/466420/credits",
"description": "The API response is the cast and crew for the movie Killers of the Flower Moon (id 466420).",
"output_instructions": "What is the name and id of the director of the movie Killers of the Flower Moon (id 466420)?"
}
Parser: The name of the director of the movie Killers of the Flower Moon (id 466420) is Martin Scorsese (1032)
Caller: Successfully call GET /movie/466420/credits to get the director of the movie Killers of the Flower Moon (id 466420). The name and id of the director of the movie Killers of the Flower Moon (id 466420) is Martin Scorsese (1032).</p>
<p>Planner: I am finished executing a plan and have the information the user asked for or the data the used asked to create. Martin Scorsese (1032) is the director of Leonardo DiCaprio's latest movie Killers of the Flower Moon (466420).</p>
<p>Table 6: Case 2 for TMDB.</p>
<h1>$\triangleright$ Instruction of Spotify</h1>
<p>Set the volume to 60 and skip to the next track.
$\triangleright$ RestGPT
Planner: set the volume to 60
API Selector: PUT/me/player/volume to set the volume to 60</p>
<h2>Caller:</h2>
<p>I need to make a PUT request to the /me/player/volume endpoint with the volume_percent parameter set to 60 .
Operation: PUT
Input: ${$
"url": "https://api.spotify.com/v1/me/player/volume",
"params": ${$
"volume_percent": "60"
},
"description": "Set the volume for the current playback device."
}
Parser: The volume for the current playback device has been set to $60 \%$.
Caller: Successfully call PUT /me/player/volume to set the volume to 60. The volume for the current playback device has been set to $60 \%$.</p>
<p>Planner: skip to the next track
API Selector: POST /me/player/next to skip to the next track</p>
<h2>Caller:</h2>
<p>I need to make a POST request to the /me/player/next endpoint to skip to the next track.
Operation: POST
Input: ${$
"url": "https://api.spotify.com/v1/me/player/next",
"description": "Skips to next track in the user's queue.",
}
Parser: The API call successfully skipped to the next track in the user's queue.
Caller: Successfully call POST /me/player/next to skip to the next track.
Planner: I am finished executing a plan and completed the user's instructions. I have set the volume to 60 and skipped to the next track.</p>
<p>Table 7: Case 1 for Spotify.</p>
<h1>$\triangleright$ Instruction of Spotify</h1>
<p>Add Summertime Sadness by Lana Del Rey in my first playlist.
RestGPT
Planner: Get the id of my first playlist
API Selector: GET/me/playlists to get the list of playlists owned or followed by the current Spotify user
Caller:
I need to use the GET method and generate the parameters according to the API documentation. Operation: GET
Input: ${$
"url": "https://api.spotify.com/v1/me/playlists",
"description": "Get a list of the playlists owned or followed by the current Spotify user.",
"params": {"limit": "1", "offset": "0"},
"output_instructions": "What are the ids and names of the playlists?"
}
Parser: The id and name of the first playlist in the list is 6GHT and My Pop
Caller: Successfully call GET /me/playlists to get the list of playlists owned or followed by the current Spotify user. The id and name of the first playlist in the list is 6GHT and My Pop.</p>
<p>Planner: Search for Summertime Sadness by Lana Del Rey
API Selector: GET /search to search for the track "Summertime Sadness" by Lana Del Rey
Caller:
I need to call GET /search with the appropriate parameters to search for the track "Summertime Sadness" by Lana Del Rey.
Operation: GET
Input: ${$
"url": "https://api.spotify.com/v1/search",
"params": {"q": "track:Summertime Sadness artist:Lana Del Rey", "type": "track", "limit": "1", "offset": "0"},
"description": "The API response is a track object for the track 'Summertime Sadness' by Lana Del Rey.",
"output_instructions": "What is the id of the track?"
}
Parser: The id of the track is 1Ist
Caller: Successfully call GET /search to search for the track "Summertime Sadness" by Lana Del Rey. The id of the track is 1Ist.</p>
<p>Planner: Add Summertime Sadness by Lana Del Rey (1Ist) in my first playlist (6GHT)
Caller:
I need to make a POST request to add the track to the playlist.
Operation: POST
Input: ${$
"url": "https://api.spotify.com/v1/playlists/6GHT/tracks",
"data": {"uris": ["spotify:track:1Ist"]},
"description": "The API response is the track added to the playlist.",
"output_instructions": "What is the id of the snapshot of the playlist?"
}
Parser: The snapshot id of the playlist is "NCxj".
Caller: Successfully call POST /playlists/6GHT/tracks to add the track "Summertime Sadness" (1Ist) to the playlist "My Pop" (6GHT).
Planner: I am finished executing a plan and have the data the used asked to create. I have added Summertime Sadness by Lana Del Rey in your first playlist My Pop.</p>
<p>Table 8: Case 2 for Spotify. Note that all IDs provided here are fake due to copyright restrictions.</p>
<h1>$\triangleright$ Instruction of TMDB</h1>
<p>Give me a photo belong to the second episode of the first season of the Witcher
$\triangleright$ RestGPT
Planner: search for the id of the second episode of the first season of the Witcher
API Selector: GET /tv/63926/season/1/episode/2 to get the id of the second episode of the first season of the Witcher</p>
<h2>Caller:</h2>
<p>Operation: GET
Input: {
"url": "https://api.themoviedb.org/3/tv/63926/season/1/episode/2",
"description": "Get the id of the second episode of the first season of the Witcher",
"output_instructions": "What is the id of the second episode of the first season of the Witcher?"
}
Parser: The id of the second episode of the first season of the Witcher is 1132654
Caller: Successfully call GET /tv/63926/season/1/episode/2 to get the id of the second episode of the first season of the Witcher. The id of the second episode of the first season of the Witcher is 1132654 .</p>
<p>Planner: search for the photo belong to the second episode of the first season of the Witcher (1132654)
...(Finally Failed)
Table 9: A failure case for TMDB.</p>
<h1>$\triangleright$ Instruction of Spotify</h1>
<p>What is the name of the song I playing right now?
$\triangleright$ RestGPT
Planner: Get the current playing song
API Selector: GET /me/player/currently-playing to get the track currently being played on the user's Spotify account</p>
<h2>Caller:</h2>
<p>Operation: GET
Input: ${$
"url": "https://api.spotify.com/v1/me/player/currently-playing",
"params": ${$
"market": "US"
},
"description": "Get the track currently being played on the user's Spotify account.",
"output_instructions": "What is the name and id of the track currently being played?"
}
Parser: The name of the track currently being played is LOVE Destiny , and its id is 5 gAC</p>
<p>Caller: Successfully call GET /me/player/currently-playing to get the track currently being played on the user's Spotify account. The name of the track currently being played is LOVE Destiny , and its id is 5 gAC.</p>
<p>Planner: Get the name of the song ( 5 gAC )
API Selector: GET /tracks/5gAC to get the name of the song</p>
<h2>Caller:</h2>
<p>I need to call GET /tracks/{id} to get the name of the song
Operation: GET
Input: ${$
"url": "https://api.spotify.com/v1/tracks/5gAC",
"description": "Get Spotify catalog information for the track LOVE Destiny ",
"output_instructions": "What is the name of the song?"
}</p>
<h2>Parser: The name of the song is A BEST</h2>
<p>Caller: Successfully call GET /tracks/5gACkVtLdO8ITqbEF3ZfD1 to get the name of the song. The name of the song is A BEST.</p>
<p>Planner: I am finished executing a plan and have the information the user asked for. The name of the song you are playing right now is A BEST.</p>
<p>Table 10: A failure case for Spotify. Note that all IDs provided here are fake due to copyright restrictions.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ https://python.langchain.com/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>