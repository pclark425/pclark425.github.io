<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7984 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7984</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7984</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-145.html">extraction-schema-145</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <p><strong>Paper ID:</strong> paper-dcaade47c361eaff61c99590ca3d5b5a709fb034</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/dcaade47c361eaff61c99590ca3d5b5a709fb034" target="_blank">Negative Deceptive Opinion Spam</a></p>
                <p><strong>Paper Venue:</strong> North American Chapter of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This work creates and study the first dataset of deceptive opinion spam with negative sentiment reviews, and finds that standard n-gram text categorization techniques can detect negative deceptive opinions spam with performance far surpassing that of human judges.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7984.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7984.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Negative Deceptive Dataset</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Negative Deceptive Opinion Spam Dataset (400 MTurk negative reviews of 20 Chicago hotels)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A gold-standard corpus created in this paper containing 400 deceptive negative hotel reviews (20 per hotel) solicited via Amazon Mechanical Turk, paired with 400 sampled truthful negative reviews mined from online review sites for balanced classification experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computer science / natural language processing</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Balanced classification evaluation on held-out hotels (hotel-level cross-validation) and human judgment</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Dataset used to train and test deception detection systems and to collect human judgments; includes stratified splits by hotel so that models are trained on reviews for a subset of hotels and tested on held-out hotels to evaluate generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy; Precision; Recall; F1-score</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Accuracy: percentage of correctly labeled reviews; Precision: TP/(TP+FP) per class (%); Recall: TP/(TP+FN) per class (%); F1: harmonic mean of Precision and Recall (%).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Negative Deceptive Opinion Spam Dataset (this paper); paired with Ott et al. (2011) positive deceptive dataset</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td>Three undergraduate volunteer judges rated a randomized subset of 160 reviews (40 per each of four hotels); also two meta-judges (MAJORITY and SKEPTIC) aggregate judgments; inter-annotator agreement: Fleiss' kappa=0.07, highest pairwise Cohen's kappa=0.26.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Automated classifiers achieved ~86.0% accuracy on negative reviews (cross-validation); human judges best accuracy 65.0%; majority meta-judge 69.4%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Truthful reviews mined from web are not perfect gold standards (possible low unknown deception rate); Mechanical Turk demographic and instruction constraints; some manual filtering of submissions; dataset limited to hotels in Chicago.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7984.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HumanJudgmentEval</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Human Deception Detection Evaluation (three judges + meta-judges)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Human evaluation protocol where three untrained human judges labeled reviews as truthful or deceptive, with results aggregated via majority and skeptic meta-judges and measured for accuracy and inter-annotator agreement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>psychology / computational linguistics</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>human judgment benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Human binary labeling with aggregation (MAJORITY and SKEPTIC)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Three volunteer judges assessed randomized reviews; MAJORITY predicts deceptive if ≥2 judges label deceptive; SKEPTIC predicts deceptive if ≥1 judge labels deceptive. Statistical significance tested with two-tailed binomial tests; inter-annotator agreement measured with Fleiss' kappa and pairwise Cohen's kappa.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy; Precision; Recall; F1-score; Fleiss' kappa; Cohen's kappa; binomial test p-values</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Accuracy: % correct; Precision/Recall/F1 as class-specific percentages; Fleiss' kappa: measure of agreement among >2 raters (unitless, scale commonly interpreted via Landis & Koch); Cohen's kappa: pairwise agreement; binomial test p-value: probability of observed correct count under null of chance.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Subset of 160 reviews (40 deceptive + 40 truthful from each of four hotels) sampled from the paper's dataset</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td>N=3 undergraduate judges; evaluations on 160 reviews; majority and skeptic aggregations computed; Fleiss' kappa=0.07; highest pairwise Cohen's kappa=0.26; statistical significance for individual judges assessed via two-tailed binomial tests (p reported: J1 p=0.0002, J2 p=0.003, J3 p=0.07).</td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Judge accuracies: 65.0%, 61.9%, 57.5%; MAJORITY meta-judge accuracy 69.4%; SKEPTIC meta-judge accuracy 58.1%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Small number of human judges (3); judges were undergraduate volunteers (untrained); low inter-annotator agreement indicates inconsistency; limited sample (160 reviews).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7984.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>n-gram SVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Linear Support Vector Machine with unigram and bigram term-frequency features</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated deception detection classifier trained using linear SVMs on unigram and bigram TF features, evaluated with stratified 5-fold cross-validation and held-out sentiment experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computer science / machine learning / NLP</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>classification model for deception detection</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>5-fold stratified hotel-level cross-validation with nested CV for hyperparameter tuning; held-out sentiment transfer experiments</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>For each CV iteration, train on reviews from 16 hotels and test on remaining 4 hotels (hotel-level split). The SVM cost parameter C is tuned via nested cross-validation on training folds. Also perform held-out experiments training on one sentiment and testing on the other to assess transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy; Precision; Recall; F1-score (per class)</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Accuracy: % correct classifications; Precision = TP/(TP+FP); Recall = TP/(TP+FN); F1 = 2 * (Precision*Recall)/(Precision+Recall). Reported as percentages.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Negative Deceptive Opinion Spam Dataset (this paper) and Ott et al. (2011) positive dataset for combined experiments</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td>Comparison baseline: three human judges and aggregated meta-judges (see HumanJudgmentEval); automated classifiers compared against human performance.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Cross-validation accuracy on negative reviews: 86.0%; on positive reviews (from Ott et al.) cross-val: 89.3%; combined training yields ~88.4% on positive and ~86.0% on negative. Held-out cross-sentiment tests yield lower accuracy (e.g., training on positive testing on negative: 75.1%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Performance drops when training and testing sentiments differ, indicating sentiment-dependent deception cues; classifiers trained on web-mined truthful reviews assume low deception rate in source sites; generalization limited to hotels and the instituted MTurk protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7984.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EvaluationMetrics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classification and Agreement Metrics (Accuracy, Precision, Recall, F1, Fleiss' kappa, Cohen's kappa, binomial test)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Set of standard metrics used to evaluate classifier and human judge performance, and inter-annotator agreement and statistical significance of human performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>statistics / machine learning / psychometrics</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>evaluation criteria and statistical tests</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Accuracy + Precision/Recall/F1 for classifiers; Fleiss' kappa and Cohen's kappa for inter-annotator agreement; binomial test for significance against chance</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Classification performance reported via Accuracy and per-class Precision, Recall, and F1. Agreement across human annotators quantified using Fleiss' kappa (multi-annotator) and Cohen's kappa (pairwise). Statistical significance of human judge accuracy assessed using two-tailed binomial tests against chance accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy; Precision; Recall; F1; Fleiss' kappa; Cohen's kappa; p-values from binomial tests</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Accuracy/Precision/Recall/F1: percentages as defined above; Fleiss' kappa: normalized agreement metric (unitless); Cohen's kappa: pairwise normalized agreement; binomial test p-value: probability under binomial/null.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td>Reported Fleiss' kappa=0.07 (slight agreement); highest pairwise Cohen's kappa=0.26; binomial test p-values for judges (J1 p=0.0002, J2 p=0.003, J3 p=0.07).</td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>See reported numbers: human accuracies 57.5%-65.0%; MAJORITY meta-judge 69.4%; Fleiss' kappa=0.07.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Agreement metrics indicate low consistency across humans; significance tests limited by small judge sample; metrics assume balanced datasets in many reported summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7984.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>5foldHotelCV</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>5-fold stratified hotel-level cross-validation with nested CV for SVM tuning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cross-validation protocol where folds are constructed by hotel so that models are trained on reviews from 16 hotels and tested on reviews from 4 held-out hotels per iteration; SVM hyperparameter C is tuned by nested CV on training folds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>machine learning / NLP</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>evaluation protocol</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Hotel-level stratified 5-fold cross-validation with nested hyperparameter tuning</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Split dataset by hotel into 5 folds; in each iteration train on 4 folds (16 hotels) and test on 1 fold (4 hotels) to assess generalization to unseen hotels; perform nested CV within training folds to choose SVM C.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy; Precision; Recall; F1 per fold and aggregated</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Metrics computed on held-out fold per iteration and averaged across folds; see standard definitions above.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Negative Deceptive Opinion Spam Dataset (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Cross-validation results reported (e.g., 86.0% accuracy on negative reviews using cross-val).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Hotel-level splits reduce lexical/topic leakage but may still not reflect broader domain generalization beyond Chicago hotels; nested CV increases computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7984.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LIWC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LIWC2007 (Linguistic Inquiry and Word Count)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A psycholinguistic lexicon/tool used to quantify linguistic categories (e.g., negative emotion terms, pronoun usage, spatial terms) to analyze differences between deceptive and truthful reviews.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The development and psychometric properties of LIWC2007</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>psycholinguistics / computational linguistics</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>linguistic feature extraction framework</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>LIWC category frequency analysis</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Count and compare proportions of LIWC categories (e.g., negative emotion, first-person singular, spatial words) across deceptive and truthful reviews to identify linguistic cues associated with deception and sentiment.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Category frequency percentages (e.g., % of words in a review that belong to a LIWC category); group-level comparisons (means, SDs)</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Reported as percentages of tokens per review falling into a LIWC category, with group means and standard deviations.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Applied to this paper's negative deceptive dataset and Ott et al. (2011) positive dataset</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Fake negative reviews show higher frequency of negative emotion terms and altered pronoun/spatial term patterns (e.g., first-person singular rates reported with means and SDs).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>LIWC category differences may reflect exaggeration of sentiment rather than 'leakage' of emotional distress; lexicon-based counts can miss context and nuance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7984.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GAMLSS Log-normal Sampling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Log-normal sampling of truthful review lengths using GAMLSS (Rigby & Stasinopoulos, 2005)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A preprocessing method where truthful reviews are sampled to match the length distribution of deceptive reviews by fitting a left-truncated log-normal distribution to deceptive review lengths using the R GAMLSS package.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generalized additive models for location, scale and shape,(with discussion)</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>statistics / data preprocessing</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>sampling / data normalization procedure</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Length-matched sampling via log-normal fit (GAMLSS)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Fit a left-truncated log-normal distribution to lengths of deceptive reviews and sample truthful reviews according to that distribution to reduce length as a confounding variable between deceptive and truthful sets.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Distributional fit (implicit) and resulting balanced dataset lengths; no explicit numeric fit-quality metrics reported in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td>Sampling ensures truthful review length distribution approximates deceptive review length distribution; truncation at 150 characters.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Applied to truthful reviews sourced from Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor, Yelp to create balanced dataset</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Resulting dataset had truthful reviews sampled to match deceptive review lengths (deceptive mean length 178 words compared to positive dataset mean 116 words in Ott et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Sampling controls for length but may discard real-world variation; assumption that length is the primary confounder may omit other topical differences.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7984.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7984.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, metrics, frameworks, datasets, or criteria used to evaluate scientific theories or hypotheses generated by large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PlagiarismCheck</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Plagiarisma.net plagiarism checking</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Third-party web service used during data collection to detect and filter plagiarized Mechanical Turk submissions before accepting reviews into the dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>data curation / corpus integrity</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>data quality check</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Automated plagiarism detection during MTurk submission filtering</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Use plagiarisma.net to determine whether a submitted review is plagiarized and discard such submissions to maintain originality of the deceptive review corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>metric_definition</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_benchmark</strong></td>
                            <td>Applied during creation of Negative Deceptive Opinion Spam Dataset</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>automated_falsifiability_check</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessment</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Approximately 2% of MTurk submissions discarded/replaced when workers misread instructions (not specifically for plagiarism count reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_generated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_noted</strong></td>
                            <td>Automated plagiarism tools may miss paraphrased or lightly edited copied text; reliance on a single tool may not catch all cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Negative Deceptive Opinion Spam', 'publication_date_yy_mm': '2013-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Finding deceptive opinion spam by any stretch of the imagination <em>(Rating: 2)</em></li>
                <li>Opinion spam and analysis <em>(Rating: 2)</em></li>
                <li>The lie detector: Explorations in the automatic recognition of deceptive language <em>(Rating: 2)</em></li>
                <li>The development and psychometric properties of LIWC2007 <em>(Rating: 2)</em></li>
                <li>Accuracy of deception judgments <em>(Rating: 2)</em></li>
                <li>On lying and being lied to: A linguistic analysis of deception in computer-mediated communication <em>(Rating: 1)</em></li>
                <li>Generalized additive models for location, scale and shape,(with discussion) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7984",
    "paper_id": "paper-dcaade47c361eaff61c99590ca3d5b5a709fb034",
    "extraction_schema_id": "extraction-schema-145",
    "extracted_data": [
        {
            "name_short": "Negative Deceptive Dataset",
            "name_full": "Negative Deceptive Opinion Spam Dataset (400 MTurk negative reviews of 20 Chicago hotels)",
            "brief_description": "A gold-standard corpus created in this paper containing 400 deceptive negative hotel reviews (20 per hotel) solicited via Amazon Mechanical Turk, paired with 400 sampled truthful negative reviews mined from online review sites for balanced classification experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "computer science / natural language processing",
            "theory_type": null,
            "evaluation_method_name": "Balanced classification evaluation on held-out hotels (hotel-level cross-validation) and human judgment",
            "evaluation_method_description": "Dataset used to train and test deception detection systems and to collect human judgments; includes stratified splits by hotel so that models are trained on reviews for a subset of hotels and tested on held-out hotels to evaluate generalization.",
            "evaluation_metric": "Accuracy; Precision; Recall; F1-score",
            "metric_definition": "Accuracy: percentage of correctly labeled reviews; Precision: TP/(TP+FP) per class (%); Recall: TP/(TP+FN) per class (%); F1: harmonic mean of Precision and Recall (%).",
            "dataset_or_benchmark": "Negative Deceptive Opinion Spam Dataset (this paper); paired with Ott et al. (2011) positive deceptive dataset",
            "human_evaluation_details": "Three undergraduate volunteer judges rated a randomized subset of 160 reviews (40 per each of four hotels); also two meta-judges (MAJORITY and SKEPTIC) aggregate judgments; inter-annotator agreement: Fleiss' kappa=0.07, highest pairwise Cohen's kappa=0.26.",
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Automated classifiers achieved ~86.0% accuracy on negative reviews (cross-validation); human judges best accuracy 65.0%; majority meta-judge 69.4%.",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Truthful reviews mined from web are not perfect gold standards (possible low unknown deception rate); Mechanical Turk demographic and instruction constraints; some manual filtering of submissions; dataset limited to hotels in Chicago.",
            "uuid": "e7984.0",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "HumanJudgmentEval",
            "name_full": "Human Deception Detection Evaluation (three judges + meta-judges)",
            "brief_description": "Human evaluation protocol where three untrained human judges labeled reviews as truthful or deceptive, with results aggregated via majority and skeptic meta-judges and measured for accuracy and inter-annotator agreement.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "psychology / computational linguistics",
            "theory_type": "human judgment benchmark",
            "evaluation_method_name": "Human binary labeling with aggregation (MAJORITY and SKEPTIC)",
            "evaluation_method_description": "Three volunteer judges assessed randomized reviews; MAJORITY predicts deceptive if ≥2 judges label deceptive; SKEPTIC predicts deceptive if ≥1 judge labels deceptive. Statistical significance tested with two-tailed binomial tests; inter-annotator agreement measured with Fleiss' kappa and pairwise Cohen's kappa.",
            "evaluation_metric": "Accuracy; Precision; Recall; F1-score; Fleiss' kappa; Cohen's kappa; binomial test p-values",
            "metric_definition": "Accuracy: % correct; Precision/Recall/F1 as class-specific percentages; Fleiss' kappa: measure of agreement among &gt;2 raters (unitless, scale commonly interpreted via Landis & Koch); Cohen's kappa: pairwise agreement; binomial test p-value: probability of observed correct count under null of chance.",
            "dataset_or_benchmark": "Subset of 160 reviews (40 deceptive + 40 truthful from each of four hotels) sampled from the paper's dataset",
            "human_evaluation_details": "N=3 undergraduate judges; evaluations on 160 reviews; majority and skeptic aggregations computed; Fleiss' kappa=0.07; highest pairwise Cohen's kappa=0.26; statistical significance for individual judges assessed via two-tailed binomial tests (p reported: J1 p=0.0002, J2 p=0.003, J3 p=0.07).",
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Judge accuracies: 65.0%, 61.9%, 57.5%; MAJORITY meta-judge accuracy 69.4%; SKEPTIC meta-judge accuracy 58.1%.",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Small number of human judges (3); judges were undergraduate volunteers (untrained); low inter-annotator agreement indicates inconsistency; limited sample (160 reviews).",
            "uuid": "e7984.1",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "n-gram SVM",
            "name_full": "Linear Support Vector Machine with unigram and bigram term-frequency features",
            "brief_description": "Automated deception detection classifier trained using linear SVMs on unigram and bigram TF features, evaluated with stratified 5-fold cross-validation and held-out sentiment experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "computer science / machine learning / NLP",
            "theory_type": "classification model for deception detection",
            "evaluation_method_name": "5-fold stratified hotel-level cross-validation with nested CV for hyperparameter tuning; held-out sentiment transfer experiments",
            "evaluation_method_description": "For each CV iteration, train on reviews from 16 hotels and test on remaining 4 hotels (hotel-level split). The SVM cost parameter C is tuned via nested cross-validation on training folds. Also perform held-out experiments training on one sentiment and testing on the other to assess transfer.",
            "evaluation_metric": "Accuracy; Precision; Recall; F1-score (per class)",
            "metric_definition": "Accuracy: % correct classifications; Precision = TP/(TP+FP); Recall = TP/(TP+FN); F1 = 2 * (Precision*Recall)/(Precision+Recall). Reported as percentages.",
            "dataset_or_benchmark": "Negative Deceptive Opinion Spam Dataset (this paper) and Ott et al. (2011) positive dataset for combined experiments",
            "human_evaluation_details": "Comparison baseline: three human judges and aggregated meta-judges (see HumanJudgmentEval); automated classifiers compared against human performance.",
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Cross-validation accuracy on negative reviews: 86.0%; on positive reviews (from Ott et al.) cross-val: 89.3%; combined training yields ~88.4% on positive and ~86.0% on negative. Held-out cross-sentiment tests yield lower accuracy (e.g., training on positive testing on negative: 75.1%).",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Performance drops when training and testing sentiments differ, indicating sentiment-dependent deception cues; classifiers trained on web-mined truthful reviews assume low deception rate in source sites; generalization limited to hotels and the instituted MTurk protocol.",
            "uuid": "e7984.2",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "EvaluationMetrics",
            "name_full": "Classification and Agreement Metrics (Accuracy, Precision, Recall, F1, Fleiss' kappa, Cohen's kappa, binomial test)",
            "brief_description": "Set of standard metrics used to evaluate classifier and human judge performance, and inter-annotator agreement and statistical significance of human performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "statistics / machine learning / psychometrics",
            "theory_type": "evaluation criteria and statistical tests",
            "evaluation_method_name": "Accuracy + Precision/Recall/F1 for classifiers; Fleiss' kappa and Cohen's kappa for inter-annotator agreement; binomial test for significance against chance",
            "evaluation_method_description": "Classification performance reported via Accuracy and per-class Precision, Recall, and F1. Agreement across human annotators quantified using Fleiss' kappa (multi-annotator) and Cohen's kappa (pairwise). Statistical significance of human judge accuracy assessed using two-tailed binomial tests against chance accuracy.",
            "evaluation_metric": "Accuracy; Precision; Recall; F1; Fleiss' kappa; Cohen's kappa; p-values from binomial tests",
            "metric_definition": "Accuracy/Precision/Recall/F1: percentages as defined above; Fleiss' kappa: normalized agreement metric (unitless); Cohen's kappa: pairwise normalized agreement; binomial test p-value: probability under binomial/null.",
            "dataset_or_benchmark": null,
            "human_evaluation_details": "Reported Fleiss' kappa=0.07 (slight agreement); highest pairwise Cohen's kappa=0.26; binomial test p-values for judges (J1 p=0.0002, J2 p=0.003, J3 p=0.07).",
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "See reported numbers: human accuracies 57.5%-65.0%; MAJORITY meta-judge 69.4%; Fleiss' kappa=0.07.",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Agreement metrics indicate low consistency across humans; significance tests limited by small judge sample; metrics assume balanced datasets in many reported summaries.",
            "uuid": "e7984.3",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "5foldHotelCV",
            "name_full": "5-fold stratified hotel-level cross-validation with nested CV for SVM tuning",
            "brief_description": "Cross-validation protocol where folds are constructed by hotel so that models are trained on reviews from 16 hotels and tested on reviews from 4 held-out hotels per iteration; SVM hyperparameter C is tuned by nested CV on training folds.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "machine learning / NLP",
            "theory_type": "evaluation protocol",
            "evaluation_method_name": "Hotel-level stratified 5-fold cross-validation with nested hyperparameter tuning",
            "evaluation_method_description": "Split dataset by hotel into 5 folds; in each iteration train on 4 folds (16 hotels) and test on 1 fold (4 hotels) to assess generalization to unseen hotels; perform nested CV within training folds to choose SVM C.",
            "evaluation_metric": "Accuracy; Precision; Recall; F1 per fold and aggregated",
            "metric_definition": "Metrics computed on held-out fold per iteration and averaged across folds; see standard definitions above.",
            "dataset_or_benchmark": "Negative Deceptive Opinion Spam Dataset (this paper)",
            "human_evaluation_details": null,
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Cross-validation results reported (e.g., 86.0% accuracy on negative reviews using cross-val).",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Hotel-level splits reduce lexical/topic leakage but may still not reflect broader domain generalization beyond Chicago hotels; nested CV increases computational cost.",
            "uuid": "e7984.4",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "LIWC",
            "name_full": "LIWC2007 (Linguistic Inquiry and Word Count)",
            "brief_description": "A psycholinguistic lexicon/tool used to quantify linguistic categories (e.g., negative emotion terms, pronoun usage, spatial terms) to analyze differences between deceptive and truthful reviews.",
            "citation_title": "The development and psychometric properties of LIWC2007",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "psycholinguistics / computational linguistics",
            "theory_type": "linguistic feature extraction framework",
            "evaluation_method_name": "LIWC category frequency analysis",
            "evaluation_method_description": "Count and compare proportions of LIWC categories (e.g., negative emotion, first-person singular, spatial words) across deceptive and truthful reviews to identify linguistic cues associated with deception and sentiment.",
            "evaluation_metric": "Category frequency percentages (e.g., % of words in a review that belong to a LIWC category); group-level comparisons (means, SDs)",
            "metric_definition": "Reported as percentages of tokens per review falling into a LIWC category, with group means and standard deviations.",
            "dataset_or_benchmark": "Applied to this paper's negative deceptive dataset and Ott et al. (2011) positive dataset",
            "human_evaluation_details": null,
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Fake negative reviews show higher frequency of negative emotion terms and altered pronoun/spatial term patterns (e.g., first-person singular rates reported with means and SDs).",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "LIWC category differences may reflect exaggeration of sentiment rather than 'leakage' of emotional distress; lexicon-based counts can miss context and nuance.",
            "uuid": "e7984.5",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "GAMLSS Log-normal Sampling",
            "name_full": "Log-normal sampling of truthful review lengths using GAMLSS (Rigby & Stasinopoulos, 2005)",
            "brief_description": "A preprocessing method where truthful reviews are sampled to match the length distribution of deceptive reviews by fitting a left-truncated log-normal distribution to deceptive review lengths using the R GAMLSS package.",
            "citation_title": "Generalized additive models for location, scale and shape,(with discussion)",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "statistics / data preprocessing",
            "theory_type": "sampling / data normalization procedure",
            "evaluation_method_name": "Length-matched sampling via log-normal fit (GAMLSS)",
            "evaluation_method_description": "Fit a left-truncated log-normal distribution to lengths of deceptive reviews and sample truthful reviews according to that distribution to reduce length as a confounding variable between deceptive and truthful sets.",
            "evaluation_metric": "Distributional fit (implicit) and resulting balanced dataset lengths; no explicit numeric fit-quality metrics reported in paper.",
            "metric_definition": "Sampling ensures truthful review length distribution approximates deceptive review length distribution; truncation at 150 characters.",
            "dataset_or_benchmark": "Applied to truthful reviews sourced from Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor, Yelp to create balanced dataset",
            "human_evaluation_details": null,
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Resulting dataset had truthful reviews sampled to match deceptive review lengths (deceptive mean length 178 words compared to positive dataset mean 116 words in Ott et al.).",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Sampling controls for length but may discard real-world variation; assumption that length is the primary confounder may omit other topical differences.",
            "uuid": "e7984.6",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        },
        {
            "name_short": "PlagiarismCheck",
            "name_full": "Plagiarisma.net plagiarism checking",
            "brief_description": "Third-party web service used during data collection to detect and filter plagiarized Mechanical Turk submissions before accepting reviews into the dataset.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "data curation / corpus integrity",
            "theory_type": "data quality check",
            "evaluation_method_name": "Automated plagiarism detection during MTurk submission filtering",
            "evaluation_method_description": "Use plagiarisma.net to determine whether a submitted review is plagiarized and discard such submissions to maintain originality of the deceptive review corpus.",
            "evaluation_metric": null,
            "metric_definition": null,
            "dataset_or_benchmark": "Applied during creation of Negative Deceptive Opinion Spam Dataset",
            "human_evaluation_details": null,
            "automated_falsifiability_check": false,
            "reproducibility_assessment": false,
            "reported_results": "Approximately 2% of MTurk submissions discarded/replaced when workers misread instructions (not specifically for plagiarism count reported).",
            "comparison_to_human_generated": null,
            "comparison_results": null,
            "limitations_noted": "Automated plagiarism tools may miss paraphrased or lightly edited copied text; reliance on a single tool may not catch all cases.",
            "uuid": "e7984.7",
            "source_info": {
                "paper_title": "Negative Deceptive Opinion Spam",
                "publication_date_yy_mm": "2013-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Finding deceptive opinion spam by any stretch of the imagination",
            "rating": 2
        },
        {
            "paper_title": "Opinion spam and analysis",
            "rating": 2
        },
        {
            "paper_title": "The lie detector: Explorations in the automatic recognition of deceptive language",
            "rating": 2
        },
        {
            "paper_title": "The development and psychometric properties of LIWC2007",
            "rating": 2
        },
        {
            "paper_title": "Accuracy of deception judgments",
            "rating": 2
        },
        {
            "paper_title": "On lying and being lied to: A linguistic analysis of deception in computer-mediated communication",
            "rating": 1
        },
        {
            "paper_title": "Generalized additive models for location, scale and shape,(with discussion)",
            "rating": 1
        }
    ],
    "cost": 0.013505,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Negative Deceptive Opinion Spam</h1>
<p>Myle Ott Claire Cardie<br>Department of Computer Science<br>Cornell University<br>Ithaca, NY 14853<br>{myleott, cardie}@cs.cornell.edu jeff.hancock@cornell.edu</p>
<h4>Abstract</h4>
<p>The rising influence of user-generated online reviews (Cone, 2011) has led to growing incentive for businesses to solicit and manufacture DECEPTIVE OPINION SPAM-fictitious reviews that have been deliberately written to sound authentic and deceive the reader. Recently, Ott et al. (2011) have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews. However, the complementary problem of negative deceptive opinion spam, intended to slander competitive offerings, remains largely unstudied. Following an approach similar to Ott et al. (2011), in this work we create and study the first dataset of deceptive opinion spam with negative sentiment reviews. Based on this dataset, we find that standard $n$-gram text categorization techniques can detect negative deceptive opinion spam with performance far surpassing that of human judges. Finally, in conjunction with the aforementioned positive review dataset, we consider the possible interactions between sentiment and deception, and present initial results that encourage further exploration of this relationship.</p>
<h2>1 Introduction</h2>
<p>Consumer's purchase decisions are increasingly influenced by user-generated online reviews of products and services (Cone, 2011). Accordingly, there is a growing incentive for businesses to solicit and manufacture DECEPTIVE OPINION SPAMfictitious reviews that have been deliberately written to sound authentic and deceive the reader (Ott et
al., 2011). For example, Ott et al. (2012) has estimated that between $1 \%$ and $6 \%$ of positive hotel reviews appear to be deceptive, suggesting that some hotels may be posting fake positive reviews in order to hype their own offerings.</p>
<p>In this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review. In particular, reviews intended to promote or hype an offering, and which therefore express a positive sentiment towards the offering, are called positive deceptive opinion spam. In contrast, reviews intended to disparage or slander competitive offerings, and which therefore express a negative sentiment towards the offering, are called negative deceptive opinion spam. While previous related work (Ott et al., 2011; Ott et al., 2012) has explored characteristics of positive deceptive opinion spam, the complementary problem of negative deceptive opinion spam remains largely unstudied.</p>
<p>Following the framework of Ott et al. (2011), we use Amazon's Mechanical Turk service to produce the first publicly available ${ }^{1}$ dataset of negative deceptive opinion spam, containing 400 gold standard deceptive negative reviews of 20 popular Chicago hotels. To validate the credibility of our deceptive reviews, we show that human deception detection performance on the negative reviews is low, in agreement with decades of traditional deception detection research (Bond and DePaulo, 2006). We then show that standard $n$-gram text categorization techniques can be used to detect negative deceptive opinion spam with approximately $86 \%$ accuracy - far</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>surpassing that of the human judges.
In conjunction with Ott et al. (2011)'s positive deceptive opinion spam dataset, we then explore the interaction between sentiment and deception with respect to three types of language features: (1) changes in first-person singular use, often attributed to psychological distancing (Newman et al., 2003), (2) decreased spatial awareness and more narrative form, consistent with theories of reality monitoring (Johnson and Raye, 1981) and imaginative writing (Biber et al., 1999; Rayson et al., 2001), and (3) increased negative emotion terms, often attributed to leakage cues (Ekman and Friesen, 1969), but perhaps better explained in our case as an exaggeration of the underlying review sentiment.</p>
<h2>2 Dataset</h2>
<p>One of the biggest challenges facing studies of deception is obtaining labeled data. Recently, Ott et al. (2011) have proposed an approach for generating positive deceptive opinion spam using Amazon's popular Mechanical Turk crowdsourcing service. In this section we discuss our efforts to extend Ott et al. (2011)'s dataset to additionally include negative deceptive opinion spam.</p>
<h3>2.1 Deceptive Reviews from Mechanical Turk</h3>
<p>Deceptive negative reviews are gathered from Mechanical Turk using the same procedure as Ott et al. (2011). In particular, we create and divide 400 HITs evenly across the 20 most popular hotels in Chicago, such that we obtain 20 reviews for each hotel. We allow workers to complete only a single HIT each, so that each review is written by a unique worker. ${ }^{2}$ We further require workers to be located in the United States and to have an average past approval rating of at least $90 \%$. We allow a maximum of 30 minutes to complete the HIT, and reward accepted submissions with one US dollar (\$1).</p>
<p>Each HIT instructs a worker to imagine that they work for the marketing department of a hotel, and that their manager has asked them to write a fake negative review of a competitor's hotel to be posted online. Accompanying each HIT is the name and</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>URL of the hotel for which the fake negative review is to be written, and instructions that: (1) workers should not complete more than one similar HIT, (2) submissions must be of sufficient quality, i.e., written for the correct hotel, legible, reasonable in length, ${ }^{3}$ and not plagiarized, ${ }^{4}$ and, (3) the HIT is for academic research purposes.</p>
<p>Submissions are manually inspected to ensure that they are written for the correct hotel and to ensure that they convey a generally negative sentiment. ${ }^{5}$ The average accepted review length was 178 words, higher than for the positive reviews gathered by Ott et al. (2011), who report an average review length of 116 words.</p>
<h3>2.2 Truthful Reviews from the Web</h3>
<p>Negative (1- or 2-star) truthful reviews are mined from six popular online review communities: Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor, and Yelp. While reviews mined from these communities cannot be considered gold standard truthful, recent work (Mayzlin et al., 2012; Ott et al., 2012) suggests that deception rates among travel review portals is reasonably small.</p>
<p>Following Ott et al. (2011), we sample a subset of the available truthful reviews so that we retain an equal number of truthful and deceptive reviews (20 each) for each hotel. However, because the truthful reviews are on average longer than our deceptive reviews, we sample the truthful reviews according to a log-normal distribution fit to the lengths of our deceptive reviews, similarly to Ott et al. (2011). ${ }^{6}$</p>
<h2>3 Deception Detection Performance</h2>
<p>In this section we report the deception detection performance of three human judges (Section 3.1) and supervised $n$-gram Support Vector Machine (SVM) classifiers (Section 3.2).</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">TRUTHFUL</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">$\mathbf{P}$</td>
<td style="text-align: center;">$\mathbf{R}$</td>
<td style="text-align: center;">$\mathbf{F}$</td>
<td style="text-align: center;">$\mathbf{P}$</td>
<td style="text-align: center;">$\mathbf{R}$</td>
<td style="text-align: center;">$\mathbf{F}$</td>
</tr>
<tr>
<td style="text-align: left;">HUMAN</td>
<td style="text-align: center;">JUDGE 1</td>
<td style="text-align: center;">$65.0 \%$</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">65.0</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">JUDGE 2</td>
<td style="text-align: center;">$61.9 \%$</td>
<td style="text-align: center;">63.0</td>
<td style="text-align: center;">57.5</td>
<td style="text-align: center;">60.1</td>
<td style="text-align: center;">60.9</td>
<td style="text-align: center;">66.3</td>
<td style="text-align: center;">63.5</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">JUDGE 3</td>
<td style="text-align: center;">$57.5 \%$</td>
<td style="text-align: center;">57.3</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">58.0</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">57.0</td>
</tr>
<tr>
<td style="text-align: left;">META</td>
<td style="text-align: center;">MAJORITY</td>
<td style="text-align: center;">$\mathbf{6 9 . 4 \%}$</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">$\mathbf{6 7 . 5}$</td>
<td style="text-align: center;">$\mathbf{6 8 . 8}$</td>
<td style="text-align: center;">$\mathbf{6 8 . 7}$</td>
<td style="text-align: center;">71.3</td>
<td style="text-align: center;">$\mathbf{6 9 . 9}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">SKEPTIC</td>
<td style="text-align: center;">$58.1 \%$</td>
<td style="text-align: center;">$\mathbf{7 8 . 3}$</td>
<td style="text-align: center;">22.5</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">54.7</td>
<td style="text-align: center;">$\mathbf{9 3 . 8}$</td>
<td style="text-align: center;">69.1</td>
</tr>
</tbody>
</table>
<p>Table 1: Deception detection performance, incl. (P)recision, (R)ecall, and (F)1-score, for three human judges and two meta-judges on a set of 160 negative reviews. The largest value in each column is indicated with boldface.</p>
<h3>3.1 Human Performance</h3>
<p>Recent large-scale meta-analyses have shown human deception detection performance is low, with accuracies often not much better than chance (Bond and DePaulo, 2006). Indeed, Ott et al. (2011) found that two out of three human judges were unable to perform statistically significantly better than chance (at the $p&lt;0.05$ level) at detecting positive deceptive opinion spam. Nevertheless, it is important to subject our reviews to human judgments to validate their convincingness. In particular, if human detection performance is found to be very high, then it would cast doubt on the usefulness of the Mechanical Turk approach for soliciting gold standard deceptive opinion spam.</p>
<p>Following Ott et al. (2011), we asked three volunteer undergraduate university students to read and make assessments on a subset of the negative review dataset described in Section 2. Specifically, we randomized all 40 deceptive and truthful reviews from each of four hotels ( 160 reviews total). We then asked the volunteers to read each review and mark whether they believed it to be truthful or deceptive.</p>
<p>Performance for the three human judges appears in Table 1. We additionally show the deception detection performance of two meta-judges that aggregate the assessments of the individual human judges: (1) the MAJORITY meta-judge predicts deceptive when at least two out of three human judges predict deceptive (and truthful otherwise), and (2) the SKEPTIC meta-judge predicts deceptive when at least one out of three human judges predicts deceptive (and truthful otherwise).</p>
<p>A two-tailed binomial test suggests that JUDGE 1 and JUDGE 2 both perform better than chance ( $p=$ $0.0002,0.003$, respectively), while JUDGE 3 fails to reject the null hypothesis of performing at-chance
( $p=0.07$ ). However, while the best human judge is accurate $65 \%$ of the time, inter-annotator agreement computed using Fleiss' kappa is only slight at 0.07 (Landis and Koch, 1977). Furthermore, based on Cohen's kappa, the highest pairwise interannotator agreement is only 0.26 , between JUDGE 1 and JUDGE 2. These low agreements suggest that while the judges may perform statistically better than chance, they are identifying different reviews as deceptive, i.e., few reviews are consistently identified as deceptive.</p>
<h3>3.2 Automated Classifier Performance</h3>
<p>Standard $n$-gram-based text categorization techniques have been shown to be effective at detecting deception in text (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Ott et al., 2011; Feng et al., 2012). Following Ott et al. (2011), we evaluate the performance of linear Support Vector Machine (SVM) classifiers trained with unigram and bigram term-frequency features on our novel negative deceptive opinion spam dataset. We employ the same 5 -fold stratified cross-validation (CV) procedure as Ott et al. (2011), whereby for each cross-validation iteration we train our model on all reviews for 16 hotels, and test our model on all reviews for the remaining 4 hotels. The SVM cost parameter, $C$, is tuned by nested cross-validation on the training data.</p>
<p>Results appear in Table 2. Each row lists the sentiment of the train and test reviews, where "Cross Val." corresponds to the cross-validation procedure described above, and "Held Out" corresponds to classifiers trained on reviews of one sentiment and tested on the other. The results suggest that $n$-grambased SVM classifiers can detect negative deceptive opinion spam in a balanced dataset with performance far surpassing that of untrained human judges (see Section 3.1). Furthermore, our results show that</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">TRUTHFUL</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">DECEPTIVE</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Train Sentiment</td>
<td style="text-align: center;">Test Sentiment</td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">$\mathbf{P}$</td>
<td style="text-align: center;">$\mathbf{R}$</td>
<td style="text-align: center;">$\mathbf{F}$</td>
<td style="text-align: center;">$\mathbf{P}$</td>
<td style="text-align: center;">$\mathbf{R}$</td>
<td style="text-align: center;">$\mathbf{F}$</td>
</tr>
<tr>
<td style="text-align: center;">POSITIVE <br> (800 reviews)</td>
<td style="text-align: center;">POSITIVE (800 reviews, Cross Val.)</td>
<td style="text-align: center;">$89.3 \%$</td>
<td style="text-align: center;">89.6</td>
<td style="text-align: center;">88.8</td>
<td style="text-align: center;">89.2</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">89.8</td>
<td style="text-align: center;">89.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NEGATIVE (800 reviews, Held Out)</td>
<td style="text-align: center;">$75.1 \%$</td>
<td style="text-align: center;">69.0</td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">78.6</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">70.3</td>
</tr>
<tr>
<td style="text-align: center;">NEGATIVE <br> (800 reviews)</td>
<td style="text-align: center;">POSITIVE (800 reviews, Held Out)</td>
<td style="text-align: center;">$81.4 \%$</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">71.8</td>
<td style="text-align: center;">79.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NEGATIVE (800 reviews, Cross Val.)</td>
<td style="text-align: center;">$86.0 \%$</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">85.5</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">86.5</td>
<td style="text-align: center;">86.1</td>
</tr>
<tr>
<td style="text-align: center;">COMBINED <br> (1600 reviews)</td>
<td style="text-align: center;">POSITIVE (800 reviews, Cross Val.)</td>
<td style="text-align: center;">$88.4 \%$</td>
<td style="text-align: center;">87.7</td>
<td style="text-align: center;">89.3</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">89.1</td>
<td style="text-align: center;">87.5</td>
<td style="text-align: center;">88.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NEGATIVE (800 reviews, Cross Val.)</td>
<td style="text-align: center;">$86.0 \%$</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">85.9</td>
</tr>
</tbody>
</table>
<p>Table 2: Automated classifier performance for different train and test sets, incl. (P)recision, (R)ecall and (F)1-score.
classifiers trained and tested on reviews of different sentiments perform worse, despite having more training data, ${ }^{7}$ than classifiers trained and tested on reviews of the same sentiment. This suggests that cues to deception differ depending on the sentiment of the text (see Section 4).</p>
<p>Interestingly, we find that training on the combined sentiment dataset results in performance that is comparable to that of the "same sentiment" classifiers ( $88.4 \%$ vs. $89.3 \%$ accuracy for positive reviews and $86.0 \%$ vs. $86.0 \%$ accuracy for negative reviews). This is explainable in part by the increased training set size ( 1,280 vs. 640 reviews per 4 training folds).</p>
<h2>4 Interaction of Sentiment and Deception</h2>
<p>An important question is how language features operate in our fake negative reviews compared with the fake positive reviews of Ott et al. (2011). For example, fake positive reviews included less spatial language (e.g., floor, small, location, etc.) because individuals who had not actually experienced the hotel simply had less spatial detail available for their review (Johnson and Raye, 1981). This was also the case for our negative reviews, with less spatial language observed for fake negative reviews relative to truthful. Likewise, our fake negative reviews had more verbs relative to nouns than truthful, suggesting a more narrative style that is indicative of imaginative writing (Biber et al., 1999; Rayson et al., 2001), a pattern also observed by Ott et al. (2011).</p>
<p>There were, however, several important differences in the deceptive language of fake negative relative to fake positive reviews. First, as might be expected, negative emotion terms were more fre-</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>quent, according to LIWC (Pennebaker et al., 2007), in our fake negative reviews than in the fake positive reviews. But, importantly, the fake negative reviewers over-produced negative emotion terms (e.g., terrible, disappointed) relative to the truthful reviews in the same way that fake positive reviewers over-produced positive emotion terms (e.g., elegant, luxurious). Combined, these data suggest that the more frequent negative emotion terms in the present dataset are not the result of "leakage cues" that reveal the emotional distress of lying (Ekman and Friesen, 1969). Instead, the differences suggest that fake hotel reviewers exaggerate the sentiment they are trying to convey relative to similarly-valenced truthful reviews.</p>
<p>Second, the effect of deception on the pattern of pronoun frequency was not the same across positive and negative reviews. In particular, while first person singular pronouns were produced more frequently in fake reviews than truthful, consistent with the case for positive reviews, the increase was diminished in the negative reviews examined here. In the positive reviews reported by Ott et al. (2011), the rate of first person singular in fake reviews $(\mathrm{M}=4.36 \%, \mathrm{SD}=2.96 \%)$ was twice the rate observed in truthful reviews ( $\mathrm{M}=2.18 \%, \mathrm{SD}=2.04 \%$ ). In contrast, the rate of first person singular in the deceptive negative reviews ( $\mathrm{M}=4.47 \%, \mathrm{SD}=2.83 \%$ ) was only $57 \%$ greater than for truthful reviews ( $\mathrm{M}=2.85 \%$, $\mathrm{SD}=2.23 \%$ ). These results suggest that the emphasis on the self, perhaps as a strategy of convincing the reader that the author had actually been to the hotel, is not as evident in the fake negative reviews, perhaps because the negative tone of the reviews caused the reviewers to psychologically distance themselves from their negative statements, a phenomenon observed in several other deception studies, e.g., Hancock et al. (2008).</p>
<h2>5 Conclusion</h2>
<p>We have created the first publicly-available corpus of gold standard negative deceptive opinion spam, containing 400 reviews of 20 Chicago hotels, which we have used to compare the deception detection capabilities of untrained human judges and standard $n$-gram-based Support Vector Machine classifiers. Our results demonstrate that while human deception detection performance is greater for negative rather than positive deceptive opinion spam, the best detection performance is still achieved through automated classifiers, with approximately $86 \%$ accuracy.</p>
<p>We have additionally explored, albeit briefly, the relationship between sentiment and deception by utilizing Ott et al. (2011)'s positive deceptive opinion spam dataset in conjunction with our own. In particular, we have identified several features of language that seem to remain consistent across sentiment, such as decreased awareness of spatial details and exaggerated language. We have also identified other features that vary with the sentiment, such as first person singular use, although further work is required to determine if these differences may be exploited to improve deception detection performance. Indeed, future work may wish to jointly model sentiment and deception in order to better determine the effect each has on language use.</p>
<h2>Acknowledgments</h2>
<p>This work was supported in part by NSF Grant BCS0904822, a DARPA Deft grant, the Jack Kent Cooke Foundation, and by a gift from Google. We also thank the three Cornell undergraduate volunteer judges, as well as the NAACL reviewers for their insightful comments, suggestions and advice on various aspects of this work.</p>
<h2>References</h2>
<p>D. Biber, S. Johansson, G. Leech, S. Conrad, E. Finegan, and R. Quirk. 1999. Longman grammar of spoken and written English, volume 2. MIT Press.
C.F. Bond and B.M. DePaulo. 2006. Accuracy of deception judgments. Personality and Social Psychology Review, 10(3):214.
Cone. 2011. 2011 Online Influence Trend Tracker. Online: http://www.coneinc.com/negative-reviews-online-reverse-purchase-decisions, August.
P. Ekman and W.V. Friesen. 1969. Nonverbal leakage and clues to deception. Psychiatry, 32(1):88.
Song Feng, Ritwik Banerjee, and Yejin Choi. 2012. Syntactic stylometry for deception detection. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 171-175. Association for Computational Linguistics.
J.T. Hancock, L.E. Curry, S. Goorha, and M. Woodworth. 2008. On lying and being lied to: A linguistic analysis of deception in computer-mediated communication. Discourse Processes, 45(1):1-23.
N. Jindal and B. Liu. 2008. Opinion spam and analysis. In Proceedings of the international conference on Web search and web data mining, pages 219-230. ACM.
M.K. Johnson and C.L. Raye. 1981. Reality monitoring. Psychological Review, 88(1):67-85.
J.R. Landis and G.G. Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 33(1):159.
Dina Mayzlin, Yaniv Dover, and Judith A Chevalier. 2012. Promotional reviews: An empirical investigation of online review manipulation. Technical report, National Bureau of Economic Research.
R. Mihalcea and C. Strapparava. 2009. The lie detector: Explorations in the automatic recognition of deceptive language. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 309-312. Association for Computational Linguistics.
M.L. Newman, J.W. Pennebaker, D.S. Berry, and J.M. Richards. 2003. Lying words: Predicting deception from linguistic styles. Personality and Social Psychology Bulletin, 29(5):665.
M. Ott, Y. Choi, C. Cardie, and J.T. Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 309319. Association for Computational Linguistics.</p>
<p>Myle Ott, Claire Cardie, and Jeff Hancock. 2012. Estimating the prevalence of deception in online review communities. In Proceedings of the 21st international conference on World Wide Web, pages 201-210. ACM.
J.W. Pennebaker, C.K. Chung, M. Ireland, A. Gonzales, and R.J. Booth. 2007. The development and psychometric properties of LIWC2007. Austin, TX: LIWC (www.liwc.net).
P. Rayson, A. Wilson, and G. Leech. 2001. Grammatical word class variation within the British National Corpus sampler. Language and Computers, 36(1):295306.
R. A. Rigby and D. M. Stasinopoulos. 2005. Generalized additive models for location, scale and shape,(with discussion). Applied Statistics, 54:507-554.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>7"Cross Val." classifiers are effectively trained on $80 \%$ of the data and tested on the remaining $20 \%$, whereas "Held Out" classifiers are trained and tested on $100 \%$ of each data.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{3}$ We define "reasonable length" to be $\geq 150$ characters.
${ }^{4}$ We use http://plagiarisma.net to determine whether or not a review is plagiarized.
${ }^{5}$ We discarded and replaced approximately $2 \%$ of the submissions, where it was clear that the worker had misread the instructions and instead written a deceptive positive review.
${ }^{6}$ We use the R package GAMLSS (Rigby and Stasinopoulos, 2005) to fit a log-normal distribution (left truncated at 150 characters) to the lengths of the deceptive reviews.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>