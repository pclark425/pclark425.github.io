<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7377 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7377</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7377</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-276259157</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2502.06911v2.pdf" target="_blank">Foundation Models for Anomaly Detection: Vision and Challenges</a></p>
                <p><strong>Paper Abstract:</strong> As data continues to grow in volume and complexity across domains such as finance, manufacturing, and healthcare, effective anomaly detection is essential for identifying irregular patterns that may signal critical issues. Recently, foundation models (FMs) have emerged as a powerful tool for advancing anomaly detection. They have demonstrated unprecedented capabilities in enhancing anomaly identification, generating detailed data descriptions, and providing visual explanations. This survey presents the first comprehensive review of recent advancements in FM-based anomaly detection. We propose a novel taxonomy that classifies FMs into three categories based on their roles in anomaly detection tasks, i.e., as encoders, detectors, or interpreters. We provide a systematic analysis of state-of-the-art methods and discuss key challenges in leveraging FMs for improved anomaly detection. We also outline future research directions in this rapidly evolving field.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7377.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7377.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Tabular (ref. [3])</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMs for non-semantic financial data encoding (reference [3] in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Survey summary of a prior work that uses LLMs to encode non-semantic categorical journal entries from real-world financial records and combines those embeddings with sentence-transformer embeddings and ML classifiers to improve anomaly detection in tabular/financial data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLMs (three LLMs evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language models used as encoders for categorical financial records; exact variants not listed in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Hybrid embedding: LLM-based encoding of categorical/tabular fields combined with sentence-transformer embeddings and downstream ML classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Real-world financial records (journal entries) — described as non-semantic categorical financial data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular / categorical journal entries (financial records).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Evaluated from perspectives of quality, efficiency, and speed (no standard numeric metrics reported in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against traditional encoders and five ML classifiers (no numeric results reported in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey notes LLMs can better handle feature heterogeneity and sparsity in financial audits; no explicit failure numbers given in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Foundation Models for Anomaly Detection: Vision and Challenges', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7377.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7377.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPICED</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SPICED: LLM-based framework for syntactical bug and analog Trojan detection in circuit net lists</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based approach applied to circuit net lists (structured lists of circuit tokens) that uses prompt-learning strategies to detect and localize syntactical bugs and analog Trojans in netlists; listed in the survey as an example of serialization-based detection on list-like data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-capable decoder-only LLM (as reported in the survey table for SPICED).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Serialization-based detection: netlists are serialized into text and LLM prompt-learning is used to identify anomalies and localize issues.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Not provided in survey; described generically as prompt-engineered questions/queries over serialized netlist text (serialization SRL(·) + parsing Parse(·)).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Code / circuit net lists (structured lists of tokens representing electronic circuits).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Prompt-learning (few-shot or engineered prompts) — survey indicates prompt learning strategy is used but does not specify number of shots.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey highlights general LLM failure modes in serialization-based detection (e.g., mismatched indices/values, generating indices beyond batch length, listing every item as abnormal) which are relevant to netlist tasks; no SPICED-specific failures reported in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Foundation Models for Anomaly Detection: Vision and Challenges', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7377.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7377.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogConfigLocalizer (Face it yourselves)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogConfigLocalizer: two-stage LLM-based strategy to localize configuration errors via logs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Survey cites a two-stage approach for log-based anomaly/root-cause localization where key anomalous logs are first identified and then an LLM (reported as GPT-4 in the survey table) is used for verification and to provide additional natural-language explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large instruction-capable decoder-only LLM (as listed in the survey table for the log-localizer work).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Hybrid/verification-based: preliminary anomaly identification in logs followed by LLM-based verification and explanation of root-cause logs.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Log messages from software systems (survey describes application to configuration error localization); no dataset names provided.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured / semi-structured logs (list-like sequences of log entries).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey notes strategies designed to increase reliability of LLM judgments; no quantitative failure modes reported for this work in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Foundation Models for Anomaly Detection: Vision and Challenges', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7377.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7377.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM multi-agent finance framework (ref. [30])</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based multi-agent framework for anomaly detection in financial markets (reference [30])</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Survey references a work proposing an LLM-based multi-agent system to analyze detailed anomaly information in financial markets, intended to serve as an interface between AI analyses and human decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM(s)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multi-agent architecture employing LLMs for analysis and explanation in finance; exact model variants not specified in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Multi-agent analysis and verification using LLM(s) to interpret anomaly signals in financial/market tabular time-series data.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Financial market data (survey does not list benchmark/dataset names).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular / time-series financial market data.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey does not report specific limitations for this referenced work; notes general concerns about bias and reliability when using FMs in high-stakes domains.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Foundation Models for Anomaly Detection: Vision and Challenges', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7377.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7377.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Aodong Li et al. (2024) - tabular LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anomaly detection of tabular data using LLMs (Aodong Li et al., 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced paper in the survey explicitly focused on anomaly detection for tabular data using large language models (listed in the survey's bibliography), but the survey does not summarize experimental details beyond the citation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Anomaly detection of tabular data using llms</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data (explicitly stated in the cited paper title).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Foundation Models for Anomaly Detection: Vision and Challenges', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Anomaly detection of tabular data using llms <em>(Rating: 2)</em></li>
                <li>Advancing anomaly detection: Non-semantic financial data encoding with llms <em>(Rating: 2)</em></li>
                <li>Spiced: Syntactical bug and trojan pattern identification in a/ms circuits using llm-enhanced detection <em>(Rating: 2)</em></li>
                <li>Face it yourselves: An llm-based two-stage strategy to localize configuration errors via logs <em>(Rating: 2)</em></li>
                <li>Enhancing anomaly detection in financial markets with an llm-based multi-agent framework <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7377",
    "paper_id": "paper-276259157",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "LLM-Tabular (ref. [3])",
            "name_full": "LLMs for non-semantic financial data encoding (reference [3] in survey)",
            "brief_description": "Survey summary of a prior work that uses LLMs to encode non-semantic categorical journal entries from real-world financial records and combines those embeddings with sentence-transformer embeddings and ML classifiers to improve anomaly detection in tabular/financial data.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified LLMs (three LLMs evaluated)",
            "model_description": "Transformer-based large language models used as encoders for categorical financial records; exact variants not listed in the survey.",
            "model_size": null,
            "anomaly_detection_approach": "Hybrid embedding: LLM-based encoding of categorical/tabular fields combined with sentence-transformer embeddings and downstream ML classifiers.",
            "prompt_template": null,
            "training_data": "Real-world financial records (journal entries) — described as non-semantic categorical financial data.",
            "data_type": "Tabular / categorical journal entries (financial records).",
            "dataset_name": null,
            "evaluation_metric": "Evaluated from perspectives of quality, efficiency, and speed (no standard numeric metrics reported in survey).",
            "performance": null,
            "baseline_comparison": "Compared against traditional encoders and five ML classifiers (no numeric results reported in survey).",
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": "Survey notes LLMs can better handle feature heterogeneity and sparsity in financial audits; no explicit failure numbers given in survey.",
            "computational_cost": null,
            "uuid": "e7377.0",
            "source_info": {
                "paper_title": "Foundation Models for Anomaly Detection: Vision and Challenges",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "SPICED",
            "name_full": "SPICED: LLM-based framework for syntactical bug and analog Trojan detection in circuit net lists",
            "brief_description": "An LLM-based approach applied to circuit net lists (structured lists of circuit tokens) that uses prompt-learning strategies to detect and localize syntactical bugs and analog Trojans in netlists; listed in the survey as an example of serialization-based detection on list-like data.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-3.5",
            "model_description": "Instruction-capable decoder-only LLM (as reported in the survey table for SPICED).",
            "model_size": null,
            "anomaly_detection_approach": "Serialization-based detection: netlists are serialized into text and LLM prompt-learning is used to identify anomalies and localize issues.",
            "prompt_template": "Not provided in survey; described generically as prompt-engineered questions/queries over serialized netlist text (serialization SRL(·) + parsing Parse(·)).",
            "training_data": null,
            "data_type": "Code / circuit net lists (structured lists of tokens representing electronic circuits).",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "Prompt-learning (few-shot or engineered prompts) — survey indicates prompt learning strategy is used but does not specify number of shots.",
            "limitations_or_failure_cases": "Survey highlights general LLM failure modes in serialization-based detection (e.g., mismatched indices/values, generating indices beyond batch length, listing every item as abnormal) which are relevant to netlist tasks; no SPICED-specific failures reported in survey.",
            "computational_cost": null,
            "uuid": "e7377.1",
            "source_info": {
                "paper_title": "Foundation Models for Anomaly Detection: Vision and Challenges",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "LogConfigLocalizer (Face it yourselves)",
            "name_full": "LogConfigLocalizer: two-stage LLM-based strategy to localize configuration errors via logs",
            "brief_description": "Survey cites a two-stage approach for log-based anomaly/root-cause localization where key anomalous logs are first identified and then an LLM (reported as GPT-4 in the survey table) is used for verification and to provide additional natural-language explanations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_description": "Large instruction-capable decoder-only LLM (as listed in the survey table for the log-localizer work).",
            "model_size": null,
            "anomaly_detection_approach": "Hybrid/verification-based: preliminary anomaly identification in logs followed by LLM-based verification and explanation of root-cause logs.",
            "prompt_template": null,
            "training_data": "Log messages from software systems (survey describes application to configuration error localization); no dataset names provided.",
            "data_type": "Structured / semi-structured logs (list-like sequences of log entries).",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": "Survey notes strategies designed to increase reliability of LLM judgments; no quantitative failure modes reported for this work in the survey.",
            "computational_cost": null,
            "uuid": "e7377.2",
            "source_info": {
                "paper_title": "Foundation Models for Anomaly Detection: Vision and Challenges",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "LLM multi-agent finance framework (ref. [30])",
            "name_full": "LLM-based multi-agent framework for anomaly detection in financial markets (reference [30])",
            "brief_description": "Survey references a work proposing an LLM-based multi-agent system to analyze detailed anomaly information in financial markets, intended to serve as an interface between AI analyses and human decision-making.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM(s)",
            "model_description": "Multi-agent architecture employing LLMs for analysis and explanation in finance; exact model variants not specified in survey.",
            "model_size": null,
            "anomaly_detection_approach": "Multi-agent analysis and verification using LLM(s) to interpret anomaly signals in financial/market tabular time-series data.",
            "prompt_template": null,
            "training_data": "Financial market data (survey does not list benchmark/dataset names).",
            "data_type": "Tabular / time-series financial market data.",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": "Survey does not report specific limitations for this referenced work; notes general concerns about bias and reliability when using FMs in high-stakes domains.",
            "computational_cost": null,
            "uuid": "e7377.3",
            "source_info": {
                "paper_title": "Foundation Models for Anomaly Detection: Vision and Challenges",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "Aodong Li et al. (2024) - tabular LLMs",
            "name_full": "Anomaly detection of tabular data using LLMs (Aodong Li et al., 2024)",
            "brief_description": "Referenced paper in the survey explicitly focused on anomaly detection for tabular data using large language models (listed in the survey's bibliography), but the survey does not summarize experimental details beyond the citation.",
            "citation_title": "Anomaly detection of tabular data using llms",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": null,
            "prompt_template": null,
            "training_data": null,
            "data_type": "Tabular data (explicitly stated in the cited paper title).",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": null,
            "computational_cost": null,
            "uuid": "e7377.4",
            "source_info": {
                "paper_title": "Foundation Models for Anomaly Detection: Vision and Challenges",
                "publication_date_yy_mm": "2025-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Anomaly detection of tabular data using llms",
            "rating": 2,
            "sanitized_title": "anomaly_detection_of_tabular_data_using_llms"
        },
        {
            "paper_title": "Advancing anomaly detection: Non-semantic financial data encoding with llms",
            "rating": 2,
            "sanitized_title": "advancing_anomaly_detection_nonsemantic_financial_data_encoding_with_llms"
        },
        {
            "paper_title": "Spiced: Syntactical bug and trojan pattern identification in a/ms circuits using llm-enhanced detection",
            "rating": 2,
            "sanitized_title": "spiced_syntactical_bug_and_trojan_pattern_identification_in_ams_circuits_using_llmenhanced_detection"
        },
        {
            "paper_title": "Face it yourselves: An llm-based two-stage strategy to localize configuration errors via logs",
            "rating": 2,
            "sanitized_title": "face_it_yourselves_an_llmbased_twostage_strategy_to_localize_configuration_errors_via_logs"
        },
        {
            "paper_title": "Enhancing anomaly detection in financial markets with an llm-based multi-agent framework",
            "rating": 2,
            "sanitized_title": "enhancing_anomaly_detection_in_financial_markets_with_an_llmbased_multiagent_framework"
        }
    ],
    "cost": 0.0118265,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Foundation Models for Anomaly Detection: Vision and Challenges
13 Jun 2025</p>
<p>Jing Ren 
Tao Tang 
Hong Jia 
Ziqi Xu 
Haytham Fayek 
Xiaodong Li 
Suyu Ma 
Xiwei Xu 
Feng Xia 
Foundation Models for Anomaly Detection: Vision and Challenges
13 Jun 2025216F20E53FF22C08BA973F602B6AA72E10.1002/aaai.0001arXiv:2502.06911v2[cs.LG]foundation modelanomaly detectionexplainabilitylarge language model
As data continues to grow in volume and complexity across domains such as finance, manufacturing, and healthcare, effective anomaly detection is essential for identifying irregular patterns that may signal critical issues.Recently, foundation models (FMs) have emerged as a powerful tool for advancing anomaly detection.They have demonstrated unprecedented capabilities in enhancing anomaly identification, generating detailed data descriptions, and providing visual explanations.This survey presents the first comprehensive review of recent advancements in FM-based anomaly detection.We propose a novel taxonomy that classifies FMs into three categories based on their roles in anomaly detection tasks, i.e., as encoders, detectors, or interpreters.We provide a systematic analysis of state-of-the-art methods and discuss key challenges in leveraging FMs for improved anomaly detection.We also outline future research directions in this rapidly evolving field.</p>
<p>Introduction</p>
<p>Anomaly detection, also known as outlier detection, is the process of identifying patterns or events in data that significantly deviate from expected behavior [33].This process is vital across various fields, including, e.g., finance [30], business [11], manufacturing [10], social media [8] and healthcare [28].Traditionally, classical methods like k-nearest neighbors and clustering algorithms have been employed for this purpose.However, recent advancements in machine learning, such as deep learning, one-class classification, self-supervised learning, Jing Ren, Ziqi Xu, Haytham Fayek, Xiaodong Li, and Feng Xia are with the School of Computing Technologies, RMIT University, Melbourne, VIC 3000, Australia (jing.ren@ieee.org;ziqi.xu@rmit.edu.au;haytham.fayek@ieee.org;xiaodong.li@rmit.edu.au;f.xia@ieee.org).Tao Tang is with STEM, the University of South Australia, Adelaide, South Australia 5001, Australia (tao.tang@ieee.org).Hong Jia is with the School of Computing and Information Systems, University of Melbourne, Melbourne, VIC 3010, Australia (hong.jia@unimelb.edu.au).Suyu Ma and Xiwei Xu are with CSIRO's Data61, Australia (suyu.ma@data61.csiro.au,xiwei.xu@data61.csiro.au).and generative adversarial networks, have revolutionized this field.These modern techniques have proved extremely successful in detecting or even predicting anomalies from normal data, making them the primary approaches of anomaly analysis in a wide range of applications [34,22].</p>
<p>Foundation models (FMs) are a class of large-scale, pre-trained machine learning models that are trained on massive, diverse datasets using self-supervised or unsupervised learning [4].In recent years, they have shown impressive performance in learning a wide range of representations and tasks, such as translation, summarization, and question answering, with notable examples including include GPT-4, Gemini and CLIP.Trained on extensive and diverse datasets, FMs comprise a large number of parameters that enable them to capture intricate patterns and subtle nuances within data.This ability to model such complexity makes them particularly well-suited for anomaly detection, where identifying deviations from normal behavior is essential.</p>
<p>FMs offer several advantages for anomaly detection, driven by advancements in computational hardware, model architectures, and access to large-scale training data.A key advantage is their capacity for in-context learning, which enables seamless adaptation to entirely new anomaly detection tasks using only natural language instructions [3].This eliminates the need for extensive task-specific training for real-world applications, enabling a more flexible and efficient approach.Additionally, many modern FMs integrate multiple data modalities [26], such as text, images, and time-series data, which is crucial for detecting anomalies in complex scenarios involving diverse data types.For instance, multimodal models such as Gato [32], can perform tasks ranging from image captioning to robotic control, exemplifying the potential of such models as generalist agents.Furthermore, the application of FMs in anomaly detection can enhance explainability, a critical requirement in high-stakes domains such as healthcare, finance, and cybersecurity, where understanding the rationale behind detected anomalies is critical.</p>
<p>FMs are increasingly being applied to anomaly detection tasks.However, systematic reviews that thoroughly examine and depict this field are still limited.While some works have explored the use of large language models (LLMs) for anomaly detection and have made initial attempts to formalize the research landscape, few provide a comprehensive summary of current progress or address the key challenges in this area.For instance, Su et al. [39] review the application of LLMs in forecasting and anomaly detection but do not provide a taxonomy specifically tailored to show how FMs are applied to anomaly detection tasks.Similarly, Xu et al. [40] focus on anomaly and out-of-distribution detection with LLMs but overlooks other FMs capable of processing diverse data modalities.This highlights the need for a more systematic and inclusive review.In this survey, we focus on methodologies that leverage FMs for anomaly detection to provide a clearer and more structured perspective by categorizing the models based on the roles FMs play in the detection process-specifically as encoders, detectors, or interpreters.This framework offers a comprehensive overview of the field, presents key insights and advancements in the field, and identifies potential directions for future research.</p>
<p>Our main contributions include:</p>
<p>• A novel taxonomy.We propose a structured taxonomy that categorizes the role of FMs in anomaly detection into three primary functions: encoder, detector, and interpreter.This classification provides a clear framework for understanding how FMs contribute to different stages of anomaly detection.• A systematic review.We conduct an extensive review of state-of-the-art methods that leverage FMs for anomaly detection, organizing them according to our proposed taxonomy.This review highlights the latest trends, methodologies, and applications across various domains.• Future directions.We identify key challenges in FM-based anomaly detection, including efficiency, bias, explainability, and multimodality.Furthermore, we outline promising future research directions to address these challenges and advance the field.</p>
<p>Preliminaries</p>
<p>We introduce some basic concepts of FMs and present our proposed taxonomy of anomaly detection using FMs.</p>
<p>Foundation Models</p>
<p>Definition.FMs are a class of large, pre-trained models that serve as the common basis for a wide range of downstream tasks across various domains.First introduced by [4], FMs build on concepts from deep neural networks and self-supervised learning.A prominent subset of FMs, LLMs, are trained on extensive text datasets and are able to perform tasks like language generation, comprehension, and translation.Unlike LLMs, which are limited to written language, FMs have a broader scope, capable of processing diverse data types such as text, images, and audio.They undergo large-scale pre-training on vast datasets and can be fine-tuned with task-specific data, making them highly versatile for numerous applications.</p>
<p>Composition.FMs are usually built on the basis of large data, self-supervised pretraining, and transformer-based architecture [47].Pretraining focuses on training a general model to learn generic representations using large amounts of diverse, unlabelled data.This general model, inspired by transfer learning [29], could then be used to perform different downstream tasks and enhance model performance in other fields through fine-tuning.In the pretraining stage, self-supervised learning [25] is applied across a wide range of domains and areas where unlabeled data is naturally available.As for the model structure, the transformer architecture is the most popular for FMs in different areas, like natural language processing (NLP) and computer vision (CV).These pretrained models may be adapted to specific tasks using a number of methods, such as transfer learning to fine-tune some or all of the parameters of FMs with a much smaller task-specific dataset [44], few-shot learning with only a few samples, or zero-shot learning without any task-specific examples.</p>
<p>Proposed Taxonomy</p>
<p>As shown in Figure 1, the taxonomy of this survey classifies current anomaly detection FMs into three main categories: 1) FM as Encoder, where FMs are incorporated into the process of computing embeddings for high-level representations; 2) FM as Detector, where FMs are directly used as anomaly detectors to identify and localize specific anomalies; 3) FM as Interpreter, where FMs are assisted in providing explanations on the causes of anomalies.Examples of downstream tasks include fake news detection in social networks, driver fatigue detection in autonomous robotic systems, and plant disease detection in agricultural systems, to name a few.</p>
<p>It should be noted that in some works, due to the diversity of FMs, more than one kind of FMs are used, and sometimes they serve diverse roles in different stages of anomaly detection.Therefore, it is inappropriate to categorize them exclusively into one of these three main classes.For example, LogiCode [46] transforms structured request prompts and logical rules into executable Python codes by harnessing the power of the LLM in this regard, which regards the foundation model as a code generator.AnomalyRuler [41] employs two different FMs, a Vision-Language Model (VLM) to generate descriptions for input video frames and a LLM to derive rules for anomaly detection by contrasting the rules for normality.Audit-LLM [38] regards a FM as an assistant by serving as task decomposer, tool builder, and executor in every stage during the whole process of insider threat detection.</p>
<p>Table 1 summarizes the models that leverage FMs to assist anomaly detection tasks according to the proposed taxonomy.In the next three sections, we will systematically examine the state of the art in this field, organizing our review by category.</p>
<p>FM as Encoder</p>
<p>In an anomaly detection model, the encoder module plays a critical role in transforming input data (e.g., text, time series, images, etc.) into a latent feature embeddings.This representation captures essential characteristics of the data samples that can later be analyzed to detect deviations or anomalies.FM as encoder approaches focus on enhancing the quality of data embeddings with the help of powerful FMs.The derived embeddings are directly inputted into downstream classifiers for anomaly detection.Referring to Figure 2, we naturally categorize these approaches into two branches: FM-based and hybrid embedding, depending on whether or not the latent embeddings are only generated by the foundation model.</p>
<p>There is a special case where FM is not the encoder of data samples.We classify this kind of models in this section because the FM indirectly participates in the encoding process.Specifically, AnomalyLLM [21] is a knowledge distillation-based time series anomaly detection model by employing the foundation model as its teacher network.The anomalies are detected based on the discrepancy between the features of the teacher and student networks, where a large representation gap reflects anomalous samples.</p>
<p>FM-based Embedding</p>
<p>With reference to Figure 2(a), FMs are directly utilized as the unique encoder to output embeddings into the classifier for anomaly detection:
Embedding: z i = ϕ F M (x i ),(1)
Anomaly Detection: Ŷ = τ (z i ).</p>
<p>(
)2
In these equations, the text information x i is encoded by a foundation model ϕ F M (•) into z i .The embeddings generated by this kind of approach are directly fed into the classifier τ (•) for classification label Ŷ , typically without the need for any other encoders.Generally, most of these works use a Large Vision-Language Model (LVLM) to generate both textual and visual embeddings for image/video anomaly detection.</p>
<p>In the case of image anomaly detection, there are generally two encoders, one for text embedding to describe the content of images, the other for visual embedding to encode images [31].One representative example is Win-CLIP [14], which proposed language-guided zero-shot anomaly detection by introducing a compositional prompt ensemble.To leverage the normal images available in the few normal shots setting, its few-normal-shot extension   WinCLIP+ is introduced to aggregate complementary information from WinCLIP and visual signals from normal samples.However, the performance of WinCLIP+ is heavily dependent on extensive engineering on hundreds of manually defined prompts.To solve this problem, Anoma-lyCLIP [48] uses an object-agnostic prompt template to model the semantics of general abnormality and normality, thus improving the performance of generalized zero-shot anomaly detection.A similar model, InCTRL [50], also explores the problem of generalist anomaly detection, meaning that a single model can detect anomalies in different data sets from various application scenarios without the need of additional training on the target dataset.The detection strategy is to identify the discrepancies between query images and a set of few-shot normal images from the auxiliary data, where anomalies are expected to have larger discrepancies than normal samples.Moreover, ALFA [49] and MVFA [13] propose to solve generalist anomaly detection in zero/few-shot scenarios as well.Specifically, a run-time prompt adaptation strategy is utilized in ALFA to generate informative anomaly prompts for every image.Then, a fine-grained aligner is developed to learn local semantic space projection, which can be generalized to support pixel-level anomaly localization.As for MVFA, the authors design a multi-level visual feature adaptation architecture for medical image anomaly detection, on the basis of CLIP model.In [37], the authors use relatively small FMs (e.g., 120M parameters) to detect deviations from prior experiences in real time.At the same time, the LLM-based monitor can reason about the safety consequences of anomalous scenarios, thereby determining whether intervention is necessary.</p>
<p>Hybrid Embedding</p>
<p>Approaches using hybrid embeddings focus on utilizing the capability of FMs to capture additional information as shown in Figure 2(b).Taking graph anomaly detection as an example, the embeddings are generated by combining the output of both foundation model ϕ F M (cdot) and graph neural networks (GNNs) ϕ GN N s (cdot):</p>
<p>Embedding:
z i = F (ϕ F M (x i ), ϕ GN N (x i )),(3)
Anomaly Detection:
Ŷ = τ (z i ).(4)
There are multiple fusion strategies F (•) of embeddings, such as concatenation, weighted averaging, or using attention mechanisms to highlight relevant features.This fused representation captures both semantic and relational information, enriching the dataset without the need for large quantities of labeled data.For example, AnomalyLLM [24] was proposed to detect anomaly edges by aligning LLM with dynamic graphs.Instead of directly using LLM as an encoder, the backbone LLM takes the embedding from a GNN encoder as input to generate the final representation vector for anomaly detection.Despite that FMs have the powerful capacity to capture semantic information, [3] uses LLMs to encode non-semantic categorical data (i.e., journal entries) from real-world financial records.Compared with traditional encoders, LLMs could better solve the issues of feature heterogeneity and sparsity in financial audits.In [3], a hybrid model that combines sentence-transformer embeddings with machine learning (ML) classifiers is designed to enhance anomaly detection performance.To compare the performance of different models, three LLMs and five ML classifiers are evaluated from the perspectives of quality, efficiency, and speed, thereby facilitating a comprehensive evaluation.</p>
<p>Discussion.Utilizing FMs as encoder has demonstrated superior performance on anomaly detection, being capable of effectively capturing rich semantic, general-purpose patterns.At the same time, many multimodal FMs (e.g., CLIP or GPT-4) enable joint processing of data from multiple modalities (e.g., text, image, video) into a unified space, enhancing anomaly detection in complex and multimodal datasets.Moreover, FMs are more resilient to imperfect data thanks to its pretraining stage.However, despite some papers claiming strong scalability [45], the resource-intensive characteristic of FMs limits their use in real-time or edge-based anomaly detection applications.Besides, the representations generated by FM directly impact the detection results of models, which may in turn pose transparency and trustworthiness issues in critical applications.</p>
<p>FM as Detector</p>
<p>The core idea behind this category is to utilize FMs as anomaly detectors to detect anomalies for a wide range of tasks, including classifications and localization.However, applying FMs directly as detectors presents unique challenges, primarily</p>
<p>Serialization-based Detection</p>
<p>Most of the existing research attempts to employ the question-answering capability of the FM to directly detect anomalies, which omits the representation learning process of data embeddings.As shown in Figure 3(a), serialization-based detection typically involves two steps: (1) transforming source data into a sequence of text with a serialization function SRL(•), and (2) extracting the detected anomalies from the FM output with a parsing function P arse(•), as illustrated below:</p>
<p>Data Serialization:
X txt = SRL(X ),(5)
Prediction:
Ŷ = P arse(ϕ F M (X txt , p)),(6)
where p denotes the instruction prompt for the specific task.The parsing strategies of models are generally standardized.For example, given that the output of FMs often involves their reasoning and logic processes, several works [7,42,18] utilize specific prompts to extract the predicted label from the output.Another way is to regard anomaly detection as a Q&amp;A problem where FMs are instructed to answer questions in a specific format.For instance, some works [10, 1, 9, 6] limit LLM's output format via guiding instructions in prompts, such as "This is a photo of leather.</p>
<p>Is there any anomaly in the image?".In addition, some methods [12] fine-tune FMs to directly output the label of anomalies, allowing them to provide accurate predictions without additional parsing steps.</p>
<p>Considering that FMs sometimes show failure cases, such as pairing incorrect indices and values, generating indices beyond the batch length, and listing every data item as abnormal, Li et al. [18] simulate a synthetic dataset with ground-truth labels for LLMs to be fine-tuned in a supervised manner.Note that the data are serialized into text before being inputted into the FMs.When detecting anomalies from unstable logs in software systems, one critical challenge is the lack of information about new logs because there is insufficient log data in new software versions.To mitigate the data insufficiency issue, [12] pre-trains LLMs on vast amount of data for robust understanding of diverse patterns and contextual information.Specifically, the authors compare fine-tuned and prompt-engineered FMs to demonstrate which strategy performs better.</p>
<p>SIGLLM [1] is mainly made up of two parts, a PROMPTER to identify parts of a sequence that LLM thinks are anomalous and a DETECTOR to find anomalies using the residual between the original signal and the forecast.Before inputting into the LLM, a time series-to-text conversion module is devised to convert time series data into LLM-ready input.Similarly, to explore whether FMs could be used as a time series anomaly detector, Dong et al. [7] design a prompt learning strategy and synthesize a data set to automatically generate time series anomalies with explanations.With instruction fine-tuning on this dataset, the authors demonstrate that foundation models can yield improved performance in time-series anomaly detection tasks.</p>
<p>Elhafsi et al. [9] introduce a monitoring framework to detect semantic anomalies limited by vision-based policies; the monitor is composed of an LLM to infer what kind of observed objects in a scene may lead to confusion that could result in policy errors.To improve the reasoning ability of LLM, prompt engineering like few-shot prompting and chain-of-thought reasoning are employed in the instantiations of this framework.The same prompt learning strategy is used in SPICED [6], which is an LLM-based framework for the detection and localization of syntactical bugs and analog Trojans in circuit net lists.</p>
<p>Encoding-based Detection</p>
<p>Deep learning (DL) has demonstrated impressive capabilities in understanding different data structures through neural networks, which excel at recognizing patterns in complex and high-dimensional data.As illustrated in Figure 3(b), encoding-based detection leverages the advantages of deep learning to incorporate complex characteristics present in source data, allowing FMs to be characteristic-aware: Representation Learning:
z i = f DL (x i ),(7)
Prediction:
Ŷ = P arse(ϕ F M (z i , p)),(8)
where f DL is the encoder for data representation learning based on deep learning.DL-based prediction also utilizes a parser to retrieve FM output.</p>
<p>To combat the challenge that traditional industrial anomaly detection models can only provide anomaly scores of data samples and the threshold must be manually determined, AnomalyGPT [10] employs an image decoder to provide fine-grained semantics and introduces a prompt learner to fine-tune the LVLM using prompt embeddings.Therefore, it can directly assess the locations of anomalies and provide image information in a human-understandable manner.</p>
<p>LAVAD [42] uses LLMs to detect video anomalies exclusively from a scene description without further training.After generating a textual description for each video frame with a pre-trained VLM, an LLM is applied to capture the dynamics of the scene and summarize captions within a temporal window, which will be further used to provide an anomaly score for each frame.</p>
<p>Discussion.Utilizing FMs directly as detectors shows superiority in processing textual attributes of different types of data, especially achieving remarkable zero/few-shot performance compared with traditional DL models.The ultimate goal is to develop and refine methods for encoding these structured information into a format that FMs can comprehend and manipulate effectively and efficiently.Despite the fact that LLMs have shown their potential in understanding long-context and mathematical reasoning, they cannot be directly applied as an anomaly detector without prompt learning and fine-tuning strategy.Moreover, FMs tend to miss or normalize anomalies, especially some subtle or domain-specific ones, because they are trained Table 1.A summary of models that leverage FMs to assist anomaly detection or prediction tasks in literature.FMs shows the specific open-sourced FMs used in the paper.Acronyms in FM type: LLM (Large Language Model); LVLM (Large Vision-Language Models); MLLM (Multimodal Large Language Model).Fine-tuning denotes whether the parameters of FMs are fine-tuned during the detection process, and ⋆ indicates that models employ parameter-efficient fine-tuning (PEFT).Prompting indicates the use of text-formatted prompts in LLM.Data indicates the anomalous data type detected in the paper.</p>
<p>Model</p>
<p>FMs FM type Fine-tuning Prompting</p>
<p>Others LogiCode [46] GPT-4 LLM Image Industry -AnomalyRuler [41] GPT-4 &amp; Mistral-7B LVLM&amp;LLM Video Real-world surveillance Link Audit-LLM [38] GPT-3.</p>
<p>FM as Interpreter</p>
<p>In the last stage of anomaly detection, the FMs could be used as an interpreter to provide explanations on the detection results.We classify the models into detection-based and verification-based models based on whether FM serves as an anomaly detector as well.</p>
<p>Detection-based Explanation</p>
<p>This classification is based on the primary focus of interpreting anomalous samples, including the reasoning behind anomalies and the additional context they provide.As illustrated in Figures 4(a) and 4(b), these approaches can be grouped into direct and indirect detection, depending on the input structure used with FMs.Correspondingly, the explanation Exp of FMs f F M (•) is paired with a corresponding anomaly-aware question P d to construct an instruction item set I:
Explanation: Exp = f F M (P t , y i , c i )(9)
Instruction Dataset Construction: I i = {"user : " : P d , "F M " : Exp}, (10) where task prompt P t combined with the abnormal label y i and detailed caption c i are inputs to the foundation model f F M (•) to make judgements and provide explanations.</p>
<p>Direct detection.Holmes-VAD [43] is composed of three key components, namely, a Video Encoder for encoding input video, a Temporal Sampler for abnormal frame prediction, and a Multi-modal LLM for generating text explanations.To create a generic model capable of detecting semantic anomalies in business processes, DABL [11] fine-tunes the Llama by incorporating traces into question and answer content.Specifically, every trace item (i.e., business process) and its label are inputs to the foundation model so that the model could be fine-tuned in a supervised way.Then, the fine-tuned model outputs whether the given trace is normal or anomalous, and provides causes of anomalous traces.LLMAD [23] is an LLM-based framework for time series anomaly detection.It improves detection performance and interpretation quality by injecting data background and domain knowledge into model via time-series In-Context Learning and Chain-of-Thought approach guiding its decision-making process.</p>
<p>Indirect detection.In Myriad [19], a vision expert tokenizer embeds the anomaly map into vision expert tokens to make LLM perceive prior knowledge, and a vision expert instructor generates domain vision-language tokens to compensate for the errors of vision experts.VAD-LLaMA [27] is composed of a video encoder and a foundation model, which are connected by a projection layer called adapter.By treating the foundation model as a question-answer system, the foundation model provides detailed information (e.g., the concrete video content and the accurate time frames when anomalies appeared) of anomalies by answering the human queries.</p>
<p>Verification-based Explanation</p>
<p>Verification-based FMs aim to further verify the detection results by providing some textual explanations about the detected anomalies (Figure 4(c)).To ensure the effectiveness of FMs, specific prompts are designed to consistently generate identical output for the same queries.</p>
<p>To further validate the authenticity of detected anomalies, [30] proposes an LLM-based multi-agent framework to analyze the detailed anomaly information, which serves as a critical interface between the AI-driven analysis process and human decision-making.With the aim of assisting end-users in coping with configuration errors in software systems through log analysis, [36] proposes a two-stage strategy to localize the root-cause configuration logs.The first stage is to identify anomalous logs through obtaining key log messages, and the second stage is to use an LLM for further verification with the help of their strong power in natural language understanding and processing.Specifically, strategies are designed to increase the reliability of LLMs' judgments and provide additional information about the configuration errors.</p>
<p>Discussions.It is acknowledged that providing human-understanable explanations for anomaly detection results is useful for high-stake domains like healthcare and finance, where domain experts without AI knowledge can engage with the system.Apart from the explanation results, incorporating external knowledge that are not encoded in the raw data has the potential to reduce false positives through context [46].</p>
<p>Although FMs excel in providing explanations on the anomaly detection results, its interpretability is still limited due to the difficulty of well-crafted prompts.Actually, creating these prompts needs domain specific knowledge from experts [5].Therefore, how to improve the data quality with acceptable labeling costs is still a core challenge to be solved in the future.</p>
<p>Open Challenges and Way Forward</p>
<p>Based on the above review and analysis, we believe that there are still many open challenges and potentials for further advancements in this field.In this section, we list some future research directions for further exploration.</p>
<p>Efficiency</p>
<p>Notwithstanding the stellar progress and accomplishments of FMs, the improvements of performance in these models come at the expense of the model's efficiency.However, anomaly detection models need to be particularly efficient because they are often applied in real-time, high-stakes environments where timely detection and response to anomalies are critical.Common application scenarios include fraud detection and healthcare, where even small delays of identification may lead to significant financial loss or even safety risks.While some lightweight adaptation techniques have been proposed to improve the parameter efficiency, Lester et al. [17] give an example that, as the model size increases, the performance gap between full fine-tuning and lightweight adaptation is diminishing rapidly.Therefore, exploring mechanisms to optimize the trade-off between efficiency and expressivity of FMs still remains a notable challenge.</p>
<p>Bias</p>
<p>In recent years, FMs have led to an extraordinary level of homogenization, which refers to the consolidation of methodologies for building machine learning systems across a wide range of applications [4]: current NLP models are often adapted from one of popular FMs like BERT.Despite that any improvements of FMs can help produce immediate benefits, such kind of extension might also have the potential to inherit or even amplify the problematic biases of these models.A biased anomaly detection model may potentially lead to incorrect or unfair outcomes.For example, a biased model may disproportionately flag specific data points or groups (e.g., gender and racial bias) as anomalous even when they are normal, limiting their capability of detecting genuine anomalies.Such kind of false positives or false negatives can lead to unfair treatment of certain individuals or groups, missed critical alerts, or a lack of trust in the system, ultimately compromising its effectiveness and fairness.Therefore, it is critical to eliminate the intrinsic bias present within FMs, thereby further avoiding extrinsic harms in downstream tasks.</p>
<p>Explainability</p>
<p>Despite that FMs are currently used as interpreters, in many works, to illustrate why anomalies are detected by providing textual explanations in a human-understandable manner, the models themselves are not transparent or interpretable enough to give explanations of the internal model structures and behaviors.However, providing evidence and logical steps for decision-making is a critical issue in anomaly detection especially in applications like healthcare and finance, where understanding the reasoning behind an anomaly is as important as detecting it [15].Therefore, how to improve the interpretability of FMs remains an open research question, and it is absolutely important for researchers to enhance the trustworthiness, usability, and decision-making transparency of anomaly detection.</p>
<p>Multimodality</p>
<p>While multimodality is considered a critical element of intelligence, and serves as a crucial component for the development of both thorough and broad comprehension of the world, models that go beyond simple alignment of vision and language are yet to emerge [31,2].In real-world application scenarios, taking healthcare as an example, medical data are highly multimodal, with various data types, scales, and styles.Multimodal models generally have better performance on anomaly detection by integrating and analyzing data from different sources than models with a single modality.However, current anomaly detection models are mainly developed for single modality (e.g., text, image, and gene), and do not learn from various modalities.By harnessing information across different data types, multimodal data can provide richer and more robust anomaly detection, thereby improving the accuracy of detection results across various applications.Future studies should further examine the design of FMs that integrate various modalities and domains.</p>
<p>Conclusion</p>
<p>The application of FMs to anomaly detection has emerged as a prominent area of research in recent years.In this survey, we provided an in-depth review of the use of FMs in anomaly detection tasks.We introduced a novel taxonomy classifying the methods into three categories based on the roles FMs may play in different stages of anomaly detection, namely encoder, detector, and interpreter.This taxonomy clarifies how FMs can empower the process of data representations, anomaly detection, and explainable analysis of detection results.We also discussed challenges and highlighted several future research directions, aiming to shed light on the way ahead in the field of anomaly detection with FMs.As FMs continue to evolve, their role in anomaly detection is expected to expand, unlocking new possibilities for more accurate, interpretable, and scalable anomaly detection systems.</p>
<p>Figure 1 .
1
Figure 1.An illustration of applying foundation models to the three key stages of anomaly detection, playing roles as encoder, detector, and interpreter.Three cases are illustrated with image, tabular, and time series data, respectively.</p>
<p>(a) FM-based Embedding (b) Hybrid Embedding</p>
<p>Figure 2 .
2
Figure 2. FM as encoder.</p>
<p>Figure 3 .
3
Figure 3. FM as detector</p>
<p>Figure 4 .
4
Figure 4. FM as interpreter</p>
<p>Data Domain CodeFM as Encoder[3]Transformer LLM Tabular Finance -ANOMALYLLM[21]GPT-2 LLM Time series --ALFA[49]GPT LVLM Image Industry -InCTRL[50]OpenCLIP LVLM Image -Link AnomalyCLIP[48]CLIP LVLM Image -Link WinCLIP[14]OpenCLIP LVLM Image --MVFA[13]CLIP LVLM Image Medical Link[37]Many LLM Text Robotics Link AnomalyLLM[24]Transformer LLM Graph -Link[16]ChatGPT LVLM Video Real-world surveillance -FM as Detector LAVAD[42]Llama-2 LVLM&amp;LLM Video Real-world surveillance Link AnomalyGPT[10]Vicuna LLM Image Industry -[18]GPT-4 LLMGPT-4 &amp; LLaMA3 LLM ⋆ Time series --LLMAD[23]GPT-4 LLM Time series --SIGLLM[1]GPT &amp; MISTRAL LLM Time series -Link[12]GPT-3 LLM Log Software system -SPICED[6]GPT-3.5 LLM Signal Electronics -Interpreter Holmes-VAD[43]Llama3-Instruct-70B MLLM ⋆ Video Real-world surveillance Link[30]-LLM Tabular Finance -DABL[11]Llama-2 LLMs ⋆ Text Business Link Myriad[19]GPT-3.5 LVLM Image Industry Link VAD-LLaMA[27]LLaMA LVLM Video Real-world surveillance -LogConfigLocalizer[36]GPT-4 LLM Log Software system Link
Large language models can be zero-shot anomaly detectors for time series?. Sarah Alnegheimish, Linh Nguyen, Laure Berti-Equille, Kalyan Veeramachaneni, arXiv:2405.147552024arXiv preprint</p>
<p>Gpt-lad: Leveraging large multimodal models for logical anomaly detection. Yoojin An, Dongyeon Kang, </p>
<p>ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE2025</p>
<p>Advancing anomaly detection: Non-semantic financial data encoding with llms. Alexander Bakumenko, Kateřina Hlaváčková-Schindler, Claudia Plant, Nina C Hubig, arXiv:2406.036142024arXiv preprint</p>
<p>On the opportunities and risks of foundation models. Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney Von Arx, Jeannette Michael S Bernstein, Antoine Bohg, Emma Bosselut, Brunskill, arXiv:2108.072582021arXiv preprint</p>
<p>Domain-controlled prompt learning. Qinglong Cao, Zhengqin Xu, Yuntian Chen, Chao Ma, Xiaokang Yang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Spiced: Syntactical bug and trojan pattern identification in a/ms circuits using llm-enhanced detection. Jayeeta Chaudhuri, Dhruv Thapar, Arjun Chaudhuri, Farshad Firouzi, Krishnendu Chakrabarty, 2024 IEEE Physical Assurance and Inspection of Electronics (PAINE). IEEE2024</p>
<p>Can llms serve as time series anomaly detectors?. Manqing Dong, Hao Huang, Longbing Cao, arXiv:2408.034752024arXiv preprint</p>
<p>Llm-botguard: A novel framework for detecting llm-driven bots with mixture of experts and graph neural networks. Jinglong Duan, Weihua Li, Quan Bai, Minh Nguyen, Xiaodan Wang, Jianhua Jiang, IEEE Transactions on Computational Social Systems. 2025</p>
<p>Semantic anomaly detection with large language models. Amine Elhafsi, Rohan Sinha, Christopher Agia, Edward Schmerling, Marco Issa Ad Nesnas, Pavone, Autonomous Robots. 4782023</p>
<p>Anomalygpt: Detecting industrial anomalies using large vision-language models. Zhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen, Ming Tang, Jinqiao Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Dabl: Detecting semantic anomalies in business processes using large language models. Wei Guan, Jian Cao, Jianqi Gao, Haiyan Zhao, Shiyou Qian, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Anomaly detection on unstable logs with gpt models. Fatemeh Hadadi, Qinghua Xu, Domenico Bianculli, Lionel Briand, arXiv:2406.074672024arXiv preprint</p>
<p>Adapting visual-language models for generalizable anomaly detection in medical images. Chaoqin Huang, Aofan Jiang, Jinghao Feng, Ya Zhang, Xinchao Wang, Yanfeng Wang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2024</p>
<p>Winclip: Zero-/few-shot anomaly classification and segmentation. Jongheon Jeong, Yang Zou, Taewan Kim, Dongqing Zhang, Avinash Ravichandran, Onkar Dabeer, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023</p>
<p>Logicad: Explainable anomaly detection via vlm-based text feature extraction. Er Jin, Qihui Feng, Yongli Mou, Gerhard Lakemeyer, Stefan Decker, Oliver Simons, Johannes Stegmaier, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Unsupervised video anomaly detection based on similarity with predefined text descriptions. Jaehyun Kim, Seongwook Yoon, Taehyeon Choi, Sanghoon Sull, Sensors. 231462562023</p>
<p>The power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2021</p>
<p>Anomaly detection of tabular data using llms. Aodong Li, Yunhan Zhao, Chen Qiu, Marius Kloft, Padhraic Smyth, Maja Rudolph, Stephan Mandt, arXiv:2406.163082024arXiv preprint</p>
<p>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection. Yuanze Li, Haolin Wang, Shihao Yuan, Ming Liu, Debin Zhao, Yiwen Guo, Chen Xu, Guangming Shi, Wangmeng Zuo, arXiv:2310.190702023arXiv preprint</p>
<p>A survey of graph meets large language model: Progress and future directions. Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, Jeffrey Xu, Yu , International Joint Conference on Artificial Intelligence (IJCAI). 2024</p>
<p>Large language model guided knowledge distillation for time series anomaly detection. Chen Liu, Shibo He, Qihang Zhou, Shizhong Li, Wenchao Meng, Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence. the Thirty-Third International Joint Conference on Artificial Intelligence2024</p>
<p>Deep graph learning for anomalous citation detection. Jiaying Liu, Feng Xia, Xu Feng, Jing Ren, Huan Liu, IEEE Transactions on Neural Networks and Learning Systems. 3362022</p>
<p>Large language models can deliver accurate and interpretable time series anomaly detection. Jun Liu, Chaoyun Zhang, Jiaxu Qian, Minghua Ma, Si Qin, Chetan Bansal, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, arXiv:2405.153702024arXiv preprint</p>
<p>Anomalyllm: Few-shot anomaly edge detection for dynamic graphs using large language models. Shuo Liu, Di Yao, Lanting Fang, Zhetao Li, Wenbin Li, Kaiyu Feng, Xiaowen Ji, Jingping Bi, arXiv:2405.076262024arXiv preprint</p>
<p>Graph self-supervised learning: A survey. Yixin Liu, Ming Jin, Shirui Pan, Chuan Zhou, Yu Zheng, Feng Xia, Philip Yu, IEEE transactions on knowledge and data engineering. 3562022</p>
<p>Unified-io: A unified model for vision, language, and multi-modal tasks. Jiasen Lu, Christopher Clark, Rowan Zellers, Roozbeh Mottaghi, Aniruddha Kembhavi, The Eleventh International Conference on Learning Representations. 2022</p>
<p>Video anomaly detection and explanation via large language models. Hui Lv, Qianru Sun, arXiv:2401.057022024arXiv preprint</p>
<p>Foundation models for generalist medical artificial intelligence. Michael Moor, Oishi Banerjee ; Harlan M Krumholz, Jure Leskovec, Eric J Topol, Pranav Rajpurkar, Zahra Shakeri Hossein Abad. 2023616</p>
<p>A decade survey of transfer learning. Shuteng Niu, Yongxin Liu, Jian Wang, Houbing Song, IEEE Transactions on Artificial Intelligence. 122010-2020. 2020</p>
<p>Enhancing anomaly detection in financial markets with an llm-based multi-agent framework. Taejin Park, arXiv:2403.197352024arXiv preprint</p>
<p>Learning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, International conference on machine learning. PMLR2021</p>
<p>Oriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent. Scott E Reed, Konrad Zolna, Emilio Parisotto, Sergio Gómez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Trans. Mach. Learn. Res. 20222022</p>
<p>Graph learning for anomaly analytics: Algorithms, applications, and challenges. Jing Ren, Feng Xia, Ivan Lee, Azadeh Noori Hoshyar, Charu Aggarwal, ACM Transactions on Intelligent Systems and Technology. 142February 2023</p>
<p>Deep video anomaly detection: Opportunities and challenges. Jing Ren, Feng Xia, Yemeng Liu, Ivan Lee, International Conference on Data Mining Workshops (ICDMW). 2021</p>
<p>Aad-llm: Adaptive anomaly detection using large language models. Alicia Russell-Gilbert, Alexander Sommers, Andrew Thompson, Logan Cummins, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jaboure, Thomas Arnold, Joshua Church, 2024 IEEE International Conference on Big Data (BigData). IEEE2024</p>
<p>Face it yourselves: An llm-based two-stage strategy to localize configuration errors via logs. Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, Zibin Zheng, Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis. the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis2024</p>
<p>Real-time anomaly detection and reactive planning with large language models. Rohan Sinha, Amine Elhafsi, Christopher Agia, Matthew Foutter, Edward Schmerling, Marco Pavone, Proceedings of Robotics: Science and Systems. Robotics: Science and Systems2024</p>
<p>Audit-llm: Multi-agent collaboration for log-based insider threat detection. Chengyu Song, Linru Ma, Jianming Zheng, Jinzhi Liao, Hongyu Kuang, Lin Yang, arXiv:2408.089022024arXiv preprint</p>
<p>Large language models for forecasting and anomaly detection: A systematic literature review. Jing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong Xiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu, Junhong Lin, arXiv:2402.103502024arXiv preprint</p>
<p>Large language models for anomaly and out-of-distribution detection: A survey. Ruiyao Xu, Kaize Ding, arXiv:2409.019802024arXiv preprint</p>
<p>Follow the rules: reasoning for video anomaly detection with large language models. Yuchen Yang, Kwonjoon Lee, Behzad Dariush, Yinzhi Cao, Shao-Yuan Lo, European Conference on Computer Vision. Springer2025</p>
<p>Harnessing large language models for training-free video anomaly detection. Luca Zanella, Willi Menapace, Massimiliano Mancini, Yiming Wang, Elisa Ricci, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2024</p>
<p>Holmes-vad: Towards unbiased and explainable video anomaly detection via multi-modal llm. Huaxin Zhang, Xiaohao Xu, Xiang Wang, Jialong Zuo, Chuchu Han, Xiaonan Huang, Changxin Gao, Yuehuan Wang, Nong Sang, arXiv:2406.122352024arXiv preprint</p>
<p>Transfer adaptation learning: A decade survey. Lei Zhang, Xinbo Gao, IEEE Transactions on Neural Networks and Learning Systems. 2022</p>
<p>Scalalog: Scalable log-based failure diagnosis using llm. Lingzhe Zhang, Tong Jia, Mengxi Jia, Yifan Wu, Hongyi Liu, Ying Li, ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE2025</p>
<p>Logicode: an llm-driven framework for logical anomaly detection. Yiheng Zhang, Yunkang Cao, Xiaohao Xu, Weiming Shen, IEEE Transactions on Automation Science and Engineering. 2024</p>
<p>A comprehensive survey on pretrained foundation models: A history from bert to chatgpt. Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, International Journal of Machine Learning and Cybernetics. 2024</p>
<p>Anomalyclip: Object-agnostic prompt learning for zero-shot anomaly detection. Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, Jiming Chen, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Do llms understand visual anomalies? uncovering llm's capabilities in zero-shot anomaly detection. Jiaqi Zhu, Shaofeng Cai, Fang Deng, Beng , Chin Ooi, Junran Wu, Proceedings of the 32nd ACM International Conference on Multimedia. the 32nd ACM International Conference on Multimedia2024</p>
<p>Toward generalist anomaly detection via in-context residual learning with few-shot sample prompts. Jiawen Zhu, Guansong Pang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2024</p>            </div>
        </div>

    </div>
</body>
</html>