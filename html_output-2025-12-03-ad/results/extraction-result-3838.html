<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3838 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3838</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3838</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-91.html">extraction-schema-91</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-62da76a8dbff4de50495be2f4746f25c4cd7ac0c</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/62da76a8dbff4de50495be2f4746f25c4cd7ac0c" target="_blank">CLIN-X: pre-trained language models and a study on cross-task transfer for concept extraction in the clinical domain</a></p>
                <p><strong>Paper Venue:</strong> Bioinform.</p>
                <p><strong>Paper TL;DR:</strong> The results highlight the importance of specialized language models, such as CLIN-X, for concept extraction in non-standard domains, but also show that the task-agnostic model architecture is robust across the tested tasks and languages so that domain- or task-specific adaptations are not required.</p>
                <p><strong>Paper Abstract:</strong> MOTIVATION
The field of natural language processing (NLP) has recently seen a large change towards using pre-trained language models for solving almost any task. Despite showing great improvements in benchmark datasets for various tasks, these models often perform sub-optimal in non-standard domains like the clinical domain where a large gap between pre-training documents and target documents is observed. In this paper, we aim at closing this gap with domain-specific training of the language model and we investigate its effect on a diverse set of downstream tasks and settings.


RESULTS
We introduce the pre-trained CLIN-X (Clinical XLM-R) language models and show how CLIN-X outperforms other pre-trained transformer models by a large margin for ten clinical concept extraction tasks from two languages. In addition, we demonstrate how the transformer model can be further improved with our proposed task- and language-agnostic model architecture based on ensembles over random splits and cross-sentence context. Our studies in low-resource and transfer settings reveal stable model performance despite a lack of annotated data with improvements of up to 47 F1 points when only 250 labeled sentences are available. Our results highlight the importance of specialized language models, such as CLIN-X, for concept extraction in non-standard domains, but also show that our task-agnostic model architecture is robust across the tested tasks and languages so that domain- or task-specific adaptations are not required.


AVAILABILITY
The CLIN-X language models and source code for fine-tuning and transferring the model are publicly available at https://github.com/boschresearch/clin_x/ and the huggingface model hub.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>SciBERT: A pretrained language model for scientific text. <em>(Rating: 2)</em></li>
                <li>Don't stop pretraining: Adapt language models to domains and tasks. <em>(Rating: 1)</em></li>
                <li>Biobert: a pre-trained biomedical language representation model for biomedical text. <em>(Rating: 1)</em></li>
                <li>Publicly available clinical BERT embeddings. <em>(Rating: 1)</em></li>
                <li>HunFlair: an easy-to-use tool for state-of-the-art biomedical named entity recognition. <em>(Rating: 1)</em></li>
                <li>To share or not to share: Predicting sets of sources for model transfer learning. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3838",
    "paper_id": "paper-62da76a8dbff4de50495be2f4746f25c4cd7ac0c",
    "extraction_schema_id": "extraction-schema-91",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "SciBERT: A pretrained language model for scientific text.",
            "rating": 2
        },
        {
            "paper_title": "Don't stop pretraining: Adapt language models to domains and tasks.",
            "rating": 1
        },
        {
            "paper_title": "Biobert: a pre-trained biomedical language representation model for biomedical text.",
            "rating": 1
        },
        {
            "paper_title": "Publicly available clinical BERT embeddings.",
            "rating": 1
        },
        {
            "paper_title": "HunFlair: an easy-to-use tool for state-of-the-art biomedical named entity recognition.",
            "rating": 1
        },
        {
            "paper_title": "To share or not to share: Predicting sets of sources for model transfer learning.",
            "rating": 1
        }
    ],
    "cost": 0.0055847499999999994,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Data and Text Mining</h1>
<h2>CLIN-X: pre-trained language models and a study on cross-task transfer for concept extraction in the clinical domain</h2>
<p>Lukas Lange ${ }^{1,2, <em>}$, Heike Adel ${ }^{1}$, Jannik Strötgen ${ }^{1}$ and Dietrich Klakow ${ }^{2}$<br>${ }^{1}$ Bosch Center for Artificial Intelligence, Robert Bosch GmbH, Renningen, 71272, Germany and<br>${ }^{2}$ Spoken Language Systems, Saarland University, Saarbrücken, 66111, Germany.<br></em>To whom correspondence should be addressed.</p>
<h4>Abstract</h4>
<p>Motivation: The field of natural language processing (NLP) has recently seen a large change towards using pre-trained language models for solving almost any task. Despite showing great improvements in benchmark datasets for various tasks, these models often perform sub-optimal in non-standard domains like the clinical domain where a large gap between pre-training documents and target documents is observed. In this paper, we aim at closing this gap with domain-specific training of the language model and we investigate its effect on a diverse set of downstream tasks and settings. Results: We introduce the pre-trained CLIN-X (Clinical XLM-R) language models and show how CLIN-X outperforms other pre-trained transformer models by a large margin for ten clinical concept extraction tasks from two languages. In addition, we demonstrate how the transformer model can be further improved with our proposed task- and language-agnostic model architecture based on ensembles over random splits and cross-sentence context. Our studies in low-resource and transfer settings reveal stable model performance despite a lack of annotated data with improvements of up to $47 F_{1}$ points when only 250 labeled sentences are available. Our results highlight the importance of specialized language models as CLIN-X for concept extraction in non-standard domains, but also show that our task-agnostic model architecture is robust across the tested tasks and languages so that domain- or task-specific adaptations are not required. Availability: The CLIN-X language models and source code for fine-tuning and transferring the model are publicly available at https://github.com/boschresearch/clin_x/ and the huggingface model hub. Contact: Lukas.Lange@de.bosch.com</p>
<h2>1 Introduction</h2>
<p>Collecting and understanding key clinical information, such as disorders, symptoms, drugs, etc., from electronic health records (EHRs) has wideranging applications within clinical practice and research (Leaman et al., 2015; Wang et al., 2018). A better understanding of this information can, on the one hand, facilitate novel clinical studies, and, on the other hand, help practitioners to optimize clinical workflows. However, free text is ubiquitous in EHRs. This leads to great difficulties in harvesting knowledge from EHRs. Therefore, natural language processing (NLP) systems, especially information extraction components, play a critical role in extracting and encoding information of interest from clinical narratives, as this information can then be fed into downstream applications. For
example, the extraction of structured information from clinical narratives can help in decision making or drug repurposing (Marimon et al., 2019).</p>
<p>However, information extraction in non-standard domains like the clinical domain is a challenging problem due to the large number of complex terms and unusual document structures (Lee et al., 2020). In addition, pre-trained language models (PLM) such as BERT (Devlin et al., 2019) that demonstrated superior performance for many NLP tasks are typically trained on standard domains, such as web texts, news articles or Wikipedia. Despite showing some robustness across languages and domains (Conneau et al., 2020) these models still achieve their best performance when applied to targets similar to their pre-training corpora which can limit their applicability in many situations (Gururangan et al., 2020). One way to overcome this domain-gap is the adaptation of existing language models to the new target domain or training a new domainspecific model from scratch (Beltagy et al., 2019; Lee et al., 2020). Several</p>
<p>recent works have shown that this kind of adaptation boosts performance for downstream tasks in non-standard domains by, e.g., pre-training with masked language modeling (MLM) objectives on documents from the target domain (Weber et al., 2019; Naserm et al., 2021).</p>
<p>While all the previous methods help to build high-performing model architectures, often there is also a lack of annotated data in the clinical domain which is usually needed for all deep-learning-based models. On the one hand, this domain has high requirements regarding the removal or masking of protected health information (PHI) of individuals (Cramer et al., 2007; Stubbs et al., 2015) which is particularly worthy of protection and can prevent data publication. On the other hand, information extraction tasks are often specific to their target domain and clinical concepts are only found very infrequently outside EHRs which limits reusability of existing resources. Possible solutions for the low-resource problem can be multitask learning (Khan et al., 2020; Mulyar et al., 2021) or transfer Learning (Lee et al., 2018; Peng et al., 2019) across similar corpora from the clinical domain. However, transferring knowledge is particularly challenging in the clinical domain as biomedical NLP models have problems generalizing to new entities (Kim and Kang, 2021). Therefore, one has to carefully select the transfer sources (Lange et al., 2021b).</p>
<p>Over the last years, we have participated in a series of shared tasks on information extraction in the Spanish clinical domain (Marimon et al., 2019; Miranda-Escalada et al., 2020; Lima-López et al., 2021). With our systems, we were able to outperform the other participants and won the competitions twice. The winning systems were task-agnostic and utilized domain-adapted language models and word embeddings (Lange et al., 2019), as well as improved training routines for transformer models (Lange et al., 2021a). Based on our findings and lessons learned during the competitions, we propose in this paper a robust model architecture and training procedure for concept extraction in the clinical domain that is task- and language-agnostic. We introduce a new Spanish clinical language model CLIN-X ${ }<em 1="1">{E: S}$ (Clinical XLM-R) that outperforms existing transformer models on Spanish corpora and exemplifies the benefits of cross-language domain adaptation for English tasks as well. For this, we perform a broad evaluation of ten clinical information extraction tasks from two languages (English and Spanish), including low-resource settings. Finally, we perform cross-task transfer experiments and show that this can boost performance by more than $47 F</em>}$ points for few-shot training. Our results demonstrate great and consistent improvements compared to standard transformer models across all tasks in both languages. We release both, CLIN-X ${ <em E:="E:" N="N">{E: S}$ as well as its English counterpart CLIN-X ${ }</em>$.</p>
<h2>2 Approach</h2>
<p>In this paper, we introduce new pre-trained language models and propose a robust model architecture to perform concept extraction in the clinical domain for English and Spanish. The overall model architecture is shown in Figure 1 and our proposed model components are highlighted. First, the input is computed on subword-level instead of the usual word-level, which eliminates the need for external tokenization. In addition, the input is enriched with its cross-sentence context to capture a wider document context. Second, the input is processed by a transformer model that is adapted to our target domain. Third, the model output is computed using a conditional random field (CRF) output layer to address long annotations. Then, an ensemble over models trained on different training splits is computed that reduces variance and captures the complementary knowledge from all models. Finally, we experiment with cross-task model transfer to further improve the model in few-shot settings.</p>
<p>In summary, the contributions of this paper are as follows:
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: Overview of the concept extraction pipeline based on CLIN-X and our model components for subword-based extraction with cross-sentence context, BIOSE labels, CRFs and model transfer.</p>
<ul>
<li>We study the impact of domain-adaptive pre-training for clinical concept extraction for different embedding types and publish new language models that are adapted to the clinical domain. We show that this PLM outperforms other publicly available embeddings and models in our settings and we also show that cross-language domain adaptations works for English tasks as well.</li>
<li>We perform a broad evaluation of ten clinical sequence labeling tasks across two languages, including low-resource and transfer settings. By this, we demonstrate how our methods can further boost already highperforming transformer models by using advanced training methods and effective changes in the architecture.</li>
<li>Our models outperform the state-of-the-art methods for clinical and biomedical concept extraction, as well as various other transformer models for all ten tasks.</li>
<li>We make our new domain-adapted CLIN-X language models and the source code for fine-tuning the concept extraction models using our methods publicly available.</li>
</ul>
<h2>3 Materials and Methods</h2>
<p>In this section, we start with a brief description of the input representations. Then, we discuss our proposed architectural choices as well as the advanced training methods.</p>
<h3>3.1 Input Representations for the Clinical Domain</h3>
<p>State-of-the-art methods for concept extraction typically rely on word embeddings or language models as input representations. The standard approach is the pre-training of these models on large-scale unannotated datasets once and their reuse as powerful representations for many downstream applications (Collobert et al., 2011). Phan et al. (2019) have shown that contextual information helps in particular in the medical domain, e.g., due to the high number of synonyms. Thus, we focus on the usage of contextualized embeddings in this work, which are most often retrieved from transformer language models nowadays. This is either done with auto-regressive language modeling (Peters et al., 2018) or masked language modeling (Devlin et al., 2019), which we use in this paper.</p>
<p>Domain-specific embeddings. A popular way to approach the challenges of NLP in non-standard domains is the inclusion of domain knowledge via domain-specific embeddings (Friedrich et al., 2020). For this, word embeddings or language models are pre-trained or further specialized on documents of the target domain. These embeddings can be used in</p>
<p>downstream applications. This kind of domain adaptation has shown great benefits in practice (Gururangan et al., 2020), thus, we explore domainand language-adaptive pre-training of transformer models in this paper.</p>
<p>The CLIN-X pre-trained language model. At the time of writing, there is no Spanish clinical transformer publicly available. Thus, we train and publish the CLIN- $X_{E: S}$ language model. The model is based on the multilingual XLM-R transformer, which was trained on 100 languages and showed superior performance in many different tasks across languages and can even outperform monolingual models in certain settings (Conneau et al., 2020). Even though XLM-R was pre-trained on 53GB of Spanish documents, this was only $2 \%$ of the overall training data. To steer this model towards the Spanish clinical domain, we sample documents from the Scielo archive and the MeSpEn resources (Villegas et al., 2018). The resulting corpus has a size of 790 MB and is highly specific for our target setting. We initialize CLIN-X using the pre-trained XLM-R weights and train masked language modeling (MLM) on the clinical corpus for 3 epochs which roughly corresponds to 32 k steps. Nonetheless, this model is still multilingual and we demonstrate the positive impact of cross-language domain adaptation by applying this model to English tasks. ${ }^{1}$</p>
<h3>3.2 Concept Extraction Model</h3>
<p>In the following, we describe the architectural choices we made compared to the standard transformer model for sequence labeling as proposed by Devlin et al. (2019).</p>
<p>Subword-level inputs. Information extraction tasks are typically performed on the token level, while most transformers work on finer subwords instead. Thus, the input representations from transformers for tokens are either retrieved from the first subword or the average (Devlin et al., 2019). In contrasts, we perform concept extraction directly on the subword level. By doing this, there is no need for external tokenization besides the subword segmentation of the transformer. Note that the usage of domainspecific subwords is still often beneficial compared to the general domain segmentation (Beltagy et al., 2019; Lee et al., 2020).</p>
<p>Cross-sentence context. Transformers are suited to incorporate information from a larger context. Luoma and Pyysalo (2020) showed that context information from neighboring sentences has positive effects for named entity recognition on the general domain. Finkel et al. (2004) also showed the positive impact of context for clinical concept extraction. We follow these approaches and add context information to the input similar to Schweter and Akbik (2020). We incorporate the context of 100 subwords to the left and right and use the document boundaries to set the context limits as all corpora are clearly separated in documents.</p>
<p>Conditional Random Field Output. As Kim and Kang (2021) have shown, entity recognition models in the biomedical domain tend to memorize training instances and their labels. This can result in incorrect label encodings as the model fails to generalize. A conditional random field (CRF, Lafferty et al., 2001) can constrain these incorrect sequences as the Viterbi algorithm is used for decoding. In addition, the CRF has advantages when it comes to long entities covering multiple tokens (Lima-López et al., 2021) that appear frequently in the clinical domain.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2: Ensembles over different training splits splits.</p>
<h3>3.3 Training on Data Splits.</h3>
<p>Having a robust model architecture is a good starting point for NLP in the clinical domain. However, even more important might be the actual training procedure of the model. Thus, we discuss standard and random splits, as well as ensemble models over these splits in the following.</p>
<p>Standard splits. Typically, each dataset is divided into training, development and test splits. The training split is used each epoch to train the model parameters and the best training epoch is selected based on the evaluation score on the development set. Finally, the held-out test set is used by the selected model to compute the final score. These data splits are helpful to compare performances of different models on standardized data, however, using the standard training split without modifications may not result in optimal performance (Gorman and Bedrick, 2019).</p>
<p>Further random splits. The training and development parts can be further randomly divided into $n$ separate parts. Then, $n-1$ parts can be used for training and one part as the validation set for early stopping similar to crossfold validation. An ensemble based on models trained on the different data splits should be more powerful than the single models as each of them encodes complementary knowledge which helps to reduce variance and biases (Clark et al., 2019). In our experiments, we use $n=5$ so that we get 5 different settings with unique training sets and we train one model for each setting. Note that we do not change or use the test set at all to ensure comparability to previous results.</p>
<p>Training on all available instances. Recent works sometimes finds that there is no need for a held-out development set and that these labeled instances might be better used during the training. For example, Luoma and Pyysalo (2020) have shown that training on the combined training and development sets boosts performance for named entity recognition remarkably. By this, the model has access to the most data during training and model selection is based on the training loss. However, the training loss is not as meaningful as a stopping criterion and its hard to pick the best model checkpoint. We will compare to this method as an alternative to our split-based experiments.</p>
<h3>3.4 Transfer Learning</h3>
<p>Many NLP tasks suffer from a lack of labeled data. This includes nonstandard domains like the clinical domain in particular. One solution to improve performance in these domains is the usage of resources from a related task in a transfer process. For example, Hofer et al. (2018) have shown that few-shot NER in the biomedical domain can be improved by transferring trained weights from a similar task. We perform a similar kind of model transfer by transferring the transformer to the new target.</p>
<p>However, not all transfer sources are actually useful as many can lead to negative transfer (Lange et al., 2021b). Thus, we first have to predict a suitable transfer source. We follow Lange et al. (2021b) and compute</p>
<p>Table 1. Statistics of the Spanish datasets.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Corpus</th>
<th style="text-align: center;">Size (#Sentences)</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Train</td>
<td style="text-align: center;">Dev</td>
</tr>
<tr>
<td style="text-align: left;">Meddocan (Marimon et al., 2019)</td>
<td style="text-align: center;">15,858</td>
<td style="text-align: center;">8,283</td>
</tr>
<tr>
<td style="text-align: left;">Pharmacomer (Gonzalez-Agirre et al., 2019)</td>
<td style="text-align: center;">8,582</td>
<td style="text-align: center;">4,016</td>
</tr>
<tr>
<td style="text-align: left;">Cantemist (Miranda-Escalada et al., 2020)</td>
<td style="text-align: center;">19,426</td>
<td style="text-align: center;">18,172</td>
</tr>
<tr>
<td style="text-align: left;">Meddoprof (Lima-López et al., 2021)</td>
<td style="text-align: center;">51,350</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Table 2. Statistics of the English datasets.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Corpus</td>
<td style="text-align: center;">Size (#Sentences)</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Train</td>
<td style="text-align: center;">Dev</td>
</tr>
<tr>
<td style="text-align: left;">c2b2 2006 (Uzuner et al., 2007)</td>
<td style="text-align: center;">51,429</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">c2b2 2010 (Uzuner et al., 2011)</td>
<td style="text-align: center;">16,487</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">c2b2 2012 (Sun et al., 2013)</td>
<td style="text-align: center;">7,636</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">c2b2 2014 (Stubbs et al., 2015)</td>
<td style="text-align: center;">52,026</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>similarities between our datasets using their proposed model similarity measure. This has been shown to work well across different tasks and domains. The similarity between two models is computed based on the neural feature representations for the target datasets between two taskspecific trained models. In our experiments, we study the effect of transfer from different sources in comparison to standard single-task training. Further, we will investigate this kind of transfer in low-resource settings, when the target task has only limited training resources.</p>
<p>Ensembles over models. In addition to the other methods, ensembling can be used to combine multiple model predictions into one. This ensemble is usually better than a single model - in particular if the models or their training data differ to some degree. We either create ensembles by majority voting (Clark et al., 2019) of training runs that vary by their random seed (standard splits) or their training data (random splits).</p>
<h2>4 Results</h2>
<p>This section describes the experimental setup starting with tasks, datasets and implementation details, and discusses the results for our experiments.</p>
<h3>4.1 Tasks and Datasets</h3>
<p>Many datasets for natural language processing in specialized domains are published in the context of shared tasks - competitions to evaluate different systems and approaches. Besides English, the clinical domain is well addressed for Spanish, and there exists an active community of researchers for natural language processing of Spanish clinical texts. Thus, in the context of the BerLEF workshop series (Berian Language Evaluation Forum), several shared tasks have been proposed by the Barcelona Supercomputing Center concerning concept extraction in the clinical domain (Marimon et al., 2019; Gonzalez-Agirre et al., 2019; MirandaEscalada et al., 2020; Lima-López et al., 2021). In addition to datasets of these shared tasks for Spanish, we consider four English datasets published during a series of shared tasks of the i2b2 project (Uzuner et al., 2007, 2011; Sun et al., 2013; Stubbs et al., 2015). Information on the dataset sizes are given in Table 1 and 2 for Spanish and English, respectively. Note that the Meddoprof and i2b2 2012 corpora consist of two different extraction tasks each. Thus, we consider both tracks as separated tasks in this work resulting in a total of ten tasks. Following the evaluations in the shared tasks, we use the strict micro $F_{1}$ for all datasets as evaluation metric.</p>
<p>Table 3. Overview of different models averaged for the two languages $\left(F_{1}\right)$. Word embeddings are used in a RNN model similar to Akhik et al. (2018). Transformers are used with a classification layer similar to Devlin et al. (2019).</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Pre-training Domain</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">English</th>
<th style="text-align: center;">Spanish</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">word2vec</td>
<td style="text-align: center;">80.26</td>
<td style="text-align: center;">78.20</td>
</tr>
<tr>
<td style="text-align: left;">General</td>
<td style="text-align: left;">flair</td>
<td style="text-align: center;">85.15</td>
<td style="text-align: center;">80.28</td>
</tr>
<tr>
<td style="text-align: left;">(e.g., Web, News,</td>
<td style="text-align: left;">BERT (En)</td>
<td style="text-align: center;">85.34</td>
<td style="text-align: center;">77.78</td>
</tr>
<tr>
<td style="text-align: left;">Wikipedia, ...)</td>
<td style="text-align: left;">BETO (Es)</td>
<td style="text-align: center;">83.57</td>
<td style="text-align: center;">83.92</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">XLM-R</td>
<td style="text-align: center;">87.13</td>
<td style="text-align: center;">83.87</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">word2vec</td>
<td style="text-align: center;">80.98</td>
<td style="text-align: center;">79.72</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">flair</td>
<td style="text-align: center;">86.43</td>
<td style="text-align: center;">80.72</td>
</tr>
<tr>
<td style="text-align: left;">Clinical</td>
<td style="text-align: left;">ClinicalBERT (En)</td>
<td style="text-align: center;">85.76</td>
<td style="text-align: center;">76.94</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CLIN- $X_{E: 0}$</td>
<td style="text-align: center;">$\mathbf{8 7 . 6 7}$</td>
<td style="text-align: center;">84.57</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CLIN- $X_{E: 0}$</td>
<td style="text-align: center;">87.48</td>
<td style="text-align: center;">$\mathbf{8 5 . 3 7}$</td>
</tr>
</tbody>
</table>
<h3>4.2 Experimental Setup and Implementation Details</h3>
<p>Masked Language Modeling. We use eight NVIDIA V100 (32GB) GPUs for pre-training the CLIN-X models. The training takes less than 1 day with a batch size of 4 per device and a sequence length of up to 512 subwords. The models were trained with the huggingface trainer for MLM.
Sequence Labeling. The sequence labeling models were trained on single NVIDIA V100 GPUs up to 20 hours depending on the dataset size. The models were trained using the flair framework with the AdamW optimizer with an initial learning rate of $2.0 \mathrm{e}-5$ and a batch size of 16 for 20 epochs. The model selection was performed on the development score if trained on standard or random splits or the training loss otherwise.
Transfer and Low-Resource Experiments. The median model according to the development score on the source dataset was taken for transfer and used for the initialization of the target model. Except for the initialization, the training was identical to the single task training. The low-resource settings were created by limiting the data splits to the first $n$ sentences without shuffling. The test set is not changed and remains identical.</p>
<h3>4.3 Evaluation of Embeddings</h3>
<p>The choice of input embeddings has a large impact on downstream performance and may be the most important factor. Table 3 shows the average performance of several different embeddings and transformer models for the two languages. As expected, the monolingual transformers (BERT, BETO) excel at their target language, but cannot compete with multilingual models (mBERT, XLM-R) when applied to an unseen language. The lower part of Table 3 lists domain-specific variants of the embeddings which are generally more powerful in our domain-specific setting. We see that our CLIN-X models perform best for their respective languages. Furthermore, the CLIN- $X_{E: 0}$ performs almost as well as the CLIN- $X_{E: 0}$ model on the English datasets, for which it was not explicitly trained. This shows, that the domain adaptation of multilingual models can also help for texts from other languages of the same domain. Due to CLIN- $X_{E: 0}$ stable performance across all tasks and languages, we will use this model for the following ablations and transfer experiments.</p>
<h3>4.4 Evaluation of Training Methods</h3>
<p>The foundation for all following concept extraction models is the CLIN- $X_{E: 0}$ transformer, as it has shown robust results across all tasks. For comparison to fixed standard splits, we train the models on different random splits. We see in Table 4 that in particular ensembles over random</p>
<p>Table 4. Comparison of training splits with our model architecture and ablation study of the model components averaged for each language $\left(F_{1}\right)$.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">English</th>
<th style="text-align: center;">Spanish</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">87.83</td>
<td style="text-align: center;">86.46</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Median model</td>
<td style="text-align: center;">87.63</td>
<td style="text-align: center;">85.16</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Best model</td>
<td style="text-align: center;">87.85</td>
<td style="text-align: center;">85.99</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ensemble</td>
<td style="text-align: center;">87.95</td>
<td style="text-align: center;">86.06</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Median model</td>
<td style="text-align: center;">87.69</td>
<td style="text-align: center;">86.17</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Best model</td>
<td style="text-align: center;">88.31</td>
<td style="text-align: center;">86.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ensemble</td>
<td style="text-align: center;">88.78</td>
<td style="text-align: center;">88.15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">- BIOSE Labels</td>
<td style="text-align: center;">88.52</td>
<td style="text-align: center;">87.13</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">- CRF</td>
<td style="text-align: center;">88.38</td>
<td style="text-align: center;">85.95</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">- Context</td>
<td style="text-align: center;">87.83</td>
<td style="text-align: center;">86.84</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">- Subword NER</td>
<td style="text-align: center;">87.38</td>
<td style="text-align: center;">86.81</td>
</tr>
</tbody>
</table>
<p>Table 5. Cross-task transfer results for few-shot settings for the English corpora $\left(F_{1}\right)$. The predicted transfer source and the best models are highlighted.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"># training sentences</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Tgt.</td>
<td style="text-align: center;">Src. / Setting</td>
<td style="text-align: center;">250</td>
<td style="text-align: center;">500</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">2500</td>
<td style="text-align: center;">7500</td>
<td style="text-align: center;">All</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">71.24</td>
<td style="text-align: center;">81.06</td>
<td style="text-align: center;">84.15</td>
<td style="text-align: center;">95.49</td>
<td style="text-align: center;">96.89</td>
<td style="text-align: center;">98.34</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2010</td>
<td style="text-align: center;">81.55</td>
<td style="text-align: center;">90.38</td>
<td style="text-align: center;">89.09</td>
<td style="text-align: center;">95.61</td>
<td style="text-align: center;">97.47</td>
<td style="text-align: center;">96.88</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-C</td>
<td style="text-align: center;">79.28</td>
<td style="text-align: center;">86.5</td>
<td style="text-align: center;">88.71</td>
<td style="text-align: center;">96.75</td>
<td style="text-align: center;">97.92</td>
<td style="text-align: center;">98.23</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-T</td>
<td style="text-align: center;">71.58</td>
<td style="text-align: center;">80.31</td>
<td style="text-align: center;">83.29</td>
<td style="text-align: center;">95.87</td>
<td style="text-align: center;">97.97</td>
<td style="text-align: center;">97.41</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2014</td>
<td style="text-align: center;">87.52</td>
<td style="text-align: center;">90.86</td>
<td style="text-align: center;">91.87</td>
<td style="text-align: center;">97.11</td>
<td style="text-align: center;">97.95</td>
<td style="text-align: center;">98.50</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">65.38</td>
<td style="text-align: center;">74.96</td>
<td style="text-align: center;">82.59</td>
<td style="text-align: center;">85.54</td>
<td style="text-align: center;">88.48</td>
<td style="text-align: center;">89.10</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2006</td>
<td style="text-align: center;">68.90</td>
<td style="text-align: center;">78.32</td>
<td style="text-align: center;">82.07</td>
<td style="text-align: center;">85.70</td>
<td style="text-align: center;">87.95</td>
<td style="text-align: center;">88.69</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-C</td>
<td style="text-align: center;">83.99</td>
<td style="text-align: center;">86.25</td>
<td style="text-align: center;">86.88</td>
<td style="text-align: center;">88.46</td>
<td style="text-align: center;">89.34</td>
<td style="text-align: center;">89.74</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-T</td>
<td style="text-align: center;">69.49</td>
<td style="text-align: center;">74.92</td>
<td style="text-align: center;">81.31</td>
<td style="text-align: center;">85.35</td>
<td style="text-align: center;">88.25</td>
<td style="text-align: center;">88.65</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2014</td>
<td style="text-align: center;">72.05</td>
<td style="text-align: center;">79.11</td>
<td style="text-align: center;">82.49</td>
<td style="text-align: center;">85.54</td>
<td style="text-align: center;">87.69</td>
<td style="text-align: center;">88.80</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">69.09</td>
<td style="text-align: center;">73.21</td>
<td style="text-align: center;">75.70</td>
<td style="text-align: center;">78.03</td>
<td style="text-align: center;">80.36</td>
<td style="text-align: center;">80.42</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2006</td>
<td style="text-align: center;">68.83</td>
<td style="text-align: center;">72.14</td>
<td style="text-align: center;">75.34</td>
<td style="text-align: center;">77.86</td>
<td style="text-align: center;">79.25</td>
<td style="text-align: center;">80.15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2010</td>
<td style="text-align: center;">76.39</td>
<td style="text-align: center;">77.98</td>
<td style="text-align: center;">79.44</td>
<td style="text-align: center;">80.90</td>
<td style="text-align: center;">81.65</td>
<td style="text-align: center;">80.93</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-T</td>
<td style="text-align: center;">65.30</td>
<td style="text-align: center;">69.61</td>
<td style="text-align: center;">73.30</td>
<td style="text-align: center;">75.88</td>
<td style="text-align: center;">80.25</td>
<td style="text-align: center;">80.12</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2014</td>
<td style="text-align: center;">68.67</td>
<td style="text-align: center;">72.56</td>
<td style="text-align: center;">75.39</td>
<td style="text-align: center;">77.96</td>
<td style="text-align: center;">79.98</td>
<td style="text-align: center;">79.83</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">67.49</td>
<td style="text-align: center;">72.67</td>
<td style="text-align: center;">75.44</td>
<td style="text-align: center;">78.00</td>
<td style="text-align: center;">78.33</td>
<td style="text-align: center;">78.48</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2006</td>
<td style="text-align: center;">68.57</td>
<td style="text-align: center;">72.49</td>
<td style="text-align: center;">74.34</td>
<td style="text-align: center;">77.73</td>
<td style="text-align: center;">78.43</td>
<td style="text-align: center;">78.34</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2010</td>
<td style="text-align: center;">68.10</td>
<td style="text-align: center;">74.04</td>
<td style="text-align: center;">78.01</td>
<td style="text-align: center;">78.98</td>
<td style="text-align: center;">79.29</td>
<td style="text-align: center;">79.60</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-C</td>
<td style="text-align: center;">70.17</td>
<td style="text-align: center;">75.04</td>
<td style="text-align: center;">76.36</td>
<td style="text-align: center;">78.12</td>
<td style="text-align: center;">78.54</td>
<td style="text-align: center;">80.03</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2014</td>
<td style="text-align: center;">69.44</td>
<td style="text-align: center;">72.66</td>
<td style="text-align: center;">75.04</td>
<td style="text-align: center;">77.88</td>
<td style="text-align: center;">78.86</td>
<td style="text-align: center;">79.36</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">64.96</td>
<td style="text-align: center;">81.61</td>
<td style="text-align: center;">85.74</td>
<td style="text-align: center;">92.70</td>
<td style="text-align: center;">96.08</td>
<td style="text-align: center;">97.62</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2006</td>
<td style="text-align: center;">81.50</td>
<td style="text-align: center;">85.76</td>
<td style="text-align: center;">88.96</td>
<td style="text-align: center;">93.51</td>
<td style="text-align: center;">96.04</td>
<td style="text-align: center;">97.46</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2010</td>
<td style="text-align: center;">71.72</td>
<td style="text-align: center;">83.55</td>
<td style="text-align: center;">87.81</td>
<td style="text-align: center;">93.18</td>
<td style="text-align: center;">96.14</td>
<td style="text-align: center;">97.17</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-C</td>
<td style="text-align: center;">71.24</td>
<td style="text-align: center;">82.97</td>
<td style="text-align: center;">87.09</td>
<td style="text-align: center;">93.15</td>
<td style="text-align: center;">96.13</td>
<td style="text-align: center;">97.33</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">i2b2 2012-T</td>
<td style="text-align: center;">69.12</td>
<td style="text-align: center;">81.25</td>
<td style="text-align: center;">85.08</td>
<td style="text-align: center;">91.35</td>
<td style="text-align: center;">96.02</td>
<td style="text-align: center;">97.00</td>
</tr>
</tbody>
</table>
<p>splits are a lot better than the standard splits and also all training instances. While the median performance is roughly similar for all methods, the random splits offer a lot more variety in training instances and allow for better maximum performance models. Thus, the ensemble based on random splits achieves also much higher numbers.</p>
<p>Table 6. Cross-task transfer results for few-shot settings for the Spanish corpora $\left(F_{1}\right)$. The predicted transfer source and the best models are highlighted.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"># training sentences</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Tgt.</td>
<td style="text-align: center;">Src. / Setting</td>
<td style="text-align: center;">250</td>
<td style="text-align: center;">500</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">2500</td>
<td style="text-align: center;">7500</td>
<td style="text-align: center;">All</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">51.68</td>
<td style="text-align: center;">59.00</td>
<td style="text-align: center;">67.35</td>
<td style="text-align: center;">77.15</td>
<td style="text-align: center;">84.10</td>
<td style="text-align: center;">88.24</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddocan</td>
<td style="text-align: center;">56.48</td>
<td style="text-align: center;">59.51</td>
<td style="text-align: center;">69.33</td>
<td style="text-align: center;">76.57</td>
<td style="text-align: center;">83.43</td>
<td style="text-align: center;">88.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-N</td>
<td style="text-align: center;">52.06</td>
<td style="text-align: center;">59.26</td>
<td style="text-align: center;">67.18</td>
<td style="text-align: center;">77.27</td>
<td style="text-align: center;">83.05</td>
<td style="text-align: center;">87.74</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-C</td>
<td style="text-align: center;">53.94</td>
<td style="text-align: center;">55.41</td>
<td style="text-align: center;">65.71</td>
<td style="text-align: center;">76.65</td>
<td style="text-align: center;">83.20</td>
<td style="text-align: center;">88.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Pharmaconer</td>
<td style="text-align: center;">55.53</td>
<td style="text-align: center;">59.14</td>
<td style="text-align: center;">66.78</td>
<td style="text-align: center;">76.44</td>
<td style="text-align: center;">83.59</td>
<td style="text-align: center;">87.95</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">84.00</td>
<td style="text-align: center;">92.01</td>
<td style="text-align: center;">95.28</td>
<td style="text-align: center;">96.48</td>
<td style="text-align: center;">97.20</td>
<td style="text-align: center;">98.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cantemist</td>
<td style="text-align: center;">83.61</td>
<td style="text-align: center;">89.36</td>
<td style="text-align: center;">95.35</td>
<td style="text-align: center;">96.75</td>
<td style="text-align: center;">97.43</td>
<td style="text-align: center;">97.57</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-N</td>
<td style="text-align: center;">86.99</td>
<td style="text-align: center;">92.77</td>
<td style="text-align: center;">93.55</td>
<td style="text-align: center;">96.15</td>
<td style="text-align: center;">97.01</td>
<td style="text-align: center;">97.66</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-C</td>
<td style="text-align: center;">88.70</td>
<td style="text-align: center;">93.76</td>
<td style="text-align: center;">95.03</td>
<td style="text-align: center;">96.32</td>
<td style="text-align: center;">97.35</td>
<td style="text-align: center;">97.73</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Pharmaconer</td>
<td style="text-align: center;">92.74</td>
<td style="text-align: center;">94.30</td>
<td style="text-align: center;">96.16</td>
<td style="text-align: center;">96.84</td>
<td style="text-align: center;">97.49</td>
<td style="text-align: center;">97.65</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">13.99</td>
<td style="text-align: center;">44.28</td>
<td style="text-align: center;">51.24</td>
<td style="text-align: center;">58.95</td>
<td style="text-align: center;">72.54</td>
<td style="text-align: center;">81.68</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cantemist</td>
<td style="text-align: center;">10.01</td>
<td style="text-align: center;">38.41</td>
<td style="text-align: center;">50.64</td>
<td style="text-align: center;">62.66</td>
<td style="text-align: center;">71.74</td>
<td style="text-align: center;">79.77</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddocan</td>
<td style="text-align: center;">16.39</td>
<td style="text-align: center;">45.30</td>
<td style="text-align: center;">52.89</td>
<td style="text-align: center;">62.25</td>
<td style="text-align: center;">73.30</td>
<td style="text-align: center;">81.38</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-C</td>
<td style="text-align: center;">61.29</td>
<td style="text-align: center;">68.37</td>
<td style="text-align: center;">72.83</td>
<td style="text-align: center;">72.88</td>
<td style="text-align: center;">78.04</td>
<td style="text-align: center;">81.88</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Pharmaconer</td>
<td style="text-align: center;">23.72</td>
<td style="text-align: center;">44.91</td>
<td style="text-align: center;">52.90</td>
<td style="text-align: center;">60.53</td>
<td style="text-align: center;">73.35</td>
<td style="text-align: center;">81.07</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">No Transfer</td>
<td style="text-align: center;">16.46</td>
<td style="text-align: center;">24.28</td>
<td style="text-align: center;">47.67</td>
<td style="text-align: center;">54.66</td>
<td style="text-align: center;">68.68</td>
<td style="text-align: center;">80.54</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cantemist</td>
<td style="text-align: center;">10.99</td>
<td style="text-align: center;">29.73</td>
<td style="text-align: center;">49.20</td>
<td style="text-align: center;">52.75</td>
<td style="text-align: center;">66.57</td>
<td style="text-align: center;">78.76</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddocan</td>
<td style="text-align: center;">31.83</td>
<td style="text-align: center;">38.01</td>
<td style="text-align: center;">53.80</td>
<td style="text-align: center;">56.46</td>
<td style="text-align: center;">69.98</td>
<td style="text-align: center;">79.33</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-N</td>
<td style="text-align: center;">57.46</td>
<td style="text-align: center;">57.70</td>
<td style="text-align: center;">61.56</td>
<td style="text-align: center;">64.92</td>
<td style="text-align: center;">72.37</td>
<td style="text-align: center;">79.38</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Pharmaconer</td>
<td style="text-align: center;">22.61</td>
<td style="text-align: center;">35.15</td>
<td style="text-align: center;">50.50</td>
<td style="text-align: center;">53.49</td>
<td style="text-align: center;">69.59</td>
<td style="text-align: center;">79.08</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Sinlge-Task</td>
<td style="text-align: center;">67.71</td>
<td style="text-align: center;">76.38</td>
<td style="text-align: center;">81.32</td>
<td style="text-align: center;">87.68</td>
<td style="text-align: center;">91.31</td>
<td style="text-align: center;">92.27</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cantemist</td>
<td style="text-align: center;">60.34</td>
<td style="text-align: center;">71.77</td>
<td style="text-align: center;">79.45</td>
<td style="text-align: center;">86.77</td>
<td style="text-align: center;">90.61</td>
<td style="text-align: center;">92.35</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddocan</td>
<td style="text-align: center;">74.48</td>
<td style="text-align: center;">76.02</td>
<td style="text-align: center;">82.79</td>
<td style="text-align: center;">88.39</td>
<td style="text-align: center;">91.49</td>
<td style="text-align: center;">92.27</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-N</td>
<td style="text-align: center;">69.48</td>
<td style="text-align: center;">76.44</td>
<td style="text-align: center;">78.73</td>
<td style="text-align: center;">88.60</td>
<td style="text-align: center;">92.02</td>
<td style="text-align: center;">91.98</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Meddoprof-C</td>
<td style="text-align: center;">69.25</td>
<td style="text-align: center;">74.15</td>
<td style="text-align: center;">80.13</td>
<td style="text-align: center;">88.27</td>
<td style="text-align: center;">91.80</td>
<td style="text-align: center;">92.29</td>
</tr>
</tbody>
</table>
<h3>4.5 Evaluation of Concept Extraction Models</h3>
<p>The lower part of Table 4 lists an ablation study of our individual model components. For example, adding cross-sentence context to the transformers boosts performance across all tasks by 0.5 F1 on average. Performing concept extraction on the subword level helps even further. This is particularly helpful considering that no external tokenization is needed, which can be challenging in the clinical domain (Lange et al., 2020). The CRF helps for both languages, though the differences are larger for Spanish, as the two MEDDOPROF tasks have particularly long annotations ( 2.53 tokens per annotation on average). The same holds for the BIOSE labels, that have the smallest impact of all components, but consistently improve upon the standard BIO labels. As each of our proposed methods improves the transformer even further, we use the combination of all methods in the following as our model architecture.</p>
<h3>4.6 Evaluation of Transfer Learning</h3>
<p>In addition to the training based on random splits, we explore the effects of transfer learning. For this, we simulate low-resource settings where we limit the annotated data of the target dataset between 250 labeled sentences up to 7500 sentences, roughly the size of the smallest corpus. The results are given in Table 5 and Table 6 for English and Spanish, respectively.</p>
<p>Large positive transfer happens in most settings, particularly for the low-resource settings with up to ( $+47.3 F_{2}$ points) for Meddoprof when only 250 labeled sentences are available. The improvements in the full data scenario are below 1 F1. However, there is also negative transfer, in particular using i2b2 2012-T and Cantemist datasets as transfer sources</p>
<p>Table 7. Comparison to baseline systems and state-of-the-art results $\left(F_{1}\right)$. We highlight statistically significant differences between CLIN- $\mathrm{X}_{E N}+$ OurArchitecture with and without transfer following the significant codes of R: ${ }^{<em> * </em>} p$-value $\leq 0.001 ;{ }^{<em> </em>} p$-value $&lt;0.01 ;{ }^{*} p$-value $&lt;0.05 ;{ }^{\dagger}$ highlights our ClinicalBERT results.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>English (i2b2)</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th>Spanish</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>2006</td>
<td>2010</td>
<td>2012-C</td>
<td>2012-T</td>
<td>2014</td>
<td>Cantemist</td>
<td>Meddocan</td>
<td>M.prof-N</td>
<td>M.prof-C</td>
<td>Pharma.</td>
<td></td>
</tr>
<tr>
<td>BERT/BETO (monolingual)</td>
<td>94.80</td>
<td>85.25</td>
<td>76.51</td>
<td>75.28</td>
<td>94.86</td>
<td>81.30</td>
<td>96.81</td>
<td>79.19</td>
<td>74.59</td>
<td>87.70</td>
<td></td>
</tr>
<tr>
<td>BERT (multilingual)</td>
<td>94.79</td>
<td>84.91</td>
<td>76.01</td>
<td>76.56</td>
<td>95.34</td>
<td>80.94</td>
<td>96.30</td>
<td>76.39</td>
<td>71.84</td>
<td>86.98</td>
<td></td>
</tr>
<tr>
<td>XLM-R (multilingual)</td>
<td>96.72</td>
<td>87.54</td>
<td>79.63</td>
<td>75.36</td>
<td>96.39</td>
<td>82.17</td>
<td>96.76</td>
<td>77.44</td>
<td>74.05</td>
<td>88.92</td>
<td></td>
</tr>
<tr>
<td>HunFlair (monolingual)</td>
<td>93.48</td>
<td>86.70</td>
<td>78.52</td>
<td>77.16</td>
<td>95.90</td>
<td>83.80</td>
<td>96.50</td>
<td>75.16</td>
<td>70.01</td>
<td>88.40</td>
<td></td>
</tr>
<tr>
<td>ClinicalBERT</td>
<td>94.8</td>
<td>87.8</td>
<td>78.9</td>
<td>$76.58^{\dagger}$</td>
<td>93.0</td>
<td>$77.18^{\dagger}$</td>
<td>$94.63^{\dagger}$</td>
<td>$65.74^{\dagger}$</td>
<td>$62.85^{\dagger}$</td>
<td>$84.32^{\dagger}$</td>
<td></td>
</tr>
<tr>
<td>NLNDE</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>85.3</td>
<td>96.96</td>
<td>81.8</td>
<td>79.3</td>
<td>88.6</td>
<td></td>
</tr>
<tr>
<td>CLIN- $X_{E N}$</td>
<td>96.25</td>
<td>88.10</td>
<td>79.58</td>
<td>77.70</td>
<td>96.73</td>
<td>82.80</td>
<td>97.08</td>
<td>78.62</td>
<td>75.05</td>
<td>89.33</td>
<td></td>
</tr>
<tr>
<td>CLIN- $X_{E N}$</td>
<td>95.49</td>
<td>87.94</td>
<td>79.58</td>
<td>77.57</td>
<td>96.80</td>
<td>83.22</td>
<td>97.08</td>
<td>79.54</td>
<td>76.95</td>
<td>90.05</td>
<td></td>
</tr>
<tr>
<td>CLIN- $X_{E N}+$ OurArchitecture</td>
<td>98.49</td>
<td>89.23</td>
<td>80.62</td>
<td>78.50</td>
<td>97.60</td>
<td>87.72</td>
<td>97.57</td>
<td>81.36</td>
<td>78.53</td>
<td>92.36</td>
<td></td>
</tr>
<tr>
<td>CLIN- $X_{E N}+$ OurArchitecture</td>
<td>98.30</td>
<td>89.10</td>
<td>80.42</td>
<td>78.48</td>
<td>97.62*</td>
<td>88.24</td>
<td>98.00</td>
<td>81.68</td>
<td>80.54</td>
<td>92.27</td>
<td></td>
</tr>
<tr>
<td>CLIN- $X_{E N}+$ OurArchitecture + Transfer</td>
<td>98.50*</td>
<td>89.74***</td>
<td>80.93**</td>
<td>79.60*</td>
<td>97.46</td>
<td>88.00</td>
<td>97.65</td>
<td>81.88</td>
<td>79.38</td>
<td>92.27</td>
<td></td>
</tr>
</tbody>
</table>
<p>often result in negative transfer. The source selection is also crucial in low-resource scenarios, as not every source is equally beneficial. Using the model similarity measure from Lange et al. (2021b) we are able to predict good transfer sources in all settings; often the best source is selected.</p>
<h3>4.7 Comparison to State-of-the-Art Models</h3>
<p>As our results demonstrate, we have proposed a robust model for the clinical domain that works well across the different tasks in both languages. Finally, we compare CLIN- $X$ to various transformer models as introduced earlier. We also compare to HunFlair (Weber et al., 2021), the current state-of-the-art for concept extraction in the biomedical domain. We use their model architecture based on clinical flair and fastest embeddings and train models accordingly on our datasets. In addition, we compare to our NLNDE submissions for the Spanish shared tasks and the ClinicalBERT by Alsentzer et al. (2019) for the English datasets.</p>
<p>The results for each task are shown in Table 7. The CLIN- $X$ language models in combination with our model architecture outperform the other transformers and HunFlair by a large margin. CLIN- $X$ is able to utilize the domain knowledge obtained from the additional pre-training with further improvements from the assembling over random splits. Even though CLIN- $X$ works best in combination with our model architecture, CLIN- $X$ based on the standard transformer architecture with a single classification layer already outperforms the existing models on 8 out of 10 tasks.</p>
<p>We tested statistical significance between $C L I N-X_{E N}$ with and without transfer learning - highlighted with asterisks in Table 7. We find that all differences for English are significant, while only one difference for Spanish is significant. This might indicate the complementary relationship of domain adaptation and model transfer learning. As CLIN- $X$ was explicitly adapted to Spanish, additional transfer is not necessary in highresource settings. In contrast, the cross-language domain adaptation for English can still be improved with transfer from related sources, where CLIN- $X_{E N}+$ Transfer has also notably higher performances in 3 out of 5 settings compared to $C L I N-X_{E N}$ which is adapted to English.</p>
<h2>5 Conclusion</h2>
<p>In this paper, we described the newly pre-trained CLIN- $X$ language models for the clinical domain. We have shown that CLIN- $X$ sets the new state the of the art results for ten clinical concept extraction tasks in two languages. We demonstrated the positive impact of other model components, such as ensembles over random splits and cross-sentence context and we have studied the effects of cross-task transfer learning from different clinical corpora. Using a model similarity measure, we found good transfer sources for almost all datasets in general and for low-resource scenarios in particular. We are convinced that the new CLIN- $X$ language models will help boosting performance for various Spanish and English clinical information extraction tasks with our or other model architectures.</p>
<h2>References</h2>
<p>Akhik, A. et al. (2018). Contextual string embeddings for sequence labeling. In Proceedings of the 27th International Conference on Computational Linguistics, pages 1638-1649, Santa Fe, New Mexico, USA. ACL.
Alsentzer, E. et al. (2019). Publicly available clinical BERT embeddings. In Proceedings of the 2nd Clinical Natural Language Processing Workshop (Clin-NLP), pages 72-78, Minneapolis, Minnesota, USA. ACL.</p>
<p>Beltagy, I. et al. (2019). SciBERT: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-1JCNLP), pages 3615-3620, Hong Kong, China. ACL.
Clark, C. et al. (2019). Don't take the easy way out: Ensemble based methods for avoiding known dataset biases. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-1JCNLP), pages 4069-4082, Hong Kong, China. ACL.
Collobert, R. et al. (2011). Natural language processing (almost) from scratch. J. Mach. Learn. Res., 12, 2493-2537.
Conneau, A. et al. (2020). Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages 8440-8451, Online. ACL.
Devlin, J. et al. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT), pages 4171-4186, Minneapolis, Minnesota. ACL.
Finkel, J. et al. (2004). Exploiting context for biomedical entity recognition: From syntax to the web. In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications (NLPBA/BioNLP), pages 91-94, Geneva, Switzerland.</p>
<p>International Committee on Computational Linguistics.
Friedrich, A. et al. (2020). The SOFC-exp corpus and neural approaches to information extraction in the materials science domain. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1255-1268, Online. ACL.
Gonzalez-Agirre, A. et al. (2019). PharmaCoNER: Pharmacological substances, compounds and proteins named entity recognition track. In Proceedings of The 5th Workshop on BioNLP Open Shared Tasks (BioNLP-OST), pages 1-10, Hong Kong, China. ACL.
Gorman, K. and Bedrick, S. (2019). We need to talk about standard splits. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL), pages 2786-2791, Florence, Italy. ACL.
Gururangan, S. et al. (2020). Don't stop pretraining: Adapt language models to domains and tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages 83428360, Online. ACL.
Haynes, R. B. et al. (2005). Optimal search strategies for retrieving scientifically strong studies of treatment from medline: analytical survey. Bmj, 330, 1179.
Hofer, M. et al. (2018). Few-shot learning for named entity recognition in medical text. arXiv preprint arXiv:1811.05468.
Khan, M. R. et al. (2020). Mt-bionet: Multi-task learning for biomedical named entity recognition using deep bidirectional transformers. arXiv preprint arXiv:2001.08904.
Kim, H. and Kang, J. (2021). How do your biomedical named entity models generalize to novel entities? arXiv preprint arXiv:2101.00160.
Lafferty, J. D. et al. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML '01, pages 282-289, San Francisco, CA, USA.
Lange, L. et al. (2019). NLNDE: The neither-language-nor-domainexperts' way of spanish medical document de-identification. In Proceedings of The Iberian Languages Evaluation Forum (IberLEF), CEUR Workshop Proceedings.
Lange, L. et al. (2020). NLNDE at CANTEMIST: neural sequence labeling and parsing approaches for clinical concept extraction. In Proceedings of The Iberian Languages Evaluation Forum (IberLEF), CEUR Workshop Proceedings.
Lange, L. et al. (2021a). Boosting transformers for job expression extraction and classification in a low-resource setting. In Proceedings of The Iberian Languages Evaluation Forum (IberLEF), CEUR Workshop Proceedings.
Lange, L. et al. (2021b). To share or not to share: Predicting sets of sources for model transfer learning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8744-8753, Online and Punta Cana, Dominican Republic. ACL.
Leaman, R. et al. (2015). Challenges in clinical natural language processing for automated disorder normalization. J. Biomed. Inform., 57, 28-37.
Lee, J. et al. (2020). Biobert: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics, 36, $1234-1240$.
Lee, J. Y. et al. (2018). Transfer learning for named-entity recognition with neural networks. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC), Miyazaki, Japan. European Language Resources Association.
Lima-López, S. et al. (2021). Nlp applied to occupational health: Meddoprof shared task at iberlef 2021 on automatic recognition,
classification and normalization of professions and occupations from medical texts. In Proceedings of the Iberian Languages Evaluation Forum (IberLEF), CEUR Workshop Proceedings.
Luoma, J. and Pyysalo, S. (2020). Exploring cross-sentence contexts for named entity recognition with BERT. In Proceedings of the 28th International Conference on Computational Linguistics (COLING), pages 904-914, Barcelona, Spain (Online). International Committee on Computational Linguistics.
Marimon, M. et al. (2019). Automatic de-identification of medical texts in spanish: the meldocan track, corpus, guidelines, methods and evaluation of results. In Proceedings of the Iberian Languages Evaluation Forum (IberLEF), CEUR Workshop Proceedings.
Miranda-Esculada, A. et al. (2020). Named entity recognition, concept normalization and clinical coding: Overview of the cantemist track for cancer text mining in spanish, corpus, guidelines, methods and results. In Proceedings of the Iberian Languages Evaluation Forum (IberLEF), CEUR Workshop Proceedings.
Mulyar, A. et al. (2021). Mt-clinical bert: scaling clinical information extraction with multitask learning. J. Am. Med. Inform. Assoc., 28, $2108-2115$.
Naseem, U. et al. (2021). BisaIbert: A simple and effective pre-trained language model for biomedical named entity recognition. In 2021 International Joint Conference on Neural Networks (IJCNN), pages 1-7. IEEE.
Peng, Y. et al. (2019). Transfer learning in biomedical natural language processing: An evaluation of BERT and ELMs on ten benchmarking datasets. In Proceedings of the 18th BioNLP Workshop and Shared Task (BioNLP), pages 58-65, Florence, Italy. ACL.
Peters, M. E. et al. (2018). Deep contextualized word representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 2227-2237, New Orleans, Louisiana. ACL.
Phan, M. C. et al. (2019). Robust representation learning of biomedical names. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL), pages 3275-3285, Florence, Italy. ACL.</p>
<p>Schweter, S. and Akbik, A. (2020). Flert: Document-level features for named entity recognition. arXiv preprint arXiv:2011.06991.
Stubbs, A. et al. (2015). Automated systems for the de-identification of longitudinal clinical narratives: Overview of 2014 i2b2/uthealth shared task track 1. J. Biomed. Inform., 58, 11-19.
Sun, W. et al. (2013). Evaluating temporal relations in clinical text: 2012 i2b2 challenge. J. Am. Med. Inform. Assoc., 20, 806-813.
Uzuner, Ö. et al. (2007). Evaluating the state-of-the-art in automatic de-identification. J. Am. Med. Inform. Assoc., 14, 550-563.
Uzuner, Ö. et al. (2011). 2010 i2b2/va challenge on concepts, assertions, and relations in clinical text. J. Am. Med. Inform. Assoc., 18, 552-556.
Villegas, M. et al. (2018). The mespen resource for english-spanish medical machine translation and terminologies: census of parallel corpora, glossaries and term translations. LREC MultilingualBIO.
Wang, Y. et al. (2018). Clinical information extraction applications: a literature review. J. Biomed. Inform., 77, 34-49.
Weber, L. et al. (2019). HUNER: improving biomedical NER with pretraining. Bioinformatics, 36, 295-302.
Weber, L. et al. (2021). HunFlair: an easy-to-use tool for state-of-the-art biomedical named entity recognition. Bioinformatics, 37, 2792-2794.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ In addition to the Spanish CLIN- $X_{E: S}$ model, we release an English version CLIN- $X_{E: N}$ trained on clinical Pubmed abstracts (850MB) filtered following Haynes et al. (2005) for a direct comparison of our methods in a monolingual setting. This allows researchers and practitioners to address the English clinical domain with an out-of-the-box tailored model so that our transfer methods do not have to be applied. Pubmed is used with the courtesy of the U.S. National Library of Medicine.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>