<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9494 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9494</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9494</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-164.html">extraction-schema-164</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to predict or assign probabilities to specific future real-world scientific discoveries, including how the probabilities are generated, how accuracy is evaluated, and any results, limitations, or comparisons to other methods.</div>
                <p><strong>Paper ID:</strong> paper-5487397061f02b34f66e2228eee303d8985a43c4</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/5487397061f02b34f66e2228eee303d8985a43c4" target="_blank">The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation</a></p>
                <p><strong>Paper Venue:</strong> bioRxiv</p>
                <p><strong>Paper TL;DR:</strong> The Virtual Lab is introduced, an AI-human research collaboration to perform sophisticated, interdisciplinary science research that creates a novel computational nanobody design pipeline that incorporates ESM, AlphaFold-Multimer, and Rosetta and designs 92 new nanobodies.</p>
                <p><strong>Paper Abstract:</strong> Science frequently benefits from teams of interdisciplinary researchers. However, most scientists don’t have access to experts from multiple fields. Fortunately, large language models (LLMs) have recently shown an impressive ability to aid researchers across diverse domains by answering scientific questions. Here, we expand the capabilities of LLMs for science by introducing the Virtual Lab, an AI-human research collaboration to perform sophisticated, interdisciplinary science research. The Virtual Lab consists of an LLM principal investigator agent guiding a team of LLM agents with different scientific backgrounds (e.g., a chemist agent, a computer scientist agent, a critic agent), with a human researcher providing high-level feedback. We design the Virtual Lab to conduct scientific research through a series of team meetings, where all the agents discuss a scientific agenda, and individual meetings, where an agent accomplishes a specific task. We demonstrate the power of the Virtual Lab by applying it to design nanobody binders to recent variants of SARS-CoV-2, which is a challenging, open-ended research problem that requires reasoning across diverse fields from biology to computer science. The Virtual Lab creates a novel computational nanobody design pipeline that incorporates ESM, AlphaFold-Multimer, and Rosetta and designs 92 new nanobodies. Experimental validation of those designs reveals a range of functional nanobodies with promising binding profiles across SARS-CoV-2 variants. In particular, two new nanobodies exhibit improved binding to the recent JN.1 or KP.3 variants of SARS-CoV-2 while maintaining strong binding to the ancestral viral spike protein, suggesting exciting candidates for further investigation. This demonstrates the ability of the Virtual Lab to rapidly make impactful, real-world scientific discovery.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9494.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9494.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to predict or assign probabilities to specific future real-world scientific discoveries, including how the probabilities are generated, how accuracy is evaluated, and any results, limitations, or comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ESM-1b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ESM-1b (Evolutionary Scale Modeling protein language model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large pre-trained protein language model used to assign sequence likelihoods to protein (nanobody) sequences; the paper uses ESM-1b log-likelihood ratios to rank point mutations and drive iterative mutation selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ESM-1b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A transformer-based protein language model trained on large corpora of protein sequences to estimate conditional probabilities of amino acids in sequence contexts; provides per-position probability estimates used to compute likelihoods and log-likelihood ratios for mutant sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prediction_target</strong></td>
                            <td>Relative evolutionary/sequence likelihood (fitness proxy) of single-point and multi-point mutant nanobody sequences compared to an input (wild-type or previous-round) nanobody sequence, used as a proxy for improved nanobody quality and ultimately for increased binding to SARS-CoV-2 RBD variants.</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_method</strong></td>
                            <td>Compute per-position conditional probabilities from the ESM-1b model and form log-likelihood ratios (LLR) comparing the mutant residue probability to the original residue probability; used to rank all possible single point mutations and guide selection of top candidates for downstream structural/energetic evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>probability_format</strong></td>
                            <td>Log-likelihood ratio (LLR) computed from model-assigned conditional probabilities (ratio of probabilities then log-transformed). The paper also computes an alternative LLR relative to the wild-type sequence (ESM LLR^WT) for cross-round comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Proxy/stacked evaluation: (1) structural confidence (AlphaFold-Multimer interface pLDDT, AF ipLDDT), (2) energetic scoring (Rosetta dG-separated binding energy, RS dG), (3) combined weighted score (WS) combining ESM LLR, AF ipLDDT, and RS dG to select candidates, and (4) experimental laboratory validation (expression, solubility, and ELISA binding to multiple RBD variants) of selected mutants.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>All 92 selected mutant nanobodies had positive ESM LLR (ESM preferred the mutant vs the input). Across 92 mutants: 78 (85%) had AF ipLDDT greater than their respective wild-type, 32 (35%) had AF ipLDDT ≥ 80, 60 (65%) had RS dG better (more negative) than wild-type, and 23 (25%) had RS dG ≤ -50. Experimental validation: 92 designs expressed/solubility mostly preserved (only 6 of 92 had very low/no soluble expression); two mutants showed improved binding to recent variants (one Nb21 mutant and one Ty1 mutant showing binding to JN.1 and KP.3-related RBDs). Numerical probabilistic calibration metrics (e.g., Brier score) were not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>ESM is antigen-agnostic (does not condition on target antigen), so LLR optimizes for sequence 'fitness' or plausibility rather than direct antigen binding; only a single ESM model (ESM-1b) was used rather than an ensemble; LLR computations differ from prior work (Hie et al.) which used p(x_i' | x) rather than p(x_i' | x') in the numerator; no formal calibration or probabilistic accuracy assessment for ESM LLR as a predictor of true binding outcomes was provided; some computationally selected mutations led to non-specific binding or problematic biochemical effects (e.g., introduced cysteine causing non-specific reactivity).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Compared methodologically to Hie et al.'s ESM-based antibody design approach: this paper uses p(x_i' | x') in the numerator for LLR and only ESM-1b, whereas Hie et al. used p(x_i' | x) and a consensus of multiple ESM models (ESM-1b and ESM-1v ensemble). Empirical comparison to purely structural or energetic baselines is indirect: ESM LLR is combined with AlphaFold ipLDDT and Rosetta dG rather than used alone. No quantitative comparison to human expert ranking or other predictive-probability baselines (e.g., calibrated classifiers) was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>methods_for_improvement</strong></td>
                            <td>Combine ESM LLR (sequence-likelihood) with structure-confidence (AlphaFold-Multimer ipLDDT) and energetic scoring (Rosetta dG) into a weighted score (WS = 0.2 * ESM LLR + 0.5 * AF ipLDDT - 0.3 * RS dG) to improve selection; iterative multi-round mutation with re-ranking; compute ESM LLR relative to wild-type (ESM LLR^WT) to compare across rounds; use parallel/ensemble LLM meetings and a critic agent to reduce errors in design workflow; rely on experimental validation as ground truth. The paper does not report post-hoc calibration or statistical recalibration techniques for ESM probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9494.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9494.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to predict or assign probabilities to specific future real-world scientific discoveries, including how the probabilities are generated, how accuracy is evaluated, and any results, limitations, or comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o (Virtual Lab agents)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o used to instantiate Virtual Lab LLM agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large natural language model used to power role-specified agents (PI, Immunologist, Machine Learning Specialist, Computational Biologist, Scientific Critic) that design the computational workflow and produce code, but it is not used to output probabilistic forecasts for future scientific discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A high-capacity conversational large language model (LLM) used as the underlying engine to implement multiple domain-specific agents via role-conditioned prompting; agents generate plans, discussion, code (Python & RosettaScripts), and synthesis across meetings. The paper does not provide architecture size or training details beyond the model name.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prediction_target</strong></td>
                            <td>Not used to generate explicit probabilities of future scientific discoveries; instead used to (a) design experimental pipelines, (b) propose candidate mutations and workflows, and (c) write implementation code for ESM/AlphaFold/Rosetta components. Implicitly supports predictions about which designed nanobodies may perform well, but those are not issued as calibrated probability estimates by the model.</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_method</strong></td>
                            <td>Role-conditioned prompting (agent prompts specifying title/expertise/goal/role), multi-round team and individual meetings, parallel meetings with high-temperature sampling for creativity followed by low-temperature merging for consistency. The model outputs natural-language reasoning and concrete designs/code rather than explicit probabilistic forecasts.</td>
                        </tr>
                        <tr>
                            <td><strong>probability_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Designs and outputs from GPT-4o were evaluated indirectly via downstream computational metrics (ESM LLR, AF ipLDDT, RS dG) and ultimately by experimental validation of selected nanobodies (expression, solubility, ELISA binding). No formal measurement of GPT-4o's probabilistic calibration was performed because it did not provide explicit probability forecasts for discovery outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>results</strong></td>
                            <td>GPT-4o powered agents produced the full workflow, wrote Python and XML scripts (ESM scoring, AlphaFold ipLDDT extraction, Rosetta scoring), and drove iterative design that yielded 92 mutant nanobodies for experimental testing. The LLM agents authored ~98.7% of all text/artifacts in the project and substantially reduced human input. Experimental validation found multiple viable designs and two mutants with measurable binding to recent variants. The paper reports these practical results but does not provide numerical accuracy metrics for any GPT-4o probability estimates (none were produced).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>GPT-4o outputs occasionally contained implementation errors that required automated correction rounds; GPT-4o does not natively provide calibrated probabilities about scientific outcomes; reliance on LLM reasoning risks overconfidence or blind spots (explicitly noted by the Scientific Critic agent in meetings); the LLM's domain knowledge is leveraged but must be paired with domain-specific computational models and wet-lab validation to produce reliable real-world discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>No head-to-head comparison of GPT-4o's design decisions against human-only teams or other LLMs was reported. The paper compares workflows produced by the Virtual Lab (LLM agents) qualitatively to prior systems (ChemCrow, Coscientist, AI Scientist) but does not provide quantitative performance comparisons in predicting real-world scientific discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>methods_for_improvement</strong></td>
                            <td>Architectural/process improvements used in the Virtual Lab to improve outputs include: role-conditioned agent prompting, explicit Scientific Critic agent for iterative critique, parallel meeting runs (diverse high-temperature outputs) with a low-temperature merge to synthesize best elements, multi-round refinement with automated code-correction meetings, and combining multiple computational evaluation modalities (ESM, AlphaFold-Multimer, Rosetta) plus experimental feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9494",
    "paper_id": "paper-5487397061f02b34f66e2228eee303d8985a43c4",
    "extraction_schema_id": "extraction-schema-164",
    "extracted_data": [
        {
            "name_short": "ESM-1b",
            "name_full": "ESM-1b (Evolutionary Scale Modeling protein language model)",
            "brief_description": "A large pre-trained protein language model used to assign sequence likelihoods to protein (nanobody) sequences; the paper uses ESM-1b log-likelihood ratios to rank point mutations and drive iterative mutation selection.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ESM-1b",
            "model_description": "A transformer-based protein language model trained on large corpora of protein sequences to estimate conditional probabilities of amino acids in sequence contexts; provides per-position probability estimates used to compute likelihoods and log-likelihood ratios for mutant sequences.",
            "model_size": null,
            "prediction_target": "Relative evolutionary/sequence likelihood (fitness proxy) of single-point and multi-point mutant nanobody sequences compared to an input (wild-type or previous-round) nanobody sequence, used as a proxy for improved nanobody quality and ultimately for increased binding to SARS-CoV-2 RBD variants.",
            "prediction_method": "Compute per-position conditional probabilities from the ESM-1b model and form log-likelihood ratios (LLR) comparing the mutant residue probability to the original residue probability; used to rank all possible single point mutations and guide selection of top candidates for downstream structural/energetic evaluation.",
            "probability_format": "Log-likelihood ratio (LLR) computed from model-assigned conditional probabilities (ratio of probabilities then log-transformed). The paper also computes an alternative LLR relative to the wild-type sequence (ESM LLR^WT) for cross-round comparisons.",
            "evaluation_method": "Proxy/stacked evaluation: (1) structural confidence (AlphaFold-Multimer interface pLDDT, AF ipLDDT), (2) energetic scoring (Rosetta dG-separated binding energy, RS dG), (3) combined weighted score (WS) combining ESM LLR, AF ipLDDT, and RS dG to select candidates, and (4) experimental laboratory validation (expression, solubility, and ELISA binding to multiple RBD variants) of selected mutants.",
            "results": "All 92 selected mutant nanobodies had positive ESM LLR (ESM preferred the mutant vs the input). Across 92 mutants: 78 (85%) had AF ipLDDT greater than their respective wild-type, 32 (35%) had AF ipLDDT ≥ 80, 60 (65%) had RS dG better (more negative) than wild-type, and 23 (25%) had RS dG ≤ -50. Experimental validation: 92 designs expressed/solubility mostly preserved (only 6 of 92 had very low/no soluble expression); two mutants showed improved binding to recent variants (one Nb21 mutant and one Ty1 mutant showing binding to JN.1 and KP.3-related RBDs). Numerical probabilistic calibration metrics (e.g., Brier score) were not reported.",
            "limitations_or_challenges": "ESM is antigen-agnostic (does not condition on target antigen), so LLR optimizes for sequence 'fitness' or plausibility rather than direct antigen binding; only a single ESM model (ESM-1b) was used rather than an ensemble; LLR computations differ from prior work (Hie et al.) which used p(x_i' | x) rather than p(x_i' | x') in the numerator; no formal calibration or probabilistic accuracy assessment for ESM LLR as a predictor of true binding outcomes was provided; some computationally selected mutations led to non-specific binding or problematic biochemical effects (e.g., introduced cysteine causing non-specific reactivity).",
            "comparison_to_baselines": "Compared methodologically to Hie et al.'s ESM-based antibody design approach: this paper uses p(x_i' | x') in the numerator for LLR and only ESM-1b, whereas Hie et al. used p(x_i' | x) and a consensus of multiple ESM models (ESM-1b and ESM-1v ensemble). Empirical comparison to purely structural or energetic baselines is indirect: ESM LLR is combined with AlphaFold ipLDDT and Rosetta dG rather than used alone. No quantitative comparison to human expert ranking or other predictive-probability baselines (e.g., calibrated classifiers) was reported.",
            "methods_for_improvement": "Combine ESM LLR (sequence-likelihood) with structure-confidence (AlphaFold-Multimer ipLDDT) and energetic scoring (Rosetta dG) into a weighted score (WS = 0.2 * ESM LLR + 0.5 * AF ipLDDT - 0.3 * RS dG) to improve selection; iterative multi-round mutation with re-ranking; compute ESM LLR relative to wild-type (ESM LLR^WT) to compare across rounds; use parallel/ensemble LLM meetings and a critic agent to reduce errors in design workflow; rely on experimental validation as ground truth. The paper does not report post-hoc calibration or statistical recalibration techniques for ESM probabilities.",
            "uuid": "e9494.0",
            "source_info": {
                "paper_title": "The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "GPT-4o (Virtual Lab agents)",
            "name_full": "GPT-4o used to instantiate Virtual Lab LLM agents",
            "brief_description": "A large natural language model used to power role-specified agents (PI, Immunologist, Machine Learning Specialist, Computational Biologist, Scientific Critic) that design the computational workflow and produce code, but it is not used to output probabilistic forecasts for future scientific discoveries.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_description": "A high-capacity conversational large language model (LLM) used as the underlying engine to implement multiple domain-specific agents via role-conditioned prompting; agents generate plans, discussion, code (Python & RosettaScripts), and synthesis across meetings. The paper does not provide architecture size or training details beyond the model name.",
            "model_size": null,
            "prediction_target": "Not used to generate explicit probabilities of future scientific discoveries; instead used to (a) design experimental pipelines, (b) propose candidate mutations and workflows, and (c) write implementation code for ESM/AlphaFold/Rosetta components. Implicitly supports predictions about which designed nanobodies may perform well, but those are not issued as calibrated probability estimates by the model.",
            "prediction_method": "Role-conditioned prompting (agent prompts specifying title/expertise/goal/role), multi-round team and individual meetings, parallel meetings with high-temperature sampling for creativity followed by low-temperature merging for consistency. The model outputs natural-language reasoning and concrete designs/code rather than explicit probabilistic forecasts.",
            "probability_format": null,
            "evaluation_method": "Designs and outputs from GPT-4o were evaluated indirectly via downstream computational metrics (ESM LLR, AF ipLDDT, RS dG) and ultimately by experimental validation of selected nanobodies (expression, solubility, ELISA binding). No formal measurement of GPT-4o's probabilistic calibration was performed because it did not provide explicit probability forecasts for discovery outcomes.",
            "results": "GPT-4o powered agents produced the full workflow, wrote Python and XML scripts (ESM scoring, AlphaFold ipLDDT extraction, Rosetta scoring), and drove iterative design that yielded 92 mutant nanobodies for experimental testing. The LLM agents authored ~98.7% of all text/artifacts in the project and substantially reduced human input. Experimental validation found multiple viable designs and two mutants with measurable binding to recent variants. The paper reports these practical results but does not provide numerical accuracy metrics for any GPT-4o probability estimates (none were produced).",
            "limitations_or_challenges": "GPT-4o outputs occasionally contained implementation errors that required automated correction rounds; GPT-4o does not natively provide calibrated probabilities about scientific outcomes; reliance on LLM reasoning risks overconfidence or blind spots (explicitly noted by the Scientific Critic agent in meetings); the LLM's domain knowledge is leveraged but must be paired with domain-specific computational models and wet-lab validation to produce reliable real-world discoveries.",
            "comparison_to_baselines": "No head-to-head comparison of GPT-4o's design decisions against human-only teams or other LLMs was reported. The paper compares workflows produced by the Virtual Lab (LLM agents) qualitatively to prior systems (ChemCrow, Coscientist, AI Scientist) but does not provide quantitative performance comparisons in predicting real-world scientific discoveries.",
            "methods_for_improvement": "Architectural/process improvements used in the Virtual Lab to improve outputs include: role-conditioned agent prompting, explicit Scientific Critic agent for iterative critique, parallel meeting runs (diverse high-temperature outputs) with a low-temperature merge to synthesize best elements, multi-round refinement with automated code-correction meetings, and combining multiple computational evaluation modalities (ESM, AlphaFold-Multimer, Rosetta) plus experimental feedback.",
            "uuid": "e9494.1",
            "source_info": {
                "paper_title": "The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.011181749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation</h1>
<p>Kyle Swanson ${ }^{1}$, Wesley Wu ${ }^{2}$, Nash L. Bulaong ${ }^{2}$, John E. Pak ${ }^{2,4}$, James Zou ${ }^{1,2,3,4}$<br>${ }^{1}$ Department of Computer Science, Stanford University<br>${ }^{2}$ Chan Zuckerberg Biohub - San Francisco<br>${ }^{3}$ Department of Biomedical Data Science, Stanford University<br>${ }^{4}$ Correspondence: jamesz@stanford.edu, john.pak@czbiohub.org</p>
<h4>Abstract</h4>
<p>Science frequently benefits from teams of interdisciplinary researchers. However, most scientists don't have access to experts from multiple fields. Fortunately, large language models (LLMs) have recently shown an impressive ability to aid researchers across diverse domains by answering scientific questions. Here, we expand the capabilities of LLMs for science by introducing the Virtual Lab, an AI-human research collaboration to perform sophisticated, interdisciplinary science research. The Virtual Lab consists of an LLM principal investigator agent guiding a team of LLM agents with different scientific backgrounds (e.g., a chemist agent, a computer scientist agent, a critic agent), with a human researcher providing high-level feedback. We design the Virtual Lab to conduct scientific research through a series of team meetings, where all the agents discuss a scientific agenda, and individual meetings, where an agent accomplishes a specific task. We demonstrate the power of the Virtual Lab by applying it to design nanobody binders to recent variants of SARS-CoV-2, which is a challenging, open-ended research problem that requires reasoning across diverse fields from biology to computer science. The Virtual Lab creates a novel computational nanobody design pipeline that incorporates ESM, AlphaFold-Multimer, and Rosetta and designs 92 new nanobodies. Experimental validation of those designs reveals a range of functional nanobodies with promising binding profiles across SARS-CoV-2 variants. In particular, two new nanobodies exhibit improved binding to the recent JN. 1 or KP. 3 variants of SARS-CoV-2 while maintaining strong binding to the ancestral viral spike protein, suggesting exciting candidates for further investigation. This demonstrates the ability of the Virtual Lab to rapidly make impactful, real-world scientific discovery.</p>
<h2>Introduction</h2>
<p>Interdisciplinary science research is complex, requiring increasingly large teams of researchers with expertise in diverse fields of science ${ }^{1-3}$. For example, the paper by Jumper et al. ${ }^{4}$ that introduced AlphaFold 2 and later led to the 2024 Nobel Prize in Chemistry included 34 researchers with expertise across computer science, machine learning, bioinformatics, and structural biology. Building and coordinating large teams of researchers who speak different scientific languages and have different scientific priorities is challenging ${ }^{5,6}$. Furthermore, it can</p>
<p>be harder for under-resourced groups without connections to many experts across fields to engage in complex, interdisciplinary science, especially when dedicated interdisciplinary research funding is lacking ${ }^{7}$.</p>
<p>One source of broad scientific knowledge and insights that researchers are now turning to is large language models (LLMs), such as ChatGPT ${ }^{8}$ and Claude ${ }^{9}$. These LLMs have been trained on vast quantities of text data, including scientific literature, and they are therefore able to aid researchers in several ways such as by answering science questions, summarizing scientific papers, and writing scientific code ${ }^{10}$. Several studies have explored the scientific capabilities of LLMs by measuring their ability to answer scientific questions, and LLMs have shown high accuracy and can even match or outperform human scientists at these tasks ${ }^{11-16}$.</p>
<p>However, answering individual science questions is very different from engaging in sophisticated research that involves multi-step reasoning across disparate scientific fields with many unknowns. While some prior work has explored the application of LLMs to research, these studies have often focused on a single scientific domain and have explored a relatively narrow set of research questions. For example, ChemCrow is a framework that gives GPT-4 access to chemistry tools and can thus solve components of a chemistry research problem, but it cannot tackle an open-ended, interdisciplinary research problem ${ }^{17}$. Another framework called Coscientist includes GPT-4-powered modules such as a planner and a web searcher to handle several aspects of research ${ }^{18}$. However, Coscientist is primarily applied to relatively standard chemistry tasks such as chemical synthesis planning as opposed to high-level research design across disciplines. In contrast, the AI Scientist aims to use LLMs to perform the entire scientific process from generating a hypothesis to writing code to drafting a paper, but the applications are limited to narrow subfields of machine learning without real-world experiments or validation ${ }^{19}$. Si et al. ${ }^{20}$ similarly explore the use of LLMs for research idea generation and demonstrate promising results when comparing LLM research ideas to human research ideas, but the applications are limited to the field of natural language processing and do not include any implementation of the research ideas.</p>
<p>Here, we introduce the Virtual Lab to overcome these shortcomings via an Al-human research collaboration that performs interdisciplinary science to investigate broad, complex research questions. In the Virtual Lab, a human researcher guides a set of interdisciplinary Al agents ${ }^{21,22}$, such as a biologist or computer scientist, through a set of research meetings that tackle the different phases of a research project. The Al agents are run by an LLM that powers their scientific reasoning abilities with instructions that guide each agent's scientific expertise and interaction with the other agents and the human researcher. The Virtual Lab architecture is versatile and can thus be applied to a wide variety of interdisciplinary science research projects.</p>
<p>To demonstrate the abilities of the Virtual Lab, we employ the Virtual Lab to tackle a high-impact, real-world, open-ended scientific problem: designing new nanobodies that exhibit binding to the latest variant of SARS-CoV-2. There are myriad ways in which scientists could attempt to design such nanobodies, so the Virtual Lab must reason across multiple subfields of biology and computer science to make a series of interrelated decisions about how best to</p>
<p>design these nanobodies. Through a series of meetings, the Virtual Lab develops a novel computational nanobody design workflow that incorporates the protein language model $\mathrm{ESM}^{23}$, the protein folding model AlphaFold-Multimer ${ }^{24}$, and the computational biology software Rosetta ${ }^{25}$ to mutate existing nanobodies that bind to the receptor binding domain (RBD) of the spike protein of the original (Wuhan) strain of SARS-CoV-2 into nanobodies that bind to the latest variants of the virus, where an effective binder is lacking ${ }^{26}$. We experimentally validated 92 mutant nanobodies designed by the Virtual Lab and found that over $90 \%$ of the nanobodies were expressed and soluble, with two promising candidates showing unique binding profiles to the recent JN. 1 and KP. 3 spike RBD variants. This result demonstrates the capability of the Virtual Lab's Al-human collaboration to perform complex, interdisciplinary science research that translates to validated results in the real world.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1 | Virtual Lab architecture. a, The workflow for designing agents in the Virtual Lab. Each agent is specified with four criteria: title, expertise, goal, and role. The human researcher in the Virtual Lab specifies these criteria to define the Principal Investigator (PI) agent and the Scientific Critic agent. Then, given a short description of the project by the human researcher, the PI agent automatically creates several scientist agents to work on the project by specifying their title, expertise, goal, and role, using its own prompt as an example. b, The workflow for a team meeting in the Virtual Lab. The human researcher writes an agenda for the meeting specifying the topic of discussion. The PI agent begins the meeting by providing initial thoughts and agenda questions as a guide for the remaining agents. Then, over the course of N rounds of discussion, each scientist agent provides its response, followed by a critique by the Scientific Critic agent, with the PI agent then synthesizing the discussion and asking follow-up questions. Finally, after the N rounds of discussion, the PI agent summarizes the discussion and provides</p>
<p>an answer regarding the meeting agenda. c, The workflow for an individual meeting. The human researcher writes an agenda for the meeting specifying the topic of discussion. Then, the scientist agent tasked with the individual meeting provides a response to the agenda, which is critiqued by the Scientific Critic. In each round, the scientist agent improves its answer based on feedback from the Scientific Critic. Finally, after the N rounds, the scientist agent provides its final, improved answer.</p>
<h1>Virtual Lab architecture</h1>
<h2>Overview</h2>
<p>We created the Virtual Lab as a collaboration between a human researcher and a team of large language model (LLM) agents to conduct sophisticated, interdisciplinary research (Fig. 1). The human researcher provides high-level guidance for the LLM agents while the LLM agents both decide on general research directions and design solutions to specific research problems. Each agent is implemented by providing the underlying LLM (e.g., GPT-4o) with specific roles (e.g., a biologist agent) and domain-specific tools (e.g., AlphaFold). The Virtual Lab performs research in two primary ways: team meetings and individual meetings. In both cases, the human researcher provides an initial agenda to guide the discussion, and then the agents discuss how to address the agenda. In team meetings, all of the agents discuss a broad research question and work together to come up with an answer. In individual meetings, a single agent is given a more specific task to accomplish, such as writing code for a machine learning model, and the agent either works alone or in conjunction with another agent that provides critical feedback. Through a series of team meetings and individual meetings, the Virtual Lab tackles a complex research project.</p>
<h2>Agents</h2>
<p>Each LLM agent in the Virtual Lab is defined with a prompt that specifies four key criteria (Fig. 1a).</p>
<ol>
<li>Title: The name of the agent.</li>
<li>Expertise: The scientific expertise the agent has.</li>
<li>Goal: The ultimate goal of the agent in the context of the research project.</li>
<li>Role: The specific role that the agent will play in the research project.</li>
</ol>
<p>The agents of the Virtual Lab are led by an agent called the Principal Investigator (PI). The PI agent has expertise in artificial intelligence for scientific research with a goal of maximizing the scientific impact of research and with the role of guiding the research project (full prompt in the Appendix). The PI agent then automatically creates a set of scientist agents (e.g., a biologist or a computer scientist) that are appropriate for the research project based on a short description</p>
<p>of the project written by the human researcher. The PI defines these scientist agents by specifying each agent's title, expertise, goal, and role, using its own prompt as an example.</p>
<p>In addition to the PI and scientist agents, we find it useful to create an explicit critic agent to catch errors and oversights from the other agents and to give critical feedback on answers provided by the other agents ${ }^{27}$. Therefore, a Scientific Critic agent (prompt in the Appendix) can be added to any team meeting or individual meeting to provide critical feedback to the other agents.</p>
<h1>Meetings</h1>
<p>Interactions in the Virtual Lab happen through meetings, which can either be team meetings with all the agents or individual meetings with a single agent (and optionally the critic agent). Both types of meetings share the following set of inputs that structure the meeting.</p>
<ol>
<li>Agenda: (required) A description of the scientific topic to be discussed during the meeting.</li>
<li>Agenda questions: (optional) A set of questions that the agents must answer by the end of the meeting.</li>
<li>Agenda rules: (optional) A set of rules that the agents must follow during the meeting.</li>
<li>Summaries: (optional) Agent-written summaries of previous meetings to provide information about previous decisions.</li>
<li>Contexts: (optional) Additional information (e.g., scientific papers) for the agents to take into consideration.</li>
<li>Rounds: (required) The number of rounds (typically $\mathrm{N}=3$ ) of discussion among the agents.</li>
</ol>
<p>The team and individual meetings differ in terms of the agents that participate in the meeting and the prompts that guide the flow of the meeting.</p>
<h2>Team meeting</h2>
<p>In team meetings, all the agents (PI agent, scientist agents, and Scientific Critic agent) participate in a conversation to address a broad research topic (Fig. 1b). First, the human researcher writes an agenda for the team meeting along with any applicable agenda questions and agenda rules. The team meeting then begins with an automatically constructed prompt (see Appendix) then introduces the agents, agenda, agenda questions (if any), and agenda rules (if any) and describes the flow of the meeting, which involves multiple rounds of discussion. The PI agent is prompted to start the discussion by providing their initial thoughts and any guiding questions that they want to ask the team. Then, each scientist agent and the Scientific Critic agent are prompted one-by-one (in an order set by the human researcher) to provide their thoughts on the ongoing discussion given everything that has been said by the other agents. At</p>
<p>the end of a round of discussion, the PI agent synthesizes the points raised by each agent, makes decisions based on agent input, and asks follow-up questions to further the discussion. After N rounds of discussion (with N set by the human researcher), the PI agent summarizes the discussion for future meetings, provides a recommendation regarding the agenda, and answers the agenda questions (if any). The human researcher in the Virtual Lab can then read just this final response by the PI agent, thus benefiting from the extensive discussions among the LLM agents while only needing to read the final short response to understand the decisions that were made.</p>
<h1>Individual meeting</h1>
<p>In individual meetings, a single agent tackles a specific task that falls within their area of expertise, optionally with critical feedback provided by the Scientific Critic agent (Fig. 1c). To start an individual meeting, the human researcher in the Virtual Lab selects the agent that will participate. An automatically constructed prompt (see Appendix) introduces the agenda, agenda questions (if any), and agenda rules (if any) and then immediately asks the agent for a response. If the individual meeting has zero rounds $(\mathrm{N}=0)$, then the agent provides a response and the meeting ends. If the individual meeting includes one or more rounds ( $\mathrm{N} \geq 1$ ), then in each round, the agent provides a response and then the Scientific Critic agent provides critical feedback to improve the agent's response. After these rounds, the selected agent responds one more time to provide the final, improved answer.</p>
<h2>Parallel meetings</h2>
<p>To improve the expected quality and comprehensiveness of answers for a given meeting, the same meeting (same agents, same prompts) can be run multiple times in parallel to produce multiple answers (Supplementary Fig. 1). Then, an individual meeting with the appropriate agent (i.e., the PI agent for team meetings or the relevant scientist agent for individual meetings) is run to merge the summaries of each of the parallel meetings into a single answer that incorporates the best elements from each of the parallel meetings. To boost creativity while producing a consistently high-quality answer, each of the parallel meetings is run with a higher "creative" temperature of 0.8 while the single merge meeting is run with a lower "consistent" temperature of $0.2^{28}$. Parallel meetings are similar in nature to the method of majority voting from multiple LLM queries ${ }^{29}$, but the Virtual Lab's parallel meetings use a more complex and flexible merging of answers via a meeting with an LLM agent.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2 | Virtual Lab for nanobody design. The workflow used to apply the Virtual Lab to nanobody design for the latest variant of SARS-CoV-2. a, The workflow begins with the human researcher defining the Principal Investigator (PI) and Scientific Critic agents by specifying their title, expertise, goal, and role. Then, the PI agent creates a team of three scientist agents for the project. b, A team meeting discusses the project specification, and the agents make decisions such as whether to design antibodies or nanobodies. c, In another team meeting, the agents suggest a set of computational tools for nanobody design, including ESM, AlphaFold-Multimer, and Rosetta. d, In a series of individual meetings, the Machine Learning Specialist and</p>
<p>Computational Biologist, with helpful feedback from the Scientific Critic, write code and subsequently improve that code for the ESM, AlphaFold-Multimer, and Rosetta components of the nanobody design workflow. e, In an individual meeting, the PI agent decides the workflow for using the three computational tools to design and select mutated nanobody candidates.</p>
<h1>Virtual Lab for nanobody design</h1>
<h2>Overview</h2>
<p>Given the flexibility of the Virtual Lab architecture, the Virtual Lab can be applied to a wide variety of interdisciplinary research projects by adapting the agents and the flow of team and individual meetings to the specific project's goals and constraints. As a demonstration in the domain of biological research, we applied the Virtual Lab with GPT-40 ${ }^{30}$ powering the agents to design antibodies or nanobodies that can bind to the spike protein of the KP. 3 variant of SARS-CoV-2, which was one of the latest variants at the time of this work ${ }^{26}$ (Fig. 2). This is an important and challenging problem because SARS-CoV-2 is rapidly evolving resistance to existing antibody/nanobody therapies, so quickly developing new antibody/nanobody therapies that overcome this resistance and bind to the latest variants is crucial to treating those who are infected ${ }^{31,32}$. The Virtual Lab tackles this problem by rapidly creating a computational workflow to design antibodies or nanobodies for the KP. 3 variant of SARS-CoV-2, which can then be experimentally validated by human biologists. The Virtual Lab created the computational antibody/nanobody design process in five phases.</p>
<ol>
<li>Team selection: An individual meeting with the PI to define a set of scientist agents to work on the project.</li>
<li>Project specification: A team meeting to specify the project direction by deciding on key high-level details.</li>
<li>Tools selection: A team meeting to brainstorm machine learning and/or computational tools for nanobody design.</li>
<li>Tools implementation: A series of individual meetings with different scientist agents to implement three components of the nanobody design workflow-ESM, AlphaFold-Multimer, and Rosetta.</li>
<li>Workflow design: An individual meeting with the PI to determine the workflow for applying these computational tools.</li>
</ol>
<p>These phases are discussed in more detail below, and complete prompts for each phase are in the Appendix.</p>
<h2>Team selection</h2>
<p>First, Virtual Lab used an individual meeting with the PI agent (run five times in parallel followed by a merge meeting) to create a set of scientist agents for the project. The meeting agenda</p>
<p>contained a background prompt about antibody/nanobody design for the spike protein of the recent KP. 3 SARS-CoV-2 variant and a request for the PI agent to select a team of three scientist agents for the project using the same agent structure (title, expertise, goal, role) as the PI's own definition. The PI decided to create an Immunologist, a Machine Learning Specialist, and a Computational Biologist.</p>
<h1>Project specification</h1>
<p>Next, in a team meeting, the full team of agents (PI, Immunologist, Machine Learning Specialist, Computational Biologist, and Scientific Critic) discussed some of the specifics of the project beyond the general background prompt. This meeting's agenda asked the agents to consider design choices such as whether to pursue antibodies or nanobodies and whether to modify existing antibodies/nanobodies or design new ones de novo. This team meeting was run in five parallel iterations followed by an individual merge meeting with the PI agent and the Scientific Critic to produce the best answer. Below are some of the PI's final merged answers to the agenda questions.</p>
<ol>
<li>Will you design standard antibodies or nanobodies?</li>
</ol>
<h2>Agent Answer: Nanobodies</h2>
<p>Agent Justification: Nanobodies offer superior stability, tissue penetration, and ease of production, making them ideal for targeting conserved and cryptic epitopes on the SARS-CoV-2 spike protein. This choice is consistently supported across all summaries, emphasizing their advantages in accessing unique epitopes and potential for broad-spectrum activity.
2. Will you design antibodies/nanobodies de novo or will you modify existing antibodies/nanobodies (choose only one)?</p>
<p>Agent Answer: Modify existing nanobodies
Agent Justification: Modifying existing nanobodies allows us to leverage established data, providing a quicker and more reliable path to developing broad-spectrum candidates. This approach is supported by the availability of structural data and known efficacy, which can accelerate the optimization process. This decision is consistently recommended across all summaries, highlighting the efficiency and feasibility of building on known frameworks.
3. If modifying existing antibodies/nanobodies, which precise antibodies/nanobodies will you modify (please list 3-4)?</p>
<p>Agent Answer: Ty1, H11-D4, Nb21, VHH-72
Agent Justification: These candidates have demonstrated strong neutralizing capabilities against SARS-CoV-2 and have available structural data, making them excellent candidates for modification. Ty1 and H11-D4, for example, have shown efficacy</p>
<p>in neutralizing multiple variants, while Nb21 and VHH-72 offer unique binding properties that can be optimized for broader cross-reactivity. Literature supports their efficacy, with studies indicating their ability to bind conserved epitopes and maintain stability under various conditions.</p>
<p>Given these decisions, the following phases proceeded with nanobody design by modifying the four nanobodies suggested by the Virtual Lab (Ty133, H11-D434, Nb2135, and VHH-7236), which are specific to the ancestral Wuhan spike protein, to increase their affinity to the spike protein of the KP. 3 variant of SARS-CoV-2. Furthermore, the Virtual Lab suggested prioritizing "enhancing interactions with the receptor-binding domain of the spike protein by altering residues that contribute to binding affinity," so the Virtual Lab subsequently focused on developing nanobodies that bind to the receptor binding domain (RBD) of the KP. 3 spike protein.</p>
<h1>Tools selection</h1>
<p>After specifying the project direction, the Virtual Lab next needed to pick a set of computational tools to modify the selected nanobodies. To accomplish this, the Virtual Lab ran a team meeting asking the agents to list several machine learning and/or computational tools that could be used for nanobody design, with emphasis on pre-trained models for simplicity. Similar to the project selection meeting, this team meeting was run with five parallel iterations followed by a merge meeting with the PI and Scientific Critic. The agents decided to use $\mathrm{ESM}^{23}$, AlphaFold-Multimer ${ }^{24}$, and Rosetta ${ }^{25}$ as the components of its computational nanobody design workflow.</p>
<h2>Tools implementation</h2>
<p>With the project well-specified and a set of computational nanobody tools chosen, the Virtual Lab then worked on implementing these tools for nanobody design. For each tool, the Virtual Lab selected the most appropriate scientist agent via an individual meeting with the PI. Then for each tool, the Virtual Lab ran an individual meeting with the selected scientist agent and the Scientific Critic (five parallel meetings followed by a merge meeting run by the scientist agent) to implement the tool. These meetings included a set of agenda rules that specify how code should be written, e.g., with good documentation and without leaving functions undefined. These initial implementations contained small errors that needed correction, so the Virtual Lab then ran a single follow-up individual meeting (no parallelization or Scientific Critic) with the scientist agent to automatically fix all the errors that arose (see Appendix).</p>
<h2>ESM usage</h2>
<p>The Machine Learning Specialist agent was responsible for writing a Python script to identify the most promising point mutations to a nanobody sequence based on the ESM log-likelihood ratio (LLR) of the mutant sequence compared to the input sequence. The agent wrote a 130-line Python script with three functions: a main function to run the script, a function to parse command-line arguments (e.g., the input nanobody sequence), and a function that uses a pre-trained ESM model to compute log-likelihood ratios for point mutations.</p>
<p>Notably, the Virtual Lab's ESM nanobody mutation analysis is similar to the ESM-based antibody design process of Hie et al. ${ }^{37}$, but it differs in important ways. The Virtual Lab computes the ESM LLR of mutant sequence $x^{\prime}$ with mutation at position $i$ compared to the input sequence $x$ as $L L R\left(x^{\prime} \mid x\right)=\log \left(\frac{p\left(x^{\prime} \mid x^{\prime}\right)}{p\left(x_{i} \mid x\right)}\right)$, where $p\left(x_{i}^{\prime} \mid x^{\prime}\right)$ is the ESM probability of the mutant amino acid $x_{i}^{\prime}$ at position $i$ in the mutant sequence $x^{\prime}$ and $p\left(x_{i} \mid x\right)$ is the ESM probability of the original amino acid $x_{i}$ at position $i$ in the input sequence $x$. In contrast, Hie et al. use $p\left(x_{i}^{\prime} \mid x\right)$ as the numerator in the ratio instead of $p\left(x_{i}^{\prime} \mid x^{\prime}\right)$, thereby computing the probability of the mutant amino acid in the input sequence rather than the probability of the mutant amino acid in the mutant sequence. Additionally, the Virtual Lab only uses the ESM-1b ${ }^{38}$ model while Hie et al. use a consensus of ESM-1b and five ESM-1v ${ }^{39}$ models.</p>
<h1>AlphaFold-Multimer usage</h1>
<p>To use AlphaFold-Multimer, the Virtual Lab asked the Computational Biologist agent to write a Python script that processes a predicted nanobody-spike complex structure from AlphaFold-Multimer and outputs the interface pLDDT (ipLDDT), which is a measure of the confidence of the binding interface between the nanobody and the spike protein that has previously been shown to correlate with antibody-antigen binding affinity ${ }^{40}$. Computing the ipLDDT values across multiple proposed nanobodies requires reading a PDB file for each predicted nanobody-spike complex and writing as output a single CSV file with the ipLDDT from every complex. The Computational Biologist wrote a 144-line Python script with five functions: a main function to run the whole script, a function to check whether a PDB file contains a protein structure in the correct format, a function to identify the residues in the interface between the two proteins, a function to calculate the ipLDDT, and a function to run the ipLDDT calculation on every PDB file in a directory and save the results to a single CSV file.</p>
<h2>Rosetta usage</h2>
<p>The Computational Biologist was also responsible for using Rosetta to calculate nanobody-spike binding energies as a metric for measuring the quality of each mutated nanobody. Given a PDB file with a predicted nanobody-spike structure from AlphaFold-Multimer, the Computational Biologist was asked to write a RosettaScripts XML file to load the PDB file, calculate the binding energy, and save the binding energy to a Rosetta score file. Additionally, the agent was asked to write a Python script that loads all the score files in a directory and saves a CSV file with the binding energy of every nanobody-spike complex.</p>
<p>The Computational Biologist wrote a 30-line RosettaScripts XML file that first relaxes the nanobody-spike structure and then computes the binding energy (dG-separated in Rosetta terminology) of the interface using the REF15 scoring function. The Computational Biologist then wrote a 71-line Python script with two functions: a main function to run the whole script and a function to extract the binding energy score from a given Rosetta score file.</p>
<h1>Workflow design</h1>
<p>Finally, the Virtual Lab ran an individual meeting with the PI agent to design a workflow that uses ESM, AlphaFold-Multimer, and Rosetta to design nanobodies. For each of the four starting nanobody candidates, the PI agent decided to run ESM to evaluate all possible point mutations and then to select the top 20 mutations by ESM log-likelihood ratio. Each of these 20 mutant sequences would then be evaluated by both AlphaFold-Multimer and Rosetta. These 20 sequences would then be ranked and the top five would be selected using the following weighted score designed by the PI agent:
WS $=0.2$ * (ESM LLR) $+0.5$ * (AF ipLDDT) - $0.3$ * (RS dG)
where WS is the weighted score, ESM LLR is the ESM log-likelihood ratio between the mutated sequence and the input sequence, AF ipLDDT is the AlphaFold-Multimer ipLDDT binding interface confidence, and RS dG is the Rosetta dG-separated binding energy value. The PI correctly uses a negative weight for the Rosetta value since a more negative binding energy is better. The top five sequences according to WS then serve as the starting sequences for the next round of mutation, with 4 rounds of mutation in total depending on time constraints and improvements in the WS across rounds.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3 | Nb21 nanobody analysis. a, Each round of nanobody design begins with a nanobody sequence. ESM computes the log-likelihood ratio (ESM LLR) of every single point mutation to the input sequence. The top 20 mutant sequences by ESM LLR are run through AlphaFold-Multimer to predict the structure of the complex of nanobody and SARS-CoV-2 spike protein, and the interface pLDDT (AF ipLDDT) confidence value is computed. This complex is then passed to Rosetta, which relaxes the structure and computes a binding energy (RS dG). These three scores are combined into a weighted score (WS) that is used to select the top five mutant nanobodies for the next round of optimization. b-d, Evolution of mutant nanobody scores across four rounds of optimization, with improvements in ESM LLR, AF ipLDDT, and RS dG across the rounds. b, The distribution of ESM LLR values for proposed Nb21 mutant nanobodies across each round of optimization, with ESM LLR values computed relative to the input nanobody sequence from the previous round. Shown are the ESM LLR values of the top 20 proposed mutant nanobodies per input nanobody, i.e., the proposed mutant nanobodies that proceed to AlphaFold-Multimer and Rosetta analysis. c, The AF ipLDDT and the RS dG of the top five proposed nanobodies, selected by WS, at the end of each round of optimization. d, The distribution of WS values of the top five proposed nanobodies at the end of each round of optimization. e-g, Analysis of the final set of 23 mutant nanobodies selected across all rounds of optimization, which exhibit superior ESM LRR ${ }^{\mathrm{WT}}$, AF ipLDDT, and RS dG values compared to the wild-type nanobody. e, The distribution of ESM LLR ${ }^{\mathrm{WT}}$ values (ESM LLR of the mutant sequence compared to the wild-type sequence) for the selected nanobodies and the wild-type nanobody. f, The AF ipLDDT and RS dG values of the selected nanobodies and the wild-type nanobody. g, The structure (predicted by AlphaFold-Multimer followed by Rosetta relaxation) of the receptor binding domain of the spike protein of the KP. 3 variant of SARS-CoV-2 (cyan) and the proposed nanobody mutant Nb21 I77V-L59E-Q87A-R37Q (green). Side chains are shown for all residues within 4 A of the opposite chain (i.e., interface residues). Mutant residues in the proposed nanobody are shown in pink.</p>
<h1>Results</h1>
<h2>Nanobody design</h2>
<p>The Virtual Lab ran the nanobody design computational workflow (Fig. 3a) to design improved nanobody candidates for the KP. 3 variant of SARS-CoV-2, which was one of the latest variants at the time of this work. The workflow was run independently for each of the four nanobodies suggested by the agents: Ty1, H11-D4, Nb21, and VHH-72. Below, we describe the workflow in terms of a single starting nanobody for simplicity.</p>
<p>The Virtual Lab workflow began with "round 0," which evaluated the wild-type nanobody sequence without introducing any mutations. ESM LLR was assigned to zero since the wild-type nanobody sequence was unmodified. Then, the Virtual Lab ran AlphaFold-Multimer (via LocalColabFold ${ }^{41}$ version 1.5.5) on the nanobody sequence and the sequence of the receptor binding domain (RBD) of the KP. 3 spike protein to produce a predicted structure of the complex. Next, the Virtual Lab computed the AF ipLDDT as a measure of confidence in the binding interface of the complex. Then, the Virtual Lab ran Rosetta to relax the complex and compute</p>
<p>the RS dG value as an estimate of the binding energy. Finally, the Virtual Lab computed the weighted score (WS) of the wild-type nanobody.</p>
<p>In round 1, the Virtual Lab ran ESM to calculate the ESM LLR of every possible single point mutation to the wild-type nanobody. The top 20 mutated sequences by ESM LRR were retained. For each of these 20 mutated sequences, AlphaFold-Multimer and Rosetta were applied in the same way as for the wild-type sequence. The Virtual Lab then computed the WS for each of the 20 mutated sequences and selected the top five sequences for the next round. In rounds 2-4, the Virtual Lab applied the same procedure but now starting with five input sequences to the ESM LLR script, resulting in 100 top mutated sequences ( 20 proposed mutant sequences for each of the five input sequences). These sequences were analyzed by AlphaFold-Multimer and Rosetta, and the top five of these 100 sequences were selected at the end of each round by their WS.</p>
<p>After running all four rounds of mutation, the Virtual Lab needed to select the best mutated nanobody sequences across all four rounds for experimental validation. Doing so required using a slight variant of the weighted score (WS). In each round, the WS used the ESM LLR calculated as a ratio between the proposed mutant sequence and the input sequence for that round (i.e., an output sequence from the previous round), which differ by a single mutation. However, in order to fairly select the best sequences across different rounds with different numbers of mutations, an alternate ESM log-likelihood ratio, which we call the ESM LLR ${ }^{\mathrm{WT}}$, was computed between each proposed mutant sequence (with one to four mutations) and the wild-type sequence. The Virtual Lab then scored all mutant nanobody sequences using the WS ${ }^{\mathrm{WT}}$, which is the weighted score calculated using the ESM LLR ${ }^{\mathrm{WT}}$ in place of the ESM LLR. The top 23 mutant sequences were selected for experimental validation along with the wild-type sequence as a point of reference.</p>
<p>Table 1 | Nanobody score analysis. The scores of each wild-type nanobody and examples of the mutant nanobodies that were selected for experimental validation. ESM LLR ${ }^{\mathrm{WT}}$ : ESM log-likelihood ratio between the mutant nanobody sequence and the wild-type sequence. AF ipLDDT: AlphaFold-Multimer interface pLDDT for the nanobody-spike complex. RS dG: Rosetta dG-separated binding energy value. WS ${ }^{\mathrm{WT}}$ : Weighted score combining ESM LLR ${ }^{\mathrm{WT}}$, AF ipLDDT, and RS dG.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>ESM LLR ${ }^{\text {WT }}$</th>
<th>AF ipLDDT</th>
<th>RS dG</th>
<th>WS $^{\text {WT }}$</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ty1</td>
<td>0.00</td>
<td>71.83</td>
<td>-41.51</td>
<td>48.36</td>
</tr>
<tr>
<td>Ty1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>V32F-G59D-N54</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>S-F32S</td>
<td>3.51</td>
<td>86.06</td>
<td>-28.69</td>
<td>52.34</td>
</tr>
<tr>
<td>H11-D4</td>
<td>0.00</td>
<td>68.18</td>
<td>-38.93</td>
<td>45.77</td>
</tr>
<tr>
<td>H11-D4</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A14P-Y88V-K74</td>
<td>10.67</td>
<td>84.02</td>
<td>-35.04</td>
<td>54.66</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">T-R27L</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nb21</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">72.11</td>
<td style="text-align: left;">-43.32</td>
<td style="text-align: left;">49.05</td>
</tr>
<tr>
<td style="text-align: left;">Nb21 <br> I77V-L59E-Q87 <br> A-R37Q</td>
<td style="text-align: left;">7.47</td>
<td style="text-align: left;">80.41</td>
<td style="text-align: left;">-51.56</td>
<td style="text-align: left;">57.17</td>
</tr>
<tr>
<td style="text-align: left;">VHH-72</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">66.46</td>
<td style="text-align: left;">-20.90</td>
<td style="text-align: left;">39.50</td>
</tr>
<tr>
<td style="text-align: left;">VHH-72 <br> R27Y-E31D-F37 <br> V-D89E</td>
<td style="text-align: left;">8.82</td>
<td style="text-align: left;">69.51</td>
<td style="text-align: left;">-53.76</td>
<td style="text-align: left;">52.65</td>
</tr>
</tbody>
</table>
<h1>Computational nanobody analysis</h1>
<p>The successive rounds of optimization improved the quality of the proposed mutant nanobody sequences according to the three metrics of ESM LLR, AF ipLDDT, and RS dG. Fig. 3b-g shows relevant metrics for Nb21, while results are similar for Ty1 (Supplementary Fig. 2), H11-D4 (Supplementary Fig. 3), and VHH-72 (Supplementary Fig. 4). Table 1 shows scores for the wild-type sequence and some of the mutant sequences that were selected for experimental validation.</p>
<p>In each round, the top sequences selected by ESM LLR had log-likelihood ratios of roughly 1-8, indicating that each subsequent round of mutation improved the overall quality of the nanobody compared to the input sequence from the previous round (Fig. 3b). This is according to ESM's internal understanding of nanobody likelihood, which does not take the antigen (spike protein) into account but does understand overall nanobody quality. The top mutant nanobody sequences selected by ESM LLR in each round generally had improved structural complexes with the KP. 3 spike protein based on improved AF ipLDDT, improved RS dG, or both (Fig. 3c). The WS values of the top five sequences at the end of each round improved (Fig. 3d), even when using the ESM LLR instead of the ESM LLR ${ }^{\mathrm{WT}}$ that corrects for the effect of multiple mutations and not just the most recent mutation.</p>
<p>After correction, the ESM LLR ${ }^{\mathrm{WT}}$ for the final selected 23 sequences showed a large improvement over the wild-type sequence (Fig. 3e). These selected sequences also had improved AF ipLDDT and RS dG scores compared to the wild-type (Fig. 3f). An example of the AlphaFold-Multimer predicted structure of a top scoring mutant nanobody is shown in Fig. 3g. Notably, the final set of 23 selected nanobody sequences includes sequences with different numbers of mutations (i.e., from different rounds) and with a different balance of ESM LLR ${ }^{\mathrm{WT}}$, AF ipLDDT, and RS dG values, allowing for a diversity of potential improvements to the wild-type nanobody.</p>
<p>Applying this workflow to each of the four starting nanobodies resulted in 92 final selected sequences ( 23 per starting nanobody). All 92 mutant nanobodies had a positive ESM LLR,</p>
<p>indicating that ESM preferred the mutant over the wildtype. Among the 92 mutant nanobodies, 78 (85\%) had an AF ipLDDT greater than their respective wildtype nanobody, and 32 (35\%) had an AF ipLDDT $\geq 80$, which is in line with the AF ipLDDT scores of high accuracy AlphaFold-Multimer antibody-antigen structural models in prior work ${ }^{40}$. Furthermore, 60 (65\%) had an RS dG less (better) than their respective wildtype nanobody, and 23 (25\%) of the 92 mutants had an RS dG $\leq-50$, which is in line with strong Rosetta binding energy values of nanobodies or antibodies in complex with the SARS-CoV-2 receptor binding domain in prior work ${ }^{25,42}$.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4 | Workflow for nanobody experimental validation. The four categories of experiments (nanobody expression, SARS-CoV-2 spike RBD expression, antigen array printing, and multiplexed ELISA) are enclosed in boxes. The ribbons representation of a nanobody (blue) and the RBD (purple) were rendered with ChimeraX ${ }^{58}$ from PDB accession numbers 6XZN and 6MOJ, respectively. Unique RBD and control proteins of the array are shown as colored spots with fiducial markers shown as black spots.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5 | Experimental validation of Virtual Lab nanobodies. a, Histogram of nanobody expression levels. A 5-point scale ( $1=$ very low, $2=$ low, $3=$ average, $4=$ high, $5=$ very high) was used to classify the amount of nanobody in the soluble periplasmic extract. SDS-PAGE data used for the graph is shown in Supplementary Fig. 5. b, ELISA binding profiles of nanobodies to a panel of antigens. For each SARS-CoV-2 RBD protein and BSA (x-axis), individual spots represent the ELISA binding intensity ( $y$-axis) of each nanobody. Unmutated nanobodies (H11-D4, Nb21, Ty1, and VHH-72) are shown in black and nanobodies exhibiting high non-specific binding are shown in shades of red (light pink, pink, and magenta). The Nb21 mutant (I77V-L59E-Q87A-R37Q) and the Ty1 mutant (V32F-G59D-N54S-F32S) that show binding to JN. 1 are shown in green. Data shown are the mean of two measurements at a nanobody concentration of $0.5 x$. c, Comparison of ELISA binding of mutants and their unmutated sequences. Nb21 mutant I77V-L59E-Q87A-R37Q and Ty1 mutant V32F-G59D-N54S-F32S are shown as filled circles and unmutated Nb21 and Ty1 nanobodies are shown as open circles. ELISA binding intensity ( $y$-axis) to Wuhan RBD, JN. 1 RBD, and BSA are shown in blue, red, and gray, respectively. Data shown are the mean of two measurements at a 12-point serial dilution of nanobody. d, Location of mutant nanobody mutations. Models of the Nb21 mutant I77V-L59E-Q87A-R37Q and the Ty1 mutant V32F-G59D-N54S-F32S, generated by the Virtual Lab using Alphafold-Multimer, are shown in ribbons representation (blue), with the CDR loops shown in orange. Mutations introduced by the Virtual Lab are shown in pink and in red circles. Structure images were generated using ChimeraX ${ }^{58}$.</p>
<h1>Nanobody experimental validation</h1>
<p>To validate the nanobodies designed by the Virtual Lab, we conducted a set of experiments to measure their binding to a panel of spike receptor binding domain (RBD) proteins (Fig. 4). We first overexpressed each nanobody in E. coli, followed by isolation of soluble protein from the</p>
<p>periplasm. The designed nanobodies show excellent expression, with $38 \%$ ( 35 of 92 ) of the designs showing high to very high expression levels (Fig. 5a, Supplementary Fig. 5) and only $6.5 \%$ ( 6 of 92 ) of the designs showing very little to no soluble expression. Thus, the mutations proposed by the Virtual Lab are well tolerated and do not cause large-scale misfolding or aggregation of the nanobodies.</p>
<p>To determine if the 92 mutant nanobodies-23 each for Ty1, H11-D4, Nb21, and VHH-72—and the four wild-type nanobodies could bind to the SARS-CoV-2 KP. 3 spike RBD, we generated a spike RBD array that included the KP. 3 RBD protein, its closely related parental strain (JN. 1 RBD), a closely related variant (KP.2.3 RBD), an early Omicron variant (BA. 2 RBD), and the ancestral strain (Wuhan RBD), which all four wild-type nanobodies show specificity for.</p>
<p>Using this RBD array, we first profiled the binding of all 96 nanobodies by indirect ELISA to each antigen at a single nanobody dilution ( 0.5 X ) (Fig. 5b). For the H11-D4 and Nb21 series, binding to Wuhan RBD is overwhelmingly retained in $96 \%$ of mutant nanobodies ( 44 of 46 ). Three mutants in the H11-D4 series exhibit high non-specific binding to BSA and all of the RBDs (Fig. 5b), possibly owing to the Virtual Lab inadvertently introducing an R27C mutation, which may be leading to disulfide crosslinking. In contrast to the H11-D4 and Nb21 mutants, the Ty1 mutants, overall, exhibit poor binding to Wuhan RBD (10 of 23 mutants). If the V32 mutation of Ty1, selected by the Virtual Lab as the first residue to mutate for each mutant, is not well tolerated, this could result in the observed poor binding to Wuhan RBD compared to the H11-D4 and Nb21 mutants. Over half of the VHH-72 mutants (13 of 22) show binding to Wuhan RBD at levels similar to that observed for the unmutated VHH-72 nanobody. Thus, the Virtual Lab designs are, overall, well tolerated with respect to preserving their original specificity to Wuhan RBD.</p>
<p>Of the 92 Virtual Lab designed nanobodies, two show promising binding profiles beyond Wuhan RBD. The first derived from Nb21, I77V-L59E-Q87A-R37Q (i.e., Nb21 with the mutations I77V, L59E, Q87A, and R37Q), shows positive ELISA binding to JN. 1 RBD (Fig. 5b-c) at nanobody dilutions up to $10^{-6}$. Maximal binding of this nanobody to JN. 1 RBD is less than that to Wuhan RBD, with a weaker EC50 ( $\sim 10^{-5}$ vs $\sim 10^{-6}$ ) showing that this new binding to JN. 1 RBD may be moderate. The wild-type Nb21 shows very low ELISA binding to JN. 1 RBD, suggesting that the Virtual Lab mutant has improved upon this existing very weak binding. Interestingly, this mutant also shows some binding to KP. 3 RBD (average intensity $=3.5$ ) compared to the other Nb21 mutants (average intensity $=0.06 \pm 0.09, n=22$ ) and the unmutated sequence (average intensity $=0.1$ ) (Fig. 5b). We further confirmed this KP. 3 binding enrichment in separate ELISA experiments. The R37Q mutation in this mutant may be important for this binding since the triple mutant nanobody without R37Q (i.e., I77V-L59E-Q87A) and three nanobodies with the same triple mutation but a different fourth mutation (I99R, Q87A, or R43L) do not bind to JN. 1 or KP.3. Additionally, the L59E mutation may contribute to JN. 1 RBD and KP. 3 RBD binding because the JN. 1 RBD and the KP. 3 RBD have mutations that introduce positive charges relative to the Wuhan RBD (e.g., E484K) while the L59E and R37Q mutations in the nanobody introduce a negative charge (and reduce positive charge), which could lead to beneficial electrostatic forces or hydrogen bonding (Fig. 5d).</p>
<p>Notably, a Ty1 mutant nanobody (V32F-G59D-N54S-F32S) not only improved binding to Wuhan RBD, as measured by ELISA, but also gained moderate binding to JN. 1 RBD (Fig. 5b-c). In contrast, we see no evidence for even low levels of unmutated Ty1 nanobody binding to JN. 1 RBD. Interestingly, the Virtual Lab initially introduced a V32F mutation in the first round and then later followed up with an F32S mutation in the fourth round, resulting in a V32S mutation in the final mutant nanobody. Every one of the 23 mutant nanobodies introduced a mutation at position 32 in the first round (either V32F or V32C), but only three of the 23 mutants later modified position 32 again, two introducing F32Y and this mutant introducing F32S. This indicates that position 32, which is predicted to be near the binding domain, may be particularly important for Ty1 but may require a very specific mutation to induce binding to JN.1. Similar to that observed for the Nb21 mutant that binds to JN. 1 RBD, this Ty1 mutant also introduces a negative charge (G59D). All the mutations of this mutant nanobody are in the CDR loops of the nanobody (Fig. 5d).</p>
<p>Across the mutant nanobodies, the preserved and improved binding affinities for the Wuhan RBD (and JN. 1 RBD for Nb21) relative to their respective wild-type forms is likely due to the effect of the Virtual Lab's use of ESM log-likelihoods, which are agnostic to the antigen but select for evolutionarily favorable nanobody sequences with improved fitness ${ }^{37}$. In contrast, the Ty1 mutant that gained binding affinity for the JN. 1 RBD, which is the close ancestor of KP. 3 sharing $99.1 \%$ identity in the $\mathrm{RBD}^{43}$ ( 220 of 222 residues), and the Nb21 mutant that gained binding affinity for the KP. 3 RBD and improved binding affinity for the JN. 1 RBD may demonstrate the effect of the AlphaFold-Multimer and Rosetta scoring, which explicitly aim to predict binding affinity of the mutant antibody to the KP. 3 RBD, and thus by extension the closely related JN. 1 RBD. Through the use of these three tools, the Virtual Lab designed a set of promising nanobody candidates with potential for further development.</p>
<p>Principal Investigator: I want to emphasize the significance of our objective: to develop effective antibodies or nanobodies that can target the newest variant of the SARS-CoV-2 spike protein, while also maintaining activity against other circulating minor variants and past variants.</p>
<p>Immunologist: I recommend modifying existing nanobodies. We have a wealth of data on several broadly neutralizing nanobodies that have shown efficacy against diverse SARS-CoV-2 variants. This approach reduces the risk and time associated with de novo design, leveraging existing structural and binding data for rapid development.</p>
<p>Machine Learning Specialist: I agree with the emphasis on nanobodies... Their smaller size also means fewer degrees of freedom, which can simplify machine learning model complexity... For modifying existing nanobodies, we can utilize deep learning models trained on structural and sequence data to predict changes that enhance binding affinity and cross-reactivity.</p>
<p>Computational Biologist: The machine learning models proposed are excellent, and coupling them with molecular docking and simulations can create a robust pipeline. For instance, once a machine learning model suggests modifications, simulations can be used to validate and refine these predictions by assessing the energetic favorability and structural compatibility with the spike protein.</p>
<p>Scientific Critic: We must remain cautious of over-reliance on computational predictions without thorough cross-validation. Machine learning models can suffer from bias, particularly if trained on limited or non-representative datasets.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6 | Virtual Lab discussion analysis. a, Excerpts from a Virtual Lab team meeting discussing the nanobody project specification. Each LLM agent addresses the agenda from its own perspective based on its title, expertise, goal, and role, leading to a comprehensive and interdisciplinary discussion of the agenda. b, The number of words (space-separated tokens) written by the Virtual Lab (human researcher and each LLM agent) across all phases of the nanobody design process. c, The number of words written by the Virtual Lab in the project specification phase. d, The number of words written by the Virtual Lab in the ESM implementation phase. e, The number of words written by the Virtual Lab in the workflow design phase.</p>
<h1>Analyses of Virtual Lab interactions</h1>
<p>The Virtual Lab proceeded rapidly through the phases of the nanobody design workflow, with each meeting (or a set of parallel meetings) only taking the agents about 5-10 minutes. Furthermore, the Virtual Lab was able to conduct extensive discussions with relatively minimal input from the human researcher, and the individual identities of the agents contributed to a comprehensive, interdisciplinary discussion with each agent providing perspective based on its specific background (Fig. 6a). For example, the Immunologist discusses the benefits of modifying existing nanobodies instead of designing nanobodies de novo, the Machine Learning Specialist explains how nanobody size can affect machine learning model complexity, the</p>
<p>Computational Biologist explores computational techniques like molecular docking, and the Scientific Critic raises questions about over-reliance on predictions and bias in datasets.</p>
<p>One of the benefits of the Virtual Lab is that relatively limited human input is required. Across all the phases of the workflow, the human researcher wrote only 1,596 words (defined as space-separated tokens) in total, including some copy-pasted text from a Rosetta score file, which is just $1.3 \%$ of all the words written by the Virtual Lab (Fig. 6b). In contrast, the LLM agents wrote 122,462 words ( $98.7 \%$ of all words), including all the Python scripts and one XML script that were written from scratch by the agents.</p>
<p>The meetings in the nanobody design workflow reveal interesting social dynamics among the Virtual Lab agents. For example, in the project specification team meeting, the PI agent wrote the most ( $36.4 \%$ of the words) followed by the Scientific Critic ( $21.0 \%$ ) and then the three scientist agents-the Computational Biologist (14.8\%), the Machine Learning Specialist (14.5\%), and the Immunologist ( $12.8 \%$ )—with the human researcher only writing $0.5 \%$ of the words (Fig. 6c). The distribution is similar for the tools selection team meeting (Supplementary Fig. 6a). This order is reasonable given that the PI not only has to synthesize the agent responses after each round of discussion to guide the next round but also has to initiate the meeting and write a summary at the end. The Scientific Critic likely writes more than the scientist agents since the Scientific Critic must address the limitations of every agents' response while each scientist agent is only concerned with providing its own opinions. In the individual meetings with both a scientist agent and the Scientific Critic, the scientist agent tends to dominate the discussion, producing around $66 \%$ of the words compared to around $33 \%$ for the Scientific Critic and around 1\% for the human researcher (Fig. 6d, Supplementary Fig. 6b-c). In individual meetings with an agent without the Scientific Critic, which have no back-and-forth discussion, the agent writes more than $80 \%$ of the words compared to less than $20 \%$ written by the human researcher (Fig. 6e, Supplementary Fig. 6d-e).</p>
<p>The use of parallel meetings was notable as it led to answers with improved consistency and quality. For example, the five parallel individual meetings with the PI agent produced the following five sets of scientist agents.</p>
<ol>
<li>Computational Biologist, AI/ML Specialist, Immunologist</li>
<li>Computational Biologist, Immunologist, Machine Learning Specialist</li>
<li>Computational Biologist, Virologist, Antibody Engineer</li>
<li>Immunologist, Structural Biologist, Machine Learning Specialist</li>
<li>Computational Biologist, Structural Biologist, Immunologist</li>
</ol>
<p>Upon merging these answers, the PI chose to define a Computational Biologist, a Machine Learning Specialist, and an Immunologist. This roughly aligns with the majority vote of the five parallel meetings, resulting in a more consistent answer than any one of the meetings. Furthermore, the merge meeting aimed to select the best form of each agent. For example, the final merged Machine Learning Specialist's expertise is "developing algorithms for protein-ligand interactions and optimization," which is the same as that of the Machine Learning Specialist in</p>            </div>
        </div>

    </div>
</body>
</html>