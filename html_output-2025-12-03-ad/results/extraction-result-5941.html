<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5941 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5941</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5941</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-119.html">extraction-schema-119</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-207226d2b33cfef5288dac1c95d7baeb69729d4e</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/207226d2b33cfef5288dac1c95d7baeb69729d4e" target="_blank">Prediction of robust scientific facts from literature</a></p>
                <p><strong>Paper Venue:</strong> Nature Machine Intelligence</p>
                <p><strong>Paper TL;DR:</strong> A Bayesian calculus is demonstrated that enables positive prediction of robust scientific claims with findings extracted from published literature, weighted by scientific, social and institutional factors demonstrated to increase replicability.</p>
                <p><strong>Paper Abstract:</strong> The growth of published science in recent years has escalated the difficulty that human and algorithmic agents face in reasoning over prior knowledge to select the next experiment. This challenge is increased by uncertainty about the reproducibility of published findings. The availability of massive digital archives, machine reading, extraction tools and automated high-throughput experiments allows us to evaluate these challenges computationally at scale and identify novel opportunities to craft policies that accelerate scientific progress. Here we demonstrate a Bayesian calculus that enables positive prediction of robust scientific claims with findings extracted from published literature, weighted by scientific, social and institutional factors demonstrated to increase replicability. Illustrated with the case of gene regulatory interactions, our approach automatically estimates and counteracts sources of bias, revealing that scientifically focused but socially and institutionally diverse research activity is most likely to replicate. This results in updated certainty about the literature, which accurately predicts robust scientific facts on which new experiments should build. Our findings allow us to identify and evaluate policy recommendations for scientific institutions that may increase robust scientific knowledge, including sponsorship of increased diversity of and independence between investigations of any particular scientific phenomenon, and diversity of scientific phenomena investigated. With the availability of a vast and growing number of digital publications, machine reading and other knowledge mining tools, computational methods can be applied at scale to extract insights from the scientific literature. Belikov et al. develop a Bayesian method to mine the biomedical literature that identifies robust scientific findings which could improve the planning of further experiments and scientific investigation.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5941.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5941.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GeneWays</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GeneWays</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated information-extraction system that semantically parses biomedical text with a context-free grammar tuned to the biomedicine sublanguage to extract directed gene-gene relations (positive/negative). Used here to extract gene interaction claims from MEDLINE abstracts and produce a directed genetic graph for downstream analysis and validation against LINCS L1000.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GeneWays</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A rule- and grammar-based semantic parser / information-extraction pipeline tailored to biomedical text. It identifies biological entities (genes/proteins) and verbs, parses sentences with a context-free grammar tuned to biomedical sublanguage, and projects extracted relations to simplified positive/negative directional actions. Not a large neural LLM; architecture is symbolic/grammar-based (precision reported high in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Biomedical genetics — extraction of gene-gene regulatory interaction claims from scientific literature (MEDLINE abstracts).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Articles from MEDLINE (paper reports GeneWays derived from ~197k MEDLINE articles; analyses here restricted to claims extracted from abstracts resulting in tens of thousands of unique claims/interactions after filtering and merging with LINCS L1000). Filtering: only abstract-extracted claims kept, verbs projected to positive/negative, duplicates/contradictions within same paper discarded, merged to LINCS L1000 experimental interactions (~6.8K interactions after merge for GeneWays).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Symbolic information extraction using semantic parsing with a context-free grammar tuned to biomedical sublanguage; extracted directed relations (triplets: source gene, target gene, action) aggregated across papers. No fine-tuning of large neural LLMs reported; downstream uses include feature extraction for ML models and Bayesian inference, not equation discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_law_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>example_law_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Intrinsic precision estimates reported (paper cites GeneWays precision ~95% in their evaluation), measurement of percent positive interactions, and external validation by aligning extracted claims to experimental ground truth from LINCS L1000 (aggregate z-scores transformed to (0,1) CDF). Subsequent predictive models (logistic regression, random forest) used to evaluate how extracted claims predict experimental outcomes (AUC reported for downstream tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GeneWays produced a high-precision set of gene-gene directed interaction claims drawn from MEDLINE abstracts (precision reported ~95% in paper). After merging with LINCS L1000, GeneWays yielded ~15.5k claims and ~6.8k interactions for analysis. Downstream predictive models using features derived from GeneWays extractions achieved AUCs up to 0.77 for predicting claim correctness conditional on non-neutral interactions, and ~0.67 AUC for Bayesian inference of interaction direction, demonstrating utility of extracted relations for predicting experimental replication rather than discovery of quantitative equations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>GeneWays is a symbolic/grammar-based IE system (not an LLM); it extracts directional relations but does not produce quantitative equations. Coverage tradeoffs: higher precision but more constrained recall compared to other extractors; only abstracts used to reduce citation/reiteration noise; mapping to LINCS excludes interactions not present in the experiment. The system extracts categorical directional claims (positive/negative) and is not designed for distilling continuous empirical laws or mathematical relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Compared against Literome (an independent extraction pipeline using distant supervision / Markov Logic). GeneWays is described as more accurate (much higher precision) but more constrained; where datasets overlap, moderate agreement observed. Downstream, both extractors' outputs were used and validated against LINCS experimental data and ML baselines (logistic regression, random forests) to evaluate predictive signal.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prediction of robust scientific facts from literature', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5941.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5941.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Literome</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Literome</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated, PubMed-scale genomic knowledge-base extraction system that uses distant supervision (Markov Logic) to extract gene-gene relations from biomedical text; used here to produce a large set of directed gene interaction claims for analysis and validation against LINCS L1000.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Literome (Markov Logic / distant supervision pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large-scale information extraction pipeline built using distant supervision with Markov Logic (statistical relational learning) that parses abstracts into clauses, extracts biological entities and directed relationships from co-presence within parsed phrases, and filters via correspondence to annotated datasets (e.g., GENIA). Not a transformer LLM; uses probabilistic logic-based IE; reported precision in this paper is lower (~25%).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Biomedical genetics — large-scale extraction of gene/gene-product interaction claims from MEDLINE abstracts at PubMed scale.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>MEDLINE abstracts (~220k gene-related articles in the Literome source); yields hundreds of thousands of claims before filtering. Filtering: analysis limited to abstract-extracted claims; strong positive bias in extracted claims (~98% positive). After merging with LINCS L1000, resulting dataset used for downstream modeling contained ~50.5k claims and ~25.4k interactions for Literome.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Distant supervision using Markov Logic / statistical relational learning to label and extract relations from parsed clauses, followed by mapping to existing annotated datasets (GENIA) for filtering. Aggregation of extracted categorical directional relations across papers used as inputs to ML models and Bayesian inference. No methodology for discovering continuous empirical equations or mathematical laws reported.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_law_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>example_law_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Intrinsic precision estimate reported (~25% in this paper), assessment of positivity bias in extracted claims, and external validation by aligning Literome-extracted claims with experimental regulatory interaction strengths from LINCS L1000. Downstream predictive performance reported (AUCs up to ~0.74 for claim correctness conditional on non-neutral interactions; Bayesian inference AUC ~0.63 for inferring direction).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Literome produced a large, high-recall set of gene-gene directional claims with lower precision (reported ~25%). When merged with LINCS L1000 experimental data, Literome-supported models showed predictive signal for claim correctness and experimental alignment, though performance lagged GeneWays on precision-sensitive tasks. The system did not produce quantitative mathematical relationships; its output are categorical directional claims used to predict experimental replication.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Low precision relative to GeneWays (~25%), strong positive-bias in extracted claims (~98% positive), and extraction limited to categorical directional labels (positive/negative) rather than continuous quantitative relationships or equations. Mapping to experimental data excludes non-overlapping interactions; the system is not designed to discover or distill empirical mathematical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Compared to GeneWays: Literome is less precise but higher-coverage/less constrained. Both systems produced largely independent datasets with moderate agreement where overlapping; downstream comparisons performed via predictive ML models and validation against LINCS experimental ground truth rather than against human-curated law-discovery systems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prediction of robust scientific facts from literature', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data <em>(Rating: 2)</em></li>
                <li>Literome: PubMed-scale genomic knowledge base in the cloud <em>(Rating: 2)</em></li>
                <li>MSR SPLAT, a language analysis toolkit <em>(Rating: 1)</em></li>
                <li>A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5941",
    "paper_id": "paper-207226d2b33cfef5288dac1c95d7baeb69729d4e",
    "extraction_schema_id": "extraction-schema-119",
    "extracted_data": [
        {
            "name_short": "GeneWays",
            "name_full": "GeneWays",
            "brief_description": "An automated information-extraction system that semantically parses biomedical text with a context-free grammar tuned to the biomedicine sublanguage to extract directed gene-gene relations (positive/negative). Used here to extract gene interaction claims from MEDLINE abstracts and produce a directed genetic graph for downstream analysis and validation against LINCS L1000.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GeneWays",
            "model_description": "A rule- and grammar-based semantic parser / information-extraction pipeline tailored to biomedical text. It identifies biological entities (genes/proteins) and verbs, parses sentences with a context-free grammar tuned to biomedical sublanguage, and projects extracted relations to simplified positive/negative directional actions. Not a large neural LLM; architecture is symbolic/grammar-based (precision reported high in this paper).",
            "task_domain": "Biomedical genetics — extraction of gene-gene regulatory interaction claims from scientific literature (MEDLINE abstracts).",
            "input_corpus_description": "Articles from MEDLINE (paper reports GeneWays derived from ~197k MEDLINE articles; analyses here restricted to claims extracted from abstracts resulting in tens of thousands of unique claims/interactions after filtering and merging with LINCS L1000). Filtering: only abstract-extracted claims kept, verbs projected to positive/negative, duplicates/contradictions within same paper discarded, merged to LINCS L1000 experimental interactions (~6.8K interactions after merge for GeneWays).",
            "distillation_method": "Symbolic information extraction using semantic parsing with a context-free grammar tuned to biomedical sublanguage; extracted directed relations (triplets: source gene, target gene, action) aggregated across papers. No fine-tuning of large neural LLMs reported; downstream uses include feature extraction for ML models and Bayesian inference, not equation discovery.",
            "quantitative_law_type": null,
            "example_law_extracted": null,
            "evaluation_method": "Intrinsic precision estimates reported (paper cites GeneWays precision ~95% in their evaluation), measurement of percent positive interactions, and external validation by aligning extracted claims to experimental ground truth from LINCS L1000 (aggregate z-scores transformed to (0,1) CDF). Subsequent predictive models (logistic regression, random forest) used to evaluate how extracted claims predict experimental outcomes (AUC reported for downstream tasks).",
            "results_summary": "GeneWays produced a high-precision set of gene-gene directed interaction claims drawn from MEDLINE abstracts (precision reported ~95% in paper). After merging with LINCS L1000, GeneWays yielded ~15.5k claims and ~6.8k interactions for analysis. Downstream predictive models using features derived from GeneWays extractions achieved AUCs up to 0.77 for predicting claim correctness conditional on non-neutral interactions, and ~0.67 AUC for Bayesian inference of interaction direction, demonstrating utility of extracted relations for predicting experimental replication rather than discovery of quantitative equations.",
            "limitations_challenges": "GeneWays is a symbolic/grammar-based IE system (not an LLM); it extracts directional relations but does not produce quantitative equations. Coverage tradeoffs: higher precision but more constrained recall compared to other extractors; only abstracts used to reduce citation/reiteration noise; mapping to LINCS excludes interactions not present in the experiment. The system extracts categorical directional claims (positive/negative) and is not designed for distilling continuous empirical laws or mathematical relationships.",
            "comparison_to_baselines": "Compared against Literome (an independent extraction pipeline using distant supervision / Markov Logic). GeneWays is described as more accurate (much higher precision) but more constrained; where datasets overlap, moderate agreement observed. Downstream, both extractors' outputs were used and validated against LINCS experimental data and ML baselines (logistic regression, random forests) to evaluate predictive signal.",
            "uuid": "e5941.0",
            "source_info": {
                "paper_title": "Prediction of robust scientific facts from literature",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "Literome",
            "name_full": "Literome",
            "brief_description": "An automated, PubMed-scale genomic knowledge-base extraction system that uses distant supervision (Markov Logic) to extract gene-gene relations from biomedical text; used here to produce a large set of directed gene interaction claims for analysis and validation against LINCS L1000.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Literome (Markov Logic / distant supervision pipeline)",
            "model_description": "A large-scale information extraction pipeline built using distant supervision with Markov Logic (statistical relational learning) that parses abstracts into clauses, extracts biological entities and directed relationships from co-presence within parsed phrases, and filters via correspondence to annotated datasets (e.g., GENIA). Not a transformer LLM; uses probabilistic logic-based IE; reported precision in this paper is lower (~25%).",
            "task_domain": "Biomedical genetics — large-scale extraction of gene/gene-product interaction claims from MEDLINE abstracts at PubMed scale.",
            "input_corpus_description": "MEDLINE abstracts (~220k gene-related articles in the Literome source); yields hundreds of thousands of claims before filtering. Filtering: analysis limited to abstract-extracted claims; strong positive bias in extracted claims (~98% positive). After merging with LINCS L1000, resulting dataset used for downstream modeling contained ~50.5k claims and ~25.4k interactions for Literome.",
            "distillation_method": "Distant supervision using Markov Logic / statistical relational learning to label and extract relations from parsed clauses, followed by mapping to existing annotated datasets (GENIA) for filtering. Aggregation of extracted categorical directional relations across papers used as inputs to ML models and Bayesian inference. No methodology for discovering continuous empirical equations or mathematical laws reported.",
            "quantitative_law_type": null,
            "example_law_extracted": null,
            "evaluation_method": "Intrinsic precision estimate reported (~25% in this paper), assessment of positivity bias in extracted claims, and external validation by aligning Literome-extracted claims with experimental regulatory interaction strengths from LINCS L1000. Downstream predictive performance reported (AUCs up to ~0.74 for claim correctness conditional on non-neutral interactions; Bayesian inference AUC ~0.63 for inferring direction).",
            "results_summary": "Literome produced a large, high-recall set of gene-gene directional claims with lower precision (reported ~25%). When merged with LINCS L1000 experimental data, Literome-supported models showed predictive signal for claim correctness and experimental alignment, though performance lagged GeneWays on precision-sensitive tasks. The system did not produce quantitative mathematical relationships; its output are categorical directional claims used to predict experimental replication.",
            "limitations_challenges": "Low precision relative to GeneWays (~25%), strong positive-bias in extracted claims (~98% positive), and extraction limited to categorical directional labels (positive/negative) rather than continuous quantitative relationships or equations. Mapping to experimental data excludes non-overlapping interactions; the system is not designed to discover or distill empirical mathematical laws.",
            "comparison_to_baselines": "Compared to GeneWays: Literome is less precise but higher-coverage/less constrained. Both systems produced largely independent datasets with moderate agreement where overlapping; downstream comparisons performed via predictive ML models and validation against LINCS experimental ground truth rather than against human-curated law-discovery systems.",
            "uuid": "e5941.1",
            "source_info": {
                "paper_title": "Prediction of robust scientific facts from literature",
                "publication_date_yy_mm": "2020-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data",
            "rating": 2
        },
        {
            "paper_title": "Literome: PubMed-scale genomic knowledge base in the cloud",
            "rating": 2
        },
        {
            "paper_title": "MSR SPLAT, a language analysis toolkit",
            "rating": 1
        },
        {
            "paper_title": "A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles",
            "rating": 1
        }
    ],
    "cost": 0.00931075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Detecting signal from science:
The structure of research communities and prior knowledge improves prediction of genetic regulatory experiments</p>
<p>Alexander V. Belikov ${ }^{1,2}$<br>Andrey Rzhetsky ${ }^{3,4}$<br>James Evans ${ }^{1,5}$</p>
<p>The explosive growth of scientists, scientific journals, articles and findings in recent years ${ }^{1,2}$ exponentially increases the difficulty scientists face in navigating prior knowledge and collectively reasoning over it to drive future advance ${ }^{3,4}$. This challenge is exacerbated by uncertainty about the reproducibility of published findings ${ }^{5-8}$. The availability of massive digital archives, machine reading and extraction tools on the one hand, and automated high-throughput experiments on the other, allow us to evaluate these challenges at scale and identify novel opportunities for accelerating scientific advance ${ }^{9}$. Here we demonstrate a Bayesian calculus that enables the positive prediction of robust, replicable scientific claims with findings automatically extracted from published literature on gene interactions. We matched these findings, filtered by science, with unfiltered gene interactions measured by the massive LINCS L1000 high-throughput experiment to identify and counteract sources of bias. Our calculus is built on easily extracted publication meta-data regarding the position of a scientific claim within the web of prior knowledge, and its breadth of support across institutions, authors and communities, revealing that scientifically focused but socially and institutionally independent research activity is most likely to replicate. This contrasts with the ineffectiveness of alternative strategies like "follow the leader"-trusting top journals and top scientists-which do not predict robust findings. These findings recommend policies that go against the common practice of channeling biomedical research funding into centralized research consortia and institutes rather than dispersing it more broadly. Our results demonstrate that robust scientific findings hinge upon a delicate balance of shared focus and independence, and that this complex pattern can be computationally exploited to decode bias and predict the replicability of published findings. These insights provide guidance for scientists navigating the research literature and for science funders seeking to improve it. Moreover, our project models an entirely machine-driven research pipeline, from machine reading to evaluation, that could be incorporated by intelligent algorithms to augment scientific search, recommending fruitful research hypotheses to accelerate cumulative scientific advance.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>Main</h1>
<p>Millions of research papers are published globally each year ${ }^{3,4}$, with nearly a million biomedical articles published and indexed in MEDLINE, and more than a hundred thousand that discuss genes and their biological interactions. Popular individual genetic pathways receive attention from thousands of papers. This deluge of information makes it very difficult for researchers and other audiences of science to decide what to trust-what insights will replicate and generalize beyond the particular experiment or observation from which they were initially demonstrated. More certainty about what findings to trust will allow us to better select useful signals from science that advance science and accelerate technology. Knowing what findings are robust will help scientists decide what to study next, policy-makers and philanthropists what to fund next, and institutes and technologists what next to develop as life-saving medical diagnostics and therapies. In this investigation, we ask how to predict certain signals from scientific publications. We further consider the implications of our predictions for how scientific institutions might be reformed to improve those signals. Subjective bias is an inevitable reality of published science. Accurate and robust insight about nature is only one of several factors scientists consider as they undertake research and publish findings. They must also strategically think about scientific influence and academic survival. What would be theoretically significant, what will attract attention and what can inspire scientists to build on their work in future? What will journal editors and reviewers allow ${ }^{10}$ ? What will patrons fund? What will promotion committees accept? Beyond complex motivations, scientists, their experiments and observations are situated in particular positions with respect to their objects of study, which defy detached and universal notions of objectivity ${ }^{11}$ and necessarily shape their assessments. Scientists foster expectations inculcated from disciplinary education and prior experience ${ }^{12}$, and they rationally incorporate the beliefs of those they trust-respected mentors and colleagues-into their own scientific expectations and certainties ${ }^{6}$. These contextual forces add noise to the signal about what findings will replicate and generalize, above and beyond the complexity involved in deciphering experimental and observational protocols from ambiguous language.</p>
<p>Above the level of the scientist, the modern scientific system promulgates predictable bias. Competition between journals makes it far easier to publish positive findings than neutral or 'negative' ones ${ }^{1,2}$, which become underrepresented in the published record ${ }^{5}$. Moreover, favorable conditions for the "wisdom of crowds" phenomenon ${ }^{13}$, where collectives produce systematically more accurate estimates than individuals, are widely violated in science. Crowds are wise when their members have access to independent data ${ }^{14}$ or utilize independent methods ${ }^{15}$ to derive their answers, but they falter when engaged in centralized communication ${ }^{16,17}$ and share prior experience, knowledge, and methods ${ }^{9}$. By contrast, the modern life sciences are characterized by intensive and repeated collaboration ${ }^{18-20}$, increasingly large ${ }^{21,22}$ and distributed teams ${ }^{23}$, star scientists ${ }^{24,25}$, canonical citations ${ }^{26,27}$ and expensive shared equipment ${ }^{18,20}$.</p>
<p>These forces have led to widespread concerns regarding the reliability and reproducibility of findings in fields ranging from pharmacology ${ }^{7,28,29} 5$ and genetics ${ }^{5,30-323,4}$ to psychology ${ }^{33,34}$ with widespread implications for the accumulation of certainty in science. Some have even feared that distortions associated with publication and confirmation bias could lead to the canonization of false facts ${ }^{10}$. This is a problem for scientists, but also science as a system of insights on which future innovation relies. Prior work has attempted to identify the robust replicability of the scientific literature and identify sources of</p>
<p>distortion that might weaken the signal of science through simulation ${ }^{10,35,36}$, experiments ${ }^{33,37}$, and meta-analysis of prior results ${ }^{9,38}$. Psychologists have called efforts to replicate the robust essence of an experiment with an alternative research design and methods a "conceptual replication" ${ }^{39}$. Here we build on that work by demonstrating an automated research pipeline that (1) extracts gene-gene interaction claims from the biomedical literature, then (2) aligns them for conceptual replication with results from the massively replicated LINCS L1000 high-throughput experiment (Fig. 1), (3) identifies factors that increase and decrease the likelihood of replication and (4) updates our understanding and scientific certainty through a Bayesian calculus (Fig. 2). Finally, we use the results of our investigation (Fig. 3) to identify opportunities that could redesign scientific institutions and investigations for accelerated advance (Fig. 4).</p>
<p>A number of scientific and social factors could influence the likelihood that a claim is robust and generalizes. Two important classes of factors involve (1) how a claim fits into prior knowledge about nature and (2) its breadth of prior support. We may investigate how a claim fits with preexisting knowledge by assessing its position in the complex network of other scientific claims. A claim may be central or peripheral in the network, and entire claim networks may be decentralized or hierarchical, controlled through a small number of central nodes like the CEO of a corporation. New scientific claims about the influence of central nodes, such as genes at the center of a genetic regulatory network, will be more plausible than claims about peripheral genes for which we have no prior signals of influence. A claim's plausibility may also be affected by its position in the macro-structure of the network. If a claim about a genetic influence pathway is embedded within a large, dense cluster of claims about related interactions, the structure and direction of those interactions may logically and physically constrain the direction of the focal claim ${ }^{6}$, which might help researchers triangulate the correct, robust claim. The presence of other researchers asking nearby questions might also socially discipline researchers to share their most robust results, as their work will receive scrutiny by contemporaries.</p>
<p>We may examine a scientific claim's breadth of prior support through evaluating the range researchers who have reiterated it and the depth of time over which a claim has been examined. Nevertheless, recent research has shown that the independence underlying a claims' support matters. More dependencies linking research that forwards a claim because they share authors, institutions, methods, or reference the same prior work decrease the replicability of that claim by outsiders ${ }^{9}$. Dense communities become scientific echo-chambers that drive out diverse perspectives ${ }^{40}$, ignoring dissent or precisely reproducing fragile experiments unlikely to generalize beyond the context of initial demonstration. In biomedicine, findings from dense social and methodological communities are less likely to become relevant to human health and enter the clinic as practical diagnostics or therapies. They have not yet received independent support. By contrast, if more, independent research communities support a scientific claim, it will more likely be robust and generalize because it already has.</p>
<p>Other features of apparent support also exist, most notably the authority of whether a finding was published in elite, high-impact journals, or was authored by scientists from elite, strong reputation schools. As our analysis below reveals, however, these status signals deceive and are not associated with robust replication.</p>
<h1>Automated Validation Pipelines</h1>
<p>In order to predict robust signals from published science, we must first extract claims from published literature. Many prominent efforts have manually extracted statements regarding specific biological and chemical interactions from the literature and aggregate them into publicly available databases, which include the Gene Ontology ${ }^{41}$, Comparative Toxicogenomics Database ${ }^{6}$, the American Chemical Society's CASREACT, and others. These projects take a crisp view of logical inference that does not directly account for history and uncertainty. In contrast, we deploy two algorithmic approaches built on distinct architectures, GeneWays ${ }^{7}$ and Literome ${ }^{8}$. The GeneWays system (portmanteau for genetics and pathways) semantically parses the biomedical literature. It first identifies biological substances and processes-nouns and verbs-then parses them with a context-free grammar tuned to the sublanguage of biomedicine ${ }^{42}$ that extracts direct and indirect relations yielding a graph with directed links from source to target. Proteins may bind, activate, inhibit, or unleash more specific properties (acetylate, methylate, phosphorylate) upon their targets ${ }^{43}$. We simplify these interactions into positive (e.g., 'activate', 'enhance', 'increase', 'promote', 'stimulate', '[over]produce', 'upregulate', etc.) and negative (e.g., 'inactivate', 'depress', 'limit', 'inhibit', 'constrain', 'hinder', and 'downregulate', etc.) Literome inverts the GeneWays pipeline and begins by parsing articles into dependent clauses ${ }^{44}$, then extracts biological entities, including genes and proteins. From co-presence within parsed phrases, Literome identifies directed relationships and then filters these by their correspondence to existing gene relationships from the annotated GENIA dataset ${ }^{45}$. "Gene" in this context is used as a shorthand for "gene or gene product", especially in reference to the action source, and henceforth we adopt this abbreviation.</p>
<p>For both datasets, we limited examination of claims extracted from article abstracts to increase the likelihood that they were not merely reiterated, but empirically demonstrated in the associated article. The GeneWays and Literome approaches and associated gene-gene interaction datasets were derived from overlapping collections of gene-related articles present in MEDLINE (GeneWays 197K, Literome 220K). GeneWays and Literome precision is evaluated as $95 \%$ and $25 \%$, their percentage of positive interactions $96 \%$ and $77 \%$, as shown in Fig. 1, panels a and b. In summary, GeneWays is more accurate, and Literome less constrained: GeneWays and Literome yield directed genetic graphs with 5141 genes involved in 23405 interactions, 10703 genes engaged in 144172 interactions, respectively, yielding an overlap of 4516 genes, but only 6516 overlapping interactions. We perform all of our analyses on both, independently derived datasets.</p>
<p>Next, we derive specific measures associated with how a claim fits into preexisting knowledge about genetic interactions and its breadth of support from article data and meta-data, as illustrated in Fig. 3 and detailed in the supplement. We measure each genetic regulatory interaction's position within preexisting knowledge by (1) the centrality of its gene source and target, as well as (2) the partition size of which it is a member, derived from dense connection among all published genetic claims. We measure the breadth of each interaction's support by the (1) the density of articles published on it each year, (2) number of years over which it has been investigated, (3) number of collaborative communities investigating it, (4) absolute size of the particular community engaged in making each interaction claim, and (5) size of that community relative to others that investigate it. We also derive measures capturing the reputation of the institution hosting the underlying research and the journal publishing the claim, and a number of related variables.</p>
<p>We merged these findings with the massively high-throughput NIH Library of Integrated Network-Based Cellular Signatures (LINCS) L1000 experiment that perturbs 77 distinct cell lines with several different perturbation types, such as cDNA for overexpression of wild-type gene for 5.8 K genes ${ }^{46}$. Gene overexpression is a technique that utilizes expression vectors to force high levels of a gene's coding sequence. The resultant effect is high steady state mRNA levels and high steady state protein levels. This enables a vast gene-gene causal experiment: if one gene product is increased and it consistently leads to the increase or reduction in another gene across cell lines, perturbagens, dosage and time, which suggests that the over-expressed gene has a consistent and likely causal association with the other. We compute the mean z -score across experiments for genetic regulatory interactions and transform to $(0,1)$ with the normal cumulative density function, denoting this the average experimental strength of the interaction.</p>
<h1>Bayesian Signals from Science</h1>
<p>We predict scientific certainty and the class of an interaction (neutral, positive or negative) through a Bayesian calculus built atop established statistical and machine learning methods that incorporate the features capturing position within pre-existing knowledge and depth of prior support described above. Some features occur at the level of the genetic regulatory interaction (e.g., position of source and target genes within the network of prior knowledge or the number of research communities publishing on the interaction). Others occur at the level of the published claim (e.g., size of the research community publishing a particular paper about the interaction). All of these features vary with time. We use these features to predict the robust, aggregate results of LINCS L1000 experiments pertaining to the same source and target gene across distinct trials, dosages, tissues and durations.</p>
<p>Cross-tabulation between the value of published claims and the average LINCS L1000 experimental results highlights a contrast. Claims in the biomedical literature tend to be either positive or negative, with a strong positive bias. The distribution of experimental interactions does not share this bias, normally distributed and varying smoothly from negative to positive, peaked and centered at 0.5 , indicating a "neutral", inconsistent or nonexistent interaction between those genes. The contrast between published finding and experimental data suggests the extent of the file drawer problem in science where scientists euphemistically "file", but do not publish negative or inconclusive results ${ }^{47,48}$. We note that the correlation between published and experimental results increases markedly as we consider more popular interactions (see Extended Data Fig. 1). These observations led us to partition experimental interactions into 3 categories: neutral, positive and negative. First, we build models to predict the neutrality of an interaction (see SI). Second, we built models to predict whether positive and negative published claims correctly align with positive and negative experimental interactions. We separately built logistic regression and random forest models to estimate the influence of each feature on each outcome. Logistic regressions provide us with interpretable directional estimates, but assume conditional independence between features. Random forests provide us with better estimates of each feature's importance, but reduce interpretability by allowing nonlinear feature interactions. The most important features regarding how a claim fits into the fabric of prior knowledge and its breadth of prior support are defined in Fig.4; for others see Supplementary Information.</p>
<p>Once each claim's correctness is estimated, we can infer the direction of the underlying genetic interaction using Bayes formula, derived under the assumption of conditional independence of claims and the independence of correctness from interaction positivity (see Methods and SI).</p>
<h1>Predicting Claim Accuracy and Interactions</h1>
<p>We evaluate our genetic predictions from distributions of Receiver Operator Curves (ROCs) and the area under those curves (AUCs) presented in Fig.2. Our model of whether a published claim links to a non-neutral genetic interaction, as assessed across the wide range of LINCS experiments, betrays the difficulty of that task (average $\mathrm{AUC}=0.58$ for GeneWays on 6.8 K interactions, $\mathrm{AUC}=0.54$ for Literome on 25.4 K interactions). The most important feature for identifying non-neutral interactions is notable, however: the degree of the source gene in the network of prior published knowledge, reinforcing our understanding of hierarchical genetic regulation. The more central the source gene, the more likely it controls other genes.</p>
<p>Our model of whether a published claim correctly identifies the direction of a genetic interaction, conditional on the interaction not being neutral, is much more powerful ( $\mathrm{AUC}=0.77$ for GeneWays on 580 interactions, $\mathrm{AUC}=0.74$ for Literome on 1090 interactions), strongly influenced by both the position of the claim within prior knowledge and its breadth of support (Fig.3). The feature manifesting most predictive power is the size of the partition of published genetic effects that surround the interaction in question. Its positive influence suggests that the structure and direction of nearby interactions may guide researchers to the correct conclusion ${ }^{6}$. The relevance of the claim to researchers working nearby will also increase competition and anticipated scrutiny.</p>
<p>The next most important class of influences are the historical depth and breadth of support. Greater depth and breadth of investigation, absolute size of the relevant research community, and the number of communities studying the claim are associated with empirical correctness. By contrast, empirical incorrectness is correlated with higher relative community size and our index tracing author, institutional and prior knowledge dependencies. Greater relative size indicates that the majority of scientific activity comes from one or a few communities and when the dependency index is high, authors, institutions and citations densely link published claims. Together, these findings reinforce that a lack of social and theoretical independence between claims should reduce our confidence in them and paint a consistent picture of the importance of balanced, independent investigation for scientific certainty.</p>
<p>Using Bayesian inference, we apply these estimates to infer the direction of any given genetic interaction. Our out of sample predictions demonstrate substantially greater signal than random regarding the robust direction of a genetic interaction ( $\mathrm{AUC}=0.67$ for GeneWays; $\mathrm{AUC}=0.63$ for Literome). These models are less predictive than our models predicting accurate research claims because of inequality in research attention, collectively focused on a few, popular interactions. While scientific certainty about any particular interaction might be satisfied with a moderate number of replications, the inequality of research attention and activity are more likely to furnish the $100^{\text {th }}$ replication of a popular claim than the $2^{\text {nd }}$ of an unpopular one, despite the drop in information this entails for science as a system.</p>
<h2>Policies to Optimize Scientific Certainty</h2>
<p>Our findings suggest scientific policies to increase collective certainty across scientific claims, here evaluated in the context of genetic regulatory interactions. We design one statistical experiment to manipulate the distribution of independent communities examining a research claim and another to manipulate the distribution of claims across interactions, examining their effects on the correctness of all scientific inferences about genetic regulatory interaction. For a research funder like the U.S. National Institutes of Health (NIH) to influence the number of communities studying a specific topic would require them simply to prefer the social, institutional and intellectual independence of each new investigation they fund. For the NIH to broaden the distribution of claims across interactions would require them merely to prefer research on new topics. We demonstrate predictively that such policies, if implemented, could increase correct identification of the direction of genetic regulatory interaction as measured by the AUC of our model.</p>
<p>For the first statistical experiment, we divide interactions from the test sample into disjoint groups by the number of communities or author clusters that publish on them. For the subset of positive and negative interactions we (1) split the dataset into training and testing samples, (2) build the model of claim correctness, then using Bayesian inference (3) predict model certainty for groups of interactions having 1, $2,3,4$ or more communities in the test sample. The top of Fig. 4 shows that a greater number of communities has a profound, positive effect on the distributions of AUCs for interaction positivity. The more communities studying an interaction, the better we can infer correct insight from the resulting corpus of research.</p>
<p>For the second statistical experiment, we artificially shift the distribution of claim numbers by sampling interactions according to the number of times on which each is published. Specifically, we (1) fix time $t$ for all interactions in the sample and consider only claims published before $t$, (2) prepopulate the sample with $\sim 20 \%$ of claims in chronological order, and then (3) repopulate the sample with claims (and thus interactions), year by year, until each interaction contains the complete history of observed claims. In Fig.4c we present two synthetic examples of claim number distribution. The claim number distribution can be approximated with a power law, with density function proportional to the number of interactions having a given number of claims about them raised to the power of some exponent, where lower values correspond to flatter distributions. We demonstrate that flatter claim number distributions, where scientific attention is spread more widely across genetic regulatory interactions, correspond to significantly higher AUCs predicting accurate interactions (increases of $0.03 \pm 0.003$ for GeneWays and $0.007 \pm 0.002$ for Literome).</p>
<h1>Amplifying Signal from Science</h1>
<p>The deluge of published scientific information available to 21 st Century researchers, funders, inventors and developers has overwhelmed their capacity to account for all of the signals available from science in their efforts to innovate. Challenges associated with information overload are exacerbated in research about entire scientific systems, such as the regulatory interactions between all human genes as we study here. In such settings, knowledge is necessarily uneven and investing against our ignorance will multiply the value of those investments for broad scientific understanding. In this paper, we demonstrate how the emergence of massive digital archives, machine reading and information extraction tools, alongside automated experiments can help us identify and amplify the signal from science by predicting the</p>
<p>robustness of scientific claims. This project represents the first automated, machine-driven pipeline of which we are aware that reads scientific research papers, extracts information about scientific claims, aligns them high-throughput experiments, and provides a Bayesian update of that knowledge. Our approach takes into account a wide range of features including how claims fit within the web of prior understanding and their breadth of support. And this is precisely what individual scientific experts do when they critically evaluate the literature, based on deep, personal understanding of dynamics and reputations within their specific field, here scaled by machine to many overlapping areas of biomedicine beyond the scope of any single scientific reasoner.</p>
<p>Our models predict replication based on different sets of publications, read by different algorithms, but yield deep consistency regarding what predicts replication and what might be altered by science policy makers to improve the state of scientific knowledge. These findings in the context of human genetic regulatory interactions, however, reveal an essential tension in the undertaking of collective scientific investigation. Robust genetic regulatory interactions are predicted by many investigators devoted to studying popular genes, central in the network of scientific claims and embedded within dense areas of investigation. Nevertheless, greater independence between investigators, communities, institutions, and prior knowledge also dramatically increase claim robustness. This leads to a paradox for science policy. When scientists flock together by studying the same phenomenon it increases our collective understanding. When they flock together in their approach and collaborations, it decreases our collective understanding-it increases the illusion we know more than we do. Our policy experiments suggest if science policy and sponsorship take this tension seriously, they could dramatically increase the robustness of our collective understanding and accelerate innovation. When communities, people and approaches focused on a given genetic regulatory interaction are more diverse, their collective findings more likely converge to powerful estimates derived from massive, high-throughput experiments. On the other hand, when scientists spread out across the space of possible claims, our overall certainty about the entire, interacting system of gene regulation increases. This suggests that when an important scientific process or component merits scientific attention, sponsoring diversity in that attention may pay dividends in robust, replicable understanding. On the other hand, if we seek to gain understanding about the system as a whole, we also increase the signal from published science by sponsoring and rewarding more work on under-examined areas.</p>
<p>Our study has several natural limitations. Despite our replication of all findings with two different samples of research papers and claim extraction algorithms, our study nevertheless only explores claims about genetic interactions. Moreover, in order to evaluate those claims at scale, we only consider claims about regulatory interactions between pairs of genes. This excludes many other, meaningful interactions (e.g., methylation, phosphorylation). Both information extraction algorithms, GeneWays and Literome, had limitations described above, but they balanced one another in terms of precision and recall. Finally, the several linkages across datasets that facilitate our mapping of research claims to LINCS L1000 experimental results necessarily excluded interactions from the literature not present in the experiment and vice versa. To conclude, our analysis of observational data makes it impossible for us to make strong causal claims about the impact of reforming scientific institutions according to the suggestive patterns we document. Notwithstanding these limitations, all of which would have decreased the signal we might expect to isolate from scientific literature, we were able to predict the likelihood of conceptual replication</p>
<p>far above random and identify consistent patterns of focus and independence that, if enhanced, could substantially increase the signal from science.</p>
<h1>Methods</h1>
<h2>Information Extraction Algorithms</h2>
<p>GeneWays. This algorithm and associated database of automatically extracted claims ${ }^{43,49}$ contains approximately 496 K unique claims (aggregating so each claim is unique per publication) and approximately 313 K unique interactions (defined as a triplet including the source gene, target gene, and action, and where action is a verb that takes values including 'bind', 'interact', 'induce', 'associate', 'regulate', etc.) expressed in approximately 197 K publications from MEDLINE. Approximately $32 \%$ of our claims were extracted from abstracts. We found that claims in publication could either result from independent original research or simply reference a finding from a cited publication. The former were much more likely mentioned in the abstract, and so in our research we considered only claims extracted from abstracts. This operation leaves us with $\sim 172 \mathrm{~K}$ unique publication-claims and $\sim 130 \mathrm{~K}$ unique interactions from the abstracts of approximately $\sim 109 \mathrm{~K}$ unique publications.</p>
<p>A typical record in the GeneWays database has the form: abg prevents tert. To simplify the representation of interactions, we identify all such verbs that can be interpreted as positive or negative directional actions. As positive, we encode: "activate", "actuate", "cause", "control", "direct", "enhance", "facilitate", "force", "increase", "induce", "lead", "overproduce", "promote", "provoke", "stimulate", "transactivate", "trigger", "regulate", "produce", and "upregulate". As negative, we encode: "constrain", "degrade", "destroy", "downregulate", "hinder", "inactivate", "inhibit", "interrupt", "limit", "reduce", "repress", "shut", and "suppress". After projecting the interactions to positive or negative, we are left with $\sim 36 \mathrm{~K}$ unique interactions, $\sim 68.6 \mathrm{~K}$ unique claims from $\sim 51 \mathrm{~K}$ unique publications from PubMed.</p>
<p>For each attribute, Geneways contains a flag indicating whether the claim is negative, where $\sim 4 \%$ of claims are negative. According to logic, the negation of "a" increases "b" is the union of both "a" decreases "b" and "a" does not affect "b", non-interactions are never recorded and so we assume a positive interaction is the negation of a negative interaction and visa versa. If we encounter claims with respect to the same interaction extracted from the same paper that negate one another, we discard them. We retain claims from publications that present in our version of MEDLINE from 3K journals that we could identify using an available copy of the Web of Science database.
The final iteration has 23 K unique interactions, 44 K unique claims from 33 K unique publications.</p>
<h2>Literome</h2>
<p>Literome ${ }^{50}$ contains 144 K unique interactions, 259 K unique claims from 220 K unique publications extracted from MEDLINE abstracts by means of distant supervision via Markov Logic with an estimated precision of $25 \%$. We only consider claims extracted from the abstracts and note that Literome has a strong bias towards positive interactions ( $\sim 98 \%$ ). For the set of final models described in the articles, we exclude claims with respect to gene TP53 (Entrez id 7157) acting on CDKN1A (Entrez id 1026) because the 150 extracted claims on that interaction were all deemed incorrect or ambiguous as evaluated by a biomedical expert.</p>
<h1>Genetic Dataset from LINCS L1000</h1>
<p>We use the Library of Integrated Network-Based Cellular Signatures (LINCS) that was compiled using the Luminex bead technology called L1000 as the ground truth with respect to gene-gene interactions derived within the same context ${ }^{46}$. The experimental technique of LINCS L1000 is based on tracking gene expression, the procedure by which information from genes chemically perturbed in the experiment causes the synthesis of functional gene products, such as proteins, resulting in an altered cellular phenotype. We use the GSE92742 Level 5 version of LINCS L1000. Level 5 dataset contains signatures from aggregated replicates. The experiments are performed on 77 cell lines, using different perturbation types, durations and dosages. Multiple experiments are performed per combination of cell line, perturbation type, duration and dose. The result of an experiment is a z-score, which quantifies the expression of a particular gene under the action of a perturbagen, relative to the baseline experiment.</p>
<p>We aggregate the z-scores of experiments in the following manner: For a given cell line, perturbagen, dosage and duration we compute the mean value; then across cell lines, perturbagens, dosages and durations we take the maximum of the absolute value for a given interaction. The z-score is then transformed using normal cumulative density function (that takes values in $(0,1)$ ). We denote this $\hat{\pi}^{\alpha}$ and call it the experimental regulatory interaction strength.</p>
<p>For GeneWays, $40 \%$ of claims and $32 \%$ of interactions remain after merging with LINCS L1000 while for Literome, correspondingly 29 and $25 \%$. After merging GeneWays and Literome onto aggregated LINCS L1000 data we obtain 15.5 K and 50.5 K claims and 6.8 K and 25.4 K interactions, respectively. The overlap between GeneWays and Literome claims merged with LINCS L1000 is 2 K interactions ( $31 \%$ of all interactions iof GeneWays, $8 \%$ of all interactions of Literome) or 827 claims with correlation of the claim variable is .38 (representing $13 \%$ of GeneWays claims and $4 \%$ of Literome claims). The number of overlapping claims is greater than the number of overlapping interactions due to the majority of interactions being discussed in disjoint sets of publications between GeneWays and Literome. If we restrict the merged GeneWays-LINCS and Literome-LINCS datasets to the strongest positive and negative experimental regulatory interactions (intervals $(0,0.1]$ and $[0.9,1.0)$ on the interaction strength cdf) the overlap between GeneWays and Literome is 81 claims ( 34 interactions) with a correlation on the claim variable of .57 . We conclude that GeneWays and Literome datasets are significantly different, but in moderate agreement where they overlap, suggesting that they are largely independent sources of genetic regulatory interaction claims. We note that the distribution of number of claims per interaction follows Zipf's Law.</p>
<p>The correlation between regulatory interaction strength from LINCS L1000 and mean claim value from the literature is negligible, but increases as we introduce a threshold for the number of publications in which the claim appears (see Extended Data Table 1 and Fig. 1).</p>
<p>We define communities associated with each genetic regulatory interaction for claims made within a variety of fixed time intervals: the past $1,2,3$ and all years leading up to a given year. Each claim is made within a unique publication, and each paper is produced in an institutional, social and knowledge context, reflected by the multiple affiliations, authors, and references mentioned in that paper. Denote the set of affiliations (or authors or references) $V$, publications $U$, such that edges $(u, v)$ between members of these two sets form a bipartite graph, which we reduced to a weighted graph defined on the set of publications $U$, with weights proportional to the number of common affiliations. In every such local weighted graph of publications defined over a given time period (i.e., $1,2,3$, and all prior years), we identify communities using the information theoretically inspired Infomap algorithm ${ }^{51}$ and assign the number of communities, community size and community share for a given claim as derived features. Features deemed unimportant by our analysis (such as journal quality) are described in the SI and listed in Extended Data Table 2.</p>
<p>In order to classify (1) the neutrality of a genetic regulatory interaction, (2) the positivity (or negativity) of a regulatory interaction, and (3) the correctness of a claim, we used random forest and logistic regression models to enable both prediction and interpretation. While random forest allows us to reach near-maximal predictive performance, logistic regression enables the linear interpretation of features, rendering some effects positive and others negative. We choose models of optimal complexity and estimate metrics over the ensemble using procedures described in SI. In Fig. 3, features are presented pictorially with the highest Gini Importance or Mean Decrease in Impurity in the random forest model. Detailed methodology of feature importance calculation is located in the SI. Fig. 3 displays the Gini Importance or Mean Decrease in Impurity for each variable in the random forest model and associated coefficients from the logistic regression, plotted in decreasing importance for the Geneways random forest.</p>
<p>We used Python and scikit-learn for testing models, large scale computations were made possible thanks to CloudKotta infrastructure ${ }^{52}$.</p>
<h1>Acknowledgements</h1>
<p>We thank Vasili Sitnik, Valentin Danchev and Pedro Saleiro for fruitful discussions, Yadu Babuji for technical help, Hoifung Poon for suggestions regarding the formulation of the project, Ilya Mayzus, Rachel Melamed and Olga Kel-Margoulis for help with the annotation and the interpretation of biological datasets. We are grateful for comments from participants of the MetaScience Conference at Stanford, 2019, and for meetings associated with DARPA's Big Mechanism program. We acknowledge funding from DARPA (14145043, HR00111820006), the Air Force Office of Scientific Research (FA9550-19-1-0354, FA9550-15-1-0162), the National Science Foundation (SBE-1829366, 1422902, 1158803), and the John Templeton Foundation to the "Metaknowledge Network".</p>
<h2>Author contributions</h2>
<p>Alexander Belikov proposed and implemented the methodology, validated the model, analyzed the data and drafted the paper. James Evans was responsible for conception and funding of the project, contributed to the design of the methodology and drafted the paper. Andrey Rzhetsky provided feedback on the experimental work and data interpretation, and participated in drafting the paper. All authors read and approved the final manuscript.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig.1. Joint plot of the mean value of the claim (x-axis) and mean experimental interaction strength ( $\mathbf{y}$-axis). a, GeneWays (blue). b, Literome (red). More intense hues of the blue and red (and also greater marker size) correspond to the interactions with 10 or more claims per interaction; for less intense hues (and also smaller marker size) the cutoff is absent, representing the complete distribution.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig.2. Research design and prediction results. We first predicted the neutrality or non-neutrality of each gene-gene regulatory interaction. Then, if the interaction was deemed non-neutral, we predicted whether each claim (of positivity or negativity) from literature was correct. Finally, using Bayesian inference, as illustrated here and detailed in the methods section, we estimated the positive or negativity of genetic regulatory interactions. The ROC curves for the prediction models are blue for GeneWays and red for Literome. Mean ROC curves are in bold surrounded by a $95 \%$ c.i., with fainter individual lines corresponding to ROC curves for 60 models; 20 for each of 3 randomly drawn sets of non-overlapping interactions. All models were built from interactions not present in the test set on which ROC curves were evaluated.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig.3. Feature visualization and estimates from claim-level prediction models. a, illustrated relationship between genes engaged in regulatory interactions, the communities that research them, and the articles in which this research is published. Interactions cluster into partitions, researchers cluster into communities, and author teams publish articles within fixed periods. Together these structures are used to assess the position of a claim within pre-existing knowledge, the breadth of attention to a claim, and the independence of support for that claim. b,c Gini Importance or Mean Decrease in Impurity for features in the random forest models (left vertical scale, bold colors), and coefficients from the logistic regression models (right vertical scale, fainter colors) for GeneWays (b) and Literome (c). Vertical bars represent $95 \%$ c.i. for the mean value of the estimate. See Supplement for details about how specific operationalizations of each of these variables were selected as model features.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig.4. Science policy experiments revealing the relationship between community independence, collective attention, and certainty about genetic regulatory interactions. a, relationship between the number of communities studying a particular genetic regulatory interaction and the average AUC of out-of-sample predictions for positive interactions. b-c, distributions of the average AUC curves for GeneWays and Literome for interactions with 1, 2-3 and greater than 4 communities. e-f, relationship between the shape of the distribution of number of claims per interaction on the AUC of out-of-sample predictions for positive interactions. $\beta$ represents the slope of the claim number per interaction distribution for GeneWays (e) and Literome (f). g, two synthetic examples of claim number distributions, where these distributions can be approximated with power laws, proportional to the number of claims about an interaction raised to the power of some exponent $\delta$, such that lower values correspond to flatter distributions. In flatter claim number distributions, scientific attention spreads more widely across genetic regulatory interactions, which corresponds to significantly higher certainties (AUCs) of accurate interactions.</p>
<ol>
<li>Price, D. J. D. S. \&amp; De Solla Price, D. J. Little Science, Big Science. (1963) doi:10.7312/pric91844.</li>
<li>Bornmann, L. \&amp; Mutz, R. Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references. Journal of the Association for Information Science and Technology 66, 2215-2222 (2015).</li>
<li>Hey, T. \&amp; Trefethen, A. The data deluge: An e-science perspective. Grid computing: Making the global infrastructure a reality 809-824 (2003).</li>
<li>Bell, G., Hey, T. \&amp; Szalay, A. Computer science. Beyond the data deluge. Science 323, 1297-1298 (2009).</li>
<li>Ioannidis, J. P. A. Why most published research findings are false. PLoS Med. 2, e124 (2005).</li>
<li>Rzhetsky, A., Iossifov, I., Loh, J. M. \&amp; White, K. P. Microparadigms: chains of collective reasoning in publications about molecular interactions. Proc. Natl. Acad. Sci. U. S. A. 103, 4940-4945 (2006).</li>
<li>Prinz, F., Schlange, T. \&amp; Asadullah, K. Believe it or not: how much can we rely on published data on potential drug targets? Nat. Rev. Drug Discov. 10, 712-712 (2011).</li>
<li>Begley, C. G., Glenn Begley, C. \&amp; Ellis, L. M. Raise standards for preclinical cancer research. Nature vol. 483 531-533 (2012).</li>
<li>Danchev, V., Rzhetsky, A. \&amp; Evans, J. A. Centralized communities more likely generate non-replicable results. Elife (2019).</li>
<li>Nissen, S. B., Magidson, T., Gross, K. \&amp; Bergstrom, C. T. Publication bias and the canonization of false facts. Elife 5, (2016).</li>
<li>Daston, L. J. \&amp; Galison, P. Objectivity. (Zone Books, 2007).</li>
<li>Foreman, P. Weimar Culture, Causality and Quan-tum Theory 1918-1927. Hist. Stud. Phys. Biol. Sci. 3, 2-225 (1971).</li>
<li>Surowiecki, J. The wisdom of crowds: Why the many are smarter than the few and how collective</li>
</ol>
<p>wisdom shapes business. Economies, Societies and Nations 296, (2004).
14. Galton, F. Vox populi (the wisdom of crowds). Nature 75, 450-451 (1907).
15. Hong, L. \&amp; Page, S. E. Groups of diverse problem solvers can outperform groups of high-ability problem solvers. Proc. Natl. Acad. Sci. U. S. A. 101, 16385-16389 (2004).
16. Becker, J., Brackbill, D. \&amp; Centola, D. Network dynamics of social influence in the wisdom of crowds. Proc. Natl. Acad. Sci. U. S. A. 114, E5070-E5076 (2017).
17. Lorenz, J., Rauhut, H., Schweitzer, F. \&amp; Helbing, D. How social influence can undermine the wisdom of crowd effect. Proceedings of the national academy of sciences 108, 9020-9025 (2011).
18. Hicks, D. M. \&amp; Katz, J. S. Where is science going? Sci. Technol. Human Values 21, 379-406 (1996).
19. Guimerà, R., Uzzi, B., Spiro, J. \&amp; Amaral, L. A. N. Team assembly mechanisms determine collaboration network structure and team performance. Science 308, 697-702 (2005).
20. Hand, E. 'Big science' spurs collaborative trend. Nature vol. 463 282-282 (2010).
21. Wuchty, S., Jones, B. F. \&amp; Uzzi, B. The increasing dominance of teams in production of knowledge. Science 316, 1036-1039 (2007).
22. Wu, L., Wang, D. \&amp; Evans, J. A. Large teams develop and small teams disrupt science and technology. Nature (2019) doi:10.1038/s41586-019-0941-9.
23. Jones, B. F., Wuchty, S. \&amp; Uzzi, B. Multi-university research teams: shifting impact, geography, and stratification in science. Science 322, 1259-1262 (2008).
24. Merton, R. K. The Matthew Effect in Science: The reward and communication systems of science are considered. Science 159, 56-63 (1968).
25. Azoulay, P., Stuart, T. \&amp; Wang, Y. Matthew: Effect or Fable? Manage. Sci. 60, 92-109 (2014).
26. Evans, J. A. Electronic publication and the narrowing of science and scholarship. Science 321, 395-399 (2008).
27. Simkin, M. V. \&amp; Roychowdhury, V. P. Do Copied Citations Create Renowned Papers? Annals of</p>
<p>Improbable Research vol. 11 24-27 (2005).
28. Mullard, A. Reliability of 'new drug target' claims called into question. Nat. Rev. Drug Discov. 10, $643-644(2011)$.
29. Freedman, L. P. \&amp; Gibson, M. C. The impact of preclinical irreproducibility on drug development. Clin. Pharmacol. Ther. 97, 16-18 (2015).
30. Ioannidis, J. P., Ntzani, E. E., Trikalinos, T. A. \&amp; Contopoulos-Ioannidis, D. G. Replication validity of genetic association studies. Nat. Genet. 29, 306-309 (2001).
31. Hirschhorn, J. N., Lohmueller, K., Byrne, E. \&amp; Hirschhorn, K. A comprehensive review of genetic association studies. Genet. Med. 4, 45-61 (2002).
32. Lohmueller, K. E., Pearce, C. L., Pike, M., Lander, E. S. \&amp; Hirschhorn, J. N. Meta-analysis of genetic association studies supports a contribution of common variants to susceptibility to common disease. Nat. Genet. 33, 177-182 (2003).
33. Open Science Collaboration. Estimating the reproducibility of psychological science. Science 349, (2015).
34. Van Bavel, J. J., Mende-Siedlecki, P., Brady, W. J. \&amp; Reinero, D. A. Contextual sensitivity in scientific reproducibility. Proc. Natl. Acad. Sci. U. S. A. 113, 6454-6459 (2016).
35. Zollman, K. J. S. The Communication Structure of Epistemic Communities. Philos. Sci. 74, 574-587 (2007).
36. Payette, N. Agent-Based Models of Science. in Models of Science Dynamics: Encounters Between Complexity Theory and Information Sciences (eds. Scharnhorst, A., Börner, K. \&amp; van den Besselaar, P.) 127-157 (Springer Berlin Heidelberg, 2012).
37. Baker, M. Biotech giant publishes failures to confirm high-profile science. Nature 530, 141 (2016).
38. Borenstein, M., Hedges, L. V., Higgins, J. P. T. \&amp; Rothstein, H. R. Introduction to Meta-Analysis. (John Wiley \&amp; Sons, 2011).</p>
<ol>
<li>Nussbaum, D. The role of conceptual replication. Psychologist 25, 350 (2012).</li>
<li>Sunstein, C. R. Republic.com. (Princeton University Press, 2001).</li>
<li>Harris, M. A. et al. The Gene Ontology (GO) database and informatics resource. Nucleic Acids Res. 32, D258-61 (2004).</li>
<li>Friedman, C., Kra, P. \&amp; Rzhetsky, A. Two biomedical sublanguages: a description based on the theories of Zellig Harris. J. Biomed. Inform. 35, 222-235 (2002).</li>
<li>Rzhetsky, A. et al. GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data. J. Biomed. Inform. 37, 43-53 (2004).</li>
<li>Quirk, C. et al. MSR SPLAT, a language analysis toolkit. in Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstration Session 21-24 (Association for Computational Linguistics, 2012).</li>
<li>Kim, J.-D., Ohta, T., Pyysalo, S., Kano, Y. \&amp; Tsujii, J. Overview of BioNLP'09 shared task on event extraction. in Proceedings of the BioNLP 2009 workshop companion volume for shared task 1-9 (2009).</li>
<li>Subramanian, A. et al. A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles. Cell 171, 1437-1452.e17 (2017).</li>
<li>Rosenthal, R. The file drawer problem and tolerance for null results. Psychol. Bull. 86, 638 (1979).</li>
<li>Scargle, J. D. Publication Bias (The 'File-Drawer Problem') in Scientific Inference. arXiv [physics.data-an] (1999).</li>
<li>Rzhetsky, A. Geneways for Biocomputing. (2006) doi:10.21236/ada459874.</li>
<li>Poon, H., Quirk, C., DeZiel, C. \&amp; Heckerman, D. Literome: PubMed-scale genomic knowledge base in the cloud. Bioinformatics 30, 2840-2842 (2014).</li>
<li>
<p>Rosvall, M. \&amp; Bergstrom, C. T. Maps of random walks on complex networks reveal community structure. Proc. Natl. Acad. Sci. U. S. A. 105, 1118-1123 (2008).</p>
</li>
<li>
<p>Babuji, Yadu N, Chard K., Gerow A., Eamon Duede, Cloud Kotta: Enabling Secure and Scalable Data Analytics in the Cloud, IEEE International Conference on Big Data, 302- 310 (2016).</p>
</li>
</ol>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Knowledge Lab \&amp; Department of Sociology, University of Chicago; ${ }^{2}$ Hello Watt, Paris; ${ }^{3}$ Departments of Medicine and Human Genetics, University of Chicago; ${ }^{4}$ Institute for Genomic and Systems Biology, University of Chicago; ${ }^{5}$ Santa Fe Institute. Correspondence should be addressed to belikov@uchicago.edu or jevans@uchicago.edu.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>