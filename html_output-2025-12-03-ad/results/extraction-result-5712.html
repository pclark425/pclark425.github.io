<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5712 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5712</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5712</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-116.html">extraction-schema-116</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <p><strong>Paper ID:</strong> paper-266551357</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.15006v2.pdf" target="_blank">Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities</a></p>
                <p><strong>Paper Abstract:</strong> This study critically evaluates the efficacy of prompting methods in enhancing the mathematical reasoning capability of large language models (LLMs). The investigation uses three prescriptive prompting methods - simple, persona, and conversational prompting - known for their effectiveness in enhancing the linguistic tasks of LLMs. We conduct this analysis on OpenAI's LLM chatbot, ChatGPT-3.5, on extensive problem sets from the MATH, GSM8K, and MMLU datasets, encompassing a broad spectrum of mathematical challenges. A grading script adapted to each dataset is used to determine the effectiveness of these prompting interventions in enhancing the model's mathematical analysis power. Contrary to expectations, our empirical analysis reveals that none of the investigated methods consistently improves over ChatGPT-3.5's baseline performance, with some causing significant degradation. Our findings suggest that prompting strategies do not necessarily generalize to new domains, in this study failing to enhance mathematical performance.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5712.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5712.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baseline prompt (no prescriptive prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard interaction format used as control: submit the question input and obtain the model output without any preceding prescriptive prompt. Serves as the comparison point for all evaluated prompting methods in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset: 12,500 diverse mathematical problems (algebra, calculus, geometry, number theory, statistics) with full step-by-step solutions as ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Baseline: <input, output> — question presented directly without additional priming or persona instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>no effect (reference)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Baseline accuracy used as reference to quantify effects of other prompting formats.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5712.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baseline prompt (no prescriptive prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard interaction format used as control: submit the question input and obtain the model output without any preceding prescriptive prompt. Serves as the comparison point for all evaluated prompting methods in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K: ~8.5k grade-school math word problems with natural language and a final numeric solution.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Baseline: <input, output> — question presented directly without additional priming or persona instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>no effect (reference)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Baseline accuracy used as reference to quantify effects of other prompting formats.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5712.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baseline prompt (no prescriptive prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard interaction format used as control: submit the question input and obtain the model output without any preceding prescriptive prompt. Serves as the comparison point for all evaluated prompting methods in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MMLU math categories: multiple-choice questions across math-related subjects (abstract algebra, college math, elementary math, high-school math) drawn from the MMLU benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Baseline: <input, output> — multiple-choice questions presented directly; model returns a response that is then parsed/graded.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>no effect (reference)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Baseline accuracy used as reference to quantify effects of other prompting formats.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5712.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Topic Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Topic-based simple prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that provides a topic hint (e.g., 'This is an algebra problem' or 'This is geometry') before presenting the math question to prime context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a topic hint to the conversation (<prompt, input, output>), where the prompt indicates the mathematical area of the upcoming question.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output> (no topic hint)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 26.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-3.28% accuracy (topic prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Authors hypothesized topic hints would nudge ChatGPT toward the right context, but observed a small decrease on MATH; suggests topic priming did not generalize across this dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>Although topic prompting decreased performance on MATH, it slightly improved accuracy on GSM8K and MMLU, indicating dataset-dependent effects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5712.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Topic Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Topic-based simple prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that provides a topic hint (e.g., 'This is an algebra problem' or 'This is geometry') before presenting the math question to prime context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a topic hint to the conversation (<prompt, input, output>), where the prompt indicates the mathematical area of the upcoming question.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 84.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+2.0% accuracy (topic prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Topic hints slightly improved performance on GSM8K, suggesting topic priming can help on some word-problem formats.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>This benefit did not generalize to MATH where performance decreased.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5712.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Topic Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Topic-based simple prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that provides a topic hint (e.g., 'This is an algebra problem' or 'This is geometry') before presenting the math question to prime context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a topic hint to the conversation (<prompt, input, output>), where the prompt indicates the mathematical area of the upcoming question.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 80.2%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+0.7% accuracy (topic prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Slight improvement observed on MMLU, indicating topic preconditioning can benefit multiple-choice math tasks, though effects are small.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>Not universally beneficial: decreased performance on MATH dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5712.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Difficulty Prompting (Difficult)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Difficulty-based simple prompting (labelled 'Difficult')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that tells the model the upcoming question is difficult, intended to bias model confidence/approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a difficulty label ('Difficult') before the question to influence perceived difficulty and model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 27.4%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-1.8% accuracy (Difficult prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Telling the model a question is difficult did not improve performance; authors suggest biasing confidence from the start does not reliably alter correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5712.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Difficulty Prompting (Difficult)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Difficulty-based simple prompting (labelled 'Difficult')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that tells the model the upcoming question is difficult, intended to bias model confidence/approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a difficulty label ('Difficult') before the question to influence perceived difficulty and model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 76.2%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-5.8% accuracy (Difficult prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Difficulty prompting reduced GSM8K performance substantially; authors interpret that labeling affects the internal approach but not beneficially.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5712.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Difficulty Prompting (Difficult)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Difficulty-based simple prompting (labelled 'Difficult')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that tells the model the upcoming question is difficult, intended to bias model confidence/approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a difficulty label ('Difficult') before the question to influence perceived difficulty and model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 82.5%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+3.0% accuracy (Difficult prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>On MMLU, labeling questions as 'Difficult' produced a modest improvement; authors note dataset-dependent sensitivity to such labels.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5712.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Difficulty Prompting (Easy)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Difficulty-based simple prompting (labelled 'Easy')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that tells the model the upcoming question is easy, intended to bias model confidence/approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a difficulty label ('Easy') before the question to influence perceived difficulty and model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 29.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-0.27% accuracy (Easy prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>no meaningful effect (slight reduction)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Marking a problem as easy produced negligible change on MATH.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5712.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Difficulty Prompting (Easy)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Difficulty-based simple prompting (labelled 'Easy')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that tells the model the upcoming question is easy, intended to bias model confidence/approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a difficulty label ('Easy') before the question to influence perceived difficulty and model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 77.6%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-4.4% accuracy (Easy prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Labeling problems 'Easy' did not help on GSM8K and reduced performance, showing reverse of intended effect.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e5712.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Difficulty Prompting (Easy)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Difficulty-based simple prompting (labelled 'Easy')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt that tells the model the upcoming question is easy, intended to bias model confidence/approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: prepend a difficulty label ('Easy') before the question to influence perceived difficulty and model behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 78.1%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-1.4% accuracy (Easy prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>On MMLU, marking as 'Easy' slightly reduced performance; no consistent benefit across datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e5712.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Calculation Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Calculation-oriented simple prompting ('behave as an accurate calculator')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt instructing ChatGPT to act as an accurate calculator and perform precise calculations for the upcoming problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: tell the model to behave as an accurate calculator before presenting the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 26.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-2.45% accuracy (calculation prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Directing the model to act as a calculator did not improve MATH performance; may encourage skipping reasoning steps required for complex problems.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>On MMLU there was no meaningful change (+0.2%), but GSM8K saw a large deterioration, indicating inconsistent effects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e5712.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Calculation Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Calculation-oriented simple prompting ('behave as an accurate calculator')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt instructing ChatGPT to act as an accurate calculator and perform precise calculations for the upcoming problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: tell the model to behave as an accurate calculator before presenting the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 51.2%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-30.87% accuracy (calculation prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (large reduction)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Instructing the model to be a calculator produced severe degradation on GSM8K; authors suggest that such instructions may change the model's internal process unfavorably for word-problem reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e5712.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Calculation Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Calculation-oriented simple prompting ('behave as an accurate calculator')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple prompt instructing ChatGPT to act as an accurate calculator and perform precise calculations for the upcoming problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompting: tell the model to behave as an accurate calculator before presenting the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 79.7%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+0.2% accuracy (calculation prompt vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>no meaningful effect</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Calculation prompting had negligible effect on MMLU multiple-choice performance, again showing dataset-dependent outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e5712.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>High-Confidence Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (high-confidence persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting where the model is instructed to adopt a high-confidence, expert-like persona prior to answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: set a persona ('high confidence/expert') before the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 31.6%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+2.4% accuracy (high-confidence persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>High-confidence persona improved MATH performance modestly; authors hypothesize adopting a credible persona can bias model to produce more truthful/accurate responses in some settings.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>High-confidence persona degraded performance on GSM8K and MMLU, showing non-generalizable effects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.16">
                <h3 class="extraction-instance">Extracted Data Instance 16 (e5712.16)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>High-Confidence Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (high-confidence persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting where the model is instructed to adopt a high-confidence, expert-like persona prior to answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: set a persona ('high confidence/expert') before the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 74.1%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-7.9% accuracy (high-confidence persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>High-confidence persona reduced GSM8K performance; authors suggest persona biases may cause different reasoning heuristics that harm word-problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.17">
                <h3 class="extraction-instance">Extracted Data Instance 17 (e5712.17)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>High-Confidence Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (high-confidence persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting where the model is instructed to adopt a high-confidence, expert-like persona prior to answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: set a persona ('high confidence/expert') before the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 62.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-17.5% accuracy (high-confidence persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Despite improving MATH slightly, high-confidence persona substantially degraded MMLU performance; shows persona effects are not reliably beneficial across formats.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.18">
                <h3 class="extraction-instance">Extracted Data Instance 18 (e5712.18)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Low-Confidence Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (low-confidence persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting where the model is instructed to adopt a low-confidence persona prior to answering, to test influence of expressed confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: set a persona ('low confidence') before the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 27.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-2.2% accuracy (low-confidence persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Low-confidence persona consistently resulted in poor performance; suggests reducing model-assertiveness harms answer correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.19">
                <h3 class="extraction-instance">Extracted Data Instance 19 (e5712.19)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Low-Confidence Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (low-confidence persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting where the model is instructed to adopt a low-confidence persona prior to answering, to test influence of expressed confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: set a persona ('low confidence') before the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 58.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-24.0% accuracy (low-confidence persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (large)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Low-confidence persona caused large reductions, indicating lowering expressed confidence may disrupt the model's reasoning pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.20">
                <h3 class="extraction-instance">Extracted Data Instance 20 (e5712.20)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Low-Confidence Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (low-confidence persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting where the model is instructed to adopt a low-confidence persona prior to answering, to test influence of expressed confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: set a persona ('low confidence') before the question (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 74.1%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-5.4% accuracy (low-confidence persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Degradation on MMLU further supports conclusion that low-confidence personas are generally detrimental to mathematical answer accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.21">
                <h3 class="extraction-instance">Extracted Data Instance 21 (e5712.21)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>No-Explanation Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (no-explanation persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting instructing the model not to provide step-by-step explanations, only final answers, to reduce hallucinations and erroneous reasoning trails.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: instruct the model to provide no explanations and only final answers (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 22.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-6.47% accuracy (no-explanation persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (substantial)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Authors hypothesized removing explanations would reduce hallucinations, but results show dramatic drop; they conclude bypassing step-by-step reasoning causes skipping of important workflow leading to wrong answers.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.22">
                <h3 class="extraction-instance">Extracted Data Instance 22 (e5712.22)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>No-Explanation Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (no-explanation persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting instructing the model not to provide step-by-step explanations, only final answers, to reduce hallucinations and erroneous reasoning trails.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: instruct the model to provide no explanations and only final answers (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 18.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-63.2% accuracy (no-explanation persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (very large)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Removing explanations catastrophically reduced GSM8K performance; suggests that stepwise reasoning is essential for solving these word problems.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.23">
                <h3 class="extraction-instance">Extracted Data Instance 23 (e5712.23)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>No-Explanation Persona</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Persona prompting (no-explanation persona)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Persona prompting instructing the model not to provide step-by-step explanations, only final answers, to reduce hallucinations and erroneous reasoning trails.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Persona prompting: instruct the model to provide no explanations and only final answers (<prompt, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 20.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-58.7% accuracy (no-explanation persona vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (very large)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Large drop indicates that forcing omission of explanations prevents useful internal reasoning chains, harming accuracy even in multiple-choice settings.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.24">
                <h3 class="extraction-instance">Extracted Data Instance 24 (e5712.24)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Casual Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (casual preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where a casual, out-of-domain chat is used to precondition the model before asking the math question.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a casual pre-chat before presenting the mathematical question (two-shot/sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 29.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-0.2% accuracy (casual conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>no meaningful effect</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Casual preconditioning had negligible effect on MATH, indicating casual tone does not reliably prime mathematical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.25">
                <h3 class="extraction-instance">Extracted Data Instance 25 (e5712.25)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Casual Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (casual preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where a casual, out-of-domain chat is used to precondition the model before asking the math question.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a casual pre-chat before presenting the mathematical question (two-shot/sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 72.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-9.2% accuracy (casual conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Casual preconditioning reduced GSM8K performance, suggesting conversational tone can alter reasoning adversely for word problems.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.26">
                <h3 class="extraction-instance">Extracted Data Instance 26 (e5712.26)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Casual Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (casual preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where a casual, out-of-domain chat is used to precondition the model before asking the math question.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a casual pre-chat before presenting the mathematical question (two-shot/sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 82.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+3.3% accuracy (casual conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Surprisingly, casual conversations improved MMLU performance modestly; authors note out-of-domain preconditioning can sometimes benefit multiple-choice tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.27">
                <h3 class="extraction-instance">Extracted Data Instance 27 (e5712.27)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Math Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (math-focused preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where the model is engaged in a short math-focused dialogue before presenting the target question to precondition its internal context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a math-focused pre-conversation (two-shot / domain-focused sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 30.4%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+1.2% accuracy (math-conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Math-focused preconditioning slightly improved MATH performance; authors interpret that domain-specific sequential cues can prime internal state.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.28">
                <h3 class="extraction-instance">Extracted Data Instance 28 (e5712.28)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Math Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (math-focused preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where the model is engaged in a short math-focused dialogue before presenting the target question to precondition its internal context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a math-focused pre-conversation (two-shot / domain-focused sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 54.0%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-28.0% accuracy (math-conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (large)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Although math preconditioning helped MMLU (see entry), it severely degraded GSM8K; authors emphasize that guided sequential prompting effects differ across datasets and can harm performance.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.29">
                <h3 class="extraction-instance">Extracted Data Instance 29 (e5712.29)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Math Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (math-focused preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where the model is engaged in a short math-focused dialogue before presenting the target question to precondition its internal context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a math-focused pre-conversation (two-shot / domain-focused sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 91.3%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+11.8% accuracy (math-conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved (substantial)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Math conversation produced the only large, significant improvement (on MMLU); authors caution that this improvement did not generalize to GSM8K and therefore is dataset-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>Large improvement on MMLU but large degradation on GSM8K is a counterexample to generalizability of this format.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.30">
                <h3 class="extraction-instance">Extracted Data Instance 30 (e5712.30)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Physics Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (physics-focused preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where the model is engaged in a physics-focused dialogue prior to receiving the math question, representing out-of-domain but technical preconditioning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>MATH dataset problem solving with stepwise solutions expected.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a physics-focused pre-conversation (two-shot / domain-focused sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 28.2%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 29.20%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-1.07% accuracy (physics-conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (small)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Physics preconditioning produced a small reduction on MATH; out-of-domain technical preconditioning does not reliably help.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.31">
                <h3 class="extraction-instance">Extracted Data Instance 31 (e5712.31)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Physics Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (physics-focused preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where the model is engaged in a physics-focused dialogue prior to receiving the math question, representing out-of-domain but technical preconditioning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>GSM8K grade-school word problems requiring numeric answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a physics-focused pre-conversation (two-shot / domain-focused sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 74.5%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 82.00%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>-7.5% accuracy (physics-conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Physics preconditioning reduced GSM8K performance; authors note out-of-domain but technical prompts can still negatively affect word-problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5712.32">
                <h3 class="extraction-instance">Extracted Data Instance 32 (e5712.32)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Physics Conversation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conversational prompting (physics-focused preconditioning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversational prompting where the model is engaged in a physics-focused dialogue prior to receiving the math question, representing out-of-domain but technical preconditioning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MMLU (math categories)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple-choice math tasks from MMLU.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Conversational prompting: engage in a physics-focused pre-conversation (two-shot / domain-focused sequential conversation <P1, P2, input, output>).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Baseline: <input, output></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>accuracy: 84.8%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>baseline accuracy: 79.50%</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+5.3% accuracy (physics-conversation vs baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Physics preconditioning improved MMLU performance moderately, showing that even out-of-domain technical context can sometimes prime the model for better multiple-choice math performance.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities", 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Context-faithful prompting for large language models <em>(Rating: 2)</em></li>
                <li>Personas as a way to model truthfulness in language models <em>(Rating: 2)</em></li>
                <li>Mathematical capabilities of ChatGPT <em>(Rating: 2)</em></li>
                <li>Guiding AI with human intuition for solving mathematical problems in ChatGPT <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5712",
    "paper_id": "paper-266551357",
    "extraction_schema_id": "extraction-schema-116",
    "extracted_data": [
        {
            "name_short": "Baseline",
            "name_full": "Baseline prompt (no prescriptive prompt)",
            "brief_description": "Standard interaction format used as control: submit the question input and obtain the model output without any preceding prescriptive prompt. Serves as the comparison point for all evaluated prompting methods in this study.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset: 12,500 diverse mathematical problems (algebra, calculus, geometry, number theory, statistics) with full step-by-step solutions as ground truth.",
            "problem_format": "Baseline: &lt;input, output&gt; — question presented directly without additional priming or persona instructions.",
            "comparison_format": null,
            "performance": "accuracy: 29.20%",
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "no effect (reference)",
            "explanation_or_hypothesis": "Baseline accuracy used as reference to quantify effects of other prompting formats.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.0",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Baseline",
            "name_full": "Baseline prompt (no prescriptive prompt)",
            "brief_description": "Standard interaction format used as control: submit the question input and obtain the model output without any preceding prescriptive prompt. Serves as the comparison point for all evaluated prompting methods in this study.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K: ~8.5k grade-school math word problems with natural language and a final numeric solution.",
            "problem_format": "Baseline: &lt;input, output&gt; — question presented directly without additional priming or persona instructions.",
            "comparison_format": null,
            "performance": "accuracy: 82.00%",
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "no effect (reference)",
            "explanation_or_hypothesis": "Baseline accuracy used as reference to quantify effects of other prompting formats.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.1",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Baseline",
            "name_full": "Baseline prompt (no prescriptive prompt)",
            "brief_description": "Standard interaction format used as control: submit the question input and obtain the model output without any preceding prescriptive prompt. Serves as the comparison point for all evaluated prompting methods in this study.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "MMLU math categories: multiple-choice questions across math-related subjects (abstract algebra, college math, elementary math, high-school math) drawn from the MMLU benchmark.",
            "problem_format": "Baseline: &lt;input, output&gt; — multiple-choice questions presented directly; model returns a response that is then parsed/graded.",
            "comparison_format": null,
            "performance": "accuracy: 79.50%",
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "no effect (reference)",
            "explanation_or_hypothesis": "Baseline accuracy used as reference to quantify effects of other prompting formats.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.2",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Topic Prompting",
            "name_full": "Topic-based simple prompting",
            "brief_description": "A simple prompt that provides a topic hint (e.g., 'This is an algebra problem' or 'This is geometry') before presenting the math question to prime context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Simple prompting: prepend a topic hint to the conversation (&lt;prompt, input, output&gt;), where the prompt indicates the mathematical area of the upcoming question.",
            "comparison_format": "Baseline: &lt;input, output&gt; (no topic hint)",
            "performance": "accuracy: 26.0%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-3.28% accuracy (topic prompt vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Authors hypothesized topic hints would nudge ChatGPT toward the right context, but observed a small decrease on MATH; suggests topic priming did not generalize across this dataset.",
            "counterexample_or_null_result": "Although topic prompting decreased performance on MATH, it slightly improved accuracy on GSM8K and MMLU, indicating dataset-dependent effects.",
            "uuid": "e5712.3",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Topic Prompting",
            "name_full": "Topic-based simple prompting",
            "brief_description": "A simple prompt that provides a topic hint (e.g., 'This is an algebra problem' or 'This is geometry') before presenting the math question to prime context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Simple prompting: prepend a topic hint to the conversation (&lt;prompt, input, output&gt;), where the prompt indicates the mathematical area of the upcoming question.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 84.0%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "+2.0% accuracy (topic prompt vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Topic hints slightly improved performance on GSM8K, suggesting topic priming can help on some word-problem formats.",
            "counterexample_or_null_result": "This benefit did not generalize to MATH where performance decreased.",
            "uuid": "e5712.4",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Topic Prompting",
            "name_full": "Topic-based simple prompting",
            "brief_description": "A simple prompt that provides a topic hint (e.g., 'This is an algebra problem' or 'This is geometry') before presenting the math question to prime context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Simple prompting: prepend a topic hint to the conversation (&lt;prompt, input, output&gt;), where the prompt indicates the mathematical area of the upcoming question.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 80.2%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "+0.7% accuracy (topic prompt vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Slight improvement observed on MMLU, indicating topic preconditioning can benefit multiple-choice math tasks, though effects are small.",
            "counterexample_or_null_result": "Not universally beneficial: decreased performance on MATH dataset.",
            "uuid": "e5712.5",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Difficulty Prompting (Difficult)",
            "name_full": "Difficulty-based simple prompting (labelled 'Difficult')",
            "brief_description": "A simple prompt that tells the model the upcoming question is difficult, intended to bias model confidence/approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Simple prompting: prepend a difficulty label ('Difficult') before the question to influence perceived difficulty and model behavior.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 27.4%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-1.8% accuracy (Difficult prompt vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Telling the model a question is difficult did not improve performance; authors suggest biasing confidence from the start does not reliably alter correctness.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.6",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Difficulty Prompting (Difficult)",
            "name_full": "Difficulty-based simple prompting (labelled 'Difficult')",
            "brief_description": "A simple prompt that tells the model the upcoming question is difficult, intended to bias model confidence/approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Simple prompting: prepend a difficulty label ('Difficult') before the question to influence perceived difficulty and model behavior.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 76.2%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-5.8% accuracy (Difficult prompt vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Difficulty prompting reduced GSM8K performance substantially; authors interpret that labeling affects the internal approach but not beneficially.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.7",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Difficulty Prompting (Difficult)",
            "name_full": "Difficulty-based simple prompting (labelled 'Difficult')",
            "brief_description": "A simple prompt that tells the model the upcoming question is difficult, intended to bias model confidence/approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Simple prompting: prepend a difficulty label ('Difficult') before the question to influence perceived difficulty and model behavior.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 82.5%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "+3.0% accuracy (Difficult prompt vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "On MMLU, labeling questions as 'Difficult' produced a modest improvement; authors note dataset-dependent sensitivity to such labels.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.8",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Difficulty Prompting (Easy)",
            "name_full": "Difficulty-based simple prompting (labelled 'Easy')",
            "brief_description": "A simple prompt that tells the model the upcoming question is easy, intended to bias model confidence/approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Simple prompting: prepend a difficulty label ('Easy') before the question to influence perceived difficulty and model behavior.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 29.0%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-0.27% accuracy (Easy prompt vs baseline)",
            "format_effect_direction": "no meaningful effect (slight reduction)",
            "explanation_or_hypothesis": "Marking a problem as easy produced negligible change on MATH.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.9",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Difficulty Prompting (Easy)",
            "name_full": "Difficulty-based simple prompting (labelled 'Easy')",
            "brief_description": "A simple prompt that tells the model the upcoming question is easy, intended to bias model confidence/approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Simple prompting: prepend a difficulty label ('Easy') before the question to influence perceived difficulty and model behavior.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 77.6%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-4.4% accuracy (Easy prompt vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Labeling problems 'Easy' did not help on GSM8K and reduced performance, showing reverse of intended effect.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.10",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Difficulty Prompting (Easy)",
            "name_full": "Difficulty-based simple prompting (labelled 'Easy')",
            "brief_description": "A simple prompt that tells the model the upcoming question is easy, intended to bias model confidence/approach.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Simple prompting: prepend a difficulty label ('Easy') before the question to influence perceived difficulty and model behavior.",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 78.1%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "-1.4% accuracy (Easy prompt vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "On MMLU, marking as 'Easy' slightly reduced performance; no consistent benefit across datasets.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.11",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Calculation Prompting",
            "name_full": "Calculation-oriented simple prompting ('behave as an accurate calculator')",
            "brief_description": "A simple prompt instructing ChatGPT to act as an accurate calculator and perform precise calculations for the upcoming problems.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Simple prompting: tell the model to behave as an accurate calculator before presenting the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 26.8%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-2.45% accuracy (calculation prompt vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Directing the model to act as a calculator did not improve MATH performance; may encourage skipping reasoning steps required for complex problems.",
            "counterexample_or_null_result": "On MMLU there was no meaningful change (+0.2%), but GSM8K saw a large deterioration, indicating inconsistent effects.",
            "uuid": "e5712.12",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Calculation Prompting",
            "name_full": "Calculation-oriented simple prompting ('behave as an accurate calculator')",
            "brief_description": "A simple prompt instructing ChatGPT to act as an accurate calculator and perform precise calculations for the upcoming problems.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Simple prompting: tell the model to behave as an accurate calculator before presenting the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 51.2%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-30.87% accuracy (calculation prompt vs baseline)",
            "format_effect_direction": "reduced (large reduction)",
            "explanation_or_hypothesis": "Instructing the model to be a calculator produced severe degradation on GSM8K; authors suggest that such instructions may change the model's internal process unfavorably for word-problem reasoning.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.13",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Calculation Prompting",
            "name_full": "Calculation-oriented simple prompting ('behave as an accurate calculator')",
            "brief_description": "A simple prompt instructing ChatGPT to act as an accurate calculator and perform precise calculations for the upcoming problems.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Simple prompting: tell the model to behave as an accurate calculator before presenting the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 79.7%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "+0.2% accuracy (calculation prompt vs baseline)",
            "format_effect_direction": "no meaningful effect",
            "explanation_or_hypothesis": "Calculation prompting had negligible effect on MMLU multiple-choice performance, again showing dataset-dependent outcomes.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.14",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "High-Confidence Persona",
            "name_full": "Persona prompting (high-confidence persona)",
            "brief_description": "Persona prompting where the model is instructed to adopt a high-confidence, expert-like persona prior to answering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Persona prompting: set a persona ('high confidence/expert') before the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 31.6%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "+2.4% accuracy (high-confidence persona vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "High-confidence persona improved MATH performance modestly; authors hypothesize adopting a credible persona can bias model to produce more truthful/accurate responses in some settings.",
            "counterexample_or_null_result": "High-confidence persona degraded performance on GSM8K and MMLU, showing non-generalizable effects.",
            "uuid": "e5712.15",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "High-Confidence Persona",
            "name_full": "Persona prompting (high-confidence persona)",
            "brief_description": "Persona prompting where the model is instructed to adopt a high-confidence, expert-like persona prior to answering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Persona prompting: set a persona ('high confidence/expert') before the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 74.1%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-7.9% accuracy (high-confidence persona vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "High-confidence persona reduced GSM8K performance; authors suggest persona biases may cause different reasoning heuristics that harm word-problem solving.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.16",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "High-Confidence Persona",
            "name_full": "Persona prompting (high-confidence persona)",
            "brief_description": "Persona prompting where the model is instructed to adopt a high-confidence, expert-like persona prior to answering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Persona prompting: set a persona ('high confidence/expert') before the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 62.0%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "-17.5% accuracy (high-confidence persona vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Despite improving MATH slightly, high-confidence persona substantially degraded MMLU performance; shows persona effects are not reliably beneficial across formats.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.17",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Low-Confidence Persona",
            "name_full": "Persona prompting (low-confidence persona)",
            "brief_description": "Persona prompting where the model is instructed to adopt a low-confidence persona prior to answering, to test influence of expressed confidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Persona prompting: set a persona ('low confidence') before the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 27.0%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-2.2% accuracy (low-confidence persona vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Low-confidence persona consistently resulted in poor performance; suggests reducing model-assertiveness harms answer correctness.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.18",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Low-Confidence Persona",
            "name_full": "Persona prompting (low-confidence persona)",
            "brief_description": "Persona prompting where the model is instructed to adopt a low-confidence persona prior to answering, to test influence of expressed confidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Persona prompting: set a persona ('low confidence') before the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 58.0%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-24.0% accuracy (low-confidence persona vs baseline)",
            "format_effect_direction": "reduced (large)",
            "explanation_or_hypothesis": "Low-confidence persona caused large reductions, indicating lowering expressed confidence may disrupt the model's reasoning pipeline.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.19",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Low-Confidence Persona",
            "name_full": "Persona prompting (low-confidence persona)",
            "brief_description": "Persona prompting where the model is instructed to adopt a low-confidence persona prior to answering, to test influence of expressed confidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Persona prompting: set a persona ('low confidence') before the question (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 74.1%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "-5.4% accuracy (low-confidence persona vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Degradation on MMLU further supports conclusion that low-confidence personas are generally detrimental to mathematical answer accuracy.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.20",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "No-Explanation Persona",
            "name_full": "Persona prompting (no-explanation persona)",
            "brief_description": "Persona prompting instructing the model not to provide step-by-step explanations, only final answers, to reduce hallucinations and erroneous reasoning trails.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Persona prompting: instruct the model to provide no explanations and only final answers (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 22.8%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-6.47% accuracy (no-explanation persona vs baseline)",
            "format_effect_direction": "reduced (substantial)",
            "explanation_or_hypothesis": "Authors hypothesized removing explanations would reduce hallucinations, but results show dramatic drop; they conclude bypassing step-by-step reasoning causes skipping of important workflow leading to wrong answers.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.21",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "No-Explanation Persona",
            "name_full": "Persona prompting (no-explanation persona)",
            "brief_description": "Persona prompting instructing the model not to provide step-by-step explanations, only final answers, to reduce hallucinations and erroneous reasoning trails.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Persona prompting: instruct the model to provide no explanations and only final answers (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 18.8%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-63.2% accuracy (no-explanation persona vs baseline)",
            "format_effect_direction": "reduced (very large)",
            "explanation_or_hypothesis": "Removing explanations catastrophically reduced GSM8K performance; suggests that stepwise reasoning is essential for solving these word problems.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.22",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "No-Explanation Persona",
            "name_full": "Persona prompting (no-explanation persona)",
            "brief_description": "Persona prompting instructing the model not to provide step-by-step explanations, only final answers, to reduce hallucinations and erroneous reasoning trails.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Persona prompting: instruct the model to provide no explanations and only final answers (&lt;prompt, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 20.8%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "-58.7% accuracy (no-explanation persona vs baseline)",
            "format_effect_direction": "reduced (very large)",
            "explanation_or_hypothesis": "Large drop indicates that forcing omission of explanations prevents useful internal reasoning chains, harming accuracy even in multiple-choice settings.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.23",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Casual Conversation",
            "name_full": "Conversational prompting (casual preconditioning)",
            "brief_description": "Conversational prompting where a casual, out-of-domain chat is used to precondition the model before asking the math question.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Conversational prompting: engage in a casual pre-chat before presenting the mathematical question (two-shot/sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 29.0%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-0.2% accuracy (casual conversation vs baseline)",
            "format_effect_direction": "no meaningful effect",
            "explanation_or_hypothesis": "Casual preconditioning had negligible effect on MATH, indicating casual tone does not reliably prime mathematical reasoning.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.24",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Casual Conversation",
            "name_full": "Conversational prompting (casual preconditioning)",
            "brief_description": "Conversational prompting where a casual, out-of-domain chat is used to precondition the model before asking the math question.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Conversational prompting: engage in a casual pre-chat before presenting the mathematical question (two-shot/sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 72.8%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-9.2% accuracy (casual conversation vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Casual preconditioning reduced GSM8K performance, suggesting conversational tone can alter reasoning adversely for word problems.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.25",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Casual Conversation",
            "name_full": "Conversational prompting (casual preconditioning)",
            "brief_description": "Conversational prompting where a casual, out-of-domain chat is used to precondition the model before asking the math question.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Conversational prompting: engage in a casual pre-chat before presenting the mathematical question (two-shot/sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 82.8%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "+3.3% accuracy (casual conversation vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Surprisingly, casual conversations improved MMLU performance modestly; authors note out-of-domain preconditioning can sometimes benefit multiple-choice tasks.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.26",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Math Conversation",
            "name_full": "Conversational prompting (math-focused preconditioning)",
            "brief_description": "Conversational prompting where the model is engaged in a short math-focused dialogue before presenting the target question to precondition its internal context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Conversational prompting: engage in a math-focused pre-conversation (two-shot / domain-focused sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 30.4%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "+1.2% accuracy (math-conversation vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Math-focused preconditioning slightly improved MATH performance; authors interpret that domain-specific sequential cues can prime internal state.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.27",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Math Conversation",
            "name_full": "Conversational prompting (math-focused preconditioning)",
            "brief_description": "Conversational prompting where the model is engaged in a short math-focused dialogue before presenting the target question to precondition its internal context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Conversational prompting: engage in a math-focused pre-conversation (two-shot / domain-focused sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 54.0%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-28.0% accuracy (math-conversation vs baseline)",
            "format_effect_direction": "reduced (large)",
            "explanation_or_hypothesis": "Although math preconditioning helped MMLU (see entry), it severely degraded GSM8K; authors emphasize that guided sequential prompting effects differ across datasets and can harm performance.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.28",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Math Conversation",
            "name_full": "Conversational prompting (math-focused preconditioning)",
            "brief_description": "Conversational prompting where the model is engaged in a short math-focused dialogue before presenting the target question to precondition its internal context.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Conversational prompting: engage in a math-focused pre-conversation (two-shot / domain-focused sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 91.3%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "+11.8% accuracy (math-conversation vs baseline)",
            "format_effect_direction": "improved (substantial)",
            "explanation_or_hypothesis": "Math conversation produced the only large, significant improvement (on MMLU); authors caution that this improvement did not generalize to GSM8K and therefore is dataset-dependent.",
            "counterexample_or_null_result": "Large improvement on MMLU but large degradation on GSM8K is a counterexample to generalizability of this format.",
            "uuid": "e5712.29",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Physics Conversation",
            "name_full": "Conversational prompting (physics-focused preconditioning)",
            "brief_description": "Conversational prompting where the model is engaged in a physics-focused dialogue prior to receiving the math question, representing out-of-domain but technical preconditioning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MATH",
            "task_description": "MATH dataset problem solving with stepwise solutions expected.",
            "problem_format": "Conversational prompting: engage in a physics-focused pre-conversation (two-shot / domain-focused sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 28.2%",
            "performance_comparison": "baseline accuracy: 29.20%",
            "format_effect_size": "-1.07% accuracy (physics-conversation vs baseline)",
            "format_effect_direction": "reduced (small)",
            "explanation_or_hypothesis": "Physics preconditioning produced a small reduction on MATH; out-of-domain technical preconditioning does not reliably help.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.30",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Physics Conversation",
            "name_full": "Conversational prompting (physics-focused preconditioning)",
            "brief_description": "Conversational prompting where the model is engaged in a physics-focused dialogue prior to receiving the math question, representing out-of-domain but technical preconditioning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "GSM8K",
            "task_description": "GSM8K grade-school word problems requiring numeric answers.",
            "problem_format": "Conversational prompting: engage in a physics-focused pre-conversation (two-shot / domain-focused sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 74.5%",
            "performance_comparison": "baseline accuracy: 82.00%",
            "format_effect_size": "-7.5% accuracy (physics-conversation vs baseline)",
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "Physics preconditioning reduced GSM8K performance; authors note out-of-domain but technical prompts can still negatively affect word-problem solving.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.31",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Physics Conversation",
            "name_full": "Conversational prompting (physics-focused preconditioning)",
            "brief_description": "Conversational prompting where the model is engaged in a physics-focused dialogue prior to receiving the math question, representing out-of-domain but technical preconditioning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT-3.5",
            "model_size": null,
            "task_name": "MMLU (math categories)",
            "task_description": "Multiple-choice math tasks from MMLU.",
            "problem_format": "Conversational prompting: engage in a physics-focused pre-conversation (two-shot / domain-focused sequential conversation &lt;P1, P2, input, output&gt;).",
            "comparison_format": "Baseline: &lt;input, output&gt;",
            "performance": "accuracy: 84.8%",
            "performance_comparison": "baseline accuracy: 79.50%",
            "format_effect_size": "+5.3% accuracy (physics-conversation vs baseline)",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Physics preconditioning improved MMLU performance moderately, showing that even out-of-domain technical context can sometimes prime the model for better multiple-choice math performance.",
            "counterexample_or_null_result": null,
            "uuid": "e5712.32",
            "source_info": {
                "paper_title": "Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Context-faithful prompting for large language models",
            "rating": 2,
            "sanitized_title": "contextfaithful_prompting_for_large_language_models"
        },
        {
            "paper_title": "Personas as a way to model truthfulness in language models",
            "rating": 2,
            "sanitized_title": "personas_as_a_way_to_model_truthfulness_in_language_models"
        },
        {
            "paper_title": "Mathematical capabilities of ChatGPT",
            "rating": 2,
            "sanitized_title": "mathematical_capabilities_of_chatgpt"
        },
        {
            "paper_title": "Guiding AI with human intuition for solving mathematical problems in ChatGPT",
            "rating": 1,
            "sanitized_title": "guiding_ai_with_human_intuition_for_solving_mathematical_problems_in_chatgpt"
        }
    ],
    "cost": 0.0235005,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities</p>
<p>Yuhao Chen 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Chloe Wong 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Hanwen Yang 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Juan Aguenza 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Sai Bhujangari 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Benthan Vu 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Xun Lei 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Amisha Prasad 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Manny Fluss 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Eric Phuong 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Minghao Liu 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Raja Kumar 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Vanshika Vats 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>James Davis 
University of California
1156 High St95064Santa Cruz, Santa CruzCAUnited States</p>
<p>Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities
BF13CDFAF1C504E23B72FE2873E71278
This study critically evaluates the efficacy of prompting methods in enhancing the mathematical reasoning capability of large language models (LLMs).The investigation uses three prescriptive prompting methods -simple, persona, and conversational prompting -known for their effectiveness in enhancing the linguistic tasks of LLMs.We conduct this analysis on OpenAI's LLM chatbot, ChatGPT-3.5, on extensive problem sets from the MATH, GSM8K, and MMLU datasets, encompassing a broad spectrum of mathematical challenges.A grading script adapted to each dataset is used to determine the effectiveness of these prompting interventions in enhancing the model's mathematical analysis power.Contrary to expectations, our empirical analysis reveals that none of the investigated methods consistently improves over ChatGPT-3.5'sbaseline performance, with some causing significant degradation.Our findings suggest that prompting strategies do not necessarily generalize to new domains, in this study failing to enhance mathematical performance.</p>
<p>Introduction</p>
<p>Large Language Models (LLM) have recently brought transformative advancements in the field of Natural Language Processing (NLP) [1][2][3] .Generative models such as Generative Pre-trained Transformer (GPT) 3 , Pathways Language Model (PaLM) 4 , and Large Language Model Meta AI (LLaMA) 5 , are trained with billions of parameters using terabytes of data, enabling them to have a deeper understanding of language and context, making them highly effective for a wide range of applications in NLP, robotics 6,7 , chat-bot 8 and medicine 9 .</p>
<p>ChatGPT 10 , a variant of GPT designed to interact with humans in a natural conversational manner, demonstrates remarkable proficiency in generating coherent responses, and effectively addressing intricate challenges.A growing body of research has underscored the significance of prompt engineering in enhancing these models' accuracy for specialized tasks [11][12][13] .This technique has been instrumental in refining ChatGPT's performance across various fields, including medical engineering 14 , programming 15 , and software design 16 .There exist various forms of prompting techniques such as providing the chatbot a personality 17 , guiding the context of the conversation relating to a specific field 18 , or giving it a sequential connection of ideas or concepts to guide response generation 19 .Although these methods have been shown to enhance language-related tasks, these improvements do not necessarily extend to areas where LLM inherently faces challenges, like complex mathematical problem-solving 20 .</p>
<p>In this work, we explore which prompting methods are most helpful in enhancing the mathematical problem-solving ability of large language models (LLM) i .We explore three broad categories -Simple, Persona, and Conversational -and ten specific prompting methods.We test these prompting methods on three different datasets, assessing accuracy on thousands of individual mathematical problems.Contrary to our expectations, we find that none of the evaluated prompting methods consistently enhance the mathematical problem-solving ability of ChatGPT.</p>
<p>A significant challenge in assessing the mathematical capabilities of LLM lies in the development of effective grading methodologies.Existing methods 19,21 predominantly rely on human evaluation to assess the accuracy and relevance of responses generated by these models.However, human evaluation poses limitations in terms of scalability.We create an automated grading script that is accurate and designed to minimize human intervention in the evaluation process.</p>
<p>The primary contribution of this paper is evidence that prompt engineering strategies do not necessarily generalize to new domains.Our careful evaluation of ten specific prompting methods on three datasets found that none consistently improved the math problem-solving capability of ChatGPT.</p>
<p>i We use ChatGPT-3.5 in our work.In this manuscript, the terms 'ChatGPT-3.5','ChatGPT', and 'chatbot' are used synonymously.</p>
<p>Methods</p>
<p>In our study, we use three datasets to evaluate three broad categories of prompting with ten specific prompts.An automated grading script called GPT-Grader is used to compute accuracy.</p>
<p>Datasets</p>
<p>We use existing datasets -MATH 22 , GSM8K 23 , and MMLU 24,25 -to evaluate ChatGPT's mathematical capabilities.The MATH dataset consists of 12,500 mathematics problems encompassing various types, including linear algebra, calculus, geometry, number theory, and statistics.Each problem comes with a full step-by-step solution as the ground truth.The GSM8K dataset comprises 8.5K high-quality, linguistically diverse grade school math word problems having natural language as well as a final numeric solution.The MMLU dataset, or Measuring Massive Multitask Language Understanding, covers 57 tasks, including elementary mathematics, United States history, computer science, and law.For our study, we only test ChatGPT on math-related categories, including abstract algebra, college mathematics, elementary mathematics, and high school mathematics.Notably, MMLU differs from the other two datasets in that it employs multiple-choice questions and expects one correct choice instead of short answers.</p>
<p>Prompting Methods</p>
<p>Prompting is simply giving an LLM inputs for the model to respond to prior to the actual question of interest 13 .We assess ChatGPT-3.5'sproficiency in mathematical reasoning by analyzing its accuracy in responding to math questions presented after a range of prompting techniques, including simple, persona, and conversational prompting.We design specific prompts within each category.The specific prompts used in our study are shown in Table 1 and an illustration of prompting workflow is provided in Fig. 1.</p>
<p>Simple Prompting</p>
<p>This approach includes prompting methods used to bias the chatbot at the start of the conversation.Our simple prompting approach analyzes topic-based, difficulty-based, and calculation-based prompting methods.In topic prompting, we provide topic-specific prompts in the hope of nudging ChatGPT towards the right context.We hypothesize that giving the chatbot a hint regarding the type of mathematical question we are about to ask (Math/Algebra/Geometry) helps it render accurate answers.With difficulty-based prompting we test whether ChatGPT's ability to respond correctly varies with respect to how easy or difficult we have told it the question is.This is done to see if biasing the confidence level from the start would affect ChatGPT's We initiate the conversation with ChatGPT using the defined prompts.We evaluate only the response to the subsequently asked mathematical question.</p>
<p>efficacy in giving the right answer.In calculation prompting, ChatGPT is directed to behave as an accurate calculator and calculate the given mathematical problem.</p>
<p>Persona Prompting</p>
<p>Persona prompting gives an LLM an identity or personality to adopt while generating the responses 26 .Joshi et al. 27 hypothesize that large models tend to generate truthful responses if they adopt a credible persona.A high-confidence persona is created in hopes of ChatGPT mimicking someone who performs above average.Online sources are from a wide array of expertise and backgrounds.The hope is that the LLM will seek credible resources after pre-affirming its decision-making.We also test a low-confidence persona and see if the chatbot's decision-making dwindles.</p>
<p>In initial tests we noted that LLMs often produce flawed reasoning and 'hallucinations' 28 , where it delivers varied responses with high confidence despite lower accuracy rates.We thus test whether instructing ChatGPT to condense its explanations would be beneficial.We ask the chatbot to assume a persona that does not give explanations.</p>
<p>Conversational Prompting</p>
<p>We test conversational prompting by engaging in a conversation with the chatbot to sequentially guide it by providing some context of our expected results, taking inspiration from context-faithful prompting 29 .Our motivation for prompting ChatGPT with initial two-shot conversations is to test whether it performs better when guided with sequential links of thoughts toward the right field of interest.The casual conversation starts with setting a casual tone for the chatbot.This choice is aimed at examining the bot's response behavior in a relaxed, conversational setting.For the more academically inclined conversations, we test mathematical and physics-focused conversations.In the former, the conversation encompasses a mathematical field and investigates whether ChatGPT is able to take the hints.The prompts are structured to initiate a discussion about math with the aim of pre-conditioning the internal state of the chatbot prior to asking the mathematical question.The physics-focused conversation provides a pre-condition distinct from the mathematics questions that we will subsequently pose to the bot.</p>
<p>Grading Methods</p>
<p>We develop a grading script, GPT-Grader, to auto-grade ChatGPT's response.Neither the datasets nor ChatGPT consistently provide answers in a format which allows easy direct comparison.An example from each dataset illustrating the difficulty is shown in Fig. 2. GPT-Grader uses a grading method customized for the ground truth format of each dataset.</p>
<p>Given the variability of the response format in the MATH dataset, we process the resulting responses to make them comparable.For example, the final response of 0.25 and ¼ mean the same thing.After obtaining ChatGPT's response to a problem from the MATH dataset, the GPT-Grader script first looks for a direct match between the solutions.In the absence of a match, it next calculates the numerical value of each solution and compares these answers.If a match still does not exist, GPT-Grader searches the entire ChatGPT response for the ground truth solution.This extraction is done with the help of RegEx and string slicing.If the solution is identified anywhere in the response, the script verifies that the match is embedded within a mathematical equation.</p>
<p>The MMLU dataset has a multiple-choice format for answers.ChatGPT does not provide a simple response, instead embedding the answer in a paragraph of text.Since the valid answers of A,B,C,D also appear in unrelated text strings, simple matching does not work well.Instead, GPT-Grader uses ChatGPT itself to parse the response.The script resets the history of ChatGPT and resubmits the solution to it, instructing the model to identify the letter answer within the solution and format it as response is provided or until eight unsuccessful attempts.Finally, once a response is obtained, the script compares it with the actual ground truth answer from the dataset.If the response matches the ground truth, it is marked as correct; otherwise, it is incorrect.</p>
<p>The grading approach for the GSM8K dataset also uses ChatGPT to help grade its own responses.Instead of requesting ChatGPT to format the solution as [A], [B], [C], or [D] in the second step, we provide the ground truth solutions and ChatGPT's solution to the model as a new query.We ask ChatGPT to verify the accuracy of the answer, parsing this new response using a methodology similar to MMLU evaluation.</p>
<p>To validate the performance of our grading methods, we conduct manual evaluations on a random sample of responses from each method.We find an error rate of 1.35% on the MATH dataset (16 errors out of 1187 result samples), 1.54% on GSM8K (131 errors out of 8500 result samples), and 0.47% on MMLU (4 errors out of 848 result samples).We consider the average error rate of less than 2% sufficient for this study.</p>
<p>Results and Discussion</p>
<p>To examine whether the given prompting techniques are effective, we assess the accuracy on the MATH, GSM8K, and MMLU datasets.Each prompting method (<prompt, input, output>) is compared with the baseline (<input, output>), with results provided in Table 2.A visualization of the change in accuracy is provided in Fig. 3.We do not observe consistently improved outcomes for any of the prompting methods tested.</p>
<p>Among the simple prompting methods, topic prompting shows a slight improvement on the GSM8K and MMLU datasets, but a decrease in accuracy on the MATH dataset.Difficulty prompting does not show any remarkable improvement compared to the baseline results.Asking ChatGPT to behave as an accurate calculator also does not show any enhancement.</p>
<p>In persona prompting, giving a low-confidence persona to the bot consistently results in poor performance.The highconfidence persona does show improvement on the MATH dataset, but degradation on the other tests.The no-explanation persona was hypothesized to improve performance by reducing hallucinations 28 and false reasoning patterns.Unfortunately, the results consistently show a dramatic drop in accuracy from the baseline.We conclude that bypassing step-by-step reasoning can cause the large model to skip important workflow, resulting in wrong answers.</p>
<p>Analyzing the results from the guided sequential conversational prompting experiments reveals varied outcomes across the datasets.The MMLU dataset exhibits a significant boost in accuracy when the chatbot was preconditioned to converse about math.However, the GSM8K dataset shows a significant reduction in the accuracy.If we had only tested the MMLU dataset, we might have concluded that this prompting method enhances the LLM's mathematical capability.Testing prompting strategies on multiple datasets appears to be important for verifying the generalizability of results.Interestingly the out-of-domain casual and physics-based conversation prompts also led to improvements on the MMLU dataset.</p>
<p>Past researches 17,27 indicate a beneficial influence of prompting on language tasks.However, our combined results on mathematical tasks do not find any of the tested prompting methods to provide consistent improvement.There are, of course, limitations to this finding.We test only one specific LLM, GPT-3.5, and other LLMs 4, 5 might behave differently.Similarly, we tested only ten specific prompts on only three specific datasets.Nevertheless, we believe these results show that prompting strategies do not necessarily generalize from one domain to another or even from one dataset to another within the same domain.Bars denote ∆ Accuracy, improvement or deterioration in the performance when using prompts with respect to the baseline.Notice that the only significant improvement from prompting was "Math Conversation" on the MMLU dataset.However this prompting method showed a significant degradation of performance on the GSM8K dataset.We conclude that none of the evaluated prompting methods provide generalizable gains on mathematical performance.</p>
<p>Conclusion</p>
<p>We test three prompting methods using ten specific prompts to determine if prompting enhances ChatGPT performance on mathematical tasks.Contrary to initial expectations, we find that none of the tested methods consistently improve results, sometimes improving accuracy on one dataset while degrading accuracy on another.Our findings suggest that prompting strategies do not necessarily generalize to new datasets and domains.</p>
<p>Figure 1 .
1
Figure 1.Illustration of prompting workflow: The figure presents an example each from (a) simple, (b) persona,and (c) conversational prompting methods.We initiate the conversation with ChatGPT using the defined prompts.We evaluate only the response to the subsequently asked mathematical question.</p>
<p>Figure 2 .
2
Figure 2. Examples of question-answer pairs in each datasets: The figure presents an example each from the (a) MATH, (b) MMLU, and (c) GSM8K datasets, along with their dataset provided ground truth answers (GT).Below each example is ChatGPT's response for comparison.Notice that ChatGPT's responses are neither straightforward nor completely aligned with the ground truth format.We thus need specially designed grading methods for evaluation of accuracy.</p>
<p>Figure 3 .
3
Figure 3. Visualization of change in accuracy: Baseline accuracy for each dataset is normalized to 0 (zero) on the y-axis.Bars denote ∆ Accuracy, improvement or deterioration in the performance when using prompts with respect to the baseline.Notice that the only significant improvement from prompting was "Math Conversation" on the MMLU dataset.However this prompting method showed a significant degradation of performance on the GSM8K dataset.We conclude that none of the evaluated prompting methods provide generalizable gains on mathematical performance.</p>
<p>Table 1 .
1
Ten specific prompts were used to test Simple, Persona and Conversational prompting methods.Here, P1 and P2 refer to two-shot prompts used to initiate chats in conversational prompting.
arXiv:2312.15006v2 [cs.AI] 20 Feb 2024</p>
<p>Table 2 .
2
Performance of prompting methods: The accuracy of each prompt is evaluated on the MATH, GSM8K, and MMLU datasets.Performance change from the baseline (∆ Dataset ) is also provided.Notice that results are inconsistent across datasets, with none of the prompting methods providing a reliable improvement in accuracy.
Prompting MethodsPromptsAccuracy (%) MATH ∆ MATH GSM8K ∆ GSM8K MMLU ∆ MMLUBaseline29.2082.0079.50Topic Prompt26.0-3.284.0+2.080.2+0.7Simple"Difficult" Prompt27.4-1.876.2-5.882.5+3.0Prompting"Easy" Prompt29.0-0.277.6-4.478.1-1.4Calculation Prompt26.8-2.451.2-30.879.7+0.2Persona PromptingHigh Confidence Low Confidence No Explanation31.6 27.0 22.8+2.4 -2.2 -6.474.1 58.0 18.8-7.9 -24.0 -63.262.0 74.1 20.8-17.5 -5.4 -58.7Conversational PromptingCasual Conversation Math Conversation Physics Conversation29.0 30.4 28.2-0.2 +1.2 -1.072.8 54.0 74.5-9.2 -28.0 -7.582.8 91.3 84.8+3.3 +11.8 +5.3
Author contributions statement Y.C., H.Y., M.L., and J.D. designed the study; J.A., B.V., S.B., C.W., X.L., A.P., M.F., E.P., and Y.C. ran experiments and evaluations; Y.C, C.W., H.Y., and A.P. wrote the first draft of the manuscript; V.V. developed tables and visual representations; V.V and R.K. reviewed, refined, and edited the final draft.7/7
H Naveed, arXiv:2307.06435A comprehensive overview of large language models. 2023arXiv preprint</p>
<p>J Devlin, M.-W Chang, K Lee, K Toutanova, Bert, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. 2018arXiv preprint</p>
<p>Improving language understanding by generative pre-training. A Radford, K Narasimhan, T Salimans, I Sutskever, 2018OpenAI</p>
<p>PaLM: Scaling language modeling with pathways. A Chowdhery, J. Mach. Learn. Res. 242023</p>
<p>LLaMA: Open and efficient foundation language models. H Touvron, arXiv:2302.139712023arXiv preprint</p>
<p>Progprompt: Generating situated robot task plans using large language models. I Singh, 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE2023</p>
<p>LLM-planner: Few-shot grounded planning for embodied agents with large language models. C H Song, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Task oriented conversational modelling with subjective knowledge. R Kumar, arXiv:2303.176952023arXiv preprint</p>
<p>Large language models in medicine. A J Thirunavukarasu, Nat. medicine. 291930-1940 (2023</p>
<p>. Openai, Chatgpt, 2023gpt-3.5-turbo-0301. Large language model</p>
<p>Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. D Baidoo-Anu, L O Ansah, J. AI. 72023</p>
<p>ChatGPT: Jack of all trades, master of none. J Kocoń, Inf. Fusion. 1018612023</p>
<p>Prompt engineering with ChatGPT: A guide for academic writers. L Giray, Annals Biomed. Eng. 2023</p>
<p>Prompt engineering as an important emerging skill for medical professionals: tutorial. B Meskó, J. Med. Internet Res. 25e506382023</p>
<p>Use chat gpt to solve programming bugs. N M S Surameery, M Y Shakor, Int. J. Inf. Technol. &amp; Comput. Eng. (IJITC). 2455-529032023</p>
<p>ChatGPT prompt patterns for improving code quality, refactoring, requirements elicitation, and software design. J White, S Hays, Q Fu, J Spencer-Smith, D C Schmidt, arXiv:2303.078392023arXiv preprint</p>
<p>Long time no see! open-domain conversation with long-term persona memory. X Xu, arXiv:2203.057972022arXiv preprint</p>
<p>Domain adaptation via prompt learning. C Ge, IEEE Transactions on Neural Networks Learn. Syst. 2023</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, Adv. Neural Inf. Process. Syst. 352022</p>
<p>Guiding AI with human intuition for solving mathematical problems in ChatGPT. I Poola, V Bo, Int. Journals Multidiscip. Res. Acad. 112023</p>
<p>S Frieder, arXiv:2301.13867Mathematical capabilities of ChatGPT. 2023arXiv preprint</p>
<p>Measuring mathematical problem solving with the MATH dataset. D Hendrycks, Neural Inf. Process. Syst. (NeurIPS). 2021</p>
<p>Training verifiers to solve math word problems. K Cobbe, arXiv:2110.141682021arXiv preprint</p>
<p>Measuring massive multitask language understanding. D Hendrycks, Proc. Int. Conf. on Learn. Represent. (ICLR). Int. Conf. on Learn. Represent. (ICLR)2021</p>
<p>Aligning AI with shared human values. D Hendrycks, Proc. Int. Conf. on Learn. Represent. (ICLR). Int. Conf. on Learn. Represent. (ICLR)2021</p>
<p>Persona-based conversational AI: State of the art and challenges. J Liu, C Symons, R Vatsavai, 10.1109/ICDMW58026.2022.001292022 IEEE International Conference on Data Mining Workshops (ICDMW). Los Alamitos, CA, USAIEEE Computer Society2022</p>
<p>N Joshi, J Rando, A Saparov, N Kim, H He, arXiv:2310.18168Personas as a way to model truthfulness in language models. 2023arXiv preprint</p>
<p>Siren's song in the AI ocean: A survey on hallucination in large language models. Y Zhang, arXiv:2309.012192023arXiv preprint</p>
<p>Context-faithful prompting for large language models. W Zhou, S Zhang, H Poon, M Chen, arXiv:2303.113152023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>