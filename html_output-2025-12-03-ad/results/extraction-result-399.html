<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-399 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-399</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-399</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-248496374</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2205.00445v1.pdf" target="_blank">MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning</a></p>
                <p><strong>Paper Abstract:</strong> Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced"miracle") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e399.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e399.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MRKL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modular Reasoning, Knowledge and Language (MRKL) system</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular neuro-symbolic architecture that composes large pretrained language models with external knowledge sources and discrete symbolic reasoning modules via a neural router, enabling extensible, interpretable, and up-to-date natural-language-based reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MRKL (Modular Reasoning, Knowledge and Language)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MRKL is a modular neuro-symbolic system whose core design is an extensible set of expert modules (neural and symbolic) plus a learned router that maps each incoming natural-language query to the expert(s) best suited to respond. Neural experts include general-purpose and specialized pretrained LMs; symbolic experts include calculators, converters, database/API connectors and other discrete reasoners. The router can return module outputs directly or chain them (multi-hop) by routing outputs to other experts. The system is designed for robust extensibility (add experts without retraining all modules), safe fallback to a general LM when no expert matches, interpretability via explicit module invocation, and access to dynamic/proprietary knowledge by calling external APIs or databases.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Discrete symbolic modules invoked as procedural/symbolic components: deterministic calculator(s) for arithmetic, currency converters, database/API calls, and other symbolic reasoners. Representations are conventional discrete procedural APIs or symbolic procedures (not differentiable); inputs to these modules are explicit, discrete arguments (operands, operation identifiers, API parameters) extracted from text.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Pretrained neural language models and neural router networks: a large transformer LM (Jurassic-1 family; experiments used J1-large 7B) as the general-purpose language backbone and smaller/specialized LMs as neural experts; the router is itself a neural model (prompt-tuned J1-large in experiments) trained to perform natural-language understanding and to extract module-specific arguments from text.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular architecture with an explicit neural router: the router (neural) classifies/decides which expert to call and extracts discrete, structured arguments for symbolic modules. Integration is not end-to-end differentiable across symbolic modules; instead modules are trained/implemented independently and the router is trained (via prompt-tuning and data augmentation) to produce correct calls/arguments. Module outputs can be composed by routing outputs to subsequent experts (chaining/compositional invocation). Training focuses on (1) independently training experts, (2) training/tuning the router (lightweight relative to LMs) using synthetic/augmented data to reliably extract discrete parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines robust language understanding from LMs with exactness and determinism of symbolic modules, producing: (1) reliable arithmetic and other discrete-reasoning results (errors only from argument extraction), (2) interpretability via explicit module invocation (e.g., 'calculator said so'), (3) access to current/proprietary knowledge by calling external APIs, (4) compositional multi-hop reasoning by chaining modules, and (5) robust extensibility where new capabilities can be added without retraining all components.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Natural-language-to-symbolic-argument extraction and symbolic arithmetic execution: single-operation and two-operation arithmetic problems phrased in many natural-language formats (varying digits vs words, formats, operator types, and number of digits), used to evaluate the router + calculator pipeline (Jurassic-X).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>High accuracy reported for router+calculator pipeline: in-distribution single-operation accuracy >99% when trained and evaluated on the same operation; generalization across many numbers of digits nearly perfect when trained on single-digit operands; two-operation experiments: 22 of 29 two-operation combinations achieved >90% accuracy on average across random splits. (Performance metrics reported as percent accuracy on test sets.)</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Not given as a strict numeric baseline in this paper; the paper contrasts LM-only approaches qualitatively and refers to GPT-3 results that degrade sharply with operand length (see referenced [2]), but does not provide a single unified numeric baseline for all experiments in this work. (null for strict numeric comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Strong generalization in many dimensions: (1) generalizes from single-digit training to multi-digit test operands (1–9 digits) for many operations; (2) cross-format generalization is typically strong (training on one phrasing often generalizes to multiple formats), although some formats (format 4, not phrased as a question) are harder; (3) cross-operation generalization often good (e.g., models trained on addition generalize well to subtraction and multiplication), with division being an exception; (4) models trained on single operations often generalize to two-operation expressions in most cases, with a few failure modes (add-mul, sub-mul, sub-div). The paper documents out-of-distribution tests (digits, wording, formats, operation mixes) and shows robust compositional generalization in many settings but identifies specific failure pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Improved interpretability: explicit invocation of symbolic modules provides human-understandable rationales (e.g., indicating that the calculator produced the numeric answer). The modular breakdown (which expert answered) acts as an explanatory signal. Because symbolic modules perform deterministic computations, their outputs are inherently explainable (the system can attribute subresults to specific module calls).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Key limitations highlighted: (1) the main failure mode is incorrect extraction of discrete arguments by the router, not the symbolic computation itself; training the router to extract arguments reliably requires careful data augmentation and evaluation; (2) some generalization failures (e.g., add-mul, sub-mul, sub-div templates, and format 4) indicate brittleness to certain phrasings or nested phrasing styles; (3) division generalizes poorly from other operations and vice versa; (4) the architecture shifts complexity to router training and engineering for module interfaces (no free lunch); (5) integration is not end-to-end differentiable across symbolic modules, which limits some learning paradigms.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Practical division-of-labor principle: the paper advocates a systems-oriented neuro-symbolic paradigm where neural LMs handle linguistic understanding, routing, and argument extraction, while symbolic/procedural modules handle discrete, deterministic reasoning and external knowledge access. The justification is pragmatic and engineering-driven (complementary strengths), rather than a formal mathematical theory; the framework emphasizes modularity, compositionality, and lightweight retraining of the router as core principles.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e399.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e399.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Jurassic-X</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Jurassic-X (AI21 Labs' MRKL implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An implementation of the MRKL architecture that couples AI21's Jurassic-1 family LMs (J1-large in experiments) with symbolic modules (calculator, APIs) via a learned router, and demonstrates robust natural-language-to-calculator argument extraction through prompt-tuning and data augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Jurassic-X (MRKL implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Jurassic-X is AI21 Labs' MRKL-system implementation used in experiments. It uses a J1-large transformer (7B parameters in reported experiments) as backbone and as the router (via prompt-tuning with 10 prompt tokens) to identify which expert to call and to extract discrete arguments for symbolic modules. The implementation includes a deterministic calculator module and is evaluated on many natural-language arithmetic formulations; training of the router relied on data augmentation from structured templates to achieve high reliability in argument extraction. System-level design emphasizes independent expert training and lightweight retraining of the router.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Same symbolic components as MRKL: a deterministic calculator module used to perform arithmetic (actual numeric computation is performed by the symbolic calculator), plus support for connecting to external APIs/databases (currency converters, proprietary data sources) as discrete procedural modules.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>J1-large transformer (7B) used with prompt-tuning (10 prompt tokens) to form the router and/or specialized neural experts; training used gradient-based optimization (prompt-tuning) with specified hyperparameters (learning rate lr=0.3, batch size 32, linear decay, occasional weight decay 0.001).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Router-based modular invocation: the prompt-tuned J1-large router maps NL inputs to module calls and extracts discrete parameters; once extracted, parameters are passed to the symbolic calculator (or other API) which executes deterministically. The integration is operational (API-style) rather than differentiable through symbolic modules. The router was trained using synthetic data augmentation from structured template spaces to ensure robust argument extraction across lexical/format variability.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Empirical emergent behavior includes near-perfect argument extraction in many settings leading to robust arithmetic correctness, strong compositional generalization to multi-operation expressions despite limited training coverage, and an interpretability benefit from explicit module calls. Jurassic-X also demonstrates robust extensibility: new modules can be added without retraining the entire LM backbone, only requiring router updates.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Natural-language arithmetic: mapping NL arithmetic questions to symbolic calculator calls (single-operation and two-operation problems across multiple phrasings, operand representations, and digit lengths). Evaluation measured percent accuracy on held-out and out-of-distribution test splits (digits, words, formats, operator types).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>Reported hybrid (router + calculator) results: in-distribution single-operation accuracy ≳99% for same-operation training/testing; successful generalization across operand digit lengths (1–9 digits) when trained on single-digit examples; in two-operation experiments, average accuracy exceeded 90% for 22 out of 29 formula types across random splits. Metrics reported as percent test-set accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>The paper reports that few-shot LM-only approaches (e.g., GPT-3 style) degrade with increased digit length and wording variability and that prompt-tuned Jurassic-X outperforms few-shot baselines in many settings, but exact unified numeric LM-only baselines for all experiments are not enumerated numerically in this paper (null for strict numeric comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Jurassic-X generalizes well in multiple OOD axes: digit-length generalization from single-digit training to multi-digit testing, lexical generalization (training on words generalizes to digits better than the inverse), format generalization across many phrasing templates, and generalization from single-operation training to many two-operation test problems, with documented exceptions. These properties were tested with out-of-distribution splits and random partitions of two-operation formulae.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Because the calculator executes deterministically and the router explicitly chooses and invokes that module, Jurassic-X can attribute outputs to module calls (e.g., 'used calculator to compute X'), providing traceable, modular explanations rather than opaque end-to-end neural outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Practical limitations observed in Jurassic-X: the router's extraction failures are the dominant error source; some phrasing templates (format 4 and certain nested prefix templates) and certain operator combinations (add-mul, sub-mul, sub-div) were harder to generalize; training required careful data augmentation, prompt-tuning choices, and hyperparameter selection; LM-only few-shot baselines perform worse in several settings, indicating the need for fine-tuned or prompt-tuned routers.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>The implementation follows the MRKL engineering principle of complementary division-of-labor: neural LMs for linguistic abstraction and argument extraction; symbolic modules for exact computation and access to external knowledge. The framework is pragmatic and systems-oriented rather than a formal theoretical model.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Jurassic-1: Technical Details and Evaluation <em>(Rating: 2)</em></li>
                <li>Language Models are Few-Shot Learners <em>(Rating: 2)</em></li>
                <li>Language Models as Knowledge Bases? <em>(Rating: 1)</em></li>
                <li>On the Opportunities and Risks of Foundation Models <em>(Rating: 1)</em></li>
                <li>Break It Down: A Question Understanding Benchmark <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-399",
    "paper_id": "paper-248496374",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "MRKL",
            "name_full": "Modular Reasoning, Knowledge and Language (MRKL) system",
            "brief_description": "A modular neuro-symbolic architecture that composes large pretrained language models with external knowledge sources and discrete symbolic reasoning modules via a neural router, enabling extensible, interpretable, and up-to-date natural-language-based reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "MRKL (Modular Reasoning, Knowledge and Language)",
            "system_description": "MRKL is a modular neuro-symbolic system whose core design is an extensible set of expert modules (neural and symbolic) plus a learned router that maps each incoming natural-language query to the expert(s) best suited to respond. Neural experts include general-purpose and specialized pretrained LMs; symbolic experts include calculators, converters, database/API connectors and other discrete reasoners. The router can return module outputs directly or chain them (multi-hop) by routing outputs to other experts. The system is designed for robust extensibility (add experts without retraining all modules), safe fallback to a general LM when no expert matches, interpretability via explicit module invocation, and access to dynamic/proprietary knowledge by calling external APIs or databases.",
            "declarative_component": "Discrete symbolic modules invoked as procedural/symbolic components: deterministic calculator(s) for arithmetic, currency converters, database/API calls, and other symbolic reasoners. Representations are conventional discrete procedural APIs or symbolic procedures (not differentiable); inputs to these modules are explicit, discrete arguments (operands, operation identifiers, API parameters) extracted from text.",
            "imperative_component": "Pretrained neural language models and neural router networks: a large transformer LM (Jurassic-1 family; experiments used J1-large 7B) as the general-purpose language backbone and smaller/specialized LMs as neural experts; the router is itself a neural model (prompt-tuned J1-large in experiments) trained to perform natural-language understanding and to extract module-specific arguments from text.",
            "integration_method": "Modular architecture with an explicit neural router: the router (neural) classifies/decides which expert to call and extracts discrete, structured arguments for symbolic modules. Integration is not end-to-end differentiable across symbolic modules; instead modules are trained/implemented independently and the router is trained (via prompt-tuning and data augmentation) to produce correct calls/arguments. Module outputs can be composed by routing outputs to subsequent experts (chaining/compositional invocation). Training focuses on (1) independently training experts, (2) training/tuning the router (lightweight relative to LMs) using synthetic/augmented data to reliably extract discrete parameters.",
            "emergent_properties": "Combines robust language understanding from LMs with exactness and determinism of symbolic modules, producing: (1) reliable arithmetic and other discrete-reasoning results (errors only from argument extraction), (2) interpretability via explicit module invocation (e.g., 'calculator said so'), (3) access to current/proprietary knowledge by calling external APIs, (4) compositional multi-hop reasoning by chaining modules, and (5) robust extensibility where new capabilities can be added without retraining all components.",
            "task_or_benchmark": "Natural-language-to-symbolic-argument extraction and symbolic arithmetic execution: single-operation and two-operation arithmetic problems phrased in many natural-language formats (varying digits vs words, formats, operator types, and number of digits), used to evaluate the router + calculator pipeline (Jurassic-X).",
            "hybrid_performance": "High accuracy reported for router+calculator pipeline: in-distribution single-operation accuracy &gt;99% when trained and evaluated on the same operation; generalization across many numbers of digits nearly perfect when trained on single-digit operands; two-operation experiments: 22 of 29 two-operation combinations achieved &gt;90% accuracy on average across random splits. (Performance metrics reported as percent accuracy on test sets.)",
            "declarative_only_performance": null,
            "imperative_only_performance": "Not given as a strict numeric baseline in this paper; the paper contrasts LM-only approaches qualitatively and refers to GPT-3 results that degrade sharply with operand length (see referenced [2]), but does not provide a single unified numeric baseline for all experiments in this work. (null for strict numeric comparison)",
            "has_comparative_results": true,
            "generalization_properties": "Strong generalization in many dimensions: (1) generalizes from single-digit training to multi-digit test operands (1–9 digits) for many operations; (2) cross-format generalization is typically strong (training on one phrasing often generalizes to multiple formats), although some formats (format 4, not phrased as a question) are harder; (3) cross-operation generalization often good (e.g., models trained on addition generalize well to subtraction and multiplication), with division being an exception; (4) models trained on single operations often generalize to two-operation expressions in most cases, with a few failure modes (add-mul, sub-mul, sub-div). The paper documents out-of-distribution tests (digits, wording, formats, operation mixes) and shows robust compositional generalization in many settings but identifies specific failure pairs.",
            "interpretability_properties": "Improved interpretability: explicit invocation of symbolic modules provides human-understandable rationales (e.g., indicating that the calculator produced the numeric answer). The modular breakdown (which expert answered) acts as an explanatory signal. Because symbolic modules perform deterministic computations, their outputs are inherently explainable (the system can attribute subresults to specific module calls).",
            "limitations_or_failures": "Key limitations highlighted: (1) the main failure mode is incorrect extraction of discrete arguments by the router, not the symbolic computation itself; training the router to extract arguments reliably requires careful data augmentation and evaluation; (2) some generalization failures (e.g., add-mul, sub-mul, sub-div templates, and format 4) indicate brittleness to certain phrasings or nested phrasing styles; (3) division generalizes poorly from other operations and vice versa; (4) the architecture shifts complexity to router training and engineering for module interfaces (no free lunch); (5) integration is not end-to-end differentiable across symbolic modules, which limits some learning paradigms.",
            "theoretical_framework": "Practical division-of-labor principle: the paper advocates a systems-oriented neuro-symbolic paradigm where neural LMs handle linguistic understanding, routing, and argument extraction, while symbolic/procedural modules handle discrete, deterministic reasoning and external knowledge access. The justification is pragmatic and engineering-driven (complementary strengths), rather than a formal mathematical theory; the framework emphasizes modularity, compositionality, and lightweight retraining of the router as core principles.",
            "uuid": "e399.0"
        },
        {
            "name_short": "Jurassic-X",
            "name_full": "Jurassic-X (AI21 Labs' MRKL implementation)",
            "brief_description": "An implementation of the MRKL architecture that couples AI21's Jurassic-1 family LMs (J1-large in experiments) with symbolic modules (calculator, APIs) via a learned router, and demonstrates robust natural-language-to-calculator argument extraction through prompt-tuning and data augmentation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Jurassic-X (MRKL implementation)",
            "system_description": "Jurassic-X is AI21 Labs' MRKL-system implementation used in experiments. It uses a J1-large transformer (7B parameters in reported experiments) as backbone and as the router (via prompt-tuning with 10 prompt tokens) to identify which expert to call and to extract discrete arguments for symbolic modules. The implementation includes a deterministic calculator module and is evaluated on many natural-language arithmetic formulations; training of the router relied on data augmentation from structured templates to achieve high reliability in argument extraction. System-level design emphasizes independent expert training and lightweight retraining of the router.",
            "declarative_component": "Same symbolic components as MRKL: a deterministic calculator module used to perform arithmetic (actual numeric computation is performed by the symbolic calculator), plus support for connecting to external APIs/databases (currency converters, proprietary data sources) as discrete procedural modules.",
            "imperative_component": "J1-large transformer (7B) used with prompt-tuning (10 prompt tokens) to form the router and/or specialized neural experts; training used gradient-based optimization (prompt-tuning) with specified hyperparameters (learning rate lr=0.3, batch size 32, linear decay, occasional weight decay 0.001).",
            "integration_method": "Router-based modular invocation: the prompt-tuned J1-large router maps NL inputs to module calls and extracts discrete parameters; once extracted, parameters are passed to the symbolic calculator (or other API) which executes deterministically. The integration is operational (API-style) rather than differentiable through symbolic modules. The router was trained using synthetic data augmentation from structured template spaces to ensure robust argument extraction across lexical/format variability.",
            "emergent_properties": "Empirical emergent behavior includes near-perfect argument extraction in many settings leading to robust arithmetic correctness, strong compositional generalization to multi-operation expressions despite limited training coverage, and an interpretability benefit from explicit module calls. Jurassic-X also demonstrates robust extensibility: new modules can be added without retraining the entire LM backbone, only requiring router updates.",
            "task_or_benchmark": "Natural-language arithmetic: mapping NL arithmetic questions to symbolic calculator calls (single-operation and two-operation problems across multiple phrasings, operand representations, and digit lengths). Evaluation measured percent accuracy on held-out and out-of-distribution test splits (digits, words, formats, operator types).",
            "hybrid_performance": "Reported hybrid (router + calculator) results: in-distribution single-operation accuracy ≳99% for same-operation training/testing; successful generalization across operand digit lengths (1–9 digits) when trained on single-digit examples; in two-operation experiments, average accuracy exceeded 90% for 22 out of 29 formula types across random splits. Metrics reported as percent test-set accuracy.",
            "declarative_only_performance": null,
            "imperative_only_performance": "The paper reports that few-shot LM-only approaches (e.g., GPT-3 style) degrade with increased digit length and wording variability and that prompt-tuned Jurassic-X outperforms few-shot baselines in many settings, but exact unified numeric LM-only baselines for all experiments are not enumerated numerically in this paper (null for strict numeric comparison).",
            "has_comparative_results": true,
            "generalization_properties": "Jurassic-X generalizes well in multiple OOD axes: digit-length generalization from single-digit training to multi-digit testing, lexical generalization (training on words generalizes to digits better than the inverse), format generalization across many phrasing templates, and generalization from single-operation training to many two-operation test problems, with documented exceptions. These properties were tested with out-of-distribution splits and random partitions of two-operation formulae.",
            "interpretability_properties": "Because the calculator executes deterministically and the router explicitly chooses and invokes that module, Jurassic-X can attribute outputs to module calls (e.g., 'used calculator to compute X'), providing traceable, modular explanations rather than opaque end-to-end neural outputs.",
            "limitations_or_failures": "Practical limitations observed in Jurassic-X: the router's extraction failures are the dominant error source; some phrasing templates (format 4 and certain nested prefix templates) and certain operator combinations (add-mul, sub-mul, sub-div) were harder to generalize; training required careful data augmentation, prompt-tuning choices, and hyperparameter selection; LM-only few-shot baselines perform worse in several settings, indicating the need for fine-tuned or prompt-tuned routers.",
            "theoretical_framework": "The implementation follows the MRKL engineering principle of complementary division-of-labor: neural LMs for linguistic abstraction and argument extraction; symbolic modules for exact computation and access to external knowledge. The framework is pragmatic and systems-oriented rather than a formal theoretical model.",
            "uuid": "e399.1"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Jurassic-1: Technical Details and Evaluation",
            "rating": 2,
            "sanitized_title": "jurassic1_technical_details_and_evaluation"
        },
        {
            "paper_title": "Language Models are Few-Shot Learners",
            "rating": 2,
            "sanitized_title": "language_models_are_fewshot_learners"
        },
        {
            "paper_title": "Language Models as Knowledge Bases?",
            "rating": 1,
            "sanitized_title": "language_models_as_knowledge_bases"
        },
        {
            "paper_title": "On the Opportunities and Risks of Foundation Models",
            "rating": 1,
            "sanitized_title": "on_the_opportunities_and_risks_of_foundation_models"
        },
        {
            "paper_title": "Break It Down: A Question Understanding Benchmark",
            "rating": 1,
            "sanitized_title": "break_it_down_a_question_understanding_benchmark"
        }
    ],
    "cost": 0.011953749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning
May 3, 2022</p>
<p>Ehud Karpas 
AI21 Labs</p>
<p>Omri Abend 
AI21 Labs</p>
<p>Yonatan Belinkov 
AI21 Labs</p>
<p>Barak Lenz 
AI21 Labs</p>
<p>Opher Lieber 
AI21 Labs</p>
<p>Nir Ratner 
AI21 Labs</p>
<p>Yoav Shoham 
AI21 Labs</p>
<p>Hofit Bata 
AI21 Labs</p>
<p>Yoav Levine 
AI21 Labs</p>
<p>Kevin Leyton-Brown 
AI21 Labs</p>
<p>Dor Muhlgay 
AI21 Labs</p>
<p>Noam Rozen 
AI21 Labs</p>
<p>Erez Schwartz 
AI21 Labs</p>
<p>Gal Shachaf 
AI21 Labs</p>
<p>Shai Shalev-Shwartz 
AI21 Labs</p>
<p>Amnon Shashua 
AI21 Labs</p>
<p>Moshe Tenenholtz 
AI21 Labs</p>
<p>MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning
May 3, 2022
Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced "miracle") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.</p>
<p>Introduction</p>
<p>Huge language models (LMs) such as BERT [1], GPT-3 [2], Jurassic-1 [3], PaLM [4], and others [5][6][7][8][9], have taken AI by storm, with the promise of serving as versatile, general-purpose foundations for many applications. Indeed, partly for this reason, they have been rebranded by some as "foundation models" [10]. The term is meant broadly, covering language models as well as models that were trained on more than just text, and although such multimodal models are not the focus of this paper, there's another reason to take the term "language model" with a grain of salt. While LMs indeed model syntax, and other linguistic elements, their most striking feature is that they model the world, as described by the data on which they were trained.</p>
<p>And so really LMs serve as a textual gateway to the universe of knowledge [11,12], and perhaps should instead be called "language and knowledge" models.</p>
<p>When viewed this way, it becomes clear that, despite their value, current LMs have inherent limitations. While versatile and impressive, the output of even huge LMs is in many cases wrong, and often ridiculously so [13]. Here is a sample output of GPT-3 on some simple queries. (To be clear, this is not a critique of GPT-3 specifically, and other LMs -including our own Jurassic-1 -exhibit similar silliness.)</p>
<p>For example, LMs can struggle to understand that there are no US cities with more than 20m citizens, that a math teacher is a person, don't know what today's date is, nor can they engage in even simple (e.g., mathematical) reasoning.</p>
<p>When you look for the root cause, you realize the core limitations of LMs: They don't have access to all relevant knowledge, and neural models are ill-suited for certain types of calculation. More specifically:</p>
<ol>
<li>
<p>Lack of access to current information. Certain data constantly change -the exchange rate between the dollar and the Moroccan Dirham, current COVID numbers, the stock price of AAPL, the weather in Vancouver (OK, not so much), or even the current date. It's impossible, by their design, for pretrained language models to keep up with this dynamic information [14].</p>
</li>
<li>
<p>Lack of access to proprietary information sources. As an important special case of 1, the models don't have access to proprietary information, such as the client roster in a company's database or the state of an online game.</p>
</li>
<li>
<p>Lack of reasoning. Certain reasoning is beyond the reach of the neural approach, and requires a dedicated reasoning process. We saw above the classic example of arithmetic reasoning. GPT-3 and Jurassic-1 perform well on 2-digit addition, which is impressive, but confidently spit out nonsensical answers on 4-digit additions. With increased training time, better data, and larger models, the performance of LMs will improve, but will not reach the robustness of an HP calculator from the 1970s. And mathematical reasoning is just the tip of an iceberg.</p>
</li>
</ol>
<p>In addition to these shortcomings, there is another inherent problem with the traditional approach to deploying LMs: 4. Model explosion. Today's LM's zero-shot performance trails that of fine-tuned models. One can fine-tune the LM to a specific task, but then lose versatility. Contemporary efforts to mitigate the problem focus on training a huge LM jointly on many sets of curated NLP tasks in a massive multi-task setting (several leading studies reaching 100+ tasks) [6,7,15,16]. These formidable efforts are effective; the resulting models exhibit versatility and high performance when encountering inputs resembling those of the curated tasks. But the performance of these models on tasks that are not close enough to those included in the curated tasks can significantly deteriorate (for example, perplexity degrades significantly). It is not practical to fine-tune and serve multiple large models. Nor can one further tune a multi-task-trained LM [6,7,15,16] on a new task that hadn't been covered in its training; due to catastrophic forgetting, adding the new task necessitates retraining on the entire task set. Given the cost of training such models [17][18][19], this is clearly infeasible to do repeatedly.</p>
<p>Despite all these shortcomings, large language models are an essential backbone of any future AI system. So the question is how to have our cake and eat it too, enjoying the benefits of self-supervised deep language models without suffering these drawbacks. The solution we offer takes the form of a flexible architecture dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced "miracle") system, whose high-level design is depicted below.</p>
<p>A Thus a MRKL system consists of an extendable set of modules, which we term 'experts', and a router that routes every incoming natural language input to a module that can best respond to the input (the output of that module can be the output of the MRKL system, or be routed to another module). These modules can be:</p>
<p>• Neural, including the general-purpose huge language model as well as other smaller, specialized LMs.</p>
<p>• Symbolic, for example a math calculator, a currency converter or an API call to a database.</p>
<p>MRKL systems enjoy important benefits when compared to fine-tuned multi-task models:</p>
<ol>
<li>
<p>Safe fallback: In case the input doesn't match any existing expert module, the router sends the input directly to the general-purpose huge LM.</p>
</li>
<li>
<p>Robust extensibility: Since each expert is trained independently we are able to cheaply add new capabilities while guaranteeing that they do not compromise the performance of existing ones. The only component that requires retraining is the router which is a relatively lightweight task.</p>
</li>
<li>
<p>Interpretability: When the router invokes a specific module, that often has the side benefit of providing a rationale for the MRKL system's output ("1 + 1 = 2 because the calculator said so"); such explanations are crucially lacking in existing language models.</p>
</li>
<li>
<p>Up-to-date information: The integration of external APIs allows the MRKL system to hook into dynamic knowledge bases, and correctly answer inputs that static models cannot.</p>
</li>
<li>
<p>Proprietary knowledge: Access to proprietary databases and other information sources.</p>
</li>
<li>
<p>Compositionality: By routing compounded multi-hop inputs to different experts we are able to naturally integrate their responses and correctly address complex inputs [20].</p>
</li>
</ol>
<p>2 Jurassic-X: AI21 Labs' MRKL system</p>
<p>We have implemented a MRKL system called Jurassic-X, which is being piloted by a few partners.</p>
<p>Jurassic-X will soon be available to developers; you can apply for early access here.</p>
<p>Meanwhile, you can experience Jurassic-X via a demo (link).</p>
<p>Crossing the neuro-symbolic chasm: A calculator test case</p>
<p>There are of course many details involved in implementing a MRKL system. In connection with avoiding model explosion, see our detailed discussion here. There is also an interesting challenge of how to intelligently route input among modules, which we leave for a separate discussion. Here we discuss one particularly interesting challenge, that of extracting from the text the formal arguments to symbolic reasoners.</p>
<p>Arithmetic as a test case for chasm crossing</p>
<p>The relation between neural and symbolic approaches to AI is guaranteed to raise heated discussions about their relative merits with neuro-skeptics on one extreme, neuro-diehards on the other, and the rest trying to have a rational conversation. Before discussing our technical approach we'd like to clarify our guiding ideology. We believe that neural LMs are essential; we didn't build Jurassic-1 [3] for no reason, and it serves as a backbone to our applications as well as those of developers using AI21 Studio. But as we've made clear, we also believe they have inherent shortcomings. We don't take a firm position on which types of computation are best relegated to the neural machinery, and which should be carved out to symbolic methods. That will surely be an evolving process. What we do firmly believe is that some tasks should be handled by discrete methods, and we should have a clear methodology for how to hand off the computation from the neural net to the symbolic procedure.</p>
<p>Once the router has made the decision of which module to call upon, it needs to pass the right information to it. The router is a specialized neural net and therefore invoking a neural module is easy since the neural-to-neural interface is natural. However, when a neural network needs to access a database, make an API call, or invoke another symbolic computation, it must extract from the text discrete parameters required by the module. The main message here is that there is no free lunch, but that lunch is in many cases affordable. The cost is in training the router to extract the arguments reliably, which must be done rigorously. We make the point by discussing how we trained Jurassic-X to extract basic arithmetic operations.</p>
<p>There are many ways to describe in language a situation that calls for performing arithmetic. The most straightforward way is to use mathematical notation, say "3 − 1 =? . Google search handles it well:</p>
<p>Not much harder is to express it in words, as in "How much is three minus 1". Google search does this well too:</p>
<p>But then it gets tricky. At the lexical level, one may use different synonyms that carry the same meaning: ("twelve", "12" and "a dozen"). But beyond simple lexical issues, there are phrases that require world knowledge to understand that there is an arithmetic exercise encoded in the text ("I lost one ball", "I dropped one ball", "One ball was taken from me") and what the specific exercise is. Here Google search starts to stumble: This is where language models come in. Note that we limit their role to extracting the right arguments for the symbolic calculator, not performing the calculation itself.</p>
<p>But we should approach even this task with sober expectations. As anyone knows from elementary school, it's harder to teach children to solve verbal math problems than to solve explicitly stated math problems. It's harder for adults too, and it's no different for the computer. At some point the machine will stumble (indeed, at some point humans will disagree about the underlying math problem). But when we decide to invoke a symbolic method we should expect reasonable robustness.</p>
<p>The solution is to train the router to extract the right input independently for each module, with rigorous evaluation of the performance. By way of example, here is how it was achieved simple, one-and two-operation arithmetics.</p>
<p>Training Jurassic-X to extract the arguments for basic arithmetic</p>
<p>Our goal here is not to show how we can extract the most complex mathematical expressions from text, but how we can extract simple expressions with high reliability, the sort of reliability one would need in a production-grade system. We found that while extensive pretraining does allow Jurassic-1 to extract the arithmetic operation in many cases in a few-shot setting, the performance is far from perfect. See Appendix A for a detailed comparison. Using a data augmentation methodology, based on generating examples from a structured example space, we show that the static pretrained LM can be made to achieve near perfect performance. We empirically investigate two related research questions:</p>
<ol>
<li>
<p>What is required in terms of data augmentation to achieve near-perfect performance in the case of basic mathematical operations?</p>
</li>
<li>
<p>How well can Jurassic-X generalize between math problems that vary in type or complexity?</p>
</li>
</ol>
<p>To answer these questions we evaluate the model's performance on cases where the test data is drawn from the same distribution as the training data, as well as on out-of-distribution test data (allowing us, for example, to train a model on addition problems and test it on multiplication problems).</p>
<p>Data Augmentation</p>
<p>We use a small set of templates to generate a set of training and test examples. Each example is characterized by the following dimensions:</p>
<ol>
<li>
<p>The numbers used in the arithmetic expression, henceforth the operands. The operands may be digits (e.g., 48) or numbers in word form (e.g., forty eight).</p>
</li>
<li>
<p>The number of digits in the operands. We explore numbers of 1-9 digits.</p>
</li>
<li>
<p>The type of operation. We explore addition, subtraction, multiplication and division.</p>
</li>
<li>
<p>The number of operations in the arithmetic expression. We explore the cases of one and two operations. 5. The placement or absence of brackets (in expressions with two operations). In some expressions the placement of brackets may change the result. We explore all logical possibilities for the case of two operations. Table 10 in the appendix details the templates we use in this set of experiments for the case of a single operation. In the case of two operations, there are 29 distinct combinations that have a natural formulation in natural language (see Table 12). The data can be found here.</p>
</li>
</ol>
<p>Experimental setup</p>
<p>We conducted our experiments with the 7B parameters J1-large model [3] using prompt-tuning [21] with 10 prompt tokens. Across all experiments, we set our learning rate to be lr = 0.3 and used linear decay. The batch size was set to 32 and we defined a short warm-up depending on the number of steps in each experiment.</p>
<p>Experiments 1 and 2 below were trained for 3000 steps, and the reported results here were the test accuracy evaluated on the final model. For the remaining experiments we used linear weight decay (0.001), which we found to be crucial for the model's performance, and selected the best checkpoint using a validation set. Each experiment was run 3-5 times, and results show mean ± standard deviation across these runs.</p>
<p>In all experiments we verified that there was no overlap between the problems included in the training set and those included in the test set. This also includes avoiding cases with the same underlying arithmetic expression, but using different wordings for training and testing. For a detailed description of the sizes of the data splits see Section C.</p>
<p>Results</p>
<p>In the following results we report the accuracy we achieve in different experiments, by which we mean the percent of problems in the relevant test set on which the system gave the correct answer. (We note again that, since the actual calculation is done by the calculator module, all errors are due to passing the wrong operations or operands to the calculator.) Experiment 1: Generalization across different number of digits in the operands. Inspired by the experiments reported by [2], we test Jurassic-X's ability to generalize to numbers it has not seen in the training data, including numbers with a different (and much larger) number of digits. At training time we expose the model only to single-digit numbers, while at test time we evaluate on numbers with 1 to 9 digits. In this section we experiment with simple problems, involving only numbers written as digits (and not numbers as words), one format (format 0 from Table 10), and a single operation. We explore two settings: one where that operation is addition, and one where it is multiplication. Table 1 presents our results, sliced by the number of digits, and compared to the results by GPT-3's approach [2] (as representative of all language models that don't have access to external calculator), reported on addition. We note that we trained on single-digit operations for all settings while GPT-3 was conditioned on examples with the same number of digits when answering a certain problem. Our results show that despite the fact that training was only done on numbers with a single digit, the model is able to generalize to all numbers of digits explored. This is in stark contrast to the approach of language models which attempt to synthesize arithmetic capabilities from the training data, and as a result display a dramatic decrease in performance as the number of digits increases.  Experiment 2: Generalization from digits to numbers as words and vice versa. In this set of experiments, we test the model's ability to generalize from arithmetic questions with digits to ones where the numbers are expressed with words, and vice versa. We note that this task is not trivial considering the fact that the tokenization of a number represented with digits is different than that when the same number is represented as words. For example, we train the model with examples such as "How much is 58 plus 12" and evaluate it on examples such as "How much is twenty seven plus thirteen", and vice versa. While we vary the lexical choice for specifying numbers using words or digits, we hold other dimensions of the arithmetic world fixed, including using only format 0 and holding the type of operation fixed at training and test time. (In the following paragraphs we examine these other dimensions.) Table 2 shows the accuracy for all combinations of training and testing on digits and on words. We notice that in-distribution performance (training and testing on the same type of input) is close to 100 % accuracy. We further observe that training on words generalizes well to digits. Interestingly, the inverse is not true and the performance is much lower, indicating the underlying difference in the representations of the numbers.  </p>
<p>Test</p>
<p>Experiment 3: Generalization across question formats.</p>
<p>A main challenge in constructing natural language interfaces to discrete reasoners like a calculator is in handling language variability. One of the most appealing characteristics of language models is their ability to abstract away from such variability. Here we test the ability of the model to generalize over formats of arithmetic problems. Experiments are for single-operation problems. We train on a single format (format 0 in Table 10), test on all formats, and break the results by format. We report results with all four operation types. Table  3 shows that the generalization across formats is perfect in most cases. Format 4, which is the only one not phrased as a question (see Table 10) appears to be the most challenging to generalize to. We note that there are numerous ways to phrase such questions, hence the ability to generalize across formats, even for the case where the model was trained only on one format, is critical for the model's success.  and evaluating on each of the 5 formats from Table 10.</p>
<p>Experiment 4: Generalization between operations. Next we explore whether a model that was trained on one type of arithmetic problems can generalize to other types. We conduct two types of experiments: one where we examine the generalization ability of Jurassic-X on single operation problems, and one with twooperation problems.</p>
<p>For the first set of experiments, we train with one operation at a time, using all formats with numbers as digits. Operands have between 1 and 9 digits. We test on all types of single-operation problems. The results are shown in in Table 4. Consistent with the previous experiments, training and evaluating on arithmetic problems with the same operations is consistently successful (accuracy &gt; 0.99 along the diagonal). Interestingly, we find strong generalization in many cross-operation cases (off the main diagonal in the table). For example, training on addition works almost perfectly when evaluated on subtraction and multiplication. The division operation is an exception, as models trained on it struggle with multiplication and subtraction (but perform reasonably on addition). Conversely, models trained on other operations do not generalize very well to division.  For the second set of experiments, we randomly partition the 29 possible twooperation arithmetic problems (Tables 11, 12) into subsets of 14 and 15 to be used for training and testing, respectively. We repeated this process for 10 random splits of the operations, assuring that only one of the training two-operation problems would include brackets. Other settings are as with the first set of experiments. Table 5 shows the average accuracy for each of the 29 types of two-operation problems. The results show that in 22 of the 29 combinations the accuracy exceeds 90%, indicating reasonable generalization capabilities for such a setting.</p>
<p>Experiment 5: Generalization across a different number of operations.</p>
<p>This final set of experiments explores the ability of the model to generalize from single-operation problems to two-operation problems.</p>
<p>As above, we use all formats (0-4), with operands of 1 to 9 digits (numbers written with digits), and train on examples from all four operation types (singleoperation problems only). We evaluate on examples with two operations, focusing on the situations that do not require bracketing -16 unique combinations in total. The results are shown in Table 6 and are organized by the first operation (rows) and second operation (columns) in the test problems.  In almost all cases, we observe excellent performance on solving two-operation problems, despite seeing only single-operation problems at training time. This result is also important for the systematic development of the capability since the number of possible formulae grows rapidly with the number of operations, rendering an exhaustive training of all combinations extremely challenging for multi-operation formulae. There are three exceptions of failure to generalize to two-operation problems: add-mul, sub-mul, and sub-div. In these three cases, the templates are of the form of two prefix phrasings (e.g., "what is the sum of 2 and the product of 4 and 8"), while other templates are relatively simpler (Table 12). However, we obtain pretty good performance on add-div, despite it having a similar template.  Table 6: Generalization from one operation to two operations. Accuracy when training on single-operation problems and testing on two-operation problems, presented for all operation pairs.</p>
<p>Discussion</p>
<p>This paper introduces the concept of Modular Reasoning, Knowledge and Language (MRKL) systems, which embraces large language models (LMs) and augments them with an easily extensible set of external knowledge and reasoning modules. This flexible, neuro-symbolic design retains all the advantages of modern LMs, but avoids their limitations: a lack of current and/or proprietary information, and an inability to reason symbolically when needed. We discussed some of the technical challenges in implementing a MRKL system, with a special focus on how to cross the neurosymbolic divide, which we did by looking at how Jurassic-X -AI21 Labs' implementation of a MRKL system -was trained to handle basic arithmetic reliably.</p>
<p>A Few-shot vs. prompt tuning</p>
<p>Performing these experiments in a few-shot setting might be a more natural choice that requires less effort in training these models. However, as the analysis below reveals, the performance of this approach is limited, demonstrating the need to follow a systematic approach.</p>
<p>Set up: In the few-shot experiments, 10 examples were drawn from the training sets and used as a prompt for the model. The performance was evaluated on the same test set for both the few-shot and the prompt-tuning approaches.</p>
<p>Changing the number of digits: Both methods easily generalize to varying the number of digits (see Table 7).</p>
<p>Num. digits  Writing the operands in words instead of digits: A clear difference appears as the few-shot approach is unable to handle this task and the performance greatly decreases with the number of digits (see Table 8).</p>
<p>Num. digits  </p>
<p>Different question formats:</p>
<p>We explored the ability to generalize to different question formats when training on one format (format 0). We note the generalization is much lower compared to following our prompt-tuning method (Table 9).    The equations for two-operation problems, for all combinations of placing the brackets, are shown in Table 11. Table 12 shows the phrasings for these 29 formulae.</p>
<p>Num. digits</p>
<p>B Question formats</p>
<p>C Amount of data in each experiment</p>
<p>Experiment 1 -number of digits: The training set included 40 single digits operand combinations. The test set for single digits included the remaining 41 combinations (discarding 0) and 50 randomly chosen combinations for all the cases with more then 1 digit. Experiment 2 -digits and words: 200 samples were randomly drawn for each number of digits (except for 1 and 2 digits) and data was split equally between train and test data. This was repeated for both digits and words. Experiment 3 -question formats:</p>
<p>The train set included 400 samples with format 0 and the dev and test set each included 200 samples from each format, randomly drawn with number of digits ranging between 1 and 9. Experiment 4 -generalization across operations: The train set included 635 samples across all formats and digits for each operation, while the dev and test set each included 315 samples for each operation. For the two-operation experiment we drew 120 samples for each of the 29 formats, which were divided equally between the train, dev and test sets.  Table 11: Two-operation formulae. All combinations of two-operation formulae, including operator precedence where relevant. See Table 12 for the phrasings corresponding to these formulae.</p>
<p>700 samples with a single operation were used for training the model, drawn randomly from all operations, formats, and number of digits. The dev and test set each included 210 samples drawn randomly for each of the 16 combinations of two operation formulas, analyzed up to 7 digits.</p>
<p>Experiment 5 -generalization across the number of operations:</p>
<p>Table 1 :
1Robustness to the number of digits in the operands. Accuracy vs. thenumber of digits in the test data for a model that was trained only on 1-digit operands 
(5 + 3, etc.). Results for GPT-3 were taken from [2]. </p>
<p>Table 2 :
2Robustness to wordings. Accuracy for all combination of training and testing on numbers written as digits and as words. Results are averaged across all the numbers of digits.</p>
<p>Table 3 :
3Robustness to phrasing. Accuracy when training with one format (format 0)</p>
<p>Table 4 :
4Generalization across operations for single-operation problems. Accuracy when training with one operation and evaluating on other operations.</p>
<p>Table 5 :
5Generalization for two-operation problems. Mean and standard deviation across 10 partitions of the formulae to train and test.</p>
<p>Table 7 :
7Number of digits: few-shot vs. prompt tuning. Results shown for addition.</p>
<p>Table 8 :
8Number of digits: few-shot vs. prompt tuning, when numbers are written as words. Results are shown for addition.</p>
<p>Table 9 :
9Generalization across formats: few-shot vs. prompt tuning. Results are shown for addition.</p>
<p>Table 10
10shows the five formats used for single-operation problems for all operations. What is the result of {x} times {y}? What is the result of {x} over {y}? 3 What is the product of {x} and {y}? What is the ratio between {x} and {y}? 4 The product of {x} and {y} is The ratio of {x} and {y} isFormat 
addition 
subtraction 
0 
How much is {x} plus {y}? 
How much is {x} minus {y}? 
1 
What is {x} plus {y}? 
What is {x} minus {y}? 
2 
What is the result of {x} plus {y}? 
What is the result of {x} minus {y}? 
3 
What is the sum of {x} and {y}? 
What is the difference between {x} and {y}? 
4 
The sum of {x} and {y} is 
The difference between {x} and {y} is </p>
<p>multiplication 
division 
0 
How much is {x} times {y}? 
How much is {x} over {y}? 
1 
What is {x} times {y}? 
What is {x} over {y}? 
2 </p>
<p>Table 10 :
10Question formats for single-operation problems. Five different formats for each type of operation in the case of single-operation expressions.
FormulaFormat f=((A+B)<em>C) Sum A and B and multiply by C f=(A+B</em>C)What is the sum of A and the product of B and C? f=((A-B)<em>C)What is the product of A minus B and C? f=(A/(B/C)) How much is A divided by the ratio between B and C? f=(A-B</em>C) What is the difference between A and the product of B and C? f=(A<em>(B-C)) How much is A times the difference between B and C? f=((A+B)/C) What is the ratio between A plus B and C?How much is A minus the diffrence between B and C? f=((A-B)/C) What is the ratio between A minus B and C? f=(A-B/C) What is the difference between A and the ratio between B and C? f=(A/(B+C)) How much is A divided bu the sum of B and C?How much is A divided by the difference between B and C? f=(A+B/C) what is the sum of A and the ratio between B and C? f=(A</em>(B/C)) How much is A times the ratio between B and C?f=(A<em>B+C) How much is the sum of A times B and C? f=(A</em>(B+C)) How much is A times the sum of B and C? f=(A/B+C) How much is the sum of A divided by B and C? f=(A/B/C) How much is A divided by B divided by C? f=(A/B-C)How much is the difference between A divided by B and C? f=(A/B<em>C)How much is A divided by B times C? f=(A-(B+C)) How much is A minus the sum of B and C? f=(A</em>B-C) How much is the difference between A times B and C? f=(A/(B<em>C)) How much is A divided by the product of B and C? f=(A-B+C) How much is A minus B plus C? f=(A+B+C) How much is A plus B plus C? f=(A-B-C) How much is A minus B minus C? f=(A</em>B/C) How much is A times B divided by C? f=(A+B-C) How much is A plus B minus C? f=(A<em>B</em>C) How much is A times B times C?Table 12: Formats of two-operation questions.
J Devlin, M.-W Chang, K Lee, K Toutanova, Bert, Pre-training of Deep Bidirectional Transformers for Language Understanding in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Minneapolis, MinnesotaAssociation for Computational Linguistics1Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding in Proceedings of the 2019 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (Association for Computational Linguistics, Minneapolis, Minnesota, June 2019), 4171-4186. https://aclanthology.org/N19-1423.</p>
<p>Language Models are Few-Shot Learners. T B Brown, Brown, T. B. et al. Language Models are Few-Shot Learners 2020. https : //arxiv.org/abs/2005.14165.</p>
<p>Jurassic-1: Technical Details and Evaluation. O Lieber, O Sharir, B Lenz, Y Shoham, Lieber, O., Sharir, O., Lenz, B. &amp; Shoham, Y. Jurassic-1: Technical Details and Evaluation 2021. https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/ 61138924626a6981ee09caf6_jurassic_tech_paper.pdf.</p>
<p>PaLM: Scaling Language Modeling with Pathways 2022. A Chowdhery, Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways 2022. https://arxiv.org/abs/2204.02311.</p>
<p>Exploring the Limits of Transfer Learning with a Unified Textto-Text Transformer. C Raffel, Journal of Machine Learning Research. 21Raffel, C. et al. Exploring the Limits of Transfer Learning with a Unified Text- to-Text Transformer. Journal of Machine Learning Research 21, 1-67. http: //jmlr.org/papers/v21/20-074.html (2020).</p>
<p>Multitask Prompted Training Enables Zero-Shot Task Generaliza. V Sanh, International Conference on Learning Representations. Sanh, V. et al. Multitask Prompted Training Enables Zero-Shot Task Generaliza- tion in International Conference on Learning Representations (2022). https: //openreview.net/forum?id=9Vrb9D0WI4.</p>
<p>V Aribandi, Towards Extreme Multi-Task Scaling for Transfer Learning in International Conference on Learning Representations. Aribandi, V. et al. ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning in International Conference on Learning Representations (2022). https: //openreview.net/forum?id=Vzh1BFUCiIX.</p>
<p>Y Liu, A Robustly Optimized BERT Pretraining Approach. Liu, Y. et al. RoBERTa: A Robustly Optimized BERT Pretraining Approach 2019. https://arxiv.org/abs/1907.11692.</p>
<p>Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model 2022. S Smith, Smith, S. et al. Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model 2022. https://arxiv.org/ abs/2201.11990.</p>
<p>On the Opportunities and Risks of Foundation Models. R Bommasani, Bommasani, R. et al. On the Opportunities and Risks of Foundation Models 2021. https://arxiv.org/abs/2108.07258.</p>
<p>Language Models as Knowledge Bases?. F Petroni, Petroni, F. et al. Language Models as Knowledge Bases? 2019. https://arxiv. org/abs/1909.01066.</p>
<p>How Can We Know What Language Models Know?. Z Jiang, F F Xu, J Araki, G Neubig, Jiang, Z., Xu, F. F., Araki, J. &amp; Neubig, G. How Can We Know What Language Models Know? 2019. https://arxiv.org/abs/1911.12543.</p>
<p>Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models. A Tamkin, M Brundage, J Clark, D Ganguli, Tamkin, A., Brundage, M., Clark, J. &amp; Ganguli, D. Understanding the Ca- pabilities, Limitations, and Societal Impact of Large Language Models 2021. https://arxiv.org/abs/2102.02503.</p>
<p>D Loureiro, F Barbieri, L Neves, L E Anke, J Camacho-Collados, Timelms, Diachronic Language Models from Twitter 2022. Loureiro, D., Barbieri, F., Neves, L., Anke, L. E. &amp; Camacho-Collados, J. TimeLMs: Diachronic Language Models from Twitter 2022. https://arxiv. org/abs/2202.03829.</p>
<p>Finetuned Language Models Are Zero-Shot Learners. J Wei, Wei, J. et al. Finetuned Language Models Are Zero-Shot Learners 2021. https: //arxiv.org/abs/2109.01652.</p>
<p>S Min, M Lewis, L Zettlemoyer, H Hajishirzi, Metaicl, Learning to Learn In Context 2021. Min, S., Lewis, M., Zettlemoyer, L. &amp; Hajishirzi, H. MetaICL: Learning to Learn In Context 2021. https://arxiv.org/abs/2110.15943.</p>
<p>The Cost of Training NLP Models: A Concise Overview 2020. O Sharir, B Peleg, Y Shoham, Sharir, O., Peleg, B. &amp; Shoham, Y. The Cost of Training NLP Models: A Concise Overview 2020. https://arxiv.org/abs/2004.08900.</p>
<p>Sustainable AI: Environmental Implications, Challenges and Opportunities. C.-J Wu, Wu, C.-J. et al. Sustainable AI: Environmental Implications, Challenges and Opportunities 2021. https://arxiv.org/abs/2111.00364.</p>
<p>Energy and Policy Considerations for Deep Learning. E Strubell, A Ganesh, A Mccallum, NLP in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (Association for Computational Linguistics. Florence, ItalyStrubell, E., Ganesh, A. &amp; McCallum, A. Energy and Policy Considerations for Deep Learning in NLP in Proceedings of the 57th Annual Meeting of the Asso- ciation for Computational Linguistics (Association for Computational Linguis- tics, Florence, Italy, July 2019), 3645-3650. https://aclanthology.org/P19- 1355.</p>
<p>Break It Down: A Question Understanding Benchmark 2020. T Wolfson, Wolfson, T. et al. Break It Down: A Question Understanding Benchmark 2020. https://arxiv.org/abs/2001.11770.</p>
<p>The Power of Scale for Parameter-Efficient Prompt Tuning. B Lester, R Al-Rfou, N Constant, Lester, B., Al-Rfou, R. &amp; Constant, N. The Power of Scale for Parameter- Efficient Prompt Tuning 2021. https://arxiv.org/abs/2104.08691.</p>            </div>
        </div>

    </div>
</body>
</html>