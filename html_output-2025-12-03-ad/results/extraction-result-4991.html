<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4991 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4991</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4991</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-105.html">extraction-schema-105</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <p><strong>Paper ID:</strong> paper-85996f9fc312777f487dd51bf9e96bb3704c2fb7</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/85996f9fc312777f487dd51bf9e96bb3704c2fb7" target="_blank">On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> The results show that LLM's ability to autonomously generate executable plans is quite meager, averaging only about 3% success rate, and the heuristic and human-in-the-loop modes show slightly more promise.</p>
                <p><strong>Paper Abstract:</strong> Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) how good LLMs are by themselves in generating and validating simple plans in commonsense planning tasks (of the type that humans are generally quite good at) and (2) how good LLMs are in being a source of heuristic guidance for other agents--either AI planners or human planners--in their planning tasks. To investigate these questions in a systematic rather than anecdotal manner, we start by developing a benchmark suite based on the kinds of domains employed in the International Planning Competition. On this benchmark, we evaluate LLMs in three modes: autonomous, heuristic and human-in-the-loop. Our results show that LLM's ability to autonomously generate executable plans is quite meager, averaging only about 3% success rate. The heuristic and human-in-the-loop modes show slightly more promise. In addition to these results, we also make our benchmark and evaluation tools available to support investigations by research community.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4991.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4991.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Instruct-GPT3_fewshot_pattern</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Instruct-GPT3 (few-shot example-based prompting; pattern-matching behavior)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper evaluates Instruct-GPT3 (text-davinci-002) using few-shot prompts that include a lifted domain description and example problem(s) with solution plans; the model appears to rely on pattern-matching to the example plans rather than deriving a general internal planning model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Training language models to follow instructions with human feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Instruct-GPT3 (text-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned GPT-3 variant (OpenAI) used in the paper; large autoregressive transformer trained with human feedback to follow instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Few-shot example-based prompting (single-example template)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>The prompt contains a domain description and a small number of solved example instances (plans). The model is then asked to produce a plan for a new instance; similarity is achieved by showing the model a single or small set of near-identical example plans so the model produces outputs matching that pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Blocksworld Plan Generation & Optimal Planning</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense block-manipulation planning tasks (Blocksworld) with problems specified by initial state and goal; tasks include plan generation, cost-optimal planning, and related auxiliary reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Plan Generation: 41/600 (6.8%); Optimal Planning: 35/600 (5.8%); Replanning: 40/600 (6.6%); Plan Generalization: 49/500 (9.8%); Plan Reuse: 102/600 (17.0%); Robustness (goal-ordering): 467/600 (77.8%); Robustness (full->partial): 467/600 (77.8%); Robustness (partial->full): 363/600 (60.5%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Instruct-GPT3 outperforms vanilla GPT-3 and BLOOM on many tasks but still performs poorly overall on autonomous plan generation and optimal planning; its accuracy drops drastically when the example plan in the prompt is replaced, suggesting reliance on pattern-matching (similar reasoning) rather than inducing a robust internal model.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Despite better scores than other LLMs, success rates remain low (~5–17% on core planning tasks); performance is highly sensitive to the particular example plan shown (replacement of the example caused large accuracy drops).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4991.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4991.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT3_fewshot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (davinci) few-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The vanilla GPT-3 model (davinci) evaluated with the same few-shot example-based prompting; shows very low autonomous planning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models are few-shot learners.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large autoregressive transformer (Brown et al.), few-shot capable; used in vanilla (non-instruction-tuned) configuration in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Few-shot example-based prompting (single-example template)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Same prompting design as for Instruct-GPT3: domain description plus one or a few example problem/plan pairs used to elicit a plan for a new instance; promotes repetition of the shown pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Blocksworld Plan Generation & Optimal Planning</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Blocksworld planning tasks including plan generation, optimal planning, replanning and auxiliary reasoning tests.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Plan Generation: 6/600 (1.0%); Optimal Planning: 2/600 (0.3%); Replanning: 47/600 (7.8%); Plan Generalization: 33/500 (6.6%); Plan Reuse: 0/600 (0%); Robustness (goal-ordering): 460/600 (76.6%); Robustness (full->partial): 407/600 (67.8%); Robustness (partial->full): 122/600 (20.3%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Vanilla GPT-3 performs substantially worse than the instruction-tuned variant and BLOOM on several auxiliary tasks; success on core planning tasks is near-zero, indicating few-shot prompting alone (as implemented) is insufficient for reliable autonomous planning.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Failed to solve any 5-block instances; could only generate correct plans with optimal length <= 8; large majority of generated plans were incorrect.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4991.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4991.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BLOOM_fewshot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BLOOM (few-shot prompting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The open-access BLOOM 176B model was evaluated with the same few-shot prompting pipeline and showed overall poor performance across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BigScience Large Open-science Open-access Multilingual Language Model.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BLOOM (176B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large multilingual autoregressive transformer (BigScience/BLOOM) with 176B parameters; evaluated with few-shot prompts in the study.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Few-shot example-based prompting (single-example template)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Prompting with domain description and example plans; model is expected to produce a plan for a new instance by following provided examples.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Blocksworld Plan Generation & Related Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same Blocksworld tasks used for GPT-3 variants: plan generation, optimal planning, replanning, generalization, plan reuse, robustness checks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Plan Generation: 4/250 (1.6%); Optimal Planning: 3/150 (2.0%); Replanning: 3/100 (3.0%); Plan Generalization: 11/100 (11.0%); Plan Reuse: 0/100 (0%); Robustness (goal-ordering): 21/100 (21.0%); Robustness (full->partial): 9/100 (9.0%); Robustness (partial->full): 5/100 (5.0%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BLOOM performed poorly across most tasks and was generally worse than Instruct-GPT3; robustness tests that only required reproduction of example plans yielded slightly better results but still low absolute performance.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Poor performance even on auxiliary tasks where reproduction of an example plan should suffice, indicating sensitivity to prompt/template and weaker few-shot pattern reproduction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4991.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4991.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FineTuned-GPT3_blocksworld</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fine-tuned GPT-3 on Blocksworld instances</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-3 (davinci) model fine-tuned on 1000 blocksworld instances (initial state, goal, plan) showed improved but still limited autonomous planning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Fine-tuned GPT-3 (davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3 model fine-tuned on a domain-specific dataset of 1000 blocksworld instances using OpenAI's default fine-tuning hyperparameters (80-20 split).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Fine-tuning on domain transitions / supervised imitation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>Supervised fine-tuning on many examples of (initial state, goal, plan) pairs so the model internalizes domain-specific plan patterns rather than relying only on few-shot examples at inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Blocksworld Plan Generation & Optimal Planning (test set)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same blocksworld planning tasks; evaluation on held-out test instances not used in fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Plan Generation: 82/500 (16.4%); Optimal Planning: 110/500 (22.0%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Fine-tuning substantially increased correct-plan rates relative to few-shot vanilla/instruct GPT-3 (from single-digit % to ~16–22%), but overall performance remained far from human baselines, indicating fine-tuning helps but does not make LLMs robust planners.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Even after fine-tuning, success rates remained low (~20%), consistent with observations that LLMs tend to exploit statistical patterns rather than learning robust causal transition models (cited discussion and [36]).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4991.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4991.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM+LPG_heuristic_repair</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-generated seed plans repaired by LPG (heuristic mode)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper evaluates using LLM outputs as seed plans for LPG, a sound local-search planner that repairs candidate plans to produce correct, executable plans; this hybrid reliably produced valid plans, showing utility of LLMs as heuristic idea generators.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Instruct-GPT3 (seed plan) + LPG planner</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruct-GPT3 provides an initial (possibly flawed) plan; LPG (local search planner for planning graphs with action costs) takes the seed and repairs it to a valid plan using model-based search and flaw repair.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Seed-plan heuristics + planner-based repair</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>LLM generates an initial candidate plan (heuristic guidance); a sound automated planner (LPG) uses local search to identify and remove flaws in the candidate to produce a correct plan. Diversity/similarity not directly applicable—method leverages LLM's approximate output and planner's model-based correction.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Blocksworld Plan Generation (heuristic mode)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>LLM-generated plans for Blocksworld are used as initial partial/seed plans for LPG which then performs local search-based repairs to produce sound plans.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>All evaluated LLM+LPG combinations produced valid plans for the tested 600 instances (i.e., post-repair success = 100% for cases fed into LPG); average Levenshtein edit distance between LLM seed and final LPG plan = 7.22; average final plan length = 11.7; total solution generation (including API call) within ~7 seconds.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>Instruct-GPT3 alone (autonomous): Plan Generation 41/600 (6.8%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM-produced plans, though usually incorrect autonomously, can serve as effective heuristics for a sound planner which can repair them to guarantee correctness; LPG often makes substantial edits (edit distance ~7.22), indicating the LLM seeds are partial/approximate rather than near-correct.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>While repair always yielded a correct plan in their tests, the significant average edit distance implies the LLM proposals were often far from the final correct solution (>50% of plan content may be due to LPG edits), so LLMs are not reliable standalone planners but can speed up planning when combined with model-based repair.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4991.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4991.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Human-in-the-loop_LLM_suggestions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Human planners assisted by LLM-generated plan suggestions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>User study where human participants either received no assistance or an LLM-generated plan suggestion (from Instruct-GPT3); assessed whether LLM suggestions improve human planning accuracy and reduce cognitive load.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Instruct-GPT3 (used to generate suggestions)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned GPT-3 used to create plan suggestions shown to human participants during a Blocksworld planning interface study.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Assistive suggestion (single suggestion shown to human)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>LLM generates a single plan suggestion which is presented to human planners as an optional aid; humans may accept, modify, or reject the suggestion—this evaluates whether LLM-provided heuristics improve human performance.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Blocksworld planning (human-in-the-loop user study)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>IRB-approved between-subjects study where one group planned unaided and the other had LLM suggestions; measured final plan correctness, time, and subjective cognitive load (NASA-TLX).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Human baseline (no assistance): 17/23 participants produced correct plans (74%). Human + LLM suggestion: 18/22 participants produced correct plans (82%). T-tests on time and cognitive load were not statistically significant (p-values 0.81 and 0.78 respectively).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td>Human baseline (no assistance): 74% correct vs LLM-assisted: 82% correct (difference not statistically significant).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM suggestions yielded a modest increase in human plan correctness (74% -> 82%) but the improvement was not statistically significant; small number of participants accepted the LLM suggestion verbatim (automation-bias risk).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No statistically significant reduction in time or cognitive load for LLM-assisted group; some participants accepted flawed LLM suggestions as-is, indicating risk of automation bias rather than consistent improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4991.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4991.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse versus similar reasoning methods to solve reasoning problems, including descriptions of the reasoning methods, tasks, performance, and any comparisons or findings about the effectiveness of diverse versus similar reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought_mention</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites chain-of-thought prompting as part of related work (Wei et al.) but does not employ it in experiments; chain-of-thought is a prompting method that elicits intermediate reasoning steps from LLMs to improve complex reasoning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs (in referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Chain-of-thought is a prompting technique applied to large autoregressive LLMs to produce step-by-step rationales.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_description</strong></td>
                            <td>As described in related work, chain-of-thought elicits multi-step intermediate reasoning traces; diversity can be introduced by sampling or multiple chains (e.g., self-consistency ensembles) to improve final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>General multi-step reasoning benchmarks (referenced in related work)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Benchmarks for eliciting multi-step reasoning (e.g., arithmetic, word problems) where intermediate chains improve final answer accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_other_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned in related work but not evaluated in this paper; the authors did not apply chain-of-thought or ensemble/diverse prompting to the Blocksworld planning tasks and therefore provide no empirical comparison within their experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>Not applicable within this paper — chain-of-thought methods were not tested, so no negative or positive results are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models. <em>(Rating: 2)</em></li>
                <li>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. <em>(Rating: 2)</em></li>
                <li>Do as i can, not as i say: Grounding language in robotic affordances. <em>(Rating: 2)</em></li>
                <li>PDDL planning with pretrained large language models. <em>(Rating: 2)</em></li>
                <li>Decision transformer: Reinforcement learning via sequence modeling. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4991",
    "paper_id": "paper-85996f9fc312777f487dd51bf9e96bb3704c2fb7",
    "extraction_schema_id": "extraction-schema-105",
    "extracted_data": [
        {
            "name_short": "Instruct-GPT3_fewshot_pattern",
            "name_full": "Instruct-GPT3 (few-shot example-based prompting; pattern-matching behavior)",
            "brief_description": "The paper evaluates Instruct-GPT3 (text-davinci-002) using few-shot prompts that include a lifted domain description and example problem(s) with solution plans; the model appears to rely on pattern-matching to the example plans rather than deriving a general internal planning model.",
            "citation_title": "Training language models to follow instructions with human feedback.",
            "mention_or_use": "use",
            "model_name": "Instruct-GPT3 (text-davinci-002)",
            "model_description": "Instruction-tuned GPT-3 variant (OpenAI) used in the paper; large autoregressive transformer trained with human feedback to follow instructions.",
            "reasoning_method_name": "Few-shot example-based prompting (single-example template)",
            "reasoning_method_type": "similar",
            "reasoning_method_description": "The prompt contains a domain description and a small number of solved example instances (plans). The model is then asked to produce a plan for a new instance; similarity is achieved by showing the model a single or small set of near-identical example plans so the model produces outputs matching that pattern.",
            "task_name": "Blocksworld Plan Generation & Optimal Planning",
            "task_description": "Commonsense block-manipulation planning tasks (Blocksworld) with problems specified by initial state and goal; tasks include plan generation, cost-optimal planning, and related auxiliary reasoning tasks.",
            "performance": "Plan Generation: 41/600 (6.8%); Optimal Planning: 35/600 (5.8%); Replanning: 40/600 (6.6%); Plan Generalization: 49/500 (9.8%); Plan Reuse: 102/600 (17.0%); Robustness (goal-ordering): 467/600 (77.8%); Robustness (full-&gt;partial): 467/600 (77.8%); Robustness (partial-&gt;full): 363/600 (60.5%).",
            "comparison_with_other_method": false,
            "performance_other_method": null,
            "key_findings": "Instruct-GPT3 outperforms vanilla GPT-3 and BLOOM on many tasks but still performs poorly overall on autonomous plan generation and optimal planning; its accuracy drops drastically when the example plan in the prompt is replaced, suggesting reliance on pattern-matching (similar reasoning) rather than inducing a robust internal model.",
            "counter_examples_or_negative_results": "Despite better scores than other LLMs, success rates remain low (~5–17% on core planning tasks); performance is highly sensitive to the particular example plan shown (replacement of the example caused large accuracy drops).",
            "uuid": "e4991.0",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "GPT3_fewshot",
            "name_full": "GPT-3 (davinci) few-shot prompting",
            "brief_description": "The vanilla GPT-3 model (davinci) evaluated with the same few-shot example-based prompting; shows very low autonomous planning performance.",
            "citation_title": "Language models are few-shot learners.",
            "mention_or_use": "use",
            "model_name": "GPT-3 (davinci)",
            "model_description": "Large autoregressive transformer (Brown et al.), few-shot capable; used in vanilla (non-instruction-tuned) configuration in experiments.",
            "reasoning_method_name": "Few-shot example-based prompting (single-example template)",
            "reasoning_method_type": "similar",
            "reasoning_method_description": "Same prompting design as for Instruct-GPT3: domain description plus one or a few example problem/plan pairs used to elicit a plan for a new instance; promotes repetition of the shown pattern.",
            "task_name": "Blocksworld Plan Generation & Optimal Planning",
            "task_description": "Blocksworld planning tasks including plan generation, optimal planning, replanning and auxiliary reasoning tests.",
            "performance": "Plan Generation: 6/600 (1.0%); Optimal Planning: 2/600 (0.3%); Replanning: 47/600 (7.8%); Plan Generalization: 33/500 (6.6%); Plan Reuse: 0/600 (0%); Robustness (goal-ordering): 460/600 (76.6%); Robustness (full-&gt;partial): 407/600 (67.8%); Robustness (partial-&gt;full): 122/600 (20.3%).",
            "comparison_with_other_method": false,
            "performance_other_method": null,
            "key_findings": "Vanilla GPT-3 performs substantially worse than the instruction-tuned variant and BLOOM on several auxiliary tasks; success on core planning tasks is near-zero, indicating few-shot prompting alone (as implemented) is insufficient for reliable autonomous planning.",
            "counter_examples_or_negative_results": "Failed to solve any 5-block instances; could only generate correct plans with optimal length &lt;= 8; large majority of generated plans were incorrect.",
            "uuid": "e4991.1",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "BLOOM_fewshot",
            "name_full": "BLOOM (few-shot prompting)",
            "brief_description": "The open-access BLOOM 176B model was evaluated with the same few-shot prompting pipeline and showed overall poor performance across tasks.",
            "citation_title": "BigScience Large Open-science Open-access Multilingual Language Model.",
            "mention_or_use": "use",
            "model_name": "BLOOM (176B)",
            "model_description": "Large multilingual autoregressive transformer (BigScience/BLOOM) with 176B parameters; evaluated with few-shot prompts in the study.",
            "reasoning_method_name": "Few-shot example-based prompting (single-example template)",
            "reasoning_method_type": "similar",
            "reasoning_method_description": "Prompting with domain description and example plans; model is expected to produce a plan for a new instance by following provided examples.",
            "task_name": "Blocksworld Plan Generation & Related Tasks",
            "task_description": "Same Blocksworld tasks used for GPT-3 variants: plan generation, optimal planning, replanning, generalization, plan reuse, robustness checks.",
            "performance": "Plan Generation: 4/250 (1.6%); Optimal Planning: 3/150 (2.0%); Replanning: 3/100 (3.0%); Plan Generalization: 11/100 (11.0%); Plan Reuse: 0/100 (0%); Robustness (goal-ordering): 21/100 (21.0%); Robustness (full-&gt;partial): 9/100 (9.0%); Robustness (partial-&gt;full): 5/100 (5.0%).",
            "comparison_with_other_method": false,
            "performance_other_method": null,
            "key_findings": "BLOOM performed poorly across most tasks and was generally worse than Instruct-GPT3; robustness tests that only required reproduction of example plans yielded slightly better results but still low absolute performance.",
            "counter_examples_or_negative_results": "Poor performance even on auxiliary tasks where reproduction of an example plan should suffice, indicating sensitivity to prompt/template and weaker few-shot pattern reproduction.",
            "uuid": "e4991.2",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "FineTuned-GPT3_blocksworld",
            "name_full": "Fine-tuned GPT-3 on Blocksworld instances",
            "brief_description": "A GPT-3 (davinci) model fine-tuned on 1000 blocksworld instances (initial state, goal, plan) showed improved but still limited autonomous planning performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Fine-tuned GPT-3 (davinci)",
            "model_description": "GPT-3 model fine-tuned on a domain-specific dataset of 1000 blocksworld instances using OpenAI's default fine-tuning hyperparameters (80-20 split).",
            "reasoning_method_name": "Fine-tuning on domain transitions / supervised imitation",
            "reasoning_method_type": "other",
            "reasoning_method_description": "Supervised fine-tuning on many examples of (initial state, goal, plan) pairs so the model internalizes domain-specific plan patterns rather than relying only on few-shot examples at inference time.",
            "task_name": "Blocksworld Plan Generation & Optimal Planning (test set)",
            "task_description": "Same blocksworld planning tasks; evaluation on held-out test instances not used in fine-tuning.",
            "performance": "Plan Generation: 82/500 (16.4%); Optimal Planning: 110/500 (22.0%).",
            "comparison_with_other_method": false,
            "performance_other_method": null,
            "key_findings": "Fine-tuning substantially increased correct-plan rates relative to few-shot vanilla/instruct GPT-3 (from single-digit % to ~16–22%), but overall performance remained far from human baselines, indicating fine-tuning helps but does not make LLMs robust planners.",
            "counter_examples_or_negative_results": "Even after fine-tuning, success rates remained low (~20%), consistent with observations that LLMs tend to exploit statistical patterns rather than learning robust causal transition models (cited discussion and [36]).",
            "uuid": "e4991.3",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "LLM+LPG_heuristic_repair",
            "name_full": "LLM-generated seed plans repaired by LPG (heuristic mode)",
            "brief_description": "The paper evaluates using LLM outputs as seed plans for LPG, a sound local-search planner that repairs candidate plans to produce correct, executable plans; this hybrid reliably produced valid plans, showing utility of LLMs as heuristic idea generators.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Instruct-GPT3 (seed plan) + LPG planner",
            "model_description": "Instruct-GPT3 provides an initial (possibly flawed) plan; LPG (local search planner for planning graphs with action costs) takes the seed and repairs it to a valid plan using model-based search and flaw repair.",
            "reasoning_method_name": "Seed-plan heuristics + planner-based repair",
            "reasoning_method_type": "other",
            "reasoning_method_description": "LLM generates an initial candidate plan (heuristic guidance); a sound automated planner (LPG) uses local search to identify and remove flaws in the candidate to produce a correct plan. Diversity/similarity not directly applicable—method leverages LLM's approximate output and planner's model-based correction.",
            "task_name": "Blocksworld Plan Generation (heuristic mode)",
            "task_description": "LLM-generated plans for Blocksworld are used as initial partial/seed plans for LPG which then performs local search-based repairs to produce sound plans.",
            "performance": "All evaluated LLM+LPG combinations produced valid plans for the tested 600 instances (i.e., post-repair success = 100% for cases fed into LPG); average Levenshtein edit distance between LLM seed and final LPG plan = 7.22; average final plan length = 11.7; total solution generation (including API call) within ~7 seconds.",
            "comparison_with_other_method": true,
            "performance_other_method": "Instruct-GPT3 alone (autonomous): Plan Generation 41/600 (6.8%).",
            "key_findings": "LLM-produced plans, though usually incorrect autonomously, can serve as effective heuristics for a sound planner which can repair them to guarantee correctness; LPG often makes substantial edits (edit distance ~7.22), indicating the LLM seeds are partial/approximate rather than near-correct.",
            "counter_examples_or_negative_results": "While repair always yielded a correct plan in their tests, the significant average edit distance implies the LLM proposals were often far from the final correct solution (&gt;50% of plan content may be due to LPG edits), so LLMs are not reliable standalone planners but can speed up planning when combined with model-based repair.",
            "uuid": "e4991.4",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "Human-in-the-loop_LLM_suggestions",
            "name_full": "Human planners assisted by LLM-generated plan suggestions",
            "brief_description": "User study where human participants either received no assistance or an LLM-generated plan suggestion (from Instruct-GPT3); assessed whether LLM suggestions improve human planning accuracy and reduce cognitive load.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Instruct-GPT3 (used to generate suggestions)",
            "model_description": "Instruction-tuned GPT-3 used to create plan suggestions shown to human participants during a Blocksworld planning interface study.",
            "reasoning_method_name": "Assistive suggestion (single suggestion shown to human)",
            "reasoning_method_type": "other",
            "reasoning_method_description": "LLM generates a single plan suggestion which is presented to human planners as an optional aid; humans may accept, modify, or reject the suggestion—this evaluates whether LLM-provided heuristics improve human performance.",
            "task_name": "Blocksworld planning (human-in-the-loop user study)",
            "task_description": "IRB-approved between-subjects study where one group planned unaided and the other had LLM suggestions; measured final plan correctness, time, and subjective cognitive load (NASA-TLX).",
            "performance": "Human baseline (no assistance): 17/23 participants produced correct plans (74%). Human + LLM suggestion: 18/22 participants produced correct plans (82%). T-tests on time and cognitive load were not statistically significant (p-values 0.81 and 0.78 respectively).",
            "comparison_with_other_method": true,
            "performance_other_method": "Human baseline (no assistance): 74% correct vs LLM-assisted: 82% correct (difference not statistically significant).",
            "key_findings": "LLM suggestions yielded a modest increase in human plan correctness (74% -&gt; 82%) but the improvement was not statistically significant; small number of participants accepted the LLM suggestion verbatim (automation-bias risk).",
            "counter_examples_or_negative_results": "No statistically significant reduction in time or cognitive load for LLM-assisted group; some participants accepted flawed LLM suggestions as-is, indicating risk of automation bias rather than consistent improvement.",
            "uuid": "e4991.5",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "Chain-of-Thought_mention",
            "name_full": "Chain-of-Thought prompting",
            "brief_description": "The paper cites chain-of-thought prompting as part of related work (Wei et al.) but does not employ it in experiments; chain-of-thought is a prompting method that elicits intermediate reasoning steps from LLMs to improve complex reasoning performance.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models.",
            "mention_or_use": "mention",
            "model_name": "various LLMs (in referenced work)",
            "model_description": "Chain-of-thought is a prompting technique applied to large autoregressive LLMs to produce step-by-step rationales.",
            "reasoning_method_name": "Chain-of-Thought prompting",
            "reasoning_method_type": "diverse",
            "reasoning_method_description": "As described in related work, chain-of-thought elicits multi-step intermediate reasoning traces; diversity can be introduced by sampling or multiple chains (e.g., self-consistency ensembles) to improve final answers.",
            "task_name": "General multi-step reasoning benchmarks (referenced in related work)",
            "task_description": "Benchmarks for eliciting multi-step reasoning (e.g., arithmetic, word problems) where intermediate chains improve final answer accuracy.",
            "performance": null,
            "comparison_with_other_method": null,
            "performance_other_method": null,
            "key_findings": "Mentioned in related work but not evaluated in this paper; the authors did not apply chain-of-thought or ensemble/diverse prompting to the Blocksworld planning tasks and therefore provide no empirical comparison within their experiments.",
            "counter_examples_or_negative_results": "Not applicable within this paper — chain-of-thought methods were not tested, so no negative or positive results are reported here.",
            "uuid": "e4991.6",
            "source_info": {
                "paper_title": "On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)",
                "publication_date_yy_mm": "2023-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models.",
            "rating": 2
        },
        {
            "paper_title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.",
            "rating": 2
        },
        {
            "paper_title": "Do as i can, not as i say: Grounding language in robotic affordances.",
            "rating": 2
        },
        {
            "paper_title": "PDDL planning with pretrained large language models.",
            "rating": 2
        },
        {
            "paper_title": "Decision transformer: Reinforcement learning via sequence modeling.",
            "rating": 1
        }
    ],
    "cost": 0.01717475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)</h1>
<p>Karthik Valmeekam<br>School of Computing \&amp; AI<br>Arizona State University, Tempe.<br>kvalmeek@asu.edu</p>
<p>Sarath Sreedharan*<br>Department of Computer Science, Colorado State University, Fort Collins. sarath.sreedharan@colostate.edu</p>
<p>Matthew Marquez<br>School of Computing \&amp; AI<br>Arizona State University, Tempe. mmarqu22@asu.edu</p>
<h2>Alberto Olmo</h2>
<p>School of Computing \&amp; AI
Arizona State University, Tempe.
aolmoher@asu.edu</p>
<p>Subbarao Kambhampati<br>School of Computing \&amp; AI<br>Arizona State University, Tempe.<br>rao@asu.edu</p>
<h4>Abstract</h4>
<p>Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) how good LLMs are by themselves in generating and validating simple plans in commonsense planning tasks (of the type that humans are generally quite good at) and (2) how good LLMs are in being a source of heuristic guidance for other agents-either AI planners or human planners-in their planning tasks. To investigate these questions in a systematic rather than anecdotal manner, we start by developing a benchmark suite based on the kinds of domains employed in the International Planning Competition. On this benchmark, we evaluate LLMs in three modes: autonomous, heuristic and human-in-the-loop. Our results show that LLM's ability to autonomously generate executable plans is quite meager, averaging only about $3 \%$ success rate. The heuristic and human-in-the-loop modes show slightly more promise. In addition to these results, we also make our benchmark and evaluation tools available to support investigations by research community.</p>
<h2>1 Introduction</h2>
<p>It would be no exaggeration to say that transformer-based large language models (LLMs) have revolutionized the field of natural language processing (NLP). Kicked off by the advances presented by the GPT-x models developed by OpenAI [24], these types of language models currently provide state-of-the-art performance in many of the standard NLP tasks. Although LLMs were originally developed mostly to do word sequence completion tasks, with no guarantees about the completion beyond its coherence, there have been increasing claims and anecdotal evidence that they have other emergent capabilities that are not normally associated with sequence completion. Indeed, the hints of such emergent capabilities has started a veritable land rush, with researchers probing (prompting) and studying LLM behavior almost as if they were artificial organisms (c.f. [17]). Of particular interest to us in this paper is the thread of efforts that aim to investigate (and showcase) reasoning abilities of LLMs-including commonsense reasoning [33, 27, 10], logical reasoning [31], and even ethical reasoning [16]. The macro-tenor of the drumbeat of these works has been suggesting that LLM's are indeed capable of doing such kinds of reasoning [18, 35, 5].
One type of reasoning task that has been well studied in the AI community is planning and sequential decision making. At its simplest, planning involves developing a course of actions (policy) which when executed takes the agent to a desired state of the world. Planning has generally been studied primarily as an inference on world and reward models-whether specified by humans or learned by the agent by interacting with its world. In this paper, we are interested in seeing what planning abilities, if any, LLMs may already have, given their high capacity functions (with</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>billions of tunable parameters) trained on web-scale corpora. Specifically, we are interested in answering two broad questions:</p>
<ul>
<li>How good are LLMs by themselves in generating and validating simple plans in commonsense planning tasks (of the type that humans are generally quite good at)?</li>
<li>How good are LLMs in being a source of heuristic guidance for other agents-either AI planners or human planners-in their planning tasks?</li>
</ul>
<p>Notice that in theory it is possible for LLMs to be very effective as idea generators for humans in the loop in computersupported cooperative work scenarios, while themselves being very bad at generating plans that are guaranteed to be correct. This is especially likely because the chief power of LLMs comes from their pattern finding abilities than on first-principles simulations over world models. Compared to a planner that is guaranteed to be correct in a narrow set of domains, LLMs may likely be good at generating plausible (but not guaranteed to be correct) plan heuristics/suggestions in many more domains.
To investigate these questions in a systematic rather than anecdotal manner, we start by developing a benchmark suite ${ }^{2}$ based on the kinds of domains employed in the International Planning Competition [15]. The tasks in the benchmark suite are aimed to test a variety of plan generation and validation capabilities. To eliminate the subjective aspect of analysis that forms the core part of many earlier efforts on evaluating reasoning capabilities of LLMs, we automate the evaluation by leveraging models and tools from the automated planning community. While our primary interest is in plan generation, the test tasks themselves form a broad curriculum for evaluating LLM's capabilities of reasoning about actions and change.
The evaluation itself is done in three modes. In the first "autonomous" mode, LLMs are used as stand alone, and we directly assess the quality and correctness of plans they generate. As we shall see, the results in the autonomous mode are pretty bleak. Only about $3 \%$ of the plans that LLMs generate are actually executable without errors and reach their goals. We will show that the choice of the specific LLM (we experimented with two versions of GPT3 [3, 21] as well as BLOOM [28]), as well as fine tuning seems to have little effect on this dismal performance. We also give a human baseline by presenting these tasks to human subjects (through IRB-approved studies) and evaluating the quality and correctness of their plans. These results are substantially better than those of LLMs-confirming that LLMs can't plan in autonomous mode.
In the second "heuristic" mode, the plans produced by LLMs are given as input to an automated planner working off of a correct domain model to check how easy it is to "repair" the LLM plans to guarantee their correctness. Specifically we show that a well known automated planner called LPG [9], that uses local search to locate and remove flaws in a candidate plan to make it correct, is able to repair the LLM plans with relative ease.
In the third "human-in-the-loop mode", the LLM plans are given to humans in the loop to see how it affects their ability to solve the bench mark tasks. The results here show modest improvements in the accuracy of the plans generated by humans when they start with LLM suggested plans.
Beyond our own initial studies, the goal of this work is to provide a systematic benchmark to evaluate the (evolving) planning capabilities of LLMs. To this end, we make the benchmark suite and the automated evaluation tools public to support further research.</p>
<h1>2 Related Work</h1>
<p>There have been a few earlier works that looked at the planning capabilities of LLMs. Most of them, such as [14, 2] focus on commonsense domains (e.g. moving things in kitchens) and thus evaluate "zero shot" capabilities of LLMs. One issue is that in such cases, it is hard to make a judgment about the correctness of the plan, as there is no accepted world model and the humans often give the benefit of doubt for a plausible-but not actually executable-plan. ${ }^{3}$ Not surprisingly, the works such as SayCan [2], that actually care about executability, limit themselves to using LLMs in what we are calling "heuristic-mode"-with the actions suggested by the LLM being vetted by the underlying sound planner or a reinforcement learner with access to a faithful domain simulator. In our work, in contrast, we assume and allow for the problem and domain model to be specified as part of the prompt-thus allowing us to precisely evaluate the executability and quality of the plans suggested by LLMs. The ability to be conditional on the prompt is also critical for such general systems to be customized for the specific domain of interest. Finally, after our initial study and benchmark</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>were made public, another group did a parallel study that largely corroborates our results on the ineffectiveness of LLMs in finding executable plans [29].
While this paper focuses on the emergent planning abilities of LLMs not trained specifically on planning tasks, a separate question, that is also receiving attention in the literature, is how well do the underlying sequence completion LLM architectures-specifically transformers-do if trained exclusively on transition sequences. This is the question handled by works like decision transformer [4] and GATO [26]. Note that there is no a priori reason to believe that such direct training on transition sequences doesn't allow the trained transformer to predict plan completions with high accuracy. Indeed earlier works that used pre-transformer technologies such as word vectors have already shown the viability of such approaches for plan completion [38]. One question that is still not settled is whether transformers learn interpretable causal world models or mostly get by with pattern finding abilities.
The idea of developing benchmarks to evaluate emergent properties of LLMs is itself not new. Some prominent existing benchmarks include, BIG-BENCH [31] and Coin Flip [35]. One could also use datasets like GSM8K [6], AQUA [19], SVAMP [22], CommonsenseQA [33] and StrategyQA [10] for testing different shallow reasoning abilities. The contribution of our paper is a benchmark and curriculum for evaluating the planning capabilities of LLMs.</p>
<h1>3 Background on Automated Planning</h1>
<p>Given that we are interested in investigating the basic reasoning about actions and change problem, we want to look at the most fundamental planning formalism first, namely the goal-directed deterministic planning problem. Colloquially referred to as classical planning problem, these problem classes can be mathematically represented by using the tuple $\mathcal{P}=\langle\mathcal{D}, \mathcal{I}, \mathcal{G}\rangle . \mathcal{D}$ is referred to as the problem domain, $I$ is the initial state and $G$ is the goal specification. The state-space for the planning problem is defined by the possible truth assignment over the predicates. The domain is again defined by the tuple $\mathcal{D}=\langle\mathcal{F}, \mathcal{A}\rangle . \mathcal{F}$ corresponds to the set of fluents, i.e., the state variable used to define the state space and each fluent corresponds to a predicate with some arity, and $\mathcal{A}$ correspond to the set of actions that can be performed as part of the planning problem. Each action $a_{i}[\mathcal{V}] \in \mathcal{A}$ (where $a_{i}$ is the operator label and $\mathcal{V}$ is the variable used by the operator and each variable could be mapped to an object), can be further defined by two components, the precondition $\operatorname{prec}[\mathcal{V}]$ which describes when an action can be executed and the effects $e f f[\mathcal{V}]$ which defines what happens when an action is executed. We will assume that $\operatorname{prec}[\mathcal{V}]$ consists of a set of predicates defined over the variables $\mathcal{V}$. An action is assumed to be executable only if its preconditions are met, i.e, the predicates in the precondition hold in the given state. The effect set $e f f[\mathcal{V}]$ is further defined by the tuple $\langle a d d[\mathcal{V}], d e l[\mathcal{V}]\rangle$, where $a d d[\mathcal{V}]$ or add effects is the set of predicates that will be set true by the action and $d e l[\mathcal{V}]$ or delete effects is the set of predicates that will be set false by the action. An action is said to be grounded if we replace each of the variables with an object, else it is referred to as a lifted domain model (we use a similar convention to differentiate between lifted and grounded predicates).
Below we have provided a snippet of an action description from a popular benchmark problem called Blocksworld for action corresponding to picking up a block.</p>
<div class="codehilite"><pre><span></span><code>(:action pickup
    :parameters (?ob)
    :precondition (and (clear ?ob) (on-table ?ob) (arm-empty))
    :effect (and (holding ?ob) (not (clear ?ob)) (not (on-table ?ob))
        (not (arm-empty))))
</code></pre></div>

<p>The parameter line provides the possible variables, in this case ?ob, which can stand for possible blocks. The precondition says that you can only pick up a block if it is clear (i.e. predicate (clear ?ob) is true for the block), the block is on the table and the arm is empty. The effects tell you that after you execute the action, the predicate (holding ?ob) becomes true and the block will no longer be considered clear, and on-table. Finally, the arm will no longer be considered empty. A solution to a planning problem is called a plan, and corresponds to a sequence of actions that once executed in the initial state would lead to a state where the goal specification is true. The actions may additionally be associated with cost, in these cases, one could also talk about optimal plans, i.e., a plan $\pi$ is called an optimal one if no plan exists that is less costly than $\pi$.
The above description presents one of the simpler classes of planning models and can be extended in multiple ways including allowing for object typing (including type hierarchy), more complex forms of preconditions and conditional effects, not to mention supporting richer classes of planning formalisms.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The diagrammatic overview of the overall test framework. Our system consists of a domain-specific component that allows the generation of various instances of the specific PDDL planning problems and the translation from PDDL to text and back. The domain-independent component is responsible for generating the test instances that will be fed into the LLM and verifying the output generated by the LLM.</p>
<h1>4 Assessment Architecture</h1>
<p>Our basic test framework consists of two categories of components, the domain-independent ones, provided as part of the framework, and the domain-dependent components which need to be developed for each new domain we test.</p>
<h3>4.1 Domain independent component</h3>
<p>The domain-independent component is built around a planner and a plan verification component that takes various planning problems and crafts test instances corresponding to various curriculum items. This component provides the mechanism to verify the solutions generated by the LLM. The current method is going to operate almost exclusively on symbolic models (specifically ones specified using PDDL [1]) and other structured inputs compatible with such representations. The domain-dependent component would be responsible for translating outputs generated by the LLM into forms that can be used by the system.</p>
<h3>4.2 Domain dependent component</h3>
<p>The domain-dependent component consists of three main parts. A lifted domain model file, that describes the various actions that may be available to solve any given planning problem, the various predicates that could be used to describe the various relationships over the objects that may be present at a given problem instance of the domain, and the various types of objects that may be part of the given problem. The domain model is lifted because it does not refer to the actual objects that may be part of the problem, but instead, the actions are defined independently of the exact objects it may influence.</p>
<p>Problem generator: A planning problem consists of a description of the set of specific objects that are part of the specific planning problem, the initial state (described in terms of the truth values of the various predicates), and a goal description. A valid solution consists of a sequence of actions that can drive the system state to a state that satisfies the goal condition. The role of the problem generator is therefore to generate random problem instances consisting of various objects, initial states, and goals. These problems become the basis of generating the various test cases that we will be using throughout the framework. Any distributional requirements we hope to use in the tests could be built into this problem generator.</p>
<p>Translator: The translator converts the symbolic model information to natural language text and vice versa . In particular, we are interested in developing a mechanism to translate state information and plans into natural language descriptions similar to what would be provided to humans, thereby normalizing comparison between human planners and LLM planners. For the current testbed (described below), we developed a template-based mechanism to achieve this. In particular, we provide a natural language template for each predicate and each action, and we form texts of</p>
<p>states and plans by concatenating these individual strings. In terms of parsing natural language text back into structured forms, the particular task we are interested in is converting plans generated by the LLM back into plan forms that can be used by plan validator tools like [13]. Since we use our prompts to shape the LLM's output, we require each action in the plan to be listed on a different line. Then, we can parse the exact action and arguments of the action by either using template-based matching or by assuming that the verb in the sentence corresponds to the action and each noun corresponds to an object which forms a parameter of the action (then mapping it to a possible action).
The domain-independent component is responsible for generating the content for the various prompts that would be generated as part of the different test cases and for validating the output generated by the LLM. As discussed earlier, the component primarily works on formal representations of the problems, so it relies on the translator component to convert any information it generates to natural language or to convert natural language information back to formal representations. For each test case, we mainly rely on a domain-independent planner and a plan validator to generate the relevant information or to validate the output provided by the LLM. In each case, there is a test-case-specific component that uses the problems provided by the problem generator component to craft specific test-case content. In the next section, we go over each test case and the specific technique we use to generate the contents for the test case.</p>
<h1>5 Current Curriculum for Testing</h1>
<p>Each test case is meant to evaluate a central reasoning about actions and change capability and is tested in the context of a common sense planning domain. Each test case makes use of the few shot query setting of LLM where the LLM is provided a few sample answers to the specific reasoning ability being tested and is asked to respond to a new instance. The exact form of the prompt will depend on the specific test cases, but every instance will start with a description of the lifted planning domain that describes what actions can be executed, their preconditions and their effects. The current set of test cases includes the following cases:</p>
<ol>
<li>Plan Generation - Can the LLM come up with valid plans that will achieve a specific goal?</li>
<li>Cost Optimal Planning - Can the LLM come up with plans that are optimal to achieve a specific goal?</li>
<li>Reasoning about plan execution - Can the LLM reason about what happens when a plan is executed?</li>
<li>Robustness to goal reformulation - Can the LLM recognize the same goal when specified in different ways?</li>
<li>Ability to reuse plans - Can the LLM recognize scenarios where it can reuse part or the whole of the original plan to achieve the new goal?</li>
<li>Replanning - Can the LLM replan for cases where an unexpected change is reported?</li>
<li>Plan Generalization - Can the LLM take specific plans, extract underlying procedural patterns and apply them to a new instance?</li>
</ol>
<p>Out of the seven test cases, the first two test cases correspond to actual planning problems (i.e. plan generation and cost-optimal planning) and the rest correspond to simpler auxiliary tasks related to reasoning about action and change. Currently, we ground the test cases in a simple common-sense planning domain, Blocksworld. Blocksworld problems generally consist of a set of blocks, for making it closer to a common sense domain identified with unique colors, placed either on a table or on top of other blocks and the goal is to arrange some of these blocks in a stack in a particular order. The general expectation here would be that one can pick up a block if it is clear, i.e., there are no other blocks on top of that block and you can only stack a block on top of another block if it is clear. The choice of this particular domain is motivated by both the fact that this is a simple common sense domain and is a very popular domain in planning literature, that has a long history of being used to demonstrate various planning challenges. The domain description is included in the beginning of every prompt. In the rest of the section, we discuss the structure of the prompt for each of the test cases. We provide an example prompt and the corresponding completion generated by GPT-3 for each of the test cases in the Appendix.</p>
<h3>5.1 Plan Generation</h3>
<p>Following the lifted domain description, the prompt consists of a few instances of planning problem descriptions (consisting of a description of the initial state, the goal) and the corresponding plan (which ends with a tag, henceforth referred to as the plan-end tag, that denotes the end of the plan) and finally, we end the prompt with a planning problem description. The text generated by the LLM until the plan-end tag is used as a potential candidate for extracting the plan. If the plan-end tag is missing or if the plan cannot be extracted then we ignore that particular instance in our evaluation.</p>
<h1>5.2 Optimal Planning</h1>
<p>The prompt is quite similar to the one used in the earlier test case with a few changes. We modify the lifted domain description by including a statement that associates a cost with each action. To make the concept of action cost better fit into common sense domains, we can map the cost to more common concepts like the time taken for executing the action or the amount of money that needs to be spent to execute an action. In the case of each problem description, before the plan is presented we need to explicitly mention that the plan is trying to minimize cost (which depending on the scenario might correspond to saying that the plan takes the least amount of time or the plan correspond to the cheapest plan). The result generated by the LLM is evaluated similarly to the previous query, but in addition to checking if the plan is valid, we also check if the cost of the plan corresponds to the optimal plan cost.</p>
<h3>5.3 Reasoning about plan execution</h3>
<p>Here the objective is not to check whether the LLM can come up with plans, but rather if they can predict the outcome of executing an action. The prompt here again starts with the domain description, but instead of providing planning problems and plans, we provide a state, an action sequence and then questions about the state that would result from executing that action sequence in the provided state. Finally the prompt ends with a new state, a new action sequence, and a question about the resulting state. The LLM is expected to come up with an answer, which is checked by applying a plan executor that will try to identify what state will result from the execution of the current action sequence on the state.</p>
<h3>5.4 Robustness to Goal Reformulation</h3>
<p>In this test case, we will see if the LLM can recognize goals it has seen before if they are slightly modified. Here the prompt remains the same as the one used for goal-directed reasoning. However, all the example problems have the same initial state, and the last problem provided has not only the same initial state but also the same goal as the example problem. Here the goal may be obfuscated in a few ways, for example, the goal facts may be reordered or one might only include a subset of the original goal specification (meaning the same plan would still work). We can again use the same evaluation technique as the goal-directed reasoning test case to validate the output.</p>
<h3>5.5 Ability to Reuse Plans</h3>
<p>In this test case, we are interested in seeing if the LLM can reuse plans or parts of plans that it has seen before. The prompt is again the same as the goal-directed reasoning, but the prompt ends with a problem that can be solved by a prefix of a previously seen plan. We again keep the initial state the same across the example problems shown. The evaluation remains the same as the goal-directed reasoning test case.</p>
<h3>5.6 Replanning</h3>
<p>Replanning corresponds to the problem where there may be an unexpected event that occurs while executing a plan and the system needs to come up with a new plan in response to the event. Here, we focus on the ability of the LLM to replan when unexpected changes are reported. The prompt here starts with a domain description, then a set of instances where an unexpected event occurred during execution, and a new plan in response to the event. In each instance, a planning problem and a corresponding plan are provided at the beginning, the execution of the plan is described and then an unexpected event is noted (event corresponds to some facts unexpectedly turning true or false) and then a new plan from the changed state is presented. The prompt ends with a new case where the plan after replanning is left out and the LLM is expected to complete. The evaluation involves checking whether the new plan is valid from the changed state. The LLM output is evaluated to be true if the new plan it generates achieves the goals from the unexpectedly changed state.
For the Blocksworld domain, we constrain the unexpected event to be of a specific type. We execute a random prefix of the plan which ensures that some block is held at the end of that prefix. We then change the resulting state by stacking the held block onto another random block which is clear and make the hand empty. This change is reported and the LLM is asked to replan from the changed state.</p>
<h3>5.7 Plan Generalization</h3>
<p>In this test case, we want to evaluate whether LLMs can recognize the underlying pattern in the plans provided in the prompt and reuse it for a new planning problem. The prompt is the same as the goal-directed reasoning case, except that all plans were generated by a fixed program. Here the program may contain loops or conditional statements, but can</p>
<p>only solve certain types of problems, that is, the initial state and goals meet certain conditions. Such programs can be thought of as a direct generalization of line plans that we have considered in the rest of the paper [32]. Execution of this program for a specific planning problem generates a sequence of actions. In this case, we will provide some example traces generated from the program and ask LLM to come up with a plan for a new problem that could be solved by it. The evaluation again would be to take the generated plan and see if it is valid for the given problem.</p>
<h1>6 Evaluation</h1>
<h3>6.1 Autonomous mode</h3>
<h3>6.1.1 Evaluation of LLMs on the Blocksworld domain</h3>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: A detailed comparison of our current dataset, against the instances where GPT-3 or InstructGPT was able to generate a correct plan. The colors correspond to the number of blocks in the blocksworld instance. Note that neither of the LLMs were able to solve an instance which contained five blocks.</p>
<p>Our evaluation here primarily focuses on two Large Language Models, GPT-3 and BLOOM. In particular, we evaluated the test framework on the Blocksworld domain. In Table 1, we have presented the results of vanilla GPT-3 (Davinci), Instruct-GPT3 (text-davinci-002), and BLOOM on six of the test cases. For vanilla GPT-3 and Instruct-GPT3, we had tested on 600 instances for all test cases except plan generalization (for which 500 instances were tested) while with BLOOM, we had tested on 250 and 150 instances for plan generation and optimal planning test cases respectively, and 100 instances for the rest of the test cases. The experiments with GPT-3 (both the vanilla and instruct versions) took $\sim 30$ minutes for each test case while BLOOM took $\sim 36$ hours every 100 instances (on 8 NVIDIA-Quadro RTX 8000 GPUs with 48GBs of memory each). The best results (within each model) were for the auxiliary goal reformulation test cases. For these three cases, all that was required for the LLM was to repeat the same plan as the one shown in the example. Even then, vanilla GPT-3 and Instruct-GPT-3 failed to do that for some of the instances in the first two cases and the majority of the instances in the third case. BLOOM, on the other hand, was poor in all three cases. Coming to the two test cases that correspond to actual planning problems (plan generation and optimal planning), all three models performed poorly with Instruct-GPT3 performing better than the other two. Further, we found that for instances where Instruct-GPT3 generated the right plans, when the example plan in the prompt was replaced with another example plan, the accuracy dropped drastically. This suggests that the LLM seems to be primarily relying on pattern matching (rather than inducing some internal model from the prompts). We would like to point the reader to the appendix for additional experiments (including fine-tuning and domain disguising). Overall, the performance of these LLMs on our benchmark shows that, as of right now, LLMs are pretty ineffective in autonomously reasoning about actions and change. The blocksworld instances in our benchmark are somewhat simple as most of them have an optimal plan length of $\leq 8$ and a maximum of 5 blocks. Figure 2A showcases how the 600 blocksworld instances are distributed over the length of the optimal plan and the number of blocks in the instances. ${ }^{4}$ GPT-3 and Instruct GPT3 could not solve any of the 5 block instances and could only generate correct plans which have a length of $&lt;=8$ (as shown in Figure 2B \&amp; 2C), even though the maximum length among all of the generated plans (correct or incorrect) was 18.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Instances correct</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3</td>
<td style="text-align: center;">Instruct- <br> GPT3</td>
<td style="text-align: center;">BLOOM</td>
</tr>
<tr>
<td style="text-align: center;">Plan Generation - Preliminary human baseline $=78 \%$ <br> We showcase an instance and the respective plan as an example and prompt the machine with a new instance.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 6 / 600 \ &amp; (1 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 41 / 600 \ &amp; (6.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 4 / 250 \ &amp; (1.6 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Optimal Planning - Preliminary human baseline $=70 \%$ <br> We showcase an instance, the respective optimal plan and the associated cost as an example and prompt the machine with a new instance.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 2 / 600 \ &amp; (0.3 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 35 / 600 \ &amp; (5.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 3 / 150 \ &amp; (2 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Replanning <br> We showcase an instance, the respective plan and present an unexpected change of the state. We then also present a new plan from the changed state. Finally, for a new instance we repeat the same except we ask the machine for the new plan.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 47 / 600 \ &amp; (7.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 40 / 600 \ &amp; (6.6 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 3 / 100 \ &amp; (3 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Plan Generalization <br> We showcase an instance and the respective plan as an example and prompt the machine with a new instance. The plans for both the instances can be generated by a fixed program containing loops and conditionals.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 33 / 500 \ &amp; (6.6 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 49 / 500 \ &amp; (9.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 11 / 100 \ &amp; (11 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Plan Reuse <br> We showcase an instance and the respective plan as an example and prompt the machine with an instance which requires only a certain prefix of the plan provided in the example.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0 / 600 \ &amp; (0 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 102 / 600 \ &amp; (17 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0 / 100 \ &amp; (0 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Robustness to Goal Reformulation (Shuffling goal predicates) <br> We showcase an instance and the respective plan as an example and prompt the machine with the same instance but shuffle the ordering of the goals.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 460 / 600 \ &amp; (76.6 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 467 / 600 \ &amp; (77.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 21 / 100 \ &amp; (21 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Robustness to Goal Reformulation (Full $\rightarrow$ Partial) <br> We showcase an instance with a fully specified goal state and the respective plan as an example and prompt the machine with the same instance but provide a partially specified goal state.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 407 / 600 \ &amp; (67.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 467 / 600 \ &amp; (77.8 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 9 / 100 \ &amp; (9 \%) \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Robustness to Goal Reformulation (Partial $\rightarrow$ Full) <br> We showcase an instance with a partially specified goal state and the respective plan as an example and prompt the machine with the same instance but provide a fully specified goal state.</td>
<td style="text-align: center;">$\begin{aligned} &amp; 122 / 600 \ &amp; (20.3 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 363 / 600 \ &amp; (60.5 \%) \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 5 / 100 \ &amp; (5 \%) \end{aligned}$</td>
</tr>
</tbody>
</table>
<p>Table 1: LLM Assessment Suite Results on vanilla GPT-3 (davinci), Instruct-GPT3 (text-davinci-002) and BLOOM (176B model). The tasks in the highlighted rows correspond to actual planning problems while the others correspond to simpler auxiliary planning tasks.</p>
<h1>6.1.2 Human Baseline for the Blocksworld</h1>
<p>We have previously mentioned that planning tasks on the blocksworld domain are anecdotally simple enough for humans to perform. To establish this and come up with a baseline to compare LLMs performance, we conducted an IRB-approved user study where we asked 50 participants to come up with a plan for a blocksworld instance picked at random, from the set of 500 instances that we used for the evaluation of LLMs. We presented the same domain description as we did for the LLMs and then primed them with an example instance. Further, we provided them with an interface where they had two phases of interaction. In the first phase, they could write up plans by themselves for the given instance and then in the second phase, translate them (by picking the closest action from a list of grounded actions). The translated plans were used in the back-end and were evaluated in an automated fashion ${ }^{5}$. They went through this procedure first for an example instance (where they were provided with a glimpse of the example solution before using the interface) and then for the actual instance. We provided them with a bonus if they came up with a valid plan.
Out of the 50 participants, 39 of them ( $78 \%$ ) came up with a valid plan. Along with validity, we also tested the optimality of their plans even though they were not required to come up with an optimal plan. Out of the 39 participants, $35(89.7 \%)$ participants came up with an optimal plan. These initial results show that the blocksworld domain is a simple enough domain where most humans are able to come up with plans (which are also optimal) while LLMs, on the other hand, showcase subpar performance.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>6.2 Heuristic mode</h1>
<p>As mentioned earlier, instead of using LLMs for generating plans (which they seem to not do so well), we could use LLMs as heuristic guidance to drive sound planners. In this work, we use a local-search planner LPG [9] which generates plans by starting with a seed plan and iteratively repairing flaws until a correct plan is found. We feed the LLM-generated plan as the initial partial plan for LPG's iterative search. We utilized the plans generated by Instruct-GPT3 on the 600 instances of blocksworld domain as the initial plan that was given to the LPG planner for the corresponding instance. We confirmed that all the plans that were generated by this LLM+LPG combination were valid (which is as expected given that the underlying planner, LPG, is sound). Given the modest size of the test cases, the solution plans were generated within 7 seconds (including the API call to the LLM). These results show that plans generated by LLMs can be quickly 'repaired' by a sound planner to guarantee their correctness.
To get an idea of how far the initial LLM generated plans were from the final correct solutions generated by LPG, we measured the Levenshtein edit distance between them. While the default LPG local search doesn't aim to minimize the changes to the suggested plan (there do exist versions of LPG that do this; see [20]), the edit distances also give an idea of how partially or approximately correct the original LLM plan is. We found that the average Levenshtein distance on the 600 instances was 7.22 , while the average length of the final plan was 11.7. This shows that more than $50 \%$ of the final plan might have been due to the edits made by the LPG planner to the initial LLM plan.</p>
<h3>6.3 Human-in-the-loop mode</h3>
<p>Even though LLMs cannot provide sound plans by themselves, they can still offer their insights as plan suggestions directly to the human-in-the-loop which might potentially guide the user to the correct plan. After all, this sort of computer supported cooperative work (CSCW) use case has been the staple of LLM applications. We investigated the usefulness of LLMs for human planners by conducting a between-subjects user study. This user-study is similar in setup to the study described in section 6.1.2 with two key differences. (1) In this user study, there were two independent sets of participants. The first group of participants were not provided with any kind of assistance while coming up with plans (similar to the one in Section 6.1.2) whereas the other group were provided with an LLM generated suggestion that they could make use of. (2) At the end of the study, we have also asked both sets of participants to provide subjective feedback, using NASA-TLX assessment tool, to measure their cognitive load. Additionally, each participant in the second group had to provide feedback on whether the LLM-generated suggestion was correct when they were presented with the suggestion. We utilized the plans generated by Instruct-GPT3 to provide plan suggestions.
We had 23 participants in the first group, where no assistance was provided, and 22 participants in the second group, where the LLM's plan was provided as a suggestion. Out of the 23 in first group, 17 (i.e., $74 \%$ ) of them managed to generate a correct final plan, whereas in the second group, 18 out of 22 (i.e., $82 \%$ ) generated a correct plan. While this provides some evidence that LLM generated suggestions were helping the users, the statistical signficance of the findings was not high. We performed independent-samples t-tests on the time taken to come up with a plan and the cognitive load of the task between the two groups. We set the significance level at $\alpha=0.05$ for both the t-tests and ran them to see if the LLM-assisted group had lesser time taken and cognitive-load. For the t-test on the time taken, we received a statistic value of 0.92 and a p-value of 0.81 . For the t-test on the cognitive load, we received a statistic value of 0.78 and a p-value of 0.78 . This shows that we can't reject the null hypothesis and thus the difference in the time-taken and cognitive load between the two groups is not statistically significant. Further, 4 out of the 22 participants thought that the LLM suggestion was correct and 2 of them submitted the suggestion itself as the plan. This potentially hints at how these methods could feed into automation bias [7]. Overall, the results showcase that there is a slight improvement in the accuracy of the plans generated when the human planners are assisted by the LLMs but there is no statistically significant difference between the two groups in the time taken and the cognitive load on the human planner.</p>
<h2>7 Conclusion and Future Work</h2>
<p>In this paper, we presented a critical investigation of the planning abilities of large language models (LLMs). To this end, we first provided an extensible benchmark where researchers can evaluate current and future large language models. We evaluated the planning abilities of LLMs in three different modes. In the autonomous mode, our results show that even in simple common-sense planning domains where humans could easily come up with plans, current SOTA LLMs like GPT-3 and BLOOM exhibit a dismal performance. In the heuristic mode, we have seen that plans generated by LLMs can be quickly corrected by sound planners like LPG to guarantee soundness. Finally, in the human in the loop mode, we have seen that human planners are slightly better off with an LLM assisting them as having an LLM as a plan assistant showcased modest improvements in the accuracy of the plans generated by the human-in-the-loop.</p>
<p>We look to improve our assessment suite in multiple ways in the future. We plan to include a modified version of the reasoning about plan execution task to ask questions that require a more descriptive answer and provide automated validations for the answers. This benchmark can be extended to other domains, either to common-sense domains (like Virtual Home [23]) or to specialized ones. We have also performed additional experiments including evaluating a version of GPT-3 fine-tuned on blocksworld instances, and evaluating LLMs on disguised blocksworld domains. These experiments are described in the Appendix. In conclusion, we hope that this benchmark ${ }^{6}$ encourages other researchers to test the capabilities of their systems across different LLM models [5, 8, 30, 37, 25, 34, 12] and even those that are fine-tuned for such tasks.</p>
<h1>8 Acknowledgements</h1>
<p>Kambhampati's research is supported by the J.P. Morgan Faculty Research Award, ONR grants N00014-16-1-2892, N00014-18-1-2442, N00014-18-1-2840, N00014-9-1-2119, AFOSR grant FA9550-18-1-0067 and DARPA SAIL-ON grant W911NF19-2-0006. We also want to thank OpenAI and Miles Brundage for letting us get early research access to the GPT-3 API.</p>
<h2>References</h2>
<p>[1] Constructions Aeronautiques, Adele Howe, Craig Knoblock, ISI Drew McDermott, Ashwin Ram, Manuela Veloso, Daniel Weld, David Wilkins SRI, Anthony Barrett, Dave Christianson, et al. PDDL| The Planning Domain Definition Language. Technical Report, Tech. Rep., 1998.
[2] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. Do as i can, not as i say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691, 2022.
[3] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.
[4] Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. Advances in neural information processing systems, 34:15084-15097, 2021.
[5] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.
[6] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.
[7] Mary L Cummings. Automation bias in intelligent time critical decision support systems. In Decision making in aviation, pages 289-294. Routledge, 2017.
[8] Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, et al. GLaM: Efficient Scaling of Language Models with Mixture-of-Experts. pages 5547-5569, 2022.
[9] Alfonso Gerevini and Ivan Serina. Lpg: A planner based on local search for planning graphs with action costs. In AIPS, volume 2, pages 281-290, 2002.
[10] Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346-361, 2021.
[11] Malte Helmert. The fast downward planning system. Journal of Artificial Intelligence Research, 26:191-246, 2006.
[12] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.
[13] Richard Howey, Derek Long, and Maria Fox. VAL: Automatic plan validation, continuous effects and mixed initiative planning using PDDL. In 16th IEEE International Conference on Tools with Artificial Intelligence, pages 294-301. IEEE, 2004.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>[14] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207, 2022.
[15] IPC. International planning competition, 1998.
[16] Liwei Jiang, Jena D. Hwang, Chandrasekhar Bhagavatula, Ronan Le Bras, Maxwell Forbes, Jon Borchardt, Jenny Liang, Oren Etzioni, Maarten Sap, and Yejin Choi. Delphi: Towards Machine Ethics and Norms. ArXiv, abs/2110.07574, 2021.
[17] Subbarao Kambhampati. AI as (an Ersatz) Natural Science? https://cacm.acm.org/blogs/blog-cacm/261732-ai-as-an-ersatz-natural-science/fulltext, Jun 2022.
[18] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large Language Models are Zero-Shot Reasoners. arXiv preprint arXiv:2205.11916, 2022.
[19] Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146, 2017.
[20] Tuan Anh Nguyen, Minh Do, Alfonso Emilio Gerevini, Ivan Serina, Biplav Srivastava, and Subbarao Kambhampati. Generating diverse plans to handle unknown and partially known user preferences. Artificial Intelligence, 190:1-31, 2012.
[21] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155, 2022.
[22] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP Models really able to Solve Simple Math Word Problems? arXiv preprint arXiv:2103.07191, 2021.
[23] Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and Antonio Torralba. Virtualhome: Simulating household activities via programs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8494-8502, 2018.
[24] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.
[25] Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis \&amp; insights from training gopher. arXiv preprint arXiv:2112.11446, 2021.
[26] Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel BarthMaron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, et al. A generalist agent. arXiv preprint arXiv:2205.06175, 2022.
[27] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial winograd schema challenge at scale. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8732-8740, 2020.
[28] Big Science. BigScience Large Open-science Open-access Multilingual Language Model. https:// huggingface.co/bigscience/bloom, 2022.
[29] Tom Silver, Varun Hariprasad, Reece S Shuttleworth, Nishanth Kumar, Tomás Lozano-Pérez, and Leslie Pack Kaelbling. PDDL planning with pretrained large language models. In NeurIPS 2022 Foundation Models for Decision Making Workshop, 2022.
[30] Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas, Vijay Korthikanti, et al. Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model. arXiv preprint arXiv:2201.11990, 2022.
[31] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.
[32] Siddharth Srivastava, Shlomo Zilberstein, Neil Immerman, and Hector Geffner. Qualitative numeric planning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 25, pages 1010-1016, 2011.
[33] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: A question answering challenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937, 2018.
[34] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. LaMDA: Language Models for Dialog Applications. arXiv preprint arXiv:2201.08239, 2022.</p>
<p>[35] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.
[36] Honghua Zhang, Liunian Harold Li, Tao Meng, Kai-Wei Chang, and Guy Van den Broeck. On the paradox of learning to reason from data. arXiv preprint arXiv:2205.11502, 2022.
[37] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022.
[38] Hankz Hankui Zhuo, Yantian Zha, Subbarao Kambhampati, and Xin Tian. Discovering underlying plans based on shallow models. ACM Transactions on Intelligent Systems and Technology (TIST), 11(2):1-30, 2020.</p>
<h1>A Appendix</h1>
<h2>A. 1 Additional Experiments</h2>
<p>In the following sections, we will look at additional experiments that were done only on the test cases that correspond to actual planning problems (which are Plan Generation and Optimal Planning).</p>
<h2>A.1.1 Fine tuning</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Task</th>
<th style="text-align: right;">Instances correct <br> Finetuned-GPT3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Plan Generation</td>
<td style="text-align: right;">$82 / 500(16.4 \%)$</td>
</tr>
<tr>
<td style="text-align: left;">Optimal Planning</td>
<td style="text-align: right;">$110 / 500(22 \%)$</td>
</tr>
</tbody>
</table>
<p>Table 2: Results of Plan Generation and Optimal Planning in the Blocksworld Domain on Finetuned-GPT3</p>
<p>Along with testing GPT-3, Instruct-GPT3 and BLOOM, we have also looked at the utility of fine-tuning GPT-3 on the blocksworld domain. We prepared a dataset consisting of the initial state, goal state and the respective plan for 1000 blocksworld instances. These instances were different from our test set of 500 instances. We fine-tuned GPT-3 (davinci) on this dataset (using the default hyperparameters provided by Open-AI and 80-20 data split) and evaluated on the two test-cases which correspond to actual planning problems. Even though the results (in Table 2) showcase an uptick in the number of successful plans, the overall performance is still around $20 \%$. This is unsurprising as [36] point out that language models tend to focus on the inherent statistical features in reasoning problems which affects their performance on such tasks.</p>
<h2>A.1.2 Mystery blocksworld domain</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Task</th>
<th style="text-align: left;">Instances correct</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">GPT-3</td>
<td style="text-align: left;">Instruct-GPT3</td>
<td style="text-align: left;">BLOOM</td>
</tr>
<tr>
<td style="text-align: left;">Plan Generation</td>
<td style="text-align: left;">$0 / 600(0 \%)$</td>
<td style="text-align: left;">$7 / 600(1.1 \%)$</td>
<td style="text-align: left;">$0 / 50(0 \%)$</td>
</tr>
<tr>
<td style="text-align: left;">Optimal Planning</td>
<td style="text-align: left;">$0 / 600(0 \%)$</td>
<td style="text-align: left;">$8 / 600(1.3 \%)$</td>
<td style="text-align: left;">$0 / 50(0 \%)$</td>
</tr>
</tbody>
</table>
<p>Table 3: Results of Plan Generation and Optimal Planning in the Mystery Blocksworld Domain with deceptive disguising on GPT-3, Instruct-GPT3 and BLOOM.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Task</th>
<th style="text-align: left;">Instances correct</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">GPT-3</td>
<td style="text-align: left;">Instruct-GPT3</td>
</tr>
<tr>
<td style="text-align: left;">Plan Generation</td>
<td style="text-align: left;">$1 / 600(0.1 \%)$</td>
<td style="text-align: left;">$5 / 600(0.8 \%)$</td>
</tr>
<tr>
<td style="text-align: left;">Optimal Planning</td>
<td style="text-align: left;">$3 / 600(0.5 \%)$</td>
<td style="text-align: left;">$4 / 600(0.6 \%)$</td>
</tr>
</tbody>
</table>
<p>Table 4: Results of Plan Generation and Optimal Planning in the Mystery Blocksworld Domain with randomized disguising on GPT-3, Instruct-GPT3 and BLOOM.</p>
<p>Another popular domain used in the planning literature is the Mystery domain created by Drew McDermott. In this domain, the goal is to get cargo items from one place to another with vehicles having fuel availability constraints. But the domain is disguised by changing the names of predicates and actions to unrelated entities. Testing LLMs on such a domain would give us insights into whether LLMs are infact performing abstract reasoning or if they are using any common-sense knowledge (such as the meaning of the action/predicate names) in coming up with plans. The domain can be disguised in two different ways, deceptive or randomized. Deceptive disguising would require using words that have meaning by themselves but are unrelated in terms of cause and effect, thereby deceiving the LLM. Randomized disguising would use random alpha-numeric names to disguise the domain. For better comparison of results, instead of the original mystery domain, we came up with a mystery domain which disguises the blocksworld domain on which the LLMs have already been evaluated. We used both deceptive and randomized disguising and have evaluated on Plan</p>
<p>Generation and Optimal Planning test cases. For deceptive disguising, we have evaluated GPT-3, Instruct GPT-3 and BLOOM whereas for randomized disguising we have evaluated GPT-3 and Instruct GPT-3. The results (in Table 3 and Table 4) showcase a decrease in the number of successful plans generated by the LLMs in the mystery blocksworld as opposed to the original blocksworld. These results indicate that LLMs might not be reasoning at an abstract level and might be relying on the underlying meanings of the actions/predicates and the relations between them while coming up with plans.</p>
<h1>A. 2 Blocksworld Domain Prompts</h1>
<h2>A.2.1 Domain description included in the prompts</h2>
<p>Listing 1: Blocksworld Domain Description</p>
<div class="codehilite"><pre><span></span><code><span class="mf">1</span><span class="w"> </span><span class="o">===========================================</span>
<span class="mf">2</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">playing</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">need</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">arrange</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="nb">int</span><span class="n">o</span>
<span class="w">    </span><span class="n">stacks</span><span class="mf">.</span><span class="w"> </span><span class="n">Here</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">actions</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">do</span>
<span class="mf">3</span>
<span class="mf">4</span><span class="err">}\</span><span class="n">mathrm</span><span class="err">{</span><span class="w"> </span><span class="n">Pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span>
<span class="mf">5</span><span class="w"> </span><span class="n">Unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span>
<span class="mf">6</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span>
<span class="mf">7</span><span class="w"> </span><span class="n">Stack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span>
<span class="mf">8</span>
<span class="mf">9</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">restrictions</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">my</span><span class="w"> </span><span class="n">actions</span><span class="p">:</span>
<span class="mf">10</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="kr">on</span><span class="n">e</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">time</span><span class="mf">.</span>
<span class="mf">11</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">my</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">empty</span><span class="mf">.</span>
<span class="mf">12</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nb">tab</span><span class="n">le</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="mf">.</span>
<span class="w">        </span><span class="n">A</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span>
<span class="w">        </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">picked</span><span class="w"> </span><span class="n">up</span><span class="mf">.</span>
<span class="mf">13</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span>
<span class="w">        </span><span class="n">unstacking</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">really</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">14</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span>
<span class="w">        </span><span class="n">unstacking</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="mf">.</span>
<span class="mf">15</span><span class="w"> </span><span class="kr">On</span><span class="n">ce</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">holding</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">16</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">holding</span><span class="mf">.</span>
<span class="mf">17</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">holding</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span>
<span class="w">        </span><span class="n">being</span><span class="w"> </span><span class="n">stacked</span><span class="mf">.</span>
<span class="mf">18</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">onto</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span>
<span class="w">        </span><span class="n">stacking</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="mf">.</span>
<span class="mf">19</span><span class="w"> </span><span class="kr">On</span><span class="n">ce</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="n">my</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">becomes</span><span class="w"> </span><span class="n">empty</span><span class="mf">.</span>
<span class="mf">20</span><span class="w"> </span><span class="o">===========================================</span>
</code></pre></div>

<h2>A.2.2 Domain description included in the prompts for optimal planning</h2>
<p>Listing 2: Blocksworld Domain Description for Optimal Planning</p>
<div class="codehilite"><pre><span></span><code><span class="mf">1</span><span class="w"> </span><span class="o">===========================================</span>
<span class="mf">2</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">playing</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">need</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">arrange</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="nb">int</span><span class="n">o</span>
<span class="w">    </span><span class="n">stacks</span><span class="mf">.</span><span class="w"> </span><span class="n">Here</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">actions</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">do</span><span class="p">:</span>
<span class="mf">3</span>
<span class="mf">4</span><span class="err">}\</span><span class="n">mathrm</span><span class="err">{</span><span class="w"> </span><span class="n">Pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">takes</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="n">minute</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">5</span><span class="w"> </span><span class="n">Unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">takes</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="n">minute</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">6</span><span class="err">}\</span><span class="n">mathrm</span><span class="err">{</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">takes</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="n">minute</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">7</span><span class="err">}\</span><span class="n">mathrm</span><span class="err">{</span><span class="w"> </span><span class="n">Stack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">takes</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="n">minute</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">on</span>
<span class="w">    </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">8</span>
<span class="mf">9</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">restrictions</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">my</span><span class="w"> </span><span class="n">actions</span><span class="p">:</span>
<span class="mf">10</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="kr">on</span><span class="n">e</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">time</span><span class="mf">.</span>
<span class="mf">11</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">my</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">empty</span><span class="mf">.</span>
<span class="mf">12</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nb">tab</span><span class="n">le</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="mf">.</span>
<span class="w">        </span><span class="n">A</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span>
<span class="w">        </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">picked</span><span class="w"> </span><span class="n">up</span><span class="mf">.</span>
<span class="mf">13</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span>
<span class="w">        </span><span class="n">unstacking</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">really</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">block</span><span class="mf">.</span>
<span class="mf">14</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="kr">on</span><span class="n">ly</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="kr">to</span><span class="n">p</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">another</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">am</span>
<span class="w">        </span><span class="n">unstacking</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="mf">.</span>
</code></pre></div>

<p>15 Once I pick up or unstack a block, I am holding the block.
16 I can only put down a block that I am holding.
17 I can only stack a block on top of another block if I am holding the block being stacked.
18 I can only stack a block on top of another block if the block onto which I am stacking the block is clear.
19 Once I put down or stack a block, my hand becomes empty.
20
$======================$ $======================$</p>
<h1>A.2.3 Example prompts and completion by GPT-3</h1>
<p>Below we present the first instance of our 500 instances for each of the tasks and the corresponding completion by GPT-3 as an example in the blocks world domain.</p>
<h2>Plan generation</h2>
<p>Listing 3: Plan Generation</p>
<div class="codehilite"><pre><span></span><code><span class="k">[ [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the blue block is</span>
<span class="w">    </span><span class="na">clear, the yellow block is clear, the hand is empty, the blue block is on</span>
<span class="w">    </span><span class="na">top of the orange block, the red block is on the table, the orange block is</span>
<span class="w">    </span><span class="na">on the table and the yellow block is on the table.</span>
<span class="na">My goal is to have that the orange block is on top of the blue block.</span>
<span class="na">My plan is as follows</span><span class="o">:</span>
<span class="k">[ [PLAN]</span>
<span class="na">unstack the blue block from on top of the orange block</span>
<span class="na">put down the blue block</span>
<span class="na">pick up the orange block</span>
<span class="na">stack the orange block on top of the blue block</span>
<span class="k">[ [PLAN END]</span>
<span class="k">[ [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the yellow block is</span>
<span class="w">    </span><span class="na">clear, the hand is empty, the red block is on top of the blue block, the</span>
<span class="w">    </span><span class="na">yellow block is on top of the orange block, the blue block is on the table</span>
<span class="w">    </span><span class="na">and the orange block is on the table.</span>
<span class="na">My goal is to have that the orange block is on top of the red block.</span>
<span class="na">My plan is as follows</span><span class="o">:</span>
<span class="k">[ [PLAN]</span>
<span class="na">GPT3 response</span>
<span class="na">unstack the yellow block from on top of the orange block</span>
<span class="na">put down the yellow block</span>
<span class="na">pick up the orange block</span>
<span class="na">stack the orange block on top of the red block</span>
<span class="k">[ [PLAN END]</span>
<span class="na">--------- Extracted plan</span>
<span class="na">(unstack yellow orange)</span>
<span class="na">(put-down yellow)</span>
<span class="na">(pick-up orange)</span>
<span class="na">(stack orange red)</span>
<span class="na">--------- Ground truth plan</span>
<span class="na">(unstack yellow orange)</span>
<span class="na">(put-down yellow)</span>
<span class="na">(pick-up orange)</span>
<span class="na">(stack orange red)</span>
<span class="o">=</span><span class="s">======================================</span>
</code></pre></div>

<h2>Optimal Planning</h2>
<p>Listing 4: Optimal planning</p>
<p>On the Planning Abilities of Large Language Models</p>
<p>1 [STATEMENT]
2 As initial conditions I have that, the red block is clear, the blue block is clear, the yellow block is clear, the hand is empty, the blue block is on top of the orange block, the red block is on the table, the orange block is on the table and the yellow block is on the table..
3 My goal is to have that the orange block is on top of the blue block. I want to minimize the time taken to achieve my goal.
4 My plan is as follows:
5
6 [PLAN]
7 unstack the blue block from on top of the orange block
8 put down the blue block
9 pick up the orange block
10 stack the orange block on top of the blue block
11 [PLAN END]
12 The total time to execute the plan is 4 minutes.
13
14 [STATEMENT]
15 As initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table..
16 My goal is to have that the orange block is on top of the red block. I want to minimize the time taken to achieve my goal.
17 My plan is as follows:
18
19 [PLAN]
20 --------- GPT3 response
21 unstack the yellow block from on top of the orange block
22 put down the yellow block
23 pick up the orange block
24 stack the orange block on top of the red block
25 [PLAN END]
26 The total time to execute the plan is 4 minutes.
27 --------- Extracted plan
28 (unstack yellow orange)
29 (put-down yellow)
30 (pick-up orange)
31 (stack orange red)
32
33 -------- Ground truth plan
34 (unstack yellow orange)
35 (put-down yellow)
36 (pick-up orange)
37 (stack orange red)
38
39 ---------Optimal Plan
40 -----Correct cost output by LLM-----
41 ================SUCCESS ==============</p>
<h1>Replanning</h1>
<p>Listing 5: Replanning when an unexpected event occurs and changes the state.
1 [STATEMENT]
2 As initial conditions I have that, the red block is clear, the blue block is clear, the yellow block is clear, the hand is empty, the blue block is on top of the orange block, the red block is on the table, the orange block is on the table and the yellow block is on the table.
3 My goal is to have that the orange block is on top of the blue block.
4 My plan is as follows:
5
6 [PLAN]
7 unstack the blue block from on top of the orange block
8 put down the blue block
9 pick up the orange block</p>
<p>10 stack the orange block on top of the blue block
11 [PLAN END]
12
13 During execution, an unexpected event has occurred.
14 After executing the action "pick up the orange block" at step 3 in the plan, the following facts unexpectedly became true:
15 the orange block is clear,
16 the hand is empty,
17 the orange block is on top of the red block.
18
19 The following facts became unexpectedly false:
20 the red block is clear,
21 the hand is currently holding orange block.
22
23 After re-planning from the new state, the plan is as follows:
24 [PLAN]
25 unstack the orange block from on top of the red block
26 stack the orange block on top of the blue block
27 [PLAN END]
28
29 [STATEMENT]
30 As initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table.
31 My goal is to have that the orange block is on top of the red block.
32 My plan is as follows:
33
34 [PLAN]
35 unstack the yellow block from on top of the orange block
36 put down the yellow block
37 pick up the orange block
38 stack the orange block on top of the red block
39 [PLAN END]
40
41 During execution, an unexpected event has occurred.
42 After executing the action "pick up the orange block" at step 3 in the plan, the following facts unexpectedly became true:
43 the orange block is clear,
44 the hand is empty,
45 the orange block is on top of the red block.
46
47 The following facts became unexpectedly false:
48 the red block is clear,
49 the hand is currently holding orange block.
50
51 After re-planning from the new state, the plan is as follows:
52 [PLAN]
53 ..------- GPT3 response
54 unstack the orange block from on top of the red block
55 put down the orange block
56 stack the orange block on top of the yellow block
57 [PLAN END]
58 --------- Extracted plan
59 (unstack orange red)
60 (put-down orange)
61 (stack orange yellow)
62
63 -------- Ground truth plan
64
$65==============$ FAILURE $==============$</p>
<h1>Plan Generalization</h1>
<p>Listing 6: Plan generalization</p>
<p>1 [STATEMENT]
2 As initial conditions I have that, the blue block is clear, the yellow block is clear, the magenta block is clear, the black block is clear, the cyan block is clear, the green block is clear, the violet block is clear, the gold block is clear, the hand is empty, the blue block is on the table, the yellow block is on the table, the magenta block is on the table, the black block is on the table, the cyan block is on the table, the green block is on the table, the violet block is on the table and the gold block is on the table.
3 My goal is to have that the blue block is on top of the cyan block, the yellow block is on top of the blue block, the magenta block is on top of the green block, the black block is on top of the yellow block, the cyan block is on top of the gold block, the green block is on top of the black block and the violet block is on top of the magenta block.
4
5 My plan is as follows:
6
7 [PLAN]
8 pick up the cyan block
9 stack the cyan block on top of the gold block
10 pick up the blue block
11 stack the blue block on top of the cyan block
12 pick up the yellow block
13 stack the yellow block on top of the blue block
14 pick up the black block
15 stack the black block on top of the yellow block
16 pick up the green block
17 stack the green block on top of the black block
18 pick up the magenta block
19 stack the magenta block on top of the green block
20 pick up the violet block
21 stack the violet block on top of the magenta block
22 [PLAN END]
23
24 [STATEMENT]
25 As initial conditions I have that, the red block is clear, the blue block is clear, the black block is clear, the cyan block is clear, the green block is clear, the violet block is clear, the silver block is clear, the hand is empty, the red block is on the table, the blue block is on the table, the black block is on the table, the cyan block is on the table, the green block is on the table, the violet block is on the table and the silver block is on the table.
26 My goal is to have that the red block is on top of the blue block, the blue block is on top of the silver block, the black block is on top of the red block, the cyan block is on top of the green block, the violet block is on top of the black block and the silver block is on top of the cyan block.
27
28 My plan is as follows:
29
30 [PLAN]
31 --------- GPT3 response
32 pick up the red block
33 stack the red block on top of the blue block
34 pick up the blue block
35 stack the blue block on top of the silver block
36 pick up the black block
37 stack the black block on top of the red block
38 pick up the cyan block
39 stack the cyan block on top of the green block
40 pick up the violet block
41 stack the violet block on top of the black block
42 pick up the silver block
43 stack the silver block on top of the cyan block
44 [PLAN END]
45 --------- Extracted plan ---------</p>
<p>46 (pick-up red)
47 (stack red blue)
48 (pick-up blue)
49 (stack blue silver)
50 (pick-up black)
51 (stack black red)
52 (pick-up cyan)
53 (stack cyan green)
54 (pick-up violet)
55 (stack violet black)
56 (pick-up silver)
57 (stack silver cyan)
58
59 Ground truth plan
60 (pick-up cyan)
61 (stack cyan green)
62 (pick-up silver)
63 (stack silver cyan)
64 (pick-up blue)
65 (stack blue silver)
66 (pick-up red)
67 (stack red blue)
68 (pick-up black)
69 (stack black red)
70 (pick-up violet)
71 (stack violet black)
72
$73=$ $================$ FAILURE $==============$</p>
<h1>Plan Reuse</h1>
<p>Listing 7: Using a certain prefix of the plan provided in the example</p>
<div class="codehilite"><pre><span></span><code><span class="k">[ [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the blue block is</span>
<span class="w">    </span><span class="na">clear, the yellow block is clear, the hand is empty, the blue block is on</span>
<span class="w">    </span><span class="na">top of the orange block, the red block is on the table, the orange block is</span>
<span class="w">    </span><span class="na">on the table and the yellow block is on the table.</span>
<span class="na">My goal is to have that the orange block is on top of the blue block.</span>
<span class="na">My plan is as follows</span><span class="o">:</span>
<span class="na">5</span>
<span class="na">6 [PLAN]</span>
<span class="na">7 \text { unstack the blue block from on top of the orange block}</span>
<span class="na">8}\mathrm{ put down the blue block</span>
<span class="na">9}\mathrm{ pick up the orange block</span>
<span class="na">10 \text { stack the orange block on top of the blue block}</span>
<span class="na">11 [PLAN END]</span>
<span class="na">12</span>
<span class="na">13 [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the blue block is</span>
<span class="w">    </span><span class="na">clear, the yellow block is clear, the hand is empty, the blue block is on</span>
<span class="w">    </span><span class="na">top of the orange block, the red block is on the table, the orange block is</span>
<span class="w">    </span><span class="na">on the table and the yellow block is on the table.</span>
<span class="na">15 My goal is to have that the red block is clear, the orange block is clear, the</span>
<span class="w">    </span><span class="na">yellow block is clear, the hand is currently holding blue block, the red</span>
<span class="w">    </span><span class="na">block is on the table, the orange block is on the table and the yellow block</span>
<span class="w">        </span><span class="na">is on the table.</span>
<span class="na">16 My plan is as follows</span><span class="o">:</span>
<span class="na">17</span>
<span class="na">18 [PLAN]</span>
<span class="na">19</span>
<span class="w">    </span><span class="na">GPT3 response</span>
<span class="w">    </span><span class="na">unstack the blue block from on top of the red block</span>
<span class="w">    </span><span class="na">put down the blue block</span>
<span class="w">    </span><span class="na">pick up the red block</span>
<span class="w">    </span><span class="na">stack the red block on top of the orange block</span>
<span class="na">24 [PLAN END]</span>
</code></pre></div>

<p>25
26 -------- Ground truth plan
27 (unstack blue orange)
28
29 ================FAILURE =================</p>
<h1>Robustness to Goal Reformulation (Shuffling goal predicates)</h1>
<p>Listing 8: Changing the order of goal predicates</p>
<div class="codehilite"><pre><span></span><code><span class="k">[ [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the blue block is</span>
<span class="w">    </span><span class="na">clear, the yellow block is clear, the hand is empty, the blue block is on</span>
<span class="w">    </span><span class="na">top of the orange block, the red block is on the table, the orange block is</span>
<span class="w">    </span><span class="na">on the table and the yellow block is on the table.</span>
<span class="na">My goal is to have that the orange block is on top of the blue block.</span>
<span class="na">My plan is as follows</span><span class="o">:</span>
<span class="na">6</span>
<span class="k">[ [PLAN]</span>
<span class="na">unstack the blue block from on top of the orange block</span>
<span class="na">put down the blue block</span>
<span class="na">pick up the orange block</span>
<span class="na">stack the orange block on top of the blue block</span>
<span class="k">[ [PLAN END]</span>
<span class="k">[ [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the blue block is</span>
<span class="w">    </span><span class="na">clear, the yellow block is clear, the hand is empty, the blue block is on</span>
<span class="w">    </span><span class="na">top of the orange block, the red block is on the table, the orange block is</span>
<span class="w">    </span><span class="na">on the table and the yellow block is on the table.</span>
<span class="na">My goal is to have that the orange block is on top of the blue block.</span>
<span class="na">My plan is as follows</span><span class="o">:</span>
<span class="na">19</span>
<span class="k">[ [PLAN]</span>
<span class="na">--------- GPT3 response</span>
<span class="na">unstack the blue block from on top of the orange block</span>
<span class="na">put down the blue block</span>
<span class="na">pick up the orange block</span>
<span class="na">stack the orange block on top of the blue block</span>
<span class="k">[ [PLAN END]</span>
<span class="na">--------- Extracted plan</span>
<span class="na">(unstack blue orange)</span>
<span class="na">(put-down blue)</span>
<span class="na">(pick-up orange)</span>
<span class="na">(stack orange blue)</span>
<span class="na">--------- Ground truth plan</span>
<span class="na">(unstack blue orange)</span>
<span class="na">(put-down blue)</span>
<span class="na">(pick-up orange)</span>
<span class="na">(stack orange blue)</span>
<span class="na">38</span>
<span class="o">=</span><span class="s">== (GOAL ORDERING CHANGE) SUCCESS ====</span>
</code></pre></div>

<h2>Robustness to Goal Reformulation (Full $\rightarrow$ Partial)</h2>
<p>Listing 9: Providing an example with fully specified goal and asking to complete for the same example with a partially specified goal</p>
<div class="codehilite"><pre><span></span><code><span class="k">[ [STATEMENT]</span>
<span class="na">As initial conditions I have that, the red block is clear, the blue block is</span>
<span class="w">    </span><span class="na">clear, the yellow block is clear, the hand is empty, the blue block is on</span>
<span class="w">    </span><span class="na">top of the orange block, the red block is on the table, the orange block is</span>
<span class="w">    </span><span class="na">on the table and the yellow block is on the table.</span>
<span class="na">My goal is to have that the orange block is on top of the blue block, the red</span>
<span class="w">    </span><span class="na">block is clear, the red block is on the table, the blue block is on the</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">table</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">empty</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="w">        </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">.</span>
<span class="mi">4</span>
<span class="mi">5</span><span class="w"> </span><span class="err">\</span><span class="n">text</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">My</span><span class="w"> </span><span class="n">plan</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">follows</span><span class="o">:</span><span class="p">}</span>
<span class="mi">6</span>
<span class="mi">7</span><span class="w"> </span><span class="p">[</span><span class="n">PLAN</span><span class="p">]</span>
<span class="mi">8</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="mi">9</span><span class="p">}</span><span class="err">\</span><span class="n">mathrm</span><span class="p">{</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="mi">10</span><span class="p">}</span><span class="err">\</span><span class="n">mathrm</span><span class="p">{</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="mi">11</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="mi">12</span><span class="w"> </span><span class="p">[</span><span class="n">PLAN</span><span class="w"> </span><span class="n">END</span><span class="p">]</span>
<span class="mi">13</span>
<span class="mi">14</span><span class="w"> </span><span class="p">[</span><span class="n">STATEMENT</span><span class="p">]</span>
<span class="mi">15</span><span class="w"> </span><span class="n">As</span><span class="w"> </span><span class="n">initial</span><span class="w"> </span><span class="n">conditions</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">that</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span>
<span class="w">    </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">empty</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span>
<span class="w">    </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span>
<span class="w">    </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="p">.</span>
<span class="mi">16</span><span class="w"> </span><span class="n">My</span><span class="w"> </span><span class="n">goal</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="p">.</span>
<span class="mi">17</span>
<span class="mi">18</span><span class="w"> </span><span class="n">My</span><span class="w"> </span><span class="n">plan</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">follows</span><span class="o">:</span>
<span class="mi">19</span>
<span class="mi">20</span><span class="w"> </span><span class="p">[</span><span class="n">PLAN</span><span class="p">]</span>
<span class="mi">21</span><span class="w"> </span><span class="o">---------</span><span class="w"> </span><span class="n">GPT3</span><span class="w"> </span><span class="n">response</span>
<span class="mi">22</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="mi">23</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="mi">24</span><span class="p">}</span><span class="err">\</span><span class="n">mathrm</span><span class="p">{</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="mi">25</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="mi">26</span><span class="w"> </span><span class="p">[</span><span class="n">PLAN</span><span class="w"> </span><span class="n">END</span><span class="p">]</span>
<span class="mi">27</span><span class="w"> </span><span class="o">---------</span><span class="w"> </span><span class="n">Extracted</span><span class="w"> </span><span class="n">plan</span>
<span class="mi">28</span><span class="w"> </span><span class="p">(</span><span class="n">unstack</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">orange</span><span class="p">)</span>
<span class="mi">29</span><span class="w"> </span><span class="p">(</span><span class="n">put</span><span class="o">-</span><span class="n">down</span><span class="w"> </span><span class="n">blue</span><span class="p">)</span>
<span class="mi">30</span><span class="w"> </span><span class="p">(</span><span class="n">pick</span><span class="o">-</span><span class="n">up</span><span class="w"> </span><span class="n">orange</span><span class="p">)</span>
<span class="mi">31</span><span class="w"> </span><span class="p">(</span><span class="n">stack</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">blue</span><span class="p">)</span>
<span class="mi">32</span>
<span class="mi">33</span><span class="w"> </span><span class="o">--------</span><span class="w"> </span><span class="n">Ground</span><span class="w"> </span><span class="n">truth</span><span class="w"> </span><span class="n">plan</span>
<span class="mi">34</span><span class="w"> </span><span class="p">(</span><span class="n">unstack</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">orange</span><span class="p">)</span>
<span class="mi">35</span><span class="w"> </span><span class="p">(</span><span class="n">put</span><span class="o">-</span><span class="n">down</span><span class="w"> </span><span class="n">blue</span><span class="p">)</span>
<span class="mi">36</span><span class="w"> </span><span class="p">(</span><span class="n">pick</span><span class="o">-</span><span class="n">up</span><span class="w"> </span><span class="n">orange</span><span class="p">)</span>
<span class="mi">37</span><span class="w"> </span><span class="p">(</span><span class="n">stack</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">blue</span><span class="p">)</span>
<span class="mi">38</span>
<span class="mi">39</span><span class="w"> </span><span class="o">==========</span><span class="w"> </span><span class="p">(</span><span class="n">Full</span><span class="o">-&gt;</span><span class="n">Partial</span><span class="p">)</span><span class="w"> </span><span class="n">SUCCESS</span><span class="w"> </span><span class="o">=====</span>
</code></pre></div>

<h1>Robustness to Goal Reformulation (Partial $\rightarrow$ Full)</h1>
<p>Listing 10: Providing an example with partially specified goal and asking to complete for the same example with a fully specified goal</p>
<div class="codehilite"><pre><span></span><code><span class="mi">1</span><span class="w"> </span><span class="p">[</span><span class="n">STATEMENT</span><span class="p">]</span>
<span class="mi">2</span><span class="w"> </span><span class="n">As</span><span class="w"> </span><span class="n">initial</span><span class="w"> </span><span class="n">conditions</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">that</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span>
<span class="w">    </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">empty</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span>
<span class="w">    </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span>
<span class="w">    </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="p">.</span>
<span class="mi">3</span><span class="w"> </span><span class="n">My</span><span class="w"> </span><span class="n">goal</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="p">.</span>
<span class="mi">4</span>
<span class="mi">5</span><span class="w"> </span><span class="n">My</span><span class="w"> </span><span class="n">plan</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">follows</span><span class="o">:</span>
<span class="mi">6</span>
<span class="mi">7</span><span class="w"> </span><span class="p">[</span><span class="n">PLAN</span><span class="p">]</span>
<span class="mi">8</span><span class="w"> </span><span class="n">unstack</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="mi">9</span><span class="p">}</span><span class="err">\</span><span class="n">mathrm</span><span class="p">{</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="mi">10</span><span class="p">}</span><span class="err">\</span><span class="n">mathrm</span><span class="p">{</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span>
<span class="mi">11</span><span class="w"> </span><span class="n">stack</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="mi">12</span><span class="w"> </span><span class="p">[</span><span class="n">PLAN</span><span class="w"> </span><span class="n">END</span><span class="p">]</span>
<span class="mi">13</span>
<span class="mi">14</span><span class="w"> </span><span class="p">[</span><span class="n">STATEMENT</span><span class="p">]</span>
<span class="mi">15</span><span class="w"> </span><span class="n">As</span><span class="w"> </span><span class="n">initial</span><span class="w"> </span><span class="n">conditions</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">that</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span>
<span class="w">    </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">clear</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">hand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">empty</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">on</span>
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ Link to the github repo: https://github.com/karthikv792/gpt-plan-benchmark&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>