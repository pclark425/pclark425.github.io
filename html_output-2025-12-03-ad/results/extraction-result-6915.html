<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6915 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6915</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6915</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-ea82761bc409791613badb9732a674f652ecfab1</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ea82761bc409791613badb9732a674f652ecfab1" target="_blank">A test of indirect grounding of abstract concepts using multimodal distributional semantics</a></p>
                <p><strong>Paper Venue:</strong> Frontiers in Psychology</p>
                <p><strong>Paper TL;DR:</strong> This paper tests the indirect grounding view by means of multimodal distributional semantics, in which the meaning of a word is represented as the combination of textual and visual vectors, and lends some plausibility to the indirect grounded view as a cognitive mechanism of grounding abstract concepts.</p>
                <p><strong>Paper Abstract:</strong> How are abstract concepts grounded in perceptual experiences for shaping human conceptual knowledge? Recent studies on abstract concepts emphasizing the role of language have argued that abstract concepts are grounded indirectly in perceptual experiences and language (or words) functions as a bridge between abstract concepts and perceptual experiences. However, this “indirect grounding” view remains largely speculative and has hardly been supported directly by empirical evidence. In this paper, therefore, we test the indirect grounding view by means of multimodal distributional semantics, in which the meaning of a word (i.e., a concept) is represented as the combination of textual and visual vectors. The newly devised multimodal distributional semantic model incorporates the indirect grounding view by computing the visual vector of an abstract word through the visual vectors of concrete words semantically related to that abstract word. An evaluation experiment is conducted in which conceptual representation is predicted from multimodal vectors using a multilayer feed-forward neural network. The analysis of prediction performance demonstrates that the indirect grounding model achieves significantly better performance in predicting human conceptual representation of abstract words than other models that mimic competing views on abstract concepts, especially than the direct grounding model in which the visual vectors of abstract words are computed directly from the images of abstract concepts. This result lends some plausibility to the indirect grounding view as a cognitive mechanism of grounding abstract concepts.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6915.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6915.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PSS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual Symbol Systems (Barsalou)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory that concepts are modality-specific perceptual symbols (neural activation patterns) derived from sensorimotor experiences and reactivated as simulations during conceptual processing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Perceptual Symbol Systems / Embodied Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as distributed, modality-specific perceptual symbols (neural activation patterns) formed during real-world perception and reactivated (simulated) when the concept is processed.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains mental simulation during word/concept comprehension, modality-specific activation patterns, and many embodied behavioral effects (e.g., action–language compatibility).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments and neuroimaging cited (e.g., lexical decision, property generation, action–language compatibility studies)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>property generation tasks, picture priming, action-language compatibility (e.g., sentence/response congruency) and neuroimaging contrasts</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Behavioral and imaging studies show modality-relevant activations and facilitation effects consistent with mental simulation (cited works: Barsalou 1999, Barsalou & Wiemer-Hastings 2005, McRae et al. 2018).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Paper notes limitations for abstract concepts: simulations from perceptual images alone may be insufficient to capture meaning of many abstract concepts and do not explain how abstract words become linked to relevant situations; evidence that mothers use abstract words less often in presence of referents (Bergelson & Swingley 2013) challenges direct grounding for abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Barsalou 1999</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6915.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Situated Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Situated Simulation View (Barsalou et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of embodied simulation arguing that concept processing involves situationally grounded simulations and that the concrete/abstract distinction may be unnecessary.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Situated simulation in the human conceptual system</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Situated Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / situated representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual processing draws on re-enactments of situations; both concrete and abstract concepts are captured by situated simulations of relevant scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for crossmodal priming between pictures and abstract words, context-sensitive property generation, and situationally-dependent conceptual activation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments and priming studies</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>property generation, picture-to-word and word-to-picture priming (e.g., McRae et al. 2018), lexical decision with situational primes</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Pictures of situations facilitate processing of relevant abstract words and vice versa, suggesting situational simulation mediates some abstract concept processing.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors argue situated simulation may be limited: visual images alone often don't fully convey abstract concepts (e.g., justice) and situated co-occurrence of abstract words with their referent situations is rare (Bergelson & Swingley 2013), leaving a gap in explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Barsalou 2003</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6915.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DualCoding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual Coding Theory (Paivio)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational hypothesis positing two separate systems: a verbal (linguistic) system and a nonverbal (imagery/visual) system, with concrete words represented in both and abstract words primarily in the verbal system.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Imagery and Verbal Processes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Dual Coding Theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic + feature-based (dual-system)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is stored in two parallel codes: a verbal/symbolic code and an imagistic/visual code; concrete concepts have both codes, abstract concepts mainly have verbal code.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains concreteness effects in memory and processing, and differential mnemonic advantages for concrete words.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral memory and lexical processing studies</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>memory recall, concreteness effect tasks, lexical decision and imagery tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Concrete words benefit from dual coding (visual+verbal) producing processing/memory advantages; abstract words lack imagery code in theory.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Paper notes dual coding does not specify whether visual system contributes to abstract words; multimodal computational results show some abstract words benefit from visual information via linguistic links, challenging a strict dual-only verbal representation for abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Paivio 1971</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6915.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LASS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language And Situated Simulation (LASS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid account proposing temporally interacting linguistic and simulation systems: language provides rapid categorization while simulations engage later for deeper processing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language and simulation in conceptual processing</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>LASS (Language And Situated Simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>hybrid: symbolic + embodied simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>When a word is perceived both a linguistic (symbolic) system and a simulation system activate; linguistic system engages immediately for shallow tasks, while situational simulation supports deeper comprehension.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains task-dependent reliance on linguistic vs. simulation information and timecourse differences in conceptual processing.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical synthesis supported by behavioral task manipulations</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>lexical decision vs. property generation (shallow vs deep tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Predicts language suffices for shallow tasks (e.g., lexical decision) while simulations contribute to deeper tasks; paper references this as a framework rather than directly testing it.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors argue LASS does not fully explain how language shapes meaning or how abstract concepts become linked to perceptual situations (no mechanism for grounding abstracts via language specified).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Barsalou et al. 2008</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6915.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WAT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Words As social Tools (WAT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid theory emphasizing that language functions as a social tool enabling situated simulation of social experiences, playing a central role in acquisition and representation of abstract concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Words as social tools: language, sociality and inner grounding in abstract concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Words As social Tools (WAT)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>hybrid: language-mediated embodied/social representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Abstract concepts depend heavily on linguistic and social interactions; words serve as instruments to perform social actions and enable re-enactment of social experiences that ground abstract meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains importance of language and social interaction in the acquisition and neural organization of abstract concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>empirical findings on language acquisition and neuroimaging (cited reviews/studies)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>various (acquisition studies, neuroimaging contrasts showing left-lateralized perisylvian activation for abstracts)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Neuroimaging and acquisition data suggest language networks are more engaged for abstract concepts, consistent with WAT emphasis on language/social grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>WAT does not provide a detailed computational mechanism for how language shapes abstract meaning; paper positions indirect grounding as complementary by proposing language can mediate perceptual grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Borghi et al. 2019</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6915.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SymbolInterdep</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbol Interdependency Hypothesis (Louwerse)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hypothesis that language comprehension is symbolic via interdependencies among linguistic symbols but indirectly embodied through references that those symbols make to perceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Symbol interdependency in symbolic and embodied cognition</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Symbol Interdependency Hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic with indirect embodied links</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Language encodes relations that serve as a shortcut to embodied/perceptual representations; symbolic distributional statistics can predict many semantic behaviors while being indirectly grounded via perceptual referents.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how distributional linguistic structure can predict semantic performance and act as a proxy to perceptual knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments (semantic and iconicity judgment tasks) and distributional analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>semantic judgement and iconicity judgment tasks (Louwerse & Jeuniaux 2010)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Symbolic (word-pair frequency) factors predicted semantic judgments, whereas embodied/iconic factors predicted iconicity judgments, consistent with dual contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>These behavioral results support mixed contributions but do not directly prove that abstract words are grounded indirectly via language-mediated linkage to perceptual representations; further direct evidence required.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Louwerse 2011</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6915.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IndirectGroundingView</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Indirect grounding view (collective accounts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of views proposing that abstract concepts are grounded in sensorimotor/perceptual experience indirectly via language (mediator words), rather than directly via perception.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Indirect grounding view</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>language-mediated embodied grounding</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Abstract concepts acquire perceptual grounding by linguistic links to concrete concepts that have direct perceptual grounding; language acts as a bridge so abstract words access perceptual/sensorimotor representations via semantic neighbors.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for how abstract concepts can be connected to perceptual experience without direct co-occurrence; predicts language-derived distributional relations will map abstracts to perceptual representations and support behavioral embodiment effects.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational proposals, behavioral experiments (e.g., Günther et al. 2020), theoretical arguments, and the present paper's computational test</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>novel-concept sensorimotor congruency tasks (Günther et al. 2020); multimodal distributional semantic modeling with prediction of brain-based vectors (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>This paper's multimodal DSM implementing indirect grounding (averaging visual vectors of concrete semantic neighbors) predicted Binder et al.'s brain-derived conceptual vectors for abstract words better than direct grounding/hybrid models; Günther et al. (2020) showed newly learned language-only concepts can display sensorimotor congruency effects.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Still largely speculative historically; effectiveness depends on choice of mediator/concrete neighbors and modality (this paper focuses on vision only); indirect grounding can be harmful if semantic neighbors are poorly chosen or thresholding misclassifies concrete words as abstract.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>collective (Howell et al. 2005; Louwerse 2011; Gleitman et al. 2005; Günther et al. 2020)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6915.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DSM_I</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Indirect grounding multimodal distributional semantic model (DSM_I)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The computational model introduced in this paper that represents words by textual vectors and visually grounded vectors computed indirectly for abstract words via averaging visual vectors of k semantically nearest concrete neighbors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Indirect grounding multimodal DSM (model implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional multimodal vector space (text+visual) with mediated visual vectors</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Each word has a textual vector (SGNS) and a visually grounded vector; for concrete words, visual vector is direct (from images); for abstract words, visual vector is computed as the mean of direct visual vectors of k nearest concrete textual neighbors, implementing language-mediated indirect grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Predicts human brain-inspired conceptual vectors better for abstract words than direct-visual or purely textual/hybrid models; operationalizes language-as-bridge grounding mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulation and evaluation against human brain-based feature vectors (Binder et al. 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>multimodal vector construction (COCA textual SGNS vectors + ResNet152 visual vectors from Flickr images), feedforward neural network mapping to Binder et al.'s 65-dim vectors, leave-one-cluster-out cross-validation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>DSM_I outperformed hybrid (direct visual) and dual-coding models in predicting Binder et al.'s conceptual vectors for abstract words (higher Pearson correlations across concreteness thresholds), supporting plausibility of indirect grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Limitations: evaluation restricted to visual modality and to Binder et al. feature set; dependence on DNN visual features which may diverge from human vision; performance sensitive to concreteness threshold and neighbor selection (N, k).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Utsumi 2022</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6915.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Binder65</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Binder et al.'s brain-based semantic representation (65-dimensional attributes)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neurobiologically motivated featural vector set: 65 continuous attributes (across 14 domains) providing brain-informed semantic feature salience ratings per word, used as target conceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward a brain-based computational semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Brain-based featural semantic representation (Binder et al. 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based high-dimensional vector (neurobiologically motivated)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Each concept is represented as a 65-dimensional real-valued vector whose dimensions map to neurobiologically plausible attributes (vision, audition, motor, social, emotion, etc.), with values derived from human ratings.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Serves as a brain-inspired target space for evaluating how distributional and multimodal models map onto neurobiologically relevant conceptual dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral rating dataset linked to neurobiological attributes; used for computational evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Amazon Mechanical Turk attribute rating surveys; averaging produces continuous attribute salience per word</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Provides a systematic, neurobiologically motivated multidimensional feature representation that distributional/multimodal models can be trained to predict; used as ground truth in this paper's mapping experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors note feature-based vectors cannot capture relational/higher-order structure between concepts; limited coverage (535 words) and possible insufficiency for some abstract conceptual richness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder et al. 2016</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6915.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multimodal DSM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multimodal Distributional Semantics</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational framework that augments text-derived distributional vectors with nonlinguistic perceptual vectors (visual, auditory, olfactory) to form multimodal word representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Grounding distributional semantics in the visual world</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Multimodal Distributional Semantics</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional multimodal vector space</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Combines linguistic (textual) distributional vectors with perceptual vectors extracted from images/audio/other sensory inputs (e.g., DNN image features) to yield richer semantic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Aims to better capture grounded meaning, especially for concrete concepts where perceptual information is salient; can improve performance on some semantic prediction tasks over textual-only models.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational modeling and benchmark evaluations (cited empirical literature: Bruni et al. 2014; Kiela et al. 2014)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>train textual vectors (e.g., SGNS) and extract visual vectors (e.g., ResNet features), then concatenate/combine and evaluate on semantic prediction tasks or similarity benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Prior work shows adding visual vectors helps mainly for concrete concepts; this paper extends the approach by implementing indirect visual grounding for abstract words and empirically comparing variants.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Standard multimodal models that compute perceptual vectors identically for all words tend to help concrete words but not abstract words; naive addition of perceptual vectors is insufficient for capturing many abstract concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Baroni 2016</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6915.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HubSpoke</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hub-and-Spoke model (Hoffman, Lambon Ralph, McClelland)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A connectionist account where modality-specific 'spokes' (sensorimotor feature stores) interface with an amodal 'hub' (integrative semantic representation) to produce concept knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concepts, control, and context: a connectionist account of normal and disordered semantic cognition</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Hub-and-Spoke connectionist model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>relational network / connectionist high-dimensional representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Semantic cognition arises from interaction between distributed modality-specific feature representations (spokes) and an amodal hub layer that integrates across modalities; trained via prediction tasks to capture conceptual structure.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for both modality-specific effects and integrative conceptual representations, can model normal and impaired semantic cognition patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulations (connectionist modeling) and comparison to behavioral/neuropsychological data</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>training recurrent/connectionist networks to predict next words and features; analysis of hidden-layer representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Models can learn representations that mirror human semantic patterns and simulate deficits; authors proposed indirect association of abstract words with perceptual features via co-occurrence patterns in their model.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Paper notes many prior models (including Hoffman et al.) use verbally expressed featural inputs rather than directly computed nonverbal perceptual vectors; also such models did not directly compare indirect vs direct grounding for abstract words.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Hoffman et al. 2018</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6915.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PropagationGrounding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Propagation of Grounding (Howell et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed mechanism in language acquisition whereby grounded meaning of concrete words propagates through syntactic/co-occurrence links to support learning of abstract words.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A model of grounded language acquisition: Sensorimotor features improve lexical and grammatical learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Propagation of grounding</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>learning mechanism / distributional propagation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Through co-occurrence and syntactic links, perceptually grounded meanings of early-acquired concrete words propagate across the linguistic network to assist acquisition and representation of more abstract words.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how 'hard' or abstract words can be acquired indirectly using structure-to-world mappings and co-occurrence with grounded words.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational recurrent network simulations</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>recurrent network trained to predict next word and featural representations; analysis of learned representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Networks trained with featural (sensorimotor) representations improved lexical and grammatical learning, supporting the plausibility of grounding propagation.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Earlier simulations used verbally encoded featural inputs rather than raw perceptual data; they did not directly test mediated visual grounding for existing adult abstract concepts as done in the present paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Howell et al. 2005</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6915.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e6915.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MultimodalSkipGram</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multimodal Skip-Gram (Lazaridou et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of skip-gram word embedding training that incorporates visual similarity objectives so learned word vectors are influenced by image-derived information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Combining language and vision with a multimodal skip-gram model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Multimodal Skip-gram model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional multimodal vector learning</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Augments word2vec/skip-gram training objective with a term encouraging words with similar visual contexts to have similar embeddings, producing multimodal embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Can induce visually-relevant nearest neighbors for some abstract words, suggesting distributional+visual learning can indirectly associate abstract words with imageable concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational modeling and nearest-neighbor analysis</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>multimodal embedding training (text + image-derived objectives) and qualitative/quantitative analysis of nearest neighbors</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Some abstract words in multimodal skip-gram had nearest neighbors whose images depicted conceptually relevant concrete situations (e.g., 'theory' associated with bookshelf images), indicating potential for indirect grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Not all abstract words showed visually relevant neighbors; model does not explicitly implement mediated averaging of concrete visual vectors as in DSM_I.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Lazaridou et al. 2015</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A test of indirect grounding of abstract concepts using multimodal distributional semantics', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Perceptual symbol systems <em>(Rating: 2)</em></li>
                <li>Situated simulation in the human conceptual system <em>(Rating: 2)</em></li>
                <li>Imagery and Verbal Processes <em>(Rating: 1)</em></li>
                <li>Language and simulation in conceptual processing <em>(Rating: 2)</em></li>
                <li>Words as social tools: language, sociality and inner grounding in abstract concepts <em>(Rating: 2)</em></li>
                <li>Symbol interdependency in symbolic and embodied cognition <em>(Rating: 2)</em></li>
                <li>Toward a brain-based computational semantic representation <em>(Rating: 2)</em></li>
                <li>A model of grounded language acquisition: Sensorimotor features improve lexical and grammatical learning <em>(Rating: 2)</em></li>
                <li>Concepts, control, and context: a connectionist account of normal and disordered semantic cognition <em>(Rating: 2)</em></li>
                <li>Combining language and vision with a multimodal skip-gram model <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6915",
    "paper_id": "paper-ea82761bc409791613badb9732a674f652ecfab1",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "PSS",
            "name_full": "Perceptual Symbol Systems (Barsalou)",
            "brief_description": "A theory that concepts are modality-specific perceptual symbols (neural activation patterns) derived from sensorimotor experiences and reactivated as simulations during conceptual processing.",
            "citation_title": "Perceptual symbol systems",
            "mention_or_use": "mention",
            "theory_name": "Perceptual Symbol Systems / Embodied Simulation",
            "theory_type": "embodied simulation",
            "theory_description": "Concepts are represented as distributed, modality-specific perceptual symbols (neural activation patterns) formed during real-world perception and reactivated (simulated) when the concept is processed.",
            "functional_claims": "Explains mental simulation during word/concept comprehension, modality-specific activation patterns, and many embodied behavioral effects (e.g., action–language compatibility).",
            "evidence_source": "behavioral experiments and neuroimaging cited (e.g., lexical decision, property generation, action–language compatibility studies)",
            "experimental_paradigm": "property generation tasks, picture priming, action-language compatibility (e.g., sentence/response congruency) and neuroimaging contrasts",
            "key_result": "Behavioral and imaging studies show modality-relevant activations and facilitation effects consistent with mental simulation (cited works: Barsalou 1999, Barsalou & Wiemer-Hastings 2005, McRae et al. 2018).",
            "supports_theory": true,
            "counter_evidence": "Paper notes limitations for abstract concepts: simulations from perceptual images alone may be insufficient to capture meaning of many abstract concepts and do not explain how abstract words become linked to relevant situations; evidence that mothers use abstract words less often in presence of referents (Bergelson & Swingley 2013) challenges direct grounding for abstracts.",
            "citation": "Barsalou 1999",
            "uuid": "e6915.0",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Situated Simulation",
            "name_full": "Situated Simulation View (Barsalou et al.)",
            "brief_description": "An extension of embodied simulation arguing that concept processing involves situationally grounded simulations and that the concrete/abstract distinction may be unnecessary.",
            "citation_title": "Situated simulation in the human conceptual system",
            "mention_or_use": "mention",
            "theory_name": "Situated Simulation",
            "theory_type": "embodied simulation / situated representation",
            "theory_description": "Conceptual processing draws on re-enactments of situations; both concrete and abstract concepts are captured by situated simulations of relevant scenarios.",
            "functional_claims": "Accounts for crossmodal priming between pictures and abstract words, context-sensitive property generation, and situationally-dependent conceptual activation.",
            "evidence_source": "behavioral experiments and priming studies",
            "experimental_paradigm": "property generation, picture-to-word and word-to-picture priming (e.g., McRae et al. 2018), lexical decision with situational primes",
            "key_result": "Pictures of situations facilitate processing of relevant abstract words and vice versa, suggesting situational simulation mediates some abstract concept processing.",
            "supports_theory": true,
            "counter_evidence": "Authors argue situated simulation may be limited: visual images alone often don't fully convey abstract concepts (e.g., justice) and situated co-occurrence of abstract words with their referent situations is rare (Bergelson & Swingley 2013), leaving a gap in explanation.",
            "citation": "Barsalou 2003",
            "uuid": "e6915.1",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "DualCoding",
            "name_full": "Dual Coding Theory (Paivio)",
            "brief_description": "A representational hypothesis positing two separate systems: a verbal (linguistic) system and a nonverbal (imagery/visual) system, with concrete words represented in both and abstract words primarily in the verbal system.",
            "citation_title": "Imagery and Verbal Processes",
            "mention_or_use": "mention",
            "theory_name": "Dual Coding Theory",
            "theory_type": "symbolic + feature-based (dual-system)",
            "theory_description": "Conceptual knowledge is stored in two parallel codes: a verbal/symbolic code and an imagistic/visual code; concrete concepts have both codes, abstract concepts mainly have verbal code.",
            "functional_claims": "Explains concreteness effects in memory and processing, and differential mnemonic advantages for concrete words.",
            "evidence_source": "behavioral memory and lexical processing studies",
            "experimental_paradigm": "memory recall, concreteness effect tasks, lexical decision and imagery tasks",
            "key_result": "Concrete words benefit from dual coding (visual+verbal) producing processing/memory advantages; abstract words lack imagery code in theory.",
            "supports_theory": true,
            "counter_evidence": "Paper notes dual coding does not specify whether visual system contributes to abstract words; multimodal computational results show some abstract words benefit from visual information via linguistic links, challenging a strict dual-only verbal representation for abstracts.",
            "citation": "Paivio 1971",
            "uuid": "e6915.2",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "LASS",
            "name_full": "Language And Situated Simulation (LASS)",
            "brief_description": "A hybrid account proposing temporally interacting linguistic and simulation systems: language provides rapid categorization while simulations engage later for deeper processing.",
            "citation_title": "Language and simulation in conceptual processing",
            "mention_or_use": "mention",
            "theory_name": "LASS (Language And Situated Simulation)",
            "theory_type": "hybrid: symbolic + embodied simulation",
            "theory_description": "When a word is perceived both a linguistic (symbolic) system and a simulation system activate; linguistic system engages immediately for shallow tasks, while situational simulation supports deeper comprehension.",
            "functional_claims": "Explains task-dependent reliance on linguistic vs. simulation information and timecourse differences in conceptual processing.",
            "evidence_source": "theoretical synthesis supported by behavioral task manipulations",
            "experimental_paradigm": "lexical decision vs. property generation (shallow vs deep tasks)",
            "key_result": "Predicts language suffices for shallow tasks (e.g., lexical decision) while simulations contribute to deeper tasks; paper references this as a framework rather than directly testing it.",
            "supports_theory": null,
            "counter_evidence": "Authors argue LASS does not fully explain how language shapes meaning or how abstract concepts become linked to perceptual situations (no mechanism for grounding abstracts via language specified).",
            "citation": "Barsalou et al. 2008",
            "uuid": "e6915.3",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "WAT",
            "name_full": "Words As social Tools (WAT)",
            "brief_description": "A hybrid theory emphasizing that language functions as a social tool enabling situated simulation of social experiences, playing a central role in acquisition and representation of abstract concepts.",
            "citation_title": "Words as social tools: language, sociality and inner grounding in abstract concepts",
            "mention_or_use": "mention",
            "theory_name": "Words As social Tools (WAT)",
            "theory_type": "hybrid: language-mediated embodied/social representation",
            "theory_description": "Abstract concepts depend heavily on linguistic and social interactions; words serve as instruments to perform social actions and enable re-enactment of social experiences that ground abstract meaning.",
            "functional_claims": "Explains importance of language and social interaction in the acquisition and neural organization of abstract concepts.",
            "evidence_source": "empirical findings on language acquisition and neuroimaging (cited reviews/studies)",
            "experimental_paradigm": "various (acquisition studies, neuroimaging contrasts showing left-lateralized perisylvian activation for abstracts)",
            "key_result": "Neuroimaging and acquisition data suggest language networks are more engaged for abstract concepts, consistent with WAT emphasis on language/social grounding.",
            "supports_theory": true,
            "counter_evidence": "WAT does not provide a detailed computational mechanism for how language shapes abstract meaning; paper positions indirect grounding as complementary by proposing language can mediate perceptual grounding.",
            "citation": "Borghi et al. 2019",
            "uuid": "e6915.4",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "SymbolInterdep",
            "name_full": "Symbol Interdependency Hypothesis (Louwerse)",
            "brief_description": "A hypothesis that language comprehension is symbolic via interdependencies among linguistic symbols but indirectly embodied through references that those symbols make to perceptual representations.",
            "citation_title": "Symbol interdependency in symbolic and embodied cognition",
            "mention_or_use": "mention",
            "theory_name": "Symbol Interdependency Hypothesis",
            "theory_type": "symbolic with indirect embodied links",
            "theory_description": "Language encodes relations that serve as a shortcut to embodied/perceptual representations; symbolic distributional statistics can predict many semantic behaviors while being indirectly grounded via perceptual referents.",
            "functional_claims": "Explains how distributional linguistic structure can predict semantic performance and act as a proxy to perceptual knowledge.",
            "evidence_source": "behavioral experiments (semantic and iconicity judgment tasks) and distributional analyses",
            "experimental_paradigm": "semantic judgement and iconicity judgment tasks (Louwerse & Jeuniaux 2010)",
            "key_result": "Symbolic (word-pair frequency) factors predicted semantic judgments, whereas embodied/iconic factors predicted iconicity judgments, consistent with dual contributions.",
            "supports_theory": true,
            "counter_evidence": "These behavioral results support mixed contributions but do not directly prove that abstract words are grounded indirectly via language-mediated linkage to perceptual representations; further direct evidence required.",
            "citation": "Louwerse 2011",
            "uuid": "e6915.5",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "IndirectGroundingView",
            "name_full": "Indirect grounding view (collective accounts)",
            "brief_description": "A class of views proposing that abstract concepts are grounded in sensorimotor/perceptual experience indirectly via language (mediator words), rather than directly via perception.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Indirect grounding view",
            "theory_type": "language-mediated embodied grounding",
            "theory_description": "Abstract concepts acquire perceptual grounding by linguistic links to concrete concepts that have direct perceptual grounding; language acts as a bridge so abstract words access perceptual/sensorimotor representations via semantic neighbors.",
            "functional_claims": "Accounts for how abstract concepts can be connected to perceptual experience without direct co-occurrence; predicts language-derived distributional relations will map abstracts to perceptual representations and support behavioral embodiment effects.",
            "evidence_source": "computational proposals, behavioral experiments (e.g., Günther et al. 2020), theoretical arguments, and the present paper's computational test",
            "experimental_paradigm": "novel-concept sensorimotor congruency tasks (Günther et al. 2020); multimodal distributional semantic modeling with prediction of brain-based vectors (this paper)",
            "key_result": "This paper's multimodal DSM implementing indirect grounding (averaging visual vectors of concrete semantic neighbors) predicted Binder et al.'s brain-derived conceptual vectors for abstract words better than direct grounding/hybrid models; Günther et al. (2020) showed newly learned language-only concepts can display sensorimotor congruency effects.",
            "supports_theory": true,
            "counter_evidence": "Still largely speculative historically; effectiveness depends on choice of mediator/concrete neighbors and modality (this paper focuses on vision only); indirect grounding can be harmful if semantic neighbors are poorly chosen or thresholding misclassifies concrete words as abstract.",
            "citation": "collective (Howell et al. 2005; Louwerse 2011; Gleitman et al. 2005; Günther et al. 2020)",
            "uuid": "e6915.6",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "DSM_I",
            "name_full": "Indirect grounding multimodal distributional semantic model (DSM_I)",
            "brief_description": "The computational model introduced in this paper that represents words by textual vectors and visually grounded vectors computed indirectly for abstract words via averaging visual vectors of k semantically nearest concrete neighbors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Indirect grounding multimodal DSM (model implementation)",
            "theory_type": "high-dimensional multimodal vector space (text+visual) with mediated visual vectors",
            "theory_description": "Each word has a textual vector (SGNS) and a visually grounded vector; for concrete words, visual vector is direct (from images); for abstract words, visual vector is computed as the mean of direct visual vectors of k nearest concrete textual neighbors, implementing language-mediated indirect grounding.",
            "functional_claims": "Predicts human brain-inspired conceptual vectors better for abstract words than direct-visual or purely textual/hybrid models; operationalizes language-as-bridge grounding mechanism.",
            "evidence_source": "computational simulation and evaluation against human brain-based feature vectors (Binder et al. 2016)",
            "experimental_paradigm": "multimodal vector construction (COCA textual SGNS vectors + ResNet152 visual vectors from Flickr images), feedforward neural network mapping to Binder et al.'s 65-dim vectors, leave-one-cluster-out cross-validation",
            "key_result": "DSM_I outperformed hybrid (direct visual) and dual-coding models in predicting Binder et al.'s conceptual vectors for abstract words (higher Pearson correlations across concreteness thresholds), supporting plausibility of indirect grounding.",
            "supports_theory": true,
            "counter_evidence": "Limitations: evaluation restricted to visual modality and to Binder et al. feature set; dependence on DNN visual features which may diverge from human vision; performance sensitive to concreteness threshold and neighbor selection (N, k).",
            "citation": "Utsumi 2022",
            "uuid": "e6915.7",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Binder65",
            "name_full": "Binder et al.'s brain-based semantic representation (65-dimensional attributes)",
            "brief_description": "A neurobiologically motivated featural vector set: 65 continuous attributes (across 14 domains) providing brain-informed semantic feature salience ratings per word, used as target conceptual representations.",
            "citation_title": "Toward a brain-based computational semantic representation",
            "mention_or_use": "use",
            "theory_name": "Brain-based featural semantic representation (Binder et al. 2016)",
            "theory_type": "feature-based high-dimensional vector (neurobiologically motivated)",
            "theory_description": "Each concept is represented as a 65-dimensional real-valued vector whose dimensions map to neurobiologically plausible attributes (vision, audition, motor, social, emotion, etc.), with values derived from human ratings.",
            "functional_claims": "Serves as a brain-inspired target space for evaluating how distributional and multimodal models map onto neurobiologically relevant conceptual dimensions.",
            "evidence_source": "behavioral rating dataset linked to neurobiological attributes; used for computational evaluation",
            "experimental_paradigm": "Amazon Mechanical Turk attribute rating surveys; averaging produces continuous attribute salience per word",
            "key_result": "Provides a systematic, neurobiologically motivated multidimensional feature representation that distributional/multimodal models can be trained to predict; used as ground truth in this paper's mapping experiments.",
            "supports_theory": true,
            "counter_evidence": "Authors note feature-based vectors cannot capture relational/higher-order structure between concepts; limited coverage (535 words) and possible insufficiency for some abstract conceptual richness.",
            "citation": "Binder et al. 2016",
            "uuid": "e6915.8",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Multimodal DSM",
            "name_full": "Multimodal Distributional Semantics",
            "brief_description": "A computational framework that augments text-derived distributional vectors with nonlinguistic perceptual vectors (visual, auditory, olfactory) to form multimodal word representations.",
            "citation_title": "Grounding distributional semantics in the visual world",
            "mention_or_use": "use",
            "theory_name": "Multimodal Distributional Semantics",
            "theory_type": "high-dimensional multimodal vector space",
            "theory_description": "Combines linguistic (textual) distributional vectors with perceptual vectors extracted from images/audio/other sensory inputs (e.g., DNN image features) to yield richer semantic representations.",
            "functional_claims": "Aims to better capture grounded meaning, especially for concrete concepts where perceptual information is salient; can improve performance on some semantic prediction tasks over textual-only models.",
            "evidence_source": "computational modeling and benchmark evaluations (cited empirical literature: Bruni et al. 2014; Kiela et al. 2014)",
            "experimental_paradigm": "train textual vectors (e.g., SGNS) and extract visual vectors (e.g., ResNet features), then concatenate/combine and evaluate on semantic prediction tasks or similarity benchmarks",
            "key_result": "Prior work shows adding visual vectors helps mainly for concrete concepts; this paper extends the approach by implementing indirect visual grounding for abstract words and empirically comparing variants.",
            "supports_theory": true,
            "counter_evidence": "Standard multimodal models that compute perceptual vectors identically for all words tend to help concrete words but not abstract words; naive addition of perceptual vectors is insufficient for capturing many abstract concepts.",
            "citation": "Baroni 2016",
            "uuid": "e6915.9",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "HubSpoke",
            "name_full": "Hub-and-Spoke model (Hoffman, Lambon Ralph, McClelland)",
            "brief_description": "A connectionist account where modality-specific 'spokes' (sensorimotor feature stores) interface with an amodal 'hub' (integrative semantic representation) to produce concept knowledge.",
            "citation_title": "Concepts, control, and context: a connectionist account of normal and disordered semantic cognition",
            "mention_or_use": "mention",
            "theory_name": "Hub-and-Spoke connectionist model",
            "theory_type": "relational network / connectionist high-dimensional representation",
            "theory_description": "Semantic cognition arises from interaction between distributed modality-specific feature representations (spokes) and an amodal hub layer that integrates across modalities; trained via prediction tasks to capture conceptual structure.",
            "functional_claims": "Accounts for both modality-specific effects and integrative conceptual representations, can model normal and impaired semantic cognition patterns.",
            "evidence_source": "computational simulations (connectionist modeling) and comparison to behavioral/neuropsychological data",
            "experimental_paradigm": "training recurrent/connectionist networks to predict next words and features; analysis of hidden-layer representations",
            "key_result": "Models can learn representations that mirror human semantic patterns and simulate deficits; authors proposed indirect association of abstract words with perceptual features via co-occurrence patterns in their model.",
            "supports_theory": null,
            "counter_evidence": "Paper notes many prior models (including Hoffman et al.) use verbally expressed featural inputs rather than directly computed nonverbal perceptual vectors; also such models did not directly compare indirect vs direct grounding for abstract words.",
            "citation": "Hoffman et al. 2018",
            "uuid": "e6915.10",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "PropagationGrounding",
            "name_full": "Propagation of Grounding (Howell et al.)",
            "brief_description": "A proposed mechanism in language acquisition whereby grounded meaning of concrete words propagates through syntactic/co-occurrence links to support learning of abstract words.",
            "citation_title": "A model of grounded language acquisition: Sensorimotor features improve lexical and grammatical learning",
            "mention_or_use": "mention",
            "theory_name": "Propagation of grounding",
            "theory_type": "learning mechanism / distributional propagation",
            "theory_description": "Through co-occurrence and syntactic links, perceptually grounded meanings of early-acquired concrete words propagate across the linguistic network to assist acquisition and representation of more abstract words.",
            "functional_claims": "Explains how 'hard' or abstract words can be acquired indirectly using structure-to-world mappings and co-occurrence with grounded words.",
            "evidence_source": "computational recurrent network simulations",
            "experimental_paradigm": "recurrent network trained to predict next word and featural representations; analysis of learned representations",
            "key_result": "Networks trained with featural (sensorimotor) representations improved lexical and grammatical learning, supporting the plausibility of grounding propagation.",
            "supports_theory": true,
            "counter_evidence": "Earlier simulations used verbally encoded featural inputs rather than raw perceptual data; they did not directly test mediated visual grounding for existing adult abstract concepts as done in the present paper.",
            "citation": "Howell et al. 2005",
            "uuid": "e6915.11",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "MultimodalSkipGram",
            "name_full": "Multimodal Skip-Gram (Lazaridou et al.)",
            "brief_description": "An extension of skip-gram word embedding training that incorporates visual similarity objectives so learned word vectors are influenced by image-derived information.",
            "citation_title": "Combining language and vision with a multimodal skip-gram model",
            "mention_or_use": "mention",
            "theory_name": "Multimodal Skip-gram model",
            "theory_type": "high-dimensional multimodal vector learning",
            "theory_description": "Augments word2vec/skip-gram training objective with a term encouraging words with similar visual contexts to have similar embeddings, producing multimodal embeddings.",
            "functional_claims": "Can induce visually-relevant nearest neighbors for some abstract words, suggesting distributional+visual learning can indirectly associate abstract words with imageable concepts.",
            "evidence_source": "computational modeling and nearest-neighbor analysis",
            "experimental_paradigm": "multimodal embedding training (text + image-derived objectives) and qualitative/quantitative analysis of nearest neighbors",
            "key_result": "Some abstract words in multimodal skip-gram had nearest neighbors whose images depicted conceptually relevant concrete situations (e.g., 'theory' associated with bookshelf images), indicating potential for indirect grounding.",
            "supports_theory": true,
            "counter_evidence": "Not all abstract words showed visually relevant neighbors; model does not explicitly implement mediated averaging of concrete visual vectors as in DSM_I.",
            "citation": "Lazaridou et al. 2015",
            "uuid": "e6915.12",
            "source_info": {
                "paper_title": "A test of indirect grounding of abstract concepts using multimodal distributional semantics",
                "publication_date_yy_mm": "2022-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Perceptual symbol systems",
            "rating": 2,
            "sanitized_title": "perceptual_symbol_systems"
        },
        {
            "paper_title": "Situated simulation in the human conceptual system",
            "rating": 2,
            "sanitized_title": "situated_simulation_in_the_human_conceptual_system"
        },
        {
            "paper_title": "Imagery and Verbal Processes",
            "rating": 1,
            "sanitized_title": "imagery_and_verbal_processes"
        },
        {
            "paper_title": "Language and simulation in conceptual processing",
            "rating": 2,
            "sanitized_title": "language_and_simulation_in_conceptual_processing"
        },
        {
            "paper_title": "Words as social tools: language, sociality and inner grounding in abstract concepts",
            "rating": 2,
            "sanitized_title": "words_as_social_tools_language_sociality_and_inner_grounding_in_abstract_concepts"
        },
        {
            "paper_title": "Symbol interdependency in symbolic and embodied cognition",
            "rating": 2,
            "sanitized_title": "symbol_interdependency_in_symbolic_and_embodied_cognition"
        },
        {
            "paper_title": "Toward a brain-based computational semantic representation",
            "rating": 2,
            "sanitized_title": "toward_a_brainbased_computational_semantic_representation"
        },
        {
            "paper_title": "A model of grounded language acquisition: Sensorimotor features improve lexical and grammatical learning",
            "rating": 2,
            "sanitized_title": "a_model_of_grounded_language_acquisition_sensorimotor_features_improve_lexical_and_grammatical_learning"
        },
        {
            "paper_title": "Concepts, control, and context: a connectionist account of normal and disordered semantic cognition",
            "rating": 2,
            "sanitized_title": "concepts_control_and_context_a_connectionist_account_of_normal_and_disordered_semantic_cognition"
        },
        {
            "paper_title": "Combining language and vision with a multimodal skip-gram model",
            "rating": 2,
            "sanitized_title": "combining_language_and_vision_with_a_multimodal_skipgram_model"
        }
    ],
    "cost": 0.021450749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h2>OPEN ACCESS</h2>
<p>EDITED BY
Christian Huyck,
Middlesex University, United Kingdom
REVIEWED BY
Marianna Marcella Bolognesi,
University of Bologna, Italy
Marit Lobben,
Oslo Metropolitan University, Norway
Sandro Rama Fiorini,
IBM, Brazil
*CORRESPONDENCE
Akira Utsumi
utsumi@uec.ac.jp
SPECIALTY SECTION
This article was submitted to Cognitive Science, a section of the journal Frontiers in Psychology</p>
<p>RECEIVED 28 March 2022
ACCEPTED 14 September 2022
PUBLISHED 04 October 2022
CITATION
Utsumi A (2022) A test of indirect grounding of abstract concepts using multimodal distributional semantics. Front. Psychol. 13:906181. doi: 10.3389/fpsyg.2022.906181</p>
<p>COPYRIGHT
(c) 2022 Utsumi. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</p>
<h2>A test of indirect grounding of abstract concepts using multimodal distributional semantics</h2>
<p>Akira Utsumi*<br>Department of Informatics, Artificial Intelligence Exploration Research Center, The University of Electro-Communications, Tokyo, Japan</p>
<p>How are abstract concepts grounded in perceptual experiences for shaping human conceptual knowledge? Recent studies on abstract concepts emphasizing the role of language have argued that abstract concepts are grounded indirectly in perceptual experiences and language (or words) functions as a bridge between abstract concepts and perceptual experiences. However, this "indirect grounding" view remains largely speculative and has hardly been supported directly by empirical evidence. In this paper, therefore, we test the indirect grounding view by means of multimodal distributional semantics, in which the meaning of a word (i.e., a concept) is represented as the combination of textual and visual vectors. The newly devised multimodal distributional semantic model incorporates the indirect grounding view by computing the visual vector of an abstract word through the visual vectors of concrete words semantically related to that abstract word. An evaluation experiment is conducted in which conceptual representation is predicted from multimodal vectors using a multilayer feed-forward neural network. The analysis of prediction performance demonstrates that the indirect grounding model achieves significantly better performance in predicting human conceptual representation of abstract words than other models that mimic competing views on abstract concepts, especially than the direct grounding model in which the visual vectors of abstract words are computed directly from the images of abstract concepts. This result lends some plausibility to the indirect grounding view as a cognitive mechanism of grounding abstract concepts.</p>
<p>REYWORDS
abstract concepts, indirect grounding, embodied cognition, multimodal distributional semantic model, conceptual representation, symbol grounding problem</p>
<h2>1. Introduction</h2>
<h3>1.1. Abstract concepts and embodied cognition</h3>
<p>Since Harnad (1990) pointed out the symbol grounding problem, embodied approaches to cognition have emerged as promising solutions of how symbols (or words) acquire their meanings. Embodied cognition theories argue that concepts or word meanings are grounded in our perceptual or sensorimotor experiences.</p>
<p>For example, Barsalou's (1999) theory of perceptual symbol systems states that concepts (and word meanings as well) are inherently modal, perceptual symbols grounded in the real world. Perceptual symbols refer to neural representations, or activation patterns of sensorimotor regions of the brain elicited during direct perceptual experiences (e.g., seeing, touching, and playing with dogs for the concept of dog). Once these representations are encoded in the brain by repeated experiencing, they can be reactivated, that is, experiences are mentally simulated when words are encountered even in the absence of direct experience. Embodied cognition theories have been empirically supported by a considerable number of studies (e.g., Glenberg and Kaschak, 2002; Kaschak et al., 2005; Pecher and Zwaan, 2005; Barsalou, 2008; Pulvermüller, 2013; Scorolli, 2014; Barsalou, 2016; Coello and Fisher, 2016; Fisher and Coello, 2016).</p>
<p>However, abstract concepts pose a serious challenge to the embodied theory of cognition. Because abstract concepts such as love and justice do not have clearly perceivable referents, it is difficult to see how representations grounded in perceptual experiences can capture the content of abstract concepts. The empirical studies on embodied cognition have previously focused primarily on concrete concepts, such as dog and kick, which directly refer to perceivable objects or physical motions. Recently, however, the focus of concepts research has recently shifted from the embodied nature of concrete concepts to the complex nature of abstract concepts (Bolognesi and Steen, 2018; Borghi et al., 2018).</p>
<p>Some embodied theories claim a general mechanism of grounding common to both concrete and abstract concepts. Barsalou (1999, 2003) advocates that abstract concepts are represented in the same perceptual symbol systems. Perceptual symbols for abstract concepts are acquired from sensorimotor and introspective experiences in specific situations and abstract words elicit mental simulations of those situations. For example, people visualize and emotionalize two people kissing when seeing the word "love" and the court when seeing the word "justice." A recent view of situated simulation is more radical; Barsalou et al. (2018) proposed that the distinction between concrete and abstract concepts is no longer useful and should be abandoned because all concepts can be explained within the situated simulation view. The situated simulation view is supported by a number of empirical studies. Barsalou and Wiemer-Hastings (2005) and Wiemer-Hastings and Xu (2005) found using a property generation task that, when participants generated properties for abstract concepts, they were likely to describe social and introspective aspects of the situations, whereas for concrete concepts they tended to describe properties of entities in the situations. McRae et al. (2018) demonstrated that pictures of specific situations facilitated lexical decisions to abstract words relevant to the picture primes, and conversely abstract words also facilitated processing of pictures depicting the relevant situations. These empirical findings may suggest
that the situated simulation view is plausible and at least partially resolves the problem of how abstract concepts are grounded in our perceptual or sensorimotor experiences.</p>
<p>The situated simulation view, however, is not essentially sufficient to explain abstract concepts. Imagine that you have to explain abstract concepts using only visual images or videos without language. For example, to explain what is love, people may show a picture of two people kissing and hugging, a picture of wedding ceremony, and/or a picture of specific dating situations. These pictures can convey some conceptual knowledge about love, and more elaborate visual images such as films can convey greater knowledge. We feel nevertheless that only seeing them lacks something to fully understand the concept of love. This difficulty becomes more serious when more abstract concepts (e.g., justice and democracy) have to be explained; they are more difficult to explain using only visual images. This simple thought experiment suggests that situated simulation is somewhat limited as a thorough theory of abstract concepts. Another limitation is that the situated simulation view seems not to provide a clear explanation of how abstract concepts are linked to the relevant situations in acquiring those concepts. It is much less likely that people think of abstract concepts (e.g., democracy), or see or hear abstract words that refer to those concepts, at the same time as experiencing the situations associated with those concepts (e.g., casting a vote in a polling station), in contrast to concrete concepts (e.g., dog), which are often mentioned verbally in the situations including their referents. Bergelson and Swingley (2013) actually demonstrated through a videocorpus analysis of mother-infant interaction that mothers used abstract words less often in the presence of their referent events than they used concrete words in the presence of their referent objects.</p>
<p>These limitations of the situated simulation view can be largely overcome by taking into account language not only as a source of conceptual knowledge but also as an effective means of grounding abstract concepts in the real world. It has been widely accepted that language is much more important for representing abstract concepts (e.g., Borghi et al., 2017; Dove, 2018). Neuroimaging studies have demonstrated that processing of abstract concepts elicits greater activation of the left-dominant Perisylvian language network (including the left inferior frontal gyrus and the left superior temporal cortex) as compared to processing of concrete concepts (e.g., Binder et al., 2009; Wang et al., 2010). Recent embodied theories of abstract concepts have therefore emphasized the role of language in forming and processing abstract concepts or words (Borghi et al., 2017; Bolognesi and Steen, 2018). One of the important questions to be addressed by these theories is how language and embodied experience contribute to shaping our conceptual knowledge of abstract concepts and meaning representation of abstract words (e.g., Bolognesi and Steen, 2018). This question is what we address in this paper.</p>
<h3>1.2. Hybrid theory integrating symbolic and embodied cognition</h3>
<p>The dual coding theory (Paivio, 1971, 1986) is an early influential theory that integrates symbolic and embodied cognition. The main claim of this theory is that concepts are represented in two separate systems, that is, a verbal system for linguistic information and a visual system for mentally visual images. Furthermore, the dual coding theory argues that concrete words activate both the verbal and visual systems, but abstract words activate only the verbal system. This argument is consistent with the concreteness effect, whereby concrete words have processing and mnemonic advantages over abstract words. By contrast, it implies that abstract words are represented primarily by linguistic information, and it is not clear whether and how the visual system contributes to the representation of abstract words. To explain the concreteness effect, Schwanenflugel et al. (1988) and Schwanenflugel (1991) also proposed the context availability theory. According to this theory, concrete words are strongly associated with a few contexts, whereas abstract words are weakly associated with many contexts. Therefore, the context availability theory can explain the concreteness effect because abstract words require more effort to activate their contexts. Although contexts in this theory can be both linguistic or embodied, this theory is not devoted to the differences and relations between linguistic and embodied contexts or representations.</p>
<p>Recent hybrid theories, which are collectively referred to as "multiple representation theories" (Borghi et al., 2017), are more committed to how language processing interacts with embodied cognition. The multiple representation theory proposed first is Language And Situated Simulation (LASS) theory (Barsalou et al., 2008). The LASS theory focuses on the temporal interplay between language processing and situated simulation during conceptual processing. According to the LASS theory, when a word is perceived, both linguistic and simulation systems become active initially, but the linguistic system becomes engaged immediately to categorize the word. For the tasks requiring only shallow comprehension (e.g., lexical decision task), language processing would suffice. When deeper conceptual processing (e.g., property generation task) is required, the simulation system is activated later after the activation of the linguistic system peaks. However, the LASS theory is not aimed at explaining how abstract concepts are represented. It claims that both concrete and abstract concepts activate a mixture of linguistic and embodied information, and which information is dominant is determined depending on the task ${ }^{1}$, not the concept. The situated simulation view still holds in this framework, and thus the LASS theory also suffers</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>from the limitations of the situated simulation view described in section 1.1.</p>
<p>A more influential theory for the multiple representation views of abstract concepts is the "Words As social Tools" (WAT) theory (Borghi et al., 2013; Borghi and Binkofski, 2014; Borghi et al., 2019). The WAT theory claims that abstract concepts depend more on language than concrete concepts, but the role of language is not limited to word association. It emphasizes the importance of language (or words) as tools to perform social actions, and argues that the situated simulation (i.e., reenactment) of social experience through language is necessary for representing and acquiring abstract concepts. The WAT theory is supported by a number of empirical findings on language acquisition and brain organization (see, Borghi et al., 2017, 2019), but it does not clearly explain the mechanism of how language shapes the meaning representation of abstract concepts. Words not only are tools for direct social experiencing of language-related actions and events, but also function as a bridge to direct perceptual and sensorimotor experience, which is the main tenet of the indirect grounding view described in the next section.</p>
<h3>1.3. Indirect grounding view</h3>
<p>The hybrid views mentioned above assume that language provides a separate source of conceptual knowledge independent of embodied experience or the use of language is itself a constituent of embodied experience in which abstract concepts are grounded. Unlike the hybrid views, some recent studies have been devoted specifically to how language is used to relate abstract concepts to embodied experience.</p>
<p>The symbol interdependency hypothesis proposed by Louwerse $(2011,2018)$ argues for the role of language as a shortcut to the perceptual or embodied system. According to the symbol interdependency hypothesis, language comprehension is symbolic through interdependencies of amodal linguistic symbols, while it is indirectly embodied through the references linguistic symbols make to perceptual representations. Hence, "language has evolved to become a communicative short-cut for language users and encodes relations in the world, including embodied relations (Louwerse, 2011, p. 279)." Dove (2014) also argues that language provides an important means of extending our cognitive capabilities and encoding abstract concepts by enabling access to an embodied representational system that exists independently of language. Thill et al. (2014) suggest a similar view for robotic models of language grounding. Their "division of labor" approach assumes two layers of conceptual processing; a perceptual layer that associates basic, concrete concepts with perceptual features and a relational (i.e., linguistic)</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>layer that grounds more complex and abstract concepts in relation to basic concepts. The relational layer can be formed by the interdependency of linguistic symbols obtained through distributional learning. Lupyan and Lewis's (2019) "words-ascues" view is consistent with these views; they argue that language provides a cue to meaning that can augment semantic knowledge derived from perceptual experiences or construct semantic knowledge.</p>
<p>In fact, the same line of thought has been suggested earlier in the context of word learning or language acquisition. Howell et al. (2005) proposed a mechanism of "propagation of grounding" in which an abstract word inherits some meaning from the concrete words to which it is related. In their words, "the grounded meaning propagates up through the syntactic links of the co-occurrence meaning network, from the simplest early words to the most abstract (Howell et al., 2005, p. 260)." Gleitman et al. (2005) explained how "hard words" are acquired along the same line. In the early stage of lexical acquisition, the meaning of concrete words is acquired directly from perceptual information via word-to-world pairing. In the later stage, the meaning of hard words, which is not easily accessible through perception, is acquired by a structure-toworld mapping procedure that combines linguistic observations with co-occurring perceptual experience.</p>
<p>The basic idea underlying all these views is that abstract concepts or the meaning of abstract words are grounded in sensorimotor or perceptual experiences, but the grounding is indirect, rather than direct in the case of concrete concepts. Language not only provides a means to understand and represent abstract concepts (and the meaning of abstract words as well) through statistical regularities in linguistic surface structure, but also functions as a mediator between abstract concepts and perceptual experiences for a deeper understanding of abstract concepts in the absence of direct experiences with the words referring to the abstract concepts. For example, people can understand the concept of love by associating the word "love" with "kiss" (and many other relevant mediator words) via linguistic interdependency and mentally simulating the situation of kissing, even though they have never encountered the word "love" directly in the situation of kissing. In this paper, we collectively refer to these views as indirect grounding views.</p>
<p>Although the indirect grounding view may be able to provide a promising solution for the symbol grounding problem of abstract concepts, it remains largely speculative and has hardly been supported directly by empirical evidence. To empirically justify the symbol interdependency hypothesis, Louwerse and Jeuniaux (2010) demonstrated that the symbolic factor (i.e., frequency of word pairs) predicted error rates and response time in both semantic and iconicity judgments, whereas the embodied factor (i.e., iconic configuration) predicted error rates and response time in iconicity judgment. Malhi and Buchanan (2018) recently extended Louwerse and Jeuniaux's (2010) findings by using both concrete and abstract words as
stimuli and found that, for both concrete and abstract words, the symbolic factor dominated in semantic judgment and embodied factor dominated in iconicity judgment. Although these findings support the general claim that language comprehension is both embodied and symbolic, which can be predicted by the indirect grounding view and even by some of the hybrid views, they do not provide direct evidence for indirect grounding of abstract words.</p>
<p>Recently, Günther et al. (2020) provided more direct evidence for the indirect grounding view using an experimental paradigm (e.g., Zwaan and Yaxley, 2003) in which target words are faster to process when their perceptually embodied meaning (e.g., spatial location) is congruent with perceptual experiences that participants have in the experiment. They applied this paradigm to new concepts for which participants had no direct perceptual experience, but which they learned from language alone referring to vertical (i.e., up or down) concepts. The result was that, after learning new concepts via language, participants were faster at responding to sentences describing those concepts when their implied vertical position matched the direction of their hand movement for responding. This finding indicates that novel (unknown) concepts, even though not grounded directly, can be grounded indirectly by establishing a connection with directly grounded concepts via language network. In this paper, we test further the validity of the indirect grounding view for existing abstract concepts, in particular the role of language in the grounded representation of abstract concepts, using another methodology, that is, by means of multimodal distributional semantics described next.</p>
<h3>1.4. Multimodal distributional semantics</h3>
<p>Distributional semantics is an effective computational approach to constructing word meaning representations (i.e., word vectors) from the distributional statistics of words in large collections of text (Turney and Pantel, 2010; Lenci, 2018; Pilehvar and Camacho-Collados, 2020). Distributional semantics has been widely used in natural language processing (NLP) as meaning representations for neural networks or deep learning (Goldberg, 2017) and in cognitive science as a cognitive modeling method (Jones et al., 2015; Kumar, 2021). In cognitive research on concepts, in particular on embodied vs. symbolic processing, distributional semantics is regarded as a de facto standard language model (de Vega et al., 2008; Bolognesi and Steen, 2018).</p>
<p>Distributional semantics has been criticized as psychologically implausible because it is based only on linguistic (i.e., symbolic) information and thus suffers from the symbol grounding problem (de Vega et al., 2008; Baroni, 2016). Although it is controversial whether distributional semantics cannot essentially capture human semantic or conceptual knowledge, it is undoubtedly unable to represent the meaning</p>
<p>of some kinds of words, in particular concrete words, just as they are represented in human semantic memory.</p>
<p>An earlier approach to this problem is to integrate featurebased information, which is often produced by humans in property generation tasks, with distributional semantics (Andrews et al., 2009; Johns and Jones, 2012; Silberer and Lapata, 2012; Hill and Korhonen, 2014). For example, Andrews et al. (2009) used perceptual features collected as featural norm to ground a language-based topic model on perceptual experience, and demonstrated that the integrated model outperformed the language-based topic model. However, the grounding ability of these feature-integrated models is not sufficient for modeling embodied cognition. Perceptual features produced by humans are limited to what can be conveyed verbally, and they are often only salient and distinctive. Hence, implicit perceptual features characterizing a concept cannot be taken into account in the models (Bruni et al., 2014). Additionally, the number of concepts (or words) used in experiments with human-generated properties is relatively small.</p>
<p>A more promising and common approach is to directly integrate non-verbal information with (text-based) distributional semantics. Multimodal distributional semantics has been proposed for this purpose (for a review, see Baroni, 2016). In multimodal distributional semantics, linguistic or textual information is integrated with perceptual information computed directly from non-linguistic inputs such as visual (Bruni et al., 2014; Kiela et al., 2014; Silberer et al., 2017), auditory (Kiela and Clark, 2015), or olfactory (Kiela et al., 2015) ones. Furthermore, another type of approach has been proposed which utilizes visual information without directly computing visual vectors from images. Bolognesi's $(2016,2017)$ Flickr® Distributional Tagspace uses the co-occurrence statistics between user-generated tags that appear in the same image to generate word vectors. In this paper, we use multimodal distributional semantics to model the hybrid view of conceptual representation.</p>
<p>Multimodal distributional semantic models generally compute and utilize perceptual vectors in the same way for all words; they do not take account of the difference between concrete and abstract words in terms of how concepts are grounded in perceptual information, which is claimed by the indirect grounding view. Furthermore, it has been empirically demonstrated that a simple addition of perceptual information is beneficial only for concrete concepts (Bruni et al., 2014; Kiela et al., 2014). Therefore, in section 2, we devise a new multimodal distributional semantic model for indirect grounding by incorporating the indirect grounding view into an algorithm for constructing multimodal word vectors. In the devised model, the perceptual vector of an abstract word is computed from the perceptual representations of concrete words that are semantically related to (or associated with) that abstract word.</p>
<p>It must be noted that technically word vectors in (both unimodal and multimodal) distributional semantics are regarded as representing the meaning (or semantics) of words. In this paper, however, we consider the meaning of words and concepts (or the conceptual knowledge) as interchangeable, as is usually assumed in the cognitive science literature (e.g., Vigliocco and Vinson, 2007; Jackendoff, 2019). Although we do not intend to argue that concepts and word meanings are the same, it is much difficult or impossible to distinguish between concepts and word meanings in most of the cases; empirical studies on embodied cognition have used words for the tasks on conceptual representation in human adults (Borghi et al., 2017). In what follows, therefore, we assume that distributional word vectors also represent the concept referred to by a word, and that multimodal distributional semantics can be applied to modeling embodied conceptual processing.</p>
<h3>1.5. Aim of this study</h3>
<p>The aim of the present study is to test the indirect grounding view of abstract concepts by using computational modeling based on multimodal distributional semantics. For this purpose, we compare the indirect grounding view and other competing views mentioned above, the basic tenets of which are summarized in Table 1. By examining which of these views can predict the performance difference among distributional semantic models that mimic these views (and other baseline models), we attempt to test the validity of the indirect grounding view. The performance of distributional semantic models is evaluated in terms of the degree to which human conceptual representation can be predicted by the models, using Utsumi's (2020) experimental framework for analyzing and evaluating distributional semantic vectors. In the evaluation experiment, we focus on visual images as a source of perceptual (i.e., non-verbal) information, as used in many other studies on multimodal distributional semantics.</p>
<p>In the rest of this paper, after describing in detail a new multimodal semantic model for simulating indirect grounding in section 2, we explain the method of our evaluation experiment in section 3. We then report the results of the evaluation experiment in section 4 and discuss the implications and limitations of the findings in section 5.</p>
<h2>2. Distributional semantic model for indirect grounding</h2>
<p>We devise a new model to incorporate the indirect grounding view into multimodal distributional semantics. According to the indirect grounding view arguing that grounding of abstract concepts is mediated by language, different methods are used for computing visually grounded</p>
<p>TABLE 1 Summary of conceptual representation theories.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Theory</th>
<th style="text-align: center;">Basic tenets</th>
<th style="text-align: center;">Processing difference between abstract and concrete concepts</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Situated simulation view (e.g., Barsalou, 1999; Barsalou et al., 2018)</td>
<td style="text-align: center;">- Concepts are grounded in perceptual experiences via mental simulation. <br> - Language information is not necessary for understanding concepts.</td>
<td style="text-align: center;">No</td>
</tr>
<tr>
<td style="text-align: center;">Dual coding theory (Paivio, 1971, 1986)</td>
<td style="text-align: center;">- Concrete concepts are both linguistic and grounded in perceptual experiences. <br> - Abstract concepts are only linguistic.</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr>
<td style="text-align: center;">Hybrid view (e.g., <br> Barsalou et al., 2008; <br> Borghi et al., 2019)</td>
<td style="text-align: center;">- Concepts are both linguistic and grounded in perceptual experiences. <br> - The mechanism of grounding does not differ between concrete and abstract concepts; both concepts are grounded directly.</td>
<td style="text-align: center;">No</td>
</tr>
<tr>
<td style="text-align: center;">Indirect grounding view (e.g., Howell et al., 2005; Louwerse, 2011)</td>
<td style="text-align: center;">- Concepts are both linguistic and grounded in perceptual experiences. <br> - Abstract concepts are grounded indirectly via language, whereas concrete concepts are grounded directly.</td>
<td style="text-align: center;">Yes</td>
</tr>
</tbody>
</table>
<p>vectors depending on whether words are concrete or abstract. For a concrete word, its visually grounded vector is computed directly from the visual images tagged with that word, as shown in Figure 1A. For example, starting from the blind and not knowledgeable assumption that "love" is a concrete word, the visually grounded vector of "love" is computed directly from the images tagged with "love" using deep neural networks (DNNs). In this case, the visually grounded vector $\tilde{g}$ (love) is identical to the directly computed visual vector $\tilde{v}$ (love), as generally assumed by multimodal distributional semantic models that take no account of the difference between concrete and abstract concepts. By contrast, the visually grounded vector of an abstract word is computed from the visual images of concrete words semantically associated with the abstract word, that is, semantic neighbors of the abstract word, assuming that semantic neighbors are good mediator words. As shown in Figure 1B where the word "love" is supposed to be abstract,
its visually grounded vector $\tilde{g}$ (love) is not computed directly from the images of "love," but computed indirectly using the direct visual vectors, e.g., $\tilde{v}$ (kiss), $\tilde{v}$ (mother), $\tilde{v}$ (wedding), derived from the images tagged with semantic neighbors (e.g., "kiss," "mother," and "wedding"). This computation is regarded as an implementation of indirect grounding for abstract concepts.</p>
<p>Formally, we define a multimodal distributional semantic model for indirect grounding as follows. We assume that the vocabulary $V$ is divided into a set of concrete words $V_{C}$ and a set of abstract words $V_{A}$. Each word $w_{i} \in V$ has a textual vector $\tilde{l}\left(w_{i}\right) \in D S M_{T}$ trained from a text corpus and a direct visual vector $\tilde{v}\left(w_{i}\right) \in D S M_{V}$ computed directly from images for the word $w_{i}$. We build an indirect grounding model $D S M_{I}$ in which a word is represented by a pair $\left[\tilde{l}\left(w_{i}\right), \tilde{g}\left(w_{i}\right)\right]$ of a textual vector $\tilde{l}\left(w_{i}\right) \in D S M_{T}$ and visually grounded vector $\tilde{g}\left(w_{i}\right) \in D S M_{G}$. The visually grounded vector $\tilde{g}\left(w_{i}\right)$ is defined as follows:
$\tilde{g}\left(w_{i}\right)=\left{\begin{array}{ll}\tilde{v}\left(w_{i}\right) &amp; \text { (for a concrete word } w_{i} \in V_{C} \ \frac{\sum_{w_{j} \in S N_{k}\left(w_{i}\right)} \tilde{v}\left(w_{j}\right)}{k} &amp; \text { (for an abstract word } w_{i} \in V_{A}\end{array}\right)$
where $S N_{k}\left(w_{i}\right) \subset V_{C}$ is a set of $k$ semantic neighbors of $w_{i}$, that is, $k$ concrete words most semantically related to $w_{i}$. The visually grounded vector for an abstract word is thus obtained by averaging $k$ direct visual vectors of semantic neighbors.</p>
<p>Semantic neighbors of abstract words are determined using word similarity in the text-based distributional semantic model $D S M_{T}$. This implies that linguistic interdependency for indirect grounding is modeled by (text-based) distributional semantics. In the devised model, semantic neighbors $S N_{k}\left(w_{i}\right) \subset V_{C}$ of an abstract word $w_{i}$ are determined by first selecting $N(&gt;k)$ nearest neighbors of $w_{i}$ from the whole vocabulary $V$ and then selecting $k$ nearest concrete words from the set of $N$ neighbors. Nearest neighbors are computed using cosine similarity in the textual model $D S M_{T}$. The reason for limiting $N$ neighbors before selecting $k$ concrete words is that some highly abstract words (e.g., "truth," "wisdom") may not have semantically related concrete words, and in this case it is more appropriate not to consider a visual representation. Hence, when no semantic neighbors are selected [i.e., $S N_{k}\left(w_{i}\right)=\emptyset$ ], no visual vector is considered and only the textual vector is used for representing the abstract word $w_{i}$ in $D S M_{I}$.</p>
<h2>3. Materials and methods</h2>
<h3>3.1. Experimental design and predictions</h3>
<p>To evaluate the representational ability of a given distributional semantic model, we examined how accurately the model can predict human conceptual representation using Utsumi's (2020) experimental framework for analyzing and evaluating distributional semantic models. As human conceptual representation, we used a brain-based semantic</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>FIGURE 1
Two methods to compute the visual vector in the multimodal distributional semantic model for indirect grounding. (A) Direct grounding. (B) Indirect grounding.</p>
<p>representation provided by Binder et al. (2016), which is described in detail in section 3.2. In the evaluation experiment, a function from the bimodal (or unimodal) vector of a given word $w_{i}$ (section 3.3) to the target human conceptual representation $\tilde{y}\left(w_{i}\right)$ (section 3.2) was trained using the feedforward neural network shown in Figure 2. The conceptual representation of untrained words was predicted by the trained neural network. Prediction performance was evaluated by comparing the estimated conceptual representation with the target representation. The details of training and test procedure is described in section 3.4.</p>
<p>To test whether the indirect grounding view is more plausible than other views on abstract concepts listed in Table 1, we conducted the evaluation experiment described above using the following distributional semantic models, that is, four models that correspond to each of the four views in Table 1 and two additional baselines.</p>
<ul>
<li>Indirect grounding model $D S M_{I}=\left{\left[\tilde{t}\left(w_{i}\right), \tilde{g}\left(w_{i}\right)\right] \mid \tilde{t}\left(w_{i}\right) \in\right.$ $\left.D S M_{T}, \tilde{g}\left(w_{i}\right) \in D S M_{G}, w_{i} \in V\right}$ : A bimodal model for the indirect grounding view described in section 2.</li>
<li>Hybrid model $D S M_{H}=\left{\left[\tilde{t}\left(w_{i}\right), \tilde{v}\left(w_{i}\right)\right] \mid \tilde{t}\left(w_{i}\right) \in\right.$ $\left.D S M_{T}, \tilde{v}\left(w_{i}\right) \in D S M_{V}, w_{i} \in V\right}$ : A standard bimodal model in which all visual vectors are computed directly from images for a word $w_{i}$. This model is assumed to simulate the hybrid view.</li>
<li>Dual coding model $D S M_{D}=\left{\left[\tilde{t}\left(w_{i}\right), \tilde{v}\left(w_{i}\right)\right] \mid \tilde{t}\left(w_{i}\right) \in\right.$ $\left.D S M_{T}, \tilde{v}\left(w_{i}\right) \in D S M_{V}, w_{i} \in V_{C}\right} \cup\left{\tilde{t}\left(w_{i}\right) \mid \tilde{t}\left(w_{i}\right) \in\right.$ $\left.D S M_{T}, w_{i} \in V_{A}\right}$ : A partially bimodal model in which a pair of textual and direct visual vectors is used for representing a concrete word, whereas only a textual vector
<img alt="img-1.jpeg" src="img-1.jpeg" /></li>
</ul>
<p>FIGURE 2
The neural network used for predicting Binder et al.'s (2016) conceptual representation $\tilde{y}\left(w_{i}\right)$ of a word $w_{i}$ from textual and/or visual vectors in the evaluation experiment. The visual vector used as input is either $\tilde{g}\left(w_{i}\right)$ (for the indirect grounding and indirect visual models) or $\tilde{v}\left(w_{i}\right)$ (for the hybrid, dual-coding, and visual models).
is used for an abstract word. When abstract words are given in the training and test procedure, the visual layers in Figure 2 are not either trained or used. This model corresponds to the dual coding theory.</p>
<ul>
<li>Visual model $D S M_{V}=\left{\tilde{v}\left(w_{i}\right) \mid w_{i} \in V\right}$ : A unimodal model in which only direct visual vectors are used for</li>
</ul>
<p>TABLE 2 Predictions of evaluation performance by conceptual representation theories.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Best (highest performance) <br> model predicted by each theory</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Theory</td>
<td style="text-align: left;">Abstract <br> concepts</td>
<td style="text-align: left;">Concrete concepts</td>
</tr>
<tr>
<td style="text-align: left;">Situated simulation view <br> (e.g., Barsalou, 1999; <br> Barsalou et al., 2018)</td>
<td style="text-align: left;">Visual</td>
<td style="text-align: left;">Visual</td>
</tr>
<tr>
<td style="text-align: left;">Dual coding theory <br> (Paivio, 1971, 1986)</td>
<td style="text-align: left;">Dual coding, textual</td>
<td style="text-align: left;">Dual coding, hybrid, <br> indirect grounding</td>
</tr>
<tr>
<td style="text-align: left;">Hybrid view (e.g., <br> Barsalou et al., 2008;</td>
<td style="text-align: left;">Hybrid</td>
<td style="text-align: left;">Dual coding, hybrid, <br> indirect grounding</td>
</tr>
<tr>
<td style="text-align: left;">Borghi et al., 2019)</td>
<td style="text-align: left;">Indirect grounding</td>
<td style="text-align: left;">Dual coding, hybrid, <br> indirect grounding</td>
</tr>
<tr>
<td style="text-align: left;">Indirect grounding view <br> (e.g., Howell et al., 2005;</td>
<td style="text-align: left;">Indirect grounding</td>
<td style="text-align: left;">Dual coding, hybrid, <br> indirect grounding</td>
</tr>
</tbody>
</table>
<p>representing words. Hence the textual layers in Figure 2 are not used in the training and test procedure. This model corresponds to the situated simulation view.</p>
<ul>
<li>Textual model $\operatorname{DSM}<em i="i">{T}=\left{\tilde{f}\left(w</em> \in V\right}$ : A unimodal baseline model in which only textual vectors are used for representing words. Hence the visual layers in Figure 2 are not used in the training and test procedure.}\right) \mid w_{i</li>
<li>Indirect visual model $D S M_{G}=\left{\tilde{g}\left(w_{i}\right) \mid w_{i} \in V\right}$ : A unimodal baseline model in which only indirect visual vectors (defined in Equation 1) are used for representing words. The textual layers in Figure 2 are ignored in the training and test procedure.</li>
</ul>
<p>By comparing the prediction performance of the indirect grounding model with those of other models, we test the validity of indirect grounding as a plausible mechanism for embodied representation of abstract concepts. Different views of abstract concepts summarized in Table 1 make different predictions about the performance of the six models, as shown in Table 2. Basically, each of the four views predicts that its corresponding model would outperform other models. For abstract concepts, the dual coding theory predicts that the textual model also achieves the best performance because it argues that abstract concepts are represented only by linguistic information. For concrete concepts, the indirect grounding, hybrid, and dual coding views do not differ and thus make the same prediction that the indirect grounding, hybrid, and dual coding models do not significantly differ in performance and outperform the remaining models.</p>
<p>TABLE 3 Example of words included in Binder et al.'s (2016) dataset, which are selected mainly from abstract words.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">POS</th>
<th style="text-align: center;">Category</th>
<th style="text-align: center;">Word examples</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Noun</td>
<td style="text-align: center;">Abstract construct</td>
<td style="text-align: center;">analogy, irony, truth, verb, worth</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cognitive entity</td>
<td style="text-align: center;">belief, hope, knowledge, sympathy, wit</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Emotion</td>
<td style="text-align: center;">gratitude, joy, love, shame, woe</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Social event</td>
<td style="text-align: center;">advice, deceit, matinee, snub, tribute</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Time period</td>
<td style="text-align: center;">day, era, evening, semester, summer</td>
</tr>
<tr>
<td style="text-align: center;">Verb</td>
<td style="text-align: center;">Locative action</td>
<td style="text-align: center;">approach, deliver, go, leave, walk</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Social action</td>
<td style="text-align: center;">arrest, celebrate, help, play, write</td>
</tr>
<tr>
<td style="text-align: center;">Adjective</td>
<td style="text-align: center;">Visual property</td>
<td style="text-align: center;">black, dark, new, red, shiny</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Emotional property</td>
<td style="text-align: center;">angry, dangerous, happy, lonely, peaceful</td>
</tr>
</tbody>
</table>
<h3>3.2. Human conceptual representation</h3>
<p>As a target human conceptual representation $\tilde{y}\left(w_{i}\right)$, we used Binder et al.'s (2016) brain-inspired featural representation ${ }^{2}$. They provided 65 -dimensional real-valued vectors of 535 words, some of which are listed in Table 3. These words comprise 434 nouns, 62 verbs, and 39 adjectives and are classified into 47 categories that reflect grammatical classes and semantic classes. Note that, for the reason explained later in section 3.3.3. two nouns were excluded from the experimental materials and thus the remaining 533 words were used in the evaluation experiment.</p>
<p>The dimensions of the vectors correspond to neurobiologically plausible attributes whose neural correlates have been well described. Table 4 lists all 65 attributes in 14 domains used in Binder et al.'s (2016) vectors. Binder et al. (2016) selected these attributes according to two fundamental principles; they correspond to distinguishable neural processors that can be identified by an extensive body of evidence from brain imaging and neurological studies, and they can contribute to concept acquisition and composition. Each value of the conceptual vectors represents the degree of salience of the corresponding attribute for the target word. Binder et al. (2016) collected these values using Amazon Mechanical Turk. The participants of the experiment were given a single word and questions such as "To what degree do you think of this thing as a characteristic or defining color (for the attribute Color)" with some examples, and asked to rate the degree on a 7-point scale ranging from 0 to 6 . Collected ratings were averaged for each word and attribute after data screening, and these mean ratings were used in conceptual vectors.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>TABLE 4 Sixty-five attributes used in Binder et al.'s (2016) conceptual representation.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Domain</th>
<th style="text-align: center;">Attribute</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Vision</td>
<td style="text-align: center;">Vision, bright, dark, color, pattern, large, small, motion, <br> biomotion, fast, slow, shape, complexity, face, body</td>
</tr>
<tr>
<td style="text-align: center;">Somatic</td>
<td style="text-align: center;">Touch, temperature, texture, weight, pain</td>
</tr>
<tr>
<td style="text-align: center;">Audition</td>
<td style="text-align: center;">Audition, loud, low, high, sound, music, speech</td>
</tr>
<tr>
<td style="text-align: center;">Gustation</td>
<td style="text-align: center;">Taste</td>
</tr>
<tr>
<td style="text-align: center;">Olfaction</td>
<td style="text-align: center;">Smell</td>
</tr>
<tr>
<td style="text-align: center;">Motor</td>
<td style="text-align: center;">Head, upper-limb, lower-limb, practice</td>
</tr>
<tr>
<td style="text-align: center;">Spatial</td>
<td style="text-align: center;">Landmark, path, scene, near, toward, away, number</td>
</tr>
<tr>
<td style="text-align: center;">Temporal</td>
<td style="text-align: center;">Time, duration, long, short</td>
</tr>
<tr>
<td style="text-align: center;">Causal</td>
<td style="text-align: center;">Caused, consequential</td>
</tr>
<tr>
<td style="text-align: center;">Social</td>
<td style="text-align: center;">Social, human, communication, self</td>
</tr>
<tr>
<td style="text-align: center;">cognition</td>
<td style="text-align: center;">Cognition</td>
</tr>
<tr>
<td style="text-align: center;">Emotion</td>
<td style="text-align: center;">Benefit, harm, pleasant, unpleasant, happy, sad, angry, <br> disgusted, fearful, surprised</td>
</tr>
<tr>
<td style="text-align: center;">Drive</td>
<td style="text-align: center;">Drive, needs</td>
</tr>
<tr>
<td style="text-align: center;">Attention</td>
<td style="text-align: center;">Attention, arousal</td>
</tr>
</tbody>
</table>
<h3>3.3. Distributional semantic model</h3>
<h3>3.3.1. Textual vector</h3>
<p>Textual vectors $\tilde{\tilde{t}}\left(w_{i}\right) \in D S M_{T}$ were trained on the Corpus of Contemporary American English (COCA), which included 0.56 G word tokens. Words that occurred less than 30 times in the corpus were ignored, resulting in the training vocabulary of 108,230 words. As a distributional semantic model for training textual vectors, we used skip-gram with negative sampling (SGNS), which is one of two algorithms in word2vec model (Mikolov et al., 2013). In SGNS, a feed-forward neural network with one hidden layer of $d$ units is trained to predict cooccurring words of an input word (i.e., $w$ words appeared on either side of the input word in the corpus), and $d$-dimensional activation vectors in the hidden layer of the trained network are used as textual vectors. We set the vector dimension $d=300$ and the window size $w=10$. The choice of corpus, distributional semantic model, and parameter values was determined considering the result of the similar experiment (Utsumi, 2020).</p>
<h3>3.3.2. Visual vector</h3>
<p>To compute direct visual vectors $\tilde{v}\left(w_{i}\right) \in D S M_{V}$, we collected 20 images using Flickr image retrieval for each of the words in the vocabulary. The image retrieval was performed using the API flickr. photos. search with the argument sort=relevance and the top 20 most relevant images were downloaded for each word. Note that these relevant images
are often tagged with other words, but we did not use the information of these tags.</p>
<p>To compute the feature vector of each downloaded image, we utilized the ResNet152-hybrid1365 model (Zhou et al., 2018) ${ }^{3}$. This model is the Residual Network (ResNet), which is a recent high-performance version of the deep convolutional neural networks, trained on both ImageNet1000 dataset for object recognition and Places365-standard dataset for scene recognition. Each image was entered into this model and a 2,048dimensional activation vector was extracted from the last hidden layer. The activations in the last hidden layer are deemed to be appropriate for a visual vector in distributional semantics, because they are generally assumed to represent visually intrinsic features of a concept. Finally, the visual vector $\tilde{v}\left(w_{i}\right)$ was computed as the centroid (i.e., average) of the activation vectors of 20 images.</p>
<h3>3.3.3. Indirect visual vector</h3>
<p>To compute indirect visual vectors $\tilde{g}\left(w_{i}\right) \in D S M_{G}$, we must determine how to split the whole vocabulary $V$ into concrete words $V_{C}$ and abstract words $V_{A}$. For this purpose, we used Brysbaert et al.'s (2014) concreteness ratings for 39,354 English words including 37,058 single words and 2,896 twoword expressions. These words were rated on a 5-point scale ranging from 1 (abstract) to 5 (concrete) and the collected ratings were averaged per each word. In the instructions given to raters, Brysbaert et al. (2014) stressed that the assessment of word concreteness would be based on perceptual experiences involving all senses and motor responses. Specifically, the following instruction was used:</p>
<p>Some words refer to things or actions in reality, which you can experience directly through one of the five senses. We call these words concrete words. Other words refer to meanings that cannot be experienced directly but which we know because the meanings can be defined by other words. These are abstract words. (Brysbaert et al., 2014, p. 906)</p>
<p>This definition of concrete words as experience-based and abstract words as language-based is consistent with our view of abstract concepts, and thus the use of their concreteness ratings is appropriate for the indirect grounding model ${ }^{4}$.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>For the vocabulary $V$ in the indirect grounding model, we chose 28,437 words from Brysbaert et al.'s (2014) word concreteness dataset that were also included in the training vocabulary of COCA corpus and associated with at least 20 images. As a result, two words "ire" and "oration" in Binder et al.'s (2016) dataset were not included in the chosen vocabulary because they are not contained in Brysbaert et al.'s (2014) dataset. Hence, these two words were not used in the entire experiment.</p>
<p>Each word in the vocabulary $V$ was judged as abstract if its concreteness rating was less than a given threshold $\theta_{c}$, and otherwise as concrete. We performed the same experiment with different thresholds ranging from $1.2^{5}$ to 5.0 with a step size of 0.1. In section 4, we report the overall result with a representative threshold $\theta_{c}=3.0$ at which any words whose concreteness rating is toward the language-based side of the continuum are classified as abstract. Additionally, we use the threshold $\theta_{c}=4.0$, at which words are treated as abstract unless they are rated as highly experience-based. Note that 116 and 214 out of 533 words in Binder et al.'s (2016) dataset (14,305 and 21,471 out of 28,437 words in the whole vocabulary $V$ ), respectively, were judged as abstract when $\theta_{c}=3.0$ and $\theta_{c}=4.0$.</p>
<p>After concrete words $V_{C}$ and abstract words $V_{A}$ are determined, indirect visual vectors $\tilde{g}\left(w_{i}\right)$ are computed according to Equation (1). When a word $w_{i}$ is concrete (i.e., $w_{i} \in V_{C}$ ), its direct visual vector $\tilde{v}\left(w_{i}\right)$ defined in section 3.3.2 is used as a visual vector $\tilde{g}\left(w_{i}\right)$. When a word $w_{i}$ is abstract (i.e., $w_{i} \in V_{A}$ ), its semantic neighbors are determined using the textual vectors in section 3.3.1 as follows. First, $N(&gt;k)$ nearest neighbors of $w_{i}$ are selected from the whole vocabulary $V$ by computing cosine similarity between $t\left(w_{i}\right)$ and $t\left(w_{j}\right)$ for all words $w_{j} \in V(j \neq i)$ and selecting words with top $N$ highest cosine. Then, $k$ nearest (i.e., highest cosine) concrete words are selected from the set of $N$ neighbors. Finally, the direct visual vectors $\tilde{v}\left(w_{j}\right)$ of $k$ nearest neighbors are averaged and the resulting vector is used as $\tilde{g}\left(w_{i}\right)$ for the abstract word $w_{i}$.</p>
<h3>3.4. Training and prediction</h3>
<p>To train the mapping (i.e., prediction function) from bimodal (or unimodal) word vectors to Binder et al.'s (2016) conceptual representation, we used a feed-forward neural network shown in Figure 2. The activation function and the number of units are shown in each of the layers denoted by solid rectangles. The training was performed by minimizing the mean squared error (MSE), and gradient descent with Adam was used as an optimization method. The learning rate for Adam was</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>fixed at 0.001 . The weights (and biases) were initialized by the normalized initialization heuristic (Glorot and Bengio, 2010).</p>
<p>As an overall framework for evaluation (i.e., the procedure for training and prediction), we used a "leave-one-cluster-out" cross-validation procedure (Utsumi, 2020). This procedure is a variant of $n$-fold cross-validation in which semantic clusters for all words are used instead of randomly and equally partitioned groups. The reason for using leave-one-cluster-out cross-validation instead of $n$-fold cross-validation (and other methods with random sampling) is that words in Binder et al.'s (2016) dataset are not equally distributed in the semantic space. Some groups of words are semantically rich and they are very close to one another, whereas some other groups of words have only a small number of semantically less similar words. If we apply $n$-fold cross-validation to this dataset, semantically rich words with many close neighbors are likely to be better predicted independent of the representation ability of distributional semantic models, because their neighbors have more chance of being included in the training set.</p>
<p>To obtain word clusters for this procedure, we used Utsumi's (2020) method in which all 533 words were classified into 20 clusters using the k-means algorithm. Given textual vectors, we repeated k-means clustering 100 times and selected the best clustering result according to the Dunn index, which is a metric for evaluating clustering quality. Furthermore, to ensure the generality of the experimental results, we repeated this clustering procedure 10 times, and as a result, 10 different sets of 20 clusters were generated.</p>
<p>In the leave-one-cluster-out cross-validation procedure, for each cluster, the neural network in Figure 2 (i.e., prediction function) is trained using all words in the other clusters, and the conceptual vectors of words in the target cluster were predicted using the trained neural network. By repeating this procedure using each word cluster as a target, we obtained estimated conceptual vectors $\hat{\tilde{y}}\left(w_{i}\right)$ for all 533 words. Prediction performance was measured by Pearson's correlation between the estimated vector $\hat{\tilde{y}}\left(w_{i}\right)$ and the original vector $\tilde{y}\left(w_{i}\right)$. Spearman's rank correlation $\rho$ and MSE were also used as secondary measures. For each set of 20 clusters, this experimental run was carried out three times under the same condition (i.e., hyperparameters), and the result of the run with the highest mean correlation across all words was retained. Finally, the results obtained using 10 sets of clusters were averaged and used for the analysis reported in section 4.</p>
<p>Hyperparameters other than the concreteness threshold were determined using a grid search. First, we determined the number of epochs for training from hybrid, dual coding, visual, and textual models. Using the leave-one-cluster-out crossvalidation, we computed MSE across all words with the number of epochs ranging from 1 to 50 . The lowest MSE was obtained at 19 epochs for the hybrid model, 17 epochs for the dual coding and textual models, and 10 epochs for the visual model. For the indirect grounding model, two parameters $N$ and $k$ for</p>
<p>computing semantic neighbors were optimized together with the number of epochs using grid search of $N=100,200,300$ and $k=1, \cdots, 10$. In this grid search, we used the concreteness threshold $\theta_{c}=4.0$. Mean squared error was computed over all words and the lowest MSE was obtained at $N=300, k=10$, and 20 epochs. For the indirect visual model, we determined the number of epochs using indirect visual vectors at $N=300$ and $k=10$, and as a result, 16 epochs achieved the lowest MSE. These hyperparameters were used in all experimental runs for evaluation.</p>
<h2>4. Results</h2>
<h3>4.1. Performance difference among models</h3>
<p>Table 5 lists mean correlations between the original conceptual vector and the vectors estimated by the indirect grounding model and other models. Figure 3 shows the variation in correlation coefficients over abstract, concrete, and all words. Note that in this section we report the results of Pearson's correlation when used as performance measure, but we also analyzed the performance with two additional measures (i.e., Spearman's rank correlation and MSE). Because these results do not significantly differ from those of Pearson's correlation, the detailed results of the additional analysis are provided in Appendix S1 of the Supplementary material.</p>
<p>For abstract words, the indirect grounding model $D S M_{I}$ achieved the highest mean correlation in both concreteness thresholds. The Friedman test conducted on abstract words revealed a significant difference between word correlations of six models, $\chi^{2}(5, N=116)=280.20, p&lt;0.001$ for $\theta_{c}=$ 3.0 and $\chi^{2}(5, N=214)=583.23, p&lt;0.001$ for $\theta_{c}=$ 4.0. Multiple pairwise comparisons using the Wilcoxon signedrank test with Ryan's procedure ( $p&lt;0.05$ ) showed that the correlation of the indirect grounding model was significantly higher than those of all other models at $\theta_{c}=3.0$ and than those of other four models except the dual coding model at $\theta_{c}=4.0$. For other pairwise differences, only the difference between the dual coding and hybrid models was not significant for either thresholds. This result is consistent with the prediction of the indirect grounding view in Table 2. Additionally, the result that the indirect visual model $D S M_{I I}$ predicted the conceptual representation better than the simple visual model $D S M_{V}$ also indicates the effectiveness of computing visual vectors using semantic neighbors. These results clearly support the indirect grounding view of abstract concepts.</p>
<p>Although it is not the main concern of this paper whose focus lies in abstract concepts, the Friedman test conducted on correlations of concrete words also indicated a significant difference among six models, $\chi^{2}(5, N=417)=1181.66$, $p&lt;0.001$ for $\theta_{c}=3.0$ and $\chi^{2}(5, N=319)=895.97, p&lt;0.001$
for $\theta_{c}=4.0$. The highest mean correlation was achieved by the hybrid model for both concreteness thresholds, but multiple pairwise comparison revealed that pairwise differences among the hybrid, indirect grounding, and textual models were not significant. For $\theta_{c}=4.0$, the difference between the dual coding and textual models and between the dual coding and indirect grounding models also did not reach the significance level. All the other pairwise differences were significant. The absence of significant difference among the indirect grounding, hybrid, and dual coding models is a predictable result, as shown in Table 2. What is somewhat surprising is that bimodal models for abstract concepts (i.e., the indirect grounding and hybrid models) did not achieve significantly higher performance than the textual (i.e., unimodal) model, given that a number of studies on multimodal distributional semantics have shown the superiority over text-based unimodal models for concrete words (e.g., Bruni et al., 2014; Baroni, 2016). This result is not consistent with the prediction of Table 2 made by the indirect grounding, hybrid, and dual coding views.</p>
<p>One possible reason would be that the textual layer may cover most of the information needed to predict the target conceptual representation of concrete words; the textual layer compresses 300-dimensional input textual vectors to $50 \%$ ( $=$ $150 / 300$ ) of their original dimension, but the visual layer compresses 2,048-dimensional input visual vectors to a much lower percent, $7.3 \%(=150 / 2,048)$. To test this possibility, we conducted an additional experiment with the same experimental procedure by decreasing the dimension $d_{T}$ of the textual (hidden) layer. The detailed result of this additional experiment is provided in Appendix S2 of the Supplementary material. The result is supportive of this possibility; when the dimension $d_{T}$ was 30 (whose compression rate $10.0 \%$ is nearly equal to that of the visual layer) or lower, the bimodal models (i.e., indirect grounding and hybrid models) achieved significantly higher correlations than the unimodal textual model. Note also that decreasing the dimension $d_{T}$ of the textual layer did not affect the result of abstract words; the same result of performance differences were obtained regardless of $d_{T}$. From these results, it follows that the visual layer actually contributes to model performance in an expected way and our bimodal distributional semantic model achieves a result fully consistent with the prediction of the indirect grounding view when the impact of the textual and visual layers is equalized.</p>
<p>In addition, the difference among six models was also significant for all words, $\chi^{2}(5, N=533)=1438.50, p&lt;0.001$ for $\theta_{c}=3.0$ and $\chi^{2}(5, N=533)=1444.01, p&lt;0.001$ for $\theta_{c}=4.0$. The difference between the indirect grounding and hybrid models at $\theta_{c}=3.0$ and the differences among the indirect grounding, hybrid, and dual coding models at $\theta_{c}=4.0$ were not significant, but all the other pairwise comparisons were significant.</p>
<p>Summarizing, the obtained results are most consistent with the predictions of the indirect grounding view shown in</p>
<p>TABLE 5 Mean correlations for the indirect grounding model and other models.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>$\theta_{c}=3.0$</th>
<th></th>
<th></th>
<th>$\theta_{c}=4.0$</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Abstract</td>
<td>Concrete</td>
<td>All</td>
<td>Abstract</td>
<td>Concrete</td>
<td>All</td>
</tr>
<tr>
<td>Bimodal</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Indirect grounding $\left(D S M_{I}\right)$</td>
<td>0.772</td>
<td>0.742</td>
<td>0.749</td>
<td>0.731</td>
<td>0.761</td>
<td>0.749</td>
</tr>
<tr>
<td>Hybrid $\left(D S M_{H}\right)$</td>
<td>0.764</td>
<td>0.744</td>
<td>0.748</td>
<td>0.724</td>
<td>0.764</td>
<td>0.748</td>
</tr>
<tr>
<td>Dual coding $\left(D S M_{D}\right)$</td>
<td>0.762</td>
<td>0.734</td>
<td>0.740</td>
<td>0.729</td>
<td>0.756</td>
<td>0.745</td>
</tr>
<tr>
<td>Unimodal</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Visual $\left(D S M_{V}\right)$</td>
<td>0.536</td>
<td>0.475</td>
<td>0.488</td>
<td>0.480</td>
<td>0.494</td>
<td>0.488</td>
</tr>
<tr>
<td>Textual $\left(D S M_{T}\right)$</td>
<td>0.755</td>
<td>0.740</td>
<td>0.744</td>
<td>0.716</td>
<td>0.762</td>
<td>0.744</td>
</tr>
<tr>
<td>Indirect visual $\left(D S M_{G}\right)$</td>
<td>0.626</td>
<td>0.490</td>
<td>0.520</td>
<td>0.529</td>
<td>0.513</td>
<td>0.519</td>
</tr>
</tbody>
</table>
<p>Boldfaced numbers indicate the highest correlations (i.e., the best performance) among the models.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>FIGURE 3 Boxplots of word correlations for the indirect grounding model and other models.</p>
<p>Table 2. It is therefore concluded that the indirect grounding view is plausible as a conceptual representation theory of abstract concepts.</p>
<h3>4.2. Effect of the concreteness threshold</h3>
<p>To test whether the superiority of the indirect grounding model for abstract concepts reported in the last section holds for other concreteness thresholds, we conducted the same experiment at different thresholds $\theta_{c}$ ranging from 1.5 to 5.0 with a step size of 0.1 . Figure 4 shows mean correlations over abstract words for the indirect grounding, hybrid, and dual coding models. Color bars shown below the graph denote whether pairwise differences were statistically significant by multiple pairwise comparison $(p&lt;0.05)$.</p>
<p>The indirect grounding model yielded a higher correlation than other two models when the concreteness threshold was</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>FIGURE 4
Mean correlations over abstract words for the indirect grounding, hybrid, and dual coding models as a function of the concreteness threshold $\theta_{c}$. Pairwise differences significant at $p&lt;0.05$ are indicated by color bars below the graph.
between 1.5 and 4.5, although at some lower threshold the correlation of the indirect grounding model was slightly lower than that of the dual coding model. Specifically, the correlation of the indirect grounding model was significantly higher than that of the hybrid model between $\theta_{c}=2.3$ and 4.4 , and than that of the dual coding model between $\theta_{c}=2.8$ and 3.9. This confirms the finding reported in section 4.1 and indicates that the superiority of the indirect grounding model was not accidentally observed in some concreteness thresholds. At $\theta_{c}=$ 4.6 or higher, the mean correlation of the indirect grounding model was lower than the hybrid model. In these cases, highly concrete words were selected as abstract and their visual vectors were computed via semantic neighbors, even though it is appropriate that they are grounded directly through their own visual images. This "less plausible" grounding may generate a harmful effect on the prediction performance of the indirect grounding model. This behavior of the model is also consistent with the indirect grounding view.</p>
<h3>4.3. Relation between word concreteness and improvement by indirect grounding</h3>
<p>In this section, we examine whether the performance improvement of the indirect grounding model compared to the hybrid and dual coding models depends on word concreteness. To quantify the degree of improvement, we considered the difference of correlation computed by subtracting the correlation coefficient of a baseline model from the correlation coefficient of the indirect grounding model.</p>
<p>We computed a correlation between the difference of correlation and word concreteness. The difference of correlation was not correlated with word concreteness when the hybrid model is a baseline, $r=-0.104\left(\theta_{c}=3.0\right)$ and $r=0.075$ $\left(\theta_{c}=4.0\right)$. In the case of the dual coding model used as a baseline, the difference of correlation was not correlated with
word concreteness for $\theta_{c}=4.0, r=0.071$, but they were weakly correlated for the threshold $\theta_{c}=3.0, r=0.222$ ( $p&lt;0.05$ ). These results indicate that there was generally no monotonic relationship between the degree of improvement and word concreteness, but appending indirect visual vectors to textual vectors may be somewhat more effective for less abstract concepts.</p>
<p>To examine more closely the relation between performance improvement and word concreteness, we also computed the mean difference of correlation per each of the intervals into which the entire range of concreteness values was equally divided, whose results are shown in Figure 5. Overall, the indirect grounding model improved the prediction performance regardless of word concreteness, but two concreteness thresholds showed different patterns of improvement. For $\theta_{c}=3.0$, the indirect grounding model improved the performance for highly abstract words (i.e., words with concreteness rating is less than 1.75) against both competing models. This result suggests that the indirect grounding model is effective in representing purely abstract words. Furthermore, only when comparing with the dual coding model, the degree of improvement was higher for less abstract words (i.e., the ones within the range of $2.50 \leq$ concreteness rating $&lt;3.00$ ) than for more abstract words. This may suggest that these words, which may be difficult to judge concreteness or have both concrete and abstract senses, benefit from adding visual information whether directly or indirectly.</p>
<p>For $\theta_{c}=4.0$, however, the performance of highly abstract words (whose concreteness rating was less than 2.0) were not improved and the difference of correlation peaked at higher concreteness range [3.50, 3.75]. These different results for highly abstract words between both concreteness thresholds can be attributed primarily to the difference of semantic neighbors, because $\theta_{c}$ determines a word pool (i.e., a set of concrete words) from which semantic neighbors are chosen. Hence the effectiveness of indirect grounding depends on not only the concreteness of a word to be grounded, but also the choice of semantic neighbors for that word.</p>
<h3>4.4. Word-level analysis on the impact of indirect grounding</h3>
<p>Abstract (and concrete) concepts have been considered as a unitary whole, but recent research has argued that abstract concepts should be treated as a heterogeneous category including various different types of abstract concepts (Ghio et al., 2016; Troche et al., 2017; Borghi et al., 2018; Villani et al., 2019). Therefore, to examine the types of abstract concepts for which indirect grounding, in particular, visually indirect grounding, is effective, we analyzed the degree of improvement in terms of semantic categories of abstract words.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>FIGURE 5
Mean difference of correlation $\operatorname{diff}(r)$ between the indirect grounding model and two competing models per each of the equally divided intervals of concreteness. The heatmap depicts the mean correlation of hybrid, dual coding, and indirect grounding models. Numbers in parentheses denote the number of words $n$ within an interval. Red and blue graphs, respectively, denote the degree of improvement against the hybrid model and the dual coding model. (A) $\theta_{c}=3.0$. (B) $\theta_{c}=4.0$.</p>
<p>Figure 6 shows how the degree of improvement is related to semantic categories for abstract words with concreteness rating less than 4.0 (i.e., $\theta_{c}=4.0$ ). We used semantic categories provided by Binder et al. (2016) to classify abstract words. They classified all 535 words into 47 categories that reflect semantic and grammatical classes. Among them, we selected 17 categories for analysis that included four or more abstract words. In addition, these 17 categories were grouped according to the following four clusters revealed by Villani et al. (2019): physical, spatio-temporal, and quantitative (Physical and Spatio-temporal) concepts, self and sociality (Social) concepts, philosophical/spiritual (Philosophical and Mental) concepts, and emotional/inner states (Emotional) concepts.</p>
<p>As shown in Figure 6, Social and Physical and Spatiotemporal clusters are likely to show higher improvement than Philosophical and Mental and Emotional clusters. In particular, body action, locative action, sound, and time period categories in Physical and Spatio-temporal cluster achieved relatively higher improvement by the indirect grounding model. The high improvement of physical and spatio-temporal concepts is consistent with the indirect grounding view, because these abstract concepts are likely to be associated (via language) with specific visual images. For example, the concept evening easily evokes visual experiences associated with the concepts of dinner and sunset. In the experiment of this paper, "night," "dinner," "supper," "dusk," "dawn," "sundown," "twilight," "candlelight," "sunset," and "sunrise" were selected as semantic neighbors of the word "evening," and the indirect visual vectors computed from these images improved the baselines as shown in Figure 7. The relatively high improvement of social categories can be explained along the same line. A number of social concepts are associated with perceptually grounded concepts. For example, the verb play can be captured by relevant concepts such as game, soccer and football (objects to be played) and sandlot (place to play), which were selected as semantic neighbors. Meanwhile, some other social concepts (e.g., business and joke) are more complex and difficult to capture by grounded concrete concepts.</p>
<p>By contrast, emotional categories were not improved by the indirect grounding model. Emotional information is highly likely to be encoded in textual vectors (e.g., Recchia and Louwerse, 2015; Utsumi, 2020), and thus indirect grounding may not be necessary for emotional concepts. A more plausible explanation would be that emotional concepts are directly grounded in emotional experiences, and thus relatively less dependent on indirect grounding in perceptual (i.e., visual) experiences. The lesser degree of improvement for the cluster of Philosophical and Mental is not surprising. These abstract concepts are generally thought of as "highly disembodied" concepts (Dove, 2016), which are divorced from experiential (at</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>FIGURE 6
Mean difference of correlation $d g f(r)$ between the indirect grounding model and two baseline models averaged per semantic category for abstract words $(6 c=4.0)$. The heatmap depicts the mean correlation of hybrid, textual, and indirect grounding models. Numbers in parentheses denote the number of abstract words contained in semantic categories. Red and blue graphs, respectively, denote the degree of improvement against the hybrid model and the textual model.
least visual) grounding regardless of whether the grounding is direct or indirect.</p>
<p>Figure 7 shows the change of correlation coefficient in terms of concreteness threshold for some abstract words. The result of all abstract words with concreteness rating less than 4.0 is provided in Appendix S3 of the Supplementary material. The important point to note is the difference of correlation between non-shaded and shaded areas. Correlation plotted in the red shaded area (i.e., the region right of the dashed vertical line) shows the prediction performance of the indirect grounding model when a word is regarded as abstract and thus indirect visual vectors are used, whereas correlation in the non-shaded area shows the performance when that word is regarded as concrete and direct visual vectors are used. Hence, the indirect grounding model is found to be effective for words whose correlations in the shaded area are higher than those in the non-shaded area. A typical pattern in this effective case is that correlations in the shaded area are higher than those in the non-shaded area as well as higher than those of textual and hybrid models (e.g., "evening," "leave," "play"). This pattern is
also marked by the decrease of correlation at higher thresholds (i.e., $\theta_{c} \geq 4.5$ ), because good mediator words for an abstract word are erroneously judged as abstract and thus no longer selected as semantic neighbors at higher thresholds. By contrast, some words (e.g., "angry," "business," "truth") show a different pattern that correlation does not largely differ between the shaded and non-shaded area, which indicates no performance improvement by the indirect grounding model. For some other words (e.g., "fix"), correlation decreases in the shaded area; this pattern indicates that the indirect grounding model is harmful to predicting conceptual representation.</p>
<h2>5. Discussion</h2>
<h3>5.1. Contribution to the research on abstract concepts</h3>
<p>The present study makes an original contribution to research on abstract concepts. As mentioned in section I, very</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>FIGURE 7 Correlation coefficient of the indirect grounding model DSM $<em C="C">{3}$ for some individual abstract concepts as a function of concreteness threshold $\theta</em>$. The dashed vertical line denotes the word concreteness, and thus the line chart in the red shaded area represents the correlation obtained using indirect visual vectors.
few empirical studies have demonstrated direct evidence in favor of the indirect grounding view, although a number of studies have empirically shown that both symbolic/linguistic and perceptual/embodied representations are required for shaping and processing abstract concepts. Given the current lack of direct evidence, the present study provides empirical support specific to the role of language posited by the indirect grounding view. The higher prediction performance of the indirect grounding model compared to the hybrid (i.e., direct grounding) model suggests that a mere combination of symbolic and perceptual representation (e.g., Barsalou et al., 2008) is less adequate for explaining abstract concepts (or at least those that
can be grounded in visual experiences); abstract concepts are more likely to be indirectly grounded through their linguistic relations to the concepts directly grounded in the world. In other words, language functions as a bridge between abstract concepts and perceptual experiences.}$. The plot at $\theta_{C}=1.0$ denotes the correlation of the hybrid (i.e., direct grounding) model $D S M_{3 x}$ (because $D S M_{1}$ with $\theta_{C}=1.0$ is identical to $D S M_{3 x}$ ). The blue horizontal line is drawn at the correlation coefficient of the textual model $D S M_{7</p>
<p>The plausibility of indirect grounding is also supported by the result of comparing two visual models. Even when textual vectors were not used for prediction, the indirect visual model outperformed the simple visual model, as reported in section 4.1. This implies that the use of visual vectors derived from concrete words strongly associated with an abstract word stands on its own merit.</p>
<p>Furthermore, the superiority of the indirect grounding model over two unimodal models (i.e., textual and visual models) and the dual coding model suggests that abstract concepts are both linguistic and grounded in perceptual experience. This result is consistent with the recent empirical findings (Louwerse and Jeuniaux, 2010; Malhi and Buchanan, 2018) and thus lends further support to the hybrid views of abstract concepts (Louwerse, 2011; Dove, 2016; Borghi et al., 2019).</p>
<h3>5.2. Related work on computational approaches to indirect grounding</h3>
<p>Some existing studies have proposed a computational model for semantic processing that is based on similar views to indirect grounding. Howell et al. (2005) attempted to simulate the mechanism of propagation of grounding (mentioned in section 1.3) using a simple recurrent network. The network was trained to predict, from the current input word, both what the next word would be and the featural (i.e., sensorimotor) representation of the current word. They demonstrated that the network trained with featural representation achieved better performance in next word prediction than the network trained without featural representation, and argued that this result supports the propagation of grounding. However, their model does not directly simulate the process in which the sensorimotor features of concrete concepts are propagated to abstract concepts. Hoffman et al. (2018) proposed a more sophisticated neural network model that assimilates a very similar idea to indirect grounding; "Knowledge of abstract words is acquired through (a) their patterns of co-occurrence with other words and (b) acquired embodiment, whereby they become indirectly associated with the perceptual features of cooccurring concrete words (Hoffman et al., 2018, p. 293)." Their model is based on a hub-and-spoke architecture in which the information of an input word, its sensorimotor properties and past states (as context) is integrated into a hidden "hub" layer. They trained the model to predict the next word in a word sequence and showed that the trained model could represent the semantic knowledge of concrete and abstract words in a hub layer and accounted for behavioral patterns consistent with normal and impaired semantic cognition. However, they did not quantitatively test whether indirect grounding is more plausible than other competing views, such as one that abstract concepts are also grounded directly in sensorimotor experience.</p>
<p>These previous studies differ from the present study in some important respects. First of all, they use, as perceptual or sensorimotor representation, only verbally expressed featural information, which is essentially symbolic and discrete. Second, they do not directly test the plausibility of indirect grounding for representing abstract concepts; their proposed models are
not compared with other competing models to be considered. Furthermore, their studies are limited in their coverage of the vocabulary of words and features; only a relatively small set of words and features are used in the experiments. The training corpus is also small in size and generated artificially. By contrast, the present study directly uses non-verbal (i.e., visual) information as perceptual representation and quantitatively tests the indirect grounding view by comparing other competing models including the direct grounding model. The vocabulary and corpus used in the experiment of the present study are relatively large.</p>
<p>To the best of our knowledge, no prior studies on multimodal distributional semantics or other computational models using non-verbal information have tested indirect grounding of abstract concepts (or words), but a noteworthy observation was reported. Lazaridou et al. (2015) proposed a multimodal skip-gram model by extending the objective function of the original skip-gram (Mikolov et al., 2013) so as to take into account visual similarity computed using visual vectors. Using the trained multimodal word vectors, they showed that some abstract words had nearest neighbors in the trained multimodal space whose visual images depict relevant concrete situations (e.g., the nearest neighbor picture of the word "theory" depicts a bookshelf with many books), although the nearest neighbors of many other abstract words were not visually relevant. The extended skip-gram model does not directly simulate the process of indirect grounding, but this result suggests that the multimodal skip-gram may be a useful model for exploring the grounding mechanism of abstract concepts.</p>
<h3>5.3. Limitation of this study and future direction</h3>
<p>Our distributional semantics-based approach to embodied cognition of abstract concepts has its limitations. One important limitation is that the method for modeling perceptual experiences used in this paper does not deal with perceptual information other than visual one. Although people are supposed to acquire a large percentage of information from visual perception, conceptual knowledge is also grounded in other types of perceptual experiences, such as auditory, somatosensory, gustatory, and olfactory ones, as well as from emotional and social experiences (e.g., Borghi et al., 2017). Our finding in favor of indirect grounding is thus confined to visual grounding; the detailed analysis based on semantic categories reported in section 4.4 revealed that abstract concepts in only some categories (i.e., Social and Physical and Spatiotemporal categories) benefit from visually indirect grounding. Future research is required to investigate whether and how other types of abstract concepts are grounded directly or indirectly.</p>
<p>A more noteworthy limitation is that the DNN by which visual vectors are computed may diverge from human visual perception. The progress of deep learning technique has demonstrated that DNNs surpass human-level performance on some specific image classification tasks (Zhang et al., 2021) and it has been shown that their internal representations match coarsely with the brain (Cichy et al., 2016; Serre, 2019). By contrast, recent studies have also revealed that DNNs show behavioral deviations from human visual perception, for example, in terms of the sensitivity to global shape (Baker et al., 2018) and the visual representational structure in the human brain (Xu and Vaziri-Pashkam, 2021). Jacob et al. (2021) demonstrated that some phenomena (e.g., surface invariance, sensitivity to 3D shape) seen in human visual perception were not observed in ResNet-152, which is used for extracting visual vectors in this study, as well as in other DNNs. These deviations suggest that DNNs and its visual vectors are limited as a cognitive model of visual grounding. Given these potential limitations, we must be cautious about interpreting the obtained results, in particular the lower performance of the visual model $D S M_{V}$ as evidence against the situated simulation view.</p>
<p>Our choice of text-based distributional semantic model (i.e., SGNS) by which textual vectors are computed is unlikely to greatly affect the obtained results, given the current technical possibilities. Utsumi (2020) compared three distributional semantic models, that is, SGNS, GloVe (Pennington et al., 2014), and PPMI+SVD (Bullinaria and Levy, 2007), in terms of performance in predicting Binder et al.'s (2016) conceptual representation only from textual vectors. He demonstrated that SGNS achieved the highest prediction performance, and more importantly, the relative performance differences among words and attributes were quite similar among three models. Chersoni et al. (2021) extended this result by comparing a wider variety of textual models using the same prediction task. These models include BERT (Devlin et al., 2018), which is a deep neural model for contextual embeddings that achieves state-of-the-art performance in many NLP tasks. They reported that BERT did not show any significant differences from the distributional semantic models analyzed by Utsumi (2020), and word and attribute correlation of BERT is equivalent to that of SGNS. These results imply that the obtained findings in this paper have certain generality with respect to textual models. Obviously, however, it does not mean that current language models sufficiently capture semantic (or conceptual) knowledge people can acquire from language (for a review, see Rogers et al., 2020; Lake and Murphy, 2021). If a psychologically more plausible language model is developed in the future, it would be interesting to explore whether the indirect grounding model still yields the same result.</p>
<p>The present study also suffers from methodological limitations. Binder et al.'s (2016) dataset used as a target conceptual representation for the evaluation experiment is the most comprehensive and fine-grained featural representation publicly available at present, but yet not sufficient to capture
the richness of human conceptual knowledge. For example, concepts (particularly abstract concepts) generally involve the knowledge of binary and multiary relations among concepts and higher-order relations that cannot be expressed by feature-based representation. Hence the obtained result does not reflect the representational ability of relational knowledge. Furthermore, the training procedure for predicting Binder et al.'s (2016) representation poses an additional concern about whether it can precisely capture processing differences among competing models. This concern is particularly salient for the dual coding model. According to its definition in section 3.1, the dual coding model should approximate the performance of the textual model for abstract words and that of the hybrid model for concrete words. However, the result of section 3.1 (Appendix S2) diverged from these expectations; the dual coding model outperformed the textual model in predicting abstract words and showed lower performance for concrete words than the hybrid model. This discrepancy between expectations and performance may be caused by simultaneous training of concrete and abstract words. Specifically, network parameters (i.e., weights and biases) between the output layer (i.e., the bottom layer of Figure 2) and the hidden layer just above reflect the visual information of concrete words, even when visual vectors are not given. Because of this, prediction of an abstract word may indirectly reflect visual information of concrete concepts whose textual vectors are similar to that of the abstract word, and thus the dual coding model would perform better than the textual model. For concrete words, the dual coding model does not benefit from visual information for abstract words and this may cause lower performance of the dual coding model than the hybrid model. Although this discrepancy does not affect the findings on the superiority of the indirect grounding model, more valid training procedures should be pursued.</p>
<p>The use of concreteness rating may be controversial because of its limitations. Most concreteness ratings including Brysbaert et al.'s (2014) are collected by presenting words in isolation, thereby including an ambiguity in judgment for polysemous words (e.g., Reijnierse et al., 2019). This is particularly problematic for words with both concrete and abstract senses, which tend to be rated around the middle of the scale. In other words, words with low concreteness ratings are likely to be unambiguous and regarded as definitely abstract. The analysis reported in section 4.3 showed that the indirect grounding model improved the performance for words with low concreteness raging (when appropriate semantic neighbors were given), thus suggesting that our finding in favor of the indirect grounding view does not severely affected by this problem of concreteness rating.</p>
<p>Despite the positive result, there is another problem with the use of concreteness rating that must be addressed in future work. Recent studies on abstract concepts have argued that abstract concepts are not a unitary whole and should be treated as a heterogeneous category including various different types of abstract concepts (Troche et al., 2017; Borghi et al., 2018;</p>
<p>Villani et al., 2019). This argument implies that concreteness rating is not sufficient for determining words (or concepts) to be grounded indirectly. As reported in section 4.4, the impact of indirect grounding differs among various types of abstract concepts. Exploring this issue may provide an interesting avenue for future investigation.</p>
<p>The choice of semantic neighbors as mediator concepts, whose visual vectors define the indirectly grounded representation of abstract words, is an important process of the indirect grounding model. Appropriate mediator concepts need to have perceivable referents that also have perceptually clear-cut boundaries. For example, basic-level concepts such as desk and chair have specific referents that are characterized by perceptual features such as shapes, and thus they become good mediators. Superordinate concepts such as furniture also have perceivable referents but are difficult to distinguish from other concepts by perceptual features, and thus they are less likely to be good mediators. Highly underspecified concepts such as artifact no longer function as mediators because they are very generic and their defining features are not based on perceptual or other bodily experiences. However, our simple method of generating a pool of candidate words from which semantic neighbors are chosen has a potential problem in that words with higher concreteness rating do not necessarily have such specific referents. For example, the word "furniture" has a higher concreteness rating of 4.89 than "desk" (4.87) and "chair" (4.58), and the word "artifact" also has a very high rating of 4.50 in Brysbaert et al.'s (2014) dataset. Recently Bolognesi et al. (2020) empirically examined the same line of argument and demonstrated that categorical specificity should be considered as a distinct dimension from concreteness to characterize concepts. Categorical specificity is therefore an important property for choosing appropriate mediator words, although an appropriate level of specificity depends on the concept to be indirectly grounded.</p>
<p>Some other methods for determining mediator words can be considered to refine the indirect grounding model. Age-ofacquisition ratings (Kuperman et al., 2012) may be used to limit the vocabulary of candidate words for semantic neighbors, because basic words learned at the early stage of lexical acquisition are represented primarily perceptually, while other words learned at the later stage are acquired through the knowledge of basic words (Gleitman et al., 2005; Thill et al., 2014). A more promising approach is to use minimal grounding sets (Vincent-Lamarre et al., 2016) as a candidate set of semantic neighbors. A minimal grounding set is the smallest set of words (i.e., a subset of a vocabulary) from which all the other words in a vocabulary can be defined. Vincent-Lamarre et al. (2016) proposed a method for computing the minimal grounding sets from dictionary definitions. Although the minimal grounding set is not uniquely determined, it can be a theoretically more motivated pool of potential mediator words than a set of concrete words simply selected based on concreteness rating or other human-rating-based measures. Image tags may also
be a useful source of information for mediator words because tag co-occurrence statistics reflect visually motivated semantic knowledge. For example, words that are similar to a target abstract word in Flickr distributional tagspace (Bolognesi, 2017) are expected to be good mediators.</p>
<h2>6. Conclusion</h2>
<p>To test the indirect grounding view, we devised a new multimodal distributional semantic model in which a visual vector of an abstract word (i.e., embodied representation of perceptual experiences) is computed from the visual images of concrete words semantically related to the abstract word. Through the evaluation experiment, we have demonstrated that the indirect grounding model outperformed the hybrid (i.e., direct grounding) model, the dual coding model, and unimodal models. Despite the limitations described above, this finding lends some plausibility to the indirect grounding view and the present study is regarded as a first step toward empirically exploring the grounding mechanism of abstract concepts. For future work, we would like to explore a further mechanism of what and how linguistic processes come into play for grounding abstract concepts, together with to test indirect grounding via language using psychological experiments.</p>
<h2>Data availability statement</h2>
<p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p>
<h2>Author contributions</h2>
<p>AU conceptualized the study, performed the evaluation experiment and statistical analysis, and wrote the draft of the manuscript.</p>
<h2>Funding</h2>
<p>This research was supported by JSPS KAKENHI Grant Numbers JP15H02713 and JP20H04488.</p>
<h2>Conflict of interest</h2>
<p>The author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
<h2>Publisher's note</h2>
<p>All claims expressed in this article are solely those of the authors and do not necessarily represent those</p>
<p>of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
<h2>References</h2>
<p>Andrews, M., Vigliocco, G., and Vinson, D. (2009). Integrating experiential and distributional data to learn semantic representations. Psychol. Rev. 116, 463-498. doi: $10.1037 /$ a0016261</p>
<p>Baker, N., Lu, H., Erfikhman, G., and Kellman, P. J. (2018). Deep convolutional networks do not classify based on global object shape. PLoS Comput. Biol. 14:e1006613. doi: 10.1371/journal.pcbi. 1006613</p>
<p>Baroni, M. (2016). Grounding distributional semantics in the visual world. Linguist. Issues Lang. Technol. 10, 5-13. doi: 10.1111/lnc3.12170</p>
<p>Barsalou, L. W. (1999). Perceptual symbol systems. Behav. Brain Sci. 22, 577-660. doi: 10.1017/S0140525X99002149</p>
<p>Barsalou, L. W. (2003). Situated simulation in the human conceptual system. Lang. Cogn. Process. 18, 513-562. doi: 10.1080/01690960344000026</p>
<p>Barsalou, L. W. (2008). Grounded cognition. Annu. Rev. Psychol. 59, 617-645. doi: 10.1146/annurev.psych.59.103006.093639</p>
<p>Barsalou, L. W. (2016). On staying grounded and avoiding quixotic dead ends. Psychon. Bull. Rev. 23, 1122-1142. doi: 10.3758/s13423-016-1028-3</p>
<p>Barsalou, L. W., Dutriaux, L., and Scheepers, C. (2018). Moving beyond the distinction between concrete and abstract concepts. Philos. Trans. Roy. Soc. B 373:20170144. doi: 10.1098/rsrb.2017.0144</p>
<p>Barsalou, L. W., Santos, A., Simmons, W. K., and Wilson, C. D. (2008). "Language and simulation in conceptual processing," Symbols and Embodiment: Debates on Meaning and Cognition, eds M. de Vega, A. Glenberg, and A. Graesser (New York, NY: Oxford University Press), 245-283.</p>
<p>Barsalou, L. W., and Wiemer-Hastings, K. (2005). "Situating abstract concepts," in Grounding Cognition: The Role of Perception and Action in Memory, Language, and Thought, eds D. Pecher and R. Zwaan (New York, NY: Cambridge University Press), 129-163.</p>
<p>Bergelson, E., and Swingley, D. (2013). The acquisition of abstract words by young infants. Cognition 127, 391-397. doi: 10.1016/j.cognition.2013.02.011</p>
<p>Binder, J. B., Conant, L. L., Humphries, C. J., Fernandino, L., Simons, S. B., Aguilar, M., et al. (2016). Toward a brain-based computational semantic representation. Cogn. Neuropsychol. 33, 130-174. doi: 10.1080/02643294.2016.1147426</p>
<p>Binder, J. R., Desai, R. H., Graves, W. W., and Conant, L. L. (2009). Where is the semantic system? a critical review and meta-analysis of 120 functional neuroimaging studies. Cereb. Cortex 19, 2767-2796. doi: 10.1093/cercor/bhp055</p>
<p>Bolognesi, M. (2016). Modeling semantic similarity between metaphor terms of visual vs. linguistic metaphors through Flickr tag distributions. Front. Commun. 1:9. doi: 10.3389/fcomm.2016.00009</p>
<p>Bolognesi, M. (2017). "Flickr®distributional tagspace: evaluating the semantic spaces emerging from Flickr®tag distributions," in Big Data in Cognitive Science, ed M. Jones (Routledge: Taylor and Francis Group), 144-173.</p>
<p>Bolognesi, M., Burgers, C., and Caselli, T. (2020). On abstraction: decoupling conceptual concreteness and categorical specificity. Cogn. Process. 21, 365-381. doi: 10.1007/s10339-020-00965-9</p>
<p>Bolognesi, M., and Steen, G. (2018). Abstract concepts: structure, processing, and modeling. Top. Cogn. Sci. 10, 490-500. doi: 10.1111/tops. 12354</p>
<p>Borghi, A. M., Barca, L., Binkofski, F., Castelfranchi, C., Pezzulo, G., and Tummolini, L. (2019). Words as social tools: language, sociality and inner grounding in abstract concepts. Phys. Life Rev. 29, 120-153. doi: 10.1016/j.pirev.2018.12.001</p>
<p>Borghi, A. M., Barca, L., Binkofski, F., and Tummolini, L. (2018). Varieties of abstract concepts: development, use and representation in the brain. Philos. Trans. Roy. Soc. B 373:20170121. doi: 10.1098/rsrb.2017.0121</p>
<h2>Supplementary material</h2>
<p>The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/ fpsyg.2022.906181/full#supplementary-material</p>
<p>Borghi, A. M., and Binkofski, F. (2014). Words as Social Tools: An Embodied View on Abstract Concepts. New York, NY: Springer.</p>
<p>Borghi, A. M., Binkofski, F., Castelfranchi, C., Cimatti, F., Scorolli, C., and Tummolini, L. (2017). The challenge of abstract concepts. Psychol. Bull. 143, 263-292. doi: 10.1037/bul0000089</p>
<p>Borghi, A. M., Scorolli, C., Caligiore, D., Baldassarre, G., and Tummolini, L. (2013). The embodied mind extended: using words as social tools. Front. Psychol. 6:214. doi: 10.3389/fpsyg.2013.00214</p>
<p>Bruni, E., Tran, N. K., and Baroni, M. (2014). Multimodal distributional semantics. J. Artif. Intell. Res. 49, 1-47. doi: 10.1613/jair.4135</p>
<p>Bryebaert, M., Warriner, A. B., and Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. Behav. Res. Methods 46, 904-911. doi: 10.3758/s13428-013-0403-5</p>
<p>Bullinaria, J. A., and Levy, J. P. (2007). Extracting semantic representations from word co-occurrence statistics: a computational study. Behav. Res. Methods 39, 510-526. doi: 10.3758/BF03193020</p>
<p>Chersoni, E., Santus, E., Huang, C.-R., and Lenci, A. (2021). Decoding word embeddings with brain-based semantic features. Comput. Linguist. 47, 663-698. doi: 10.1162/CCLl_a_00412</p>
<p>Cichy, R. M., Khosla, A., Pantazis, D., Torralba, A., and Oliva, A. (2016). Comparison of deep neural networks to spatiotemporal cortical dynamics of human visual object recognition reveals hierarchical correspondence. Sci. Rep. 6:27755. doi: 10.1038/srep27755</p>
<p>Coello, Y., and Fisher, M. H. (2016). Foundations of Embodied Cognition: Vol. 1. Perceptual and Emotional Embodiment. Oxford UK: Routledge.
de Vega, M., Glenberg, A., and Graesser, A. (2008). Symbols and Embodiment: Debates on Meaning and Cognition. New York, NY: Oxford University Press.</p>
<p>Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). BERT: pre-training of deep bidirectional transformers for language understanding. arXiv:1810.04805[cs.CL]. doi: 10.48550/arXiv.1810.04805</p>
<p>Dove, G. (2014). Thinking in words: language as an embodied medium of thought. Top. Cogn. Sci. 6, 371-389. doi: 10.1111/tops. 12102</p>
<p>Dove, G. (2016). Three symbol ungrounding problems: abstract concepts and the future of embodied cognition. Psychon. Bull. Rev. 23, 1109-1121. doi: 10.3758/s13423-015-0825-4</p>
<p>Dove, G. (2018). Language as a disruptive technology: abstract concepts, embodiment and the flexible mind. Philos. Trans. Roy. Soc. B 373:20170135. doi: 10.1098/rsrb.2017.0135</p>
<p>Fisher, M. H., and Coello, Y. (2016). Foundations of Embodied Cognition: Vol. 2. Conceptual and Interactive Embodiment. Oxford, UK: Routledge.</p>
<p>Ghio, M., Vaghi, M. M. S., Perani, D., and Tettamanti, M. (2016). Decoding the neural representation of fine-grained conceptual categories. Neuroimage 132, 93-103. doi: 10.1016/j.neuroimage.2016.02.008</p>
<p>Gleitman, L. R., Cassidy, K., Nappa, R., Papafragou, A., and Trueswell, J. C. (2005). Hard words. Lang. Learn. Dev. 1, 23-64. doi: 10.1207/s15473341lld0101_4</p>
<p>Glenberg, A. M., and Kaschak, M. P. (2002). Grounding language in action. Psychon. Bull. Rev. 9, 558-565. doi: 10.3758/BF03196313</p>
<p>Glorot, X., and Bengio, Y. (2010). "Understanding the difficulty of training deep feedforward neural networks," in Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (Sardinia), 249-256.</p>
<p>Goldberg, Y. (2017). Neural Network Methods for Natural Language Processing. San Rafael, CA: Morgan and Claypool Publishers. doi: 10.2200/S00762ED1V01Y201703HLT037</p>
<p>Günther, F., Nguyen, T., Chen, L., Dudschig, C., Kaup, B., and Glenberg, A. M. (2020). Immediate sensorimotor grounding of novel concepts learned from language alone. J. Mem. Lang. 115:104172. doi: 10.1016/j.jml.2020.104172
Harnad, S. (1990). The symbol grounding problem. Phys. D 42, 335-346. doi: 10.1016/0167-2789(90)90087-6
Hill, F., and Korhonen, A. (2014). "Learning abstract concept embeddings from multi-modal data: Since you probably can't see what I mean," in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMSLP2014) (Doha), 255-265.
Hoffman, P., McClelland, J. L., and Lambon Ralph, M. A. (2018). Concepts, control, and context: a connectionist account of normal and disordered semantic cognition. Psychol. Rev. 125, 293-328. doi: 10.1037/rev0000094
Howell, S. B., Jankowicz, D., and Becker, S. (2005). A model of grounded language acquisition: Sensorimotor features improve lexical and grammatical learning. J. Mem. Lang. 53, 258-276. doi: 10.1016/j.jml.2005.03.002
Jackendoff, R. (2019). "Mental representations for language," in Human Language: From Genes and Brains to Behavior, ed P. Hagoort (Cambridge, MA: MIT Press), 7-20.
Jacob, G., Pramod, R., Katti, H., and Arun, S. (2021). Qualitative similarities and differences in visual object representations between brains and deep networks. Nat. Commun. 12:1872. doi: 10.1038/s41467-021-22078-3
Johns, R. T., and Jones, M. N. (2012). Perceptual reference through global lexical similarity. Top. Cogn. Sci. 4, 103-120. doi: 10.1111/j.1756-8765.2011.01176.x
Jones, M. N., Willits, J., and Dennis, S. (2015). "Models of semantic memory," in Oxford Handbook of Mathematical and Computational Psychology, eds J. R. Busemeyer, Z. Wang, J. T. Townsend, and A. Eidels (New York, NY: Oxford University Press), 232-254.
Kaschak, M. P., Madden, C. J., Therriault, D. J., Yaxley, R. H., Aveyard, M., Blanchard, A. A., et al. (2005). Perception of motion affects language processing. Cognition 94, 79-89. doi: 10.1016/j.cognition.2004.06.005
Kiela, D., Bulat, L., and Clark, S. (2015). "Grounding semantics in olfactory perception," in Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Beijing), 231-236.
Kiela, D., and Clark, S. (2015). "Multi- and cross-modal semantics beyond vision: Grounding in auditory perception," in Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (Lisbon), 2461-2470.
Kiela, D., Hill, F., Korhonen, A., and Clark, S. (2014). "Improving multimodal representations using image dispersion: why less is sometimes more," in Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Baltimore, MD), 835-841.
Kumar, A. A. (2021). Semantic memory: a review of methods, models, and current challenges. Psychon. Bull. Rev. 28, 40-80. doi: 10.3758/s13423-020-01792-x
Kuperman, V., Stadthagen-Gonzalez, H., and Brysbaert, M. (2012). Age-ofacquisition ratings for 30,000 English words. Behav. Res. Methods 44, 978-990. doi: 10.3758/s13428-012-0210-4
Lake, B. M., and Murphy, G. L. (2021). Word meaning in minds and machines. Psychol. Rev. doi: 10.1037/rev0000297. [Epub ahead of print].
Lazandou, A., Pham, N. T., and Baroni, M. (2015). "Combining language and vision with a multimodal skip-gram model," in Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Denver, CO), 153-163.
Lenci, A. (2018). Distributional models of word meaning. Annu. Rev. Linguist. 4, 151-171. doi: 10.1146/annurev-linguistics-030514-125254
Louwerse, M. M. (2011). Symbol interdependency in symbolic and embodied cognition. Top. Cogn. Sci. 3, 273-302. doi: 10.1111/j.1756-8765.2010.01106.x
Louwerse, M. M. (2018). Knowing the meaning of a word by the linguistic and perceptual company it keeps. Top. Cogn. Sci. 10, 573-589. doi: 10.1111/tops. 12349
Louwerse, M. M., and Jeuniaux, P. (2010). The linguistic and embodied nature of conceptual processing. Cognition 114, 96-104. doi: 10.1016/j.cognition.2009.09.002
Lupyan, G., and Lewis, M. (2019). From words-as-mappings to words-as-cues: the role of language in semantic knowledge. Lang. Cogn. Neurosci. 34, 1319-1337. doi: 10.1080/23273798.2017.1404114
Malhi, S. K., and Buchanan, L. (2018). A test of the symbol interdependency hypothesis with both concrete and abstract stimuli. PLoS ONE 13:e0192719. doi: 10.1371/journal.pone. 0192719
McRae, K., Nedjadraoul, D., Raymond Pau, B. P.-H. L., and King, L. (2018). Abstract concepts and pictures of real-world situations activate one another. Top. Cogn. Sci. 10, 518-532. doi: 10.1111/tops. 12328</p>
<p>Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). "Efficient estimation of word representations in vector space," in Proceedings of Workshop at the International Conference on Learning Representation (ICLR) (Scottsdale, AZ).
Paivio, A. (1971). Imagery and Verbal Processes. New York, NY: Holt, Rinehart, and Winston.
Paivio, A. (1986). Mental Representations: A Dual Coding Approach. New York, NY: Oxford University Press.
Pecher, D., and Zwaan, R. (2005). Grounding Cognition: The Role of Perception and Action in Memory, Language and Thinking. Cambridge: Cambridge University Press.
Pennington, J., Socher, R., and Manning, C. D. (2014). "GloVe: Global vectors for word representation," in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (Doha), 1532-1543.
Pilehvar, M. T., and Camacho-Collados, J. (2020). Embeddings in Natural Language Processing: Theory and Advances in Vector Representations of Meaning. Williston, VT: Morgan and Claypool Publishers. doi: 10.2200/S01057ED1V01Y202009HLT047
Pulvermüller, F. (2013). How neurons make meaning: brain mechanisms for embodied and abstract-symbolic semantics. Trends Cogn. Sci. 17, 458-470. doi: 10.1016/j.tics.2013.06.004
Recchia, G., and Louwerse, M. M. (2015). Reproducing affective norms with lexical co-occurrence statistics: predicting valence, arousal, and dominance. Q. J. Exp. Psychol. (Hens), 68, 1584-1598. doi: 10.1080/17470218.2014.941296
Reijnierse, W. G., Burgers, C., Bolognesi, M., and Krennmayr, T. (2019). How polysemy affects concreteness ratings: the case of metaphor. Cogn. Sci. 43:e12779. doi: 10.1111/cogs. 12779
Rogers, A., Kovaleva, O., and Rumshisky, A. (2020). A primer in BERTology: what we know about how BERT works. Trans. Assoc. Comput. Linguist. 8, 842-866. doi: 10.1162/tacl_a_00349
Schwanenflugel, P. J. (1991). "Why are abstract concepts hard to understand?," in The Psychology of Word Meanings, ed P. J. Schwanenflugel (Hillsdale, NJ: Lawrence Erlbaum Associates), 223-250.
Schwanenflugel, P. J., Harnisfeleger, K. K., and Stowe, R. W. (1988). Context availability and lexical decisions for abstract and concrete words. J. Mem. Lang. 27, 499-520. doi: 10.1016/0749-596X(88)90022-8
Scorolli, C. (2014). "Embodiment and language," in The Routledge Handbook of Embodied Cognition, ed L. Shapiro (New York, NY: Routledge), 127-138.
Serre, T. (2019). Deep learning: the good, the bad, and the ugly. Annu. Rev. Vis. Sci. 5, 399-426. doi: 10.1146/annurev-vision-091718-014951
Silberer, C., Ferrari, V., and Lapata, M. (2017). Visually grounded meaning representations. IEEE Trans. Pattern Recegn. Mach. Intell. 39, 2284-2297. doi: 10.1109/TPAMI.2016.2635138
Silberer, C., and Lapata, M. (2012). "Grounded models of semantic representation," in Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (Jeju Island), 1423-1433.
Thill, S., Pado, S., and Ziemke, T. (2014). On the importance of a rich embodiment in the grounding of concepts: perspectives from embodied cognitive science and computational linguistics. Top. Cogn. Sci. 6, 545-558. doi: 10.1111/tops. 12093
Troche, J., Crutch, S. J., and Reilly, J. (2017). Defining a conceptual topography of word concreteness: clustering properties of emotion, sensation, and magnitude among 750 english words. Front. Psychol. 8:1787. doi: 10.3389/fpsyg.2017.01787
Turney, P. D., and Pantel, P. (2010). From frequency to meaning: vector space models of semantics. J. Artif. Intell. Res. 37, 141-188. doi: 10.1613/jair. 2934
Utsumi, A. (2020). Exploring what is encoded in distributional word vectors: a neurobiologically motivated analysis. Cogn. Sci. 44:e12844. doi: 10.1111/cogs. 12844
Vigliocco, G., and Vinson, D. P. (2007). "Semantic representation," in The Oxford Handbook of Psycholinguistics, ed M. G. Gaskell (Oxford, UK: Oxford University Press), 217-234.
Villani, C., Lugli, L., Liuzza, M. T., and Borghi, A. M. (2019). Varieties of abstract concepts and their multiple dimensions. Lang. Cogn. 11, 403-430. doi: 10.1017/langcog.2019.23
Vincent-Lamarre, P., Massé, A. B., Lopes, M., Lord, M., Marcotte, O., and Harnada, S. (2016). The latent structure of dictionaries. Top. Cogn. Sci. 8, 625-659. doi: 10.1111/tops. 12211
Wang, J., Condor, J. A., Blitzer, D. N., and Shinkareva, S. V. (2010). Neural representation of abstract and concrete concepts: A meta-analysis of neuroimaging studies. Hum. Brain Mapp. 31, 1459-1468. doi: 10.1002/hbm. 20950</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>5 We did not use $\theta_{c}=1.1$ because the minimum concreteness rating in Binder et al.'s (2016) dataset was 1.19 (for the word "belief") and no words were judged as abstract when $\theta_{c}=1.1$.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>conceptual processing such as a property generation task that requires both linguistic and simulation (i.e., embodied) systems.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>