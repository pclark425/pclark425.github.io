<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7092 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7092</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7092</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-685d7b452431904c650cf5e00355f6882ea05e69</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/685d7b452431904c650cf5e00355f6882ea05e69" target="_blank">REINVENT 2.0: An AI Tool for De Novo Drug Design</a></p>
                <p><strong>Paper Venue:</strong> Journal of Chemical Information and Modeling</p>
                <p><strong>Paper TL;DR:</strong> This application note aims to offer the community a production-ready tool for de novo design, called REINVENT, which can be effectively applied on drug discovery projects that are striving to resolve either exploration or exploitation problems while navigating the chemical space.</p>
                <p><strong>Paper Abstract:</strong> In the past few years, we have witnessed a renaissance of the field of molecular de novo drug design. The advancements in deep learning and artificial intelligence (AI) have triggered an avalanche of ideas on how to translate such techniques to a variety of domains including the field of drug design. A range of architectures have been devised to find the optimal way of generating chemical compounds by using either graph- or string (SMILES)-based representations. With this application note, we aim to offer the community a production-ready tool for de novo design, called REINVENT. It can be effectively applied on drug discovery projects that are striving to resolve either exploration or exploitation problems while navigating the chemical space. It can facilitate the idea generation process by bringing to the researcher's attention the most promising compounds. REINVENT's code is publicly available at https://github.com/MolecularAI/Reinvent.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7092.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7092.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>REINVENT RNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>REINVENT RNN-based SMILES generative model (Agent/Prior)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Production-ready de novo small-molecule generator using SMILES-based recurrent neural networks (RNNs, LSTM-style), trained on randomized SMILES from ChEMBL and steered with reinforcement learning (actor-critic) to maximize a composite multiparameter optimization (MPO) scoring function.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>REINVENT RNN (Agent/Prior)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Recurrent neural network (LSTM-style) generative model used in an actor-critic reinforcement learning setup</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained on a dataset derived from ChEMBL; training uses 'randomized SMILES' data augmentation (multiple SMILES per molecule) to encourage grammar learning rather than memorization.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct SMILES generation by sampling the RNN; fine-tuned/steered via Reinforcement Learning (policy iteration actor-critic) where an Agent RNN is updated to match an augmented likelihood (Prior likelihood + sigma * MPO score), plus optional Transfer Learning (prior pre-focusing) and 'inception' (experience replay) to speed focusing.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES (randomized SMILES used for training); generated output is SMILES strings.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>De novo drug design / hit discovery (exploration and exploitation of chemical space for drug-like small molecules).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Composite MPO scoring (weighted sum or weighted product) combining physical–chemical properties, predictive model outputs, similarity/shape scores, matching substructure (SMARTS-based) penalty, custom alerts (SMARTS), selectivity components (target minus off-target), diversity filters (Topological DF, Identical Murcko DF, Scaffold Similarity DF), and property transformation functions (sigmoid, double-sigmoid, step, custom interpolation).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>RDKit for cheminformatics operations (fingerprints, scaffold extraction, SMARTS), PyTorch (model implementation), scikit-learn models and XGBoost used as predictive scoring components, Tensorboard for logging; output CSV and REST logging options.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ChEMBL-derived dataset for RNN training (randomized SMILES augmentation applied).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>SMILES validity %, MPO score (composite score in [0,1]); component-level scores in [0,1]; diversity/enforcement via counts per scaffold bucket; model loss defined as squared difference between Agent log-likelihood and augmented log-likelihood.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Model trained with randomized SMILES produces SMILES validity above 99% (cited from Arús-Pous et al. [12]); MPO scores are in range 0–1 by design; no numerical benchmarks (e.g., uniqueness, novelty, binding affinities, or synthesis metrics) reported in this paper for generated sets beyond validity statistic.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Only fingerprint descriptors supported for predictive model inputs (ECFP variants, MACCS, Avalon). Combining multiple predictive models amplifies cumulative uncertainty (geometric amplification with product formulation). Risk of Agent overfocusing / mode collapse (generating few high-probability molecules); inception (replay) can accelerate focusing but may exacerbate loss of diversity. Diversity Filters mitigate repetition but depend on chosen scaffold strategy; sigma scalar must be tuned/adjusted to maintain margin between augmented and Agent likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'REINVENT 2.0: An AI Tool for De Novo Drug Design', 'publication_date_yy_mm': '2020-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7092.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7092.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Randomized SMILES augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Randomized SMILES data augmentation (Arús-Pous et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Data augmentation technique that represents each molecule with multiple randomized SMILES encodings during training so the generative model learns SMILES grammar and generalizes better rather than memorizing canonical strings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Randomized SMILES strings improve the quality of molecular generative models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Randomized SMILES augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Data augmentation technique for SMILES-based generative models</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Applied to ChEMBL-derived SMILES by generating multiple randomized SMILES per molecule during training.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not a generation model itself — used during model training so the downstream RNN generates SMILES more robustly.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES (randomized permutations of canonical SMILES).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Improving generalization and validity of SMILES-based molecule generators for de novo drug design.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>No explicit chemical constraints; purpose is improved grammar learning and validity.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Used in training pipeline with RDKit for SMILES randomization and PyTorch for model training.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>ChEMBL (as used in REINVENT training pipeline).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>SMILES validity % (used to measure effect of augmentation); generative generalization indicators (not fully enumerated in this paper but validity >99% reported for the resulting model).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>The paper reports that models trained with randomized SMILES show substantially improved generalization and produce SMILES strings with validity above 99% (cited).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Technique helps validity and generalization but does not by itself address multi-objective steering, property prediction errors, or downstream synthetic accessibility; requires additional RL/optimization machinery to focus on specific targets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'REINVENT 2.0: An AI Tool for De Novo Drug Design', 'publication_date_yy_mm': '2020-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7092.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7092.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Predictive scoring models (sklearn / XGBoost)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>scikit-learn classifiers/regressors and XGBoost regressors used as predictive scoring components</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Predictive ML models (binary classifiers or regressors) used as components of the MPO scoring function to estimate activities/properties of generated molecules based on fingerprint descriptors (ECFP, MACCS, Avalon).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scikit-learn: Machine learning in Python</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>scikit-learn models / XGBoost (XGB Regressor)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Classical machine learning predictive models used as scoring functions (classification/regression)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not specified in detail in this paper (user-supplied training data for each predictive model is assumed); descriptors must be fingerprint representations (ECFP variants, MACCS, Avalon) computed with RDKit.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Used to score generated SMILES inside the RL loop (component outputs transformed to [0,1] and combined into MPO).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Molecular fingerprints (ECFP, MACCS keys, Avalon) derived from SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Predicting target activity, off-target activity, and physico-chemical / ADMET properties for multi-parameter scoring during molecule generation.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Model outputs are transformed into [0,1] via sigmoid, double-sigmoid, step functions, or custom interpolation; selectivity component computes delta (target - off-target) and applies transformation; matching substructure/custom alerts used in scoring pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Models are scikit-learn / xgboost objects called inside REINVENT scoring; fingerprint calculation via RDKit; used within the RL loop to compute MPO scores.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not reported as part of this paper — predictive model performance expected to be user-provided; the effect of predictive models on overall generation is discussed qualitatively (uncertainty amplification).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>No quantitative predictive-model performance numbers provided in this paper; paper warns about cumulative uncertainty when combining multiple models.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>REINVENT currently supports only fingerprint descriptors (no graph/learned descriptors) for these predictive models. Combining multiple predictive models increases cumulative uncertainty (geometric amplification when using product scoring), potentially degrading optimization reliability; regression outputs require ad hoc transformations to the 0–1 scoring scale; classification models must be binary with probability for positive class used as score.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'REINVENT 2.0: An AI Tool for De Novo Drug Design', 'publication_date_yy_mm': '2020-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Randomized SMILES strings improve the quality of molecular generative models <em>(Rating: 2)</em></li>
                <li>Molecular de-novo design through deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Generating focused molecule libraries for drug discovery with recurrent neural networks <em>(Rating: 2)</em></li>
                <li>Application of Generative Autoencoder in De Novo Molecular Design <em>(Rating: 1)</em></li>
                <li>Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules <em>(Rating: 1)</em></li>
                <li>Direct Steering of de novo Molecular Generation using Descriptor Conditional Recurrent Neural Networks (cRNNs) <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7092",
    "paper_id": "paper-685d7b452431904c650cf5e00355f6882ea05e69",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "REINVENT RNN",
            "name_full": "REINVENT RNN-based SMILES generative model (Agent/Prior)",
            "brief_description": "Production-ready de novo small-molecule generator using SMILES-based recurrent neural networks (RNNs, LSTM-style), trained on randomized SMILES from ChEMBL and steered with reinforcement learning (actor-critic) to maximize a composite multiparameter optimization (MPO) scoring function.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "REINVENT RNN (Agent/Prior)",
            "model_type": "Recurrent neural network (LSTM-style) generative model used in an actor-critic reinforcement learning setup",
            "model_size": null,
            "training_data_description": "Trained on a dataset derived from ChEMBL; training uses 'randomized SMILES' data augmentation (multiple SMILES per molecule) to encourage grammar learning rather than memorization.",
            "generation_method": "Direct SMILES generation by sampling the RNN; fine-tuned/steered via Reinforcement Learning (policy iteration actor-critic) where an Agent RNN is updated to match an augmented likelihood (Prior likelihood + sigma * MPO score), plus optional Transfer Learning (prior pre-focusing) and 'inception' (experience replay) to speed focusing.",
            "chemical_representation": "SMILES (randomized SMILES used for training); generated output is SMILES strings.",
            "target_application": "De novo drug design / hit discovery (exploration and exploitation of chemical space for drug-like small molecules).",
            "constraints_used": "Composite MPO scoring (weighted sum or weighted product) combining physical–chemical properties, predictive model outputs, similarity/shape scores, matching substructure (SMARTS-based) penalty, custom alerts (SMARTS), selectivity components (target minus off-target), diversity filters (Topological DF, Identical Murcko DF, Scaffold Similarity DF), and property transformation functions (sigmoid, double-sigmoid, step, custom interpolation).",
            "integration_with_external_tools": "RDKit for cheminformatics operations (fingerprints, scaffold extraction, SMARTS), PyTorch (model implementation), scikit-learn models and XGBoost used as predictive scoring components, Tensorboard for logging; output CSV and REST logging options.",
            "dataset_used": "ChEMBL-derived dataset for RNN training (randomized SMILES augmentation applied).",
            "evaluation_metrics": "SMILES validity %, MPO score (composite score in [0,1]); component-level scores in [0,1]; diversity/enforcement via counts per scaffold bucket; model loss defined as squared difference between Agent log-likelihood and augmented log-likelihood.",
            "reported_results": "Model trained with randomized SMILES produces SMILES validity above 99% (cited from Arús-Pous et al. [12]); MPO scores are in range 0–1 by design; no numerical benchmarks (e.g., uniqueness, novelty, binding affinities, or synthesis metrics) reported in this paper for generated sets beyond validity statistic.",
            "experimental_validation": false,
            "challenges_or_limitations": "Only fingerprint descriptors supported for predictive model inputs (ECFP variants, MACCS, Avalon). Combining multiple predictive models amplifies cumulative uncertainty (geometric amplification with product formulation). Risk of Agent overfocusing / mode collapse (generating few high-probability molecules); inception (replay) can accelerate focusing but may exacerbate loss of diversity. Diversity Filters mitigate repetition but depend on chosen scaffold strategy; sigma scalar must be tuned/adjusted to maintain margin between augmented and Agent likelihoods.",
            "uuid": "e7092.0",
            "source_info": {
                "paper_title": "REINVENT 2.0: An AI Tool for De Novo Drug Design",
                "publication_date_yy_mm": "2020-10"
            }
        },
        {
            "name_short": "Randomized SMILES augmentation",
            "name_full": "Randomized SMILES data augmentation (Arús-Pous et al.)",
            "brief_description": "Data augmentation technique that represents each molecule with multiple randomized SMILES encodings during training so the generative model learns SMILES grammar and generalizes better rather than memorizing canonical strings.",
            "citation_title": "Randomized SMILES strings improve the quality of molecular generative models",
            "mention_or_use": "use",
            "model_name": "Randomized SMILES augmentation",
            "model_type": "Data augmentation technique for SMILES-based generative models",
            "model_size": null,
            "training_data_description": "Applied to ChEMBL-derived SMILES by generating multiple randomized SMILES per molecule during training.",
            "generation_method": "Not a generation model itself — used during model training so the downstream RNN generates SMILES more robustly.",
            "chemical_representation": "SMILES (randomized permutations of canonical SMILES).",
            "target_application": "Improving generalization and validity of SMILES-based molecule generators for de novo drug design.",
            "constraints_used": "No explicit chemical constraints; purpose is improved grammar learning and validity.",
            "integration_with_external_tools": "Used in training pipeline with RDKit for SMILES randomization and PyTorch for model training.",
            "dataset_used": "ChEMBL (as used in REINVENT training pipeline).",
            "evaluation_metrics": "SMILES validity % (used to measure effect of augmentation); generative generalization indicators (not fully enumerated in this paper but validity &gt;99% reported for the resulting model).",
            "reported_results": "The paper reports that models trained with randomized SMILES show substantially improved generalization and produce SMILES strings with validity above 99% (cited).",
            "experimental_validation": false,
            "challenges_or_limitations": "Technique helps validity and generalization but does not by itself address multi-objective steering, property prediction errors, or downstream synthetic accessibility; requires additional RL/optimization machinery to focus on specific targets.",
            "uuid": "e7092.1",
            "source_info": {
                "paper_title": "REINVENT 2.0: An AI Tool for De Novo Drug Design",
                "publication_date_yy_mm": "2020-10"
            }
        },
        {
            "name_short": "Predictive scoring models (sklearn / XGBoost)",
            "name_full": "scikit-learn classifiers/regressors and XGBoost regressors used as predictive scoring components",
            "brief_description": "Predictive ML models (binary classifiers or regressors) used as components of the MPO scoring function to estimate activities/properties of generated molecules based on fingerprint descriptors (ECFP, MACCS, Avalon).",
            "citation_title": "Scikit-learn: Machine learning in Python",
            "mention_or_use": "use",
            "model_name": "scikit-learn models / XGBoost (XGB Regressor)",
            "model_type": "Classical machine learning predictive models used as scoring functions (classification/regression)",
            "model_size": null,
            "training_data_description": "Not specified in detail in this paper (user-supplied training data for each predictive model is assumed); descriptors must be fingerprint representations (ECFP variants, MACCS, Avalon) computed with RDKit.",
            "generation_method": "Used to score generated SMILES inside the RL loop (component outputs transformed to [0,1] and combined into MPO).",
            "chemical_representation": "Molecular fingerprints (ECFP, MACCS keys, Avalon) derived from SMILES.",
            "target_application": "Predicting target activity, off-target activity, and physico-chemical / ADMET properties for multi-parameter scoring during molecule generation.",
            "constraints_used": "Model outputs are transformed into [0,1] via sigmoid, double-sigmoid, step functions, or custom interpolation; selectivity component computes delta (target - off-target) and applies transformation; matching substructure/custom alerts used in scoring pipeline.",
            "integration_with_external_tools": "Models are scikit-learn / xgboost objects called inside REINVENT scoring; fingerprint calculation via RDKit; used within the RL loop to compute MPO scores.",
            "dataset_used": null,
            "evaluation_metrics": "Not reported as part of this paper — predictive model performance expected to be user-provided; the effect of predictive models on overall generation is discussed qualitatively (uncertainty amplification).",
            "reported_results": "No quantitative predictive-model performance numbers provided in this paper; paper warns about cumulative uncertainty when combining multiple models.",
            "experimental_validation": null,
            "challenges_or_limitations": "REINVENT currently supports only fingerprint descriptors (no graph/learned descriptors) for these predictive models. Combining multiple predictive models increases cumulative uncertainty (geometric amplification when using product scoring), potentially degrading optimization reliability; regression outputs require ad hoc transformations to the 0–1 scoring scale; classification models must be binary with probability for positive class used as score.",
            "uuid": "e7092.2",
            "source_info": {
                "paper_title": "REINVENT 2.0: An AI Tool for De Novo Drug Design",
                "publication_date_yy_mm": "2020-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Randomized SMILES strings improve the quality of molecular generative models",
            "rating": 2
        },
        {
            "paper_title": "Molecular de-novo design through deep reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Generating focused molecule libraries for drug discovery with recurrent neural networks",
            "rating": 2
        },
        {
            "paper_title": "Application of Generative Autoencoder in De Novo Molecular Design",
            "rating": 1
        },
        {
            "paper_title": "Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules",
            "rating": 1
        },
        {
            "paper_title": "Direct Steering of de novo Molecular Generation using Descriptor Conditional Recurrent Neural Networks (cRNNs)",
            "rating": 2
        }
    ],
    "cost": 0.01067475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>REINVENT 2.0 - an AI tool for de novo drug design</h1>
<p>Thomas Blaschke ${ }^{€}$, Josep Arús-Pous ${ }^{\S}$, Hongming Chen ${ }^{#}$, Christian Margreitter ${ }^{b}$, Christian Tyrchan ${ }^{\S}$, Ola Engkvist ${ }^{4}$, Kostas Papadopoulos ${ }^{4}$, Atanas Patronov ${ }^{6^{*}}$</p>
<h4>Abstract</h4>
<p>§ Hit Discovery, Discovery Sciences, MolecularAI, R\&amp;D, AstraZeneca Gothenburg, Sweden || Medicinal Chemistry, BioPharmaceuticals Early RIA, R\&amp;D, AstraZeneca, Gothenburg, Sweden $\perp$ Department of Chemistry and Biochemistry, University of Bern, Freiestrasse 3, 3012 Bern, Switzerland. $\checkmark$ Chemistry and Chemical Biology Centre, Guangzhou Regenerative Medicine and Health-Guangdong Laboratory, Science Park, Guangzhou, China € Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, D-53115 Bonn, Germany * Corresponding author: atanas.patronov@astrazeneca.com</p>
<h4>Abstract</h4>
<p>In the past few years, we have witnessed a renaissance of the field of de novo drug design. The advancements in deep learning and artificial intelligence (AI) have triggered an avalanche of ideas about how to translate such techniques to a variety of domains including the field of drug design. A range of architectures have been devised to find the optimal way of generating chemical compounds by using either graph or SMILES based representations. With this application note we aim to offer the community a production-ready tool for de novo design, named REINVENT. It can be effectively applied on drug discovery projects that are striving to resolve either exploration or exploitation problems while navigating the chemical space. It can facilitate the idea generation process by bringing to the researcher's attention the most promising compounds. REINVENT's code is publicly available at https://github.com/MolecularAI/Reinvent</p>
<h1>Introduction</h1>
<p>The main goal of de novo drug design is to identify novel active compounds that can simultaneously satisfy a constellation of essential optimization goals such as activity, selectivity, physical-chemical and ADMET properties. Because of the sheer number of possible solutions, it is a non-trivial task to optimally satisfy such a multitude of requirements which makes the search process slow and costly even when it is only conducted in silico. Therefore, having an efficient solution which enables the navigation of chemical space and generation of relevant ideas is essential. To address such needs the research community has recently turned its focus towards artificial intelligence (AI) based generative models that are capable of proposing promising small molecules. The potential of generative models for chemical space exploration has been demonstrated in numerous studies [1]-[3]. Various neural network architectures have been engineered and a plethora of AI training strategies have been employed in the race to device more efficient methods for the generation of compounds. A number of architectures, such as Variational Autoencoders (VAEs) [4], [5], Recurrent Neural Networks (RNNs) with Long ShortTerm Memory (LSTM) cells [6], Conditional RNNs or Generative Adversarial Networks have been proven successful in generating molecules by using data representation of molecules either as molecular graphs or SMILES [7]-[10].</p>
<p>However, while all of these architectures and many others are provided as open-source, only a few [11] are in a state that allows to readily apply the code on drug design related problems without the need of spending a significant amount of time developing missing functionalities. Ideally, users should be able to navigate the chemical space efficiently in two general use cases: exploration and exploitation mode. For exploitation, users define an area of interest and focus on generating compounds that share similar structural features. In contrast, the exploration mode enables them to obtain compounds that share less structural similarity but still satisfy other desired features. This implies the necessity to utilize not only predictive models and structure similarity/dissimilarity but also various rule-based scoring components to push towards or pull away from specific areas of the chemical space. Moreover, to be able to adapt appropriately to</p>
<p>any given drug discovery project at hand, the ability to fine-tune each of these potential scoring function components is paramount.</p>
<p>To achieve such behavior, apart from having a deep learning architecture with a reliable generative potential, it is essential to provide an efficient navigation mechanism. In order to address such needs, we are describing in the current paper the latest version of REINVENT - our in-house developed tool for de novo design of small molecules.</p>
<h1>Application Overview</h1>
<p>In its core, REINVENT is using a generative model with an architecture derived from the work of Arus-Pous et al [12]. The model is trained on a dataset derived from ChEMBL [13] and capable of generating compounds in the SMILES format. It has been trained by "randomizing" the SMILES representation of the input data, which is essentially a data augmentation technique [12]. Randomizing the compounds' representation uses multiple SMILES encodings for the same compound, thus ensuring that the model will likely learn the grammar rather than memorizing specific strings or parts of them. The resulting model shows a significantly improved generalization potential and produces SMILES strings with validity of above 99\% [12]. Uniform sampling of the chemical space by the model is a prerequisite for efficient exploration. The model can generate random valid compounds and is able to dive into any region of that space for exhaustive exploitation [12]. However, we are mostly interested in compounds that only act on a specific target and such creative potential of generative models is of little practical use unless specific context is given. Therefore, it is often necessary to direct the generative model towards relevant areas in the chemical space that contain compounds of interest. We achieve this by subjecting it to a Reinforcement Learning (RL) [14] scenario while aiming to satisfy a set of requirements that could vaguely sketch the desired compounds. In other words, the generative model will try to maximize the outcome of a scoring function that contains multiple components/parameters, thus computing an MPO score [15]. To stir the generation of compounds towards the desired direction, REINVENT employs a composite scoring function</p>
<p>consisting of different user-defined components. Each component is responsible for a simple target property. The feedback from the scoring function is used in a RL loop with a policy iteration as described by Olivecrona et al. [16]. Two RNNs are used in an actor-critic scenario where the critic is a prior RNN (Prior) that remains constant and serves as a baseline thus guaranteeing that the knowledge of SMILES syntax will be retained. The actor (which we will refer to as the Agent) can be an identical copy of the Prior or a focused version that has already undergone some training. The Agent takes actions by sampling a batch of SMILES $\mathbf{S}$ which are evaluated by the Prior and scored by the scoring function. The resulting score is combined with Prior's likelihood and used to form the augmented likelihood (eq 1). The augmented likelihood essentially sets the bar for the Agent since the loss is calculated as the squared difference between the Agent's likelihood and the augmented likelihood (eq 2). Also, $\boldsymbol{\sigma}$ is a scalar value, automatically adjusted to guarantee a proper margin between augmented and Agent's likelihood values.</p>
<p>$$
\begin{aligned}
&amp; \log P(\boldsymbol{S})<em P="P" i="i" o="o" r="r">{A u g m e n t e d}=\log P(\boldsymbol{S})</em>)}+\boldsymbol{\sigma} * M P O(\boldsymbol{S<em A="A" d="d" e="e" g="g" m="m" n="n" t="t" u="u">{s c o r e} \
&amp; \text { loss }=\left[\log P(\boldsymbol{S})</em>
\end{aligned}
$$}-\log P(\boldsymbol{S})_{A g e n t}\right]^{2</p>
<p>The RL scenario is complemented with an inception feature which can speed up the focusing of the Agent. Inception is essentially an extended experience replay [17] that allows users to preincept SMILES of interest so that the RL run generates compounds within an area of interest in a fewer number of steps. This can be particularly useful for specific exploitation scenarios.</p>
<p>Another key feature that has influence over the RL driven training of the Agent is the diversity filter as it can penalize the frequent generation of similar compounds. Each of these features are discussed in further detail below.</p>
<p>REINVENT offers two general scoring function formulations (equations 3 and 4). The individual components of the scoring function can be either combined as a weighted sum or as a weighted product [18]. The individual score components can have different weight coefficients reflecting their importance in the overall score. Score contribution from each component can vary in the range between 0 and 1 . As a result, the overall score is also within a range of 0 to 1.</p>
<p>$$
\begin{aligned}
&amp; P(X)=\left[\prod_{i} p\left(x_{i}\right)^{w_{i}}\right]^{1 / \sum_{i} w_{i}} \
&amp; S(X)=\frac{\sum_{i} w_{i} * p\left(x_{i}\right)}{\sum_{i} w_{i}}
\end{aligned}
$$</p>
<p>The scoring function can be comprised of components such as physical-chemical properties, predictive models (both regression and classification), shape similarity, Tanimoto similarity, and Jaccard distance scores [19]. The predictive model component in REINVENT works with both regression and classification types of scikit-learn [20] predictive models. XGB Regressor model types from the xgboost python library can be also employed [21]. A notable limitation of the current implementation is that only fingerprint descriptors can be used. REINVENT supports various representations of ECFP descriptors, MACCS keys and Avalon descriptors all of which are implemented in the RDKit library [22]-[25]. Classification models are expected to be binary class predictors and the corresponding probability of belonging to the positive class is used as an output. However, the regression models can output any continuous value and a suitable transformation should be applied to scale the predictions into the required [0,1] interval. We offer a variety of transformation functions, including sigmoid and double sigmoid as well as step functions for transforming non-continuous components such as the number of hydrogen bond donors and acceptors. We also provide a custom interpolation transformation where the score is transformed by a function that interpolates between user-defined pairs of minima and maxima. The choice of transformation depends on the predicted property or the calculated descriptor. For</p>
<p>properties that are only desirable to lie within a certain range we would seek to apply a double sigmoid transformation to cap the score between the preferred lower and upper bound values resulting in a score of 0 outside and increasing up to 1.</p>
<p>Combining multiple components in a single scoring function presents a typical multiparameter optimization problem. By increasing the number of components, the probability of discovering solutions that achieve maximum score can drop significantly as the different components are likely to pull the MPO score in different directions. Another key aspect is the cumulative uncertainty resulting from the use of multiple predictive models at a time. Even if nearly perfect models are used, combining them will result in geometric amplification of the uncertainty in the outcome of a weighted product formulation. While such an effect would be milder in the weighted sum scenario, the exploration of the chemical space by using multiple predictive models could still be likened to navigating at sea with a slightly broken compass.</p>
<p>In addition to the standard version (eq 3), we offer custom weighted scoring function formulations (eqs 5 and 6) where $\mathrm{P}<em _mathrm_CA="\mathrm{CA">{\mathrm{MS}}$ is a Matching Substructure (MS) component and $\mathrm{P}</em>$ is a Custom Alerts (CA) component. These two are binary penalty components. MS can be used to focus the generation of compounds towards a specific scaffold of interest. It uses a list of SMARTS [26] as an input and it penalizes the overall score if none of the desired substructures is represented in the generated compound. MS produces a score of either 1 or 0.5 depending on whether the scaffold is present or not, thereby being quite helpful for exploitation scenarios. CA can be either 0 or 1 and it also uses a list of SMARTS patterns that normally capture undesired moieties in the generated compounds. If there is a match with any of the listed alerts the overall score will be 0 thus penalizing the future generation of similar compounds. CA can be used also for scaffold hopping if the user is aiming for novelty and wants to avoid certain molecular substructures.
$P(\mathrm{X})=P(X)}<em A="A" C="C">{M S} \times P(X)</em>$} \times\left[\prod_{i} p\left(x_{i}\right)^{w_{i}}\right]^{\frac{1}{\sum_{i} w_{i}}</p>
<p>$S(X)=P(X)<em A="A" C="C">{M S} \times P(X)</em>\right]$} \times\left[\frac{\sum_{i} w_{i} * p\left(x_{i}\right)}{\sum_{i} w_{i}</p>
<p>Another common use case is to try to optimize against a target of interest while simultaneously minimizing the probability of binding to one or more off-targets. For this scenario, we offer a Selectivity Component (SC). SC works with two predictive models: one is used to predict the target activity and another for predicting an off-target activity. If both predictive models are regression type, the difference between the predicted activities $\Delta$ (eq 7) is calculated and consequently subjected to a sigmoid transformation thus forming the SC score. In cases where one of the models is a classifier the regression model prediction is first subjected to transformation and the resulting $\Delta$ is output as an SC score.
$\Delta=P_{\text {activity }}-P_{\text {off-target }}$</p>
<p>In cases where $\Delta&lt;0$, we assign a lower cap of 0.01 since producing 0 for the component would result in a 0 overall score if used with equations 3 or 5 and will not be sufficiently informative for the Agent. Multiple SC can be used when multiple off-targets are possible.</p>
<p>If properly formulated the scoring function will most likely guide the Agent towards a narrow niche of the chemical space, such that yields high MPO scores. As a result, the Agent will become extremely focused over time and ultimately sample only a handful of compounds with high probability. At this stage the scoring function will reach a plateau, the diversity of the generated structures will be minimal and conducting any further RL steps will not yield any new results. In order to generate another batch of novel compounds, we would need to start over and climb the same learning curve over multiple RL steps in order to optimize the scoring function. However, there is no guarantee that the RL process will not converge in a similar chemical space as the previous run. To enforce generative diversity and stimulate the exploration of a broader chemical space, we employ an additional feature in the RL loop - the Diversity Filters (DF).</p>
<p>DF can be regarded as a collection of buckets that are used for keeping track of all generated scaffolds and the compounds that share those scaffolds. Obviously, not all generated compounds are of interest and only those that are scored by the MPO function above a certain threshold will enter the scaffold buckets. Once a compound with a score above the threshold has been generated, its scaffold is extracted and stored in a scaffold registry and the compound enters the corresponding bucket. The buckets have limited capacity and once the limit of compounds in a given bucket has reached the allowed threshold, any subsequent bucket affiliation will be penalized. Every new compound that enters a full bucket will be assigned a score of zero thus informing the Agent that this area of chemical space has become unfavorable. It is important to note that compounds will be added to the bucket even if the bucket limit has been exceeded. The only impact will be on the Agent, since it will be constantly discouraged from producing similar compounds that share a given scaffold. This will enforce the Agent to seek alternative solutions thus achieving in effect chemical space exploration and will prevent the Agent from becoming stuck in local minima and thus generating the same compounds repeatedly. All collected compounds are kept and stored until the end of the RL run and become available as a csv formatted file.</p>
<p>Users can select their diversity strategy by using Topological DF, Identical Murcko DF or a Scaffold Similarity DF [27]. The Topological DF is the most restrictive since it is agnostic of the atom types. It is created by removing all side chains and subsequently converting all atoms in the structure to sp3 carbons. The other two DF also remove all side chains but retain the atom types. Identical Murcko DF only checks if there is a bucket with exactly the same scaffold while Scaffold Similarity is more permissive and can include compounds into the bucket if they satisfy a certain threshold of scaffold similarity.</p>
<h1>Directing the generative process.</h1>
<p>Once the Agent starts generating compounds of sufficiently high MPO score we can define that it has reached a state of productivity. However, starting from a random point in the chemical space and slowly focusing the Agent to a state where it can generate compounds of interest can be a complex and time-consuming task. It could even prove to be an impossible task within a single RL run, especially if the MPO formulation is too complex and has multiple components. To overcome this and to speed up the overall RL process we have identified two approaches that can complement each other.</p>
<h2>Transfer Learning (TL)</h2>
<p>At the beginning of the RL process, the Agent is an identical copy of the Prior. It possesses the same generative capacity and the potential to sample compounds from rather vast area of the chemical space. While this holds a great promise, it can also be an efficiency overhead since for the Agent to become "productive" will first need to find a "rewarding" chemical space. This will have an impact on the RL search for both types of problems: exploitation and exploration, particularly when the MPO score includes multiple conflicting components. To overcome it and to speed up the overall RL process, we resort to pre-focusing the Prior by conducting a TL with a small dataset of compounds sharing features of relevance to our problem. Once focused, the Agent will have an increased probability of sampling a chemical subspace of interest. Such generated compounds will be rewarded higher by the scoring function providing more specific directionality to the generative process. We can use the focused Agent as a starting point for the RL instead of using a copy of the Prior and reach sooner to a state of productivity.</p>
<p>Another way to speed up the transition and reach the state of productivity is by "incepting" compounds that are ranked highly by the scoring function and represent the chemical space of interest. Inception is used in analogy to experience replay in the RL loop. Compounds that we know would be scored highly are introduced to the inception memory before beginning the RL process. At each RL step, a fraction of the inception memory is randomly sampled and is added to the set of compounds generated by the Agent. In this way, early in the RL process, the Agent is presented with highly scoring compounds and will be driven to focus towards the chemical subspace defined by the inception compounds. Also, it will reach a state of productivity sooner. While helpful in the early stages of the training, replaying the compounds that scored well can lead to a very focused Agent. This is particularly likely if the RL run is sufficiently long. For exploration goals it would be best to use it in conjunction with DF since it will prevent excessive focusing by down scoring the repetitive ideas. Inception memory has a limited size and the compounds that are scored lower will be forgotten. The incepted compounds should be ideally from the chemical space of interest with a score below the DF threshold so that they are not discarded instantly.</p>
<p>Inception could be considered as a substitute to TL. However, it is far less efficient in terms of RL steps as it takes longer on average to reach productivity when comparing to starting from a focused Prior state.</p>
<p>Both, Inception and pre-focusing with TL complement each other. We recommend using inception for problems where reaching the state of productivity seems impossible or might take too long due to a very complex scoring function. Another frequent use case is when the number of compounds available for focusing is insufficient to train efficiently a focused prior with TL. In these situations, having a handful of compounds that score well and are frequently presented to the Agent can significantly help to reach the relevant chemical space within a reasonable time.</p>
<h1>Logging</h1>
<p>Essential for monitoring of the learning process is the availability of a comprehensive logging system. In REINVENT we utilize Tensorboard [28] to provide information about the evolution of the Agent during TL by sampling after each step and displaying the likelihood distribution for the sampled data. Stats on validity of the smiles and the most frequently encountered molecules are also shown. For RL we are plotting the evolution of the scoring function and the individual scoring component contributions to the overall score. We are also displaying the highest scoring compounds after each RL step. As an alternative, we also provide the implementation used by us for remote logging which can be set up to post the logging results to a custom REST endpoint.</p>
<h2>Implementation</h2>
<p>REINVENT is an open-source Python application. It uses PyTorch 1.3.0 [29] as a deep learning engine and RDKit version 2019.03.3.0 [30] as a chemistry engine. It works exclusively with scikitlearn based machine learning models and for the detailed logging of the chemical space navigation process, it makes use of Tensorboard's implementation in PyTorch.</p>
<h2>Conclusion</h2>
<p>We have described a production-ready, open-source application for de novo generation of small molecules. It can be used to address both exploration and exploitation type of problems while allowing a flexible formulation of complex MPO scores. Examples of various use cases are provided with the code repository.</p>
<p>Apart from providing a ready-to-use solution, with releasing the code, we are hoping to facilitate the research on using generative methods for drug discovery. We also hope that it can be used as an interaction point for future scientific collaborations.</p>
<h1>References</h1>
<p>[1] J. Arús-Pous et al., "SMILES-Based Deep Generative Scaffold Decorator for De-Novo Drug Design," Jan. 2020, doi: 10.26434/CHEMRXIV.11638383.V1.
[2] A. Zhavoronkov et al., "Deep learning enables rapid identification of potent DDR1 kinase inhibitors," Nat. Biotechnol., vol. 37, no. 9, pp. 1038-1040, Sep. 2019, doi: 10.1038/s41587-019-0224-x.
[3] M. H. S. Segler, T. Kogej, C. Tyrchan, and M. P. Waller, "Generating focused molecule libraries for drug discovery with recurrent neural networks," ACS Cent. Sci., vol. 4, no. 1, pp. 120-131, Jan. 2018, doi: 10.1021/acscentsci.7b00512.
[4] T. Blaschke, M. Olivecrona, O. Engkvist, J. Bajorath, and H. Chen, "Application of Generative Autoencoder in De Novo Molecular Design," Mol. Inform., vol. 37, no. 1-2, p. 1700123, Jan. 2018, doi: 10.1002/minf. 201700123.
[5] R. Gómez-Bombarelli et al., "Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules," ACS Cent. Sci., vol. 4, no. 2, pp. 268-276, Feb. 2018, doi: 10.1021/acscentsci.7b00572.
[6] S. Hochreiter and J. Schmidhuber, "Long Short-Term Memory," Neural Comput., vol. 9, no. 8, pp. 1735-1780, Nov. 1997, doi: 10.1162/neco.1997.9.8.1735.
[7] D. Weininger, "SMILES, a Chemical Language and Information System: 1: Introduction to Methodology and Encoding Rules," J. Chem. Inf. Comput. Sci., vol. 28, no. 1, pp. 31-36, Feb. 1988, doi: 10.1021/ci00057a005.
[8] O. Prykhodko et al., "A de novo molecular generation method using latent vector based generative adversarial network," J. Cheminform., vol. 11, no. 1, p. 74, Dec. 2019, doi: 10.1186/s13321-019-0397-9.
[9] P.-C. Kotsias, J. Arús-Pous, H. Chen, O. Engkvist, C. Tyrchan, and E. J. Bjerrum, "Direct Steering of de novo Molecular Generation using Descriptor Conditional Recurrent Neural Networks (cRNNs)," Nov. 2019, doi: 10.26434/CHEMRXIV. 9860906.V2.
[10] Y. Li, L. Zhang, and Z. Liu, "Multi-objective de novo drug design with conditional graph generative model," J. Cheminform., vol. 10, no. 1, p. 33, Dec. 2018, doi: 10.1186/s13321-018-0287-6.
[11] R. Winter, F. Montanari, A. Steffen, H. Briem, F. Noé, and D. A. Clevert, "Efficient multi-objective molecular optimization in a continuous latent space," Chem. Sci., vol. 10, no. 34, pp. 8016-8024, Aug. 2019, doi: 10.1039/c9sc01928f.
[12] J. Arús-Pous et al., "Randomized SMILES strings improve the quality of molecular generative models," J. Cheminform., vol. 11, no. 1, Nov. 2019, doi: 10.1186/s13321-019-0393-0.
[13] A. Gaulton et al., "The ChEMBL database in 2017," Nucleic Acids Res., vol. 45, no. D1, pp. D945D954, Jan. 2017, doi: 10.1093/nar/gkw1074.
[14] R. S. Sutton and A. G. Barto, "Reinforcement Learning: An Introduction Second edition, in progress."</p>
<p>[15] T. T. Wager, X. Hou, P. R. Verhoest, and A. Villalobos, "Moving beyond rules: The development of a central nervous system multiparameter optimization (CNS MPO) approach to enable alignment of druglike properties," ACS Chem. Neurosci., vol. 1, no. 6, pp. 435-449, Jun. 2010, doi: 10.1021/cn100008c.
[16] M. Olivecrona, T. Blaschke, O. Engkvist, and H. Chen, "Molecular de-novo design through deep reinforcement learning," J. Cheminform., vol. 9, no. 1, p. 48, Dec. 2017, doi: 10.1186/s13321-017-0235-x.
[17] L.-J. Lin, "Self-Improving Reactive Agents Based On Reinforcement Learning, Planning and Teaching," 1992.
[18] D. J. Cummins and M. A. Bell, "Integrating Everything: The Molecule Selection Toolkit, a System for Compound Prioritization in Drug Discovery," J. Med. Chem., vol. 59, no. 15, pp. 6999-7010, Aug. 2016, doi: 10.1021/acs.jmedchem.5b01338.
[19] T. T. . Tanimoto, An elementary mathematical theory of classification and prediction by T.T. Tanimoto | National Library of Australia. .
[20] F. Pedregosa et al., "Scikit-learn: Machine learning in Python," J. Mach. Learn. Res., vol. 12, pp. 2825-2830, Oct. 2011.
[21] T. Chen and C. Guestrin, "XGBoost: A scalable tree boosting system," in Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016, vol. 13-17-August-2016, pp. 785-794, doi: 10.1145/2939672.2939785.
[22] D. Rogers and M. Hahn, "Extended-connectivity fingerprints," J. Chem. Inf. Model., vol. 50, no. 5, pp. 742-754, May 2010, doi: 10.1021/ci100050t.
[23] P. Gedeck, B. Rohde, and C. Bartels, "QSAR - How good is it in practice? Comparison of descriptor sets on an unbiased cross section of corporate data sets," J. Chem. Inf. Model., vol. 46, no. 5, pp. 1924-1936, Sep. 2006, doi: 10.1021/ci050413p.
[24] H. L. Morgan, "The Generation of a Unique Machine Description for Chemical Structures-A Technique Developed at Chemical Abstracts Service," J. Chem. Doc., vol. 5, no. 2, pp. 107-113, May 1965, doi: 10.1021/c160017a018.
[25] J. L. Durant, B. A. Leland, D. R. Henry, and J. G. Nourse, "Reoptimization of MDL Keys for Use in Drug Discovery," ACS Publ., vol. 42, no. 6, pp. 1273-1280, Nov. 2002, doi: 10.1021/ci010132r.
[26] "Daylight Theory: SMARTS - A Language for Describing Molecular Patterns." [Online]. Available: https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html. [Accessed: 12-Feb-2020].
[27] G. W. Bemis and M. A. Murcko, "The properties of known drugs. 1. Molecular frameworks," J. Med. Chem., vol. 39, no. 15, pp. 2887-2893, Jul. 1996, doi: 10.1021/jm9602928.
[28] M. Abadi et al., "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems."
[29] A. Paszke et al., "Automatic differentiation in PyTorch."
[30] L. G., "RDKit." [Online]. Available: http://www.rdkit.org/. [Accessed: 12-Feb-2020].</p>            </div>
        </div>

    </div>
</body>
</html>