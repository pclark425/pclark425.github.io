<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6841 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6841</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6841</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-271974615</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2408.15512v2.pdf" target="_blank">Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations</a></p>
                <p><strong>Paper Abstract:</strong> The advent of Large Language Models (LLMs) has created new opportunities for the automation of scientific research, spanning both experimental processes and computational simulations. This study explores the feasibility of constructing an autonomous simulation agent (ASA) powered by LLM, through sophisticated API integration, to automate the entire research process, from experimental design, remote upload and simulation execution, data analysis, to report compilation. Using a simulation problem of polymer chain conformations as a case study, we assessed the performance of ASAs powered by different LLMs including GPT-4-Turbo. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on designated research missions, underscoring the potential of LLMs to manage complete scientific investigations autonomously. The outlined automation can be iteratively performed up to twenty cycles without human intervention, illustrating the potential of LLMs for large-scale autonomous research endeavors. Additionally, we discussed the intrinsic traits of ASAs in managing extensive tasks, focusing on self-validation mechanisms and the balance between local attention and global oversight.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6841.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6841.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs-for-chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models applied to chemical synthesis, property prediction, and materials generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper mentions use of general-purpose LLMs (e.g., GPT-4, Claude, Galactica) to assist in chemical synthesis planning, chemical property prediction, and de novo materials generation, often when integrated with specialized chemical tools and databases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4, Claude, Galactica (examples cited in introduction)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>general-purpose large language model (text-generation LLM); mentioned use with tool-augmented pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>prompting / LLM-guided generation and planning; integration with external chemical tools suggested (no experiment in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>chemical synthesis planning, chemical property prediction, generation of new materials (general)</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>paper states 'integrating LLMs with specialized chemical tools and databases' can extend capabilities, but does not list specific tools in this work</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper notes general limitations of LLMs for domain-specialized tasks: lack of specialized domain knowledge, tendency to overlook requirements or 'take shortcuts', persistent error/debugging loops due to reliance on dialogue history, hallucinations, and need for memory/attention management; also highlights that augmentation with domain tools/databases is necessary to extend capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6841.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6841.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GuacaMol</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GuacaMol: Benchmarking Models for de Novo Molecular Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GuacaMol is cited in the paper as an established benchmark for de novo molecular design models (mentioned among chemical generative/modeling literature).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GuacaMol: Benchmarking Models for de Novo Molecular Design.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>de novo molecular design benchmarking</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>GuacaMol is a benchmarking framework (implicit metrics include validity/uniqueness/novelty and task-specific objectives) but this paper does not list specific metrics from GuacaMol</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6841.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6841.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Stokes2020</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A deep learning approach to antibiotic discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced as an example where deep learning methods discovered novel antimicrobial compounds; cited as part of the broader AI-in-chemistry literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A deep learning approach to antibiotic discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>deep learning for molecular discovery (mentioned in related work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>antibiotic discovery / small-molecule drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6841.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6841.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Boiko2023</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as prior work demonstrating autonomous chemical research driven by LLMs; used as related work to situate the present ASA simulation-focused study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LLM-driven autonomous research agent (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM-driven planning and experiment orchestration (as referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>autonomous chemical research workflows (general)</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper references autonomy and integration challenges generally but does not enumerate specifics for Boiko et al within this text</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6841.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6841.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bran2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Augmenting large language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced as work that augments LLMs with chemistry-specific tools to extend their capabilities beyond pure language tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting large language models with chemistry tools.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>tool-augmented LLM (mentioned as related work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM + chemistry tool integration (explicitly referenced conceptually)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>chemical tasks requiring domain-specific computations or data access</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>paper notes utility of integrating with specialized chemical tools/databases; this reference likely details such integrations but the present paper does not enumerate them</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6841.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6841.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatMOF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as an example of an LLM system used to predict and generate metal-organic frameworks (MOFs).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LLM-based generative/predictive model for materials (MOFs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM-driven generation/prediction (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>metal-organic frameworks (materials generation/prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6841.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6841.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Jablonka2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Leveraging large language models for predictive chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as a recent review/position paper discussing the use of LLMs for predictive tasks in chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Leveraging large language models for predictive chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LLM applied to predictive chemistry (review/position context)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>predictive chemistry tasks (property prediction, reaction outcomes, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper cites broad challenges when applying general LLMs to chemistry (need for tool augmentation, domain data, and careful prompt engineering) as part of motivating background</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GuacaMol: Benchmarking Models for de Novo Molecular Design. <em>(Rating: 2)</em></li>
                <li>A deep learning approach to antibiotic discovery. <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models. <em>(Rating: 2)</em></li>
                <li>Augmenting large language models with chemistry tools. <em>(Rating: 2)</em></li>
                <li>ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models. <em>(Rating: 2)</em></li>
                <li>Leveraging large language models for predictive chemistry. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6841",
    "paper_id": "paper-271974615",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "LLMs-for-chemistry",
            "name_full": "Large Language Models applied to chemical synthesis, property prediction, and materials generation",
            "brief_description": "The paper mentions use of general-purpose LLMs (e.g., GPT-4, Claude, Galactica) to assist in chemical synthesis planning, chemical property prediction, and de novo materials generation, often when integrated with specialized chemical tools and databases.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-4, Claude, Galactica (examples cited in introduction)",
            "model_type": "general-purpose large language model (text-generation LLM); mentioned use with tool-augmented pipelines",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "prompting / LLM-guided generation and planning; integration with external chemical tools suggested (no experiment in this paper)",
            "chemical_representation": null,
            "target_application": "chemical synthesis planning, chemical property prediction, generation of new materials (general)",
            "constraints_used": null,
            "integration_with_external_tools": "paper states 'integrating LLMs with specialized chemical tools and databases' can extend capabilities, but does not list specific tools in this work",
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": "Paper notes general limitations of LLMs for domain-specialized tasks: lack of specialized domain knowledge, tendency to overlook requirements or 'take shortcuts', persistent error/debugging loops due to reliance on dialogue history, hallucinations, and need for memory/attention management; also highlights that augmentation with domain tools/databases is necessary to extend capabilities.",
            "uuid": "e6841.0",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "GuacaMol",
            "name_full": "GuacaMol: Benchmarking Models for de Novo Molecular Design",
            "brief_description": "GuacaMol is cited in the paper as an established benchmark for de novo molecular design models (mentioned among chemical generative/modeling literature).",
            "citation_title": "GuacaMol: Benchmarking Models for de Novo Molecular Design.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": null,
            "model_size": null,
            "training_data_description": null,
            "generation_method": null,
            "chemical_representation": null,
            "target_application": "de novo molecular design benchmarking",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": "GuacaMol is a benchmarking framework (implicit metrics include validity/uniqueness/novelty and task-specific objectives) but this paper does not list specific metrics from GuacaMol",
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6841.1",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Stokes2020",
            "name_full": "A deep learning approach to antibiotic discovery",
            "brief_description": "Referenced as an example where deep learning methods discovered novel antimicrobial compounds; cited as part of the broader AI-in-chemistry literature.",
            "citation_title": "A deep learning approach to antibiotic discovery.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "deep learning for molecular discovery (mentioned in related work)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": null,
            "chemical_representation": null,
            "target_application": "antibiotic discovery / small-molecule drug discovery",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6841.2",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Boiko2023",
            "name_full": "Autonomous chemical research with large language models",
            "brief_description": "Cited as prior work demonstrating autonomous chemical research driven by LLMs; used as related work to situate the present ASA simulation-focused study.",
            "citation_title": "Autonomous chemical research with large language models.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "LLM-driven autonomous research agent (related work)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "LLM-driven planning and experiment orchestration (as referenced)",
            "chemical_representation": null,
            "target_application": "autonomous chemical research workflows (general)",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": "Paper references autonomy and integration challenges generally but does not enumerate specifics for Boiko et al within this text",
            "uuid": "e6841.3",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Bran2024",
            "name_full": "Augmenting large language models with chemistry tools",
            "brief_description": "Referenced as work that augments LLMs with chemistry-specific tools to extend their capabilities beyond pure language tasks.",
            "citation_title": "Augmenting large language models with chemistry tools.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "tool-augmented LLM (mentioned as related work)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "LLM + chemistry tool integration (explicitly referenced conceptually)",
            "chemical_representation": null,
            "target_application": "chemical tasks requiring domain-specific computations or data access",
            "constraints_used": null,
            "integration_with_external_tools": "paper notes utility of integrating with specialized chemical tools/databases; this reference likely details such integrations but the present paper does not enumerate them",
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6841.4",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "ChatMOF",
            "name_full": "ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models",
            "brief_description": "Cited as an example of an LLM system used to predict and generate metal-organic frameworks (MOFs).",
            "citation_title": "ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "LLM-based generative/predictive model for materials (MOFs)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "LLM-driven generation/prediction (mentioned)",
            "chemical_representation": null,
            "target_application": "metal-organic frameworks (materials generation/prediction)",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6841.5",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Jablonka2024",
            "name_full": "Leveraging large language models for predictive chemistry",
            "brief_description": "Cited as a recent review/position paper discussing the use of LLMs for predictive tasks in chemistry.",
            "citation_title": "Leveraging large language models for predictive chemistry.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "LLM applied to predictive chemistry (review/position context)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": null,
            "chemical_representation": null,
            "target_application": "predictive chemistry tasks (property prediction, reaction outcomes, etc.)",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": "Paper cites broad challenges when applying general LLMs to chemistry (need for tool augmentation, domain data, and careful prompt engineering) as part of motivating background",
            "uuid": "e6841.6",
            "source_info": {
                "paper_title": "Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations",
                "publication_date_yy_mm": "2024-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GuacaMol: Benchmarking Models for de Novo Molecular Design.",
            "rating": 2,
            "sanitized_title": "guacamol_benchmarking_models_for_de_novo_molecular_design"
        },
        {
            "paper_title": "A deep learning approach to antibiotic discovery.",
            "rating": 2,
            "sanitized_title": "a_deep_learning_approach_to_antibiotic_discovery"
        },
        {
            "paper_title": "Autonomous chemical research with large language models.",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Augmenting large language models with chemistry tools.",
            "rating": 2,
            "sanitized_title": "augmenting_large_language_models_with_chemistry_tools"
        },
        {
            "paper_title": "ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models.",
            "rating": 2,
            "sanitized_title": "chatmof_an_artificial_intelligence_system_for_predicting_and_generating_metalorganic_frameworks_using_large_language_models"
        },
        {
            "paper_title": "Leveraging large language models for predictive chemistry.",
            "rating": 2,
            "sanitized_title": "leveraging_large_language_models_for_predictive_chemistry"
        }
    ],
    "cost": 0.010006749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations
16 Sep 2024</p>
<p>Zhihan Liu 
Yubo Chai 
Jianfeng Li 
Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations
16 Sep 202404BFC72E796431FF632577D5E3EDC2C8arXiv:2408.15512v2[cs.AI]autonomous researchsimulationLLMpolymer physics
The advent of Large Language Models (LLMs) has created new opportunities for the automation of scientific research, spanning both experimental processes and computational simulations.This study explores the feasibility of constructing an autonomous simulation agent (ASA) powered by LLM, through sophisticated API integration, to automate the entire research process, from experimental design, remote upload and simulation execution, data analysis, to report compilation.Using a simulation problem of polymer chain conformations as a case study, we assessed the performance of ASAs powered by different LLMs including GPT-4-Turbo.Our findings revealed that ASA-GPT-4o achieved near-flawless execution on designated research missions, underscoring the potential of LLMs to manage complete scientific investigations autonomously.The outlined automation can be iteratively performed up to twenty cycles without human intervention, illustrating the potential of LLMs for large-scale autonomous research endeavors.Additionally, we discussed the intrinsic traits of ASAs in managing extensive tasks, focusing on self-validation mechanisms and the balance between local attention and global oversight.</p>
<p>INTRODUCTION</p>
<p>In recent years, the rapid development of artificial intelligence technology, particularly the emergence of large language models (LLMs), has brought revolutionary changes to scientific research [1][2][3][4][5] .Since the launch of ChatGPT by OpenAI, LLMs such as GPT-4 and Anthropic's Claude have demonstrated outstanding performance in natural language processing, text generation, and translation 6,7 .These AI models not only excel in traditional text processing tasks but also show significant potential in scientific research, gradually transforming conventional research methods and providing scientists with unprecedented tools and methodologies [8][9][10][11] .</p>
<p>The application of artificial intelligence (AI) in the fields of chemistry and materials engineering is continually expanding.By integrating machine learning and automated experimental technologies, faster experimental design and data analysis can be achieved, leading to the discovery of new materials and the optimization of existing material properties in a shorter timeframe [12][13][14] .In the domain of physical chemistry knowledge parsing, Meta's Galactica assists researchers with tasks such as information organization, knowledge inference, and writing, showcasing the immense potential of large language models in scientific and professional domains 13 .Meanwhile, DeepMind's AlphaFold series of algorithms enable the prediction of structures for biological molecules, from proteins and nucleic acids to larger and more complex complexes 15,16 .In the fields of chemical synthesis and drug design, AI aids in complex chemical synthesis planning, chemical property prediction, and the generation of new materials.Integrating LLMs with specialized chemical tools and databases can extend their capabilities beyond general language tasks [17][18][19][20][21] .Additionally, some studies have highlighted the crucial role of prompt engineering in guiding models to produce aca The State Key Laboratory of Molecular Engineering of Polymers, The Research Center of AI for Polymer Science Department of Macromolecular Science, Fudan University, Shanghai 200433, China; E-mail: * lijf@fudan.edu.cncurate and useful outputs.Techniques such as Chain of Thought, ReAct, and Tree of Thoughts help structure the model's reasoning process, reduce errors, and improve the quality of generated results 20,[22][23][24] .</p>
<p>Recent research shows that continuous human-AI interaction can accelerate various stages of scientific research.However, this human-led, AI-assisted model still limits the speed and depth of scientific research.Some work has explored an AI-dominated research model, such as smart laboratories (SDLs) that integrate AI, laboratory automation, and robotics to conduct autonomous experiments.These systems can automatically adjust and optimize based on intelligent analysis and decision-making support from experimental results [25][26][27] .The ultimate goal for future AI scientists is to achieve full automation of scientific research processes, from experimental design to data analysis and conclusion generation.This end-to-end automation is set to become a major development in chemical research and a primary objective in chemical engineering, including both experimental and simulation aspects.This paper explores the AI automation paradigm in polymer theory simulation research.In traditional simulation research, a supervisor typically discusses and plans the research project with students.The students then write and modify the simulation program based on physical models, run simulations under different parameter conditions on remote servers, collect data, analyze results, and write reports.This paper envisions a new research paradigm where, after the research has been planned, the subsequent tasks are solely carried out by AI.Using an autonomous simulation agent (ASA) powered by LLM, after human researchers input a research plan (RP), the ASA will then take on the role of the student to complete the entire research process.Humans only need to review the AI's results at the end, thus achieving a research mode without human intervention.</p>
<p>To test this research paradigm, we systematically attempted ASAs powered by different LLMs on a moderately complex simulation problem in polymer physics.This involved an AI fully autonomously coding the simulation program, remote uploading and executing simulations, data organization, plotting, and scientific report writing.</p>
<p>Random walk and self-avoiding walk models are of significant physical importance in describing the spatial configuration of polymer chains.The random walk model assumes that each 'step' of the chain is independent and random, while the self-avoiding walk model considers the volume exclusion effects between chain segments.Therefore, they exhibit different dynamic behaviors and scaling properties, with different scaling relationships between the mean square end-to-end distance and the number of chain segmentss N.This scaling relationship has been theoretically derived by Flory, De Gennes, and others 28,29 and validated through simulations and experiment 30,31 .This problem is fundamental in polymer physics and has been extensively studied.However, for AI, it still presents a novel challenge.The difficulty of predicting the scaling exponent makes it neither too easy nor prohibitively difficult, thus serving as an excellent model problem for testing AI capabilities.We prompted the AI to write simulation programs for both random walk and self-avoiding walk models, compute the mean square end-to-end distance for different chain segment numbers N, fit the results to R 2  N  , determine the scaling exponent , plot the data, and write a complete scientific report.</p>
<p>The ASA leverages an API automation program (AutoProg) to enable multi-round text interactions with LLMs via API (Figure 1).Initially, the AutoProg provides an RP witten by human researchers to an LLM, and the LLM will break the plan down into multiple sub-tasks and write Python code to complete the first sub-task in its response.The AutoProg then extracts the Python code, executes it, and returns the execution results and any errors along with the conversation history back to the LLM.The LLM then decide whether to modify the Python code or to proceed to the following sub-tasks.This process repeats until the LLM determines that the mission is complete, at which point the AutoProg stops.Upon mission completion, humans evaluate its success based on criteria such as correct simulation, plotting, etc.The ASA we developed is a general system (minor adjustments may be required in the AutoProg for different LLM APIs) that requires only a change in the original RP to be applicable to any simulation problem involving Python programming.In addition to the RPs designed for polymer conformation simulations, we have also crafted RPs for solar system planetary orbit simulations and asteroid trajectory simulations (Figure 1C and SI).</p>
<p>We compared the performance of ASAs powered by various LLMs, including GPT-4o, and explored common characteristics and issues when LLMs tackle long tasks.These findings provide insights for researchers to better improve and utilize LLMs for AIdriven scientific research.</p>
<p>Overall, this paper presents the first fully autonomous AIconducted simulation research process powered by LLMs.As demonstrated in the demo video, simply submitting a research plan file via the command 'do AI4S_prj1.txt'to ASA allows it to execute all subsequent tasks without any human intervention; ASA can even automatically upload programs to a remote server and perform a series of simulations--something that cannot be achieved solely through interactions with a web-based LLM.By adopting this new research paradigm, we aim to explore the potential of AI in highly complex and data-intensive scientific research, breaking traditional human limitations and advancing the automation and intelligence of scientific research.</p>
<p>Results</p>
<p>Automating Basic Simulations in Research</p>
<p>We designed three simulation missions related to polymer chain conformation modeling to demonstrate and test the ability of ASAs powered by different LLMs to autonomously complete the entire research process.Each mission includes multiple sub-tasks, covering the full spectrum from conducting experiments to analyzing data and writing reports.The research plans (RPs) for these missions are shown in Figure 2.Among these RPs, RP 1 is the simplest involving only basic research steps for simulations given below.</p>
<p> RP 1 requires generating a Python program to simulate a random walk, sampling different numbers of chain segments N, deriving the scaling relation R 2  N v , saving chain conformation graphs and scaling relation fit plots, and writing a research report.</p>
<p>We established several evaluation criteria based on the requirements of the RP, such as whether graphs and plots were generated and whether the derived scaling relationships were correct, to assess task completion.We tested nine ASAs powered by different LLMs, including GPT-4o, conducting 20 trials for each RP and recording the achievement of the evaluation criteria across these trials, as shown in Figure 3.</p>
<p>ASA-GPT-4o and ASA-GPT-4-Turbo excelled on RP 1, achieving near-perfect completion in both simulation and report writing tasks (Figure 3B).ASA-Claude-3.5 and ASA-Qwen-2 followed, performing well in simulation tasks but sometimes generating reports in response or as text files, failing to meet RP 1's requirements.Other models performed well in plotting graphs but lacked accuracy in establishing correct physical models and deriving correct scaling values through simulations.</p>
<p>Although chain conformation simulations are convenient for comparing different LLMs, they are less convincing due to being previously well-studied topics.To make a stronger case, we need more challenging problems.Additionally, to demonstrate that ASA can solve problems across different scientific domains, we designed RPs for gravitational simulation problems corresponding to RP S1 and RP S2 (Figure S2 and Figure 1C).The mission of RP S2 is to evaluate the risk posed by a meteorite (or asteroid) to earth, given its initial position and velocity and write a report.This mission is challenging even for graduates from physics departments.By simply inputting RP S2 into the same ASA used for chain conformation problems, the ASA will automatically acquire the necessary parameters of the solar system, code the simulation program to calculate the asteroid's trajectory, and ultimately write the report.This result underscores the effectiveness of our API programming strategy (see Method section) and strongly demonstrates that ASA can address problems in entirely different fields.</p>
<p>Automating Simulations with Remote Server Operations and Volume Exclusion</p>
<p>RP 2 increases complexity with server interactions and RP 3 dou-bles the mission length and simulation difficulty.Brief introductions of these two RPs are shown below (Figure 2).</p>
<p> RP 2 directly provides a random walk simulation program, asking the ASA to modify it, run simulations in a designated folder on a remote server, download the experimental data, and generate graphs and plots and a research report.</p>
<p> RP 3 is similar to RP 1 but includes both random walk and self-avoiding walk simulations.</p>
<p>For RP 2, which involves remote upload and remote simulations, completion rates across ASAs significantly declined, with some agents consistently failing across multiple trials.ASA-Claude-3.5 achieved the highest completion rate, successfully completing the entire mission, including generating all required graphs in over two-thirds of trials, though it occasionally missed displaying some generated graphs in the report.ASA-GPT-4o, ASA-GPT-4-Turbo, and ASA-Qwen-2 also demonstrated some success in solving complex missions over 20 trials (Figure 3).</p>
<p>RP 3 required simulating a self-avoiding walk based on the random walk simulation in RP 1.Although the process was longer, it was less complex than RP 2, resulting in improved performance across agents.ASA-GPT-4o, ASA-GPT-4-Turbo, ASA-Claude-3.5, and ASA-Gemini-1.5-Properformed relatively well.Notably, none of the agents provided a correct self-avoiding scaling due to incorrect sampling methods during simulation, which will be discussed in detail in the Discussion section.</p>
<p>Moreover, ASA-GPT-4o and ASA-Claude-3.5 demonstrated unique advantages in generating rich content.They frequently produced detailed reports exceeding 1,000 words, delving into the distinctions between RW and SA scaling, and occasionally included precise literature citations.ASA-Claude-3.5 referenced accurate self-avoiding walk scaling relationships validated through theoretical derivations and experimental verifications, accompanied by brief analyses of simulation result deviations.Additionally, ASA-GPT-4o presented experimental data in enriched formats, such as frequency distribution plots of end-to-end distances and interactive web-based charts.</p>
<p>Automating Agent Coordination through RP Generation</p>
<p>In the preceding section, RPs were provided by humans.In this section, we task a Main AI with automatically breaking down a human-provided RP into sub-tasks and distributing them as AI RPs to several Subordinate AIs.</p>
<p>We provided RP 1 and 2 directly to the Master AI, adjusting the ASA to ensure each sub-task was handled by a distinct Subordinate AI without access to the Main AI's or other Subordinate AIs' conversation histories.The Main AI solely presents the AI RPs (Figure S1A) and received reports upon task completion.</p>
<p>We also employed GPT-4-turbo for this experiment.The results (SI-data-2) revealed that for RP 1, the Main AI effectively decomposes the mission into sub-tasks and successfully distributed them to Subordinate AIs, thereby completing RP 1.However, for RP 2, the Main AI encounters repeated failures.The primary issue lies in precise information transmission.RP 2 provides a random walk simulation program and details of a remote server, including hostname and username.Despite multiple attempts, the Main AI struggles to convey both the simulation program and server details accurately to the Subordinate AIs (Figure S1B).We attempted to instruct the Main AI to include all relevant information in the AI RPs, but this did not notably enhance the accuracy of information transmission.Additionally, we observed instances where AI RPs contained irrelevant information, potentially confusing the Subordinate AIs about the mission's focus.</p>
<p>Automating the Automation: Crafting Multi-tier RPs for Large-Scale Research</p>
<p>Back in the Automating Basic Simulations section, for each ASA and each RP, we undertake 20 rounds of 'automation' by executing RP 1 and collecting the results including codes and files generated by the ASA.Can we automate the entire process of this study on reaserch automation or can we even automate the automation itself?RP 4 is designed for this purpose.It is nested within RP 1, instructing the Primary AI to execute the command "python Au-toProg.py-s p1.txt -n i" 20 times.Each execution generates an Agent AI to fulfill RP 1 contained in p1.txt, while the Primary AI collects all generated files and conducts result analysis.The detailed content of RP 4 is depicted in Figure S1C.</p>
<p>Using ASA-GPT-4-Turbo, we conducted tests on RP 4. The results (SI) strikingly demonstrate that the Primary AI successfully executed the 20 instances of RP 1, meticulously organizing all files into their respective folders and providing a brief summary after all experiments.During this process, the AI independently and without interruption wrote 66 programs (including 26 error versions), conducted more than 20 simulations, generated 120 images, and wrote 20 research reports totaling over 5,000 words.Marvelously, all these missions were accomplished without any human intervention.This illustrates the remarkable capability of multi-tier RP structures in handling large-scale missions.</p>
<p>Discussion</p>
<p>The experiments demonstrate that LLMs, with their robust coding ability 24,[32][33][34] , can be directly employed in developing agents to autonomously complete complex research missions when aided by proper API programming.ASA-GPT-4o and ASA-GPT-4-turbo, notably, exhibits near-perfect completion rates for simpler missions, highlighting their potential.Multi-tier RP designs effectively handle more complex missions, though accurate information transmission remains challenging for such RPs.We emphasize that these simulation tasks, particularly those involving remote server execution, cannot be accomplished through interactions with web-based LLMs alone.</p>
<p>Enhancements in RP design and AI coordination are essential for fully harnessing AI's potential in automating scientific research.Below, we discuss the insights and existing problems identified in the current research.</p>
<p>Recommended Practices for Fully Autonomous Research</p>
<p>ASA achieves fully autonomous research through continuous interaction with the LLM according to a specific logical design guided by the research plan (RP) provided by the researchers.We have identified several key practices in ASA logic design and RP design to enhance execution success rates.</p>
<p> Structure agent responses for efficient code and task extraction.Require the LLM to produce structured outputs, enabling ASA to accurately extract Python code, subtasks, and progress indicators.This improves code execution success rates and ensures smooth mission progression.</p>
<p> Incorporate agent-led code review and debugging.While the LLM is powerful in code generation, it may struggle with complex programs on the first attempt.By integrating selfreview and debugging process, the LLM can generate correct and task-compliant code within several dialogue rounds.</p>
<p> Ensure key outputs at each subtask step for continuity.</p>
<p>Long missions often need to be divided into subtasks.To maintain coherence, prompt the LLM to consider previous outputs, generate key results for each step and input key results into the proceeding round of dialogue, facilitating the continuation of subsequent tasks and allowing the agent to monitor overall progress.</p>
<p> Provide detailed information for complex operations like remote server connections.Providing sufficient information in RP can improve mission success rates.In addition to necessary numeric/textual information, sometimes offering specific methods can guide the LLM to write correct programs more efficiently.</p>
<p>In summary, while the LLM has strong generative capabilities, its unpredictable outputs can complicate automation.ASA, based on Python's AutoProg, though less intelligent, is reliable when logic is well-designed.By effectively structuring logic, ASA can oversee the LLM's output, enhancing process reliability and achieving fully autonomous research.</p>
<p>Common Issues in Sequential Task</p>
<p>Despite varying completion rates among tested ASAs, their errors and failure points share common characteristics, reflecting the inherent logical features of LLMs.</p>
<p>First, some ASAs tend to overlook parts of the RP's requirements or "take shortcuts", not fully following the RP's instructions.For instance, they might skip plotting, fail to write a report, or ask humans to execute part of the task.These issues affect mission completeness and can disrupt the entire workflow.To improve autonomy in AI for science, we need to address these issues by continuously generating outputs describing the current mission status, periodically reviewing generated data, and confirming strict adherence to mission requirements.These improvements can be integrated through AutoProg modifications or by incorporating them into the "system" prompt input to LLMs or fine-tuning the LLMs.</p>
<p>Second, ASAs often underperform on technical aspects of tasks due to a lack of specialized domain knowledge.For example, when simulating a random walk, the algorithm needs to generate unit vectors uniformly distributed on a sphere to ensure isotropy.Although ASAs can often generate spatially random unit vectors, they fail to ensure uniform distribution on the sphere.</p>
<p>In another example, for simulating self-avoiding walks, ASAs often incorrectly extend the random walk strategy by merely checking distances between points, resulting in high-energy state samples with large statistical errors.Correct sampling should use importance sampling to generate statistically significant conformations 35 .To avoid these issues in research, reliable solutions should be provided in the RPs, or relevant domain knowledge should be used for fine-tuning the LLMs to enhance their understanding.</p>
<p>Error Loops in Debugging</p>
<p>Each AutoProg involves a Python code debugging process.When bugs are detected, the LLM receives error messages and attempts to revise the code, iterating until it executes correctly.However, we've noted instances where the LLM struggles to generate functional code, resulting in mission failures.This typically occurs when the LLM becomes "stuck" after repeated unsuccessful debugging attempts, cycling through the same erroneous code without progress.</p>
<p>This phenomenon may be associated with the LLM's propensity to depend heavily on past dialogue content.Research has documented instances where LLMs utilize context to deliver responses preferred by users, indicating an excessive reliance on previous information [36][37][38] .While this capability allows LLMs to adapt responses based on short dialogue histories, it can also lead to persistent errors.</p>
<p>In our experiments, to prevent such deadlocks, we implemented a maximum debug attempt limit.Once this limit is reached, the AutoProg returns a "mission failed" message.To ensure the smooth execution of concrete research missions, it is crucial to avoid these debugging loops.One solution involves clearing parts of the memory after a certain number of debug attempts or encouraging the LLM to generate varied content in each iteration (Some LLMs include parameters to avoid generating duplicate content and to adjust the creativity of the models.).</p>
<p>Balancing Global Oversight and Local Attention</p>
<p>In our experiments, ASAs exhibited a significant level of global oversight, which allows them to track mission progress based on the dialogue history.They can retain details from earlier stages of missions even after focusing on lengthy sub-tasks.However, as discussed above, ASAs occasionally skip steps in prolonged missions or fail to deliver comprehensive solutions for sub-tasks, indicating a lack of sufficient local attention.</p>
<p>Achieving successful and precise mission completion requires a delicate balance between global oversight and local attention, two perspectives that are normally conflicting.</p>
<p>In Automating Agent Coordination section, we designed a collaboration plan where a Main AI and some Subordinate AIs handled different aspects of the mission: the Main AI defined sub-task requirements and received reports, while Subordinate AIs focused on specific sub-tasks.This approach minimized redundant information in their dialogue history, enhancing the Main AI's global awareness and the Subordinate AIs' local attention.While the Main AI effectively completed the mission in RP 1, the Main-Sub AI model encountered challenges in RP 2 due to the failure of precise information transmission.One potential optimization is to involve human-designed RPs distributed among various Subordinate AIs for execution.</p>
<p>Limitations and Next Steps</p>
<p>This study demonstrates the capability of LLM powered research agent ASA to independently undertake sophisticated simulation research missions, using a well-recognized polymer physics simulation problem and a more challenging celestial-simulation problem as representative examples.However, there remains ample opportunity to explore ASA's potential in tackling novel scientific challenges.Additionally, this study focuses on presenting an automated workflow, leaving room for further optimization of prompts and automation programs.</p>
<p>Several inherent limitations of ASAs were identified: (1) ASAs may overlook mission requirements, necessitating methods to prioritize critical information; (2) general LLMs lack specialized do-main knowledge, requiring supplementary information in RPs;</p>
<p>(3) LLMs may persist in errors by relying too heavily on previous content, requiring memory management strategies in ASAs' development; (4) balancing global awareness and local attention poses a challenge; (5) accurately transmitting specific information remains problematic.</p>
<p>Addressing these issues is crucial for enhancing the role of AI in scientific research.This requires a thorough analysis of these limitations and adjustments to research methodologies and LLM capabilities, leveraging their strengths while mitigating their weaknesses.</p>
<p>Conclusion</p>
<p>This study demonstrates the potential of LLM powered research agent ASA to autonomously conduct scientific research missions, using a polymer theory simulation problem and a more challenging asteroid-trajectory prediction problem as model problems.This process, encompassing simulation coding, remote execution, data analysis, and report generation, represents the first fully autonomous AI-directed simulation research: once the research plan is made, only a single command (e.g., 'do prj.txt') is required to initiate and complete the process.The notable success herein can be largely attributed to the sophisticated API programming.Agents such as ASA-GPT-4o demonstrate high completion rates for missions, a strong grasp of task requirements, and consistent alignment with overall objectives across extensive tasks.Notably, the performance exhibited in completing RP 4, entailing a hierarchy of nested tasks, surpassed expectations in a significant manner.These capabilities underscore the readiness of ASAs to independently manage long-term scientific research missions, offering a new perspective on AI applications in science as well as in chemical engineering.</p>
<p>Methods</p>
<p>API automation Program (AutoProg)</p>
<p>Based on the official documentation of various LLMs, we implemented the API automation programs (AutoProg) by configuring Python API calling methods and setting up the local environment.This setup included installing necessary Python packages like numpy, matplotlib, paramiko, and python-docx tailored for our simulation tasks.An AutoProg serves dual functions: 1) it engages in dialogue with the LLM via the API and preserves all historical dialogues, and 2) it extracts and executes Python programs generated by the LLM in response to prompts.</p>
<p>For instance, in the case of RP 1, an AutoProg initiates the automated research process by reading mission requirements saved in a txt file.It then calls the API to transmit the RP to the LLM, instructing it to generate a comprehensive Python program.The AutoProg extracts this program from the LLM's response, sends it back to the LLM via the API along with entire dialogue history, and requests error checking and compliance verification against mission requirements.Subsequently, the AutoProg executes the validated Python program, capturing and storing output or errors.In case of errors, the AutoProg sends the prior dialogues and program errors back to the LLM, asking for modifications.This process repeats until the program runs correctly.If errors persist beyond a predefined threshold, the AutoProg halts with a "mission failed" output.Conversely, upon successful execution, it returns the program output to the LLM, prompting it to check the dialogues and files in the working directory to determine the task progress.If the task remains incomplete, the next Python program will be generated by the LLM to continue the mission, iterating through checking and debugging processes until completion.When the mission achieves full execution, the AutoProg concludes with a "mission complete" output.</p>
<p>AutoProg.py and RP.txt, containing predefined instructions, are stored in the local working directory.To initiate the automated research process for each experiment, users navigate to the directory via the command line (CMD) and execute commands such as "python AutoProg.py-s RP.txt".Alternatively, AutoProg can be elevated to a command by creating a batch file (Windows) or shell script (Linux), allowing users to simply enter "AutoProg RP.txt" from any directory to execute it.A detailed video record-ing of the execution process is available for reference (SI-video), in which a batch file is used to facilitate the execution by running the command "do AI4S_prj1.txt".</p>
<p>To evaluate LLM performance across RP 1-3, each ASA underwent 20 tests per RP, with all generated files and AutoProg outputs saved.Sample results are provided in the data (SI-data-1).</p>
<p>ASA Scoring via EWM and TOPSIS</p>
<p>To evaluate the performance of ASAs on designated RPs, we devised specific criteria for RP 1-3, including diagram generation, report composition, etc.Through systematic observation across multiple trials, we recorded each agent's fulfillment against these criteria.For quantitative analysis and scoring, we deployed the Entropy Weight Method (EWM) and TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution).</p>
<p>The EWM, a well-established approach for determining the relative significance of criteria in decision-making 39 , was utilized to assign weights based on data variability.This ensures criteria with higher variability, and thus more informational value, receive higher weights in the final evaluation.TOPSIS, originally formulated by Hwang and Yoon 40 , was subsequently applied.This method computes the geometric distance between each agent's performance and both ideal and anti-ideal solutions, facilitating a comparative assessment of ASA efficacy.</p>
<p>The evaluation procedure is delineated as follows.</p>
<p>Initially, fulfillment data for all ASAs across various criteria were gathered over 20 trials, encapsulated in matrix X, wherein x i j signifies the frequency of criterion j's attainment by agent i. Normalization was then performed on x i j : r i j =</p>
<p>x i j  min(x i j ) max(x i j )  min(x i j )</p>
<p>,</p>
<p>yielding the normalized matrix R = [r i j ].Subsequently, criterion weights were established utilizing EWM.The relative proportion p i j of the criterion j:
p i j = r i j  m i=1 r i j .(2)
The entropy e j of the criterion j:
e j = k m  i=1 p i j ln(p i j ),(3)
with k = 1/ ln(m), and m denoting the total number of agents.</p>
<p>The weight  j of the criterion j:
 j = d j  n j=1 d j ,(4)
with d j = 1  e j the disparity of the criterion and n the total number of criteria.Conclusively, agent scores were derived via TOP-SIS.Multiplication of r i j by its respective weight  j yields the weighted normalized matrix V = [v i j ] with v i j =  j  r i j .The positive ideal solution v + j and negative ideal solution v  j were determined as v + j = max(v i j ) and v  j = min(v i j ), respectively.Then the geometric distances S + j and S  j from v i j to the positive and negative ideal solutions can be computed, respectively, as
S + j = n  j=1 v i j  v + j 2(5)
and
S  j = n  j=1 v i j  v  j 2 . (6)
The relative closeness C * i for each agent was calculated as:
C * i = S  j S + j + S  j(7)
A higher C * i signifies superior agent performance relative to peers on the assigned RP.</p>
<p>ASSOCIATED CONTENT Supporting Information</p>
<p>The following Supporting Information is available free of charge.</p>
<p>Partial results for gravitational simulation mission along with examples of reports written by ASAs (SI.pdf); partial AutoProgs and experimental result files for RP 1-3, main AI generating RP, and Multi-tier human RP (Some information has been obscured; readers can replace it with their own information and follow the instructions to run the AutoProgs) (SI-data-1.zip and SI-data-2.zip);a demo video demonstrating the operation process of the automatic research system (SI-video.mp4).</p>
<p>Fig. 1 A
1
Fig. 1 A. Schematic diagram of the AI automation process for theoretical simulation research conducted in this study.The human researcher writes the research plan (RP) for the theoretical simulation and provides it to the autonomous simulation agent (ASA), which is developed by sophisticated API programming (see Method section).The ASA first generates the simulation program, then uploads it to a remote server, performs simulation calculations with different parameter conditions, collects data, and finally writes a report based on the simulation results.B. Diagram of the ASA dialogue.The human researcher only inputs the RP at the beginning, and then the ASA makes decisions based on the dialogue history, achieving a fully autonomous research mode.C. Two typical simulation problems studied in this paper: the chain conformation simulation of a random walk and the gravitational model simulation of asteroid orbit prediction (See SI).</p>
<p>Fig. 2
2
Fig.2Overview of RP 1-3.We designed three RPs related to polymer chain simulation, each containing multiple steps such as simulation, plotting, and report writing, and provided them to the ASA.RP 1 and RP 3 required the ASA to generate a complete Python program to simulate polymer chains, run the simulation locally, and produce a final report.RP 2 required the ASA to modify the provided simulation program, run the simulation on a remote server, and then generate a report.The provided simulation program (omitted in the figure) and remote server information were included in RP 2.</p>
<p>Fig. 3
3
Fig. 3 Completion Rates of Various ASAs for RP 1-3. A. Table of LLM models used in this study.B. Statistics of the number of criteria met by each ASA over 20 experiments.We established seven criteria for RP 1-3 to measure mission completion rates and counted the number of times each ASA met these criteria across 20 experiments.Some zero results are not displayed.C. ASA Scoring.Relative scores for each ASA in RP 1-3 were calculated using the EWM and TOPSIS methods.D. ASA Generated Research Report Example.Demonstrates a Word report generated by ASA-GPT-4 for RP 1, including four sections, chain conformation diagrams and a scaling relation fit plot (also see SI).</p>
<p>Fig. 4
4
Fig.4Recommended practices for fully autonomous research.By conducting iterative dialogues with the LLM adhering to a specific design logic, the success rate and efficiency of the automated process are enhanced.The diagrams on the left and right illustrate scenarios without and with the implementation of these strategies, respectively.</p>
<p>Devlin, J.; Chang, M.-W.; Lee, K.; Toutanova, K. BERT: Pretraining of Deep Bidirectional Transformers for Language Un-
ACKNOWLEDGEMENTS J.F.L. acknowledge supports from National Natural Science Foundation of China (Nos.52394272, 22373022) and National Key Research and Development Program of China (No. 2023YFA0915300).Notes and referencesAUTHOR INFORMATIONCorresponding AuthorJianfeng LiAuthor ContributionsZ.H.L. was the primary author of the paper.Y.B.C. was responsible for part of the data analysis and statistics.J.F.L. originally initiated and supervised the project.NotesThe authors declare no competing financial interest.
Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, Minnesota20191</p>
<p>Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, Journal of Machine Learning Research. 212020</p>
<p>GPT-3: Its Nature, Scope, Limits, and Consequences. Minds and Machines. L Floridi, M Chiriatti, 202030</p>
<p>PaLM: Scaling Language Modeling with Pathways. A Chowdhery, Journal of Machine Learning Research. 241132022</p>
<p>R Thoppilan, arXiv:2201.08239Language Models for Dialog Applications. 2022</p>
<p>Anthropic Model Card and Evaluations for Claude Models. 2023</p>
<p>Zero-shot text-to-image generation. A Ramesh, M Pavlov, G Goh, S Gray, C Voss, A Radford, M Chen, I Sutskever, 2021</p>
<p>On the Opportunities and Risks of Foundation Models. R Bommasani, arXiv:2108.072582022</p>
<p>A Survey on Evaluation of Large Language Models. Y Chang, ACM Transactions on Intelligent Systems and Technology. 152024</p>
<p>ChatGPT for good? On opportunities and challenges of large language models for education. E Kasneci, Learning and Individual Differences. 1031022742023</p>
<p>L Himanen, A Geurts, A S Foster, P Rinke, Data-Driven Materials Science: Status, Challenges, and Perspectives. Advanced Science. 2019. 19008086</p>
<p>R Taylor, M Kardas, G Cucurull, arXiv:2211.09085A Large Language Model for Science. 2022</p>
<p>Scientific discovery in the age of artificial intelligence. H Wang, T Fu, Y Du, Nature. 6202023</p>
<p>Protein complex prediction with AlphaFold-Multimer. R Evans, M O'neill, A Pritzel, bioRxiv:2021.10.04.4630342021</p>
<p>Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature. J Abramson, J Adler, J Dunger, 2024630</p>
<p>GuacaMol: Benchmarking Models for de Novo Molecular Design. N Brown, M Fiscato, M Segler, Journal of Chemical Information and Modeling. 592019</p>
<p>A deep learning approach to antibiotic discovery. J M Stokes, K Yang, K Swanson, Cell. 1802020</p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, Nature. 6242023</p>
<p>Augmenting large language models with chemistry tools. M Bran, A Cox, S Schilter, Nature Machine Intelligence. 62024</p>
<p>ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models. Y Kang, J Kim, Nature Communications. 1547052024</p>
<p>Leveraging large language models for predictive chemistry. K M Jablonka, P Schwaller, A Ortega-Guerrero, Nature Machine Intelligence. 62024</p>
<p>S Schulhoff, M Ilie, N Balepur, arXiv:2406.06608The Prompt Report: A Systematic Survey of Prompting Techniques. 2024</p>
<p>Z Zhou, X Ning, K Hong, arXiv:2404.14294A Survey on Efficient Inference for Large Language Models. 2024</p>
<p>The rise of self-driving labs in chemical and materials sciences. M Abolhasani, E Kumacheva, Nature Synthesis. 22023</p>
<p>An autonomous laboratory for the accelerated synthesis of novel materials. N J Szymanski, B Rendy, Y Fei, Nature 2023624</p>
<p>AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning. A A Volk, R W Epps, D T Yonemoto, Nature Communications. 1414032023</p>
<p>Statistical Mechanics of Chain Molecules. P J Flory, 1969Interscience Publishers</p>
<p>Scaling concepts in polymer physics. P G De Gennes, 1979Cornell University Press</p>
<p>The self-avoiding walk. N Madras, G Slade, 2013Birkhuser Boston</p>
<p>Static and Dynamic Light Scattering from Branched Polymers and Biopolymers. W Burchard, Advances in Polymer Science 1983. 48</p>
<p>Large Language Models for Code Analysis: Do LLMs Really Do Their Job?. C Fang, N Miao, S Srivastav, arXiv:2310.123572023</p>
<p>Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability of Large Language Model Code Generation. L Zhong, Z Wang, arXiv:2308.103352023</p>
<p>L Murr, M Grainger, D Gao, arXiv:2311.07599Testing LLMs on Code Generation with Varying Levels of Prompt Specificity. 2023</p>
<p>The pivot algorithm: A highly efficient Monte Carlo method for the self-avoiding walk. N Madras, A D Sokal, Journal of Statistical Physics. 501988</p>
<p>T B Brown, B Mann, N Ryder, arXiv:2005.14165Language Models are Few-Shot Learners. 2020</p>
<p>Making Pre-trained Language Models Better Few-shot Learners. T Gao, A Fisch, D Chen, arXiv:2012.157232020</p>
<p>Finetuned Language Models are Zero-Shot Learners. J Wei, M Bosma, V Y Zhao, K Guu, A W Yu, B Lester, N Du, A M Dai, Q V Le, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. April 25-29, 2022. 2022</p>
<p>Operations Research Principles &amp; Practice. A Ravindran, D T Phillips, J J Solberg, 1987John WileyNew York2nd ed.</p>
<p>Multiple Attribute Decision Making. C L Hwang, K Yoon, </p>            </div>
        </div>

    </div>
</body>
</html>