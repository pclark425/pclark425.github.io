<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2473 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2473</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2473</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-272581738</p>
                <p><strong>Paper Title:</strong> Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning</p>
                <p><strong>Paper Abstract:</strong> Thermo-catalytic conversion of CO2 into more valuable compounds, such as methane, is an attractive strategy for energy storage in chemical bonds and creating a carbon-based circular economy. However, designing heterogeneous catalysts remains a challenging, time- and resource-consuming task. Herein, we present an interpretable, human-in-the-loop active machine learning framework to efficiently plan catalytic experiments, execute them in an automated set-up, and estimate the effect of experimental variables on the catalytic activity. A dataset with 48 catalytic activity tests was compiled from a design space of Ni–Co/Al2O3 catalysts with over 50 million potential combinations in only eight iterations. This small dataset was found sufficient to predict CO2 conversion, methane selectivity, and methane space–time yield with remarkable accuracy (R2 > 0.9) for untested catalysts and reaction conditions. New experiments and catalysts were selected with this methodology, leading to experimental conditions that improved the methane space–time yield by nearly 50% in comparison to the previously obtained maximum in the dataset. Interpretation of the model predictions unveiled the effect of each catalyst descriptor and reaction condition on the outcome. Particularly, the strong predicted inverse trend between the calcination temperature and the catalytic activity was validated experimentally, and characterization implied an underlying structure–performance relationship. Finally, it is demonstrated that the deployed active learning model is excellently suited to predict and fit kinetic trends with a minimal amount of data. This data-driven framework is a first step to faster, model-based, and interpretable design of catalysts and holds promise for broader applications across catalytic processes.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2473.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2473.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GandALF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian n-dimensional Active Learning Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pool-based active learning design-of-experiments framework that selects experiments by optimizing informativeness, representativeness, and diversity across continuous, discrete, and categorical design spaces; used here in a human-in-the-loop workflow for catalyst optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian n-dimensional Active Learning Framework (GandALF)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GandALF is a pool-based design-of-experiments and active learning framework that draws a large unlabeled pool from the design space (default P = 100,000) and iteratively selects experiments to perform. Selection of new experiments is driven by three explicit criteria: (1) informativeness — choose points that add new information to the predictive model while minimizing redundancy with existing labeled data; (2) representativeness — prefer points that follow the underlying distribution of the pool and are not outliers relative to the training set; (3) diversity — ensure the chosen batch of experiments are sufficiently different from one another. Initial experiments are selected by clustering the pool (k-means) into a fixed number of clusters and taking centroids (in this work initial n = 5). The framework is model-agnostic and was used with Gaussian processes, random forests, and XGBoost regressors in this study; it is applied in a human-in-the-loop manner where model predictions and uncertainty inform experimental acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Catalysis/materials science experimental design (CO2 hydrogenation catalyst optimization); generally applicable to experimental design across continuous/discrete/categorical variables.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Pool-based batch selection from a large unlabeled pool (P = 100,000) using a multi-criterion acquisition that combines informativeness (to add non-redundant information to the model), representativeness (to avoid outliers and follow the distribution of the design space), and diversity (to ensure batch diversity). Initial allocation uses k-means clustering to allocate a small fixed number of initial experiments (n = 5). Subsequent allocations choose batches that optimize the combined criteria; the paper does not report an explicit analytic weighting of the three criteria, only that selection is based on them.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicit multi-criterion acquisition balances exploration and exploitation via the three criteria: informativeness drives exploitation of model-uncertain/promising regions, representativeness constrains selections to typical regions of the design distribution (reducing risk of outlier exploration), and diversity forces exploration across the batch. The exact mathematical combination or scheduling of these criteria is not specified in the text provided.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Yes — diversity is enforced by (a) selecting sufficiently different experiments within each acquisition batch, and (b) at initialization by k-means clustering of the large unlabeled pool and selecting cluster centroids as initial experiments. The framework explicitly includes diversity as one of three selection criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed-number-of-experiments (implicit); pool-size limit for candidate generation (P = 100,000); small fixed initial batch size (n = 5) used for cold-start.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled implicitly by limiting the number of experiments per batch (initialization n = 5) and drawing candidate points from a finite pool (P = 100,000). No explicit monetary or compute-cost-aware optimization routine is described in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In this study, active learning with GandALF produced a training set of 48 data points ("48 data points collected via active learning"). For kinetic parameter prediction (integrated rate-law values) Gaussian processes trained on these data achieved R^2 > 0.98 and predictions within reported experimental error bars (~5%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Implicit comparison to prior (uninformed) predictions: examples include prior vs posterior light-off curve prediction (prior without system knowledge vs posterior after one experiment). No formal numerical baseline (e.g., random search) is reported in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Posterior predictions (after performing experiments selected by active learning) improved compared to prior predictions; after adding labeled data the Gaussian process predictions of integrated rate-law achieved high accuracy (R^2 > 0.98) and agreement within ~5% experimental error. No direct numerical comparison to randomized or other baseline allocation strategies is provided in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper states the framework trades off informativeness, representativeness, and diversity when selecting experiments, implicitly balancing information gain (informativeness) against risk of sampling outliers (representativeness) and desire for hypothesis-space coverage (diversity). However, no quantitative analysis is provided in the supplied text that measures trade-offs between computational/experimental cost, information gain, diversity, and discovery probability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Practical recommendations reported: use a large pool of unlabeled candidate points (P default 100,000), initialize with k-means clustering to select a small diverse set of seed experiments (n = 5), and select subsequent batches by jointly considering informativeness, representativeness, and diversity. No closed-form optimal allocation policy or cost-aware optimization is reported in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2473.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2473.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>k-means init</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>k-means clustering initialization for experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using k-means clustering on the candidate pool to choose cluster centroids as initial experiments to ensure representativeness and diversity in the cold-start of active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Algorithm AS 136: A K-Means Clustering Algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>k-means clustering for initial experiment selection</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The pool of unlabeled candidate experiments is clustered using k-means and the centroids of the clusters are selected as initial experiments. In this work the authors used k-means to select 5 initial experiments (cold-start) from the large candidate pool to provide representative and diverse starting data for the active learning loop.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Initialization stage of experimental-design active learning; applied here to catalyst experiments but broadly applicable to experimental domains.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates a small, fixed number of initial runs by choosing centroids of k clusters to maximize representativeness and initial coverage. The number of clusters/initial experiments is set by the experimenter (in this work = 5).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Provides an exploratory, diversity-focused initialization to seed the model and thereby bootstrap exploitation in subsequent rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Yes — k-means clustering creates spatially separated clusters in the candidate pool and selecting centroids promotes diversity and representativeness across the design space.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed small-number initialization (n = 5 in this study).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by explicitly setting the number of clusters/initial experiments; no cost optimization is described.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Initial batch size used was 5 experiments; no further numerical metrics for k-means beyond its role in initialization are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>k-means initialization is presented as increasing representativeness and diversity for cold-start, but no quantitative tradeoff analysis is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation: use clustering-based initial selection (k-means) to obtain representative and diverse seed experiments; choose a small fixed number of initial experiments appropriate to the study (here 5).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2473.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2473.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mahalanobis criterion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mahalanobis distance outlier/representativeness criterion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of Mahalanobis distance to quantify how far a candidate experiment's feature vector lies from the distribution of the current training set, enabling detection of outliers and supporting the representativeness selection criterion.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Mahalanobis distance criterion for representativeness/outlier detection</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mahalanobis distance is computed between a candidate experiment's 7-dimensional experimental-variable vector and the covariance matrix of the training set (d_M^2 = z^T Λ'^{-1} z). It measures how atypical a candidate is relative to the labeled data distribution and is used to enforce the representativeness requirement by avoiding selection of outliers.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used within the active learning/experimental design pipeline for catalytic experiments in this study; general-purpose measure for multivariate outlier detection in experimental design.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Acts as a filter or penalty in the acquisition selection: experiments with large Mahalanobis distance from the training set are considered outliers and deprioritized to maintain representativeness.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Contributes to the exploration-exploitation balance by constraining exploration (penalizing outliers) while allowing exploration within the distribution of known data.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Indirect: it discourages selection of extreme outliers but does not itself enforce intra-batch diversity; used together with diversity criterion in GandALF.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Mahalanobis distance is used to trade off representativeness against exploration; selecting points with low Mahalanobis distance avoids high-risk outlier experiments, but no quantitative tradeoff analysis is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation: use Mahalanobis distance relative to the training set covariance to avoid selecting outliers and ensure representativeness when allocating experimental runs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2473.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2473.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Expected Model Output Changes (reference)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Selecting Influential Examples: Active Learning with Expected Model Output Changes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced active learning approach that selects examples expected to induce the largest change in model outputs; relevant to acquisition strategies based on expected impact on the predictive model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Selecting Influential Examples: Active Learning with Expected Model Output Changes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Expected Model Output Changes active learning</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A literature method (cited) which quantifies the expected change in the model's outputs if a candidate were labeled and added to the training set, using this expected model-change as an acquisition score; relevant to informativeness-driven selection.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General active learning for machine learning models (computer vision in original citation, but methodology is applicable across domains).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select candidates that maximize expected change in model outputs (proxy for informativeness).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected model output change (proxy for informativeness/expected information), as per the cited method.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Primarily an informativeness-driven (exploitative) acquisition; may be combined with diversity or representativeness constraints in hybrid methods.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2473.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2473.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active-learning pyrolysis (reference)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active learning-based exploration of the catalytic pyrolysis of plastic waste</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced applied active learning study exploring catalytic pyrolysis of plastic waste, cited as an example of active learning-driven experimental exploration in catalytic contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Active learning-based exploration of the catalytic pyrolysis of plastic waste</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Active learning-based experimental exploration (pyrolysis study)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced applied study that used active learning to guide experimental exploration of catalytic pyrolysis; details are cited but not described in the current paper's main text.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Catalysis / catalytic pyrolysis of plastic waste (applied experimental design).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Selecting Influential Examples: Active Learning with Expected Model Output Changes <em>(Rating: 2)</em></li>
                <li>Active learning-based exploration of the catalytic pyrolysis of plastic waste <em>(Rating: 2)</em></li>
                <li>Algorithm AS 136: A K-Means Clustering Algorithm <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2473",
    "paper_id": "paper-272581738",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "GandALF",
            "name_full": "Gaussian n-dimensional Active Learning Framework",
            "brief_description": "A pool-based active learning design-of-experiments framework that selects experiments by optimizing informativeness, representativeness, and diversity across continuous, discrete, and categorical design spaces; used here in a human-in-the-loop workflow for catalyst optimization.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Gaussian n-dimensional Active Learning Framework (GandALF)",
            "system_description": "GandALF is a pool-based design-of-experiments and active learning framework that draws a large unlabeled pool from the design space (default P = 100,000) and iteratively selects experiments to perform. Selection of new experiments is driven by three explicit criteria: (1) informativeness — choose points that add new information to the predictive model while minimizing redundancy with existing labeled data; (2) representativeness — prefer points that follow the underlying distribution of the pool and are not outliers relative to the training set; (3) diversity — ensure the chosen batch of experiments are sufficiently different from one another. Initial experiments are selected by clustering the pool (k-means) into a fixed number of clusters and taking centroids (in this work initial n = 5). The framework is model-agnostic and was used with Gaussian processes, random forests, and XGBoost regressors in this study; it is applied in a human-in-the-loop manner where model predictions and uncertainty inform experimental acquisition.",
            "application_domain": "Catalysis/materials science experimental design (CO2 hydrogenation catalyst optimization); generally applicable to experimental design across continuous/discrete/categorical variables.",
            "resource_allocation_strategy": "Pool-based batch selection from a large unlabeled pool (P = 100,000) using a multi-criterion acquisition that combines informativeness (to add non-redundant information to the model), representativeness (to avoid outliers and follow the distribution of the design space), and diversity (to ensure batch diversity). Initial allocation uses k-means clustering to allocate a small fixed number of initial experiments (n = 5). Subsequent allocations choose batches that optimize the combined criteria; the paper does not report an explicit analytic weighting of the three criteria, only that selection is based on them.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Explicit multi-criterion acquisition balances exploration and exploitation via the three criteria: informativeness drives exploitation of model-uncertain/promising regions, representativeness constrains selections to typical regions of the design distribution (reducing risk of outlier exploration), and diversity forces exploration across the batch. The exact mathematical combination or scheduling of these criteria is not specified in the text provided.",
            "diversity_mechanism": "Yes — diversity is enforced by (a) selecting sufficiently different experiments within each acquisition batch, and (b) at initialization by k-means clustering of the large unlabeled pool and selecting cluster centroids as initial experiments. The framework explicitly includes diversity as one of three selection criteria.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed-number-of-experiments (implicit); pool-size limit for candidate generation (P = 100,000); small fixed initial batch size (n = 5) used for cold-start.",
            "budget_constraint_handling": "Handled implicitly by limiting the number of experiments per batch (initialization n = 5) and drawing candidate points from a finite pool (P = 100,000). No explicit monetary or compute-cost-aware optimization routine is described in the provided text.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "In this study, active learning with GandALF produced a training set of 48 data points (\"48 data points collected via active learning\"). For kinetic parameter prediction (integrated rate-law values) Gaussian processes trained on these data achieved R^2 &gt; 0.98 and predictions within reported experimental error bars (~5%).",
            "comparison_baseline": "Implicit comparison to prior (uninformed) predictions: examples include prior vs posterior light-off curve prediction (prior without system knowledge vs posterior after one experiment). No formal numerical baseline (e.g., random search) is reported in the provided text.",
            "performance_vs_baseline": "Posterior predictions (after performing experiments selected by active learning) improved compared to prior predictions; after adding labeled data the Gaussian process predictions of integrated rate-law achieved high accuracy (R^2 &gt; 0.98) and agreement within ~5% experimental error. No direct numerical comparison to randomized or other baseline allocation strategies is provided in the text.",
            "efficiency_gain": null,
            "tradeoff_analysis": "The paper states the framework trades off informativeness, representativeness, and diversity when selecting experiments, implicitly balancing information gain (informativeness) against risk of sampling outliers (representativeness) and desire for hypothesis-space coverage (diversity). However, no quantitative analysis is provided in the supplied text that measures trade-offs between computational/experimental cost, information gain, diversity, and discovery probability.",
            "optimal_allocation_findings": "Practical recommendations reported: use a large pool of unlabeled candidate points (P default 100,000), initialize with k-means clustering to select a small diverse set of seed experiments (n = 5), and select subsequent batches by jointly considering informativeness, representativeness, and diversity. No closed-form optimal allocation policy or cost-aware optimization is reported in the provided text.",
            "uuid": "e2473.0",
            "source_info": {
                "paper_title": "Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "k-means init",
            "name_full": "k-means clustering initialization for experimental design",
            "brief_description": "Using k-means clustering on the candidate pool to choose cluster centroids as initial experiments to ensure representativeness and diversity in the cold-start of active learning.",
            "citation_title": "Algorithm AS 136: A K-Means Clustering Algorithm",
            "mention_or_use": "use",
            "system_name": "k-means clustering for initial experiment selection",
            "system_description": "The pool of unlabeled candidate experiments is clustered using k-means and the centroids of the clusters are selected as initial experiments. In this work the authors used k-means to select 5 initial experiments (cold-start) from the large candidate pool to provide representative and diverse starting data for the active learning loop.",
            "application_domain": "Initialization stage of experimental-design active learning; applied here to catalyst experiments but broadly applicable to experimental domains.",
            "resource_allocation_strategy": "Allocates a small, fixed number of initial runs by choosing centroids of k clusters to maximize representativeness and initial coverage. The number of clusters/initial experiments is set by the experimenter (in this work = 5).",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Provides an exploratory, diversity-focused initialization to seed the model and thereby bootstrap exploitation in subsequent rounds.",
            "diversity_mechanism": "Yes — k-means clustering creates spatially separated clusters in the candidate pool and selecting centroids promotes diversity and representativeness across the design space.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed small-number initialization (n = 5 in this study).",
            "budget_constraint_handling": "Handled by explicitly setting the number of clusters/initial experiments; no cost optimization is described.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Initial batch size used was 5 experiments; no further numerical metrics for k-means beyond its role in initialization are reported.",
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "k-means initialization is presented as increasing representativeness and diversity for cold-start, but no quantitative tradeoff analysis is provided.",
            "optimal_allocation_findings": "Recommendation: use clustering-based initial selection (k-means) to obtain representative and diverse seed experiments; choose a small fixed number of initial experiments appropriate to the study (here 5).",
            "uuid": "e2473.1",
            "source_info": {
                "paper_title": "Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Mahalanobis criterion",
            "name_full": "Mahalanobis distance outlier/representativeness criterion",
            "brief_description": "Use of Mahalanobis distance to quantify how far a candidate experiment's feature vector lies from the distribution of the current training set, enabling detection of outliers and supporting the representativeness selection criterion.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Mahalanobis distance criterion for representativeness/outlier detection",
            "system_description": "Mahalanobis distance is computed between a candidate experiment's 7-dimensional experimental-variable vector and the covariance matrix of the training set (d_M^2 = z^T Λ'^{-1} z). It measures how atypical a candidate is relative to the labeled data distribution and is used to enforce the representativeness requirement by avoiding selection of outliers.",
            "application_domain": "Used within the active learning/experimental design pipeline for catalytic experiments in this study; general-purpose measure for multivariate outlier detection in experimental design.",
            "resource_allocation_strategy": "Acts as a filter or penalty in the acquisition selection: experiments with large Mahalanobis distance from the training set are considered outliers and deprioritized to maintain representativeness.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Contributes to the exploration-exploitation balance by constraining exploration (penalizing outliers) while allowing exploration within the distribution of known data.",
            "diversity_mechanism": "Indirect: it discourages selection of extreme outliers but does not itself enforce intra-batch diversity; used together with diversity criterion in GandALF.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Mahalanobis distance is used to trade off representativeness against exploration; selecting points with low Mahalanobis distance avoids high-risk outlier experiments, but no quantitative tradeoff analysis is provided.",
            "optimal_allocation_findings": "Recommendation: use Mahalanobis distance relative to the training set covariance to avoid selecting outliers and ensure representativeness when allocating experimental runs.",
            "uuid": "e2473.2",
            "source_info": {
                "paper_title": "Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Expected Model Output Changes (reference)",
            "name_full": "Selecting Influential Examples: Active Learning with Expected Model Output Changes",
            "brief_description": "A referenced active learning approach that selects examples expected to induce the largest change in model outputs; relevant to acquisition strategies based on expected impact on the predictive model.",
            "citation_title": "Selecting Influential Examples: Active Learning with Expected Model Output Changes",
            "mention_or_use": "mention",
            "system_name": "Expected Model Output Changes active learning",
            "system_description": "A literature method (cited) which quantifies the expected change in the model's outputs if a candidate were labeled and added to the training set, using this expected model-change as an acquisition score; relevant to informativeness-driven selection.",
            "application_domain": "General active learning for machine learning models (computer vision in original citation, but methodology is applicable across domains).",
            "resource_allocation_strategy": "Select candidates that maximize expected change in model outputs (proxy for informativeness).",
            "computational_cost_metric": null,
            "information_gain_metric": "Expected model output change (proxy for informativeness/expected information), as per the cited method.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Primarily an informativeness-driven (exploitative) acquisition; may be combined with diversity or representativeness constraints in hybrid methods.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2473.3",
            "source_info": {
                "paper_title": "Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Active-learning pyrolysis (reference)",
            "name_full": "Active learning-based exploration of the catalytic pyrolysis of plastic waste",
            "brief_description": "A referenced applied active learning study exploring catalytic pyrolysis of plastic waste, cited as an example of active learning-driven experimental exploration in catalytic contexts.",
            "citation_title": "Active learning-based exploration of the catalytic pyrolysis of plastic waste",
            "mention_or_use": "mention",
            "system_name": "Active learning-based experimental exploration (pyrolysis study)",
            "system_description": "Referenced applied study that used active learning to guide experimental exploration of catalytic pyrolysis; details are cited but not described in the current paper's main text.",
            "application_domain": "Catalysis / catalytic pyrolysis of plastic waste (applied experimental design).",
            "resource_allocation_strategy": null,
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": null,
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2473.4",
            "source_info": {
                "paper_title": "Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Selecting Influential Examples: Active Learning with Expected Model Output Changes",
            "rating": 2,
            "sanitized_title": "selecting_influential_examples_active_learning_with_expected_model_output_changes"
        },
        {
            "paper_title": "Active learning-based exploration of the catalytic pyrolysis of plastic waste",
            "rating": 2,
            "sanitized_title": "active_learningbased_exploration_of_the_catalytic_pyrolysis_of_plastic_waste"
        },
        {
            "paper_title": "Algorithm AS 136: A K-Means Clustering Algorithm",
            "rating": 1,
            "sanitized_title": "algorithm_as_136_a_kmeans_clustering_algorithm"
        }
    ],
    "cost": 0.010858749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Accelerated Design of Nickel-Cobalt Based Catalysts for CO 2 Hydrogenation with Human-in-the-Loop Active Machine Learning</p>
<p>Yasemen Kuddusi yasemen.kuddusi@epfl.ch 
Institute of Chemical Sciences and Engineering (ISIC)
Basic Science Faculty (SB)
Laboratory of Materials for Renewable Energy (LMER)
École Polytechnique Fédérale de Lausanne (EPFL) Valais/Wallis
Rue de l'Industrie 171951Energypolis, SionSwitzerland</p>
<p>Empa Materials Science &amp; Technology
8600DübendorfSwitzerland</p>
<p>Maarten R Dobbelaere 
Department of Materials
Textiles and Chemical Engineering
Laboratory for Chemical Technology
Ghent University
Technologiepark 1259052GentBelgium</p>
<p>Kevin M Van Geem 
Department of Materials
Textiles and Chemical Engineering
Laboratory for Chemical Technology
Ghent University
Technologiepark 1259052GentBelgium</p>
<p>Andreas Züttel 
Institute of Chemical Sciences and Engineering (ISIC)
Basic Science Faculty (SB)
Laboratory of Materials for Renewable Energy (LMER)
École Polytechnique Fédérale de Lausanne (EPFL) Valais/Wallis
Rue de l'Industrie 171951Energypolis, SionSwitzerland</p>
<p>Empa Materials Science &amp; Technology
8600DübendorfSwitzerland</p>
<p>Accelerated Design of Nickel-Cobalt Based Catalysts for CO 2 Hydrogenation with Human-in-the-Loop Active Machine Learning
40E9D1B009494F3D80CC9C9ABD8E28AF</p>
<p>S1. Code Availability</p>
<p>The entire source code is provided as open-source software under MIT license in the following repository: https://www.github.com/mrodobbe/gandalf-doe. All conclusions from the paper can be reproduced using the provided scripts.A demo notebook is available in the folder notebooks/demo.ipynb.</p>
<p>S2. Hyperparameter Optimization</p>
<p>The key hyperparameters of each model were optimized via grid search.The optimized hyperparameters are marked in bold.</p>
<p>S2.1. Extreme Gradient Boosting</p>
<p>S3. Gaussian n-dimensional Active Learning Framework (GandALF)</p>
<p>The Gaussian n-dimensional Active Learning Framework (GandALF) was applied in this study and in this section, we repeat the working principle of this algorithm [1].</p>
<p>GandALF is a versatile design-of-experiments tool that can handle continuous, discrete, and categorical variables.It selects the next experiment or set of experiments based on informativeness, representativeness, and diversity.The informativeness criterion imposes that an experiment should be chosen so that it adds information to the model while minimizing the information redundancy.An experiment is representative when it follows the distribution of experiments and is not an outlier.The diversity is guaranteed when experiments are selected that are sufficiently different from each other.Before initiating the experiments, a pool of P unlabeled data points is drawn from the design space.Here, the pool size P is kept at the default size of 100,000.The initial experiments are selected by clustering the pool of potential experiments into (in this work: = 5) initial experiments using the k-means algorithm [2].The centroid of</p>
<p>S4.2. Catalytic Activity Tests</p>
<p>Table S3.1.Overview of all experiments performed in this work with the experimental variables and output metrics.
T [K] P [bar] GHSV [ml/h/g] Ni [%] Co [%] T calc [K] T red [K] Y CH 4 [%] X CO 2 [%] S CH 4 [%] S CO [%] STY CH 4 [g/h/</p>
<p>S5. Mahalanobis Distance Criterion</p>
<p>The Mahalanobis distance (d M ) measures the distance between a distribution of data points and a single data point.In this case, the distance is measured between a set of experimental variables and the training set.It is calculated via eq (S1).
𝑑 2 𝑀 = 𝑧 𝑇 Λ ' -1 𝑧 (S1)
In eq (S1), is a column vector containing the seven experimental variables and is the
𝑧 Λ' 7 × 7
covariance matrix of the experimental variables in the dataset.</p>
<p>S12 S6. SHAP Values</p>
<p>The importance of a feature in a model can be visualized using summary plots.These plots sort the features vertically by importance.In each row, the SHAP value per data point is given.The color of this dot indicates the value of the feature.For example, a red dot in the temperature row indicates a set of experimental variables that includes a high temperature value.A first requirement is the experimental determination of the reaction order which was given in  equation (S8).This parameter cannot be estimated since the H 2 /CO 2 ratio is kept constant in the design space.The reaction order for CO 2 is determined from the slope of the linear fits in  S17 kJ/mol.These values are in the order of magnitude of the activation energies that are found for similar catalytic systems, ranging between 70 and 100 kJ/mol [6], [7], [8], [9].</p>
<p>S8. Light-Off Curve</p>
<p></p>
<p>Extreme gradient boosting (XGB) models are created with the open-source software XGBoost (version 1.6.2) in python 3.7.The following XGB hyperparameters are optimized via grid search:  Number of estimators: [500, 1000, 2500, 5000, 10000]  Maximum depth: [2, 3, 4]  Learning rate: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 0.75]  Subsample: [0.05, 0.1, 0.25, 0.5, 0.6, 0.7, 0.75, 1] Tree method: [histograms, exact] S2.2.Random Forests Random forests (RF) regressors are implemented via scikit-learn (version 1.3.2 in python 3.11).The following RF hyperparameters are optimized via grid search:  Number of estimators: [100, 500, 1000]  Maximum depth: [None, 2, 5]  Maximum features: [sqrt, log2]  Minimal samples per split: [2, 5, 10] S2.3.Gaussian Processes Gaussian process regression (GP) is implemented via GPy (version 1.12 in python 3.7).The following GP hyperparameters are optimized via grid search:  Kernel: [Rational quadratic, exponential, linear, Matérn 32, Matérn 52, radial basis function]</p>
<p>Figure S3. 1 .
1
Figure S3.1.Plan of the experimental setup with gas supply and controlling unit, the microreactor and the gas analysis unit.</p>
<p>Figure S3. 2 .
2
Figure S3.2.Thermogravimetric analysis (TGA) of 15Ni-5Co/Al 2 O 3 under air flow heating up to 700°C with a heating rate of 5°C/min.Residual mass curve is represented by the black line and</p>
<p>Figure S3. 3 .
3
Figure S3.3.Ni 2p XPS spectra of (a) c623 (b) c673 (c) c723 (d) c773 (e) c823 (f) c873.Orange species represent NiAl 2 O 4 and blue species represent NiO.</p>
<p>Figures S5.1 to S5.3 show the summary plots that are created for XGB models trained on CO 2 conversion, CH 4 selectivity, and CH 4 space-time yield.These summary plots were created using a single model of which the hyperparameters were optimized with stratified k-fold cross-validation.The training sets were the same of the interpolative model (48 data points collected via active learning).</p>
<p>Figure S5. 1 .
1
Figure S5.1.Summary plot between experimental variable and the impact on the CO 2 conversion.</p>
<p>Figure S5. 2 .
2
Figure S5.2.Summary plot between experimental variable and the impact on the CH 4 selectivity.</p>
<p>Figure S5. 3 .
3
Figure S5.3.Summary plot between experimental variable and the impact on the CH 4 space-time yield.</p>
<p>Figure S6. 4 .
4
a and found to be 0.08 for the 19Ni-4Co/Al 2 O 3 and 0.06 for the 21Ni-3Co/Al 2 O 3 .In the modeling approach used here, which assumes a fractional rate law, the next step consists of deriving the Arrhenius parameters.This is done by varying the residence time at different temperatures.The rate coefficient is in this rate-law model determined by plotting the integrated rate law versus the residence time.The y-axis values are predicted using the model trained on the CO 2 conversion, .To ensure the interpolative regime and ascertain accuracy, one measurement   2 is added to the training set at each different GHSV.It is seen in Figure S6.4.b that high accuracy (R²&gt;0.98) is achieved and the agreement between model and experimental data is in all cases within the 5% error bars.Nevertheless, to determine the Arrhenius parameters, a linear trend has to be obtained and despite the low absolute error, the model is too noisy extract these Arrhenius parameters.Experimentally, the activation energies are obtained with a highly linear trend, as shown in Figure S6.4.c.It was found that the 19Ni-4Co/Al 2 O 3 sample has an activation energy of approximately 89 kJ/mol, while the 21Ni-3Co/Al 2 O 3 sample has a lower activation energy of 73</p>
<p>Figure S6. 4 .
4
Figure S6.4.Experiments to derive the kinetic parameters of 19Ni-4Co/Al2O3 catalyst, calcinated at 723 K, reduced at 873 K (orange) and 21Ni-3Co/Al2O3 catalyst, calcinated at 673 K, reduced at 823 K (blue).(a) Linear regression to determine the reaction order.(b) Parity plot for the prediction of the integrated rate law values with Gaussian processes.(c) Linear regression of experimental rate constants with respect to temperature to determine the activation energy.</p>
<p>Figure S7. 1 .
1
Figure S7.1.Prior light-off curve prediction without knowledge about the catalytic system for a 21Ni-3Co/Al 2 O 3 catalyst, calcinated at 673 K, reduced at 873 K.</p>
<p>Figure S7. 2 .
2
Figure S7.2.Predicted light-off curve after performing one experiment with the 21Ni-3Co/Al 2 O 3 catalyst, calcinated at 673 K, reduced at 873 K.</p>
<p>Table S3 .2. Mass residuals and changes retrieved from TGA of 15Ni-5Co/Al 2 O 3 under air flow heating up to 700°C with a heating rate of 5°C/min.
S3S4.4. XPS SpectraTemperature (°C)Mass change from 30 °CResidual mass from 30 °C(%)(%)35038.7061.9040039.3760.6145040.0559.9350040.3659.6255040.6359.3560040.8359.1665040.9958.9870041.1358.85S9</p>
<p>Table S3 .3. ESCA parameters of Ni 2p lines. XPS fitting details for NiO and NiAl 2 O 4 for main and satellite peaks. These parameters were retrieved from
S3
[4].
Ni 2p 3/2Ni 2p 1/2Main peakSatellite 1 Satellite 2 Main peak Satellite 1 Satellite 2E bFWHME bE bE b FWHME bE bNiO854.54.1856.4861.0 872.3 5.4874.2879.7NiAl 2 O 4 856.02.8858.1862.3 873.6 3.6875.7880.6</p>
<p>Table S3 .4. NiO percentages throughout the samples that are calcined at different temperatures.
S3S4.5. Textural PropertiesSample CodingNiO / (NiO+NiAl 2 O 4 )NiO / (NiO+NiAl 2 O 4 )at Ni 2p 3/2 (%)at Ni 2p 1/2 (%)c62310.5210.51c67311.7711.78c7237.7157.715c7736.5906.590c8233.8573.857c8732.4582.458S11</p>
<p>Table S3 .5. BET/BJH analysis results. Surface area, average pore volume and average pore size for 15Ni-5Co/Al 2 O 3 samples that are calcined at various temperatures.
S3Sample CodingBET surface areaBJH pore volumeBJH pore(m 2 g -1 )(cm 3 g -1 )diameter (nm)c623193.690.49509.7454c673199.080.534710.263c723197.890.554610.649c773192.350.557011.102c823193.500.543410.625c873192.790.557010.915
SUPPORTING INFORMATIONSupplementary Information (SI) for Catalysis Science &amp; Technology.This journal is © The Royal Society of Chemistry 2024S7. Validation by Kinetic ModelingA microkinetic model is directly interpretable and it provides a relationship between the catalyst structure and its performance.A trade-off lies in the prediction of kinetic parameters.To this extent, we make use of the CO 2 methanation modeling assumptions set by Mutschler et al.[5].Here, we create a model to validate the obtained results.The rate law that was derived in the work of Mutschler et al.[5]was used to calculate the activation energy and Arrhenius parameters.Below is a short overview of the equations required to derive the activation energy.The rate is defined as the change in partial pressure of CO 2 , as shown in equation (S2).We derive the rate law for the kinetically limited zone, in which we assume that the backward reaction is close to zero.We define the rate law in equation (S3), in which is the forward rateis the partial pressure of H 2 , and and are thereaction order with respect to CO 2 and H 2 .The Arrhenius equation (equation (S4)) relates with the pre-exponential factor A, the activation  + energy E A , the ideal gas constant R, the temperature T.Mutschler et al.[5]further assume that because of the stoichiometry of the reaction and the corresponding change in partial pressure (equation (S5)), the reaction orders of CO 2 and H 2 are linked.With the relationship between the partial pressures, the reaction rate can be rewritten as given in equation (S6).To determine the reaction order, the reaction rate is rewritten as a function of the space velocity (SV) and the conversion of CO 2 molecules (X CO2 ) (equation (S7)).The natural logarithm of equation (S7) allows to derive the reaction order , as shown in equationTo obtain the Arrhenius parameters, equation (S6) is rearranged to equation (S9) and integrated from the inlet partial pressure to the outlet partial pressure and from 0 to the residence The expression for the modified forward rate constant is then obtained in equation (S10).
Posterior light-off curve prediction for the 21Ni-3Co/Al 2 O 3 catalyst. Figure S7.3673</p>
<p>873 K after performing activity tests. </p>
<p>Active learning-based exploration of the catalytic pyrolysis of plastic waste. Y Ureel, 10.1016/j.fuel.2022.125340Fuel. 328125340Nov. 2022</p>
<p>Algorithm AS 136: A K-Means Clustering Algorithm. J A Hartigan, M A Wong, 10.2307/2346830Journal of the Royal Statistical Society. Series C (Applied Statistics). 2811979</p>
<p>Selecting Influential Examples: Active Learning with Expected Model Output Changes. A Freytag, E Rodner, J Denzler, Computer Vision -ECCV. D Fleet, T Pajdla, B Schiele, T Tuytelaars, ChamSpringer International Publishing2014. 2014</p>
<p>Curve Fitting Analysis of ESCA Ni 2p Spectra of Nickel-Oxygen Compounds and Ni/Al2O3 Catalysts. C P Li, A Proctor, D M Hercules, Appl. Spectrosc. 386Nov. 1984</p>
<p>Modelling the CO2 hydrogenation reaction over Co, Ni and Ru/Al2O3. R Mutschler, E Moioli, A Züttel, 10.1016/j.jcat.2019.05.023Journal of Catalysis. 375Jul. 2019</p>
<p>Intrinsic kinetics of CO2 methanation on low-loaded Ni/Al2O3 catalyst: Mechanism, model discrimination and parameter estimation. A Quindimil, 10.1016/j.jcou.2022.101888Journal of CO2 Utilization. 57101888Mar. 2022</p>
<p>CO and CO2 methanation over Ni/Al@Al2O3 core-shell catalyst. T A Le, J Kim, J K Kang, E D Park, 10.1016/j.cattod.2019.09.028Catalysis Today. 356Oct. 2020</p>
<p>A study of Ni/La-Al2O3 catalysts: A competitive system for CO2 methanation. G Garbarino, 10.1016/j.apcatb.2018.12.063Applied Catalysis B: Environmental. 248Jul. 2019</p>
<p>Methanation of carbon dioxide on Ru/Al2O3 and Ni/Al2O3 catalysts at atmospheric pressure: Catalysts activation, behaviour and stability. G Garbarino, D Bellotti, P Riani, L Magistri, G Busca, 10.1016/j.ijhydene.2015.05.059International Journal of Hydrogen Energy. 4030Aug. 2015</p>            </div>
        </div>

    </div>
</body>
</html>